{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA1NjA0NzE4", "number": 1964, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOVQxNjo1MDo0NFrODzbaKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNjo1MTo1MFrODzkp4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1MjUzMDM0OnYy", "diffSide": "RIGHT", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOVQxNjo1MDo0NFrOGH6GEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQyMzowODozMVrOGKPgQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTA0MA==", "bodyText": "Use the logger format with {}", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945040", "createdAt": "2020-04-19T16:50:44Z", "author": {"login": "goiri"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java", "diffHunk": "@@ -321,6 +321,7 @@ private void initHM() {\n   \n   protected void initRPC() throws IOException {\n     InetSocketAddress bindAddr = getRpcAddressToBindTo();\n+    LOG.info(\"ZKFC RpcServer binding to \" + bindAddr);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM5Mjk2Mg==", "bodyText": "Fixed", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r413392962", "createdAt": "2020-04-22T23:08:31Z", "author": {"login": "dhirajh"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java", "diffHunk": "@@ -321,6 +321,7 @@ private void initHM() {\n   \n   protected void initRPC() throws IOException {\n     InetSocketAddress bindAddr = getRpcAddressToBindTo();\n+    LOG.info(\"ZKFC RpcServer binding to \" + bindAddr);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTA0MA=="}, "originalCommit": {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1MjUzMTU4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOVQxNjo1MToyMlrOGH6Glw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQyMzowODo1OVrOGKPg5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTE3NQ==", "bodyText": "Use standard javadoc with a break line and add the param and the return.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945175", "createdAt": "2020-04-19T16:51:22Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -125,7 +128,21 @@ static int getZkfcPort(Configuration conf) {\n     return conf.getInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY,\n         DFSConfigKeys.DFS_HA_ZKFC_PORT_DEFAULT);\n   }\n-  \n+ \n+  /** Given a configuration get the bind host that could be used by ZKFC.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTYyNg==", "bodyText": "It kind of comes from HAUtil but let's make it right here.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945626", "createdAt": "2020-04-19T16:54:23Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -125,7 +128,21 @@ static int getZkfcPort(Configuration conf) {\n     return conf.getInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY,\n         DFSConfigKeys.DFS_HA_ZKFC_PORT_DEFAULT);\n   }\n-  \n+ \n+  /** Given a configuration get the bind host that could be used by ZKFC.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTE3NQ=="}, "originalCommit": {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM5MzEyNA==", "bodyText": "Fixed. Added javadoc", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r413393124", "createdAt": "2020-04-22T23:08:59Z", "author": {"login": "dhirajh"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -125,7 +128,21 @@ static int getZkfcPort(Configuration conf) {\n     return conf.getInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY,\n         DFSConfigKeys.DFS_HA_ZKFC_PORT_DEFAULT);\n   }\n-  \n+ \n+  /** Given a configuration get the bind host that could be used by ZKFC.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTE3NQ=="}, "originalCommit": {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1MjUzNzI1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOVQxNjo1NTo1M1rOGH6JIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQyMzowODo0NFrOGKPgiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTgyNA==", "bodyText": "As this is already checking for ==null or isEmpty() this is redundant with getZkfcServerBindHost() we could just return the value instead of doing line 139.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945824", "createdAt": "2020-04-19T16:55:53Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -111,8 +111,11 @@ protected HAServiceTarget dataToTarget(byte[] data) {\n   @Override\n   protected InetSocketAddress getRpcAddressToBindTo() {\n     int zkfcPort = getZkfcPort(conf);\n-    return new InetSocketAddress(localTarget.getAddress().getAddress(),\n-          zkfcPort);\n+    String zkfcBindAddr = getZkfcServerBindHost(conf);\n+    if (zkfcBindAddr == null || zkfcBindAddr.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM5MzAzNQ==", "bodyText": "Fixed, removed the lines.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r413393035", "createdAt": "2020-04-22T23:08:44Z", "author": {"login": "dhirajh"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -111,8 +111,11 @@ protected HAServiceTarget dataToTarget(byte[] data) {\n   @Override\n   protected InetSocketAddress getRpcAddressToBindTo() {\n     int zkfcPort = getZkfcPort(conf);\n-    return new InetSocketAddress(localTarget.getAddress().getAddress(),\n-          zkfcPort);\n+    String zkfcBindAddr = getZkfcServerBindHost(conf);\n+    if (zkfcBindAddr == null || zkfcBindAddr.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTgyNA=="}, "originalCommit": {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1MjUzNzk0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOVQxNjo1NjowOFrOGH6JZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQyMTowMDo1NVrOGKLo-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTg5NQ==", "bodyText": "Use logger", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945895", "createdAt": "2020-04-19T16:56:08Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzMyOTY1Ng==", "bodyText": "He has moved tests to the existing test class so this file is deleted.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r413329656", "createdAt": "2020-04-22T21:00:55Z", "author": {"login": "liuml07"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTg5NQ=="}, "originalCommit": {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1Mzg2ODY4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNTo1MToxOFrOGIEJ1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNTo1MToxOFrOGIEJ1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEwOTg0NQ==", "bodyText": "nit: this can be one blank line.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411109845", "createdAt": "2020-04-20T05:51:18Z", "author": {"login": "liuml07"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1Mzk0NTc2OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNjoyMDoxNVrOGIE1CQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzozNjowNlrOGJn3_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyMDkwNQ==", "bodyText": "Alternatively, this test can go to TestDFSZKFailoverController? We may reuse existing setup and shutdown methods hopefully?", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411120905", "createdAt": "2020-04-20T06:20:15Z", "author": {"login": "liuml07"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0MzY3Nw==", "bodyText": "Fixed. I moved tests case to TestDFSZKFailoverController", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412743677", "createdAt": "2020-04-22T07:36:06Z", "author": {"login": "dhirajh"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyMDkwNQ=="}, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1Mzk2MjMzOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNjoyNTozOVrOGIE-LQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzozNjo0N1rOGJn5yA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyMzI0NQ==", "bodyText": "nit: remove blank lines within try clause? Seems related statements. It's fine if you prefer keeping them.\nnit: line length is usually 80 characters. You can check the checkstyle reports from the QA comment, for e.g. https://builds.apache.org/job/hadoop-multibranch/job/PR-1964/2/artifact/out/diff-checkstyle-root.txt", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411123245", "createdAt": "2020-04-20T06:25:39Z", "author": {"login": "liuml07"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0NDEzNg==", "bodyText": "Fixed", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412744136", "createdAt": "2020-04-22T07:36:47Z", "author": {"login": "dhirajh"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyMzI0NQ=="}, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1Mzk3MTY1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNjoyODo0MFrOGIFDZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzozNjo1OFrOGJn6NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyNDU4Mg==", "bodyText": "nit: assertEquals is simpler.\nassertThat(\"Bind address not expected to be wildcard by default.\",\n    LOCALHOST_SERVER_ADDRESS, zkfc.getRpcAddressToBindTo().getHostString());", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411124582", "createdAt": "2020-04-20T06:28:40Z", "author": {"login": "liuml07"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {\n+\n+            cluster = new MiniDFSCluster.Builder(conf).nnTopology(topology).numDataNodes(0).build();\n+\n+            DFSZKFailoverController zkfc = DFSZKFailoverController.create(\n+                    conf);\n+\n+            assertThat(\"Bind address not expected to be wildcard by default.\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0NDI0NQ==", "bodyText": "Fixed.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412744245", "createdAt": "2020-04-22T07:36:58Z", "author": {"login": "dhirajh"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {\n+\n+            cluster = new MiniDFSCluster.Builder(conf).nnTopology(topology).numDataNodes(0).build();\n+\n+            DFSZKFailoverController zkfc = DFSZKFailoverController.create(\n+                    conf);\n+\n+            assertThat(\"Bind address not expected to be wildcard by default.\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyNDU4Mg=="}, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1Mzk4MzU1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNjozMjozMVrOGIFJww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzozNjoyMVrOGJn4nA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyNjIxMQ==", "bodyText": "If you like, you can use try-with on MiniDFSCluster, e.g.\ntry (MiniDFSCluster cluster = new MiniDFSCluster.Builder...) {\n    // some stuff using cluster\n}\n\nand later\ntry (MiniDFSCluster cluster = new MiniDFSCluster.Builder...) {\n    // some stuff using cluster\n}\n\nwithout name conflicts and no necessary to reset cluster to null in-between.\nBut if you move this to TestDFSZKFailoverController, we can split this test method into two methods and reuse the mini cluster defined there. I'm fine either way.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411126211", "createdAt": "2020-04-20T06:32:31Z", "author": {"login": "liuml07"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0MzgzNg==", "bodyText": "Went with the first suggestion", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412743836", "createdAt": "2020-04-22T07:36:21Z", "author": {"login": "dhirajh"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyNjIxMQ=="}, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NDAyODczOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNjo0NzowM1rOGIFjgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzozNTo0M1rOGJn26w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzMjgwMw==", "bodyText": "nit: not used?", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411132803", "createdAt": "2020-04-20T06:47:03Z", "author": {"login": "liuml07"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0MzQwMw==", "bodyText": "Fixed", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412743403", "createdAt": "2020-04-22T07:35:43Z", "author": {"login": "dhirajh"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzMjgwMw=="}, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NDAzMTE3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNjo0Nzo1MlrOGIFk8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzozNzowN1rOGJn6iQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzMzE2OA==", "bodyText": "I'm thinking, since we care more about the service RPC binding host, this config should be setting that only.\nconf.set(DFS_NAMENODE_SERVICE_RPC_BIND_HOST_KEY, WILDCARD_ADDRESS);\n\nIs this agreed?", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411133168", "createdAt": "2020-04-20T06:47:52Z", "author": {"login": "liuml07"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {\n+\n+            cluster = new MiniDFSCluster.Builder(conf).nnTopology(topology).numDataNodes(0).build();\n+\n+            DFSZKFailoverController zkfc = DFSZKFailoverController.create(\n+                    conf);\n+\n+            assertThat(\"Bind address not expected to be wildcard by default.\",\n+                    zkfc.getRpcAddressToBindTo().getHostString(), is(LOCALHOST_SERVER_ADDRESS));\n+        } finally {\n+            if (cluster != null) {\n+                cluster.shutdown();\n+                cluster = null;\n+            }\n+        }\n+\n+        LOG.info(\"Testing with \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // Tell NN to bind the wildcard address.\n+        conf.set(DFS_NAMENODE_RPC_BIND_HOST_KEY, WILDCARD_ADDRESS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0NDMyOQ==", "bodyText": "Fixed.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412744329", "createdAt": "2020-04-22T07:37:07Z", "author": {"login": "dhirajh"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {\n+\n+            cluster = new MiniDFSCluster.Builder(conf).nnTopology(topology).numDataNodes(0).build();\n+\n+            DFSZKFailoverController zkfc = DFSZKFailoverController.create(\n+                    conf);\n+\n+            assertThat(\"Bind address not expected to be wildcard by default.\",\n+                    zkfc.getRpcAddressToBindTo().getHostString(), is(LOCALHOST_SERVER_ADDRESS));\n+        } finally {\n+            if (cluster != null) {\n+                cluster.shutdown();\n+                cluster = null;\n+            }\n+        }\n+\n+        LOG.info(\"Testing with \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // Tell NN to bind the wildcard address.\n+        conf.set(DFS_NAMENODE_RPC_BIND_HOST_KEY, WILDCARD_ADDRESS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzMzE2OA=="}, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NDA0NTEzOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwNjo1MTo1MFrOGIFswA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNzozNTozMlrOGJn2cQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzNTE2OA==", "bodyText": "This actually can be private static.\n\nFirst it can be static because it does not refer to this ZKFC object fields\nOther methods are protected I guess because they are overriding parent class ZKFailoverController methods. When overriding, we can not change the scope to a smaller one (aka weaker access privilege). So here we keep the protected keyword.", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411135168", "createdAt": "2020-04-20T06:51:50Z", "author": {"login": "liuml07"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -111,21 +111,37 @@ protected HAServiceTarget dataToTarget(byte[] data) {\n   @Override\n   protected InetSocketAddress getRpcAddressToBindTo() {\n     int zkfcPort = getZkfcPort(conf);\n-    return new InetSocketAddress(localTarget.getAddress().getAddress(),\n-          zkfcPort);\n+    String zkfcBindAddr = getZkfcServerBindHost(conf);\n+    if (zkfcBindAddr == null || zkfcBindAddr.isEmpty()) {\n+      zkfcBindAddr = localTarget.getAddress().getAddress().getHostAddress();\n+    }\n+    return new InetSocketAddress(zkfcBindAddr, zkfcPort);\n   }\n-  \n \n   @Override\n   protected PolicyProvider getPolicyProvider() {\n     return new HDFSPolicyProvider();\n   }\n-  \n+\n   static int getZkfcPort(Configuration conf) {\n     return conf.getInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY,\n         DFSConfigKeys.DFS_HA_ZKFC_PORT_DEFAULT);\n   }\n-  \n+\n+  /** Given a configuration get the bind host that could be used by ZKFC.\n+   * We derive it from NN service rpc bind host or NN rpc bind host.\n+   */\n+  protected String getZkfcServerBindHost(Configuration conf) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0MzI4MQ==", "bodyText": "Fixed", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412743281", "createdAt": "2020-04-22T07:35:32Z", "author": {"login": "dhirajh"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -111,21 +111,37 @@ protected HAServiceTarget dataToTarget(byte[] data) {\n   @Override\n   protected InetSocketAddress getRpcAddressToBindTo() {\n     int zkfcPort = getZkfcPort(conf);\n-    return new InetSocketAddress(localTarget.getAddress().getAddress(),\n-          zkfcPort);\n+    String zkfcBindAddr = getZkfcServerBindHost(conf);\n+    if (zkfcBindAddr == null || zkfcBindAddr.isEmpty()) {\n+      zkfcBindAddr = localTarget.getAddress().getAddress().getHostAddress();\n+    }\n+    return new InetSocketAddress(zkfcBindAddr, zkfcPort);\n   }\n-  \n \n   @Override\n   protected PolicyProvider getPolicyProvider() {\n     return new HDFSPolicyProvider();\n   }\n-  \n+\n   static int getZkfcPort(Configuration conf) {\n     return conf.getInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY,\n         DFSConfigKeys.DFS_HA_ZKFC_PORT_DEFAULT);\n   }\n-  \n+\n+  /** Given a configuration get the bind host that could be used by ZKFC.\n+   * We derive it from NN service rpc bind host or NN rpc bind host.\n+   */\n+  protected String getZkfcServerBindHost(Configuration conf) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzNTE2OA=="}, "originalCommit": {"oid": "43cefff8950d452de22b06379bb90d2b8271015b"}, "originalPosition": 29}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3522, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}