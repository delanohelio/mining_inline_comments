{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc1NDg4MzMy", "number": 2258, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxODowNToyMVrOEd14uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxODowNToyMVrOEd14uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzI3MDM1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxODowNToyMVrOHJP11A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMzo1MTo0OFrOHQJgFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1ODc3Mg==", "bodyText": "I don't think it's being used in the HDFS code base a lot, but we can use LambdaTestUtils\nlike in https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/TestS3ABlockOutputStream.java#L81", "url": "https://github.com/apache/hadoop/pull/2258#discussion_r479458772", "createdAt": "2020-08-28T18:05:21Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java", "diffHunk": "@@ -2442,4 +2442,38 @@ public void testGetTrashRootOnEZInSnapshottableDir()\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDisallowSnapshotShouldThrowWhenTrashRootExists()\n+      throws IOException {\n+    Configuration conf = getTestConfiguration();\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/disallowss/test1/\");\n+      Path file0path = new Path(testDir, \"file-0\");\n+      dfs.create(file0path);\n+      dfs.allowSnapshot(testDir);\n+      // Create trash root manually\n+      Path testDirTrashRoot = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      dfs.mkdirs(testDirTrashRoot);\n+      // Try disallowing snapshot, should throw\n+      try {\n+        dfs.disallowSnapshot(testDir);\n+        fail(\"Should have thrown IOException when trash root exists inside \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c63e7fe0f5fbd0aa18223661bf7bae30a852b390"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY5NDkzNQ==", "bodyText": "Thanks! I have updated accordingly.", "url": "https://github.com/apache/hadoop/pull/2258#discussion_r486694935", "createdAt": "2020-09-10T23:51:48Z", "author": {"login": "smengcl"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java", "diffHunk": "@@ -2442,4 +2442,38 @@ public void testGetTrashRootOnEZInSnapshottableDir()\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDisallowSnapshotShouldThrowWhenTrashRootExists()\n+      throws IOException {\n+    Configuration conf = getTestConfiguration();\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/disallowss/test1/\");\n+      Path file0path = new Path(testDir, \"file-0\");\n+      dfs.create(file0path);\n+      dfs.allowSnapshot(testDir);\n+      // Create trash root manually\n+      Path testDirTrashRoot = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      dfs.mkdirs(testDirTrashRoot);\n+      // Try disallowing snapshot, should throw\n+      try {\n+        dfs.disallowSnapshot(testDir);\n+        fail(\"Should have thrown IOException when trash root exists inside \"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1ODc3Mg=="}, "originalCommit": {"oid": "c63e7fe0f5fbd0aa18223661bf7bae30a852b390"}, "originalPosition": 23}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3413, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}