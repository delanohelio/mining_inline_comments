{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg0Mjc1Mzk4", "number": 2297, "title": "HADOOP-17125. Using snappy-java in SnappyCodec", "bodyText": "See https://issues.apache.org/jira/browse/HADOOP-17125 for details.\nOffline discussed with @dbtsai and submitted this based on #2201.", "createdAt": "2020-09-10T20:01:42Z", "url": "https://github.com/apache/hadoop/pull/2297", "merged": true, "mergeCommit": {"oid": "c9ea344f98497b0f3e524bb3406f4ef8bc00fc89"}, "closed": true, "closedAt": "2020-10-06T16:07:55Z", "author": {"login": "viirya"}, "timelineItems": {"totalCount": 40, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdErQrYAH2gAyNDg0Mjc1Mzk4OjIzZGE1MTM0YTRhMTQ4NTM0OTFkNjY3NGIxYmZlODQ4ZWZjMTJiNjM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdPnywPAH2gAyNDg0Mjc1Mzk4OjU2ODViMGI3OTAyZTdhNmMzNTBkMzM3OGRlYTExNTljYjk2OGNiMjQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "23da5134a4a14853491d6674b1bfe848efc12b63", "author": {"user": {"login": "dbtsai", "name": "DB Tsai"}}, "url": "https://github.com/apache/hadoop/commit/23da5134a4a14853491d6674b1bfe848efc12b63", "committedDate": "2020-09-01T17:57:04Z", "message": "SnappyCodec with java-snappy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3aa3f55a770dc1cf736142786dd791ea78960453", "author": {"user": {"login": "dbtsai", "name": "DB Tsai"}}, "url": "https://github.com/apache/hadoop/commit/3aa3f55a770dc1cf736142786dd791ea78960453", "committedDate": "2020-09-01T17:57:04Z", "message": "rebase master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65fd9f4f2e40da5f64e46afb072fe70ad2ece6ae", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/65fd9f4f2e40da5f64e46afb072fe70ad2ece6ae", "committedDate": "2020-09-10T19:35:10Z", "message": "Reset compressedDirectBuf and uncompressedDirectBuf."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c0f08b274261b00436c50f7fe67f7d46486015c", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/9c0f08b274261b00436c50f7fe67f7d46486015c", "committedDate": "2020-09-10T20:00:44Z", "message": "Revert some debugging code."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f52dd205707259064247b23f7443f5840bace62f", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/f52dd205707259064247b23f7443f5840bace62f", "committedDate": "2020-09-10T22:52:49Z", "message": "Remove snappy native code."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2Mzc0MDQ1", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-486374045", "createdAt": "2020-09-10T23:19:12Z", "commit": {"oid": "f52dd205707259064247b23f7443f5840bace62f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMzoxOToxMlrOHQI6OQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMzoxOToxMlrOHQI6OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY4NTI0MQ==", "bodyText": "Per #2201 (comment) Are those native code used in hadoop-mapreduce-client-nativetask? If so, we probably need to keep it now.", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r486685241", "createdAt": "2020-09-10T23:19:12Z", "author": {"login": "dbtsai"}, "path": "hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/snappy/SnappyCompressor.c", "diffHunk": "@@ -1,166 +0,0 @@\n-/*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f52dd205707259064247b23f7443f5840bace62f"}, "originalPosition": 1}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87903a929342688cc39a512d931441b438b74e72", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/87903a929342688cc39a512d931441b438b74e72", "committedDate": "2020-09-11T03:40:01Z", "message": "Remove snappy compilation."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5adcf53117d0338910376146766365aa25a13e19", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/5adcf53117d0338910376146766365aa25a13e19", "committedDate": "2020-09-11T17:13:16Z", "message": "Fix limit parameter."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40cc18a897efd3bbcfbf14bf77babf77890103e8", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/40cc18a897efd3bbcfbf14bf77babf77890103e8", "committedDate": "2020-09-13T22:20:17Z", "message": "Remove require.snappy."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e44d4b810fa94253c6eb9b0ad5ea30bc62175ba", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/0e44d4b810fa94253c6eb9b0ad5ea30bc62175ba", "committedDate": "2020-09-15T17:55:23Z", "message": "trigger CI"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "666a37bc56d6512fe953e438ad4224e935ea6cd2", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/666a37bc56d6512fe953e438ad4224e935ea6cd2", "committedDate": "2020-09-15T21:28:22Z", "message": "Add compatibility test."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5NjAzMzg4", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-489603388", "createdAt": "2020-09-16T13:06:02Z", "commit": {"oid": "666a37bc56d6512fe953e438ad4224e935ea6cd2"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMzowNjowM1rOHSv4vA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMzoxMDoxMlrOHSwDww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQyMDk4OA==", "bodyText": "provided", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r489420988", "createdAt": "2020-09-16T13:06:03Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/pom.xml", "diffHunk": "@@ -363,6 +363,10 @@\n       <artifactId>wildfly-openssl-java</artifactId>\n       <scope>provided</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.xerial.snappy</groupId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "666a37bc56d6512fe953e438ad4224e935ea6cd2"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQyMjMyMw==", "bodyText": "use name of config option which users can tun", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r489422323", "createdAt": "2020-09-16T13:08:03Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.java", "diffHunk": "@@ -276,13 +258,29 @@ public void end() {\n     // do nothing\n   }\n \n-  private native static void initIDs();\n+  private int decompressBytesDirect() throws IOException {\n+    if (compressedDirectBufLen == 0) {\n+      return 0;\n+    } else {\n+      // Set the position and limit of `compressedDirectBuf` for reading\n+      compressedDirectBuf.limit(compressedDirectBufLen).position(0);\n+      // There is compressed input, decompress it now.\n+      int size = Snappy.uncompressedLength((ByteBuffer) compressedDirectBuf);\n+      if (size > uncompressedDirectBuf.remaining()) {\n+        throw new IOException(\"Could not decompress data. \" +\n+          \"uncompressedDirectBuf length is too small.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "666a37bc56d6512fe953e438ad4224e935ea6cd2"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQyMjY2MQ==", "bodyText": "please stop the IDE removing trailing whitespace on lines which haven't been edited; complicates life", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r489422661", "createdAt": "2020-09-16T13:08:33Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.java", "diffHunk": "@@ -276,13 +258,29 @@ public void end() {\n     // do nothing\n   }\n \n-  private native static void initIDs();\n+  private int decompressBytesDirect() throws IOException {\n+    if (compressedDirectBufLen == 0) {\n+      return 0;\n+    } else {\n+      // Set the position and limit of `compressedDirectBuf` for reading\n+      compressedDirectBuf.limit(compressedDirectBufLen).position(0);\n+      // There is compressed input, decompress it now.\n+      int size = Snappy.uncompressedLength((ByteBuffer) compressedDirectBuf);\n+      if (size > uncompressedDirectBuf.remaining()) {\n+        throw new IOException(\"Could not decompress data. \" +\n+          \"uncompressedDirectBuf length is too small.\");\n+      }\n+      size = Snappy.uncompress((ByteBuffer) compressedDirectBuf,\n+              (ByteBuffer) uncompressedDirectBuf);\n+      compressedDirectBufLen = 0;\n+      compressedDirectBuf.limit(compressedDirectBuf.capacity()).position(0);\n+      return size;\n+    }\n+  }\n \n-  private native int decompressBytesDirect();\n-  \n   int decompressDirect(ByteBuffer src, ByteBuffer dst) throws IOException {\n     assert (this instanceof SnappyDirectDecompressor);\n-    \n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "666a37bc56d6512fe953e438ad4224e935ea6cd2"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQyMzgxMQ==", "bodyText": "what about the others snappylibs?", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r489423811", "createdAt": "2020-09-16T13:10:12Z", "author": {"login": "steveloughran"}, "path": "hadoop-project-dist/pom.xml", "diffHunk": "@@ -341,7 +340,6 @@\n                     <argument>--openssllib=${openssl.lib}</argument>\n                     <argument>--opensslbinbundle=${bundle.openssl.in.bin}</argument>\n                     <argument>--openssllibbundle=${bundle.openssl}</argument>\n-                    <argument>--snappybinbundle=${bundle.snappy.in.bin}</argument>\n                     <argument>--snappylib=${snappy.lib}</argument>\n                     <argument>--snappylibbundle=${bundle.snappy}</argument>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "666a37bc56d6512fe953e438ad4224e935ea6cd2"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9de4712af35830e483d37c50261c36812ed047fa", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/9de4712af35830e483d37c50261c36812ed047fa", "committedDate": "2020-09-17T01:23:24Z", "message": "Check snappy library and remove useless code."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0ed518d238adfee81c821b74434785afb5684710", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/0ed518d238adfee81c821b74434785afb5684710", "committedDate": "2020-09-17T01:34:39Z", "message": "Revert trailing whitespace."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ab2926aa62b9a612e61f0f3a0aba24ca4308afa6", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/ab2926aa62b9a612e61f0f3a0aba24ca4308afa6", "committedDate": "2020-09-17T01:31:19Z", "message": "Revert trailing whitespace."}, "afterCommit": {"oid": "0ed518d238adfee81c821b74434785afb5684710", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/0ed518d238adfee81c821b74434785afb5684710", "committedDate": "2020-09-17T01:34:39Z", "message": "Revert trailing whitespace."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwMjEzNzg5", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-490213789", "createdAt": "2020-09-17T03:15:02Z", "commit": {"oid": "0ed518d238adfee81c821b74434785afb5684710"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMzoxNTowMlrOHTOdZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMzoxNTowMlrOHTOdZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTkyMTg5Mw==", "bodyText": "In the original code, we throw a runtime exception if the native snappy is not found. Should we follow?\n      throw new RuntimeException(\"native snappy library not available: \" +\n          \"SnappyCompressor has not been loaded.\");", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r489921893", "createdAt": "2020-09-17T03:15:02Z", "author": {"login": "dbtsai"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.java", "diffHunk": "@@ -45,30 +46,19 @@\n   private int userBufOff = 0, userBufLen = 0;\n   private boolean finished;\n \n-  private static boolean nativeSnappyLoaded = false;\n-\n-  static {\n-    if (NativeCodeLoader.isNativeCodeLoaded() &&\n-        NativeCodeLoader.buildSupportsSnappy()) {\n-      try {\n-        initIDs();\n-        nativeSnappyLoaded = true;\n-      } catch (Throwable t) {\n-        LOG.error(\"failed to load SnappyDecompressor\", t);\n-      }\n-    }\n-  }\n-  \n-  public static boolean isNativeCodeLoaded() {\n-    return nativeSnappyLoaded;\n-  }\n-  \n   /**\n    * Creates a new compressor.\n    *\n    * @param directBufferSize size of the direct buffer to be used.\n    */\n   public SnappyDecompressor(int directBufferSize) {\n+    // `snappy-java` is provided scope. We need to check if its availability.\n+    try {\n+      SnappyLoader.getVersion();\n+    } catch (Throwable t) {\n+      LOG.warn(\"Error loading snappy libraries: \" + t);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ed518d238adfee81c821b74434785afb5684710"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwMjE0MzQ2", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-490214346", "createdAt": "2020-09-17T03:16:50Z", "commit": {"oid": "0ed518d238adfee81c821b74434785afb5684710"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMzoxNjo1MFrOHTOhpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMzoxNjo1MFrOHTOhpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTkyMjk4MQ==", "bodyText": "we need to check if the snappy class is available for SnappyCompressor too.", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r489922981", "createdAt": "2020-09-17T03:16:50Z", "author": {"login": "dbtsai"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java", "diffHunk": "@@ -48,24 +48,6 @@\n   private long bytesRead = 0L;\n   private long bytesWritten = 0L;\n \n-  private static boolean nativeSnappyLoaded = false;\n-  \n-  static {\n-    if (NativeCodeLoader.isNativeCodeLoaded() &&\n-        NativeCodeLoader.buildSupportsSnappy()) {\n-      try {\n-        initIDs();\n-        nativeSnappyLoaded = true;\n-      } catch (Throwable t) {\n-        LOG.error(\"failed to load SnappyCompressor\", t);\n-      }\n-    }\n-  }\n-  \n-  public static boolean isNativeCodeLoaded() {\n-    return nativeSnappyLoaded;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ed518d238adfee81c821b74434785afb5684710"}, "originalPosition": 30}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "712749c041c012bb8eef41f826d1abc8da937a36", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/712749c041c012bb8eef41f826d1abc8da937a36", "committedDate": "2020-09-17T22:22:39Z", "message": "For review comment."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MjM3NjU1", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-495237655", "createdAt": "2020-09-24T05:51:38Z", "commit": {"oid": "712749c041c012bb8eef41f826d1abc8da937a36"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwNTo1MTozOFrOHXKqoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwNjowMjoxOFrOHXK4CA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDA1NDA0OA==", "bodyText": "Fix this last sentence if you make a new PR", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r494054048", "createdAt": "2020-09-24T05:51:38Z", "author": {"login": "saintstack"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java", "diffHunk": "@@ -48,30 +49,20 @@\n   private long bytesRead = 0L;\n   private long bytesWritten = 0L;\n \n-  private static boolean nativeSnappyLoaded = false;\n-  \n-  static {\n-    if (NativeCodeLoader.isNativeCodeLoaded() &&\n-        NativeCodeLoader.buildSupportsSnappy()) {\n-      try {\n-        initIDs();\n-        nativeSnappyLoaded = true;\n-      } catch (Throwable t) {\n-        LOG.error(\"failed to load SnappyCompressor\", t);\n-      }\n-    }\n-  }\n-  \n-  public static boolean isNativeCodeLoaded() {\n-    return nativeSnappyLoaded;\n-  }\n-  \n   /**\n    * Creates a new compressor.\n    *\n    * @param directBufferSize size of the direct buffer to be used.\n    */\n   public SnappyCompressor(int directBufferSize) {\n+    // `snappy-java` is provided scope. We need to check if its availability.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "712749c041c012bb8eef41f826d1abc8da937a36"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDA1NDM4OQ==", "bodyText": "Is it the 'native snappy library' that is missing or the java-snappy jar?", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r494054389", "createdAt": "2020-09-24T05:52:44Z", "author": {"login": "saintstack"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java", "diffHunk": "@@ -48,30 +49,20 @@\n   private long bytesRead = 0L;\n   private long bytesWritten = 0L;\n \n-  private static boolean nativeSnappyLoaded = false;\n-  \n-  static {\n-    if (NativeCodeLoader.isNativeCodeLoaded() &&\n-        NativeCodeLoader.buildSupportsSnappy()) {\n-      try {\n-        initIDs();\n-        nativeSnappyLoaded = true;\n-      } catch (Throwable t) {\n-        LOG.error(\"failed to load SnappyCompressor\", t);\n-      }\n-    }\n-  }\n-  \n-  public static boolean isNativeCodeLoaded() {\n-    return nativeSnappyLoaded;\n-  }\n-  \n   /**\n    * Creates a new compressor.\n    *\n    * @param directBufferSize size of the direct buffer to be used.\n    */\n   public SnappyCompressor(int directBufferSize) {\n+    // `snappy-java` is provided scope. We need to check if its availability.\n+    try {\n+      SnappyLoader.getVersion();\n+    } catch (Throwable t) {\n+      throw new RuntimeException(\"native snappy library not available: \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "712749c041c012bb8eef41f826d1abc8da937a36"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDA1NTM0NA==", "bodyText": "s/compressBytesDirect/compressBytesDirectBuf/ ? Or.. why the Bytes... I see none referenced in the method so compressDirectBuf?", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r494055344", "createdAt": "2020-09-24T05:55:41Z", "author": {"login": "saintstack"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java", "diffHunk": "@@ -291,9 +282,17 @@ public long getBytesWritten() {\n   public void end() {\n   }\n \n-  private native static void initIDs();\n-\n-  private native int compressBytesDirect();\n-\n-  public native static String getLibraryName();\n+  private int compressBytesDirect() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "712749c041c012bb8eef41f826d1abc8da937a36"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDA1NTkwMQ==", "bodyText": "ditto... could this message be more informative: i.e. \"hey, operator... you need to add the snappy-java.jar to your CLASSPATH... its not packaged up for you..\"", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r494055901", "createdAt": "2020-09-24T05:57:15Z", "author": {"login": "saintstack"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.java", "diffHunk": "@@ -45,30 +46,20 @@\n   private int userBufOff = 0, userBufLen = 0;\n   private boolean finished;\n \n-  private static boolean nativeSnappyLoaded = false;\n-\n-  static {\n-    if (NativeCodeLoader.isNativeCodeLoaded() &&\n-        NativeCodeLoader.buildSupportsSnappy()) {\n-      try {\n-        initIDs();\n-        nativeSnappyLoaded = true;\n-      } catch (Throwable t) {\n-        LOG.error(\"failed to load SnappyDecompressor\", t);\n-      }\n-    }\n-  }\n-  \n-  public static boolean isNativeCodeLoaded() {\n-    return nativeSnappyLoaded;\n-  }\n-  \n   /**\n    * Creates a new compressor.\n    *\n    * @param directBufferSize size of the direct buffer to be used.\n    */\n   public SnappyDecompressor(int directBufferSize) {\n+    // `snappy-java` is provided scope. We need to check if its availability.\n+    try {\n+      SnappyLoader.getVersion();\n+    } catch (Throwable t) {\n+      throw new RuntimeException(\"native snappy library not available: \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "712749c041c012bb8eef41f826d1abc8da937a36"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDA1NjQyOQ==", "bodyText": "ditto", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r494056429", "createdAt": "2020-09-24T05:59:04Z", "author": {"login": "saintstack"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.java", "diffHunk": "@@ -276,10 +267,20 @@ public void end() {\n     // do nothing\n   }\n \n-  private native static void initIDs();\n+  private int decompressBytesDirect() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "712749c041c012bb8eef41f826d1abc8da937a36"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDA1NzQ4MA==", "bodyText": "hmm... this is a little anemic. Have you considered adding a data file that is a little more interesting than this?", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r494057480", "createdAt": "2020-09-24T06:02:18Z", "author": {"login": "saintstack"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy/TestSnappyCompressorDecompressor.java", "diffHunk": "@@ -446,4 +442,43 @@ public void doWork() throws Exception {\n \n     ctx.waitFor(60000);\n   }\n+\n+  @Test\n+  public void testSnappyCompatibility() throws Exception {\n+    // HADOOP-17125. Using snappy-java in SnappyCodec. These strings are raw data and compressed data\n+    // using previous native Snappy codec. We use updated Snappy codec to decode it and check if it\n+    // matches.\n+    String rawData = \"010a06030a040a0c0109020c0a010204020d02000b010701080605080b090902060a080502060a0d06070908080a0c0105030904090d05090800040c090c0d0d0804000d00040b0b0d010d060907020a030a0c0900040905080107040d0c01060a0b09070a04000b01040b09000e0e00020b06050b060e030e0a07050d06050d\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "712749c041c012bb8eef41f826d1abc8da937a36"}, "originalPosition": 52}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b5a2122d597c06373d242b0cbc3eed8d3fb7aa4", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/2b5a2122d597c06373d242b0cbc3eed8d3fb7aa4", "committedDate": "2020-09-24T18:34:48Z", "message": "Address review comments."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1ODU4NDE5", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-495858419", "createdAt": "2020-09-24T18:46:06Z", "commit": {"oid": "2b5a2122d597c06373d242b0cbc3eed8d3fb7aa4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQxODo0NjowNlrOHXoLfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQxODo0NjowNlrOHXoLfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDUzNzU5Nw==", "bodyText": "nit, uncompressedDirectBuf.limit(uncompressedDirectBuf.capacity()).position(0); for safety.", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r494537597", "createdAt": "2020-09-24T18:46:06Z", "author": {"login": "dbtsai"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java", "diffHunk": "@@ -291,9 +283,17 @@ public long getBytesWritten() {\n   public void end() {\n   }\n \n-  private native static void initIDs();\n-\n-  private native int compressBytesDirect();\n-\n-  public native static String getLibraryName();\n+  private int compressDirectBuf() throws IOException {\n+    if (uncompressedDirectBufLen == 0) {\n+      return 0;\n+    } else {\n+      // Set the position and limit of `uncompressedDirectBuf` for reading\n+      uncompressedDirectBuf.limit(uncompressedDirectBufLen).position(0);\n+      int size = Snappy.compress((ByteBuffer) uncompressedDirectBuf,\n+              (ByteBuffer) compressedDirectBuf);\n+      uncompressedDirectBufLen = 0;\n+      uncompressedDirectBuf.limit(directBufferSize).position(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5a2122d597c06373d242b0cbc3eed8d3fb7aa4"}, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1ODYwMjY5", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-495860269", "createdAt": "2020-09-24T18:48:37Z", "commit": {"oid": "2b5a2122d597c06373d242b0cbc3eed8d3fb7aa4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQxODo0ODozOFrOHXoRBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQxODo0ODozOFrOHXoRBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDUzOTAxNA==", "bodyText": "Why is this change needed?", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r494539014", "createdAt": "2020-09-24T18:48:38Z", "author": {"login": "dbtsai"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/CompressDecompressTester.java", "diffHunk": "@@ -432,7 +412,11 @@ public void assertCompression(String name, Compressor compressor,\n               joiner.join(name, \"byte arrays not equals error !!!\"),\n               originalRawData, decompressOut.toByteArray());\n         } catch (Exception ex) {\n-          fail(joiner.join(name, ex.getMessage()));\n+          if (ex.getMessage() != null) {\n+            fail(joiner.join(name, ex.getMessage()));\n+          } else {\n+            fail(joiner.join(name, ExceptionUtils.getStackTrace(ex)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b5a2122d597c06373d242b0cbc3eed8d3fb7aa4"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1ODYxNzQ2", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-495861746", "createdAt": "2020-09-24T18:50:39Z", "commit": {"oid": "2b5a2122d597c06373d242b0cbc3eed8d3fb7aa4"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1cb398bbbaf702501f558ce32cda07d1ca7917ca", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/1cb398bbbaf702501f558ce32cda07d1ca7917ca", "committedDate": "2020-09-24T19:09:33Z", "message": "Take safer approach."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1OTAwMDUy", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-495900052", "createdAt": "2020-09-24T19:47:37Z", "commit": {"oid": "1cb398bbbaf702501f558ce32cda07d1ca7917ca"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2NjU2MDU5", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-496656059", "createdAt": "2020-09-25T18:22:07Z", "commit": {"oid": "1cb398bbbaf702501f558ce32cda07d1ca7917ca"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxODoyMjowN1rOHYOEWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxODozNzoxNlrOHYOh3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTE1ODM2Mg==", "bodyText": "nit: this seems unnecessary as clear is called shortly after at the call site?", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r495158362", "createdAt": "2020-09-25T18:22:07Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java", "diffHunk": "@@ -291,9 +283,17 @@ public long getBytesWritten() {\n   public void end() {\n   }\n \n-  private native static void initIDs();\n-\n-  private native int compressBytesDirect();\n-\n-  public native static String getLibraryName();\n+  private int compressDirectBuf() throws IOException {\n+    if (uncompressedDirectBufLen == 0) {\n+      return 0;\n+    } else {\n+      // Set the position and limit of `uncompressedDirectBuf` for reading\n+      uncompressedDirectBuf.limit(uncompressedDirectBufLen).position(0);\n+      int size = Snappy.compress((ByteBuffer) uncompressedDirectBuf,\n+              (ByteBuffer) compressedDirectBuf);\n+      uncompressedDirectBufLen = 0;\n+      uncompressedDirectBuf.limit(uncompressedDirectBuf.capacity()).position(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cb398bbbaf702501f558ce32cda07d1ca7917ca"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTE1ODY1NQ==", "bodyText": "nit: SnappyLoader is marked as \"internal use-only\" though so not sure if there is better alternative here.", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r495158655", "createdAt": "2020-09-25T18:22:41Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.java", "diffHunk": "@@ -45,30 +46,21 @@\n   private int userBufOff = 0, userBufLen = 0;\n   private boolean finished;\n \n-  private static boolean nativeSnappyLoaded = false;\n-\n-  static {\n-    if (NativeCodeLoader.isNativeCodeLoaded() &&\n-        NativeCodeLoader.buildSupportsSnappy()) {\n-      try {\n-        initIDs();\n-        nativeSnappyLoaded = true;\n-      } catch (Throwable t) {\n-        LOG.error(\"failed to load SnappyDecompressor\", t);\n-      }\n-    }\n-  }\n-  \n-  public static boolean isNativeCodeLoaded() {\n-    return nativeSnappyLoaded;\n-  }\n-  \n   /**\n    * Creates a new compressor.\n    *\n    * @param directBufferSize size of the direct buffer to be used.\n    */\n   public SnappyDecompressor(int directBufferSize) {\n+    // `snappy-java` is provided scope. We need to check if it is available.\n+    try {\n+      SnappyLoader.getVersion();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cb398bbbaf702501f558ce32cda07d1ca7917ca"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTE2Mzg1MA==", "bodyText": "nit: can we just call compressedDirectBuf.clear()?", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r495163850", "createdAt": "2020-09-25T18:33:04Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/snappy/SnappyDecompressor.java", "diffHunk": "@@ -276,10 +268,20 @@ public void end() {\n     // do nothing\n   }\n \n-  private native static void initIDs();\n+  private int decompressDirectBuf() throws IOException {\n+    if (compressedDirectBufLen == 0) {\n+      return 0;\n+    } else {\n+      // Set the position and limit of `compressedDirectBuf` for reading\n+      compressedDirectBuf.limit(compressedDirectBufLen).position(0);\n+      int size = Snappy.uncompress((ByteBuffer) compressedDirectBuf,\n+              (ByteBuffer) uncompressedDirectBuf);\n+      compressedDirectBufLen = 0;\n+      compressedDirectBuf.limit(compressedDirectBuf.capacity()).position(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cb398bbbaf702501f558ce32cda07d1ca7917ca"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTE2NTM5OA==", "bodyText": "nit: unrelated changes :)", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r495165398", "createdAt": "2020-09-25T18:36:13Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/CompressDecompressTester.java", "diffHunk": "@@ -495,19 +479,16 @@ public String getName() {\n     Compressor compressor = pair.compressor;\n \n     if (compressor.getClass().isAssignableFrom(Lz4Compressor.class)\n-            && (NativeCodeLoader.isNativeCodeLoaded()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cb398bbbaf702501f558ce32cda07d1ca7917ca"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTE2NTkxOQ==", "bodyText": "nit: long lines (80 chars).", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r495165919", "createdAt": "2020-09-25T18:37:16Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy/TestSnappyCompressorDecompressor.java", "diffHunk": "@@ -446,4 +442,49 @@ public void doWork() throws Exception {\n \n     ctx.waitFor(60000);\n   }\n+\n+  @Test\n+  public void testSnappyCompatibility() throws Exception {\n+    // HADOOP-17125. Using snappy-java in SnappyCodec. These strings are raw data and compressed data\n+    // using previous native Snappy codec. We use updated Snappy codec to decode it and check if it\n+    // matches.\n+    String rawData = \"010a06030a040a0c0109020c0a010204020d02000b010701080605080b090902060a08050206\" +\n+            \"0a0d06070908080a0c0105030904090d05090800040c090c0d0d0804000d00040b0b0d010d060907020a0\" +\n+            \"30a0c0900040905080107040d0c01060a0b09070a04000b01040b09000e0e00020b06050b060e030e0a07\" +\n+            \"050d06050d\";\n+    String compressed = \"8001f07f010a06030a040a0c0109020c0a010204020d02000b010701080605080b0909020\" +\n+            \"60a080502060a0d06070908080a0c0105030904090d05090800040c090c0d0d0804000d00040b0b0d010d\" +\n+            \"060907020a030a0c0900040905080107040d0c01060a0b09070a04000b01040b09000e0e00020b06050b0\" +\n+            \"60e030e0a07050d06050d\";\n+\n+    byte[] rawDataBytes = Hex.decodeHex(rawData);\n+    byte[] compressedBytes = Hex.decodeHex(compressed);\n+\n+    ByteBuffer inBuf = ByteBuffer.allocateDirect(compressedBytes.length);\n+    inBuf.put(compressedBytes, 0, compressedBytes.length);\n+    inBuf.flip();\n+\n+    ByteBuffer outBuf = ByteBuffer.allocateDirect(rawDataBytes.length);\n+    ByteBuffer expected = ByteBuffer.wrap(rawDataBytes);\n+\n+    SnappyDecompressor.SnappyDirectDecompressor decompressor = new SnappyDecompressor.SnappyDirectDecompressor();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cb398bbbaf702501f558ce32cda07d1ca7917ca"}, "originalPosition": 71}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa6a6d550d6c154f072622371263287dc1b34f11", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/aa6a6d550d6c154f072622371263287dc1b34f11", "committedDate": "2020-09-25T19:25:02Z", "message": "For review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "19edba29fa0e6949f11926ada6d606bee39dad67", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/19edba29fa0e6949f11926ada6d606bee39dad67", "committedDate": "2020-09-25T19:33:35Z", "message": "Update BUILDING and NativeLibraries."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "beec93160a3dafbc62637672a70c07f53474e3f9", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/beec93160a3dafbc62637672a70c07f53474e3f9", "committedDate": "2020-09-25T19:35:34Z", "message": "Merge remote-tracking branch 'upstream/trunk' into java-snappy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc525faf79b68662f452fc0cd8233194ef9f4555", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/fc525faf79b68662f452fc0cd8233194ef9f4555", "committedDate": "2020-09-29T17:53:36Z", "message": "Make snappy-java as compile scope."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4Nzc3OTg5", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-498777989", "createdAt": "2020-09-29T18:45:28Z", "commit": {"oid": "fc525faf79b68662f452fc0cd8233194ef9f4555"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxODo0NToyOFrOHZ8EMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxOToxMzo1NFrOHZ9F1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2MDU2Mw==", "bodyText": "We shouldn't remove this", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r496960563", "createdAt": "2020-09-29T18:45:28Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/native/native.vcxproj", "diffHunk": "@@ -68,30 +68,13 @@\n     <IntDir>..\\..\\..\\target\\native\\$(Configuration)\\</IntDir>\n     <TargetName>hadoop</TargetName>\n   </PropertyGroup>\n-  <PropertyGroup>\n-    <SnappyLib Condition=\"Exists('$(CustomSnappyPrefix)\\snappy.dll')\">$(CustomSnappyPrefix)</SnappyLib>\n-    <SnappyLib Condition=\"Exists('$(CustomSnappyPrefix)\\lib\\snappy.dll') And '$(SnappyLib)' == ''\">$(CustomSnappyPrefix)\\lib</SnappyLib>\n-    <SnappyLib Condition=\"Exists('$(CustomSnappyPrefix)\\bin\\snappy.dll') And '$(SnappyLib)' == ''\">$(CustomSnappyPrefix)\\bin</SnappyLib>\n-    <SnappyLib Condition=\"Exists('$(CustomSnappyLib)') And '$(SnappyLib)' == ''\">$(CustomSnappyLib)</SnappyLib>\n-    <SnappyInclude Condition=\"Exists('$(CustomSnappyPrefix)\\snappy.h')\">$(CustomSnappyPrefix)</SnappyInclude>\n-    <SnappyInclude Condition=\"Exists('$(CustomSnappyPrefix)\\include\\snappy.h') And '$(SnappyInclude)' == ''\">$(CustomSnappyPrefix)\\include</SnappyInclude>\n-    <SnappyInclude Condition=\"Exists('$(CustomSnappyInclude)') And '$(SnappyInclude)' == ''\">$(CustomSnappyInclude)</SnappyInclude>\n-    <SnappyEnabled Condition=\"'$(SnappyLib)' != '' And '$(SnappyInclude)' != ''\">true</SnappyEnabled>\n-    <IncludePath Condition=\"'$(SnappyEnabled)' == 'true'\">$(SnappyInclude);$(IncludePath)</IncludePath>\n-    <IncludePath Condition=\"Exists('$(ZLIB_HOME)')\">$(ZLIB_HOME);$(IncludePath)</IncludePath>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc525faf79b68662f452fc0cd8233194ef9f4555"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3NzM2NA==", "bodyText": "does this mean we don't need the option in dev-support/bin/dist-copynativelibs for snappy?", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r496977364", "createdAt": "2020-09-29T19:13:54Z", "author": {"login": "sunchao"}, "path": "hadoop-project-dist/pom.xml", "diffHunk": "@@ -341,7 +340,6 @@\n                     <argument>--openssllib=${openssl.lib}</argument>\n                     <argument>--opensslbinbundle=${bundle.openssl.in.bin}</argument>\n                     <argument>--openssllibbundle=${bundle.openssl}</argument>\n-                    <argument>--snappybinbundle=${bundle.snappy.in.bin}</argument>\n                     <argument>--snappylib=${snappy.lib}</argument>\n                     <argument>--snappylibbundle=${bundle.snappy}</argument>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQyMzgxMQ=="}, "originalCommit": {"oid": "666a37bc56d6512fe953e438ad4224e935ea6cd2"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "562b80d036e43dfe4412219b3887f2e557b2d783", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/562b80d036e43dfe4412219b3887f2e557b2d783", "committedDate": "2020-09-29T23:06:44Z", "message": "For review comment."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4OTg4MDQ0", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-498988044", "createdAt": "2020-09-29T23:13:35Z", "commit": {"oid": "fc525faf79b68662f452fc0cd8233194ef9f4555"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0600169d3fa5d082c6a28defc59872b2f485873f", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/0600169d3fa5d082c6a28defc59872b2f485873f", "committedDate": "2020-09-29T23:15:14Z", "message": "Revert Snappy description in BUILDING.txt."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "051018ca080ac73b00e9e67acaf3d555d2367d60", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/051018ca080ac73b00e9e67acaf3d555d2367d60", "committedDate": "2020-09-29T23:11:40Z", "message": "Revert Snappy description in BUILDING.txt."}, "afterCommit": {"oid": "0600169d3fa5d082c6a28defc59872b2f485873f", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/0600169d3fa5d082c6a28defc59872b2f485873f", "committedDate": "2020-09-29T23:15:14Z", "message": "Revert Snappy description in BUILDING.txt."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk5NjA2NTQx", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-499606541", "createdAt": "2020-09-30T16:23:46Z", "commit": {"oid": "0600169d3fa5d082c6a28defc59872b2f485873f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd71a20df19543a66f23f384c58ad985f0ee2e67", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/fd71a20df19543a66f23f384c58ad985f0ee2e67", "committedDate": "2020-10-01T17:10:56Z", "message": "Fix style issue."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7dc320ddddeaeac5a4eee36c703fededbccbf6de", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/7dc320ddddeaeac5a4eee36c703fededbccbf6de", "committedDate": "2020-10-02T18:57:22Z", "message": "Fix another style..."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyMjQwNzUz", "url": "https://github.com/apache/hadoop/pull/2297#pullrequestreview-502240753", "createdAt": "2020-10-05T16:48:20Z", "commit": {"oid": "7dc320ddddeaeac5a4eee36c703fededbccbf6de"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjo0ODoyMFrOHcle5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjo0ODoyMFrOHcle5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTczNjI5NA==", "bodyText": "NPE is why toString() is what new code should do.\nWhy don't we just throw new AssertionError(name +ex, ex). That way, the stack trace doesn't get lost, which is something we never want to have happen,", "url": "https://github.com/apache/hadoop/pull/2297#discussion_r499736294", "createdAt": "2020-10-05T16:48:20Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/CompressDecompressTester.java", "diffHunk": "@@ -432,7 +412,11 @@ public void assertCompression(String name, Compressor compressor,\n               joiner.join(name, \"byte arrays not equals error !!!\"),\n               originalRawData, decompressOut.toByteArray());\n         } catch (Exception ex) {\n-          fail(joiner.join(name, ex.getMessage()));\n+          if (ex.getMessage() != null) {\n+            fail(joiner.join(name, ex.getMessage()));\n+          } else {\n+            fail(joiner.join(name, ExceptionUtils.getStackTrace(ex)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDUzOTAxNA=="}, "originalCommit": {"oid": "2b5a2122d597c06373d242b0cbc3eed8d3fb7aa4"}, "originalPosition": 44}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5685b0b7902e7a6c350d3378dea1159cb968cb24", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/5685b0b7902e7a6c350d3378dea1159cb968cb24", "committedDate": "2020-10-05T18:07:50Z", "message": "Address comments: throwing AssertionError and exclude jobTokenPassword for license check."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3644, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}