{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2NjE4Mjg3", "number": 1893, "title": "HADOOP-16920 ABFS: Make list page size configurable", "bodyText": "NOTICE\nPlease create an issue in ASF JIRA before opening a pull request,\nand you need to set the title of the pull request which starts with\nthe corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.)\nFor more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute", "createdAt": "2020-03-11T10:56:09Z", "url": "https://github.com/apache/hadoop/pull/1893", "merged": true, "mergeCommit": {"oid": "6ce5f8734f1864a2d628b23479cf3f6621b2fcb4"}, "closed": true, "closedAt": "2020-03-18T14:14:19Z", "author": {"login": "bilaharith"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcMk0-SgH2gAyMzg2NjE4Mjg3OmE1YmZlMTM1YWUzZThkYzNhOTE5MjM4ZDQwZDQ2ODRjNTg0MTA0YTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcOmcUogH2gAyMzg2NjE4Mjg3OmRiYWRjZmU0NTIxZjMxNjY0YjJiNTM2ZWUzM2ZkMWQyYzdkYTk3ZGU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a5bfe135ae3e8dc3a919238d40d4684c584104a6", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/a5bfe135ae3e8dc3a919238d40d4684c584104a6", "committedDate": "2020-03-11T10:47:37Z", "message": "ABFS: Made list page size configurable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b21e920537d88243c5a2e9e41dd12f5dd73e5c8", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/1b21e920537d88243c5a2e9e41dd12f5dd73e5c8", "committedDate": "2020-03-11T10:54:02Z", "message": "fixing import order"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1afca492cb4f7c99ca5d1e22c821ed0b115c0eb2", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/1afca492cb4f7c99ca5d1e22c821ed0b115c0eb2", "committedDate": "2020-03-11T11:04:59Z", "message": "Added hamcrest dependancy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a19a718cf692c176589e05f0efe6ec99e138feb", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/0a19a718cf692c176589e05f0efe6ec99e138feb", "committedDate": "2020-03-12T05:45:57Z", "message": "Merge branch 'trunk' into HADOOP-16920"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczMzI4OTEy", "url": "https://github.com/apache/hadoop/pull/1893#pullrequestreview-373328912", "createdAt": "2020-03-12T07:34:17Z", "commit": {"oid": "0a19a718cf692c176589e05f0efe6ec99e138feb"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc791e2297cd37d99b2bdc5b3d6ff181c80c6ca4", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/cc791e2297cd37d99b2bdc5b3d6ff181c80c6ca4", "committedDate": "2020-03-13T07:20:35Z", "message": "Improved test case readability. Added min value for the azure.list.max.results config as 1."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7291934705c45bf659a5e76a166c291027601819", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/7291934705c45bf659a5e76a166c291027601819", "committedDate": "2020-03-13T07:25:12Z", "message": "Fixing import order"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NTY4MDAy", "url": "https://github.com/apache/hadoop/pull/1893#pullrequestreview-375568002", "createdAt": "2020-03-16T20:43:38Z", "commit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDo0MzozOFrOF3FCiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDo0NTozMFrOF3FFpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5ODU2OQ==", "bodyText": "that;s just a lambda expression, you should be able to go es.submit(() -> { touch(filename); return null; }", "url": "https://github.com/apache/hadoop/pull/1893#discussion_r393298569", "createdAt": "2020-03-16T20:43:38Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsClient.java", "diffHunk": "@@ -75,4 +89,80 @@ public void testUnknownHost() throws Exception {\n             \"UnknownHostException: \" + fakeAccountName,\n             () -> FileSystem.get(conf.getRawConfiguration()));\n   }\n+\n+  @Test\n+  public void testListPathWithValidListMaxResultsValues()\n+      throws IOException, ExecutionException, InterruptedException {\n+    final int fileCount = 10;\n+    final String directory = \"testWithValidListMaxResultsValues\";\n+    createDirectoryWithNFiles(directory, fileCount);\n+    final int[] testData = {fileCount + 100, fileCount + 1, fileCount,\n+        fileCount - 1, 1};\n+    for (int i = 0; i < testData.length; i++) {\n+      int listMaxResults = testData[i];\n+      setListMaxResults(listMaxResults);\n+      int expectedListResultsSize =\n+          listMaxResults > fileCount ? fileCount : listMaxResults;\n+      assertThat(listPath(directory).size(),\n+          is(equalTo(expectedListResultsSize)));\n+    }\n+  }\n+\n+  @Test\n+  public void testListPathWithValueGreaterThanServerMaximum()\n+      throws IOException, ExecutionException, InterruptedException {\n+    setListMaxResults(LIST_MAX_RESULTS_SERVER + 100);\n+    final String directory = \"testWithValueGreaterThanServerMaximum\";\n+    createDirectoryWithNFiles(directory, LIST_MAX_RESULTS_SERVER + 200);\n+    assertThat(listPath(directory).size(),\n+        is(equalTo(LIST_MAX_RESULTS_SERVER)));\n+  }\n+\n+  @Test\n+  public void testListPathWithInvalidListMaxResultsValues() throws Exception {\n+    for (int i = -1; i < 1; i++) {\n+      setListMaxResults(i);\n+      intercept(AbfsRestOperationException.class, \"Operation failed: \\\"One of \"\n+          + \"the query parameters specified in the request URI is outside\" + \" \"\n+          + \"the permissible range.\", () -> listPath(\"directory\"));\n+    }\n+  }\n+\n+  private List<ListResultEntrySchema> listPath(String directory)\n+      throws IOException {\n+    return getFileSystem().getAbfsClient()\n+        .listPath(directory, false, getListMaxResults(), null).getResult()\n+        .getListResultSchema().paths();\n+  }\n+\n+  private int getListMaxResults() throws IOException {\n+    return getFileSystem().getAbfsStore().getAbfsConfiguration()\n+        .getListMaxResults();\n+  }\n+\n+  private void setListMaxResults(int listMaxResults) throws IOException {\n+    getFileSystem().getAbfsStore().getAbfsConfiguration()\n+        .setListMaxResults(listMaxResults);\n+  }\n+\n+  private void createDirectoryWithNFiles(String directory, int n)\n+      throws ExecutionException, InterruptedException {\n+    final List<Future<Void>> tasks = new ArrayList<>();\n+    ExecutorService es = Executors.newFixedThreadPool(10);\n+    for (int i = 0; i < n; i++) {\n+      final Path fileName = new Path(\"/\" + directory + \"/test\" + i);\n+      Callable<Void> callable = new Callable<Void>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5OTM2Ng==", "bodyText": "use assertJ here and below. It is way better because of the better errors it gives, e.g.\nassertThat(listPath).describedAs(...).hasSize(...)", "url": "https://github.com/apache/hadoop/pull/1893#discussion_r393299366", "createdAt": "2020-03-16T20:45:30Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsClient.java", "diffHunk": "@@ -75,4 +89,80 @@ public void testUnknownHost() throws Exception {\n             \"UnknownHostException: \" + fakeAccountName,\n             () -> FileSystem.get(conf.getRawConfiguration()));\n   }\n+\n+  @Test\n+  public void testListPathWithValidListMaxResultsValues()\n+      throws IOException, ExecutionException, InterruptedException {\n+    final int fileCount = 10;\n+    final String directory = \"testWithValidListMaxResultsValues\";\n+    createDirectoryWithNFiles(directory, fileCount);\n+    final int[] testData = {fileCount + 100, fileCount + 1, fileCount,\n+        fileCount - 1, 1};\n+    for (int i = 0; i < testData.length; i++) {\n+      int listMaxResults = testData[i];\n+      setListMaxResults(listMaxResults);\n+      int expectedListResultsSize =\n+          listMaxResults > fileCount ? fileCount : listMaxResults;\n+      assertThat(listPath(directory).size(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NjY2MjYz", "url": "https://github.com/apache/hadoop/pull/1893#pullrequestreview-375666263", "createdAt": "2020-03-17T00:29:18Z", "commit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDoyOToxOFrOF3KJXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDoyOToxOFrOF3KJXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4MjIzNg==", "bodyText": "Do we need a MaxValue here?", "url": "https://github.com/apache/hadoop/pull/1893#discussion_r393382236", "createdAt": "2020-03-17T00:29:18Z", "author": {"login": "DadanielZ"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java", "diffHunk": "@@ -125,6 +125,11 @@\n       DefaultValue = MAX_CONCURRENT_WRITE_THREADS)\n   private int maxConcurrentWriteThreads;\n \n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = AZURE_LIST_MAX_RESULTS,\n+      MinValue = 1,\n+      DefaultValue = DEFAULT_AZURE_LIST_MAX_RESULTS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b0bf2cc75b445d5fd7dc50fa5e9b326f0890780", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/2b0bf2cc75b445d5fd7dc50fa5e9b326f0890780", "committedDate": "2020-03-17T16:15:48Z", "message": "Incorporating review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc2MTkyMzI1", "url": "https://github.com/apache/hadoop/pull/1893#pullrequestreview-376192325", "createdAt": "2020-03-17T16:18:54Z", "commit": {"oid": "2b0bf2cc75b445d5fd7dc50fa5e9b326f0890780"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dbadcfe4521f31664b2b536ee33fd1d2c7da97de", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/dbadcfe4521f31664b2b536ee33fd1d2c7da97de", "committedDate": "2020-03-17T17:48:21Z", "message": "Checkstyle fix"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4477, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}