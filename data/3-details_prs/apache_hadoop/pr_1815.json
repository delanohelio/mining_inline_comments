{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY1NjI0MjUy", "number": 1815, "title": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are\u2026", "bodyText": "\u2026 authoritative\nNOTICE\nPlease create an issue in ASF JIRA before opening a pull request,\nand you need to set the title of the pull request which starts with\nthe corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.)\nFor more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute", "createdAt": "2020-01-22T01:49:53Z", "url": "https://github.com/apache/hadoop/pull/1815", "merged": true, "mergeCommit": {"oid": "5977360878e6780bd04842c8a2156f9848e1d088"}, "closed": true, "closedAt": "2020-01-30T10:16:52Z", "author": {"login": "mustafaiman"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb8uv8RgBqjI5Njg3MTkwMDU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb_EuMXAFqTM1MDA1NDc3Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3a248e9126d57de13c2a897ea892776c2a21f203", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/3a248e9126d57de13c2a897ea892776c2a21f203", "committedDate": "2020-01-21T22:04:59Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}, "afterCommit": {"oid": "ac9ea612be14006a4a9b14494bf8f533e6774a8e", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/ac9ea612be14006a4a9b14494bf8f533e6774a8e", "committedDate": "2020-01-22T05:18:05Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ac9ea612be14006a4a9b14494bf8f533e6774a8e", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/ac9ea612be14006a4a9b14494bf8f533e6774a8e", "committedDate": "2020-01-22T05:18:05Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}, "afterCommit": {"oid": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "committedDate": "2020-01-22T23:50:17Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NTQzMjkx", "url": "https://github.com/apache/hadoop/pull/1815#pullrequestreview-347543291", "createdAt": "2020-01-23T19:15:11Z", "commit": {"oid": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxOToxNToxMVrOFhJn6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxOToyMDozMVrOFhJyEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNTAwMw==", "bodyText": "nit: leave the empty line", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370305003", "createdAt": "2020-01-23T19:15:11Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/S3Guard.java", "diffHunk": "@@ -35,6 +35,7 @@\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n+import org.apache.hadoop.fs.RemoteIterator;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNjE1Nw==", "bodyText": "This test suite has made the leap to AssertJ assertions -please us them unless you can make the case against them. They're better, really", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370306157", "createdAt": "2020-01-23T19:17:30Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestDynamoDBMetadataStoreAuthoritativeMode.java", "diffHunk": "@@ -291,6 +295,102 @@ public void testListStatusMakesEmptyDirAuth() throws Throwable {\n     assertListDoesNotUpdateAuth(dir);\n   }\n \n+  @Test\n+  public void testListFilesRecursiveWhenAllListingsAreAuthoritative()\n+      throws Exception {\n+    describe(\"listFiles does not make further calls to the fs when\"\n+        + \"all nested directory listings are authoritative\");\n+    Set<Path> files = new HashSet<>();\n+\n+    Path parentDir = dir;\n+    Path parentFile = dirFile;\n+    Path nestedDir1 = new Path(dir, \"nested1\");\n+    Path nestedFile1 = new Path(nestedDir1, \"nestedFile1\");\n+    Path nestedDir2 = new Path(nestedDir1, \"nested2/\");\n+    Path nestedFile2 = new Path(nestedDir2, \"nestedFile2\");\n+\n+    files.add(parentFile);\n+    files.add(nestedFile1);\n+    files.add(nestedFile2);\n+\n+    authFS.mkdirs(parentDir);\n+    authFS.mkdirs(nestedDir1);\n+    authFS.mkdirs(nestedDir2);\n+    touchFile(parentFile);\n+    touchFile(nestedFile1);\n+    touchFile(nestedFile2);\n+\n+    // making listStatus call to mark directories authoritative\n+    authFS.listStatus(parentDir);\n+    authFS.listStatus(nestedDir1);\n+    authFS.listStatus(nestedDir2);\n+\n+    S3AStorageStatistics statistics = authFS.getStorageStatistics();\n+    statistics.reset();\n+\n+    RemoteIterator<LocatedFileStatus> statusIterator =\n+        authFS.listFiles(dir, true);\n+\n+    while (statusIterator.hasNext()) {\n+      LocatedFileStatus locatedFileStatus = statusIterator.next();\n+      assertTrue(\"This path does not exist in original listing: \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNzA2NQ==", "bodyText": "assertJ's assert will list the array, so is needed here", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370307065", "createdAt": "2020-01-23T19:19:23Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestDynamoDBMetadataStoreAuthoritativeMode.java", "diffHunk": "@@ -291,6 +295,102 @@ public void testListStatusMakesEmptyDirAuth() throws Throwable {\n     assertListDoesNotUpdateAuth(dir);\n   }\n \n+  @Test\n+  public void testListFilesRecursiveWhenAllListingsAreAuthoritative()\n+      throws Exception {\n+    describe(\"listFiles does not make further calls to the fs when\"\n+        + \"all nested directory listings are authoritative\");\n+    Set<Path> files = new HashSet<>();\n+\n+    Path parentDir = dir;\n+    Path parentFile = dirFile;\n+    Path nestedDir1 = new Path(dir, \"nested1\");\n+    Path nestedFile1 = new Path(nestedDir1, \"nestedFile1\");\n+    Path nestedDir2 = new Path(nestedDir1, \"nested2/\");\n+    Path nestedFile2 = new Path(nestedDir2, \"nestedFile2\");\n+\n+    files.add(parentFile);\n+    files.add(nestedFile1);\n+    files.add(nestedFile2);\n+\n+    authFS.mkdirs(parentDir);\n+    authFS.mkdirs(nestedDir1);\n+    authFS.mkdirs(nestedDir2);\n+    touchFile(parentFile);\n+    touchFile(nestedFile1);\n+    touchFile(nestedFile2);\n+\n+    // making listStatus call to mark directories authoritative\n+    authFS.listStatus(parentDir);\n+    authFS.listStatus(nestedDir1);\n+    authFS.listStatus(nestedDir2);\n+\n+    S3AStorageStatistics statistics = authFS.getStorageStatistics();\n+    statistics.reset();\n+\n+    RemoteIterator<LocatedFileStatus> statusIterator =\n+        authFS.listFiles(dir, true);\n+\n+    while (statusIterator.hasNext()) {\n+      LocatedFileStatus locatedFileStatus = statusIterator.next();\n+      assertTrue(\"This path does not exist in original listing: \" +\n+          locatedFileStatus.getPath(),\n+          files.remove(locatedFileStatus.getPath()));\n+    }\n+    assertEquals(\"Some files were missing from authoritative listing:\"\n+        + Arrays.toString(files.toArray()), 0, files.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNzYwMQ==", "bodyText": "good to see you've discovered using the metrics for your asserts -use MetricDiff to make it easier", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370307601", "createdAt": "2020-01-23T19:20:31Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestDynamoDBMetadataStoreAuthoritativeMode.java", "diffHunk": "@@ -291,6 +295,102 @@ public void testListStatusMakesEmptyDirAuth() throws Throwable {\n     assertListDoesNotUpdateAuth(dir);\n   }\n \n+  @Test\n+  public void testListFilesRecursiveWhenAllListingsAreAuthoritative()\n+      throws Exception {\n+    describe(\"listFiles does not make further calls to the fs when\"\n+        + \"all nested directory listings are authoritative\");\n+    Set<Path> files = new HashSet<>();\n+\n+    Path parentDir = dir;\n+    Path parentFile = dirFile;\n+    Path nestedDir1 = new Path(dir, \"nested1\");\n+    Path nestedFile1 = new Path(nestedDir1, \"nestedFile1\");\n+    Path nestedDir2 = new Path(nestedDir1, \"nested2/\");\n+    Path nestedFile2 = new Path(nestedDir2, \"nestedFile2\");\n+\n+    files.add(parentFile);\n+    files.add(nestedFile1);\n+    files.add(nestedFile2);\n+\n+    authFS.mkdirs(parentDir);\n+    authFS.mkdirs(nestedDir1);\n+    authFS.mkdirs(nestedDir2);\n+    touchFile(parentFile);\n+    touchFile(nestedFile1);\n+    touchFile(nestedFile2);\n+\n+    // making listStatus call to mark directories authoritative\n+    authFS.listStatus(parentDir);\n+    authFS.listStatus(nestedDir1);\n+    authFS.listStatus(nestedDir2);\n+\n+    S3AStorageStatistics statistics = authFS.getStorageStatistics();\n+    statistics.reset();\n+\n+    RemoteIterator<LocatedFileStatus> statusIterator =\n+        authFS.listFiles(dir, true);\n+\n+    while (statusIterator.hasNext()) {\n+      LocatedFileStatus locatedFileStatus = statusIterator.next();\n+      assertTrue(\"This path does not exist in original listing: \" +\n+          locatedFileStatus.getPath(),\n+          files.remove(locatedFileStatus.getPath()));\n+    }\n+    assertEquals(\"Some files were missing from authoritative listing:\"\n+        + Arrays.toString(files.toArray()), 0, files.size());\n+    assertEquals(\"There must not be any OBJECT_LIST requests\"\n+            + \"as all directory listings are authoritative.\",\n+        0, (long) statistics.getLong(OBJECT_LIST_REQUESTS.getSymbol()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5"}, "originalPosition": 65}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "committedDate": "2020-01-22T23:50:17Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}, "afterCommit": {"oid": "252108adbd6d24ae4b0bfe6589ffaefc5c38fd39", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/252108adbd6d24ae4b0bfe6589ffaefc5c38fd39", "committedDate": "2020-01-23T23:32:27Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "252108adbd6d24ae4b0bfe6589ffaefc5c38fd39", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/252108adbd6d24ae4b0bfe6589ffaefc5c38fd39", "committedDate": "2020-01-23T23:32:27Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}, "afterCommit": {"oid": "f4a8515586521a6889aeb14994e2fc618e7a9f0c", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/f4a8515586521a6889aeb14994e2fc618e7a9f0c", "committedDate": "2020-01-24T07:31:38Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f4a8515586521a6889aeb14994e2fc618e7a9f0c", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/f4a8515586521a6889aeb14994e2fc618e7a9f0c", "committedDate": "2020-01-24T07:31:38Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}, "afterCommit": {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/638cbddefe7513f22cb81f66441dcc1e53d08230", "committedDate": "2020-01-27T18:59:22Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5NDAyMTIx", "url": "https://github.com/apache/hadoop/pull/1815#pullrequestreview-349402121", "createdAt": "2020-01-28T14:11:35Z", "commit": {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxNDoxMTozNVrOFimV7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxNTowNTo1N1rOFiobaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDEwOA==", "bodyText": "Missing javadoc for rejectAuthoritative", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371824108", "createdAt": "2020-01-28T14:11:35Z", "author": {"login": "bgaborg"}, "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/OperationCallbacks.java", "diffHunk": "@@ -119,7 +119,8 @@ void deleteObjectAtPath(Path path,\n       Path path,\n       S3AFileStatus status,\n       boolean collectTombstones,\n-      boolean includeSelf) throws IOException;\n+      boolean includeSelf,\n+      boolean rejectAuthoritative) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNTQ4NQ==", "bodyText": "There's a call to this method in two places, and both of these places pass true for rejectAuthoritative.\nI don't see the point of modifying OperationCallbacks interface for this - just pass true from this method instead.", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371825485", "createdAt": "2020-01-28T14:13:56Z", "author": {"login": "bgaborg"}, "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java", "diffHunk": "@@ -1444,15 +1444,17 @@ public void deleteObjectAtPath(final Path path,\n         final Path path,\n         final S3AFileStatus status,\n         final boolean collectTombstones,\n-        final boolean includeSelf) throws IOException {\n+        final boolean includeSelf,\n+        final boolean rejectAuthoritative) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNTgxMQ==", "bodyText": "Also, I don't see any point for this interface change. Please justify.", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371825811", "createdAt": "2020-01-28T14:14:31Z", "author": {"login": "bgaborg"}, "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/OperationCallbacks.java", "diffHunk": "@@ -119,7 +119,8 @@ void deleteObjectAtPath(Path path,\n       Path path,\n       S3AFileStatus status,\n       boolean collectTombstones,\n-      boolean includeSelf) throws IOException;\n+      boolean includeSelf,\n+      boolean rejectAuthoritative) throws IOException;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDEwOA=="}, "originalCommit": {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNjQyNg==", "bodyText": "please add a comment before this if in what it's doing - just a short summary, preferably one line.", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371826426", "createdAt": "2020-01-28T14:15:35Z", "author": {"login": "bgaborg"}, "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java", "diffHunk": "@@ -4035,6 +4057,15 @@ public LocatedFileStatus next() throws IOException {\n               new MetadataStoreListFilesIterator(metadataStore, pm,\n                   allowAuthoritative);\n           tombstones = metadataStoreListFilesIterator.listTombstones();\n+          if (!forceNonAuthoritativeMS &&", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNjgwOQ==", "bodyText": "also extend the javadoc with this behaviour", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371826809", "createdAt": "2020-01-28T14:16:13Z", "author": {"login": "bgaborg"}, "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java", "diffHunk": "@@ -4035,6 +4057,15 @@ public LocatedFileStatus next() throws IOException {\n               new MetadataStoreListFilesIterator(metadataStore, pm,\n                   allowAuthoritative);\n           tombstones = metadataStoreListFilesIterator.listTombstones();\n+          if (!forceNonAuthoritativeMS &&", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNjQyNg=="}, "originalCommit": {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTg1ODI4MQ==", "bodyText": "I would name this listFilesAndEmptyDirectoriesForceNonAuth", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371858281", "createdAt": "2020-01-28T15:05:57Z", "author": {"login": "bgaborg"}, "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/ImportOperation.java", "diffHunk": "@@ -146,7 +146,7 @@ private long importDir() throws IOException {\n       long countOfFilesWritten = 0;\n       long countOfDirsWritten = 0;\n       RemoteIterator<S3ALocatedFileStatus> it = getFilesystem()\n-          .listFilesAndEmptyDirectories(basePath, true);\n+          .listFilesAndEmptyDirectoriesStrict(basePath, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e04538142aeeab20f8233d9f00d54083bfc2c690", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/e04538142aeeab20f8233d9f00d54083bfc2c690", "committedDate": "2020-01-28T21:59:03Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/638cbddefe7513f22cb81f66441dcc1e53d08230", "committedDate": "2020-01-27T18:59:22Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}, "afterCommit": {"oid": "e04538142aeeab20f8233d9f00d54083bfc2c690", "author": {"user": {"login": "mustafaiman", "name": "Mustafa \u0130man"}}, "url": "https://github.com/apache/hadoop/commit/e04538142aeeab20f8233d9f00d54083bfc2c690", "committedDate": "2020-01-28T21:59:03Z", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwMDU0Nzcz", "url": "https://github.com/apache/hadoop/pull/1815#pullrequestreview-350054773", "createdAt": "2020-01-29T12:02:14Z", "commit": {"oid": "e04538142aeeab20f8233d9f00d54083bfc2c690"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4662, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}