{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk4NTU2NzIx", "number": 2363, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNjoyMjozM1rOEq0oWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwMzowMDo0MlrOErbalw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMzM3OTQ2OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNjoyMjozM1rOHdP5vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNjo1ODo1OFrOHdRU_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMTI5NQ==", "bodyText": "Extract the builder.build()", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500431295", "createdAt": "2020-10-06T16:22:33Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -519,6 +525,21 @@ private Object invokeMethod(\n     }\n   }\n \n+  /**\n+   * For Tracking which is the actual client address.\n+   * It adds key/value (clientIp/\"ip\") pair to the caller context.\n+   */\n+  private void appendClientIp2CallerContext() {\n+    final CallerContext ctx = CallerContext.getCurrent();\n+    CallerContext.Builder builder;\n+    String origContext = ctx == null ? null : ctx.getContext();\n+    byte[] origSignature = ctx == null ? null : ctx.getSignature();\n+    builder = new CallerContext.Builder(origContext, clientConf);\n+    builder.append(CLIENT_IP_STR, Server.getRemoteAddress());\n+    builder.setSignature(origSignature);\n+    CallerContext.setCurrent(builder.build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NDY1NQ==", "bodyText": "Ok", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500454655", "createdAt": "2020-10-06T16:58:58Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -519,6 +525,21 @@ private Object invokeMethod(\n     }\n   }\n \n+  /**\n+   * For Tracking which is the actual client address.\n+   * It adds key/value (clientIp/\"ip\") pair to the caller context.\n+   */\n+  private void appendClientIp2CallerContext() {\n+    final CallerContext ctx = CallerContext.getCurrent();\n+    CallerContext.Builder builder;\n+    String origContext = ctx == null ? null : ctx.getContext();\n+    byte[] origSignature = ctx == null ? null : ctx.getSignature();\n+    builder = new CallerContext.Builder(origContext, clientConf);\n+    builder.append(CLIENT_IP_STR, Server.getRemoteAddress());\n+    builder.setSignature(origSignature);\n+    CallerContext.setCurrent(builder.build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMTI5NQ=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMzM4NjgxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNjoyNDoxMlrOHdP-Eg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNjo1OToxOFrOHdRVyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjQwMg==", "bodyText": "Do this in the moment you create it in line 537.", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500432402", "createdAt": "2020-10-06T16:24:12Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -519,6 +525,21 @@ private Object invokeMethod(\n     }\n   }\n \n+  /**\n+   * For Tracking which is the actual client address.\n+   * It adds key/value (clientIp/\"ip\") pair to the caller context.\n+   */\n+  private void appendClientIp2CallerContext() {\n+    final CallerContext ctx = CallerContext.getCurrent();\n+    CallerContext.Builder builder;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NDg1OA==", "bodyText": "Ok", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500454858", "createdAt": "2020-10-06T16:59:18Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -519,6 +525,21 @@ private Object invokeMethod(\n     }\n   }\n \n+  /**\n+   * For Tracking which is the actual client address.\n+   * It adds key/value (clientIp/\"ip\") pair to the caller context.\n+   */\n+  private void appendClientIp2CallerContext() {\n+    final CallerContext ctx = CallerContext.getCurrent();\n+    CallerContext.Builder builder;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjQwMg=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMzM4OTk4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNjoyNTowMFrOHdQAFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMzo1NTo0NlrOHdhtDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjkxOA==", "bodyText": "Can we verify we still contain the old context we had?", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500432918", "createdAt": "2020-10-06T16:25:00Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1903,19 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testCreateWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"705\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientIp:\"\n+    assertTrue(auditlog.getOutput().contains(\"callerContext=clientIp:\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NTE1Ng==", "bodyText": "old context is null, Will add a check.", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500455156", "createdAt": "2020-10-06T16:59:45Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1903,19 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testCreateWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"705\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientIp:\"\n+    assertTrue(auditlog.getOutput().contains(\"callerContext=clientIp:\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjkxOA=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDU0MTIwNQ==", "bodyText": "I was referring to having this test with a null context but also a test with some already passed context.", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500541205", "createdAt": "2020-10-06T19:22:57Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1903,19 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testCreateWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"705\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientIp:\"\n+    assertTrue(auditlog.getOutput().contains(\"callerContext=clientIp:\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjkxOA=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDcyMjk1OA==", "bodyText": "ok", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500722958", "createdAt": "2020-10-07T03:55:46Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1903,19 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testCreateWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"705\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientIp:\"\n+    assertTrue(auditlog.getOutput().contains(\"callerContext=clientIp:\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjkxOA=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMzM5NDg3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNjoyNjoxMlrOHdQDIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNjo1OTo1NFrOHdRXTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzY5OQ==", "bodyText": "I would do it more formal: appendClientIpToCallerContext", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500433699", "createdAt": "2020-10-06T16:26:12Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -404,6 +409,7 @@ private Object invokeMethod(\n           \" with params \" + Arrays.deepToString(params) + \" from \"\n           + router.getRouterId());\n     }\n+    appendClientIp2CallerContext();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NTI0Ng==", "bodyText": "ok", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500455246", "createdAt": "2020-10-06T16:59:54Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -404,6 +409,7 @@ private Object invokeMethod(\n           \" with params \" + Arrays.deepToString(params) + \" from \"\n           + router.getRouterId());\n     }\n+    appendClientIp2CallerContext();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzY5OQ=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMzM5NjQ0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxNjoyNjo0MlrOHdQEMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNjoxMDo1OFrOHd6_OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA==", "bodyText": "Is there something else we need to add?", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500433968", "createdAt": "2020-10-06T16:26:42Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -116,10 +118,13 @@\n   /** Optional perf monitor. */\n   private final RouterRpcMonitor rpcMonitor;\n \n+  private final Configuration clientConf;\n+\n   /** Pattern to parse a stack trace line. */\n   private static final Pattern STACK_TRACE_PATTERN =\n       Pattern.compile(\"\\\\tat (.*)\\\\.(.*)\\\\((.*):(\\\\d*)\\\\)\");\n \n+  private static final String CLIENT_IP_STR = \"clientIp\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NTgyNQ==", "bodyText": "Now don't know Whether add anything else except client ip, any thoughts?", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500455825", "createdAt": "2020-10-06T17:00:49Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -116,10 +118,13 @@\n   /** Optional perf monitor. */\n   private final RouterRpcMonitor rpcMonitor;\n \n+  private final Configuration clientConf;\n+\n   /** Pattern to parse a stack trace line. */\n   private static final Pattern STACK_TRACE_PATTERN =\n       Pattern.compile(\"\\\\tat (.*)\\\\.(.*)\\\\((.*):(\\\\d*)\\\\)\");\n \n+  private static final String CLIENT_IP_STR = \"clientIp\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDU0MDg0OQ==", "bodyText": "One of the things that was brought up in the past was to send back in the context which was the namespace that executed this.\nAnyway, let's focus on the locality one for now.\nDoes it make sense to add a test to make sure we can do proper locality from the Namenode side with this change? Or should we leave this for the future.", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500540849", "createdAt": "2020-10-06T19:22:16Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -116,10 +118,13 @@\n   /** Optional perf monitor. */\n   private final RouterRpcMonitor rpcMonitor;\n \n+  private final Configuration clientConf;\n+\n   /** Pattern to parse a stack trace line. */\n   private static final Pattern STACK_TRACE_PATTERN =\n       Pattern.compile(\"\\\\tat (.*)\\\\.(.*)\\\\((.*):(\\\\d*)\\\\)\");\n \n+  private static final String CLIENT_IP_STR = \"clientIp\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDcyMjgzOA==", "bodyText": "HDFS-13248 focuses on the locality, here we focus on audit log, does it make sense?", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500722838", "createdAt": "2020-10-07T03:55:18Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -116,10 +118,13 @@\n   /** Optional perf monitor. */\n   private final RouterRpcMonitor rpcMonitor;\n \n+  private final Configuration clientConf;\n+\n   /** Pattern to parse a stack trace line. */\n   private static final Pattern STACK_TRACE_PATTERN =\n       Pattern.compile(\"\\\\tat (.*)\\\\.(.*)\\\\((.*):(\\\\d*)\\\\)\");\n \n+  private static final String CLIENT_IP_STR = \"clientIp\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzNzIwOA==", "bodyText": "Makes sense, let's just keep in mind HDFS-13248 when doing this.\nSo far it looks like is covered.", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501137208", "createdAt": "2020-10-07T16:10:58Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -116,10 +118,13 @@\n   /** Optional perf monitor. */\n   private final RouterRpcMonitor rpcMonitor;\n \n+  private final Configuration clientConf;\n+\n   /** Pattern to parse a stack trace line. */\n   private static final Pattern STACK_TRACE_PATTERN =\n       Pattern.compile(\"\\\\tat (.*)\\\\.(.*)\\\\((.*):(\\\\d*)\\\\)\");\n \n+  private static final String CLIENT_IP_STR = \"clientIp\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA=="}, "originalCommit": {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNzkxMDM2OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNjoxMjoxNlrOHd7CrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMToxOTowNVrOHeF6JQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg==", "bodyText": "Anyway we can check for the actual IP?", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501138092", "createdAt": "2020-10-07T16:12:16Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1904,27 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testMkdirsWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Current callerContext is null\n+    assertNull(CallerContext.getCurrent());\n+\n+    // Set client context\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(\"clientContext\").build());\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"755\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientContext,clientIp:\"\n+    assertTrue(auditlog.getOutput()\n+        .contains(\"callerContext=clientContext,clientIp:\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTE3Njk4OQ==", "bodyText": "Had thought  about this. DFSClient & Client do not expose ip, and TestAuditLogger & TestAuditLogs do not check client ip. So do you have any suggestions?", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501176989", "createdAt": "2020-10-07T17:12:12Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1904,27 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testMkdirsWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Current callerContext is null\n+    assertNull(CallerContext.getCurrent());\n+\n+    // Set client context\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(\"clientContext\").build());\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"755\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientContext,clientIp:\"\n+    assertTrue(auditlog.getOutput()\n+        .contains(\"callerContext=clientContext,clientIp:\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}, "originalCommit": {"oid": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTE4NTcwMg==", "bodyText": "Or just keep it that way, and do not modify UT", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501185702", "createdAt": "2020-10-07T17:26:26Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1904,27 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testMkdirsWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Current callerContext is null\n+    assertNull(CallerContext.getCurrent());\n+\n+    // Set client context\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(\"clientContext\").build());\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"755\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientContext,clientIp:\"\n+    assertTrue(auditlog.getOutput()\n+        .contains(\"callerContext=clientContext,clientIp:\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}, "originalCommit": {"oid": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIzMDU1Mw==", "bodyText": "The only issue I see is to grab random logs but I guess is fine.", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501230553", "createdAt": "2020-10-07T18:38:26Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1904,27 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testMkdirsWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Current callerContext is null\n+    assertNull(CallerContext.getCurrent());\n+\n+    // Set client context\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(\"clientContext\").build());\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"755\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientContext,clientIp:\"\n+    assertTrue(auditlog.getOutput()\n+        .contains(\"callerContext=clientContext,clientIp:\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}, "originalCommit": {"oid": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTI0MDEwMg==", "bodyText": "Sorry, do not understand it.\nI think If we check the actual IP, we should get the client actual IP, e.g \"w.x.y.z\", and then check the audit log, it should contain \"callerContext=clientContext,clientIp:w.x.y.z\", is it right?\nNow it's hard to get client ip.", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501240102", "createdAt": "2020-10-07T18:55:38Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1904,27 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testMkdirsWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Current callerContext is null\n+    assertNull(CallerContext.getCurrent());\n+\n+    // Set client context\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(\"clientContext\").build());\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"755\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientContext,clientIp:\"\n+    assertTrue(auditlog.getOutput()\n+        .contains(\"callerContext=clientContext,clientIp:\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}, "originalCommit": {"oid": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNjEzMw==", "bodyText": "Correct, grabbing the proper Client IP is not trivial and error prone so I'm fine with this.", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501316133", "createdAt": "2020-10-07T21:19:05Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1904,27 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testMkdirsWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Current callerContext is null\n+    assertNull(CallerContext.getCurrent());\n+\n+    // Set client context\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(\"clientContext\").build());\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"755\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientContext,clientIp:\"\n+    assertTrue(auditlog.getOutput()\n+        .contains(\"callerContext=clientContext,clientIp:\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}, "originalCommit": {"oid": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTczMzk5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwMzowMDo0MlrOHeMRwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwNDozNjowMlrOHeNqRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQyMDQ4MA==", "bodyText": "Can we pass the string separator instead of configuration to avoid unnecessary Configuration.get() for each RPC?", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501420480", "createdAt": "2020-10-08T03:00:42Z", "author": {"login": "aajisaka"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -519,6 +525,20 @@ private Object invokeMethod(\n     }\n   }\n \n+  /**\n+   * For Tracking which is the actual client address.\n+   * It adds key/value (clientIp/\"ip\") pair to the caller context.\n+   */\n+  private void appendClientIpToCallerContext() {\n+    final CallerContext ctx = CallerContext.getCurrent();\n+    String origContext = ctx == null ? null : ctx.getContext();\n+    byte[] origSignature = ctx == null ? null : ctx.getSignature();\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(origContext, clientConfiguration)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQ0MzE0MQ==", "bodyText": "OK, fixed, please review again, thanks!", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501443141", "createdAt": "2020-10-08T04:36:02Z", "author": {"login": "ferhui"}, "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -519,6 +525,20 @@ private Object invokeMethod(\n     }\n   }\n \n+  /**\n+   * For Tracking which is the actual client address.\n+   * It adds key/value (clientIp/\"ip\") pair to the caller context.\n+   */\n+  private void appendClientIpToCallerContext() {\n+    final CallerContext ctx = CallerContext.getCurrent();\n+    String origContext = ctx == null ? null : ctx.getContext();\n+    byte[] origSignature = ctx == null ? null : ctx.getSignature();\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(origContext, clientConfiguration)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQyMDQ4MA=="}, "originalCommit": {"oid": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1"}, "originalPosition": 57}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3194, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}