{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY4MTQzMTk2", "number": 2228, "title": "YARN-10399 Refactor NodeQueueLoadMonitor class to make it extendable", "bodyText": "", "createdAt": "2020-08-14T19:13:00Z", "url": "https://github.com/apache/hadoop/pull/2228", "merged": true, "mergeCommit": {"oid": "9b9f7ea16a299911fc75738401cb5a0f8713ead7"}, "closed": true, "closedAt": "2020-08-19T17:14:50Z", "author": {"login": "zhengbli"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc-5dhIgH2gAyNDY4MTQzMTk2OmRmOTIzNzQxZDUxNjNiYWUxNWNmMmE5NzY5MzkwNjQ5MDA3Y2E1M2I=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdAOlQaAH2gAyNDY4MTQzMTk2OmMxZTc2MDYyNzk0N2QyOTYzMjM1MmE2YTc2ZWEyZDViNTdkYzg3NzM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "df923741d5163bae15cf2a9769390649007ca53b", "author": {"user": {"login": "zhengbli", "name": "Zhengbo Li"}}, "url": "https://github.com/apache/hadoop/commit/df923741d5163bae15cf2a9769390649007ca53b", "committedDate": "2020-08-14T19:06:13Z", "message": "Refactor NodeQueueLoadMonitor class to make it extendable"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3ODIwNzky", "url": "https://github.com/apache/hadoop/pull/2228#pullrequestreview-467820792", "createdAt": "2020-08-14T19:18:16Z", "commit": {"oid": "df923741d5163bae15cf2a9769390649007ca53b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxOToxODoxN1rOHBAsWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxOToxODoxN1rOHBAsWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDgyMTk3Nw==", "bodyText": "As we are moving this, we can make it a proper logger comment with {}.", "url": "https://github.com/apache/hadoop/pull/2228#discussion_r470821977", "createdAt": "2020-08-14T19:18:17Z", "author": {"login": "goiri"}, "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/distributed/NodeQueueLoadMonitor.java", "diffHunk": "@@ -260,55 +236,72 @@ public void updateNode(RMNode rmNode) {\n       opportunisticContainersStatus =\n           OpportunisticContainersStatus.newInstance();\n     }\n-    int opportQueueCapacity =\n-        opportunisticContainersStatus.getOpportQueueCapacity();\n-    int estimatedQueueWaitTime =\n-        opportunisticContainersStatus.getEstimatedQueueWaitTime();\n-    int waitQueueLength = opportunisticContainersStatus.getWaitQueueLength();\n+\n     // Add nodes to clusterNodes. If estimatedQueueTime is -1, ignore node\n     // UNLESS comparator is based on queue length.\n     ReentrantReadWriteLock.WriteLock writeLock = clusterNodesLock.writeLock();\n     writeLock.lock();\n     try {\n-      ClusterNode currentNode = this.clusterNodes.get(rmNode.getNodeID());\n-      if (currentNode == null) {\n-        if (rmNode.getState() != NodeState.DECOMMISSIONING &&\n-            (estimatedQueueWaitTime != -1 ||\n-                comparator == LoadComparator.QUEUE_LENGTH)) {\n-          this.clusterNodes.put(rmNode.getNodeID(),\n-              new ClusterNode(rmNode.getNodeID())\n-                  .setQueueWaitTime(estimatedQueueWaitTime)\n-                  .setQueueLength(waitQueueLength)\n-                  .setQueueCapacity(opportQueueCapacity));\n-          LOG.info(\"Inserting ClusterNode [\" + rmNode.getNodeID() + \"] \" +\n-              \"with queue wait time [\" + estimatedQueueWaitTime + \"] and \" +\n-              \"wait queue length [\" + waitQueueLength + \"]\");\n-        } else {\n-          LOG.warn(\"IGNORING ClusterNode [\" + rmNode.getNodeID() + \"] \" +\n-              \"with queue wait time [\" + estimatedQueueWaitTime + \"] and \" +\n-              \"wait queue length [\" + waitQueueLength + \"]\");\n-        }\n+      ClusterNode clusterNode = this.clusterNodes.get(rmNode.getNodeID());\n+      if (clusterNode == null) {\n+        onNewNodeAdded(rmNode, opportunisticContainersStatus);\n       } else {\n-        if (rmNode.getState() != NodeState.DECOMMISSIONING &&\n-            (estimatedQueueWaitTime != -1 ||\n-                comparator == LoadComparator.QUEUE_LENGTH)) {\n-          currentNode\n+        onExistingNodeUpdated(rmNode, clusterNode, opportunisticContainersStatus);\n+      }\n+    } finally {\n+      writeLock.unlock();\n+    }\n+  }\n+\n+  protected void onNewNodeAdded(\n+      RMNode rmNode, OpportunisticContainersStatus status) {\n+    int opportQueueCapacity = status.getOpportQueueCapacity();\n+    int estimatedQueueWaitTime = status.getEstimatedQueueWaitTime();\n+    int waitQueueLength = status.getWaitQueueLength();\n+\n+    if (rmNode.getState() != NodeState.DECOMMISSIONING &&\n+        (estimatedQueueWaitTime != -1 ||\n+            comparator == LoadComparator.QUEUE_LENGTH)) {\n+      this.clusterNodes.put(rmNode.getNodeID(),\n+          new ClusterNode(rmNode.getNodeID())\n               .setQueueWaitTime(estimatedQueueWaitTime)\n               .setQueueLength(waitQueueLength)\n-              .updateTimestamp();\n-          LOG.debug(\"Updating ClusterNode [{}] with queue wait time [{}] and\"\n+              .setNodeLabels(rmNode.getNodeLabels())\n+              .setQueueCapacity(opportQueueCapacity));\n+      LOG.info(\"Inserting ClusterNode [\" + rmNode.getNodeID() + \"] \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df923741d5163bae15cf2a9769390649007ca53b"}, "originalPosition": 234}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3ODIwODkw", "url": "https://github.com/apache/hadoop/pull/2228#pullrequestreview-467820890", "createdAt": "2020-08-14T19:18:28Z", "commit": {"oid": "df923741d5163bae15cf2a9769390649007ca53b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0932068f0e6a879e42cff44754910f3154562c0f", "author": {"user": {"login": "zhengbli", "name": "Zhengbo Li"}}, "url": "https://github.com/apache/hadoop/commit/0932068f0e6a879e42cff44754910f3154562c0f", "committedDate": "2020-08-14T19:34:30Z", "message": "Use proper logging format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c1e760627947d29632352a6a76ea2d5b57dc8773", "author": {"user": {"login": "zhengbli", "name": "Zhengbo Li"}}, "url": "https://github.com/apache/hadoop/commit/c1e760627947d29632352a6a76ea2d5b57dc8773", "committedDate": "2020-08-18T22:16:36Z", "message": "Add more comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3914, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}