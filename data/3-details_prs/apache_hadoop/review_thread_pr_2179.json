{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU5NDI0OTkw", "number": 2179, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMFQxMDoyOToxMVrOEeDhbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMFQxMDozMDo0MVrOEeDh6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5OTUwNDQ0OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/ConfigurationKeys.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMFQxMDoyOToxMVrOHJhueQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwMzo0NDoyMFrOHMUw8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTc1MTgwMQ==", "bodyText": "use experimental in name to show they are exactly that", "url": "https://github.com/apache/hadoop/pull/2179#discussion_r479751801", "createdAt": "2020-08-30T10:29:11Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/ConfigurationKeys.java", "diffHunk": "@@ -52,6 +52,8 @@\n   public static final String AZURE_OAUTH_TOKEN_FETCH_RETRY_DELTA_BACKOFF = \"fs.azure.oauth.token.fetch.retry.delta.backoff\";\n \n   // Read and write buffer sizes defined by the user\n+  public static final String AZURE_WRITE_MAX_CONCURRENT_REQUESTS = \"fs.azure.write.max.concurrent.requests\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef072e07600fcba97a18271eba92b3934648d4e9"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjY4NTE2OA==", "bodyText": "These configs are tested on prod environments. The same can remain as a means to controle the resource usage. With the internal discussions we had we would like to keep the same this way.", "url": "https://github.com/apache/hadoop/pull/2179#discussion_r482685168", "createdAt": "2020-09-03T03:44:20Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/ConfigurationKeys.java", "diffHunk": "@@ -52,6 +52,8 @@\n   public static final String AZURE_OAUTH_TOKEN_FETCH_RETRY_DELTA_BACKOFF = \"fs.azure.oauth.token.fetch.retry.delta.backoff\";\n \n   // Read and write buffer sizes defined by the user\n+  public static final String AZURE_WRITE_MAX_CONCURRENT_REQUESTS = \"fs.azure.write.max.concurrent.requests\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTc1MTgwMQ=="}, "originalCommit": {"oid": "ef072e07600fcba97a18271eba92b3934648d4e9"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5OTUwNTI4OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/site/markdown/abfs.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMFQxMDozMDowNFrOHJhu1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMFQxMDozMDowNFrOHJhu1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTc1MTg5NQ==", "bodyText": "make clear: or when doing many writes in same process (bulk uploads, hive LLAP/spark with many workers)", "url": "https://github.com/apache/hadoop/pull/2179#discussion_r479751895", "createdAt": "2020-08-30T10:30:04Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/site/markdown/abfs.md", "diffHunk": "@@ -796,6 +796,18 @@ will be -1. To disable readaheads, set this value to 0. If your workload is\n  doing only random reads (non-sequential) or you are seeing throttling, you\n   may try setting this value to 0.\n \n+To run under limited memory situations configure the following.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef072e07600fcba97a18271eba92b3934648d4e9"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5OTUwNTY4OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/ITestAbfsOutputStream.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMFQxMDozMDo0MVrOHJhvBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwMzo0NDo0MVrOHMUxow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTc1MTk0Mg==", "bodyText": "try with resources, always", "url": "https://github.com/apache/hadoop/pull/2179#discussion_r479751942", "createdAt": "2020-08-30T10:30:41Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AbstractAbfsIntegrationTest;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem;\n+import org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys;\n+\n+/**\n+ * Test create operation.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  private static final Path TEST_FILE_PATH = new Path(\"testfile\");\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testMaxRequestsAndQueueCapacityDefaults() throws Exception {\n+    Configuration conf = getRawConfiguration();\n+    final AzureBlobFileSystem fs = getFileSystem(conf);\n+    FSDataOutputStream out = fs.create(TEST_FILE_PATH);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef072e07600fcba97a18271eba92b3934648d4e9"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjY4NTM0Nw==", "bodyText": "Done", "url": "https://github.com/apache/hadoop/pull/2179#discussion_r482685347", "createdAt": "2020-09-03T03:44:41Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AbstractAbfsIntegrationTest;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem;\n+import org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys;\n+\n+/**\n+ * Test create operation.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  private static final Path TEST_FILE_PATH = new Path(\"testfile\");\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testMaxRequestsAndQueueCapacityDefaults() throws Exception {\n+    Configuration conf = getRawConfiguration();\n+    final AzureBlobFileSystem fs = getFileSystem(conf);\n+    FSDataOutputStream out = fs.create(TEST_FILE_PATH);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTc1MTk0Mg=="}, "originalCommit": {"oid": "ef072e07600fcba97a18271eba92b3934648d4e9"}, "originalPosition": 45}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3349, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}