{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAyMDUwMDM3", "number": 1952, "title": "HDFS-1820. FTPFileSystem attempts to close the outputstream even when it is not initialised.", "bodyText": "Making sure an underlying outputstream is successfully created by apache-commons FTPClient before wrapping it with FSDataOutputStream.\nGracefully release resources when a destination file can't be created due to lack of permissions.", "createdAt": "2020-04-10T20:10:01Z", "url": "https://github.com/apache/hadoop/pull/1952", "merged": true, "mergeCommit": {"oid": "18d7dfbf35564694e24bf2b7c99fea1bee1c790e"}, "closed": true, "closedAt": "2020-04-27T13:43:52Z", "author": {"login": "mpryahin"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcWT5e-AH2gAyNDAyMDUwMDM3OmYzM2Y3NmY4ZmI2N2Y5YjFjOTRlNjVkMjliZmI0MTVjYTgyNmJkMmQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcZhkJIAH2gAyNDAyMDUwMDM3OmY0NmI2NTE0ODA1ZTNkNDU2YTlmNzA4NDAxMDc4YjhjZTlkODVhOGU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f33f76f8fb67f9b1c94e65d29bfb415ca826bd2d", "author": {"user": {"login": "mpryahin", "name": "Mike"}}, "url": "https://github.com/apache/hadoop/commit/f33f76f8fb67f9b1c94e65d29bfb415ca826bd2d", "committedDate": "2020-04-10T16:43:24Z", "message": "HDFS-1820 SFTPFilesSystem hangs when a user lacks write permissions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d879a247ff7498182097aedf4a625ae31dd77ddf", "author": {"user": {"login": "mpryahin", "name": "Mike"}}, "url": "https://github.com/apache/hadoop/commit/d879a247ff7498182097aedf4a625ae31dd77ddf", "committedDate": "2020-04-10T17:57:51Z", "message": "HDFS-1820 fixed code style issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc200c7e2f03b954d8516b4b30e0cf56bd97353d", "author": {"user": {"login": "mpryahin", "name": "Mike"}}, "url": "https://github.com/apache/hadoop/commit/bc200c7e2f03b954d8516b4b30e0cf56bd97353d", "committedDate": "2020-04-10T19:23:47Z", "message": "HDFS-1820 code style issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzkzMDM4", "url": "https://github.com/apache/hadoop/pull/1952#pullrequestreview-391793038", "createdAt": "2020-04-11T19:13:18Z", "commit": {"oid": "bc200c7e2f03b954d8516b4b30e0cf56bd97353d"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxOToxMzoxOFrOGEPavw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxOToxNjoxMFrOGEPcDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzEwMDA5NQ==", "bodyText": "Can we use setBoolean()?", "url": "https://github.com/apache/hadoop/pull/1952#discussion_r407100095", "createdAt": "2020-04-11T19:13:18Z", "author": {"login": "goiri"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/ftp/TestFTPFileSystem.java", "diffHunk": "@@ -37,9 +54,71 @@\n  */\n public class TestFTPFileSystem {\n \n+  private TestFtpServer server;\n+\n   @Rule\n   public Timeout testTimeout = new Timeout(180000);\n \n+  @Before\n+  public void setUp() throws Exception {\n+    server = new TestFtpServer(GenericTestUtils.getTestDir().toPath()).start();\n+  }\n+\n+  @After\n+  @SuppressWarnings(\"ResultOfMethodCallIgnored\")\n+  public void tearDown() throws Exception {\n+    server.stop();\n+    Files.walk(server.getFtpRoot())\n+        .sorted(Comparator.reverseOrder())\n+        .map(java.nio.file.Path::toFile)\n+        .forEach(File::delete);\n+  }\n+\n+  @Test\n+  public void testCreateWithWritePermissions() throws Exception {\n+    BaseUser user = server.addUser(\"test\", \"password\", new WritePermission());\n+    Configuration configuration = new Configuration();\n+    configuration.set(\"fs.defaultFS\", \"ftp:///\");\n+    configuration.set(\"fs.ftp.host\", \"localhost\");\n+    configuration.setInt(\"fs.ftp.host.port\", server.getPort());\n+    configuration.set(\"fs.ftp.user.localhost\", user.getName());\n+    configuration.set(\"fs.ftp.password.localhost\", user.getPassword());\n+    configuration.set(\"fs.ftp.impl.disable.cache\", \"true\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc200c7e2f03b954d8516b4b30e0cf56bd97353d"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzEwMDIwMg==", "bodyText": "We should use LambdaTestUtils#intercept and make sure that we fail after write()", "url": "https://github.com/apache/hadoop/pull/1952#discussion_r407100202", "createdAt": "2020-04-11T19:14:06Z", "author": {"login": "goiri"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/ftp/TestFTPFileSystem.java", "diffHunk": "@@ -37,9 +54,71 @@\n  */\n public class TestFTPFileSystem {\n \n+  private TestFtpServer server;\n+\n   @Rule\n   public Timeout testTimeout = new Timeout(180000);\n \n+  @Before\n+  public void setUp() throws Exception {\n+    server = new TestFtpServer(GenericTestUtils.getTestDir().toPath()).start();\n+  }\n+\n+  @After\n+  @SuppressWarnings(\"ResultOfMethodCallIgnored\")\n+  public void tearDown() throws Exception {\n+    server.stop();\n+    Files.walk(server.getFtpRoot())\n+        .sorted(Comparator.reverseOrder())\n+        .map(java.nio.file.Path::toFile)\n+        .forEach(File::delete);\n+  }\n+\n+  @Test\n+  public void testCreateWithWritePermissions() throws Exception {\n+    BaseUser user = server.addUser(\"test\", \"password\", new WritePermission());\n+    Configuration configuration = new Configuration();\n+    configuration.set(\"fs.defaultFS\", \"ftp:///\");\n+    configuration.set(\"fs.ftp.host\", \"localhost\");\n+    configuration.setInt(\"fs.ftp.host.port\", server.getPort());\n+    configuration.set(\"fs.ftp.user.localhost\", user.getName());\n+    configuration.set(\"fs.ftp.password.localhost\", user.getPassword());\n+    configuration.set(\"fs.ftp.impl.disable.cache\", \"true\");\n+\n+    FileSystem fs = FileSystem.get(configuration);\n+    byte[] bytesExpected = \"hello world\".getBytes(StandardCharsets.UTF_8);\n+    try (FSDataOutputStream outputStream = fs.create(new Path(\"test1.txt\"))) {\n+      outputStream.write(bytesExpected);\n+    }\n+    try (FSDataInputStream input = fs.open(new Path(\"test1.txt\"))) {\n+      assertThat(bytesExpected, equalTo(IOUtils.readFullyToByteArray(input)));\n+    }\n+  }\n+\n+  @Test\n+  public void testCreateWithoutWritePermissions() throws Exception {\n+    BaseUser user = server.addUser(\"test\", \"password\");\n+    Configuration configuration = new Configuration();\n+    configuration.set(\"fs.defaultFS\", \"ftp:///\");\n+    configuration.set(\"fs.ftp.host\", \"localhost\");\n+    configuration.setInt(\"fs.ftp.host.port\", server.getPort());\n+    configuration.set(\"fs.ftp.user.localhost\", user.getName());\n+    configuration.set(\"fs.ftp.password.localhost\", user.getPassword());\n+    configuration.set(\"fs.ftp.impl.disable.cache\", \"true\");\n+\n+    FileSystem fs = FileSystem.get(configuration);\n+    byte[] bytesExpected = \"hello world\".getBytes(StandardCharsets.UTF_8);\n+\n+    try (FSDataOutputStream outputStream = fs.create(new Path(\"test1.txt\"))) {\n+      outputStream.write(bytesExpected);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc200c7e2f03b954d8516b4b30e0cf56bd97353d"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzEwMDQyOA==", "bodyText": "Starting by Test in  this folder I would expect it to have a @test in it.\nTBH, I don't know what better name to give it, FtpTestServer?", "url": "https://github.com/apache/hadoop/pull/1952#discussion_r407100428", "createdAt": "2020-04-11T19:16:10Z", "author": {"login": "goiri"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/ftp/TestFtpServer.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ftp;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+\n+import org.apache.ftpserver.FtpServer;\n+import org.apache.ftpserver.FtpServerFactory;\n+import org.apache.ftpserver.ftplet.Authority;\n+import org.apache.ftpserver.ftplet.FtpException;\n+import org.apache.ftpserver.ftplet.UserManager;\n+import org.apache.ftpserver.impl.DefaultFtpServer;\n+import org.apache.ftpserver.listener.Listener;\n+import org.apache.ftpserver.listener.ListenerFactory;\n+import org.apache.ftpserver.usermanager.PropertiesUserManagerFactory;\n+import org.apache.ftpserver.usermanager.impl.BaseUser;\n+\n+/**\n+ * Helper class facilitating to manage a local ftp\n+ * server for unit tests purposes only.\n+ */\n+public class TestFtpServer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc200c7e2f03b954d8516b4b30e0cf56bd97353d"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "499ecf99180a2f209f97fff6b874c60a69d5fe80", "author": {"user": {"login": "mpryahin", "name": "Mike"}}, "url": "https://github.com/apache/hadoop/commit/499ecf99180a2f209f97fff6b874c60a69d5fe80", "committedDate": "2020-04-12T08:34:13Z", "message": "HDFS-1820 code review improvements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "385ed063d0a9247b73610d4a548200ff4e311b27", "author": {"user": {"login": "mpryahin", "name": "Mike"}}, "url": "https://github.com/apache/hadoop/commit/385ed063d0a9247b73610d4a548200ff4e311b27", "committedDate": "2020-04-12T09:37:25Z", "message": "HDFS-1820 code style issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxODgzNjA4", "url": "https://github.com/apache/hadoop/pull/1952#pullrequestreview-391883608", "createdAt": "2020-04-12T18:26:16Z", "commit": {"oid": "385ed063d0a9247b73610d4a548200ff4e311b27"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk2MzMzMjMz", "url": "https://github.com/apache/hadoop/pull/1952#pullrequestreview-396333233", "createdAt": "2020-04-20T10:33:05Z", "commit": {"oid": "385ed063d0a9247b73610d4a548200ff4e311b27"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMDozMzowN1rOGIN_MA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxMDozNjowNlrOGIOFxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTI3MDk2MA==", "bodyText": "handle case where server==null, i.e. setup failed", "url": "https://github.com/apache/hadoop/pull/1952#discussion_r411270960", "createdAt": "2020-04-20T10:33:07Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/ftp/TestFTPFileSystem.java", "diffHunk": "@@ -37,9 +54,70 @@\n  */\n public class TestFTPFileSystem {\n \n+  private FtpTestServer server;\n+\n   @Rule\n   public Timeout testTimeout = new Timeout(180000);\n \n+  @Before\n+  public void setUp() throws Exception {\n+    server = new FtpTestServer(GenericTestUtils.getTestDir().toPath()).start();\n+  }\n+\n+  @After\n+  @SuppressWarnings(\"ResultOfMethodCallIgnored\")\n+  public void tearDown() throws Exception {\n+    server.stop();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "385ed063d0a9247b73610d4a548200ff4e311b27"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTI3MjExNA==", "bodyText": "could this raise an IOE? If so, that disconnect() afterwards still needs to be called, so make close() a catch/log operation. IOUtils.closeStream could do this (and it includes the null check)", "url": "https://github.com/apache/hadoop/pull/1952#discussion_r411272114", "createdAt": "2020-04-20T10:35:09Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ftp/FTPFileSystem.java", "diffHunk": "@@ -340,8 +343,19 @@ public FSDataOutputStream create(Path file, FsPermission permission,\n     // file. The FTP client connection is closed when close() is called on the\n     // FSDataOutputStream.\n     client.changeWorkingDirectory(parent.toUri().getPath());\n-    FSDataOutputStream fos = new FSDataOutputStream(client.storeFileStream(file\n-        .getName()), statistics) {\n+    OutputStream outputStream = client.storeFileStream(file.getName());\n+\n+    if (!FTPReply.isPositivePreliminary(client.getReplyCode())) {\n+      // The ftpClient is an inconsistent state. Must close the stream\n+      // which in turn will logout and disconnect from FTP server\n+      if (outputStream != null) {\n+        outputStream.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "385ed063d0a9247b73610d4a548200ff4e311b27"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTI3MjY0Nw==", "bodyText": "assuming we have documentation for the FTP connector, you are going to have to document this new option.", "url": "https://github.com/apache/hadoop/pull/1952#discussion_r411272647", "createdAt": "2020-04-20T10:36:06Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ftp/FTPFileSystem.java", "diffHunk": "@@ -110,7 +111,9 @@ public void initialize(URI uri, Configuration conf) throws IOException { // get\n \n     // get port information from uri, (overrides info in conf)\n     int port = uri.getPort();\n-    port = (port == -1) ? FTP.DEFAULT_PORT : port;\n+    if(port == -1){\n+      port = conf.getInt(FS_FTP_HOST_PORT, FTP.DEFAULT_PORT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "385ed063d0a9247b73610d4a548200ff4e311b27"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6ceac7de28f9a9658ef539dd2b157b5963d9599e", "author": {"user": {"login": "mpryahin", "name": "Mike"}}, "url": "https://github.com/apache/hadoop/commit/6ceac7de28f9a9658ef539dd2b157b5963d9599e", "committedDate": "2020-04-20T11:24:42Z", "message": "HDFS-1820 core review enhancements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c9b5ad0606371abf04ab08865b4e8f9c75babd9", "author": {"user": {"login": "mpryahin", "name": "Mike"}}, "url": "https://github.com/apache/hadoop/commit/3c9b5ad0606371abf04ab08865b4e8f9c75babd9", "committedDate": "2020-04-20T13:34:36Z", "message": "Merge branch 'trunk' of https://github.com/apache/hadoop into HDFS-1820"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f46b6514805e3d456a9f708401078b8ce9d85a8e", "author": {"user": {"login": "mpryahin", "name": "Mike"}}, "url": "https://github.com/apache/hadoop/commit/f46b6514805e3d456a9f708401078b8ce9d85a8e", "committedDate": "2020-04-20T16:20:32Z", "message": "Merge branch 'trunk' of https://github.com/apache/hadoop into HDFS-1820"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4586, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}