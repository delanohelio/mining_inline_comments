{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAwMDgzMjQ3", "number": 2370, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxNzo0Mzo0N1rOEruKwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxMDoyNTo1MlrOEr_cVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MjgwNjQwOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxNzo0Mzo0N1rOHepjGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxNzo0Mzo0N1rOHepjGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTkwMDA1Ng==", "bodyText": "I am not 100% sure about this condition check. Any suggestions/confirmations?\nThe goal is to only let Active NN to check and provision snapshot trash roots. The assumption is that the mkdirs() call below propagates the write to standby NameNode.", "url": "https://github.com/apache/hadoop/pull/2370#discussion_r501900056", "createdAt": "2020-10-08T17:43:47Z", "author": {"login": "smengcl"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "diffHunk": "@@ -8524,6 +8530,39 @@ void checkAccess(String src, FsAction mode) throws IOException {\n     logAuditEvent(true, operationName, src);\n   }\n \n+  /**\n+   * Check if snapshot roots are created for all existing snapshottable\n+   * directories. Create them if not.\n+   */\n+  void checkAndProvisionSnapshotTrashRoots() throws IOException {\n+    if (haEnabled) {\n+      if (!inActiveState()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dce5752068a327b86e28c8cf1c642691f95d6741"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0NTYyNTY5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxMDoyMjoxMlrOHfD95Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxMDoyMjoxMlrOHfD95Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjMzMjkwMQ==", "bodyText": "getIsSnapshotTrashRootEnabled --> isSnapshotTrashRootEnabled??", "url": "https://github.com/apache/hadoop/pull/2370#discussion_r502332901", "createdAt": "2020-10-09T10:22:12Z", "author": {"login": "bshashikant"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "diffHunk": "@@ -2031,6 +2033,10 @@ private String metaSaveAsString() {\n     return sw.toString();\n   }\n \n+  public boolean getIsSnapshotTrashRootEnabled() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dce5752068a327b86e28c8cf1c642691f95d6741"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0NTYzNjcwOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxMDoyNTo1MlrOHfEEsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjo1OTowMlrOHgGd1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjMzNDY0Mw==", "bodyText": "how about doing this here:\n @Override\n    public void startActiveServices() throws IOException {\n      try {\n        namesystem.startActiveServices();\n        startTrashEmptier(getConf());\n      } catch (Throwable t) {\n        doImmediateShutdown(t);\n      }\n    }\n\njust before starting the trashEmptier thread. We don't need to check for Active or standby state here as these should be called in only Active NameNode.", "url": "https://github.com/apache/hadoop/pull/2370#discussion_r502334643", "createdAt": "2020-10-09T10:25:52Z", "author": {"login": "bshashikant"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java", "diffHunk": "@@ -781,6 +781,10 @@ protected void initialize(Configuration conf) throws IOException {\n       }\n     }\n \n+    if (namesystem.getIsSnapshotTrashRootEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dce5752068a327b86e28c8cf1c642691f95d6741"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzQyMjQyMw==", "bodyText": "good idea", "url": "https://github.com/apache/hadoop/pull/2370#discussion_r503422423", "createdAt": "2020-10-12T16:59:02Z", "author": {"login": "smengcl"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java", "diffHunk": "@@ -781,6 +781,10 @@ protected void initialize(Configuration conf) throws IOException {\n       }\n     }\n \n+    if (namesystem.getIsSnapshotTrashRootEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjMzNDY0Mw=="}, "originalCommit": {"oid": "dce5752068a327b86e28c8cf1c642691f95d6741"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3204, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}