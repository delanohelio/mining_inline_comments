{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk1MzE0OTM1", "number": 2352, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMDozNTozMlrOEo-ICg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMjowMjowNVrOEo_1oQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMzk2MzYyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMDozNTozMlrOHaXc1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxODozNjoyN1rOHaqdSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQwOTIzNg==", "bodyText": "should it be even allowed to create a .Trash file inside a snapshottable root?", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497409236", "createdAt": "2020-09-30T10:35:32Z", "author": {"login": "bshashikant"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "diffHunk": "@@ -2094,6 +2103,41 @@ public Void next(final FileSystem fs, final Path p)\n     }.resolve(this, absF);\n   }\n \n+  /**\n+   * Helper function to check if a trash root exists in the given directory,\n+   * remove the trash root if it is empty, or throw IOException if not empty\n+   * @param p Path to a directory.\n+   */\n+  private void checkTrashRootAndRemoveIfEmpty(final Path p) throws IOException {\n+    Path trashRoot = new Path(p, FileSystem.TRASH_PREFIX);\n+    try {\n+      // listStatus has 4 possible outcomes here:\n+      // 1) throws FileNotFoundException: the trash root doesn't exist.\n+      // 2) returns empty array: the trash path is an empty directory.\n+      // 3) returns non-empty array, len >= 2: the trash root is not empty.\n+      // 4) returns non-empty array, len == 1:\n+      //    i) if the element's path is exactly p, the trash path is not a dir.\n+      //       e.g. a file named .Trash. Ignore.\n+      //   ii) if the element's path isn't p, the trash root is not empty.\n+      FileStatus[] fileStatuses = listStatus(trashRoot);\n+      if (fileStatuses.length == 0) {\n+        DFSClient.LOG.debug(\"Removing empty trash root {}\", trashRoot);\n+        delete(trashRoot, false);\n+      } else {\n+        if (fileStatuses.length == 1\n+            && !fileStatuses[0].isDirectory()\n+            && !fileStatuses[0].getPath().equals(p)) {\n+          // Ignore the trash path because it is not a directory.\n+          DFSClient.LOG.warn(\"{} is not a directory.\", trashRoot);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzcyMDY0OQ==", "bodyText": "I get your point. But I don't think it is worth it to prevent the user from doing so. At best, we can throw some client-side warnings when the user is attempting to do so.\nThere are so many ways to circumvent this that I can think of so far if the user really wants to: the user could create the .Trash file before allowing snapshot, rename .Trash file from another place.\nEven if we have placed restrictions on a newer version of HDFS NameNode, they might have already created the .Trash before the NN upgrade.\nAlso, regular user trash also faces the same issue.\n$ hdfs dfs -touch hdfs://127.0.0.1:9999/user/smeng/.Trash\n$ hdfs dfs -touch hdfs://127.0.0.1:9999/file3\n$ hdfs dfs -rm hdfs://127.0.0.1:9999/file3\n2020-09-30 11:27:43,062 WARN fs.TrashPolicyDefault: Can't create trash directory: hdfs://127.0.0.1:9999/user/smeng/.Trash/Current\norg.apache.hadoop.fs.ParentNotDirectoryException: /user/smeng/.Trash (is not a directory)\n\tat org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkIsDirectory(FSPermissionChecker.java:743)\n...\nrm: Failed to move to trash: hdfs://127.0.0.1:9999/file3: /user/smeng/.Trash (is not a directory)\n\nAnother point is, trash is mostly a client-side feature. The client should still have some freedom to do something with it.\nIt is a bit sarcastic for me to say this cause I myself have made so many changes to intervene the trash usage :D.\nAt least creating this .Trash file shouldn't cause harm. It just fails, gloriously, if it is a file and someone is trying to move to that trash.\nOr, maybe the admin would do this intentionally to prevent users from using trash inside that specific snapshot directory?", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497720649", "createdAt": "2020-09-30T18:36:27Z", "author": {"login": "smengcl"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "diffHunk": "@@ -2094,6 +2103,41 @@ public Void next(final FileSystem fs, final Path p)\n     }.resolve(this, absF);\n   }\n \n+  /**\n+   * Helper function to check if a trash root exists in the given directory,\n+   * remove the trash root if it is empty, or throw IOException if not empty\n+   * @param p Path to a directory.\n+   */\n+  private void checkTrashRootAndRemoveIfEmpty(final Path p) throws IOException {\n+    Path trashRoot = new Path(p, FileSystem.TRASH_PREFIX);\n+    try {\n+      // listStatus has 4 possible outcomes here:\n+      // 1) throws FileNotFoundException: the trash root doesn't exist.\n+      // 2) returns empty array: the trash path is an empty directory.\n+      // 3) returns non-empty array, len >= 2: the trash root is not empty.\n+      // 4) returns non-empty array, len == 1:\n+      //    i) if the element's path is exactly p, the trash path is not a dir.\n+      //       e.g. a file named .Trash. Ignore.\n+      //   ii) if the element's path isn't p, the trash root is not empty.\n+      FileStatus[] fileStatuses = listStatus(trashRoot);\n+      if (fileStatuses.length == 0) {\n+        DFSClient.LOG.debug(\"Removing empty trash root {}\", trashRoot);\n+        delete(trashRoot, false);\n+      } else {\n+        if (fileStatuses.length == 1\n+            && !fileStatuses[0].isDirectory()\n+            && !fileStatuses[0].getPath().equals(p)) {\n+          // Ignore the trash path because it is not a directory.\n+          DFSClient.LOG.warn(\"{} is not a directory.\", trashRoot);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQwOTIzNg=="}, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNDIxODQ5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMTo1NDoyN1rOHaZ6hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQwMDozNzoyM1rOHa0V_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ0OTYwNw==", "bodyText": "Should isSnapshotTrashRootEnabled be checked here?  If isSnapshotTrashRootEnabled == false, all the provisionSnapshottableDirTrash calls should fail.", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497449607", "createdAt": "2020-09-30T11:54:27Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "diffHunk": "@@ -2901,6 +2945,74 @@ private void provisionEZTrash(String path, FsPermission trashPermission)\n     setPermission(trashPath, trashPermission);\n   }\n \n+  /**\n+   * HDFS only.\n+   * \n+   * Provision snapshottable directory trash.\n+   * @param path Path to a snapshottable directory.\n+   * @param trashPermission Expected FsPermission of the trash root.\n+   * @throws IOException\n+   */\n+  public void provisionSnapshottableDirTrash(final Path path,\n+      final FsPermission trashPermission) throws IOException {\n+    Path absF = fixRelativePart(path);\n+    new FileSystemLinkResolver<Void>() {\n+      @Override\n+      public Void doCall(Path p) throws IOException {\n+        provisionSnapshottableDirTrash(getPathName(p), trashPermission);\n+        return null;\n+      }\n+\n+      @Override\n+      public Void next(FileSystem fs, Path p) throws IOException {\n+        if (fs instanceof DistributedFileSystem) {\n+          DistributedFileSystem myDfs = (DistributedFileSystem)fs;\n+          myDfs.provisionSnapshottableDirTrash(p, trashPermission);\n+          return null;\n+        }\n+        throw new UnsupportedOperationException(\n+            \"Cannot provisionSnapshottableDirTrash through a symlink to\" +\n+            \" a non-DistributedFileSystem: \" + fs + \" -> \" + p);\n+      }\n+    }.resolve(this, absF);\n+  }\n+\n+  private void provisionSnapshottableDirTrash(\n+      String pathStr, FsPermission trashPermission) throws IOException {\n+    Path path = new Path(pathStr);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMTIzOA==", "bodyText": "Hi Nicholas, thanks for reviewing the patch.\nI thought about placing the check, but I eventually didn't. Only admins can use it since this is a dfsadmin command. Maybe the admin just want to provision snapshot trash before restarting the NameNode to enable snapshot trash root.\nThat being said, I want to add a warning if isSnapshotTrashRootEnabled == false when running this command. So the admin can be reminded. What do you think?", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497731238", "createdAt": "2020-09-30T18:55:21Z", "author": {"login": "smengcl"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "diffHunk": "@@ -2901,6 +2945,74 @@ private void provisionEZTrash(String path, FsPermission trashPermission)\n     setPermission(trashPath, trashPermission);\n   }\n \n+  /**\n+   * HDFS only.\n+   * \n+   * Provision snapshottable directory trash.\n+   * @param path Path to a snapshottable directory.\n+   * @param trashPermission Expected FsPermission of the trash root.\n+   * @throws IOException\n+   */\n+  public void provisionSnapshottableDirTrash(final Path path,\n+      final FsPermission trashPermission) throws IOException {\n+    Path absF = fixRelativePart(path);\n+    new FileSystemLinkResolver<Void>() {\n+      @Override\n+      public Void doCall(Path p) throws IOException {\n+        provisionSnapshottableDirTrash(getPathName(p), trashPermission);\n+        return null;\n+      }\n+\n+      @Override\n+      public Void next(FileSystem fs, Path p) throws IOException {\n+        if (fs instanceof DistributedFileSystem) {\n+          DistributedFileSystem myDfs = (DistributedFileSystem)fs;\n+          myDfs.provisionSnapshottableDirTrash(p, trashPermission);\n+          return null;\n+        }\n+        throw new UnsupportedOperationException(\n+            \"Cannot provisionSnapshottableDirTrash through a symlink to\" +\n+            \" a non-DistributedFileSystem: \" + fs + \" -> \" + p);\n+      }\n+    }.resolve(this, absF);\n+  }\n+\n+  private void provisionSnapshottableDirTrash(\n+      String pathStr, FsPermission trashPermission) throws IOException {\n+    Path path = new Path(pathStr);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ0OTYwNw=="}, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg4MjYyMw==", "bodyText": "Sure, adding a warning sounds good.", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497882623", "createdAt": "2020-10-01T00:37:23Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "diffHunk": "@@ -2901,6 +2945,74 @@ private void provisionEZTrash(String path, FsPermission trashPermission)\n     setPermission(trashPath, trashPermission);\n   }\n \n+  /**\n+   * HDFS only.\n+   * \n+   * Provision snapshottable directory trash.\n+   * @param path Path to a snapshottable directory.\n+   * @param trashPermission Expected FsPermission of the trash root.\n+   * @throws IOException\n+   */\n+  public void provisionSnapshottableDirTrash(final Path path,\n+      final FsPermission trashPermission) throws IOException {\n+    Path absF = fixRelativePart(path);\n+    new FileSystemLinkResolver<Void>() {\n+      @Override\n+      public Void doCall(Path p) throws IOException {\n+        provisionSnapshottableDirTrash(getPathName(p), trashPermission);\n+        return null;\n+      }\n+\n+      @Override\n+      public Void next(FileSystem fs, Path p) throws IOException {\n+        if (fs instanceof DistributedFileSystem) {\n+          DistributedFileSystem myDfs = (DistributedFileSystem)fs;\n+          myDfs.provisionSnapshottableDirTrash(p, trashPermission);\n+          return null;\n+        }\n+        throw new UnsupportedOperationException(\n+            \"Cannot provisionSnapshottableDirTrash through a symlink to\" +\n+            \" a non-DistributedFileSystem: \" + fs + \" -> \" + p);\n+      }\n+    }.resolve(this, absF);\n+  }\n+\n+  private void provisionSnapshottableDirTrash(\n+      String pathStr, FsPermission trashPermission) throws IOException {\n+    Path path = new Path(pathStr);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ0OTYwNw=="}, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNDIyNzg4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMTo1NzoyM1rOHaaATA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxODo1OTowMFrOHarOng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ1MTA4NA==", "bodyText": "Use the constant HdfsAdmin.TRASH_PERMISSION instead of harding coding it.", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497451084", "createdAt": "2020-09-30T11:57:23Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java", "diffHunk": "@@ -1245,6 +1265,10 @@ private void printHelp(String cmd) {\n     String disallowSnapshot = \"-disallowSnapshot <snapshotDir>:\\n\" +\n         \"\\tDo not allow snapshots to be taken on a directory any more.\\n\";\n \n+    String provisionSnapshotTrash = \"-provisionSnapshotTrash <snapshotDir>:\\n\" +\n+        \"\\tProvision trash root in a snapshottable directory with permission\"\n+        + \"\\t777 and sticky bit.\\n\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzI3OA==", "bodyText": "done. made HdfsAdmin.TRASH_PERMISSION public for this.", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497733278", "createdAt": "2020-09-30T18:59:00Z", "author": {"login": "smengcl"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java", "diffHunk": "@@ -1245,6 +1265,10 @@ private void printHelp(String cmd) {\n     String disallowSnapshot = \"-disallowSnapshot <snapshotDir>:\\n\" +\n         \"\\tDo not allow snapshots to be taken on a directory any more.\\n\";\n \n+    String provisionSnapshotTrash = \"-provisionSnapshotTrash <snapshotDir>:\\n\" +\n+        \"\\tProvision trash root in a snapshottable directory with permission\"\n+        + \"\\t777 and sticky bit.\\n\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ1MTA4NA=="}, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNDIzNjE4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMTo1OTo1MFrOHaaFfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMTo1OTo1MFrOHaaFfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ1MjQxMg==", "bodyText": "Return the trash path.", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497452412", "createdAt": "2020-09-30T11:59:50Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "diffHunk": "@@ -2901,6 +2945,74 @@ private void provisionEZTrash(String path, FsPermission trashPermission)\n     setPermission(trashPath, trashPermission);\n   }\n \n+  /**\n+   * HDFS only.\n+   * \n+   * Provision snapshottable directory trash.\n+   * @param path Path to a snapshottable directory.\n+   * @param trashPermission Expected FsPermission of the trash root.\n+   * @throws IOException\n+   */\n+  public void provisionSnapshottableDirTrash(final Path path,\n+      final FsPermission trashPermission) throws IOException {\n+    Path absF = fixRelativePart(path);\n+    new FileSystemLinkResolver<Void>() {\n+      @Override\n+      public Void doCall(Path p) throws IOException {\n+        provisionSnapshottableDirTrash(getPathName(p), trashPermission);\n+        return null;\n+      }\n+\n+      @Override\n+      public Void next(FileSystem fs, Path p) throws IOException {\n+        if (fs instanceof DistributedFileSystem) {\n+          DistributedFileSystem myDfs = (DistributedFileSystem)fs;\n+          myDfs.provisionSnapshottableDirTrash(p, trashPermission);\n+          return null;\n+        }\n+        throw new UnsupportedOperationException(\n+            \"Cannot provisionSnapshottableDirTrash through a symlink to\" +\n+            \" a non-DistributedFileSystem: \" + fs + \" -> \" + p);\n+      }\n+    }.resolve(this, absF);\n+  }\n+\n+  private void provisionSnapshottableDirTrash(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 120}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNDI0MjA1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMjowMTozMlrOHaaJDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMjowMTozMlrOHaaJDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ1MzMyNA==", "bodyText": "Return the trash path.", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497453324", "createdAt": "2020-09-30T12:01:32Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java", "diffHunk": "@@ -2901,6 +2945,74 @@ private void provisionEZTrash(String path, FsPermission trashPermission)\n     setPermission(trashPath, trashPermission);\n   }\n \n+  /**\n+   * HDFS only.\n+   * \n+   * Provision snapshottable directory trash.\n+   * @param path Path to a snapshottable directory.\n+   * @param trashPermission Expected FsPermission of the trash root.\n+   * @throws IOException\n+   */\n+  public void provisionSnapshottableDirTrash(final Path path,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNDI0NDE3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMjowMjowNVrOHaaKRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxMjowMjowNVrOHaaKRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ1MzYzNw==", "bodyText": "Print out the trash path.", "url": "https://github.com/apache/hadoop/pull/2352#discussion_r497453637", "createdAt": "2020-09-30T12:02:05Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java", "diffHunk": "@@ -782,14 +784,32 @@ public void allowSnapshot(String[] argv) throws IOException {\n    */\n   public void disallowSnapshot(String[] argv) throws IOException {\n     Path p = new Path(argv[1]);\n-    final DistributedFileSystem dfs = AdminHelper.getDFS(p.toUri(), getConf());\n+    final HdfsAdmin admin = new HdfsAdmin(p.toUri(), getConf());\n     try {\n-      dfs.disallowSnapshot(p);\n+      admin.disallowSnapshot(p);\n     } catch (SnapshotException e) {\n       throw new RemoteException(e.getClass().getName(), e.getMessage());\n     }\n     System.out.println(\"Disallowing snapshot on \" + argv[1] + \" succeeded\");\n   }\n+\n+  /**\n+   * Provision trash root in a snapshottable directory.\n+   * Usage: hdfs dfsadmin -provisionSnapshotTrash snapshotDir\n+   * @param argv List of of command line parameters.\n+   * @exception IOException\n+   */\n+  public void provisionSnapshotTrash(String[] argv) throws IOException {\n+    Path p = new Path(argv[1]);\n+    final HdfsAdmin admin = new HdfsAdmin(p.toUri(), getConf());\n+    try {\n+      admin.provisionSnapshottableDirTrash(p);\n+    } catch (SnapshotException e) {\n+      throw new RemoteException(e.getClass().getName(), e.getMessage());\n+    }\n+    System.out.println(\"Provision of snapshot trash in \" + argv[1] +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20640f3dc8c6cb4ca26ba7971d5bc4026db077c"}, "originalPosition": 57}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3320, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}