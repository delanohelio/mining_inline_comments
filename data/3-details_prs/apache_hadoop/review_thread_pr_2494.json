{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI4MzY4NDY1", "number": 2494, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNToyOTo0MVrOE_NRig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNTozNDowOVrOE_NaXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NzEzMjI2OnYy", "diffSide": "LEFT", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNToyOTo0MVrOH8yaMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMzowNzowM1rOH9IlvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjUxMg==", "bodyText": "Why remove this variable and add new within if-else block?", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533502512", "createdAt": "2020-12-01T15:29:41Z", "author": {"login": "jiwq"}, "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -531,11 +531,11 @@ private static boolean shouldSkipNodeSchedule(FiCaSchedulerNode node,\n \n   /**\n    * Schedule on all nodes by starting at a random point.\n+   * Schedule on all partitions by starting at a random partition\n+   * when multiNodePlacementEnabled is true.\n    * @param cs\n    */\n   static void schedule(CapacityScheduler cs) throws InterruptedException{\n-    // First randomize the start point\n-    int current = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb506a09bcf17d30468cb22231e710492168a1c8"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg2NTkxNg==", "bodyText": "Fixed it.", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533865916", "createdAt": "2020-12-02T03:07:03Z", "author": {"login": "zhuqi-lucas"}, "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -531,11 +531,11 @@ private static boolean shouldSkipNodeSchedule(FiCaSchedulerNode node,\n \n   /**\n    * Schedule on all nodes by starting at a random point.\n+   * Schedule on all partitions by starting at a random partition\n+   * when multiNodePlacementEnabled is true.\n    * @param cs\n    */\n   static void schedule(CapacityScheduler cs) throws InterruptedException{\n-    // First randomize the start point\n-    int current = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjUxMg=="}, "originalCommit": {"oid": "fb506a09bcf17d30468cb22231e710492168a1c8"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NzEzNDM4OnYy", "diffSide": "RIGHT", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNTozMDowM1rOH8ybeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMzowNjo1MVrOH9Iljw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjg0MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  //Get all partitions\n          \n          \n            \n                  // Get all partitions", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533502841", "createdAt": "2020-12-01T15:30:03Z", "author": {"login": "jiwq"}, "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -544,44 +544,73 @@ static void schedule(CapacityScheduler cs) throws InterruptedException{\n     if(nodeSize == 0) {\n       return;\n     }\n-    int start = random.nextInt(nodeSize);\n+    if (!cs.multiNodePlacementEnabled) {\n+      // First randomize the start point\n+      int current = 0;\n+      int start = random.nextInt(nodeSize);\n \n-    // To avoid too verbose DEBUG logging, only print debug log once for\n-    // every 10 secs.\n-    boolean printSkipedNodeLogging = false;\n-    if (Time.monotonicNow() / 1000 % 10 == 0) {\n-      printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n-    } else {\n-      printedVerboseLoggingForAsyncScheduling = false;\n-    }\n+      // To avoid too verbose DEBUG logging, only print debug log once for\n+      // every 10 secs.\n+      boolean printSkipedNodeLogging = false;\n+      if (Time.monotonicNow() / 1000 % 10 == 0) {\n+        printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n+      } else {\n+        printedVerboseLoggingForAsyncScheduling = false;\n+      }\n+\n+      // Allocate containers of node [start, end)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ >= start) {\n+          if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n+            continue;\n+          }\n+          cs.allocateContainersToNode(node.getNodeID(), false);\n+        }\n+      }\n \n-    // Allocate containers of node [start, end)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ >= start) {\n+      current = 0;\n+\n+      // Allocate containers of node [0, start)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ > start) {\n+          break;\n+        }\n         if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n           continue;\n         }\n         cs.allocateContainersToNode(node.getNodeID(), false);\n       }\n-    }\n-\n-    current = 0;\n \n-    // Allocate containers of node [0, start)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ > start) {\n-        break;\n+      if (printSkipedNodeLogging) {\n+        printedVerboseLoggingForAsyncScheduling = true;\n       }\n-      if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n-        continue;\n+    } else {\n+      //Get all partitions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb506a09bcf17d30468cb22231e710492168a1c8"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg2NTg3MQ==", "bodyText": "Fixed it.", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533865871", "createdAt": "2020-12-02T03:06:51Z", "author": {"login": "zhuqi-lucas"}, "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -544,44 +544,73 @@ static void schedule(CapacityScheduler cs) throws InterruptedException{\n     if(nodeSize == 0) {\n       return;\n     }\n-    int start = random.nextInt(nodeSize);\n+    if (!cs.multiNodePlacementEnabled) {\n+      // First randomize the start point\n+      int current = 0;\n+      int start = random.nextInt(nodeSize);\n \n-    // To avoid too verbose DEBUG logging, only print debug log once for\n-    // every 10 secs.\n-    boolean printSkipedNodeLogging = false;\n-    if (Time.monotonicNow() / 1000 % 10 == 0) {\n-      printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n-    } else {\n-      printedVerboseLoggingForAsyncScheduling = false;\n-    }\n+      // To avoid too verbose DEBUG logging, only print debug log once for\n+      // every 10 secs.\n+      boolean printSkipedNodeLogging = false;\n+      if (Time.monotonicNow() / 1000 % 10 == 0) {\n+        printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n+      } else {\n+        printedVerboseLoggingForAsyncScheduling = false;\n+      }\n+\n+      // Allocate containers of node [start, end)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ >= start) {\n+          if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n+            continue;\n+          }\n+          cs.allocateContainersToNode(node.getNodeID(), false);\n+        }\n+      }\n \n-    // Allocate containers of node [start, end)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ >= start) {\n+      current = 0;\n+\n+      // Allocate containers of node [0, start)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ > start) {\n+          break;\n+        }\n         if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n           continue;\n         }\n         cs.allocateContainersToNode(node.getNodeID(), false);\n       }\n-    }\n-\n-    current = 0;\n \n-    // Allocate containers of node [0, start)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ > start) {\n-        break;\n+      if (printSkipedNodeLogging) {\n+        printedVerboseLoggingForAsyncScheduling = true;\n       }\n-      if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n-        continue;\n+    } else {\n+      //Get all partitions", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjg0MQ=="}, "originalCommit": {"oid": "fb506a09bcf17d30468cb22231e710492168a1c8"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NzE1NDg2OnYy", "diffSide": "RIGHT", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNTozNDowOVrOH8yn6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMzowNjozOFrOH9IlOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwNjAyNg==", "bodyText": "Due to getCandiateNodeSet(String) method maybe return null, so call allocateContainersToNode can cause NPE.", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533506026", "createdAt": "2020-12-01T15:34:09Z", "author": {"login": "jiwq"}, "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -544,44 +544,73 @@ static void schedule(CapacityScheduler cs) throws InterruptedException{\n     if(nodeSize == 0) {\n       return;\n     }\n-    int start = random.nextInt(nodeSize);\n+    if (!cs.multiNodePlacementEnabled) {\n+      // First randomize the start point\n+      int current = 0;\n+      int start = random.nextInt(nodeSize);\n \n-    // To avoid too verbose DEBUG logging, only print debug log once for\n-    // every 10 secs.\n-    boolean printSkipedNodeLogging = false;\n-    if (Time.monotonicNow() / 1000 % 10 == 0) {\n-      printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n-    } else {\n-      printedVerboseLoggingForAsyncScheduling = false;\n-    }\n+      // To avoid too verbose DEBUG logging, only print debug log once for\n+      // every 10 secs.\n+      boolean printSkipedNodeLogging = false;\n+      if (Time.monotonicNow() / 1000 % 10 == 0) {\n+        printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n+      } else {\n+        printedVerboseLoggingForAsyncScheduling = false;\n+      }\n+\n+      // Allocate containers of node [start, end)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ >= start) {\n+          if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n+            continue;\n+          }\n+          cs.allocateContainersToNode(node.getNodeID(), false);\n+        }\n+      }\n \n-    // Allocate containers of node [start, end)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ >= start) {\n+      current = 0;\n+\n+      // Allocate containers of node [0, start)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ > start) {\n+          break;\n+        }\n         if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n           continue;\n         }\n         cs.allocateContainersToNode(node.getNodeID(), false);\n       }\n-    }\n-\n-    current = 0;\n \n-    // Allocate containers of node [0, start)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ > start) {\n-        break;\n+      if (printSkipedNodeLogging) {\n+        printedVerboseLoggingForAsyncScheduling = true;\n       }\n-      if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n-        continue;\n+    } else {\n+      //Get all partitions\n+      List<String> partitions = cs.nodeTracker.getPartitions();\n+      int partitionSize = partitions.size();\n+      // First randomize the start point\n+      int start = random.nextInt(partitionSize);\n+      int current = 0;\n+      // Allocate containers of partition [start, end)\n+      for (String partititon : partitions) {\n+        if (current++ >= start) {\n+          cs.allocateContainersToNode(cs.getCandidateNodeSet(partititon),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fb506a09bcf17d30468cb22231e710492168a1c8"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg2NTc4Ng==", "bodyText": "Fixed it.", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533865786", "createdAt": "2020-12-02T03:06:38Z", "author": {"login": "zhuqi-lucas"}, "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -544,44 +544,73 @@ static void schedule(CapacityScheduler cs) throws InterruptedException{\n     if(nodeSize == 0) {\n       return;\n     }\n-    int start = random.nextInt(nodeSize);\n+    if (!cs.multiNodePlacementEnabled) {\n+      // First randomize the start point\n+      int current = 0;\n+      int start = random.nextInt(nodeSize);\n \n-    // To avoid too verbose DEBUG logging, only print debug log once for\n-    // every 10 secs.\n-    boolean printSkipedNodeLogging = false;\n-    if (Time.monotonicNow() / 1000 % 10 == 0) {\n-      printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n-    } else {\n-      printedVerboseLoggingForAsyncScheduling = false;\n-    }\n+      // To avoid too verbose DEBUG logging, only print debug log once for\n+      // every 10 secs.\n+      boolean printSkipedNodeLogging = false;\n+      if (Time.monotonicNow() / 1000 % 10 == 0) {\n+        printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n+      } else {\n+        printedVerboseLoggingForAsyncScheduling = false;\n+      }\n+\n+      // Allocate containers of node [start, end)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ >= start) {\n+          if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n+            continue;\n+          }\n+          cs.allocateContainersToNode(node.getNodeID(), false);\n+        }\n+      }\n \n-    // Allocate containers of node [start, end)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ >= start) {\n+      current = 0;\n+\n+      // Allocate containers of node [0, start)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ > start) {\n+          break;\n+        }\n         if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n           continue;\n         }\n         cs.allocateContainersToNode(node.getNodeID(), false);\n       }\n-    }\n-\n-    current = 0;\n \n-    // Allocate containers of node [0, start)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ > start) {\n-        break;\n+      if (printSkipedNodeLogging) {\n+        printedVerboseLoggingForAsyncScheduling = true;\n       }\n-      if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n-        continue;\n+    } else {\n+      //Get all partitions\n+      List<String> partitions = cs.nodeTracker.getPartitions();\n+      int partitionSize = partitions.size();\n+      // First randomize the start point\n+      int start = random.nextInt(partitionSize);\n+      int current = 0;\n+      // Allocate containers of partition [start, end)\n+      for (String partititon : partitions) {\n+        if (current++ >= start) {\n+          cs.allocateContainersToNode(cs.getCandidateNodeSet(partititon),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwNjAyNg=="}, "originalCommit": {"oid": "fb506a09bcf17d30468cb22231e710492168a1c8"}, "originalPosition": 89}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3146, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}