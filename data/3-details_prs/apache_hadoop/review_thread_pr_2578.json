{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQ2NjY1NzIz", "number": 2578, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQyMzoxMTo1MFrOFJ4-aA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNjoxNDoxMFrOFMAeNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ1OTE0OTg0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQyMzoxMTo1MFrOIMaMyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwNzoxOTozMVrOINng6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTg4MzA4MA==", "bodyText": "We'll need to add these new metrics to here right?", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r549883080", "createdAt": "2020-12-29T23:11:50Z", "author": {"login": "sunchao"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.java", "diffHunk": "@@ -183,6 +183,11 @@\n   @Metric private MutableRate checkAndUpdateOp;\n   @Metric private MutableRate updateReplicaUnderRecoveryOp;\n \n+  @Metric MutableCounterLong totalPacketsReceived;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTE0OTgwMw==", "bodyText": "Done", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r551149803", "createdAt": "2021-01-04T07:19:31Z", "author": {"login": "fengnanli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.java", "diffHunk": "@@ -183,6 +183,11 @@\n   @Metric private MutableRate checkAndUpdateOp;\n   @Metric private MutableRate updateReplicaUnderRecoveryOp;\n \n+  @Metric MutableCounterLong totalPacketsReceived;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTg4MzA4MA=="}, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ1OTE1MDQ0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQyMzoxMjowOVrOIMaNFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwNzoxOTo0MlrOINnhJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTg4MzE1OA==", "bodyText": "nit: code style", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r549883158", "createdAt": "2020-12-29T23:12:09Z", "author": {"login": "sunchao"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "diffHunk": "@@ -161,6 +163,65 @@ public void testReceivePacketMetrics() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testReceivePacketSlowMetrics() throws Exception {\n+    Configuration conf = new HdfsConfiguration();\n+    final int interval = 1;\n+    conf.set(DFSConfigKeys.DFS_METRICS_PERCENTILES_INTERVALS_KEY, \"\" + interval);\n+    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)\n+        .numDataNodes(3).build();\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final DataNodeFaultInjector injector =\n+          Mockito.mock(DataNodeFaultInjector.class);\n+      Mockito.doAnswer(new Answer() {\n+        @Override\n+        public Object answer(InvocationOnMock invocationOnMock)\n+            throws Throwable {\n+          // make the op taking longer time\n+          Thread.sleep(1000);\n+          return null;\n+        }\n+      }).when(injector).stopSendingPacketDownstream(Mockito.anyString());\n+      Mockito.doAnswer(new Answer() {\n+        @Override\n+        public Object answer(InvocationOnMock invocationOnMock)\n+            throws Throwable {\n+          // make the op taking longer time\n+          Thread.sleep(1000);\n+          return null;\n+        }\n+      }).when(injector).delayWriteToOsCache();\n+      Mockito.doAnswer(new Answer() {\n+        @Override\n+        public Object answer(InvocationOnMock invocationOnMock)\n+            throws Throwable {\n+          // make the op taking longer time\n+          Thread.sleep(1000);\n+          return null;\n+        }\n+      }).when(injector).delayWriteToDisk();\n+      DataNodeFaultInjector.set(injector);\n+      Path testFile = new Path(\"/testFlushNanosMetric.txt\");\n+      FSDataOutputStream fout = fs.create(testFile);\n+      fout.write(new byte[1]);\n+      fout.hsync();\n+      fout.close();\n+      List<DataNode> datanodes = cluster.getDataNodes();\n+      DataNode datanode = datanodes.get(0);\n+      MetricsRecordBuilder dnMetrics = getMetrics(datanode.getMetrics().name());\n+      assertTrue(\"More than 1 packet received\",\n+          getLongCounter(\"TotalPacketsReceived\", dnMetrics) > 1L);\n+      assertTrue(\"More than 1 slow packet to mirror\",\n+          getLongCounter(\"TotalPacketsSlowWriteToMirror\", dnMetrics) > 1L);\n+      assertCounter(\"TotalPacketsSlowWriteToDisk\", 1L, dnMetrics);\n+      assertCounter(\"TotalPacketsSlowWriteOsCache\", 0L, dnMetrics);\n+    } finally {\n+      if (cluster != null) {cluster.shutdown();}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTE0OTg2MA==", "bodyText": "Done", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r551149860", "createdAt": "2021-01-04T07:19:42Z", "author": {"login": "fengnanli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "diffHunk": "@@ -161,6 +163,65 @@ public void testReceivePacketMetrics() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testReceivePacketSlowMetrics() throws Exception {\n+    Configuration conf = new HdfsConfiguration();\n+    final int interval = 1;\n+    conf.set(DFSConfigKeys.DFS_METRICS_PERCENTILES_INTERVALS_KEY, \"\" + interval);\n+    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)\n+        .numDataNodes(3).build();\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final DataNodeFaultInjector injector =\n+          Mockito.mock(DataNodeFaultInjector.class);\n+      Mockito.doAnswer(new Answer() {\n+        @Override\n+        public Object answer(InvocationOnMock invocationOnMock)\n+            throws Throwable {\n+          // make the op taking longer time\n+          Thread.sleep(1000);\n+          return null;\n+        }\n+      }).when(injector).stopSendingPacketDownstream(Mockito.anyString());\n+      Mockito.doAnswer(new Answer() {\n+        @Override\n+        public Object answer(InvocationOnMock invocationOnMock)\n+            throws Throwable {\n+          // make the op taking longer time\n+          Thread.sleep(1000);\n+          return null;\n+        }\n+      }).when(injector).delayWriteToOsCache();\n+      Mockito.doAnswer(new Answer() {\n+        @Override\n+        public Object answer(InvocationOnMock invocationOnMock)\n+            throws Throwable {\n+          // make the op taking longer time\n+          Thread.sleep(1000);\n+          return null;\n+        }\n+      }).when(injector).delayWriteToDisk();\n+      DataNodeFaultInjector.set(injector);\n+      Path testFile = new Path(\"/testFlushNanosMetric.txt\");\n+      FSDataOutputStream fout = fs.create(testFile);\n+      fout.write(new byte[1]);\n+      fout.hsync();\n+      fout.close();\n+      List<DataNode> datanodes = cluster.getDataNodes();\n+      DataNode datanode = datanodes.get(0);\n+      MetricsRecordBuilder dnMetrics = getMetrics(datanode.getMetrics().name());\n+      assertTrue(\"More than 1 packet received\",\n+          getLongCounter(\"TotalPacketsReceived\", dnMetrics) > 1L);\n+      assertTrue(\"More than 1 slow packet to mirror\",\n+          getLongCounter(\"TotalPacketsSlowWriteToMirror\", dnMetrics) > 1L);\n+      assertCounter(\"TotalPacketsSlowWriteToDisk\", 1L, dnMetrics);\n+      assertCounter(\"TotalPacketsSlowWriteOsCache\", 0L, dnMetrics);\n+    } finally {\n+      if (cluster != null) {cluster.shutdown();}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTg4MzE1OA=="}, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ2MTc1ODk4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxNzo1NTo0N1rOIMySYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwNzoyODowNlrOINnq6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzczMA==", "bodyText": "As we are at it, let's use the logger format. We still need the Arrays toString so we need the isWarnEnabled though.", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r550277730", "createdAt": "2020-12-30T17:55:47Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java", "diffHunk": "@@ -603,12 +604,15 @@ private int receivePacket() throws IOException {\n             mirrorAddr,\n             duration);\n         trackSendPacketToLastNodeInPipeline(duration);\n-        if (duration > datanodeSlowLogThresholdMs && LOG.isWarnEnabled()) {\n-          LOG.warn(\"Slow BlockReceiver write packet to mirror took \" + duration\n-              + \"ms (threshold=\" + datanodeSlowLogThresholdMs + \"ms), \"\n-              + \"downstream DNs=\" + Arrays.toString(downstreamDNs)\n-              + \", blockId=\" + replicaInfo.getBlockId()\n-              + \", seqno=\" + seqno);\n+        if (duration > datanodeSlowLogThresholdMs) {\n+          datanode.metrics.incrPacketSlowWriteToMirror();\n+          if (LOG.isWarnEnabled()) {\n+            LOG.warn(\"Slow BlockReceiver write packet to mirror took \" + duration\n+                + \"ms (threshold=\" + datanodeSlowLogThresholdMs + \"ms), \"\n+                + \"downstream DNs=\" + Arrays.toString(downstreamDNs)\n+                + \", blockId=\" + replicaInfo.getBlockId()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTE1MjM2MQ==", "bodyText": "Done", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r551152361", "createdAt": "2021-01-04T07:28:06Z", "author": {"login": "fengnanli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java", "diffHunk": "@@ -603,12 +604,15 @@ private int receivePacket() throws IOException {\n             mirrorAddr,\n             duration);\n         trackSendPacketToLastNodeInPipeline(duration);\n-        if (duration > datanodeSlowLogThresholdMs && LOG.isWarnEnabled()) {\n-          LOG.warn(\"Slow BlockReceiver write packet to mirror took \" + duration\n-              + \"ms (threshold=\" + datanodeSlowLogThresholdMs + \"ms), \"\n-              + \"downstream DNs=\" + Arrays.toString(downstreamDNs)\n-              + \", blockId=\" + replicaInfo.getBlockId()\n-              + \", seqno=\" + seqno);\n+        if (duration > datanodeSlowLogThresholdMs) {\n+          datanode.metrics.incrPacketSlowWriteToMirror();\n+          if (LOG.isWarnEnabled()) {\n+            LOG.warn(\"Slow BlockReceiver write packet to mirror took \" + duration\n+                + \"ms (threshold=\" + datanodeSlowLogThresholdMs + \"ms), \"\n+                + \"downstream DNs=\" + Arrays.toString(downstreamDNs)\n+                + \", blockId=\" + replicaInfo.getBlockId()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzczMA=="}, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ2MTc2MTM1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxNzo1Njo0OFrOIMyTrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwNzoyODozMFrOINnrdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3ODA2Mw==", "bodyText": "setInt", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r550278063", "createdAt": "2020-12-30T17:56:48Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "diffHunk": "@@ -161,6 +163,65 @@ public void testReceivePacketMetrics() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testReceivePacketSlowMetrics() throws Exception {\n+    Configuration conf = new HdfsConfiguration();\n+    final int interval = 1;\n+    conf.set(DFSConfigKeys.DFS_METRICS_PERCENTILES_INTERVALS_KEY, \"\" + interval);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTE1MjUwMQ==", "bodyText": "Done", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r551152501", "createdAt": "2021-01-04T07:28:30Z", "author": {"login": "fengnanli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "diffHunk": "@@ -161,6 +163,65 @@ public void testReceivePacketMetrics() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testReceivePacketSlowMetrics() throws Exception {\n+    Configuration conf = new HdfsConfiguration();\n+    final int interval = 1;\n+    conf.set(DFSConfigKeys.DFS_METRICS_PERCENTILES_INTERVALS_KEY, \"\" + interval);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3ODA2Mw=="}, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ2MTc2MjYyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxNzo1NzoyNVrOIMyUZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwNzoyODozNlrOINnrlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3ODI0Ng==", "bodyText": "Extract the sleeping answer and return for each?", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r550278246", "createdAt": "2020-12-30T17:57:25Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "diffHunk": "@@ -161,6 +163,65 @@ public void testReceivePacketMetrics() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testReceivePacketSlowMetrics() throws Exception {\n+    Configuration conf = new HdfsConfiguration();\n+    final int interval = 1;\n+    conf.set(DFSConfigKeys.DFS_METRICS_PERCENTILES_INTERVALS_KEY, \"\" + interval);\n+    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)\n+        .numDataNodes(3).build();\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final DataNodeFaultInjector injector =\n+          Mockito.mock(DataNodeFaultInjector.class);\n+      Mockito.doAnswer(new Answer() {\n+        @Override\n+        public Object answer(InvocationOnMock invocationOnMock)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTE1MjUzNQ==", "bodyText": "Done", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r551152535", "createdAt": "2021-01-04T07:28:36Z", "author": {"login": "fengnanli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "diffHunk": "@@ -161,6 +163,65 @@ public void testReceivePacketMetrics() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testReceivePacketSlowMetrics() throws Exception {\n+    Configuration conf = new HdfsConfiguration();\n+    final int interval = 1;\n+    conf.set(DFSConfigKeys.DFS_METRICS_PERCENTILES_INTERVALS_KEY, \"\" + interval);\n+    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)\n+        .numDataNodes(3).build();\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final DataNodeFaultInjector injector =\n+          Mockito.mock(DataNodeFaultInjector.class);\n+      Mockito.doAnswer(new Answer() {\n+        @Override\n+        public Object answer(InvocationOnMock invocationOnMock)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3ODI0Ng=="}, "originalCommit": {"oid": "1da0b9f849271744214d9474f6f0a514085dd36b"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ4MDA1MjY0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQxOTo1Nzo1MVrOIPUX2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQxOTo1Nzo1MVrOIPUX2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjkzMzMzNg==", "bodyText": "nit: name this to incrPacketsSlowWriteToOsCache?", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r552933336", "createdAt": "2021-01-06T19:57:51Z", "author": {"login": "sunchao"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.java", "diffHunk": "@@ -690,4 +695,20 @@ public void addCheckAndUpdateOp(long latency) {\n   public void addUpdateReplicaUnderRecoveryOp(long latency) {\n     updateReplicaUnderRecoveryOp.add(latency);\n   }\n+\n+  public void incrPacketsReceived() {\n+    packetsReceived.incr();\n+  }\n+\n+  public void incrPacketsSlowWriteToMirror() {\n+    packetsSlowWriteToMirror.incr();\n+  }\n+\n+  public void incrPacketsSlowWriteToDisk() {\n+    packetsSlowWriteToDisk.incr();\n+  }\n+\n+  public void incrPacketsSlowWriteOsCache() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05f04b1ca4ced0849b1fc0685077f88db2a47027"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ4MDA1MzM3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQxOTo1ODowNVrOIPUYQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQxOTo1ODowNVrOIPUYQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjkzMzQ0Mg==", "bodyText": "ditto", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r552933442", "createdAt": "2021-01-06T19:58:05Z", "author": {"login": "sunchao"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.java", "diffHunk": "@@ -183,6 +183,11 @@\n   @Metric private MutableRate checkAndUpdateOp;\n   @Metric private MutableRate updateReplicaUnderRecoveryOp;\n \n+  @Metric MutableCounterLong packetsReceived;\n+  @Metric MutableCounterLong packetsSlowWriteToMirror;\n+  @Metric MutableCounterLong packetsSlowWriteToDisk;\n+  @Metric MutableCounterLong packetsSlowWriteOsCache;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05f04b1ca4ced0849b1fc0685077f88db2a47027"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ4MTM0OTY1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNjoxNDoxMFrOIPgTgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNjoxNDoxMFrOIPgTgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEyODgzNA==", "bodyText": "I think this also needs update.", "url": "https://github.com/apache/hadoop/pull/2578#discussion_r553128834", "createdAt": "2021-01-07T06:14:10Z", "author": {"login": "sunchao"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java", "diffHunk": "@@ -161,6 +163,53 @@ public void testReceivePacketMetrics() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testReceivePacketSlowMetrics() throws Exception {\n+    Configuration conf = new HdfsConfiguration();\n+    final int interval = 1;\n+    conf.setInt(DFSConfigKeys.DFS_METRICS_PERCENTILES_INTERVALS_KEY, interval);\n+    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)\n+        .numDataNodes(3).build();\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final DataNodeFaultInjector injector =\n+          Mockito.mock(DataNodeFaultInjector.class);\n+      Answer answer = new Answer() {\n+        @Override\n+        public Object answer(InvocationOnMock invocationOnMock)\n+            throws Throwable {\n+          // make the op taking longer time\n+          Thread.sleep(1000);\n+          return null;\n+        }\n+      };\n+      Mockito.doAnswer(answer).when(injector).\n+          stopSendingPacketDownstream(Mockito.anyString());\n+      Mockito.doAnswer(answer).when(injector).delayWriteToOsCache();\n+      Mockito.doAnswer(answer).when(injector).delayWriteToDisk();\n+      DataNodeFaultInjector.set(injector);\n+      Path testFile = new Path(\"/testFlushNanosMetric.txt\");\n+      FSDataOutputStream fout = fs.create(testFile);\n+      fout.write(new byte[1]);\n+      fout.hsync();\n+      fout.close();\n+      List<DataNode> datanodes = cluster.getDataNodes();\n+      DataNode datanode = datanodes.get(0);\n+      MetricsRecordBuilder dnMetrics = getMetrics(datanode.getMetrics().name());\n+      assertTrue(\"More than 1 packet received\",\n+          getLongCounter(\"TotalPacketsReceived\", dnMetrics) > 1L);\n+      assertTrue(\"More than 1 slow packet to mirror\",\n+          getLongCounter(\"TotalPacketsSlowWriteToMirror\", dnMetrics) > 1L);\n+      assertCounter(\"TotalPacketsSlowWriteToDisk\", 1L, dnMetrics);\n+      assertCounter(\"TotalPacketsSlowWriteOsCache\", 0L, dnMetrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3be5d26cec4c93b5b47ef795ee320b38e5a9356d"}, "originalPosition": 52}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3109, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}