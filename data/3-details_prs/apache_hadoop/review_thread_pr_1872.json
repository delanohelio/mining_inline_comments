{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgyNjM4ODMw", "number": 1872, "reviewThreads": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwNzo1NzoyMFrODki8Lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQyMDozNjoyNVrODnPkXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5NjQ3NzkwOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwNzo1NzoyMFrOFw7YEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQyMDozNTo1OVrOF1IMug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODc4Nw==", "bodyText": "If expiresOnInSecs is supposed to be the field to rely on and has been returned -1, why not error out in else ?\nWhy is it that we are defaulting to value in expires_in which is not reliable ?", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386848787", "createdAt": "2020-03-03T07:57:20Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,29 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTQ3MDEzNQ==", "bodyText": "This seemed a safer approach. Also its not unreliable when you are retrieving from AAD service itself, it becomes unreliable for cache scenario like msi.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389470135", "createdAt": "2020-03-09T05:35:41Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,29 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODc4Nw=="}, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMjM2NQ==", "bodyText": "Though MSI team confirmed faulty expires_in it still is valid for other flows and MSI response will defenitly contain the expires_in field", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389902365", "createdAt": "2020-03-09T19:09:06Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,29 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODc4Nw=="}, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTI1MzE3OA==", "bodyText": "it'd be good to have some test JSONs here for real-world responses", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r391253178", "createdAt": "2020-03-11T20:35:59Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,29 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODc4Nw=="}, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5NjQ3ODcxOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwNzo1NzozOVrOFw7YjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwNzo1NzozOVrOFw7YjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODkwOQ==", "bodyText": "new line after if check block needed.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386848909", "createdAt": "2020-03-03T07:57:39Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,29 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();\n+        expiry = expiry + expiryPeriodInSecs\n+            * 1000L; // convert expiryPeriod to milliseconds and add\n+        token.setExpiry(new Date(expiry));\n+      }\n+      LOG.debug(\"AADToken: fetched token with expiry {}, expiresOn passed: {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5NjUyMTQ3OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwODoxNDoxOFrOFw7yKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwODoxNDoxOFrOFw7yKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1NTQ2Ng==", "bodyText": "Order the non-static imports in the order:\n\njava*\nany non org.apache imports\norg.apache imports", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386855466", "createdAt": "2020-03-03T08:14:18Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5NjUyNDkxOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwODoxNTozOVrOFw70Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwODoxNTozOVrOFw70Sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1NjAxMA==", "bodyText": "It seems there are javadoc compilers issues with description comments without a dot at end. Please add here and at places such comments are added.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386856010", "createdAt": "2020-03-03T08:15:39Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken;\n+import org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.Date;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.AuthConfigurations.DEFAULT_FS_AZURE_ACCOUNT_OAUTH_MSI_AUTHORITY;\n+import static org.apache.hadoop.fs.azurebfs.constants.AuthConfigurations.DEFAULT_FS_AZURE_ACCOUNT_OAUTH_MSI_ENDPOINT;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_CLIENT_ID;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_AUTHORITY;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_ENDPOINT;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_TENANT;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.Matchers.isEmptyOrNullString;\n+import static org.hamcrest.Matchers.isEmptyString;\n+import static org.junit.Assume.assumeThat;\n+\n+/**\n+ * Test MsiTokenProvider", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5NjUyNjc3OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwODoxNjoyMlrOFw71fA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwODoxNjoyMlrOFw71fA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1NjMxNg==", "bodyText": "Please refer to non-static import order mentioned in above comment.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386856316", "createdAt": "2020-03-03T08:16:22Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs.unittests;\n+\n+import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5NjU0OTc0OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QwODoyNToxMFrOFw8DXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QxNzoxNToyM1rOFxPB3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1OTg2OQ==", "bodyText": "With this mock the code which parses the response and sets the expiry from expires_on will not be hit ?", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386859869", "createdAt": "2020-03-03T08:25:10Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs.unittests;\n+\n+import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken;\n+import org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider;\n+import org.junit.Assert;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mockito;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import java.io.IOException;\n+import java.util.Date;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.hamcrest.core.AllOf.allOf;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Mockito.when;\n+import static org.powermock.api.mockito.PowerMockito.mockStatic;\n+import static org.powermock.reflect.Whitebox.getInternalState;\n+import static org.powermock.reflect.Whitebox.invokeMethod;\n+import static org.powermock.reflect.Whitebox.setInternalState;\n+\n+/**\n+ * Unit test for MsiTokenProvider\n+ */\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest(AzureADAuthenticator.class)\n+public class TestMsiTokenProvider {\n+\n+  private static final long ONE_HOUR = 3600 * 1000;\n+  private static final long TWO_HOUR = ONE_HOUR * 2;\n+\n+  @Test\n+  public void testMsiTokenProvider() throws Exception {\n+    String testToken = \"TEST_TOKEN1\";\n+    setMockAzureADAuthenticator(testToken,\n+        System.currentTimeMillis() + TWO_HOUR);\n+\n+    AccessTokenProvider msiTokenProvider = new MsiTokenProvider(\"\", \"\", \"\", \"\");\n+    long tokenFetchTime = getInternalState(msiTokenProvider, \"tokenFetchTime\");\n+    Assert.assertEquals(-1, tokenFetchTime);\n+\n+    long before = System.currentTimeMillis();\n+    AzureADToken token = msiTokenProvider.getToken();\n+    long after = System.currentTimeMillis();\n+    long newTokenFetchTime = getInternalState(msiTokenProvider,\n+        \"tokenFetchTime\");\n+    assertThat(newTokenFetchTime,\n+        is(allOf(greaterThan(before), lessThanOrEqualTo(after))));\n+    assertThat(token.getAccessToken(), is(equalTo(testToken)));\n+\n+    assertThat(invokeMethod(msiTokenProvider, \"isTokenAboutToExpire\"),\n+        is(false));\n+\n+    setInternalState(msiTokenProvider, \"tokenFetchTime\",\n+        System.currentTimeMillis() - ONE_HOUR);\n+    assertThat(invokeMethod(msiTokenProvider, \"isTokenAboutToExpire\"),\n+        is(true));\n+\n+    setInternalState(msiTokenProvider, \"tokenFetchTime\",\n+        System.currentTimeMillis() + 2 - ONE_HOUR);\n+    assertThat(invokeMethod(msiTokenProvider, \"isTokenAboutToExpire\"),\n+        is(false));\n+  }\n+\n+  private AzureADToken setMockAzureADAuthenticator(String tokenStr, long expiry)\n+      throws IOException {\n+    AzureADToken token = new AzureADToken();\n+    token.setAccessToken(tokenStr);\n+    token.setExpiry(new Date(expiry));\n+    mockStatic(AzureADAuthenticator.class);\n+    when(AzureADAuthenticator\n+        .getTokenFromMsi(Mockito.anyString(), Mockito.anyString(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzE3MDc4Mw==", "bodyText": "No. Planning to do that as a separate task.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387170783", "createdAt": "2020-03-03T17:15:23Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs.unittests;\n+\n+import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken;\n+import org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider;\n+import org.junit.Assert;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mockito;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import java.io.IOException;\n+import java.util.Date;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.hamcrest.core.AllOf.allOf;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Mockito.when;\n+import static org.powermock.api.mockito.PowerMockito.mockStatic;\n+import static org.powermock.reflect.Whitebox.getInternalState;\n+import static org.powermock.reflect.Whitebox.invokeMethod;\n+import static org.powermock.reflect.Whitebox.setInternalState;\n+\n+/**\n+ * Unit test for MsiTokenProvider\n+ */\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest(AzureADAuthenticator.class)\n+public class TestMsiTokenProvider {\n+\n+  private static final long ONE_HOUR = 3600 * 1000;\n+  private static final long TWO_HOUR = ONE_HOUR * 2;\n+\n+  @Test\n+  public void testMsiTokenProvider() throws Exception {\n+    String testToken = \"TEST_TOKEN1\";\n+    setMockAzureADAuthenticator(testToken,\n+        System.currentTimeMillis() + TWO_HOUR);\n+\n+    AccessTokenProvider msiTokenProvider = new MsiTokenProvider(\"\", \"\", \"\", \"\");\n+    long tokenFetchTime = getInternalState(msiTokenProvider, \"tokenFetchTime\");\n+    Assert.assertEquals(-1, tokenFetchTime);\n+\n+    long before = System.currentTimeMillis();\n+    AzureADToken token = msiTokenProvider.getToken();\n+    long after = System.currentTimeMillis();\n+    long newTokenFetchTime = getInternalState(msiTokenProvider,\n+        \"tokenFetchTime\");\n+    assertThat(newTokenFetchTime,\n+        is(allOf(greaterThan(before), lessThanOrEqualTo(after))));\n+    assertThat(token.getAccessToken(), is(equalTo(testToken)));\n+\n+    assertThat(invokeMethod(msiTokenProvider, \"isTokenAboutToExpire\"),\n+        is(false));\n+\n+    setInternalState(msiTokenProvider, \"tokenFetchTime\",\n+        System.currentTimeMillis() - ONE_HOUR);\n+    assertThat(invokeMethod(msiTokenProvider, \"isTokenAboutToExpire\"),\n+        is(true));\n+\n+    setInternalState(msiTokenProvider, \"tokenFetchTime\",\n+        System.currentTimeMillis() + 2 - ONE_HOUR);\n+    assertThat(invokeMethod(msiTokenProvider, \"isTokenAboutToExpire\"),\n+        is(false));\n+  }\n+\n+  private AzureADToken setMockAzureADAuthenticator(String tokenStr, long expiry)\n+      throws IOException {\n+    AzureADToken token = new AzureADToken();\n+    token.setAccessToken(tokenStr);\n+    token.setExpiry(new Date(expiry));\n+    mockStatic(AzureADAuthenticator.class);\n+    when(AzureADAuthenticator\n+        .getTokenFromMsi(Mockito.anyString(), Mockito.anyString(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1OTg2OQ=="}, "originalCommit": {"oid": "d3d12d9a844f6af2015b295789219460dff6a726"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5OTk4NjI4OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMToyMDoyOFrOFxc4iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMToyMDoyOFrOFxc4iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM5Nzc2OA==", "bodyText": "the version need to go to hadoop-project pom file", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387397768", "createdAt": "2020-03-04T01:20:28Z", "author": {"login": "DadanielZ"}, "path": "hadoop-tools/hadoop-azure/pom.xml", "diffHunk": "@@ -45,6 +45,7 @@\n     <fs.azure.scale.test.timeout>7200</fs.azure.scale.test.timeout>\n     <fs.azure.scale.test.list.performance.threads>10</fs.azure.scale.test.list.performance.threads>\n     <fs.azure.scale.test.list.performance.files>1000</fs.azure.scale.test.list.performance.files>\n+    <powermock.version>2.0.4</powermock.version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5OTk5ODUxOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMToyNjowMVrOFxc_6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxOToxMzowNlrOFz13-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM5OTY1OA==", "bodyText": "I suppose 0 is not a valid value for expiresOnInSecs, do we need to add value check here?", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387399658", "createdAt": "2020-03-04T01:26:01Z", "author": {"login": "DadanielZ"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwNDM3Nw==", "bodyText": "Changed to expiresOnInSecs > 0, good to have check, for a safer side", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389904377", "createdAt": "2020-03-09T19:13:06Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM5OTY1OA=="}, "originalCommit": {"oid": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMDA1MTQzOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMTo1Njo0NFrOFxdgEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMTo1Njo0NFrOFxdgEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwNzg4OQ==", "bodyText": "need to update this @return documentation too.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387407889", "createdAt": "2020-03-04T01:56:44Z", "author": {"login": "DadanielZ"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java", "diffHunk": "@@ -51,6 +55,35 @@ protected AzureADToken refreshToken() throws IOException {\n     LOG.debug(\"AADToken: refreshing token from MSI\");\n     AzureADToken token = AzureADAuthenticator\n         .getTokenFromMsi(authEndpoint, tenantGuid, clientId, authority, false);\n+    tokenFetchTime = System.currentTimeMillis();\n     return token;\n   }\n+\n+  /**\n+   * Checks if the token is about to expire as per base expiry logic.\n+   * Otherwise try to expire every 1 hour\n+   *\n+   * @return true if the token is expiring in next 5 minutes", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMjg2OTAwOnYy", "diffSide": "RIGHT", "path": "hadoop-project/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODozMDo1OFrOFx4tYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODozMDo1OFrOFx4tYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg1MzY2NQ==", "bodyText": "define a variable for the version", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387853665", "createdAt": "2020-03-04T18:30:58Z", "author": {"login": "DadanielZ"}, "path": "hadoop-project/pom.xml", "diffHunk": "@@ -1680,6 +1680,20 @@\n         <artifactId>jna</artifactId>\n         <version>${jna.version}</version>\n       </dependency>\n+\n+      <dependency>\n+        <groupId>org.powermock</groupId>\n+        <artifactId>powermock-api-mockito2</artifactId>\n+        <scope>test</scope>\n+        <version>2.0.4</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b70be69cc406ead58202d5f9d311c86b68c6a5"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMjg2OTQ0OnYy", "diffSide": "RIGHT", "path": "hadoop-project/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODozMTowOVrOFx4tsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODozMTowOVrOFx4tsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg1Mzc0Nw==", "bodyText": "same here", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387853747", "createdAt": "2020-03-04T18:31:09Z", "author": {"login": "DadanielZ"}, "path": "hadoop-project/pom.xml", "diffHunk": "@@ -1680,6 +1680,20 @@\n         <artifactId>jna</artifactId>\n         <version>${jna.version}</version>\n       </dependency>\n+\n+      <dependency>\n+        <groupId>org.powermock</groupId>\n+        <artifactId>powermock-api-mockito2</artifactId>\n+        <scope>test</scope>\n+        <version>2.0.4</version>\n+      </dependency>\n+      <dependency>\n+        <groupId>org.powermock</groupId>\n+        <artifactId>powermock-module-junit4</artifactId>\n+        <scope>test</scope>\n+        <version>2.0.4</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b70be69cc406ead58202d5f9d311c86b68c6a5"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMjkwMzY0OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODo0MToyOFrOFx5DOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODo0MToyOFrOFx5DOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg1OTI1OA==", "bodyText": "remove it if not being used", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387859258", "createdAt": "2020-03-04T18:41:28Z", "author": {"login": "DadanielZ"}, "path": "hadoop-tools/hadoop-azure/pom.xml", "diffHunk": "@@ -45,7 +45,7 @@\n     <fs.azure.scale.test.timeout>7200</fs.azure.scale.test.timeout>\n     <fs.azure.scale.test.list.performance.threads>10</fs.azure.scale.test.list.performance.threads>\n     <fs.azure.scale.test.list.performance.files>1000</fs.azure.scale.test.list.performance.files>\n-    <powermock.version>2.0.4</powermock.version>\n+    <!--<powermock.version>2.0.4</powermock.version>-->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b70be69cc406ead58202d5f9d311c86b68c6a5"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMjkwNTM0OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODo0MTo1MlrOFx5ELg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODo0MTo1MlrOFx5ELg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg1OTUwMg==", "bodyText": "same here", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387859502", "createdAt": "2020-03-04T18:41:52Z", "author": {"login": "DadanielZ"}, "path": "hadoop-tools/hadoop-azure/pom.xml", "diffHunk": "@@ -290,13 +290,13 @@\n       <groupId>org.powermock</groupId>\n       <artifactId>powermock-api-mockito2</artifactId>\n       <scope>test</scope>\n-      <version>${powermock.version}</version>\n+      <!--<version>${powermock.version}</version>-->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b70be69cc406ead58202d5f9d311c86b68c6a5"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMjkwNjQ0OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODo0MjoxNFrOFx5E6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODo0MjoxNFrOFx5E6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg1OTY4OA==", "bodyText": "same here", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387859688", "createdAt": "2020-03-04T18:42:14Z", "author": {"login": "DadanielZ"}, "path": "hadoop-tools/hadoop-azure/pom.xml", "diffHunk": "@@ -290,13 +290,13 @@\n       <groupId>org.powermock</groupId>\n       <artifactId>powermock-api-mockito2</artifactId>\n       <scope>test</scope>\n-      <version>${powermock.version}</version>\n+      <!--<version>${powermock.version}</version>-->\n     </dependency>\n     <dependency>\n       <groupId>org.powermock</groupId>\n       <artifactId>powermock-module-junit4</artifactId>\n       <scope>test</scope>\n-      <version>${powermock.version}</version>\n+      <!--<version>${powermock.version}</version>-->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97b70be69cc406ead58202d5f9d311c86b68c6a5"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwNDUyOTY0OnYy", "diffSide": "RIGHT", "path": "hadoop-project/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQwNzoyMzoxOVrOFyIs-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOFQxNzo0Nzo0NlrOFzWiAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODExNTcwNg==", "bodyText": "Hey @bilaharith  @steveloughran ,  I'm still not sure about this change. Simply updating the existing \"powermock.version\" will cause build issues for some other projects, so new version variable \"powermock-api.version\" is introduced.\nSome other projects already override \"powermock.version\" for powermock-api-mockito2 , such as Hadoop-Yarn here.\nMaybe we can override its version in hadoop-azure's pom file too, instead of introducing the new version variable?\nOther changes look good to me.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r388115706", "createdAt": "2020-03-05T07:23:19Z", "author": {"login": "DadanielZ"}, "path": "hadoop-project/pom.xml", "diffHunk": "@@ -204,6 +204,7 @@\n     <assertj.version>3.12.2</assertj.version>\n     <jline.version>3.9.0</jline.version>\n     <powermock.version>1.5.6</powermock.version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "39496686cb9f8d75c6d42186d7b12be6bf855742"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTM5MDg0OA==", "bodyText": "Removing powermock for now, will raise another PR for powermock upgrade and then one for the mocktest", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389390848", "createdAt": "2020-03-08T17:47:46Z", "author": {"login": "bilaharith"}, "path": "hadoop-project/pom.xml", "diffHunk": "@@ -204,6 +204,7 @@\n     <assertj.version>3.12.2</assertj.version>\n     <jline.version>3.9.0</jline.version>\n     <powermock.version>1.5.6</powermock.version>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODExNTcwNg=="}, "originalCommit": {"oid": "39496686cb9f8d75c6d42186d7b12be6bf855742"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNDEzODg5OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMDoyNjozOVrOFzhsog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxOTowNzozOVrOFz1tSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3Mzc5NA==", "bodyText": "I'd like some reporting of parse failures here, especially which field isn't parsing.\nAlso, make sure that the code is validating content type before JSON parsing. We've done that for OAuth, needs to be done here so that a bad URL or proxy returns HTML and everything fails for no obvious reason", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389573794", "createdAt": "2020-03-09T10:26:39Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMTI0Mg==", "bodyText": "Added log to indicate based on which field exactly the expiry is calculated", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389901242", "createdAt": "2020-03-09T19:06:51Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3Mzc5NA=="}, "originalCommit": {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMTY0Mw==", "bodyText": "content type check is done at the method from where this method is called.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389901643", "createdAt": "2020-03-09T19:07:39Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3Mzc5NA=="}, "originalCommit": {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNDE0MDU2OnYy", "diffSide": "RIGHT", "path": "hadoop-project/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMDoyNzoxNFrOFzhtxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMDoyNzoxNFrOFzhtxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NDA4Nw==", "bodyText": "this is going to be a separate PR, isn't it?", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389574087", "createdAt": "2020-03-09T10:27:14Z", "author": {"login": "steveloughran"}, "path": "hadoop-project/pom.xml", "diffHunk": "@@ -1680,6 +1680,20 @@\n         <artifactId>jna</artifactId>\n         <version>${jna.version}</version>\n       </dependency>\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNDE0NjE4OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMDoyODo0OFrOFzhxGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxOToxMTozOFrOFz11SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NDkzNg==", "bodyText": "put expiryPeriod and * 1000 on same line. Also, feel free to use the new java time classes which are complex but powerful once you start to use them", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389574936", "createdAt": "2020-03-09T10:28:48Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > 0) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();\n+        expiry = expiry + expiryPeriodInSecs\n+            * 1000L; // convert expiryPeriod to milliseconds and add", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMzY4OA==", "bodyText": "Not using Java 8 features as we keep a backport to an older Java version branch.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389903688", "createdAt": "2020-03-09T19:11:38Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > 0) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();\n+        expiry = expiry + expiryPeriodInSecs\n+            * 1000L; // convert expiryPeriod to milliseconds and add", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NDkzNg=="}, "originalCommit": {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNDE0ODM4OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMDoyOTozM1rOFzhyew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMDoyOTozM1rOFzhyew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NTI5MQ==", "bodyText": "or if a token has never been fetched", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389575291", "createdAt": "2020-03-09T10:29:33Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java", "diffHunk": "@@ -51,6 +55,35 @@ protected AzureADToken refreshToken() throws IOException {\n     LOG.debug(\"AADToken: refreshing token from MSI\");\n     AzureADToken token = AzureADAuthenticator\n         .getTokenFromMsi(authEndpoint, tenantGuid, clientId, authority, false);\n+    tokenFetchTime = System.currentTimeMillis();\n     return token;\n   }\n+\n+  /**\n+   * Checks if the token is about to expire as per base expiry logic.\n+   * Otherwise try to expire every 1 hour\n+   *\n+   * @return true if the token is expiring in next 1 hour", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNDE0OTk3OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxMDozMDowMlrOFzhziw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxOTowOToyMVrOFz1wnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NTU2Mw==", "bodyText": "check import ordering. you know what I'll complain about", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389575563", "createdAt": "2020-03-09T10:30:02Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.commons.lang3.StringUtils;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMjQ5NQ==", "bodyText": "Done :)", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389902495", "createdAt": "2020-03-09T19:09:21Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.commons.lang3.StringUtils;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NTU2Mw=="}, "originalCommit": {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNzM3MDAxOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwMzo1NjowOFrOF0Awyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwMzo1NjowOFrOF0Awyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA4Mjc2Mw==", "bodyText": "Extra new line.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r390082763", "createdAt": "2020-03-10T03:56:08Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f794d651df01651941b8e56c005579b988fa0a4"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNzM3MDYxOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwMzo1NjozNVrOF0AxPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwMzo1NjozNVrOF0AxPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA4Mjg3Ng==", "bodyText": "import ordering still not as expected.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r390082876", "createdAt": "2020-03-10T03:56:35Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+\n+import java.io.IOException;\n+import java.util.Date;\n+\n+import org.junit.Test;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken;\n+import org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider;\n+\n+import static org.junit.Assume.assumeThat;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f794d651df01651941b8e56c005579b988fa0a4"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyMjkyNTkwOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMzoxMjoyMVrOF02Onw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMzoxMjoyMVrOF02Onw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDk1ODc1MQ==", "bodyText": "Not something needing changing in this PR, but this should really be Map<> and the code to move to a HashMap; all of Hashtable's methods are synchronized and it underperforms.", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r390958751", "createdAt": "2020-03-11T13:12:21Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -258,8 +258,13 @@ public UnexpectedResponseException(final int httpErrorCode,\n   }\n \n   private static AzureADToken getTokenCall(String authEndpoint, String body,\n-                                           Hashtable<String, String> headers, String httpMethod)\n-          throws IOException {\n+      Hashtable<String, String> headers, String httpMethod) throws IOException {\n+    return getTokenCall(authEndpoint, body, headers, httpMethod, false);\n+  }\n+\n+  private static AzureADToken getTokenCall(String authEndpoint, String body,\n+      Hashtable<String, String> headers, String httpMethod, boolean isMsi)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "982dad0c57f84b40e5c4b1c761f4c4e5a5f4db43"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNDc2MTI1OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQyMDozNjoyNVrOF1INlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQyMDozNjoyNVrOF1INlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTI1MzM5Nw==", "bodyText": "better: 3600_1000", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r391253397", "createdAt": "2020-03-11T20:36:25Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java", "diffHunk": "@@ -36,6 +36,10 @@\n \n   private final String clientId;\n \n+  private long tokenFetchTime = -1;\n+\n+  private static final long ONE_HOUR = 3600 * 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "982dad0c57f84b40e5c4b1c761f4c4e5a5f4db43"}, "originalPosition": 6}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3602, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}