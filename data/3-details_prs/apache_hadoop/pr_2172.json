{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU3MTMxODQ4", "number": 2172, "title": "HDFS-15483. Ordered snapshot deletion: Disallow rename between two snapshottable directories.", "bodyText": "please check https://issues.apache.org/jira/browse/HDFS-15483", "createdAt": "2020-07-27T12:29:50Z", "url": "https://github.com/apache/hadoop/pull/2172", "merged": true, "mergeCommit": {"oid": "092bfe7c8e9736efb0dbe3d39af77c4bfffa6ef2"}, "closed": true, "closedAt": "2020-08-17T07:26:14Z", "author": {"login": "bshashikant"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc5lAgEAFqTQ1NzE4NjU3Ng==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc-2ViTgH2gAyNDU3MTMxODQ4Ojg0NDRmNWRlYWMxMWI1ODgwYmY1ZDczYzVlOWY1ZjcyMDUxZTQ4ZjA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MTg2NTc2", "url": "https://github.com/apache/hadoop/pull/2172#pullrequestreview-457186576", "createdAt": "2020-07-29T04:30:54Z", "commit": {"oid": "da5c24a1523fa177e920a2bf8f1232a466d48f34"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwNDozMDo1NFrOG4oKLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwNjoyNToxOVrOG4qQ1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAzMTQwNA==", "bodyText": "There are 2 callers of      fsd.ezManager.checkMoveValidity(srcIIP, dstIIP);", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r462031404", "createdAt": "2020-07-29T04:30:54Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java", "diffHunk": "@@ -193,7 +194,7 @@ static INodesInPath unprotectedRenameTo(FSDirectory fsd,\n     }\n \n     validateNestSnapshot(fsd, src, dstParent.asDirectory(), snapshottableDirs);\n-\n+    FSDirSnapshotOp.checkUnderSameSnapshottableRoot(fsd, srcIIP, dstIIP);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da5c24a1523fa177e920a2bf8f1232a466d48f34"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAzMTU2NQ==", "bodyText": "FSDirSnapshotOp.checkUnderSameSnapshottableRoot(fsd, srcIIP, dstIIP); lets add snapshot rename check at the same places.", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r462031565", "createdAt": "2020-07-29T04:31:35Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java", "diffHunk": "@@ -193,7 +194,7 @@ static INodesInPath unprotectedRenameTo(FSDirectory fsd,\n     }\n \n     validateNestSnapshot(fsd, src, dstParent.asDirectory(), snapshottableDirs);\n-\n+    FSDirSnapshotOp.checkUnderSameSnapshottableRoot(fsd, srcIIP, dstIIP);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAzMTQwNA=="}, "originalCommit": {"oid": "da5c24a1523fa177e920a2bf8f1232a466d48f34"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAzMjg3Mw==", "bodyText": "we can replace snapshotManager.getSnapshottableAncestorDir(srcIIP))  with src here.", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r462032873", "createdAt": "2020-07-29T04:36:46Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java", "diffHunk": "@@ -341,4 +341,24 @@ static void checkSnapshot(FSDirectory fsd, INodesInPath iip,\n       checkSnapshot(iip.getLastINode(), snapshottableDirs);\n     }\n   }\n+\n+  static void checkUnderSameSnapshottableRoot(FSDirectory fsd,\n+      INodesInPath srcIIP, INodesInPath dstIIP) throws IOException {\n+    // Ensure rename out of a snapshottable root is not permitted if ordered\n+    // snapshot deletion feature is enabled\n+    if (fsd.isSnapshotDeletionOrdered()) {\n+      SnapshotManager snapshotManager = fsd.getFSNamesystem().\n+          getSnapshotManager();\n+      String errMsg = \"Source \" + srcIIP.getPath() +\n+          \" and dest \" + dstIIP.getPath() + \" are not under \" +\n+          \"the same snapshot root.\";\n+      INodeDirectory src = snapshotManager.\n+          getSnapshottableAncestorDir(srcIIP);\n+      INodeDirectory dst = snapshotManager.getSnapshottableAncestorDir(dstIIP);\n+      if (!(dstIIP.isDescendant(snapshotManager.\n+          getSnapshottableAncestorDir(srcIIP)))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da5c24a1523fa177e920a2bf8f1232a466d48f34"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA2NTQyNw==", "bodyText": "Add Assert.equals or Assert true here ?", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r462065427", "createdAt": "2020-07-29T06:24:25Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestRenameWithOrderedSnapshotDeletion.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.server.namenode;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdfs.DistributedFileSystem;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+import org.apache.hadoop.hdfs.DFSTestUtil;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.\n+    DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED;\n+\n+/**\n+ * Test Rename with ordered snapshot deletion.\n+ */\n+public class TestRenameWithOrderedSnapshotDeletion {\n+  private final Path snapshottableDir\n+      = new Path(\"/\" + getClass().getSimpleName());\n+  private DistributedFileSystem hdfs;\n+  private MiniDFSCluster cluster;\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    final Configuration conf = new Configuration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED, true);\n+\n+    cluster = new MiniDFSCluster.Builder(conf).numDataNodes(0).build();\n+    cluster.waitActive();\n+    hdfs = cluster.getFileSystem();\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    if (cluster != null) {\n+      cluster.shutdown();\n+      cluster = null;\n+    }\n+  }\n+\n+  @Test(timeout = 60000)\n+  public void testRename() throws Exception {\n+    final Path dir1 = new Path(\"/dir1\");\n+    final Path dir2 = new Path(\"/dir2\");\n+    final Path sub0 = new Path(snapshottableDir, \"sub0\");\n+    hdfs.mkdirs(sub0);\n+    final Path file1 = new Path(dir1, \"file1\");\n+    final Path file2 = new Path(sub0, \"file2\");\n+    hdfs.mkdirs(snapshottableDir);\n+    hdfs.mkdirs(dir1);\n+    hdfs.mkdirs(dir2);\n+    hdfs.mkdirs(sub0);\n+    DFSTestUtil.createFile(hdfs, file1, 0, (short) 1, 0);\n+    DFSTestUtil.createFile(hdfs, file2, 0, (short) 1, 0);\n+    hdfs.allowSnapshot(snapshottableDir);\n+    // rename from non snapshottable dir to snapshottable dir should fail\n+    validateRename(file1, sub0);\n+    hdfs.createSnapshot(snapshottableDir, \"s0\");\n+    validateRename(file1, sub0);\n+    // rename across non snapshottable dirs should work\n+    hdfs.rename(file1, dir2);\n+    // rename beyond snapshottable root should fail\n+    validateRename(file2, dir1);\n+    // rename within snapshottable root should work\n+    hdfs.rename(file2, snapshottableDir);\n+  }\n+\n+  private void validateRename(Path src, Path dest) {\n+    try {\n+      hdfs.rename(src, dest);\n+    } catch (IOException ioe) {\n+      ioe.getMessage().contains(\"are not under the same snapshot root.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da5c24a1523fa177e920a2bf8f1232a466d48f34"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA2NTg3Ng==", "bodyText": "Lets also add some directory level renames here", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r462065876", "createdAt": "2020-07-29T06:25:19Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestRenameWithOrderedSnapshotDeletion.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.server.namenode;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdfs.DistributedFileSystem;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+import org.apache.hadoop.hdfs.DFSTestUtil;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.\n+    DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED;\n+\n+/**\n+ * Test Rename with ordered snapshot deletion.\n+ */\n+public class TestRenameWithOrderedSnapshotDeletion {\n+  private final Path snapshottableDir\n+      = new Path(\"/\" + getClass().getSimpleName());\n+  private DistributedFileSystem hdfs;\n+  private MiniDFSCluster cluster;\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    final Configuration conf = new Configuration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED, true);\n+\n+    cluster = new MiniDFSCluster.Builder(conf).numDataNodes(0).build();\n+    cluster.waitActive();\n+    hdfs = cluster.getFileSystem();\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    if (cluster != null) {\n+      cluster.shutdown();\n+      cluster = null;\n+    }\n+  }\n+\n+  @Test(timeout = 60000)\n+  public void testRename() throws Exception {\n+    final Path dir1 = new Path(\"/dir1\");\n+    final Path dir2 = new Path(\"/dir2\");\n+    final Path sub0 = new Path(snapshottableDir, \"sub0\");\n+    hdfs.mkdirs(sub0);\n+    final Path file1 = new Path(dir1, \"file1\");\n+    final Path file2 = new Path(sub0, \"file2\");\n+    hdfs.mkdirs(snapshottableDir);\n+    hdfs.mkdirs(dir1);\n+    hdfs.mkdirs(dir2);\n+    hdfs.mkdirs(sub0);\n+    DFSTestUtil.createFile(hdfs, file1, 0, (short) 1, 0);\n+    DFSTestUtil.createFile(hdfs, file2, 0, (short) 1, 0);\n+    hdfs.allowSnapshot(snapshottableDir);\n+    // rename from non snapshottable dir to snapshottable dir should fail\n+    validateRename(file1, sub0);\n+    hdfs.createSnapshot(snapshottableDir, \"s0\");\n+    validateRename(file1, sub0);\n+    // rename across non snapshottable dirs should work\n+    hdfs.rename(file1, dir2);\n+    // rename beyond snapshottable root should fail\n+    validateRename(file2, dir1);\n+    // rename within snapshottable root should work\n+    hdfs.rename(file2, snapshottableDir);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da5c24a1523fa177e920a2bf8f1232a466d48f34"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3Mzk5ODMz", "url": "https://github.com/apache/hadoop/pull/2172#pullrequestreview-457399833", "createdAt": "2020-07-29T10:37:33Z", "commit": {"oid": "6058607d5603fc3c9a37b18d21d2367db3f8788f"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMDozNzozM1rOG4ytGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMDozNzozM1rOG4ytGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIwNDE4Nw==", "bodyText": "Sorry I wasn't able to notice this earlier.", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r462204187", "createdAt": "2020-07-29T10:37:33Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java", "diffHunk": "@@ -193,7 +194,7 @@ static INodesInPath unprotectedRenameTo(FSDirectory fsd,\n     }\n \n     validateNestSnapshot(fsd, src, dstParent.asDirectory(), snapshottableDirs);\n-\n+    FSDirSnapshotOp.checkUnderSameSnapshottableRoot(fsd, srcIIP, dstIIP);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAzMTQwNA=="}, "originalCommit": {"oid": "da5c24a1523fa177e920a2bf8f1232a466d48f34"}, "originalPosition": 13}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e9d96a153ca8939c37ec3385329a7d7dd7e6579", "author": {"user": {"login": "bshashikant", "name": null}}, "url": "https://github.com/apache/hadoop/commit/4e9d96a153ca8939c37ec3385329a7d7dd7e6579", "committedDate": "2020-08-12T05:44:20Z", "message": "HDFS-15483. Ordered snapshot deletion: Disallow rename between two snapshottable directories."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d5c151b684d2ed78d21fb0ce9a21cff62882d3b", "author": {"user": {"login": "bshashikant", "name": null}}, "url": "https://github.com/apache/hadoop/commit/6d5c151b684d2ed78d21fb0ce9a21cff62882d3b", "committedDate": "2020-08-12T05:44:20Z", "message": "Addressed review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "70f6603fe0cc4a6081622dee40ca50fa4d7f0a48", "author": {"user": {"login": "bshashikant", "name": null}}, "url": "https://github.com/apache/hadoop/commit/70f6603fe0cc4a6081622dee40ca50fa4d7f0a48", "committedDate": "2020-08-12T06:21:47Z", "message": "Rebased to latest trunk and added snapshotTrashRoot config check."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6058607d5603fc3c9a37b18d21d2367db3f8788f", "author": {"user": {"login": "bshashikant", "name": null}}, "url": "https://github.com/apache/hadoop/commit/6058607d5603fc3c9a37b18d21d2367db3f8788f", "committedDate": "2020-07-29T07:28:04Z", "message": "Addressed review comments."}, "afterCommit": {"oid": "70f6603fe0cc4a6081622dee40ca50fa4d7f0a48", "author": {"user": {"login": "bshashikant", "name": null}}, "url": "https://github.com/apache/hadoop/commit/70f6603fe0cc4a6081622dee40ca50fa4d7f0a48", "committedDate": "2020-08-12T06:21:47Z", "message": "Rebased to latest trunk and added snapshotTrashRoot config check."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3MDU1OTg4", "url": "https://github.com/apache/hadoop/pull/2172#pullrequestreview-467055988", "createdAt": "2020-08-13T19:11:01Z", "commit": {"oid": "70f6603fe0cc4a6081622dee40ca50fa4d7f0a48"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxOToxMTowMVrOHAZ4Ww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxOToxNzowNVrOHAaGoQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE4NjA3NQ==", "bodyText": "This check should be moved to right before the for-loop below (line 389).", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r470186075", "createdAt": "2020-08-13T19:11:01Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java", "diffHunk": "@@ -363,23 +363,38 @@ void assertFirstSnapshot(INodeDirectory dir,\n    * @param iip INodesInPath for the directory to get snapshot root.\n    * @return the snapshot root INodeDirectory\n    */\n+  public INodeDirectory checkAndGetSnapshottableAncestorDir(\n+      final INodesInPath iip) throws IOException {\n+    final INodeDirectory dir = getSnapshottableAncestorDir(iip);\n+    if (dir == null) {\n+      throw new SnapshotException(\"Directory is neither snapshottable nor\" +\n+          \" under a snap root!\");\n+    }\n+    return dir;\n+  }\n+\n   public INodeDirectory getSnapshottableAncestorDir(final INodesInPath iip)\n       throws IOException {\n     final String path = iip.getPath();\n-    final INodeDirectory dir = INodeDirectory.valueOf(iip.getLastINode(), path);\n-    if (dir.isSnapshottable()) {\n-      return dir;\n+    final INode inode = iip.getLastINode();\n+    final INodeDirectory dir;\n+    if (inode instanceof INodeDirectory) {\n+      dir = INodeDirectory.valueOf(inode, path);\n+      if (dir.isSnapshottable()) {\n+        return dir;\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70f6603fe0cc4a6081622dee40ca50fa4d7f0a48"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE4Njc0Nw==", "bodyText": "This is only used in FSDirRenameOp.  Let's move to there?", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r470186747", "createdAt": "2020-08-13T19:12:14Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java", "diffHunk": "@@ -358,4 +358,23 @@ static void checkSnapshot(FSDirectory fsd, INodesInPath iip,\n       checkSnapshot(iip.getLastINode(), snapshottableDirs);\n     }\n   }\n+\n+  static void checkUnderSameSnapshottableRoot(FSDirectory fsd,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70f6603fe0cc4a6081622dee40ca50fa4d7f0a48"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE4OTY1OA==", "bodyText": "The errMsg should be constructed right before \"throw new SnapshotException(errMsg);\"", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r470189658", "createdAt": "2020-08-13T19:16:55Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java", "diffHunk": "@@ -358,4 +358,23 @@ static void checkSnapshot(FSDirectory fsd, INodesInPath iip,\n       checkSnapshot(iip.getLastINode(), snapshottableDirs);\n     }\n   }\n+\n+  static void checkUnderSameSnapshottableRoot(FSDirectory fsd,\n+      INodesInPath srcIIP, INodesInPath dstIIP) throws IOException {\n+    // Ensure rename out of a snapshottable root is not permitted if ordered\n+    // snapshot deletion feature is enabled\n+    SnapshotManager snapshotManager = fsd.getFSNamesystem().\n+        getSnapshotManager();\n+    if (snapshotManager.isSnapshotDeletionOrdered() && fsd.getFSNamesystem()\n+        .isSnapshotTrashRootEnabled()) {\n+      String errMsg = \"Source \" + srcIIP.getPath() +\n+          \" and dest \" + dstIIP.getPath() + \" are not under \" +\n+          \"the same snapshot root.\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70f6603fe0cc4a6081622dee40ca50fa4d7f0a48"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE4OTcyOQ==", "bodyText": "src can be null.  We should add a test for this case.", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r470189729", "createdAt": "2020-08-13T19:17:05Z", "author": {"login": "szetszwo"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java", "diffHunk": "@@ -358,4 +358,23 @@ static void checkSnapshot(FSDirectory fsd, INodesInPath iip,\n       checkSnapshot(iip.getLastINode(), snapshottableDirs);\n     }\n   }\n+\n+  static void checkUnderSameSnapshottableRoot(FSDirectory fsd,\n+      INodesInPath srcIIP, INodesInPath dstIIP) throws IOException {\n+    // Ensure rename out of a snapshottable root is not permitted if ordered\n+    // snapshot deletion feature is enabled\n+    SnapshotManager snapshotManager = fsd.getFSNamesystem().\n+        getSnapshotManager();\n+    if (snapshotManager.isSnapshotDeletionOrdered() && fsd.getFSNamesystem()\n+        .isSnapshotTrashRootEnabled()) {\n+      String errMsg = \"Source \" + srcIIP.getPath() +\n+          \" and dest \" + dstIIP.getPath() + \" are not under \" +\n+          \"the same snapshot root.\";\n+      INodeDirectory src = snapshotManager.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70f6603fe0cc4a6081622dee40ca50fa4d7f0a48"}, "originalPosition": 16}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "279e772f2736a6beac1ef034bfaa4e6dbb329855", "author": {"user": {"login": "bshashikant", "name": null}}, "url": "https://github.com/apache/hadoop/commit/279e772f2736a6beac1ef034bfaa4e6dbb329855", "committedDate": "2020-08-14T05:47:32Z", "message": "Addressed review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "edee22e378985607bcc813b388f1c80f18b996a9", "author": {"user": {"login": "bshashikant", "name": null}}, "url": "https://github.com/apache/hadoop/commit/edee22e378985607bcc813b388f1c80f18b996a9", "committedDate": "2020-08-14T05:50:23Z", "message": "Removede empty line added in SnapshotManager.Java."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NTE5NjIy", "url": "https://github.com/apache/hadoop/pull/2172#pullrequestreview-467519622", "createdAt": "2020-08-14T12:00:03Z", "commit": {"oid": "edee22e378985607bcc813b388f1c80f18b996a9"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NTk2Njgy", "url": "https://github.com/apache/hadoop/pull/2172#pullrequestreview-467596682", "createdAt": "2020-08-14T13:58:29Z", "commit": {"oid": "edee22e378985607bcc813b388f1c80f18b996a9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxMzo1ODoyOVrOHA1nDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxMzo1ODoyOVrOHA1nDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDY0MDM5OQ==", "bodyText": "can we use equals here ? as for comparing inodes we can use equals", "url": "https://github.com/apache/hadoop/pull/2172#discussion_r470640399", "createdAt": "2020-08-14T13:58:29Z", "author": {"login": "hemanthboyina"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java", "diffHunk": "@@ -821,6 +823,29 @@ void updateQuotasInSourceTree(BlockStoragePolicySuite bsps) {\n     }\n   }\n \n+  private static void checkUnderSameSnapshottableRoot(\n+      FSDirectory fsd, INodesInPath srcIIP, INodesInPath dstIIP)\n+      throws IOException {\n+    // Ensure rename out of a snapshottable root is not permitted if ordered\n+    // snapshot deletion feature is enabled\n+    SnapshotManager snapshotManager = fsd.getFSNamesystem().\n+        getSnapshotManager();\n+    if (snapshotManager.isSnapshotDeletionOrdered() && fsd.getFSNamesystem()\n+        .isSnapshotTrashRootEnabled()) {\n+      INodeDirectory srcRoot = snapshotManager.\n+          getSnapshottableAncestorDir(srcIIP);\n+      INodeDirectory dstRoot = snapshotManager.\n+          getSnapshottableAncestorDir(dstIIP);\n+      // Ensure snapshoottable root for both src and dest are same.\n+      if (srcRoot != dstRoot) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "edee22e378985607bcc813b388f1c80f18b996a9"}, "originalPosition": 43}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8444f5deac11b5880bf5d73c5e9f5f72051e48f0", "author": {"user": {"login": "bshashikant", "name": null}}, "url": "https://github.com/apache/hadoop/commit/8444f5deac11b5880bf5d73c5e9f5f72051e48f0", "committedDate": "2020-08-14T15:27:47Z", "message": "Addressed whitespace issues."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3797, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}