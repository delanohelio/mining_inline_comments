{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1MjQ0MDk1", "number": 1885, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjowNDo1N1rOD87g8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxOToyMToxOFrOD98H1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjE2MjQzOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjowNDo1N1rOGWK7Uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjoxNzo1NFrOGWh-mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDg4Mw==", "bodyText": "suggeset to use assertEquals()", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425900883", "createdAt": "2020-05-15T16:04:57Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODU1Mg==", "bodyText": "done", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278552", "createdAt": "2020-05-17T16:17:54Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDg4Mw=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjE2MzI5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjowNTowOFrOGWK7wQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjoxNzo1MFrOGWh-jQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDk5Mw==", "bodyText": "ditto", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425900993", "createdAt": "2020-05-15T16:05:08Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODU0MQ==", "bodyText": "done", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278541", "createdAt": "2020-05-17T16:17:50Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDk5Mw=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjE3OTcxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjowOTo0NVrOGWLGHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjoxNzo0NVrOGWh-gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzY0Nw==", "bodyText": "please add test timeout", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425903647", "createdAt": "2020-05-15T16:09:45Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODUyOQ==", "bodyText": "done", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278529", "createdAt": "2020-05-17T16:17:45Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzY0Nw=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjE4MDY4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjoxMDowMVrOGWLG0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjoxNzozOVrOGWh-bw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzgyNA==", "bodyText": "Can we make this sleep time shorter? Waiting for 15 seconds seems too excessive. You may have to change the timeout configuration.", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425903824", "createdAt": "2020-05-15T16:10:01Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODUxMQ==", "bodyText": "done", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278511", "createdAt": "2020-05-17T16:17:39Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzgyNA=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjE4NzMxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjoxMTo1NFrOGWLKwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxOToxOTo1M1rOGXvIMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNDgzMg==", "bodyText": "is the mini cluster required? starting a mini cluster takes time and prone to flaky failures. Would be nice to avoid using it.", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425904832", "createdAt": "2020-05-15T16:11:54Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODQ5NQ==", "bodyText": "the mini cluster is required. i use the mini cluster in a lot ut.\nWould you have any good way to replace it\uff1f", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278495", "createdAt": "2020-05-17T16:17:30Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNDgzMg=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MjU3Ng==", "bodyText": "Ok. That's fine.", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427542576", "createdAt": "2020-05-19T19:19:53Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNDgzMg=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjE4ODU1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjoxMjoxOFrOGWLLmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjoxNTo1NlrOGWh92Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTA1MQ==", "bodyText": "assertEquals()", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425905051", "createdAt": "2020-05-15T16:12:18Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    // restart the datanode to invalidate the cache\n+    cluster.restartDataNode(0);\n+    Thread.sleep(1000);\n+    // after the restart, new allocation and release should not be affect\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    Slot slot2 = null;\n+    try {\n+      slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+    } catch (ClosedChannelException ce) {\n+\n+    }\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(2000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODM2MQ==", "bodyText": "done", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278361", "createdAt": "2020-05-17T16:15:56Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    // restart the datanode to invalidate the cache\n+    cluster.restartDataNode(0);\n+    Thread.sleep(1000);\n+    // after the restart, new allocation and release should not be affect\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    Slot slot2 = null;\n+    try {\n+      slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+    } catch (ClosedChannelException ce) {\n+\n+    }\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(2000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTA1MQ=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjE4OTE0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjoxMjoyNlrOGWLL-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjoxNTo1MVrOGWh9zQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTE0NA==", "bodyText": "ditto", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425905144", "createdAt": "2020-05-15T16:12:26Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    // restart the datanode to invalidate the cache\n+    cluster.restartDataNode(0);\n+    Thread.sleep(1000);\n+    // after the restart, new allocation and release should not be affect\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    Slot slot2 = null;\n+    try {\n+      slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+    } catch (ClosedChannelException ce) {\n+\n+    }\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(2000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODM0OQ==", "bodyText": "done", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278349", "createdAt": "2020-05-17T16:15:51Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    // restart the datanode to invalidate the cache\n+    cluster.restartDataNode(0);\n+    Thread.sleep(1000);\n+    // after the restart, new allocation and release should not be affect\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    Slot slot2 = null;\n+    try {\n+      slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+    } catch (ClosedChannelException ce) {\n+\n+    }\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(2000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTE0NA=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjIyMDY0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjoyMToxN1rOGWLfyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxOToxODoxNVrOGXvExQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw==", "bodyText": "not that familiar with short circuit read. Is true that it's single threaded?", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425910217", "createdAt": "2020-05-15T16:21:17Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {\n+          try {\n+            if (domainSocket == null || !domainSocket.isOpen()) {\n+              // we are running in single thread mode, no protection needed for", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3NzkyNA==", "bodyText": "yeah, the SlotReleaser is running in single thread as follow code.\nShortCircuitCache#uref->replica.close()->cache.scheduleSlotReleaser(slot)->releaserExecutor.execute(new SlotReleaser(slot))-> SlotReleaser#run {\n...\ntry {\nif (domainSocket == null || !domainSocket.isOpen()) {\n// we are running in single thread mode, no protection needed for\n// domainSocket\ndomainSocket = DomainSocket.connect(path);\n}\n...\n}\nSince ShortCircuitCache#uref run in lock\uff0cthis code is run serially in a core thread of a thread pool.", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426277924", "createdAt": "2020-05-17T16:11:19Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {\n+          try {\n+            if (domainSocket == null || !domainSocket.isOpen()) {\n+              // we are running in single thread mode, no protection needed for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODI5NA==", "bodyText": "ShortCircuitCache#unref->ShortCircuitReplica#close->cache.scheduleSlotReleaser(slot)->releaserExecutor.execute(new SlotReleaser(slot))->SlotReleaser#run {\n...\nif (domainSocket == null || !domainSocket.isOpen()) {\n// we are running in single thread mode, no protection needed for\n// domainSocket\ndomainSocket = DomainSocket.connect(path);\n}\n...\n}\nSince ShortCircuitCache#unref run in lock, this code is run serially in a thread of a thread pool.", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278294", "createdAt": "2020-05-17T16:15:20Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {\n+          try {\n+            if (domainSocket == null || !domainSocket.isOpen()) {\n+              // we are running in single thread mode, no protection needed for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MTcwMQ==", "bodyText": "Got it. The release scheduler has only one thread.\n/**\n\nThe executor service that runs the cacheCleaner.\n*/\nprivate final ScheduledThreadPoolExecutor releaserExecutor\n= new ScheduledThreadPoolExecutor(1, new ThreadFactoryBuilder().\nsetDaemon(true).setNameFormat(\"ShortCircuitCache_SlotReleaser\").\nbuild());", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427541701", "createdAt": "2020-05-19T19:18:15Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {\n+          try {\n+            if (domainSocket == null || !domainSocket.isOpen()) {\n+              // we are running in single thread mode, no protection needed for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjMyNDc4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjo1MToyMlrOGWMiNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjoxNTozOVrOGWh9rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNzIyMw==", "bodyText": "If retries becomes 0, the code would silently ignore the error. How should we handle this case better?", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425927223", "createdAt": "2020-05-15T16:51:22Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODMxOQ==", "bodyText": "done", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278319", "createdAt": "2020-05-17T16:15:39Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNzIyMw=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2Mjc0NzcyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxOToyMToxOFrOGXvLig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQwMTo1NTo0N1rOGX4n_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MzQzNA==", "bodyText": "This one doesn't look right. I think you want to remove \"== 0\"?", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427543434", "createdAt": "2020-05-19T19:21:18Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -910,4 +912,94 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test(timeout = 60000)\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final ShortCircuitCache cache =\n+          fs.getClient().getClientContext().getShortCircuitCache();\n+      DomainPeer peer = getDomainPeerToDn(conf);\n+      MutableBoolean usedPeer = new MutableBoolean(false);\n+      ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+      final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+          .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+      // Allocating the first shm slot requires using up a peer.\n+      Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+      Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+      cache.scheduleSlotReleaser(slot1);\n+\n+      Thread.sleep(2000);\n+      cache.scheduleSlotReleaser(slot2);\n+      Thread.sleep(2000);\n+      Assert.assertEquals(0,\n+          cluster.getDataNodes().get(0).getShortCircuitRegistry().getShmNum());\n+      Assert.assertEquals(0, cache.getDfsClientShmManager().getShmNum());\n+    } finally {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 60000)\n+  public void testDNRestart() throws Exception {\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final ShortCircuitCache cache =\n+          fs.getClient().getClientContext().getShortCircuitCache();\n+      DomainPeer peer = getDomainPeerToDn(conf);\n+      MutableBoolean usedPeer = new MutableBoolean(false);\n+      ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+      final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+          .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+      // Allocating the first shm slot requires using up a peer.\n+      Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+      // restart the datanode to invalidate the cache\n+      cluster.restartDataNode(0);\n+      Thread.sleep(1000);\n+      // after the restart, new allocation and release should not be affect\n+      cache.scheduleSlotReleaser(slot1);\n+\n+      Slot slot2 = null;\n+      try {\n+        slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+            \"testReleaseSlotReuseDomainSocket_client\");\n+      } catch (ClosedChannelException ce) {\n+\n+      }\n+      cache.scheduleSlotReleaser(slot2);\n+      Thread.sleep(2000);\n+      Assert.assertEquals(0, cluster.getDataNodes().get(0)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f2c8c586801dec07d8e6b0302b43c012112fc92b"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY5ODE3NA==", "bodyText": "yeah, I really think so and update the patch.", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427698174", "createdAt": "2020-05-20T01:55:47Z", "author": {"login": "leosunli"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -910,4 +912,94 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test(timeout = 60000)\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final ShortCircuitCache cache =\n+          fs.getClient().getClientContext().getShortCircuitCache();\n+      DomainPeer peer = getDomainPeerToDn(conf);\n+      MutableBoolean usedPeer = new MutableBoolean(false);\n+      ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+      final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+          .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+      // Allocating the first shm slot requires using up a peer.\n+      Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+      Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+      cache.scheduleSlotReleaser(slot1);\n+\n+      Thread.sleep(2000);\n+      cache.scheduleSlotReleaser(slot2);\n+      Thread.sleep(2000);\n+      Assert.assertEquals(0,\n+          cluster.getDataNodes().get(0).getShortCircuitRegistry().getShmNum());\n+      Assert.assertEquals(0, cache.getDfsClientShmManager().getShmNum());\n+    } finally {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 60000)\n+  public void testDNRestart() throws Exception {\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final ShortCircuitCache cache =\n+          fs.getClient().getClientContext().getShortCircuitCache();\n+      DomainPeer peer = getDomainPeerToDn(conf);\n+      MutableBoolean usedPeer = new MutableBoolean(false);\n+      ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+      final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+          .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+      // Allocating the first shm slot requires using up a peer.\n+      Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+      // restart the datanode to invalidate the cache\n+      cluster.restartDataNode(0);\n+      Thread.sleep(1000);\n+      // after the restart, new allocation and release should not be affect\n+      cache.scheduleSlotReleaser(slot1);\n+\n+      Slot slot2 = null;\n+      try {\n+        slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+            \"testReleaseSlotReuseDomainSocket_client\");\n+      } catch (ClosedChannelException ce) {\n+\n+      }\n+      cache.scheduleSlotReleaser(slot2);\n+      Thread.sleep(2000);\n+      Assert.assertEquals(0, cluster.getDataNodes().get(0)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MzQzNA=="}, "originalCommit": {"oid": "f2c8c586801dec07d8e6b0302b43c012112fc92b"}, "originalPosition": 103}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3615, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}