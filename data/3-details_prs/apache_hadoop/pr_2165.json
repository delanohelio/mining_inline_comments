{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU0OTc0Mzgx", "number": 2165, "title": "HDFS-15481. Ordered snapshot deletion: garbage collect deleted snapshots", "bodyText": "Please see https://issues.apache.org/jira/browse/HDFS-15481", "createdAt": "2020-07-22T08:49:41Z", "url": "https://github.com/apache/hadoop/pull/2165", "merged": true, "mergeCommit": {"oid": "05b3337a4605dcb6904cb3fe2a58e4dc424ef015"}, "closed": true, "closedAt": "2020-07-30T17:36:52Z", "author": {"login": "szetszwo"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc3jSKdABqjM1Nzc4OTQ3MzE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc6DMBQAFqTQ1ODYxNjU2OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1708613805d61d50c7c5db0f33ce92e2c6e0e276", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/1708613805d61d50c7c5db0f33ce92e2c6e0e276", "committedDate": "2020-07-22T08:47:42Z", "message": "HDFS-15481"}, "afterCommit": {"oid": "3525f0837551612acbd0f1c78be48c065e4984c3", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/3525f0837551612acbd0f1c78be48c065e4984c3", "committedDate": "2020-07-22T23:17:47Z", "message": "HDFS-15481"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a01433c454f6ca68f2940464e68cb8112dee01bb", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/a01433c454f6ca68f2940464e68cb8112dee01bb", "committedDate": "2020-07-23T08:11:47Z", "message": "HDFS-15481"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3525f0837551612acbd0f1c78be48c065e4984c3", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/3525f0837551612acbd0f1c78be48c065e4984c3", "committedDate": "2020-07-22T23:17:47Z", "message": "HDFS-15481"}, "afterCommit": {"oid": "a01433c454f6ca68f2940464e68cb8112dee01bb", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/a01433c454f6ca68f2940464e68cb8112dee01bb", "committedDate": "2020-07-23T08:11:47Z", "message": "HDFS-15481"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "16990d25e98d25a2bd93bbf9fdec219b248db1e9", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/16990d25e98d25a2bd93bbf9fdec219b248db1e9", "committedDate": "2020-07-23T18:10:48Z", "message": "Fix checkstyle and move the private confs to SnapshotManager."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "29dd96fca501240831de9e4b8519f901025bc58f", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/29dd96fca501240831de9e4b8519f901025bc58f", "committedDate": "2020-07-23T17:58:06Z", "message": "Fix checkstyle"}, "afterCommit": {"oid": "16990d25e98d25a2bd93bbf9fdec219b248db1e9", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/16990d25e98d25a2bd93bbf9fdec219b248db1e9", "committedDate": "2020-07-23T18:10:48Z", "message": "Fix checkstyle and move the private confs to SnapshotManager."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc1debd29a01c520fa344ff6a4dc934693c05f8e", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/dc1debd29a01c520fa344ff6a4dc934693c05f8e", "committedDate": "2020-07-23T18:15:03Z", "message": "Rename a test method."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1MzAwMTEy", "url": "https://github.com/apache/hadoop/pull/2165#pullrequestreview-455300112", "createdAt": "2020-07-25T17:59:21Z", "commit": {"oid": "dc1debd29a01c520fa344ff6a4dc934693c05f8e"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxNzo1OToyMVrOG3GV-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxODowMDoxN1rOG3GWTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQyODc5Mg==", "bodyText": "Lets move this to a different funcation like chooseSnapshottableDir, as this might be policy controleed later.", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r460428792", "createdAt": "2020-07-25T17:59:21Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java", "diffHunk": "@@ -629,4 +641,36 @@ public void shutdown() {\n         s.getRoot().getLocalName(), s.getRoot().getFullPathName(),\n         s.getRoot().getModificationTime());\n   }\n-}\n+\n+  Snapshot.Root chooseDeletedSnapshot() {\n+    final List<INodeDirectory> dirs = getSnapshottableDirs();\n+    Collections.shuffle(dirs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc1debd29a01c520fa344ff6a4dc934693c05f8e"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQyODg3Nw==", "bodyText": "Lets add an assert that this is the first snapshot in the snapshottable dir ?", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r460428877", "createdAt": "2020-07-25T18:00:17Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotDeletionGc.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.server.namenode.snapshot;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdfs.server.namenode.FSNamesystem;\n+import org.apache.hadoop.util.StringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Timer;\n+import java.util.TimerTask;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS;\n+import static org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS_DEFAULT;\n+\n+public class SnapshotDeletionGc {\n+  public static final Logger LOG = LoggerFactory.getLogger(\n+      SnapshotDeletionGc.class);\n+\n+  private final FSNamesystem namesystem;\n+  private final int deletionOrderedGcPeriodMs;\n+  private final AtomicReference<Timer> timer = new AtomicReference<>();\n+\n+  public SnapshotDeletionGc(FSNamesystem namesystem, Configuration conf) {\n+    this.namesystem = namesystem;\n+\n+    this.deletionOrderedGcPeriodMs = conf.getInt(\n+        DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS,\n+        DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS_DEFAULT);\n+    LOG.info(\"{} = {}\", DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS,\n+        deletionOrderedGcPeriodMs);\n+  }\n+\n+  public void schedule() {\n+    if (timer.get() != null) {\n+      return;\n+    }\n+    final Timer t = new Timer(getClass().getSimpleName(), true);\n+    if (timer.compareAndSet(null, t)) {\n+      LOG.info(\"Schedule at fixed rate {}\",\n+          StringUtils.formatTime(deletionOrderedGcPeriodMs));\n+      t.scheduleAtFixedRate(new GcTask(),\n+          deletionOrderedGcPeriodMs, deletionOrderedGcPeriodMs);\n+    }\n+  }\n+\n+  public void cancel() {\n+    final Timer t = timer.getAndSet(null);\n+    if (t != null) {\n+      LOG.info(\"cancel\");\n+      t.cancel();\n+    }\n+  }\n+\n+  private void gcDeletedSnapshot(String name) {\n+    final Snapshot.Root deleted;\n+    namesystem.readLock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc1debd29a01c520fa344ff6a4dc934693c05f8e"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1NTg4NTEx", "url": "https://github.com/apache/hadoop/pull/2165#pullrequestreview-455588511", "createdAt": "2020-07-27T08:44:19Z", "commit": {"oid": "dc1debd29a01c520fa344ff6a4dc934693c05f8e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QwODo0NDoyMFrOG3ZK0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QwODo0NDoyMFrOG3ZK0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDczNzIzMg==", "bodyText": "I think its better to start the gc work in FSNameSystem#startActiveServices() after quota setup and initialization is done\nstartActiveServices()\n``\n// Initialize the quota.\ndir.updateCountForQuota();\n// Enable quota checks.\ndir.enableQuotaChecks();", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r460737232", "createdAt": "2020-07-27T08:44:20Z", "author": {"login": "bshashikant"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "diffHunk": "@@ -1284,6 +1288,7 @@ void startCommonServices(Configuration conf, HAContext haContext) throws IOExcep\n       dir.setINodeAttributeProvider(inodeAttributeProvider);\n     }\n     snapshotManager.registerMXBean();\n+    snapshotDeletionGc.schedule();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dc1debd29a01c520fa344ff6a4dc934693c05f8e"}, "originalPosition": 29}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "99dab64faea4426ad8c82eba6b581c984ac98943", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/99dab64faea4426ad8c82eba6b581c984ac98943", "committedDate": "2020-07-28T00:43:57Z", "message": "Address review comments."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2NjkyMTIz", "url": "https://github.com/apache/hadoop/pull/2165#pullrequestreview-456692123", "createdAt": "2020-07-28T14:28:59Z", "commit": {"oid": "99dab64faea4426ad8c82eba6b581c984ac98943"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2ODk5MTEx", "url": "https://github.com/apache/hadoop/pull/2165#pullrequestreview-456899111", "createdAt": "2020-07-28T18:28:57Z", "commit": {"oid": "99dab64faea4426ad8c82eba6b581c984ac98943"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxODoyODo1N1rOG4ZNIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxOToxMToyNlrOG4aqjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc4NjQwMA==", "bodyText": "This assertion should also be inside gcDeletedSnapshot ?", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r461786400", "createdAt": "2020-07-28T18:28:57Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java", "diffHunk": "@@ -382,6 +395,14 @@ public void deleteSnapshot(final INodesInPath iip, final String snapshotName,\n             EnumSet.of(XAttrSetFlag.CREATE, XAttrSetFlag.REPLACE));\n         return;\n       }\n+\n+      // assert if it is deleting the first snapshot\n+      final INodeDirectoryAttributes first = snapshottable.getDiffs().getFirstSnapshotINode();\n+      if (snapshot.getRoot() != first) {\n+        throw new IllegalStateException(\"Failed to delete snapshot \" + snapshotName", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99dab64faea4426ad8c82eba6b581c984ac98943"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwNTE2OQ==", "bodyText": "Lets assert that xattr is set on the snapshot and this is the first snapshot to be deleted.", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r461805169", "createdAt": "2020-07-28T19:01:52Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "diffHunk": "@@ -7166,6 +7175,29 @@ void deleteSnapshot(String snapshotRoot, String snapshotName,\n     logAuditEvent(true, operationName, rootPath, null, null);\n   }\n \n+  public void gcDeletedSnapshot(String snapshotRoot, String snapshotName)\n+      throws IOException {\n+    final String operationName = \"gcDeletedSnapshot\";\n+    String rootPath = null;\n+    final INode.BlocksMapUpdateInfo blocksToBeDeleted;\n+\n+    checkOperation(OperationCategory.WRITE);\n+    writeLock();\n+    try {\n+      checkOperation(OperationCategory.WRITE);\n+      rootPath = Snapshot.getSnapshotPath(snapshotRoot, snapshotName);\n+      checkNameNodeSafeMode(\"Cannot gcDeletedSnapshot for \" + rootPath);\n+\n+      final long now = Time.now();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99dab64faea4426ad8c82eba6b581c984ac98943"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwNjMxOQ==", "bodyText": "Lets change this to error and abort and exit from the namenode if the deletion is not possible.\nI feel we should do this earlier to identify issues with snapshot deletion code.", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r461806319", "createdAt": "2020-07-28T19:04:04Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotDeletionGc.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.server.namenode.snapshot;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdfs.server.namenode.FSNamesystem;\n+import org.apache.hadoop.util.StringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Timer;\n+import java.util.TimerTask;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS;\n+import static org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS_DEFAULT;\n+\n+public class SnapshotDeletionGc {\n+  public static final Logger LOG = LoggerFactory.getLogger(\n+      SnapshotDeletionGc.class);\n+\n+  private final FSNamesystem namesystem;\n+  private final long deletionOrderedGcPeriodMs;\n+  private final AtomicReference<Timer> timer = new AtomicReference<>();\n+\n+  public SnapshotDeletionGc(FSNamesystem namesystem, Configuration conf) {\n+    this.namesystem = namesystem;\n+\n+    this.deletionOrderedGcPeriodMs = conf.getLong(\n+        DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS,\n+        DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS_DEFAULT);\n+    LOG.info(\"{} = {}\", DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS,\n+        deletionOrderedGcPeriodMs);\n+  }\n+\n+  public void schedule() {\n+    if (timer.get() != null) {\n+      return;\n+    }\n+    final Timer t = new Timer(getClass().getSimpleName(), true);\n+    if (timer.compareAndSet(null, t)) {\n+      LOG.info(\"Schedule at fixed rate {}\",\n+          StringUtils.formatTime(deletionOrderedGcPeriodMs));\n+      t.scheduleAtFixedRate(new GcTask(),\n+          deletionOrderedGcPeriodMs, deletionOrderedGcPeriodMs);\n+    }\n+  }\n+\n+  public void cancel() {\n+    final Timer t = timer.getAndSet(null);\n+    if (t != null) {\n+      LOG.info(\"cancel\");\n+      t.cancel();\n+    }\n+  }\n+\n+  private void gcDeletedSnapshot(String name) {\n+    final Snapshot.Root deleted;\n+    namesystem.readLock();\n+    try {\n+      deleted = namesystem.getSnapshotManager().chooseDeletedSnapshot();\n+    } finally {\n+      namesystem.readUnlock();\n+    }\n+    if (deleted == null) {\n+      LOG.trace(\"{}: no snapshots are marked as deleted.\", name);\n+      return;\n+    }\n+\n+    final String snapshotRoot = deleted.getRootFullPathName();\n+    final String snapshotName = deleted.getLocalName();\n+    LOG.info(\"{}: delete snapshot {} from {}\",\n+        name, snapshotName, snapshotRoot);\n+\n+    try {\n+      namesystem.gcDeletedSnapshot(snapshotRoot, snapshotName);\n+    } catch (Throwable e) {\n+      LOG.warn(\"Failed to gcDeletedSnapshot \" + deleted.getFullPathName(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99dab64faea4426ad8c82eba6b581c984ac98943"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwNzA2MA==", "bodyText": "lets catch Throwable here and log error in case we get an exception here.", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r461807060", "createdAt": "2020-07-28T19:05:27Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotDeletionGc.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.server.namenode.snapshot;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdfs.server.namenode.FSNamesystem;\n+import org.apache.hadoop.util.StringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Timer;\n+import java.util.TimerTask;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS;\n+import static org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS_DEFAULT;\n+\n+public class SnapshotDeletionGc {\n+  public static final Logger LOG = LoggerFactory.getLogger(\n+      SnapshotDeletionGc.class);\n+\n+  private final FSNamesystem namesystem;\n+  private final long deletionOrderedGcPeriodMs;\n+  private final AtomicReference<Timer> timer = new AtomicReference<>();\n+\n+  public SnapshotDeletionGc(FSNamesystem namesystem, Configuration conf) {\n+    this.namesystem = namesystem;\n+\n+    this.deletionOrderedGcPeriodMs = conf.getLong(\n+        DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS,\n+        DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS_DEFAULT);\n+    LOG.info(\"{} = {}\", DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS,\n+        deletionOrderedGcPeriodMs);\n+  }\n+\n+  public void schedule() {\n+    if (timer.get() != null) {\n+      return;\n+    }\n+    final Timer t = new Timer(getClass().getSimpleName(), true);\n+    if (timer.compareAndSet(null, t)) {\n+      LOG.info(\"Schedule at fixed rate {}\",\n+          StringUtils.formatTime(deletionOrderedGcPeriodMs));\n+      t.scheduleAtFixedRate(new GcTask(),\n+          deletionOrderedGcPeriodMs, deletionOrderedGcPeriodMs);\n+    }\n+  }\n+\n+  public void cancel() {\n+    final Timer t = timer.getAndSet(null);\n+    if (t != null) {\n+      LOG.info(\"cancel\");\n+      t.cancel();\n+    }\n+  }\n+\n+  private void gcDeletedSnapshot(String name) {\n+    final Snapshot.Root deleted;\n+    namesystem.readLock();\n+    try {\n+      deleted = namesystem.getSnapshotManager().chooseDeletedSnapshot();\n+    } finally {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99dab64faea4426ad8c82eba6b581c984ac98943"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgxMDMxNw==", "bodyText": "I feel all the deletion should happen via one code path, i.e. the background thread. some deletion from the user thread and others from background is error prone.", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r461810317", "createdAt": "2020-07-28T19:11:26Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java", "diffHunk": "@@ -382,6 +395,14 @@ public void deleteSnapshot(final INodesInPath iip, final String snapshotName,\n             EnumSet.of(XAttrSetFlag.CREATE, XAttrSetFlag.REPLACE));\n         return;\n       }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99dab64faea4426ad8c82eba6b581c984ac98943"}, "originalPosition": 40}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "032729514c1406f0d329fca1c421bb09f8acf783", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/032729514c1406f0d329fca1c421bb09f8acf783", "committedDate": "2020-07-28T20:07:50Z", "message": "Address Mukul's second set of review comments."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MTUxMDg2", "url": "https://github.com/apache/hadoop/pull/2165#pullrequestreview-457151086", "createdAt": "2020-07-29T02:24:00Z", "commit": {"oid": "032729514c1406f0d329fca1c421bb09f8acf783"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoyNDowMFrOG4mN_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozMDo1NFrOG4mVIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5OTYxMw==", "bodyText": "I agree that code paths are similar. However, just wanted to discuss this once. :) The only thing which might not work is the sleep between every snap deletes here. It may happen that the user operation snap delete and the background thread based snap delete are not time spaced correctly. But that is not a big issue anyways.", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r461999613", "createdAt": "2020-07-29T02:24:00Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java", "diffHunk": "@@ -382,6 +395,14 @@ public void deleteSnapshot(final INodesInPath iip, final String snapshotName,\n             EnumSet.of(XAttrSetFlag.CREATE, XAttrSetFlag.REPLACE));\n         return;\n       }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgxMDMxNw=="}, "originalCommit": {"oid": "99dab64faea4426ad8c82eba6b581c984ac98943"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5OTkyNQ==", "bodyText": "If the snapshot delete for the same snapname failed multiple times after the namenode came out of safemode. Should we exit the NN process ?", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r461999925", "createdAt": "2020-07-29T02:25:09Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotDeletionGc.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.server.namenode.snapshot;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdfs.server.namenode.FSNamesystem;\n+import org.apache.hadoop.util.StringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Timer;\n+import java.util.TimerTask;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS;\n+import static org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS_DEFAULT;\n+\n+public class SnapshotDeletionGc {\n+  public static final Logger LOG = LoggerFactory.getLogger(\n+      SnapshotDeletionGc.class);\n+\n+  private final FSNamesystem namesystem;\n+  private final long deletionOrderedGcPeriodMs;\n+  private final AtomicReference<Timer> timer = new AtomicReference<>();\n+\n+  public SnapshotDeletionGc(FSNamesystem namesystem, Configuration conf) {\n+    this.namesystem = namesystem;\n+\n+    this.deletionOrderedGcPeriodMs = conf.getLong(\n+        DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS,\n+        DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS_DEFAULT);\n+    LOG.info(\"{} = {}\", DFS_NAMENODE_SNAPSHOT_DELETION_ORDERED_GC_PERIOD_MS,\n+        deletionOrderedGcPeriodMs);\n+  }\n+\n+  public void schedule() {\n+    if (timer.get() != null) {\n+      return;\n+    }\n+    final Timer t = new Timer(getClass().getSimpleName(), true);\n+    if (timer.compareAndSet(null, t)) {\n+      LOG.info(\"Schedule at fixed rate {}\",\n+          StringUtils.formatTime(deletionOrderedGcPeriodMs));\n+      t.scheduleAtFixedRate(new GcTask(),\n+          deletionOrderedGcPeriodMs, deletionOrderedGcPeriodMs);\n+    }\n+  }\n+\n+  public void cancel() {\n+    final Timer t = timer.getAndSet(null);\n+    if (t != null) {\n+      LOG.info(\"cancel\");\n+      t.cancel();\n+    }\n+  }\n+\n+  private void gcDeletedSnapshot(String name) {\n+    final Snapshot.Root deleted;\n+    namesystem.readLock();\n+    try {\n+      deleted = namesystem.getSnapshotManager().chooseDeletedSnapshot();\n+    } catch (Throwable e) {\n+      LOG.error(\"Failed to chooseDeletedSnapshot\", e);\n+      throw e;\n+    } finally {\n+      namesystem.readUnlock();\n+    }\n+    if (deleted == null) {\n+      LOG.trace(\"{}: no snapshots are marked as deleted.\", name);\n+      return;\n+    }\n+\n+    final String snapshotRoot = deleted.getRootFullPathName();\n+    final String snapshotName = deleted.getLocalName();\n+    LOG.info(\"{}: delete snapshot {} from {}\",\n+        name, snapshotName, snapshotRoot);\n+\n+    try {\n+      namesystem.gcDeletedSnapshot(snapshotRoot, snapshotName);\n+    } catch (Throwable e) {\n+      LOG.error(\"Failed to gcDeletedSnapshot \" + deleted.getFullPathName(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "032729514c1406f0d329fca1c421bb09f8acf783"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMDg3NQ==", "bodyText": "The check here should be !snapshotRoot.isMarkedAsDeleted() ?", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r462000875", "createdAt": "2020-07-29T02:29:00Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java", "diffHunk": "@@ -267,6 +280,20 @@ public INodeDirectory getSnapshottableRoot(final INodesInPath iip)\n     return dir;\n   }\n \n+  public void assertMarkedAsDeleted(INodesInPath iip, String snapshotName)\n+      throws IOException {\n+    final INodeDirectory dir = getSnapshottableRoot(iip);\n+    final Snapshot.Root snapshotRoot = dir.getDirectorySnapshottableFeature()\n+        .getSnapshotByName(dir, snapshotName)\n+        .getRoot();\n+\n+    if (snapshotRoot.isMarkedAsDeleted()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "032729514c1406f0d329fca1c421bb09f8acf783"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMTQ0Mg==", "bodyText": "should we also add an assert inside FSDirSnapshotOp.deleteSnapshot, which is common to both the code paths. That with the ordered delete flag set to true. The snapshot being deleted is the first snapshot in the list ?", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r462001442", "createdAt": "2020-07-29T02:30:54Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "diffHunk": "@@ -7166,6 +7175,30 @@ void deleteSnapshot(String snapshotRoot, String snapshotName,\n     logAuditEvent(true, operationName, rootPath, null, null);\n   }\n \n+  public void gcDeletedSnapshot(String snapshotRoot, String snapshotName)\n+      throws IOException {\n+    final String operationName = \"gcDeletedSnapshot\";\n+    String rootPath = null;\n+    final INode.BlocksMapUpdateInfo blocksToBeDeleted;\n+\n+    checkOperation(OperationCategory.WRITE);\n+    writeLock();\n+    try {\n+      checkOperation(OperationCategory.WRITE);\n+      rootPath = Snapshot.getSnapshotPath(snapshotRoot, snapshotName);\n+      checkNameNodeSafeMode(\"Cannot gcDeletedSnapshot for \" + rootPath);\n+\n+      final long now = Time.now();\n+      final INodesInPath iip = dir.resolvePath(null, snapshotRoot, DirOp.WRITE);\n+      snapshotManager.assertMarkedAsDeleted(iip, snapshotName);\n+      blocksToBeDeleted = FSDirSnapshotOp.deleteSnapshot(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "032729514c1406f0d329fca1c421bb09f8acf783"}, "originalPosition": 64}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a16f77f9304e8aa06c62d1837a4b41d3b28cb9c7", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/a16f77f9304e8aa06c62d1837a4b41d3b28cb9c7", "committedDate": "2020-07-29T18:52:40Z", "message": "Do not create SnapshotDeletionGc when the feature is disable, fix a bug and add more assertions."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68ed1e018ae6cf44dba373fff20951eda9566fa2", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/68ed1e018ae6cf44dba373fff20951eda9566fa2", "committedDate": "2020-07-29T19:32:39Z", "message": "Move FSDirectory.snapshotDeletionOrdered to SnapshotManager."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6fa88dcf07cbc8305ffaf7a07c89ab7e877d3c42", "author": {"user": {"login": "szetszwo", "name": "Tsz-Wo Nicholas Sze"}}, "url": "https://github.com/apache/hadoop/commit/6fa88dcf07cbc8305ffaf7a07c89ab7e877d3c42", "committedDate": "2020-07-29T19:48:52Z", "message": "Some minor changes."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4MDg3NzQy", "url": "https://github.com/apache/hadoop/pull/2165#pullrequestreview-458087742", "createdAt": "2020-07-30T05:49:57Z", "commit": {"oid": "6fa88dcf07cbc8305ffaf7a07c89ab7e877d3c42"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQwNTo0OTo1N1rOG5UBzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQwNTo0OTo1N1rOG5UBzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjc1MDE1OA==", "bodyText": "do we need to do a null check here before calling removeBlocks as its done in other code paths where remove blocks is getting called ?\ne.g. FsNamesystem#deleteSnapshot:\n---------// Breaking the pattern as removing blocks have to happen outside of the // global lock if (blocksToBeDeleted != null) { removeBlocks(blocksToBeDeleted); }", "url": "https://github.com/apache/hadoop/pull/2165#discussion_r462750158", "createdAt": "2020-07-30T05:49:57Z", "author": {"login": "bshashikant"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "diffHunk": "@@ -7166,6 +7178,30 @@ void deleteSnapshot(String snapshotRoot, String snapshotName,\n     logAuditEvent(true, operationName, rootPath, null, null);\n   }\n \n+  public void gcDeletedSnapshot(String snapshotRoot, String snapshotName)\n+      throws IOException {\n+    final String operationName = \"gcDeletedSnapshot\";\n+    String rootPath = null;\n+    final INode.BlocksMapUpdateInfo blocksToBeDeleted;\n+\n+    checkOperation(OperationCategory.WRITE);\n+    writeLock();\n+    try {\n+      checkOperation(OperationCategory.WRITE);\n+      rootPath = Snapshot.getSnapshotPath(snapshotRoot, snapshotName);\n+      checkNameNodeSafeMode(\"Cannot gcDeletedSnapshot for \" + rootPath);\n+\n+      final long now = Time.now();\n+      final INodesInPath iip = dir.resolvePath(null, snapshotRoot, DirOp.WRITE);\n+      snapshotManager.assertMarkedAsDeleted(iip, snapshotName);\n+      blocksToBeDeleted = FSDirSnapshotOp.deleteSnapshot(\n+          dir, snapshotManager, iip, snapshotName, now);\n+    } finally {\n+      writeUnlock(operationName, getLockReportInfoSupplier(rootPath));\n+    }\n+    removeBlocks(blocksToBeDeleted);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fa88dcf07cbc8305ffaf7a07c89ab7e877d3c42"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NjAzNTAw", "url": "https://github.com/apache/hadoop/pull/2165#pullrequestreview-458603500", "createdAt": "2020-07-30T17:18:27Z", "commit": {"oid": "6fa88dcf07cbc8305ffaf7a07c89ab7e877d3c42"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NjAzNTk2", "url": "https://github.com/apache/hadoop/pull/2165#pullrequestreview-458603596", "createdAt": "2020-07-30T17:18:36Z", "commit": {"oid": "6fa88dcf07cbc8305ffaf7a07c89ab7e877d3c42"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NjE2NTY5", "url": "https://github.com/apache/hadoop/pull/2165#pullrequestreview-458616569", "createdAt": "2020-07-30T17:36:32Z", "commit": {"oid": "6fa88dcf07cbc8305ffaf7a07c89ab7e877d3c42"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3780, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}