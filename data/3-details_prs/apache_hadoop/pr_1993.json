{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEyMTc3MzA1", "number": 1993, "title": "HADOOP-17021. Add concat fs command", "bodyText": "We should add one concat fs command for ease of use. It concatenates existing source files into the target file using FileSystem.concat().", "createdAt": "2020-05-01T15:32:43Z", "url": "https://github.com/apache/hadoop/pull/1993", "merged": true, "mergeCommit": {"oid": "52db86b0bb4d2fa644362c23a6566eec1cb5200b"}, "closed": true, "closedAt": "2020-10-08T09:36:08Z", "author": {"login": "wojiaodoubao"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc02JYiAFqTQ0ODA5Njg2Mg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdORy_BgFqTUwMDM3MzU2Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ4MDk2ODYy", "url": "https://github.com/apache/hadoop/pull/1993#pullrequestreview-448096862", "createdAt": "2020-07-14T13:18:32Z", "commit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxMzoxODozMlrOGxTRhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxMzozNDoyN1rOGxT53Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM0OTE5MA==", "bodyText": "one of the examples should include the hdfs:// reference; for the -* one, maybe add  * for those shells which do the expansion locally (i.e. bash), otherwise things don't work right", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454349190", "createdAt": "2020-07-14T13:18:32Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/site/markdown/FileSystemShell.md", "diffHunk": "@@ -824,6 +824,19 @@ Example:\n * `hadoop fs -truncate 55 /user/hadoop/file1 /user/hadoop/file2`\n * `hadoop fs -truncate -w 127 hdfs://nn1.example.com/user/hadoop/file1`\n \n+concat\n+--------\n+\n+Usage: `hadoop fs -concat <target file> <source files>`\n+\n+Concatenate existing source files into the target file. Target file and source\n+files should be in the same directory.\n+\n+Example:\n+\n+* `hadoop fs -concat /user/hadoop/target-file /user/hadoop/file-0 /user/hadoop/file-1`\n+* `hadoop fs -concat /user/hadoop/target-file /user/hadoop/file-*`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MDEwMg==", "bodyText": "use the relevant ContractTestUtils assertion here, for better error reporting.", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454350102", "createdAt": "2020-07-14T13:20:00Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    assertTrue(lfs.exists(dstPath));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MDY0NA==", "bodyText": "Prefer Assertions.assertThat for new tests, as it will generate a meaningful error message", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454350644", "createdAt": "2020-07-14T13:20:51Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    assertTrue(lfs.exists(dstPath));\n+    assertEquals(1, lfs.listStatus(testRootDir).length);\n+  }\n+\n+  @Test\n+  public void testUnsupportedFs() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doThrow(\n+        new UnsupportedOperationException(\"Mock unsupported exception.\"))\n+        .when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Mockito.doAnswer(invocationOnMock -> new URI(\"mockfs:///\")).when(mockFs)\n+        .getUri();\n+    Concat.setTstFs(mockFs);\n+    PrintStream oldErr = System.err;\n+    final ByteArrayOutputStream err = new ByteArrayOutputStream();\n+    System.setErr(new PrintStream(err));\n+    shellRun(1, \"-concat\", dstPath.toString(), testRootDir + \"/file-*\");\n+    System.setErr(oldErr);\n+    System.err.print(err.toString());\n+    assertTrue(err.toString()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MDk1Nw==", "bodyText": "try/finally here to always restore the error stream", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454350957", "createdAt": "2020-07-14T13:21:20Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    assertTrue(lfs.exists(dstPath));\n+    assertEquals(1, lfs.listStatus(testRootDir).length);\n+  }\n+\n+  @Test\n+  public void testUnsupportedFs() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doThrow(\n+        new UnsupportedOperationException(\"Mock unsupported exception.\"))\n+        .when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Mockito.doAnswer(invocationOnMock -> new URI(\"mockfs:///\")).when(mockFs)\n+        .getUri();\n+    Concat.setTstFs(mockFs);\n+    PrintStream oldErr = System.err;\n+    final ByteArrayOutputStream err = new ByteArrayOutputStream();\n+    System.setErr(new PrintStream(err));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MTg4OA==", "bodyText": "there's some ContractTestUtils helper method for writing files. If not, use try-with-resources", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454351888", "createdAt": "2020-07-14T13:22:45Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    assertTrue(lfs.exists(dstPath));\n+    assertEquals(1, lfs.listStatus(testRootDir).length);\n+  }\n+\n+  @Test\n+  public void testUnsupportedFs() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doThrow(\n+        new UnsupportedOperationException(\"Mock unsupported exception.\"))\n+        .when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Mockito.doAnswer(invocationOnMock -> new URI(\"mockfs:///\")).when(mockFs)\n+        .getUri();\n+    Concat.setTstFs(mockFs);\n+    PrintStream oldErr = System.err;\n+    final ByteArrayOutputStream err = new ByteArrayOutputStream();\n+    System.setErr(new PrintStream(err));\n+    shellRun(1, \"-concat\", dstPath.toString(), testRootDir + \"/file-*\");\n+    System.setErr(oldErr);\n+    System.err.print(err.toString());\n+    assertTrue(err.toString()\n+        .contains(\"Dest filesystem 'mockfs' doesn't support concat\"));\n+  }\n+\n+  private void shellRun(int n, String... args) {\n+    assertEquals(n, shell.run(args));\n+  }\n+\n+  /**\n+   * Simple simulation of concat.\n+   */\n+  private void mockConcat(Path target, Path[] srcArray) throws IOException {\n+    Path tmp = new Path(target.getParent(), target.getName() + \".bak\");\n+    lfs.rename(target, tmp);\n+    OutputStream out = lfs.create(target);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1Mjk0Mg==", "bodyText": "prefer an import ordering of\norg.java\n\nanything-not-org-apache (here junit and mockito)\n\norg.apache\n\nall static imports", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454352942", "createdAt": "2020-07-14T13:24:21Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MzUwMQ==", "bodyText": "make a subclass of AbstractHadoopTestBase for test timeout and thread naming", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454353501", "createdAt": "2020-07-14T13:25:15Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NDMzNw==", "bodyText": "just call delete with no probe. or use ContractTestUtils method which checks delete() return value", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454354337", "createdAt": "2020-07-14T13:26:30Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NDg3Mg==", "bodyText": "use String.format with a 0 prefix, e.g %02d for ordering", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454354872", "createdAt": "2020-07-14T13:27:15Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NjE5OA==", "bodyText": "include Usage text", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454356198", "createdAt": "2020-07-14T13:29:21Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NjI2MQ==", "bodyText": "include Usage text", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454356261", "createdAt": "2020-07-14T13:29:25Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\"The number of source paths is less than 2.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NjY4Nw==", "bodyText": "raise FileNotFoundException", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454356687", "createdAt": "2020-07-14T13:30:03Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\"The number of source paths is less than 2.\");\n+    }\n+    PathData target = args.removeFirst();\n+    LinkedList<PathData> srcList = args;\n+    if (!target.exists || !target.stat.isFile()) {\n+      throw new IOException(String.format(\"Target path %s does not exist or is\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1Njc2Mg==", "bodyText": "raise FileNotFoundException", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454356762", "createdAt": "2020-07-14T13:30:10Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\"The number of source paths is less than 2.\");\n+    }\n+    PathData target = args.removeFirst();\n+    LinkedList<PathData> srcList = args;\n+    if (!target.exists || !target.stat.isFile()) {\n+      throw new IOException(String.format(\"Target path %s does not exist or is\"\n+              + \" not file.\", target.path));\n+    }\n+    Path[] srcArray = new Path[srcList.size()];\n+    for (int i = 0; i < args.size(); i++) {\n+      PathData src = srcList.get(i);\n+      if (!src.exists || !src.stat.isFile()) {\n+        throw new IOException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NzQ4Nw==", "bodyText": "throw PathIOException with full target path. Bits of a mounted FS may have different support for concat,\ninclude inner stack trace", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454357487", "createdAt": "2020-07-14T13:31:12Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\"The number of source paths is less than 2.\");\n+    }\n+    PathData target = args.removeFirst();\n+    LinkedList<PathData> srcList = args;\n+    if (!target.exists || !target.stat.isFile()) {\n+      throw new IOException(String.format(\"Target path %s does not exist or is\"\n+              + \" not file.\", target.path));\n+    }\n+    Path[] srcArray = new Path[srcList.size()];\n+    for (int i = 0; i < args.size(); i++) {\n+      PathData src = srcList.get(i);\n+      if (!src.exists || !src.stat.isFile()) {\n+        throw new IOException(\n+            String.format(\"%s does not exist or is not file.\", src.path));\n+      }\n+      srcArray[i] = src.path;\n+    }\n+    FileSystem fs = target.fs;\n+    if (tstFs != null) {\n+      fs = tstFs;\n+    }\n+    try {\n+      fs.concat(target.path, srcArray);\n+    } catch (UnsupportedOperationException exception) {\n+      throw new IOException(\"Dest filesystem '\" + fs.getUri().getScheme()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1OTIzNg==", "bodyText": "why can't localfs be used directly? is it because it doesn't actually support it?", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454359236", "createdAt": "2020-07-14T13:34:01Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1OTUxNw==", "bodyText": "save the list of concatenated paths and then verify that the list passed in is of the correct length and order.", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454359517", "createdAt": "2020-07-14T13:34:27Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2"}, "originalPosition": 85}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "78baf53be883b8d61383f10cff6c0f760b1349c2", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/78baf53be883b8d61383f10cff6c0f760b1349c2", "committedDate": "2020-05-01T15:25:32Z", "message": "1. Fix checkstyle.\n2. Fix unit test.\n3. Add license.\n4. Handle fs doesn't support concat.\n5. Add documntation."}, "afterCommit": {"oid": "3c6fa7eca2907df27892f33295118c311b9e080c", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/3c6fa7eca2907df27892f33295118c311b9e080c", "committedDate": "2020-09-18T09:20:55Z", "message": "follow steve's suggestions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1fa1f9a66d273d267f0c45e5d5b25338a385d884", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/1fa1f9a66d273d267f0c45e5d5b25338a385d884", "committedDate": "2020-09-21T09:54:05Z", "message": "fix checkstyle and white space"}, "afterCommit": {"oid": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "committedDate": "2020-09-21T09:59:24Z", "message": "follow steve's suggestions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk0ODkyMjM2", "url": "https://github.com/apache/hadoop/pull/1993#pullrequestreview-494892236", "createdAt": "2020-09-23T17:33:54Z", "commit": {"oid": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNzozMzo1NFrOHW5SFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNzozNjoxN1rOHW5XmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc2OTIzNg==", "bodyText": "stick the java import block at the top. thanks", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r493769236", "createdAt": "2020-09-23T17:33:54Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathIOException;\n+\n+import java.io.FileNotFoundException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc2OTY5Mg==", "bodyText": "tstFs needs some vowels. How about testFs?", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r493769692", "createdAt": "2020-09-23T17:34:44Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathIOException;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc3MDIxNg==", "bodyText": "move the non java. imports to a block below java. and above the org.apache block", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r493770216", "createdAt": "2020-09-23T17:35:31Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.junit.Before;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc3MDY0OQ==", "bodyText": "consider AssertJ assertions here, as they will include the list contents in the error", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r493770649", "createdAt": "2020-09-23T17:36:17Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+import org.assertj.core.api.Assertions;\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.apache.hadoop.fs.contract.ContractTestUtils;\n+import org.apache.hadoop.test.AbstractHadoopTestBase;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat extends AbstractHadoopTestBase {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    lfs.delete(testRootDir, true);\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out =\n+          lfs.create(new Path(testRootDir, String.format(\"file-%02d\", i)));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    // Read concatenated files to build the expected file content.\n+    ByteArrayOutputStream out = new ByteArrayOutputStream();\n+    for (int i = 0; i < 10; i++) {\n+      try (InputStream in = lfs\n+          .open(new Path(testRootDir, String.format(\"file-%02d\", i)))) {\n+        IOUtils.copyBytes(in, out, 1024);\n+      }\n+    }\n+    byte[] expectContent = out.toByteArray();\n+\n+    // Do concat.\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    // Verify concat result.\n+    ContractTestUtils\n+        .assertPathExists(lfs, \"The target file doesn't exist.\", dstPath);\n+    assertEquals(1, lfs.listStatus(testRootDir).length);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b"}, "originalPosition": 106}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b98dfbfd17cb9437742dd6aa45ddf76d8af835b5", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/b98dfbfd17cb9437742dd6aa45ddf76d8af835b5", "committedDate": "2020-09-24T10:38:06Z", "message": "add command concat"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d36f969a3395e1a9f2977d57aee3f0f1b0e3521", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/5d36f969a3395e1a9f2977d57aee3f0f1b0e3521", "committedDate": "2020-09-24T10:38:06Z", "message": "1. Fix checkstyle.\n2. Fix unit test.\n3. Add license.\n4. Handle fs doesn't support concat.\n5. Add documntation."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ab61ae2c3e7b8dc42e0dcad930866c3bbbbe142", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/2ab61ae2c3e7b8dc42e0dcad930866c3bbbbe142", "committedDate": "2020-09-24T10:38:06Z", "message": "follow steve's suggestions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e45760bbfdb2879c44be43cd1a7d14731e9b095", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/7e45760bbfdb2879c44be43cd1a7d14731e9b095", "committedDate": "2020-09-24T10:38:06Z", "message": "v04"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "committedDate": "2020-09-21T09:59:24Z", "message": "follow steve's suggestions"}, "afterCommit": {"oid": "7e45760bbfdb2879c44be43cd1a7d14731e9b095", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/7e45760bbfdb2879c44be43cd1a7d14731e9b095", "committedDate": "2020-09-24T10:38:06Z", "message": "v04"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "58033012f536ff4dbcc1258a53af910e7d359730", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/58033012f536ff4dbcc1258a53af910e7d359730", "committedDate": "2020-09-24T11:48:25Z", "message": "v05"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f04c7931565682f9301f74aceed43fd7defb600a", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/f04c7931565682f9301f74aceed43fd7defb600a", "committedDate": "2020-09-27T06:34:26Z", "message": "triger yetus"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f4e8ddf5bbfb7c9c6c823f653c732ed5c3950115", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/f4e8ddf5bbfb7c9c6c823f653c732ed5c3950115", "committedDate": "2020-09-29T14:32:54Z", "message": "trigger new ci check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwMzczNTYz", "url": "https://github.com/apache/hadoop/pull/1993#pullrequestreview-500373563", "createdAt": "2020-10-01T13:56:14Z", "commit": {"oid": "f4e8ddf5bbfb7c9c6c823f653c732ed5c3950115"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQxMzo1NjoxNFrOHbLndw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQxMzo1NjoxNFrOHbLndw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODI2MzkyNw==", "bodyText": "change this to the PathIOE which takes the target.path.toString as the first param.\nThe command line tools aren't great for reporting failures -anything we can do to improve the reporting is worth trying", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r498263927", "createdAt": "2020-10-01T13:56:14Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathIOException;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem testFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified. \" + USAGE);\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\n+          \"The number of source paths is less than 2. \" + USAGE);\n+    }\n+    PathData target = args.removeFirst();\n+    LinkedList<PathData> srcList = args;\n+    if (!target.exists || !target.stat.isFile()) {\n+      throw new FileNotFoundException(String\n+          .format(\"Target path %s does not exist or is\" + \" not file.\",\n+              target.path));\n+    }\n+    Path[] srcArray = new Path[srcList.size()];\n+    for (int i = 0; i < args.size(); i++) {\n+      PathData src = srcList.get(i);\n+      if (!src.exists || !src.stat.isFile()) {\n+        throw new FileNotFoundException(\n+            String.format(\"%s does not exist or is not file.\", src.path));\n+      }\n+      srcArray[i] = src.path;\n+    }\n+    FileSystem fs = target.fs;\n+    if (testFs != null) {\n+      fs = testFs;\n+    }\n+    try {\n+      fs.concat(target.path, srcArray);\n+    } catch (UnsupportedOperationException exception) {\n+      throw new PathIOException(\"Dest filesystem '\" + fs.getUri().getScheme()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f4e8ddf5bbfb7c9c6c823f653c732ed5c3950115"}, "originalPosition": 82}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4274, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}