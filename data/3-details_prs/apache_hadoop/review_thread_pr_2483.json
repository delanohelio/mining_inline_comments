{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI1Mzk4ODE4", "number": 2483, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMTozNTozOFrOE-2dbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzo1NTo1OFrOE-4_6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MzM5NDM3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMTozNTozOFrOH8OxgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODo1OTo0NFrOH87Z3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkxODY1Nw==", "bodyText": "How about describe the parameter option as: \"sort datanodes based on the utilization so that highly utilized datanodes get scheduled first\"?", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r532918657", "createdAt": "2020-11-30T21:35:38Z", "author": {"login": "Jing9"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "diffHunk": "@@ -199,7 +199,10 @@\n       + \"\\tWhether to run the balancer during an ongoing HDFS upgrade.\"\n       + \"This is usually not desired since it will not affect used space \"\n       + \"on over-utilized machines.\"\n-      + \"\\n\\t[-asService]\\tRun as a long running service.\";\n+      + \"\\n\\t[-asService]\\tRun as a long running service.\"\n+      + \"\\n\\t[-sortTopNodes]\"\n+      + \"\\tSort over-utilized nodes by capacity to\"\n+      + \" bring down top used datanode faster.\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ddd66e0b65e51ca31cb1b628fb05505554078ba6"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY0OTg4Nw==", "bodyText": "Sounds good, will update", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r533649887", "createdAt": "2020-12-01T18:59:44Z", "author": {"login": "LeonGao91"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "diffHunk": "@@ -199,7 +199,10 @@\n       + \"\\tWhether to run the balancer during an ongoing HDFS upgrade.\"\n       + \"This is usually not desired since it will not affect used space \"\n       + \"on over-utilized machines.\"\n-      + \"\\n\\t[-asService]\\tRun as a long running service.\";\n+      + \"\\n\\t[-asService]\\tRun as a long running service.\"\n+      + \"\\n\\t[-sortTopNodes]\"\n+      + \"\\tSort over-utilized nodes by capacity to\"\n+      + \" bring down top used datanode faster.\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkxODY1Nw=="}, "originalCommit": {"oid": "ddd66e0b65e51ca31cb1b628fb05505554078ba6"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MzQzNTIyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMTo0ODoxN1rOH8PKog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxOTowMDozM1rOH87cMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkyNTA5MA==", "bodyText": "Do we need this \"if\" statement? Maybe use a Preconditions instead?", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r532925090", "createdAt": "2020-11-30T21:48:17Z", "author": {"login": "Jing9"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "diffHunk": "@@ -435,6 +444,22 @@ private long init(List<DatanodeStorageReport> reports) {\n     return Math.max(overLoadedBytes, underLoadedBytes);\n   }\n \n+  private void sortOverUtilizedNodes() {\n+    LOG.info(\"Sorting over-utilized nodes by capacity\" +\n+        \" to bring down top used datanode capacity faster\");\n+\n+    if (overUtilized instanceof List) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ddd66e0b65e51ca31cb1b628fb05505554078ba6"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY1MDQ4Mg==", "bodyText": "This is for findbugs, will check if I can get around it with precondition", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r533650482", "createdAt": "2020-12-01T19:00:33Z", "author": {"login": "LeonGao91"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "diffHunk": "@@ -435,6 +444,22 @@ private long init(List<DatanodeStorageReport> reports) {\n     return Math.max(overLoadedBytes, underLoadedBytes);\n   }\n \n+  private void sortOverUtilizedNodes() {\n+    LOG.info(\"Sorting over-utilized nodes by capacity\" +\n+        \" to bring down top used datanode capacity faster\");\n+\n+    if (overUtilized instanceof List) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkyNTA5MA=="}, "originalCommit": {"oid": "ddd66e0b65e51ca31cb1b628fb05505554078ba6"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MzgxMDM1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzo1NTo1OFrOH8SmVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxOTowMTowOFrOH87dqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk4MTMzMw==", "bodyText": "Do we need to consider StorageType (which is associated with Source)? E.g., suppose a DN has 2 storage types, one of which is highly utilized and the other is just above average. Do we want to first schedule the movement for the highly-utilized storage type on this node?", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r532981333", "createdAt": "2020-11-30T23:55:58Z", "author": {"login": "Jing9"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "diffHunk": "@@ -435,6 +444,22 @@ private long init(List<DatanodeStorageReport> reports) {\n     return Math.max(overLoadedBytes, underLoadedBytes);\n   }\n \n+  private void sortOverUtilizedNodes() {\n+    LOG.info(\"Sorting over-utilized nodes by capacity\" +\n+        \" to bring down top used datanode capacity faster\");\n+\n+    if (overUtilized instanceof List) {\n+      List<Source> list = (List<Source>) overUtilized;\n+      list.sort(\n+          (Source source1, Source source2) ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ddd66e0b65e51ca31cb1b628fb05505554078ba6"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY1MDg1Nw==", "bodyText": "Good idea, we should use utilization for storage type instead of datanode utilization. Will fix", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r533650857", "createdAt": "2020-12-01T19:01:08Z", "author": {"login": "LeonGao91"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "diffHunk": "@@ -435,6 +444,22 @@ private long init(List<DatanodeStorageReport> reports) {\n     return Math.max(overLoadedBytes, underLoadedBytes);\n   }\n \n+  private void sortOverUtilizedNodes() {\n+    LOG.info(\"Sorting over-utilized nodes by capacity\" +\n+        \" to bring down top used datanode capacity faster\");\n+\n+    if (overUtilized instanceof List) {\n+      List<Source> list = (List<Source>) overUtilized;\n+      list.sort(\n+          (Source source1, Source source2) ->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk4MTMzMw=="}, "originalCommit": {"oid": "ddd66e0b65e51ca31cb1b628fb05505554078ba6"}, "originalPosition": 50}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3139, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}