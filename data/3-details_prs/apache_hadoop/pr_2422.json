{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEyMTYzMzQw", "number": 2422, "title": "HADOOP-17311. ABFS: Logs should redact SAS signature", "bodyText": "Masking SAS signatures from logs\nHNS-OAuth\n[INFO] Results:\n[INFO]\n[INFO] Tests run: 88, Failures: 0, Errors: 0, Skipped: 0\n[INFO] Results:\n[INFO]\n[WARNING] Tests run: 459, Failures: 0, Errors: 0, Skipped: 66\n[INFO] Results:\n[INFO]\n[WARNING] Tests run: 208, Failures: 0, Errors: 0, Skipped: 24\nHNS-SharedKey\n[INFO] Results:\n[INFO]\n[INFO] Tests run: 88, Failures: 0, Errors: 0, Skipped: 0\n[INFO] Results:\n[INFO]\n[WARNING] Tests run: 459, Failures: 0, Errors: 0, Skipped: 24\n[INFO] Results:\n[INFO]\n[WARNING] Tests run: 208, Failures: 0, Errors: 0, Skipped: 16\nNonHNS-SharedKey\n[INFO] Results:\n[INFO]\n[INFO] Tests run: 88, Failures: 0, Errors: 0, Skipped: 0\n[INFO] Results:\n[INFO]\n[WARNING] Tests run: 459, Failures: 0, Errors: 0, Skipped: 247\n[INFO] Results:\n[INFO]\n[WARNING] Tests run: 208, Failures: 0, Errors: 0, Skipped: 16", "createdAt": "2020-10-29T10:13:17Z", "url": "https://github.com/apache/hadoop/pull/2422", "merged": true, "mergeCommit": {"oid": "3193d8c7938741e154320756c444f77992083106"}, "closed": true, "closedAt": "2020-11-25T14:22:11Z", "author": {"login": "bilaharith"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdXPdfigBqjM5MzU1MTU4ODg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdf2BRYgFqTUzODEzNTU5Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5e7f550f0397c06ed5f483992562566583fbbcbe", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/5e7f550f0397c06ed5f483992562566583fbbcbe", "committedDate": "2020-10-29T10:02:30Z", "message": "ABFS: Masking SAS signatures from logs"}, "afterCommit": {"oid": "0e4dbc8a2dd892c6c2088dc355fcfaf76c7bb6de", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/0e4dbc8a2dd892c6c2088dc355fcfaf76c7bb6de", "committedDate": "2020-10-29T10:17:25Z", "message": "ABFS: Masking SAS signatures from logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/8883b59a819d5aa77cb37a2a422d9039cab943a3", "committedDate": "2020-10-29T10:20:05Z", "message": "ABFS: Masking SAS signatures from logs"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0e4dbc8a2dd892c6c2088dc355fcfaf76c7bb6de", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/0e4dbc8a2dd892c6c2088dc355fcfaf76c7bb6de", "committedDate": "2020-10-29T10:17:25Z", "message": "ABFS: Masking SAS signatures from logs"}, "afterCommit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/8883b59a819d5aa77cb37a2a422d9039cab943a3", "committedDate": "2020-10-29T10:20:05Z", "message": "ABFS: Masking SAS signatures from logs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE5OTEzNDk2", "url": "https://github.com/apache/hadoop/pull/2422#pullrequestreview-519913496", "createdAt": "2020-10-29T17:33:26Z", "commit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxNzozMzoyNlrOHqnEnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxNzozODozMFrOHqnRig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0MjM5Ng==", "bodyText": "now all shaded I'm afraid. Making backporting harder already", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514442396", "createdAt": "2020-10-29T17:33:26Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -36,6 +36,7 @@\n import org.codehaus.jackson.JsonParser;\n import org.codehaus.jackson.JsonToken;\n import org.codehaus.jackson.map.ObjectMapper;\n+import com.google.common.annotations.VisibleForTesting;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0Mzc3MA==", "bodyText": "While you are there\n\nadd a catch for UnknownHostException\nmove from String.format to Log.warn(\"unknown host {}\", httpOperation,getHost()", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514443770", "createdAt": "2020-10-29T17:35:29Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java", "diffHunk": "@@ -256,7 +256,9 @@ private boolean executeHttpOperation(final int retryCount) throws AzureBlobFileS\n       }\n     } catch (IOException ex) {\n       if (ex instanceof UnknownHostException) {\n-        LOG.warn(String.format(\"Unknown host name: %s. Retrying to resolve the host name...\", httpOperation.getUrl().getHost()));\n+        LOG.warn(String.format(\n+            \"Unknown host name: %s. Retrying to resolve the host name...\",\n+            httpOperation.getHost()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NDU1NA==", "bodyText": "use LambdaTestUtils.intercept(). Not only simpler, it will (correctly) fail if the rest operation didn't actually raise an exception", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514444554", "createdAt": "2020-10-29T17:36:42Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemDelegationSAS.java", "diffHunk": "@@ -381,4 +383,39 @@ public void testProperties() throws Exception {\n \n     assertArrayEquals(propertyValue, fs.getXAttr(reqPath, propertyName));\n   }\n+\n+  @Test\n+  public void testSignatureMask() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String src = \"/testABC/test.xt\";\n+    fs.create(new Path(src));\n+    AbfsRestOperation abfsHttpRestOperation = fs.getAbfsClient()\n+        .renamePath(src, \"/testABC\" + \"/abc.txt\", null);\n+    AbfsHttpOperation result = abfsHttpRestOperation.getResult();\n+    String url = result.getSignatureMaskedUrlStr();\n+    String encodedUrl = result.getSignatureMaskedEncodedUrlStr();\n+    Assertions.assertThat(url.substring(url.indexOf(\"sig=\")))\n+        .describedAs(\"Signature query param should be masked\")\n+        .startsWith(\"sig=XXXX\");\n+    Assertions.assertThat(encodedUrl.substring(encodedUrl.indexOf(\"sig%3D\")))\n+        .describedAs(\"Signature query param should be masked\")\n+        .startsWith(\"sig%3DXXXX\");\n+  }\n+\n+  @Test\n+  public void testSignatureMaskOnExceptionMessage() {\n+    final AzureBlobFileSystem fs;\n+    String msg = null;\n+    try {\n+      fs = getFileSystem();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NTcwNg==", "bodyText": "This is complicated enough it could be pulled out into a static method, and so its handling fully tested in (new) Unit tests, as well as in the ITests.", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514445706", "createdAt": "2020-10-29T17:38:30Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -513,4 +509,45 @@ private void parseListFilesResponse(final InputStream stream) throws IOException\n   private boolean isNullInputStream(InputStream stream) {\n     return stream == null ? true : false;\n   }\n+\n+  @VisibleForTesting\n+  public String getSignatureMaskedUrlStr() {\n+    if (this.maskedUrlStr != null) {\n+      return this.maskedUrlStr;\n+    }\n+    final String urlStr = url.toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3"}, "originalPosition": 68}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMzQxMjQ3", "url": "https://github.com/apache/hadoop/pull/2422#pullrequestreview-521341247", "createdAt": "2020-11-02T05:36:04Z", "commit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwNTozNjowNVrOHr2yUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwNTo0NDo1M1rOHr26bA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0ODQzNA==", "bodyText": "create a private static final string. - private static final String SIGNATURE_QUERY_PARAM_KEY = \"sig=\";", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515748434", "createdAt": "2020-11-02T05:36:05Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -513,4 +509,45 @@ private void parseListFilesResponse(final InputStream stream) throws IOException\n   private boolean isNullInputStream(InputStream stream) {\n     return stream == null ? true : false;\n   }\n+\n+  @VisibleForTesting\n+  public String getSignatureMaskedUrlStr() {\n+    if (this.maskedUrlStr != null) {\n+      return this.maskedUrlStr;\n+    }\n+    final String urlStr = url.toString();\n+    final String qpStr = \"sig=\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0OTExOQ==", "bodyText": "Using string replace should be easier.\nint sigStartIndex = urlStr.indexOf(SIGNATURE_QUERY_PARAM_KEY);\nif (sigStartIndex == -1) {\n  // no signature query param in the url\n  return urlStr;\n}\n\nsigStartIndex += SIGNATURE_QUERY_PARAM_KEY.length();\nint sigEndIndex = urlStr.indexOf(\"&\", sigStartIndex);\nString sigValue = (sigEndIndex == -1)\n    ? urlStr.substring(sigStartIndex)\n    : urlStr.substring(sigStartIndex, sigEndIndex);\n\nreturn urlStr.replace(sigValue, \"XXXX\");", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515749119", "createdAt": "2020-11-02T05:39:11Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -513,4 +509,45 @@ private void parseListFilesResponse(final InputStream stream) throws IOException\n   private boolean isNullInputStream(InputStream stream) {\n     return stream == null ? true : false;\n   }\n+\n+  @VisibleForTesting\n+  public String getSignatureMaskedUrlStr() {\n+    if (this.maskedUrlStr != null) {\n+      return this.maskedUrlStr;\n+    }\n+    final String urlStr = url.toString();\n+    final String qpStr = \"sig=\";\n+    final int qpStrIdx = urlStr.indexOf(qpStr);\n+    if (qpStrIdx < 0) {\n+      return urlStr;\n+    }\n+    final StringBuilder sb = new StringBuilder();\n+    sb.append(urlStr, 0, qpStrIdx);\n+    sb.append(qpStr);\n+    sb.append(\"XXXX\");\n+    if (qpStrIdx + qpStr.length() < urlStr.length()) {\n+      String urlStrSecondPart = urlStr.substring(qpStrIdx + qpStr.length());\n+      int idx = urlStrSecondPart.indexOf(\"&\");\n+      if (idx > -1) {\n+        sb.append(urlStrSecondPart.substring(idx));\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc1MDUwOA==", "bodyText": "Is a header called \"sig\" getting added when SAS ?", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515750508", "createdAt": "2020-11-02T05:44:53Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsIoUtils.java", "diffHunk": "@@ -58,6 +58,9 @@ public static void dumpHeadersToDebugLog(final String origin,\n         if (key.contains(\"Cookie\")) {\n           values = \"*cookie info*\";\n         }\n+        if (key.equals(\"sig\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "committedDate": "2020-11-02T09:33:50Z", "message": "Addressing review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxNTM0MDMz", "url": "https://github.com/apache/hadoop/pull/2422#pullrequestreview-521534033", "createdAt": "2020-11-02T11:08:33Z", "commit": {"oid": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxMTowODozM1rOHr_9jQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxMTowODozM1rOHr_9jQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5ODc2NQ==", "bodyText": "Remove Str suffix", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515898765", "createdAt": "2020-11-02T11:08:33Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -61,6 +64,8 @@\n \n   private final String method;\n   private final URL url;\n+  private String maskedUrlStr;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxNTQ2Nzk2", "url": "https://github.com/apache/hadoop/pull/2422#pullrequestreview-521546796", "createdAt": "2020-11-02T11:27:57Z", "commit": {"oid": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxMToyNzo1N1rOHsAlLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxMToyNzo1N1rOHsAlLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkwODkwOA==", "bodyText": "query params ending mysig/*sig.", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515908908", "createdAt": "2020-11-02T11:27:57Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsHttpOperation.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.UnsupportedEncodingException;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.net.URLEncoder;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsHttpOperation.getAbfsHttpOperationWithFixedResult;\n+\n+public class TestAbfsHttpOperation {\n+\n+  @Test\n+  public void testForURLs()\n+      throws MalformedURLException, UnsupportedEncodingException {\n+    testIfMaskedSuccessfully(\"Where sig is the only query param\"\n+        ,\"http://www.testurl.net?sig=abcd\"\n+        ,\"http://www.testurl.net?sig=XXXX\");\n+\n+    testIfMaskedSuccessfully(\"Where sig is the first query param\"\n+        ,\"http://www.testurl.net?sig=abcd&abc=xyz\"\n+        ,\"http://www.testurl.net?sig=XXXX&abc=xyz\");\n+\n+    testIfMaskedSuccessfully(\"Where sig is neither first nor last query param\"\n+        ,\"http://www.testurl.net?lmn=abc&sig=abcd&abc=xyz\"\n+        ,\"http://www.testurl.net?lmn=abc&sig=XXXX&abc=xyz\");\n+\n+    testIfMaskedSuccessfully(\"Where sig is the last query param\"\n+        ,\"http://www.testurl.net?abc=xyz&sig=abcd\"\n+        ,\"http://www.testurl.net?abc=xyz&sig=XXXX\");\n+\n+    testIfMaskedSuccessfully(\"Where sig query param is not present\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26"}, "originalPosition": 52}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d227991654a5f1b49b3ef3bd9144e96b513f731f", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/d227991654a5f1b49b3ef3bd9144e96b513f731f", "committedDate": "2020-11-02T14:09:49Z", "message": "Adding more test cases and addressing review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "723f7206e836a7040bbc00c3b639d672e1cfa591", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/723f7206e836a7040bbc00c3b639d672e1cfa591", "committedDate": "2020-11-03T06:16:01Z", "message": "Checkstyle fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd872b60e7ed0e402b903a90cdf392da9d6e3ada", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/bd872b60e7ed0e402b903a90cdf392da9d6e3ada", "committedDate": "2020-11-04T07:54:40Z", "message": "Fixing findbugs issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4MTM1NTk3", "url": "https://github.com/apache/hadoop/pull/2422#pullrequestreview-538135597", "createdAt": "2020-11-25T03:45:09Z", "commit": {"oid": "bd872b60e7ed0e402b903a90cdf392da9d6e3ada"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3521, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}