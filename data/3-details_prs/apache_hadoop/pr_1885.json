{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1MjQ0MDk1", "number": 1885, "title": "HDFS-13639. SlotReleaser is not fast enough", "bodyText": "Signed-off-by: sunlisheng sunlisheng@xiaomi.com\nNOTICE\nPlease create an issue in ASF JIRA before opening a pull request,\nand you need to set the title of the pull request which starts with\nthe corresponding JIRA issue number. (e.g. HADOOP-XXXXX. Fix a typo in YYY.)\nFor more details, please see https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute", "createdAt": "2020-03-08T09:11:00Z", "url": "https://github.com/apache/hadoop/pull/1885", "merged": true, "mergeCommit": {"oid": "be374faf429d28561dd9c582f5c55451213d89a4"}, "closed": true, "closedAt": "2020-05-21T20:21:17Z", "author": {"login": "leosunli"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABchkc0zgFqTQxMjc3ODIyMg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcjP04VAFqTQxNTcyMjEyMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyNzc4MjIy", "url": "https://github.com/apache/hadoop/pull/1885#pullrequestreview-412778222", "createdAt": "2020-05-15T16:04:57Z", "commit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjowNDo1N1rOGWK7Uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjoxMjoyNlrOGWLL-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDg4Mw==", "bodyText": "suggeset to use assertEquals()", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425900883", "createdAt": "2020-05-15T16:04:57Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDk5Mw==", "bodyText": "ditto", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425900993", "createdAt": "2020-05-15T16:05:08Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzY0Nw==", "bodyText": "please add test timeout", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425903647", "createdAt": "2020-05-15T16:09:45Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzgyNA==", "bodyText": "Can we make this sleep time shorter? Waiting for 15 seconds seems too excessive. You may have to change the timeout configuration.", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425903824", "createdAt": "2020-05-15T16:10:01Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNDgzMg==", "bodyText": "is the mini cluster required? starting a mini cluster takes time and prone to flaky failures. Would be nice to avoid using it.", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425904832", "createdAt": "2020-05-15T16:11:54Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTA1MQ==", "bodyText": "assertEquals()", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425905051", "createdAt": "2020-05-15T16:12:18Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    // restart the datanode to invalidate the cache\n+    cluster.restartDataNode(0);\n+    Thread.sleep(1000);\n+    // after the restart, new allocation and release should not be affect\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    Slot slot2 = null;\n+    try {\n+      slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+    } catch (ClosedChannelException ce) {\n+\n+    }\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(2000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTE0NA==", "bodyText": "ditto", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425905144", "createdAt": "2020-05-15T16:12:26Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    // restart the datanode to invalidate the cache\n+    cluster.restartDataNode(0);\n+    Thread.sleep(1000);\n+    // after the restart, new allocation and release should not be affect\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    Slot slot2 = null;\n+    try {\n+      slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+    } catch (ClosedChannelException ce) {\n+\n+    }\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(2000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 95}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyNzkwMDA0", "url": "https://github.com/apache/hadoop/pull/1885#pullrequestreview-412790004", "createdAt": "2020-05-15T16:21:16Z", "commit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjoyMToxN1rOGWLfyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjoyMToxN1rOGWLfyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw==", "bodyText": "not that familiar with short circuit read. Is true that it's single threaded?", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425910217", "createdAt": "2020-05-15T16:21:17Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {\n+          try {\n+            if (domainSocket == null || !domainSocket.isOpen()) {\n+              // we are running in single thread mode, no protection needed for", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyODExMzU2", "url": "https://github.com/apache/hadoop/pull/1885#pullrequestreview-412811356", "createdAt": "2020-05-15T16:51:22Z", "commit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjo1MToyMlrOGWMiNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjo1MToyMlrOGWMiNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNzIyMw==", "bodyText": "If retries becomes 0, the code would silently ignore the error. How should we handle this case better?", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425927223", "createdAt": "2020-05-15T16:51:22Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 34}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fef36fc1eceb2850ee353bc2dddc0bdb95bd3fc", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/7fef36fc1eceb2850ee353bc2dddc0bdb95bd3fc", "committedDate": "2020-05-19T13:31:11Z", "message": "SlotReleaser is not fast enough\n\nSigned-off-by: sunlisheng <sunlisheng@xiaomi.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71670765213b2c51eeba01b01f74c283a2e6775e", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/71670765213b2c51eeba01b01f74c283a2e6775e", "committedDate": "2020-05-19T13:31:11Z", "message": "Fix TestShortCircuitCache UT\n\nSigned-off-by: sunlisheng <sunlisheng@xiaomi.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b", "author": {"user": null}, "url": "https://github.com/apache/hadoop/commit/49e8948ec052fcd2f45626e7f360c8553821654b", "committedDate": "2020-03-09T14:54:48Z", "message": "Fix TestShortCircuitCache UT\n\nSigned-off-by: sunlisheng <sunlisheng@xiaomi.com>"}, "afterCommit": {"oid": "2f99cb12f9c4aa0824698d5426118de37ab8dd54", "author": {"user": {"login": "leosunli", "name": null}}, "url": "https://github.com/apache/hadoop/commit/2f99cb12f9c4aa0824698d5426118de37ab8dd54", "committedDate": "2020-05-19T13:31:11Z", "message": "Fix TestShortCircuitCache\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2c8c586801dec07d8e6b0302b43c012112fc92b", "author": {"user": {"login": "leosunli", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f2c8c586801dec07d8e6b0302b43c012112fc92b", "committedDate": "2020-05-19T13:38:23Z", "message": "Fix TestShortCircuitCache\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2f99cb12f9c4aa0824698d5426118de37ab8dd54", "author": {"user": {"login": "leosunli", "name": null}}, "url": "https://github.com/apache/hadoop/commit/2f99cb12f9c4aa0824698d5426118de37ab8dd54", "committedDate": "2020-05-19T13:31:11Z", "message": "Fix TestShortCircuitCache\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>"}, "afterCommit": {"oid": "f2c8c586801dec07d8e6b0302b43c012112fc92b", "author": {"user": {"login": "leosunli", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f2c8c586801dec07d8e6b0302b43c012112fc92b", "committedDate": "2020-05-19T13:38:23Z", "message": "Fix TestShortCircuitCache\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE0NzUwNzAw", "url": "https://github.com/apache/hadoop/pull/1885#pullrequestreview-414750700", "createdAt": "2020-05-19T19:18:15Z", "commit": {"oid": "f2c8c586801dec07d8e6b0302b43c012112fc92b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxOToxODoxNVrOGXvExQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxOToyMToxOFrOGXvLig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MTcwMQ==", "bodyText": "Got it. The release scheduler has only one thread.\n/**\n\nThe executor service that runs the cacheCleaner.\n*/\nprivate final ScheduledThreadPoolExecutor releaserExecutor\n= new ScheduledThreadPoolExecutor(1, new ThreadFactoryBuilder().\nsetDaemon(true).setNameFormat(\"ShortCircuitCache_SlotReleaser\").\nbuild());", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427541701", "createdAt": "2020-05-19T19:18:15Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {\n+          try {\n+            if (domainSocket == null || !domainSocket.isOpen()) {\n+              // we are running in single thread mode, no protection needed for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MjU3Ng==", "bodyText": "Ok. That's fine.", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427542576", "createdAt": "2020-05-19T19:19:53Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNDgzMg=="}, "originalCommit": {"oid": "49e8948ec052fcd2f45626e7f360c8553821654b"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MzQzNA==", "bodyText": "This one doesn't look right. I think you want to remove \"== 0\"?", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427543434", "createdAt": "2020-05-19T19:21:18Z", "author": {"login": "jojochuang"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -910,4 +912,94 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test(timeout = 60000)\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final ShortCircuitCache cache =\n+          fs.getClient().getClientContext().getShortCircuitCache();\n+      DomainPeer peer = getDomainPeerToDn(conf);\n+      MutableBoolean usedPeer = new MutableBoolean(false);\n+      ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+      final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+          .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+      // Allocating the first shm slot requires using up a peer.\n+      Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+      Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+      cache.scheduleSlotReleaser(slot1);\n+\n+      Thread.sleep(2000);\n+      cache.scheduleSlotReleaser(slot2);\n+      Thread.sleep(2000);\n+      Assert.assertEquals(0,\n+          cluster.getDataNodes().get(0).getShortCircuitRegistry().getShmNum());\n+      Assert.assertEquals(0, cache.getDfsClientShmManager().getShmNum());\n+    } finally {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 60000)\n+  public void testDNRestart() throws Exception {\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final ShortCircuitCache cache =\n+          fs.getClient().getClientContext().getShortCircuitCache();\n+      DomainPeer peer = getDomainPeerToDn(conf);\n+      MutableBoolean usedPeer = new MutableBoolean(false);\n+      ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+      final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+          .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+      // Allocating the first shm slot requires using up a peer.\n+      Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+      // restart the datanode to invalidate the cache\n+      cluster.restartDataNode(0);\n+      Thread.sleep(1000);\n+      // after the restart, new allocation and release should not be affect\n+      cache.scheduleSlotReleaser(slot1);\n+\n+      Slot slot2 = null;\n+      try {\n+        slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+            \"testReleaseSlotReuseDomainSocket_client\");\n+      } catch (ClosedChannelException ce) {\n+\n+      }\n+      cache.scheduleSlotReleaser(slot2);\n+      Thread.sleep(2000);\n+      Assert.assertEquals(0, cluster.getDataNodes().get(0)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f2c8c586801dec07d8e6b0302b43c012112fc92b"}, "originalPosition": 103}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8652c1b4c4ca5e34598f45b05bcebe1aa679c48a", "author": {"user": {"login": "leosunli", "name": null}}, "url": "https://github.com/apache/hadoop/commit/8652c1b4c4ca5e34598f45b05bcebe1aa679c48a", "committedDate": "2020-05-20T01:56:47Z", "message": "Fix UT\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cc0e0eccdabe8a811d4e8adeb66c7fb4da4774e7", "author": {"user": {"login": "leosunli", "name": null}}, "url": "https://github.com/apache/hadoop/commit/cc0e0eccdabe8a811d4e8adeb66c7fb4da4774e7", "committedDate": "2020-05-20T01:52:51Z", "message": "Fix UT\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>"}, "afterCommit": {"oid": "8652c1b4c4ca5e34598f45b05bcebe1aa679c48a", "author": {"user": {"login": "leosunli", "name": null}}, "url": "https://github.com/apache/hadoop/commit/8652c1b4c4ca5e34598f45b05bcebe1aa679c48a", "committedDate": "2020-05-20T01:56:47Z", "message": "Fix UT\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE1NzIyMTIy", "url": "https://github.com/apache/hadoop/pull/1885#pullrequestreview-415722122", "createdAt": "2020-05-20T21:19:46Z", "commit": {"oid": "8652c1b4c4ca5e34598f45b05bcebe1aa679c48a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4455, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}