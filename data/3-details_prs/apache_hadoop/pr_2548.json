{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQwMDA2Nzc0", "number": 2548, "title": "HADOOP-17475. ABFS: Implementing ListStatusRemoteIterator", "bodyText": "This is a draft PR not ready fo review.", "createdAt": "2020-12-15T06:18:29Z", "url": "https://github.com/apache/hadoop/pull/2548", "merged": true, "mergeCommit": {"oid": "5f34271bb1449d98629e2581fc691226276995e1"}, "closed": true, "closedAt": "2021-02-04T13:36:20Z", "author": {"login": "bilaharith"}, "timelineItems": {"totalCount": 38, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdmUZ1ygH2gAyNTQwMDA2Nzc0OmYwMGNkNGUzMDM3MjJiYmQ3ZTI4MzAzNGM0MWRlZjc0ZjdjMzVkOGM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABd2hK5fgH2gAyNTQwMDA2Nzc0OmIwMTY1OWEyMGMyYTI2ZmRmNDVhMTllMDczZGMyZWI4Yjc2ZDZmNmE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f00cd4e303722bbd7e283034c41def74f7c35d8c", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f00cd4e303722bbd7e283034c41def74f7c35d8c", "committedDate": "2020-12-15T06:32:41Z", "message": "Implementing ListStatusRemoteIterator"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f6cab07bc1b6587baeba0f460a1176f6627bdd74", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f6cab07bc1b6587baeba0f460a1176f6627bdd74", "committedDate": "2020-12-15T06:15:49Z", "message": "Implementing ListStatusRemoteIterator"}, "afterCommit": {"oid": "f00cd4e303722bbd7e283034c41def74f7c35d8c", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f00cd4e303722bbd7e283034c41def74f7c35d8c", "committedDate": "2020-12-15T06:32:41Z", "message": "Implementing ListStatusRemoteIterator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "baeceb0c4b9efb9513f3cff102f47c152c09e137", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/baeceb0c4b9efb9513f3cff102f47c152c09e137", "committedDate": "2020-12-30T03:31:50Z", "message": "Added test cases. Improved ListIteraor logic."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/13ddf5274a425bf83c8b25176f53b9e10be03102", "committedDate": "2020-12-30T11:14:03Z", "message": "Making the server calls as a background activity"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "01bb58ef5f8657bf22bb8f8e0c98cd53fd426664", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/01bb58ef5f8657bf22bb8f8e0c98cd53fd426664", "committedDate": "2020-12-30T11:09:26Z", "message": "Making the server calls as a background activity"}, "afterCommit": {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/13ddf5274a425bf83c8b25176f53b9e10be03102", "committedDate": "2020-12-30T11:14:03Z", "message": "Making the server calls as a background activity"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwMDI0NzQw", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-560024740", "createdAt": "2020-12-30T12:15:56Z", "commit": {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMjoxNTo1NlrOIMr_Tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxMjozNzowNVrOIMsWrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NDU0Mw==", "bodyText": "ArrayBlockingQueue", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550174543", "createdAt": "2020-12-30T12:15:56Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NTMwNQ==", "bodyText": "ioExcetion and currentIterator to null", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550175305", "createdAt": "2020-12-30T12:18:28Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =\n+      new LinkedList<>();\n+\n+  private boolean firstRead = true;\n+  private String continuation;\n+  private ListIterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) throws IOException {\n+    this.path = path;\n+    this.abfsStore = abfsStore;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NTc2MQ==", "bodyText": "Move to line 106", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550175761", "createdAt": "2020-12-30T12:19:46Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =\n+      new LinkedList<>();\n+\n+  private boolean firstRead = true;\n+  private String continuation;\n+  private ListIterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) throws IOException {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    fetchAllAsync();\n+    updateCurrentIterator();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    synchronized (this) {\n+      while (!isIterationComplete() && iteratorsQueue.isEmpty()) {\n+        try {\n+          this.wait();\n+        } catch (InterruptedException e) {\n+          Thread.currentThread().interrupt();\n+          LOG.error(\"Thread got interrupted: {}\", e);\n+        }\n+      }\n+      if (!iteratorsQueue.isEmpty()) {\n+        currIterator = iteratorsQueue.poll();\n+      } else if (ioException != null) {\n+        throw ioException;\n+      }\n+    }\n+  }\n+\n+  private void fetchAllAsync() {\n+    CompletableFuture.supplyAsync(() -> {\n+      while (!isIterationComplete()) {\n+        List<FileStatus> fileStatuses = new ArrayList<>();\n+        try {\n+          continuation = abfsStore\n+              .listStatus(path, null, fileStatuses, FETCH_ALL_FALSE,\n+                  continuation);\n+        } catch (IOException e) {\n+          ioException = e;\n+          return null;\n+        } finally {\n+          if (firstRead) {\n+            firstRead = false;\n+          }\n+        }\n+        if (fileStatuses != null && !fileStatuses.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NjA0Nw==", "bodyText": "we just need to add to queue", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550176047", "createdAt": "2020-12-30T12:20:55Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =\n+      new LinkedList<>();\n+\n+  private boolean firstRead = true;\n+  private String continuation;\n+  private ListIterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) throws IOException {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    fetchAllAsync();\n+    updateCurrentIterator();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    synchronized (this) {\n+      while (!isIterationComplete() && iteratorsQueue.isEmpty()) {\n+        try {\n+          this.wait();\n+        } catch (InterruptedException e) {\n+          Thread.currentThread().interrupt();\n+          LOG.error(\"Thread got interrupted: {}\", e);\n+        }\n+      }\n+      if (!iteratorsQueue.isEmpty()) {\n+        currIterator = iteratorsQueue.poll();\n+      } else if (ioException != null) {\n+        throw ioException;\n+      }\n+    }\n+  }\n+\n+  private void fetchAllAsync() {\n+    CompletableFuture.supplyAsync(() -> {\n+      while (!isIterationComplete()) {\n+        List<FileStatus> fileStatuses = new ArrayList<>();\n+        try {\n+          continuation = abfsStore\n+              .listStatus(path, null, fileStatuses, FETCH_ALL_FALSE,\n+                  continuation);\n+        } catch (IOException e) {\n+          ioException = e;\n+          return null;\n+        } finally {\n+          if (firstRead) {\n+            firstRead = false;\n+          }\n+        }\n+        if (fileStatuses != null && !fileStatuses.isEmpty()) {\n+          iteratorsQueue.add(fileStatuses.listIterator());\n+          synchronized (this) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3ODU5OQ==", "bodyText": "Let us avoid blocking in the ctor", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550178599", "createdAt": "2020-12-30T12:29:39Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =\n+      new LinkedList<>();\n+\n+  private boolean firstRead = true;\n+  private String continuation;\n+  private ListIterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) throws IOException {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    fetchAllAsync();\n+    updateCurrentIterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE4MDUyNg==", "bodyText": "spacing etc\ncontinuation.IsEmpty", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550180526", "createdAt": "2020-12-30T12:37:05Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -862,16 +871,16 @@ public FileStatus getFileStatus(final Path path) throws IOException {\n             startFrom);\n \n     final String relativePath = getRelativePath(path);\n-    String continuation = null;\n \n-    // generate continuation token if a valid startFrom is provided.\n-    if (startFrom != null && !startFrom.isEmpty()) {\n-      continuation = getIsNamespaceEnabled()\n-              ? generateContinuationTokenForXns(startFrom)\n-              : generateContinuationTokenForNonXns(relativePath, startFrom);\n+    if(continuation==null ||continuation.length()<1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102"}, "originalPosition": 34}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc40333f784888c1c381b07472a077d455fd499a", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/fc40333f784888c1c381b07472a077d455fd499a", "committedDate": "2021-01-11T04:38:13Z", "message": "Making the async call exit if the queue is full. Adding more test cases."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "committedDate": "2021-01-11T04:47:55Z", "message": "Merge branch 'trunk' into lsitr"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY1MDcxMTcw", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-565071170", "createdAt": "2021-01-11T05:01:18Z", "commit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNTowMToxOFrOIRBymQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNTowMToxOFrOIRBymQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcyNjA0MQ==", "bodyText": "needs to be done under lock", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554726041", "createdAt": "2021-01-11T05:01:18Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      isAsyncInProgress = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 134}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY1MDczNTgw", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-565073580", "createdAt": "2021-01-11T05:13:19Z", "commit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNToxMzoxOVrOIRCSYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNTo0MTo1MVrOIRDixQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDczNDE3OQ==", "bodyText": "do under config", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554734179", "createdAt": "2021-01-11T05:13:19Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -982,6 +984,14 @@ public boolean exists(Path f) throws IOException {\n     return super.exists(f);\n   }\n \n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(Path path)\n+      throws IOException {\n+    LOG.debug(\"AzureBlobFileSystem.listStatusIterator path : {}\", path);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc0NDk4OQ==", "bodyText": "is it right to catch interrupted exception?", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554744989", "createdAt": "2021-01-11T05:28:31Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc0ODkzNw==", "bodyText": "do next and ensure correct exception", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554748937", "createdAt": "2021-01-11T05:33:52Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc0OTcxMQ==", "bodyText": "filename", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554749711", "createdAt": "2021-01-11T05:34:48Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc1MDY5NQ==", "bodyText": "Next() and then ensure hasnext return false and NExt throws", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554750695", "createdAt": "2021-01-11T05:35:59Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc1Mjg4OA==", "bodyText": "rename throughout", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554752888", "createdAt": "2021-01-11T05:39:12Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc1NDc1Nw==", "bodyText": "make queue empty by iterating and then set the exception and do another hasNext", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554754757", "createdAt": "2021-01-11T05:41:51Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n+        .listStatusIterator(rootPath);\n+    Thread.sleep(1000);\n+\n+    String exceptionMessage = \"test exception\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 125}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY2MDk3NDE4", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-566097418", "createdAt": "2021-01-12T09:47:18Z", "commit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwOTo0NzoxOFrOIR5jSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwOTo0NzoxOFrOIR5jSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTYzOTYyNg==", "bodyText": "continuation.isEmpty()", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r555639626", "createdAt": "2021-01-12T09:47:18Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -865,16 +873,16 @@ public FileStatus getFileStatus(final Path path) throws IOException {\n             startFrom);\n \n     final String relativePath = getRelativePath(path);\n-    String continuation = null;\n \n-    // generate continuation token if a valid startFrom is provided.\n-    if (startFrom != null && !startFrom.isEmpty()) {\n-      continuation = getIsNamespaceEnabled()\n-              ? generateContinuationTokenForXns(startFrom)\n-              : generateContinuationTokenForNonXns(relativePath, startFrom);\n+    if (continuation == null || continuation.length() < 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY2MTY3OTQy", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-566167942", "createdAt": "2021-01-12T11:14:03Z", "commit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxMToxNDowM1rOIR84uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxMToxNDowM1rOIR84uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTY5NDI2Nw==", "bodyText": "We are here because the thread already got interrupted ? why call interrupt ?", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r555694267", "createdAt": "2021-01-12T11:14:03Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 101}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY2MTcwODIz", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-566170823", "createdAt": "2021-01-12T11:17:58Z", "commit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxMToxNzo1OFrOIR9Buw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxMToxNzo1OFrOIR9Buw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTY5NjU3MQ==", "bodyText": "Instead of testing failure case by setting ioException field, try to mock abfsStore or lower to give a failure response.", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r555696571", "createdAt": "2021-01-12T11:17:58Z", "author": {"login": "snvijaya"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n+        .listStatusIterator(rootPath);\n+    Thread.sleep(1000);\n+\n+    String exceptionMessage = \"test exception\";\n+    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n+        new IOException(exceptionMessage));\n+    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 128}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY2MTcxMDM2", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-566171036", "createdAt": "2021-01-12T11:18:15Z", "commit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3MTY0Nzgz", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-567164783", "createdAt": "2021-01-13T12:16:46Z", "commit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QxMjoxNjo0N1rOISstVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QxMjoyODoxNlrOIStFow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3Nzc4Mg==", "bodyText": "use interface for operations, as with org.apache.hadoop.fs.s3a.impl.ListingOperationCallbacks", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556477782", "createdAt": "2021-01-13T12:16:47Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3ODU2NA==", "bodyText": "if, at the end of the loop I keep call hasNext() repeatedly, what happens?", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556478564", "createdAt": "2021-01-13T12:18:22Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MDUzNA==", "bodyText": "should only be scheduled if there isn't one already in progress", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556480534", "createdAt": "2021-01-13T12:22:08Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    CompletableFuture.runAsync(() -> asyncOp());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MDkyOA==", "bodyText": "these are going to have to be Atomic, aren't they?", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556480928", "createdAt": "2021-01-13T12:22:49Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MjE0OQ==", "bodyText": "this is why you need a list callback. This is low-level field abuse. Better to have a {{getAbfsStoreForTesting()}} call, at the very least", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556482149", "createdAt": "2021-01-13T12:25:01Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n+        .listStatusIterator(rootPath);\n+    Thread.sleep(1000);\n+\n+    String exceptionMessage = \"test exception\";\n+    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n+        new IOException(exceptionMessage));\n+    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n+        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n+\n+    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n+        \"When ioException is not null and queue is empty exception should be \"\n+            + \"thrown\").isInstanceOf(IOException.class)\n+        .hasMessage(exceptionMessage);\n+  }\n+\n+  private void setPrivateField(Object obj, Class classObj, String fieldName,\n+      Object value) throws NoSuchFieldException, IllegalAccessException {\n+    Field field = classObj.getDeclaredField(fieldName);\n+    field.setAccessible(true);\n+    field.set(obj, value);\n+  }\n+\n+  private void setPrivateFinalField(Object obj, Class classObj,\n+      String fieldName, Object value)\n+      throws NoSuchFieldException, IllegalAccessException {\n+    Field field = classObj.getDeclaredField(fieldName);\n+    field.setAccessible(true);\n+    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n+    modifiersField.setAccessible(true);\n+    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n+    field.set(obj, value);\n+  }\n+\n+  private List<String> createFiles(int numFiles, String rootPathStr,\n+      String filenamePrefix)\n+      throws ExecutionException, InterruptedException, IOException {\n+    final List<Future<Void>> tasks = new ArrayList<>();\n+    final List<String> fileNames = new ArrayList<>();\n+    ExecutorService es = Executors.newFixedThreadPool(10);\n+    final Path rootPath = new Path(rootPathStr);\n+    for (int i = 0; i < numFiles; i++) {\n+      final Path filePath = new Path(rootPath, filenamePrefix + i);\n+      Callable<Void> callable = new Callable<Void>() {\n+        @Override\n+        public Void call() throws Exception {\n+          getFileSystem().create(filePath);\n+          fileNames.add(makeQualified(filePath).toString());\n+          return null;\n+        }\n+      };\n+      tasks.add(es.submit(callable));\n+    }\n+    for (Future<Void> task : tasks) {\n+      task.get();\n+    }\n+    es.shutdownNow();\n+    return fileNames;\n+  }\n+\n+  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4Mjg3Mg==", "bodyText": "also need to test a loop of it.next() until NoMoreElementsException is raised", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556482872", "createdAt": "2021-01-13T12:26:22Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MzcyOQ==", "bodyText": "this is an abuse of internals. If you use a callback for the listing operations, you can explicitly raise the IOE instead.", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556483729", "createdAt": "2021-01-13T12:27:47Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n+        .listStatusIterator(rootPath);\n+    Thread.sleep(1000);\n+\n+    String exceptionMessage = \"test exception\";\n+    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4NDAwMw==", "bodyText": "needs to go into the non-shaded bit of hadoop imports.", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556484003", "createdAt": "2021-01-13T12:28:16Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -37,6 +37,8 @@\n import java.util.concurrent.Executors;\n import java.util.concurrent.Future;\n \n+import org.apache.hadoop.fs.RemoteIterator;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83ec324f866e78bbacd4416f13d607e5b901b374", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/83ec324f866e78bbacd4416f13d607e5b901b374", "committedDate": "2021-01-14T18:29:34Z", "message": "Addressing review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6e54076877b4ee4d3e5d2acacacbd10e70bee1b", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/a6e54076877b4ee4d3e5d2acacacbd10e70bee1b", "committedDate": "2021-01-15T05:37:37Z", "message": "Putting empty iterator in finally block. This is to prevent the take from hanging in case the first call itself result in exception"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9ff82c25d3000b4f531bd0b397b7610919ab31c", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/b9ff82c25d3000b4f531bd0b397b7610919ab31c", "committedDate": "2021-01-15T10:12:18Z", "message": "Throwing FileNotFoundException when the directory does not exist"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2b3ad42d2a79f33f49135a5c44ab29a41f9caa1", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f2b3ad42d2a79f33f49135a5c44ab29a41f9caa1", "committedDate": "2021-01-15T11:08:20Z", "message": "Making the put on finally non blocking"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY5MTk0MDQ1", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-569194045", "createdAt": "2021-01-15T11:51:44Z", "commit": {"oid": "b9ff82c25d3000b4f531bd0b397b7610919ab31c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMTo1MTo0NVrOIUZVjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMTo1MTo0NVrOIUZVjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI1NzU0OQ==", "bodyText": "did u want to do this even when u did not have an exception?", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r558257549", "createdAt": "2021-01-15T11:51:45Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private synchronized boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (asyncOpLock) {\n+        try {\n+          iteratorsQueue.put(Collections.emptyIterator());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9ff82c25d3000b4f531bd0b397b7610919ab31c"}, "originalPosition": 135}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "committedDate": "2021-01-18T05:31:56Z", "message": "Adding empty iterator from the catch block"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcwMzE2Mzgy", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-570316382", "createdAt": "2021-01-18T09:39:07Z", "commit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwOTozOTowOFrOIVg_cQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQwOTozOTowOFrOIVg_cQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTQzMTUzNw==", "bodyText": "|| ioException != null", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r559431537", "createdAt": "2021-01-18T09:39:08Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private synchronized boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 109}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxMTc0MzA5", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-571174309", "createdAt": "2021-01-19T11:59:20Z", "commit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMTo1OToyMFrOIWLXfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMjoxMjozNVrOIWLywg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyNTgyMg==", "bodyText": "should go above so imports are in order; goal is to reduce conflict between patches, branches and versions", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560125822", "createdAt": "2021-01-19T11:59:20Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -45,6 +45,8 @@\n import org.apache.commons.lang3.ArrayUtils;\n import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n import org.apache.hadoop.fs.azurebfs.services.AbfsClientThrottlingIntercept;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyNjczMQ==", "bodyText": "would you ever want to make this not optional? one code path == better testing", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560126731", "createdAt": "2021-01-19T12:01:00Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -982,6 +985,19 @@ public boolean exists(Path f) throws IOException {\n     return super.exists(f);\n   }\n \n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(Path path)\n+      throws IOException {\n+    LOG.debug(\"AzureBlobFileSystem.listStatusIterator path : {}\", path);\n+    if (abfsStore.getAbfsConfiguration().enableAbfsListIterator()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyODA5Ng==", "bodyText": "you can just use a () -> { } closure here", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560128096", "createdAt": "2021-01-19T12:03:36Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java", "diffHunk": "@@ -0,0 +1,339 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.ListingSupport;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.ArgumentMatchers.anyList;\n+import static org.mockito.ArgumentMatchers.nullable;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Test ListStatusRemoteIterator operation.\n+ */\n+public class ITestAbfsListStatusIterator extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAbfsListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListStatusRemoteIterator() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());\n+    RemoteIterator<FileStatus> fsItr = new AbfsListStatusRemoteIterator(\n+        getFileSystem().getFileStatus(testDir), listngSupport);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should be instance of \"\n+            + \"AbfsListStatusRemoteIterator by default\")\n+        .isInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    while (fsItr.hasNext()) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+    verify(listngSupport, Mockito.atLeast(100))\n+        .listStatus(any(Path.class), nullable(String.class),\n+            anyList(), anyBoolean(),\n+            nullable(String.class));\n+  }\n+\n+  @Test\n+  public void testListStatusRemoteIteratorWithoutHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());\n+    RemoteIterator<FileStatus> fsItr = new AbfsListStatusRemoteIterator(\n+        getFileSystem().getFileStatus(testDir), listngSupport);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should be instance of \"\n+            + \"AbfsListStatusRemoteIterator by default\")\n+        .isInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    for (int i = 0; i < TEST_FILES_NUMBER; i++) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+            \"next() should throw NoSuchElementException since next has been \"\n+                + \"called \" + TEST_FILES_NUMBER + \" times\")\n+        .isInstanceOf(NoSuchElementException.class);\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+    verify(listngSupport, Mockito.atLeast(100))\n+        .listStatus(any(Path.class), nullable(String.class),\n+            anyList(), anyBoolean(),\n+            nullable(String.class));\n+  }\n+\n+  @Test\n+  public void testWithAbfsIteratorDisabled() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    setEnableAbfsIterator(false);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    RemoteIterator<FileStatus> fsItr =\n+        getFileSystem().listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should not be instance of \"\n+            + \"AbfsListStatusRemoteIterator when it is disabled\")\n+        .isNotInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    while (fsItr.hasNext()) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testWithAbfsIteratorDisabledWithutHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    setEnableAbfsIterator(false);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    RemoteIterator<FileStatus> fsItr =\n+        getFileSystem().listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should not be instance of \"\n+            + \"AbfsListStatusRemoteIterator when it is disabled\")\n+        .isNotInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    for (int i = 0; i < TEST_FILES_NUMBER; i++) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+            \"next() should throw NoSuchElementException since next has been \"\n+                + \"called \" + TEST_FILES_NUMBER + \" times\")\n+        .isInstanceOf(NoSuchElementException.class);\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    RemoteIterator fsItr =\n+        new AbfsListStatusRemoteIterator(getFileSystem().getFileStatus(testDir),\n+            getFileSystem().getAbfsStore());\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next())\n+        .describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\")\n+        .isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    RemoteIterator<FileStatus> fsItr = getFileSystem()\n+        .listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\")\n+        .isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String testFileName = \"testFile\";\n+    Path testFile = new Path(testFileName);\n+    getFileSystem().create(testFile);\n+    setPageSize(10);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(testFile);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+    Assertions.assertThat(fsItr.next().getPath().toString())\n+        .describedAs(\"next returns the file itself\")\n+        .endsWith(testFileName);\n+  }\n+\n+  @Test\n+  public void testIOException() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    getFileSystem().mkdirs(testDir);\n+\n+    String exceptionMessage = \"test exception\";\n+    ListingSupport lsSupport =getMockListingSupport(exceptionMessage);\n+    RemoteIterator fsItr =\n+        new AbfsListStatusRemoteIterator(getFileSystem().getFileStatus(testDir),\n+        lsSupport);\n+\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+        \"When ioException is not null and queue is empty exception should be \"\n+            + \"thrown\")\n+        .isInstanceOf(IOException.class)\n+        .hasMessage(exceptionMessage);\n+  }\n+\n+  @Test\n+  public void testNonExistingPath() throws Throwable {\n+    Path nonExistingDir = new Path(\"nonExistingPath\");\n+    Assertions.assertThatThrownBy(\n+        () -> getFileSystem().listStatusIterator(nonExistingDir)).describedAs(\n+        \"test the listStatusIterator call on a path which is not \"\n+            + \"present should result in FileNotFoundException\")\n+        .isInstanceOf(FileNotFoundException.class);\n+  }\n+\n+  private ListingSupport getMockListingSupport(String exceptionMessage) {\n+    return new ListingSupport() {\n+      @Override\n+      public FileStatus[] listStatus(Path path) throws IOException {\n+        return null;\n+      }\n+\n+      @Override\n+      public FileStatus[] listStatus(Path path, String startFrom)\n+          throws IOException {\n+        return null;\n+      }\n+\n+      @Override\n+      public String listStatus(Path path, String startFrom,\n+          List<FileStatus> fileStatuses, boolean fetchAll, String continuation)\n+          throws IOException {\n+        throw new IOException(exceptionMessage);\n+      }\n+    };\n+  }\n+\n+  private Path createTestDirectory() throws IOException {\n+    String testDirectoryName = \"testDirectory\" + System.currentTimeMillis();\n+    Path testDirectory = new Path(testDirectoryName);\n+    getFileSystem().mkdirs(testDirectory);\n+    return testDirectory;\n+  }\n+\n+  private void setEnableAbfsIterator(boolean shouldEnable) throws IOException {\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(getFileSystem());\n+    abfsStore.getAbfsConfiguration().setEnableAbfsListIterator(shouldEnable);\n+  }\n+\n+  private void setPageSize(int pageSize) throws IOException {\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(getFileSystem());\n+    abfsStore.getAbfsConfiguration().setListMaxResults(pageSize);\n+  }\n+\n+  private List<String> createFilesUnderDirectory(int numFiles, Path rootPath,\n+      String filenamePrefix)\n+      throws ExecutionException, InterruptedException, IOException {\n+    final List<Future<Void>> tasks = new ArrayList<>();\n+    final List<String> fileNames = new ArrayList<>();\n+    ExecutorService es = Executors.newFixedThreadPool(10);\n+    for (int i = 0; i < numFiles; i++) {\n+      final Path filePath = new Path(rootPath, filenamePrefix + i);\n+      Callable<Void> callable = new Callable<Void>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzMTk2NQ==", "bodyText": "should only be set with first IOE, as that's usually first sign of failure. Rest just log message @ warn and stack @ debug.\nwhat about other exceptions? are they handled by the normal Futures code? In which case ExecutionException needs to be picked up and unwrapped. The code in org.apache.hadoop.util.functional.FutureIO can help there", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560131965", "createdAt": "2021-01-19T12:11:00Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private synchronized boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzMjgwMg==", "bodyText": "With an interface, you don't need to play mockito games any more. Instead just provide a dummy impl to simulate deep/wide directories, controllable page size etc", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560132802", "createdAt": "2021-01-19T12:12:35Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java", "diffHunk": "@@ -0,0 +1,339 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.ListingSupport;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.ArgumentMatchers.anyList;\n+import static org.mockito.ArgumentMatchers.nullable;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Test ListStatusRemoteIterator operation.\n+ */\n+public class ITestAbfsListStatusIterator extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAbfsListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListStatusRemoteIterator() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 66}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxOTc5NDc0", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-571979474", "createdAt": "2021-01-20T08:40:30Z", "commit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwODo0MDozMFrOIWyo9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwODo0NjowOFrOIWy7kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc2OTI3MQ==", "bodyText": "why synchronized? this will cause contention on line 83. u are holding the lock across a listing call to server.", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560769271", "createdAt": "2021-01-20T08:40:30Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private synchronized boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;\n+      iteratorsQueue.offer(Collections.emptyIterator());\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (asyncOpLock) {\n+        isAsyncInProgress = false;\n+      }\n+    }\n+  }\n+\n+  private synchronized void addNextBatchIteratorToQueue()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc2OTUxMA==", "bodyText": "why recursion?", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560769510", "createdAt": "2021-01-20T08:40:55Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc3NDAzNA==", "bodyText": "set continuationtoken to empty. why do we need firstbatch?", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560774034", "createdAt": "2021-01-20T08:46:08Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 50}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c4f64a45183bd03677c68c241642e41530cf88e", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/7c4f64a45183bd03677c68c241642e41530cf88e", "committedDate": "2021-01-24T16:00:34Z", "message": "Addressing review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1MTE1NzAy", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-575115702", "createdAt": "2021-01-25T07:19:36Z", "commit": {"oid": "7c4f64a45183bd03677c68c241642e41530cf88e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQwNzoxOTozN1rOIZZljA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQwNzoxOTozN1rOIZZljA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwNDUyNA==", "bodyText": "can this be done outside the sync block? If put blocks u are holding the lock.", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r563504524", "createdAt": "2021-01-25T07:19:37Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    if (currIterator == null) {\n+      return false;\n+    }\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    do {\n+      currIterator = getNextIterator();\n+    } while (currIterator != null && !currIterator.hasNext()\n+        && !isIterationComplete);\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty() && isIterationComplete) {\n+          return null;\n+      }\n+    }\n+    try {\n+      Object obj = iteratorsQueue.take();\n+      if(obj instanceof Iterator){\n+        return (Iterator<FileStatus>) obj;\n+      }\n+      throw (IOException) obj;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+      return null;\n+    }\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isIterationComplete && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      try {\n+        iteratorsQueue.put(e);\n+      } catch (InterruptedException interruptedException) {\n+        Thread.currentThread().interrupt();\n+        LOG.error(\"Thread got interrupted: {}\", interruptedException);\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (asyncOpLock) {\n+        isAsyncInProgress = false;\n+      }\n+    }\n+  }\n+\n+  private void addNextBatchIteratorToQueue()\n+      throws IOException, InterruptedException {\n+    List<FileStatus> fileStatuses = new ArrayList<>();\n+    continuation = listingSupport\n+        .listStatus(fileStatus.getPath(), null, fileStatuses, FETCH_ALL_FALSE,\n+            continuation);\n+    synchronized (this) {\n+      if (continuation == null || continuation.isEmpty()) {\n+        isIterationComplete = true;\n+      }\n+      iteratorsQueue.put(fileStatuses.iterator());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c4f64a45183bd03677c68c241642e41530cf88e"}, "originalPosition": 155}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1MTIwMTIy", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-575120122", "createdAt": "2021-01-25T07:28:20Z", "commit": {"oid": "7c4f64a45183bd03677c68c241642e41530cf88e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQwNzoyODoyMVrOIZZypQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQwNzoyODoyMVrOIZZypQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwNzg3Nw==", "bodyText": "can we avoid this completely?", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r563507877", "createdAt": "2021-01-25T07:28:21Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c4f64a45183bd03677c68c241642e41530cf88e"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1MTIyMzMx", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-575122331", "createdAt": "2021-01-25T07:32:31Z", "commit": {"oid": "7c4f64a45183bd03677c68c241642e41530cf88e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQwNzozMjozMVrOIZZ5Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQwNzozMjozMVrOIZZ5Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwOTUyNw==", "bodyText": "null or empty iterator? same question for line 106.\nStandrad with collections is to return an empty collection/iterator - not a null object.", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r563509527", "createdAt": "2021-01-25T07:32:31Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    if (currIterator == null) {\n+      return false;\n+    }\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    do {\n+      currIterator = getNextIterator();\n+    } while (currIterator != null && !currIterator.hasNext()\n+        && !isIterationComplete);\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty() && isIterationComplete) {\n+          return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c4f64a45183bd03677c68c241642e41530cf88e"}, "originalPosition": 94}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f578bbd7c776751dfbfc63b1e586c2308c3f2501", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f578bbd7c776751dfbfc63b1e586c2308c3f2501", "committedDate": "2021-01-25T15:34:59Z", "message": "Addressing review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89222d1f2d56cafe5075b5b570a3ca3a73f25b42", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/89222d1f2d56cafe5075b5b570a3ca3a73f25b42", "committedDate": "2021-01-25T15:38:15Z", "message": "Addressing review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1NTMyOTgz", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-575532983", "createdAt": "2021-01-25T15:48:59Z", "commit": {"oid": "89222d1f2d56cafe5075b5b570a3ca3a73f25b42"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNTo0OTowMFrOIZtW9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxNTo0OTowMFrOIZtW9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzgyODQ3MA==", "bodyText": "not within sync block", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r563828470", "createdAt": "2021-01-25T15:49:00Z", "author": {"login": "vinaysbadami"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    do {\n+      currIterator = getNextIterator();\n+    } while (currIterator != null && !currIterator.hasNext()\n+        && !isIterationComplete);\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty() && isIterationComplete) {\n+          return Collections.emptyIterator();\n+      }\n+    }\n+    try {\n+      Object obj = iteratorsQueue.take();\n+      if(obj instanceof Iterator){\n+        return (Iterator<FileStatus>) obj;\n+      }\n+      throw (IOException) obj;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+      return Collections.emptyIterator();\n+    }\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (this) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isIterationComplete && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      try {\n+        iteratorsQueue.put(e);\n+      } catch (InterruptedException interruptedException) {\n+        Thread.currentThread().interrupt();\n+        LOG.error(\"Thread got interrupted: {}\", interruptedException);\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (this  ) {\n+        isAsyncInProgress = false;\n+      }\n+    }\n+  }\n+\n+  private void addNextBatchIteratorToQueue()\n+      throws IOException, InterruptedException {\n+    List<FileStatus> fileStatuses = new ArrayList<>();\n+    continuation = listingSupport\n+        .listStatus(fileStatus.getPath(), null, fileStatuses, FETCH_ALL_FALSE,\n+            continuation);\n+    iteratorsQueue.put(fileStatuses.iterator());\n+    synchronized (this) {\n+      if (continuation == null || continuation.isEmpty()) {\n+        isIterationComplete = true;\n+        iteratorsQueue.put(Collections.emptyIterator());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89222d1f2d56cafe5075b5b570a3ca3a73f25b42"}, "originalPosition": 151}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/5970d6ec245c2bfb273435733de5b76f2ddcb22b", "committedDate": "2021-01-27T10:59:52Z", "message": "Adressing review comments. Checkstyle fixes."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc3MjQ4MjYz", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-577248263", "createdAt": "2021-01-27T11:40:04Z", "commit": {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgwNTY2OTU4", "url": "https://github.com/apache/hadoop/pull/2548#pullrequestreview-580566958", "createdAt": "2021-02-01T17:00:24Z", "commit": {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMVQxNzowMDoyNFrOIdrJVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMVQxNzowOTo1M1rOIdrkCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4NjUxNg==", "bodyText": "OK, but it's something to plan to cut after a release has been out. So file a new JIRA about cutting the old one.", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567986516", "createdAt": "2021-02-01T17:00:24Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -982,6 +985,19 @@ public boolean exists(Path f) throws IOException {\n     return super.exists(f);\n   }\n \n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(Path path)\n+      throws IOException {\n+    LOG.debug(\"AzureBlobFileSystem.listStatusIterator path : {}\", path);\n+    if (abfsStore.getAbfsConfiguration().enableAbfsListIterator()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyNjczMQ=="}, "originalCommit": {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4NjY2Nw==", "bodyText": "nice", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567986667", "createdAt": "2021-02-01T17:00:33Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -982,6 +985,19 @@ public boolean exists(Path f) throws IOException {\n     return super.exists(f);\n   }\n \n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(Path path)\n+      throws IOException {\n+    LOG.debug(\"AzureBlobFileSystem.listStatusIterator path : {}\", path);\n+    if (abfsStore.getAbfsConfiguration().enableAbfsListIterator()) {\n+      AbfsListStatusRemoteIterator abfsLsItr =\n+          new AbfsListStatusRemoteIterator(getFileStatus(path), abfsStore);\n+      return RemoteIterators.typeCastingRemoteIterator(abfsLsItr);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4ODQ1NQ==", "bodyText": "nit: space after if", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567988455", "createdAt": "2021-02-01T17:03:09Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.activation.UnsupportedDataTypeException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator\n+    implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+  private static final long POLL_WAIT_TIME_IN_MS = 250;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    currIterator = getNextIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    try {\n+      Object obj = null;\n+      while (obj == null\n+          && (!isIterationComplete || !iteratorsQueue.isEmpty())) {\n+        obj = iteratorsQueue.poll(POLL_WAIT_TIME_IN_MS, TimeUnit.MILLISECONDS);\n+      }\n+      if (obj == null) {\n+        return Collections.emptyIterator();\n+      } else if (obj instanceof Iterator) {\n+        return (Iterator<FileStatus>) obj;\n+      } else if (obj instanceof IOException) {\n+        throw (IOException) obj;\n+      } else {\n+        throw new UnsupportedDataTypeException();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+      throw new IOException(e);\n+    }\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress || isIterationComplete) {\n+      return;\n+    }\n+    synchronized (this) {\n+      if (isAsyncInProgress || isIterationComplete) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isIterationComplete && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException ioe) {\n+      LOG.error(\"Fetching filestatuses failed\", ioe);\n+      try {\n+        iteratorsQueue.put(ioe);\n+      } catch (InterruptedException interruptedException) {\n+        Thread.currentThread().interrupt();\n+        LOG.error(\"Thread got interrupted: {}\", interruptedException);\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (this) {\n+        isAsyncInProgress = false;\n+      }\n+    }\n+  }\n+\n+  private void addNextBatchIteratorToQueue()\n+      throws IOException, InterruptedException {\n+    List<FileStatus> fileStatuses = new ArrayList<>();\n+    continuation = listingSupport\n+        .listStatus(fileStatus.getPath(), null, fileStatuses, FETCH_ALL_FALSE,\n+            continuation);\n+    if(!fileStatuses.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4OTMzMQ==", "bodyText": "add that at the actual interface, along with the @Private . Not that we'd expect anyone to use it", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567989331", "createdAt": "2021-02-01T17:04:21Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListingSupport.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+\n+public interface ListingSupport {\n+\n+  /**\n+   * @param path The list path.\n+   * @return the entries in the path.\n+   */\n+  FileStatus[] listStatus(Path path) throws IOException;\n+\n+  /**\n+   * @param path      Path the list path.\n+   * @param startFrom The entry name that list results should start with.\n+   *                  For example, if folder \"/folder\" contains four\n+   *                  files: \"afile\", \"bfile\", \"hfile\", \"ifile\". Then\n+   *                  listStatus(Path(\"/folder\"), \"hfile\") will return\n+   *                  \"/folder/hfile\" and \"folder/ifile\" Notice that if\n+   *                  startFrom is a non-existent entry name, then the\n+   *                  list response contains all entries after this\n+   *                  non-existent entry in lexical order: listStatus\n+   *                  (Path(\"/folder\"), \"cfile\") will return\n+   *                  \"/folder/hfile\" and \"/folder/ifile\".\n+   * @return the entries in the path start from  \"startFrom\" in lexical order.\n+   */\n+  @InterfaceStability.Unstable", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4OTUxMA==", "bodyText": "cut", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567989510", "createdAt": "2021-02-01T17:04:38Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.ListingSupport;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.ArgumentMatchers.anyList;\n+import static org.mockito.ArgumentMatchers.nullable;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Test ListStatusRemoteIterator operation.\n+ */\n+public class ITestAbfsListStatusRemoteIterator extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAbfsListStatusRemoteIterator() throws Exception {\n+    super();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk5MDU5Nw==", "bodyText": "this should be in a finally block", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567990597", "createdAt": "2021-02-01T17:06:03Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.ListingSupport;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.ArgumentMatchers.anyList;\n+import static org.mockito.ArgumentMatchers.nullable;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Test ListStatusRemoteIterator operation.\n+ */\n+public class ITestAbfsListStatusRemoteIterator extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAbfsListStatusRemoteIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testAbfsIteratorWithHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());\n+    RemoteIterator<FileStatus> fsItr = new AbfsListStatusRemoteIterator(\n+        getFileSystem().getFileStatus(testDir), listngSupport);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should be instance of \"\n+            + \"AbfsListStatusRemoteIterator by default\")\n+        .isInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    while (fsItr.hasNext()) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+    int minNumberOfInvokations = TEST_FILES_NUMBER / 10;\n+    verify(listngSupport, Mockito.atLeast(minNumberOfInvokations))\n+        .listStatus(any(Path.class), nullable(String.class),\n+            anyList(), anyBoolean(),\n+            nullable(String.class));\n+  }\n+\n+  @Test\n+  public void testAbfsIteratorWithoutHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());\n+    RemoteIterator<FileStatus> fsItr = new AbfsListStatusRemoteIterator(\n+        getFileSystem().getFileStatus(testDir), listngSupport);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should be instance of \"\n+            + \"AbfsListStatusRemoteIterator by default\")\n+        .isInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    for (int i = 0; i < TEST_FILES_NUMBER; i++) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+            \"next() should throw NoSuchElementException since next has been \"\n+                + \"called \" + TEST_FILES_NUMBER + \" times\")\n+        .isInstanceOf(NoSuchElementException.class);\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+    int minNumberOfInvokations = TEST_FILES_NUMBER / 10;\n+    verify(listngSupport, Mockito.atLeast(minNumberOfInvokations))\n+        .listStatus(any(Path.class), nullable(String.class),\n+            anyList(), anyBoolean(),\n+            nullable(String.class));\n+  }\n+\n+  @Test\n+  public void testWithAbfsIteratorDisabled() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    setEnableAbfsIterator(false);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    RemoteIterator<FileStatus> fsItr =\n+        getFileSystem().listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should not be instance of \"\n+            + \"AbfsListStatusRemoteIterator when it is disabled\")\n+        .isNotInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    while (fsItr.hasNext()) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testWithAbfsIteratorDisabledWithoutHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    setEnableAbfsIterator(false);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    RemoteIterator<FileStatus> fsItr =\n+        getFileSystem().listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should not be instance of \"\n+            + \"AbfsListStatusRemoteIterator when it is disabled\")\n+        .isNotInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    for (int i = 0; i < TEST_FILES_NUMBER; i++) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+            \"next() should throw NoSuchElementException since next has been \"\n+                + \"called \" + TEST_FILES_NUMBER + \" times\")\n+        .isInstanceOf(NoSuchElementException.class);\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    RemoteIterator fsItr =\n+        new AbfsListStatusRemoteIterator(getFileSystem().getFileStatus(testDir),\n+            getFileSystem().getAbfsStore());\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next())\n+        .describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\")\n+        .isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    RemoteIterator<FileStatus> fsItr = getFileSystem()\n+        .listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\")\n+        .isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String testFileName = \"testFile\";\n+    Path testFile = new Path(testFileName);\n+    getFileSystem().create(testFile);\n+    setPageSize(10);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(testFile);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+    Assertions.assertThat(fsItr.next().getPath().toString())\n+        .describedAs(\"next returns the file itself\")\n+        .endsWith(testFileName);\n+  }\n+\n+  @Test\n+  public void testIOException() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    getFileSystem().mkdirs(testDir);\n+\n+    String exceptionMessage = \"test exception\";\n+    ListingSupport lsSupport =getMockListingSupport(exceptionMessage);\n+    RemoteIterator fsItr =\n+        new AbfsListStatusRemoteIterator(getFileSystem().getFileStatus(testDir),\n+        lsSupport);\n+\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+        \"When ioException is not null and queue is empty exception should be \"\n+            + \"thrown\")\n+        .isInstanceOf(IOException.class)\n+        .hasMessage(exceptionMessage);\n+  }\n+\n+  @Test\n+  public void testNonExistingPath() throws Throwable {\n+    Path nonExistingDir = new Path(\"nonExistingPath\");\n+    Assertions.assertThatThrownBy(\n+        () -> getFileSystem().listStatusIterator(nonExistingDir)).describedAs(\n+        \"test the listStatusIterator call on a path which is not \"\n+            + \"present should result in FileNotFoundException\")\n+        .isInstanceOf(FileNotFoundException.class);\n+  }\n+\n+  private ListingSupport getMockListingSupport(String exceptionMessage) {\n+    return new ListingSupport() {\n+      @Override\n+      public FileStatus[] listStatus(Path path) throws IOException {\n+        return null;\n+      }\n+\n+      @Override\n+      public FileStatus[] listStatus(Path path, String startFrom)\n+          throws IOException {\n+        return null;\n+      }\n+\n+      @Override\n+      public String listStatus(Path path, String startFrom,\n+          List<FileStatus> fileStatuses, boolean fetchAll, String continuation)\n+          throws IOException {\n+        throw new IOException(exceptionMessage);\n+      }\n+    };\n+  }\n+\n+  private Path createTestDirectory() throws IOException {\n+    String testDirectoryName = \"testDirectory\" + System.currentTimeMillis();\n+    Path testDirectory = new Path(testDirectoryName);\n+    getFileSystem().mkdirs(testDirectory);\n+    return testDirectory;\n+  }\n+\n+  private void setEnableAbfsIterator(boolean shouldEnable) throws IOException {\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(getFileSystem());\n+    abfsStore.getAbfsConfiguration().setEnableAbfsListIterator(shouldEnable);\n+  }\n+\n+  private void setPageSize(int pageSize) throws IOException {\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(getFileSystem());\n+    abfsStore.getAbfsConfiguration().setListMaxResults(pageSize);\n+  }\n+\n+  private List<String> createFilesUnderDirectory(int numFiles, Path rootPath,\n+      String filenamePrefix)\n+      throws ExecutionException, InterruptedException, IOException {\n+    final List<Future<Void>> tasks = new ArrayList<>();\n+    final List<String> fileNames = new ArrayList<>();\n+    ExecutorService es = Executors.newFixedThreadPool(10);\n+    for (int i = 0; i < numFiles; i++) {\n+      final Path filePath = new Path(rootPath, filenamePrefix + i);\n+      Callable<Void> callable = () -> {\n+        getFileSystem().create(filePath);\n+        fileNames.add(makeQualified(filePath).toString());\n+        return null;\n+      };\n+      tasks.add(es.submit(callable));\n+    }\n+    for (Future<Void> task : tasks) {\n+      task.get();\n+    }\n+    es.shutdownNow();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b"}, "originalPosition": 334}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk5MzM1Mw==", "bodyText": "I can't help thinking this a bit of an abuse of a queue to mix object types in there -but to do it in any other way within java would be pretty convoluted (new class, essentially), so let's go with what is here. Just need to make sure there's test coverage for the IOE path", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567993353", "createdAt": "2021-02-01T17:09:53Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.activation.UnsupportedDataTypeException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator\n+    implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+  private static final long POLL_WAIT_TIME_IN_MS = 250;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    currIterator = getNextIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    try {\n+      Object obj = null;\n+      while (obj == null\n+          && (!isIterationComplete || !iteratorsQueue.isEmpty())) {\n+        obj = iteratorsQueue.poll(POLL_WAIT_TIME_IN_MS, TimeUnit.MILLISECONDS);\n+      }\n+      if (obj == null) {\n+        return Collections.emptyIterator();\n+      } else if (obj instanceof Iterator) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b"}, "originalPosition": 93}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b8053c7a32cce97aab5b256452132b4a397c2e9", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/9b8053c7a32cce97aab5b256452132b4a397c2e9", "committedDate": "2021-02-02T15:00:50Z", "message": "Addressing review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "919245daaa42c9b46903f198f8eba58d21226998", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/919245daaa42c9b46903f198f8eba58d21226998", "committedDate": "2021-02-03T11:37:36Z", "message": "To ignore the findbug warning related to continuation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51bd08a71719310ad11b22f107fd5a4378d27271", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/51bd08a71719310ad11b22f107fd5a4378d27271", "committedDate": "2021-02-03T11:41:30Z", "message": "Fixing javadoc issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b01659a20c2a26fdf45a19e073dc2eb8b76d6f6a", "author": {"user": {"login": "bilaharith", "name": null}}, "url": "https://github.com/apache/hadoop/commit/b01659a20c2a26fdf45a19e073dc2eb8b76d6f6a", "committedDate": "2021-02-03T14:27:55Z", "message": "findbugs fix"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3199, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}