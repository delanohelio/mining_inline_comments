{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMzODIzNTA2", "number": 2528, "title": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy", "bodyText": "In some slow runs TestUpgradeDomainBlockPlacementPolicy#testPlacement and TestUpgradeDomainBlockPlacementPolicy#testPlacementAfterDecommission fail.\nOn branch-2.10, this was fixed by waiting for the replication to be complete.", "createdAt": "2020-12-07T17:15:16Z", "url": "https://github.com/apache/hadoop/pull/2528", "merged": true, "mergeCommit": {"oid": "01383a21722be706d7ab682323285e794f71cadf"}, "closed": true, "closedAt": "2020-12-08T19:25:25Z", "author": {"login": "amahussein"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdj-spgABqjQwODIyMzI2NTg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdlL1tLgFqTU1MDM4MzkxNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7efa58ec8bf94b267781ea000a29208eb719dea5", "author": {"user": {"login": "amahussein", "name": "Ahmed Hussein"}}, "url": "https://github.com/apache/hadoop/commit/7efa58ec8bf94b267781ea000a29208eb719dea5", "committedDate": "2020-12-07T17:12:51Z", "message": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy"}, "afterCommit": {"oid": "147f2caaf142aad28510391cdb33df68abe210fb", "author": {"user": {"login": "amahussein", "name": "Ahmed Hussein"}}, "url": "https://github.com/apache/hadoop/commit/147f2caaf142aad28510391cdb33df68abe210fb", "committedDate": "2020-12-08T00:06:59Z", "message": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "def653ae9ddbaf48a0eebc84ee800733fde67aa9", "author": {"user": {"login": "amahussein", "name": "Ahmed Hussein"}}, "url": "https://github.com/apache/hadoop/commit/def653ae9ddbaf48a0eebc84ee800733fde67aa9", "committedDate": "2020-12-08T14:41:53Z", "message": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "147f2caaf142aad28510391cdb33df68abe210fb", "author": {"user": {"login": "amahussein", "name": "Ahmed Hussein"}}, "url": "https://github.com/apache/hadoop/commit/147f2caaf142aad28510391cdb33df68abe210fb", "committedDate": "2020-12-08T00:06:59Z", "message": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy"}, "afterCommit": {"oid": "def653ae9ddbaf48a0eebc84ee800733fde67aa9", "author": {"user": {"login": "amahussein", "name": "Ahmed Hussein"}}, "url": "https://github.com/apache/hadoop/commit/def653ae9ddbaf48a0eebc84ee800733fde67aa9", "committedDate": "2020-12-08T14:41:53Z", "message": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3MzIwNDY0", "url": "https://github.com/apache/hadoop/pull/2528#pullrequestreview-547320464", "createdAt": "2020-12-08T15:03:37Z", "commit": {"oid": "def653ae9ddbaf48a0eebc84ee800733fde67aa9"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwMzgzOTE2", "url": "https://github.com/apache/hadoop/pull/2528#pullrequestreview-550383916", "createdAt": "2020-12-11T17:59:31Z", "commit": {"oid": "def653ae9ddbaf48a0eebc84ee800733fde67aa9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNzo1OTozMlrOIEDyWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNzo1OTozMlrOIEDyWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTEyNzI1OA==", "bodyText": "Why not leave this static import?", "url": "https://github.com/apache/hadoop/pull/2528#discussion_r541127258", "createdAt": "2020-12-11T17:59:32Z", "author": {"login": "goiri"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestUpgradeDomainBlockPlacementPolicy.java", "diffHunk": "@@ -231,32 +229,34 @@ public Boolean get() {\n         } catch (IOException ioe) {\n           return false;\n         }\n-        for(LocatedBlock block : locatedBlocks.getLocatedBlocks()) {\n+        for (LocatedBlock block : locatedBlocks.getLocatedBlocks()) {\n           Set<DatanodeInfo> locs = new HashSet<>();\n           for (DatanodeInfo datanodeInfo : block.getLocations()) {\n-            if (datanodeInfo.getAdminState() ==\n-                DatanodeInfo.AdminStates.NORMAL) {\n+            if (datanodeInfo.getAdminState().equals(\n+                DatanodeInfo.AdminStates.NORMAL)) {\n               locs.add(datanodeInfo);\n             }\n           }\n           for (DatanodeID datanodeID : expectedDatanodeIDs) {\n-            successful = successful && locs.contains(datanodeID);\n+            if (!locs.contains(datanodeID)) {\n+              return false;\n+            }\n           }\n         }\n-        return successful;\n+        return true;\n       }\n-    }, 1000, 60000);\n+    }, 1000, WAIT_TIMEOUT_MS);\n \n     // Verify block placement policy of each block.\n-    LocatedBlocks locatedBlocks;\n-    locatedBlocks =\n+    LocatedBlocks locatedBlocks =\n         cluster.getFileSystem().getClient().getLocatedBlocks(\n             path.toString(), 0, fileSize);\n-    for(LocatedBlock block : locatedBlocks.getLocatedBlocks()) {\n-      BlockPlacementStatus status = cluster.getNamesystem().getBlockManager().\n-          getBlockPlacementPolicy().verifyBlockPlacement(\n-              block.getLocations(), REPLICATION_FACTOR);\n-      assertTrue(status.isPlacementPolicySatisfied());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "def653ae9ddbaf48a0eebc84ee800733fde67aa9"}, "originalPosition": 167}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3396, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}