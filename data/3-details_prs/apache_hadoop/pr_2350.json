{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk1MDUxMTky", "number": 2350, "title": " HADOOP-17292. Using lz4-java in Lz4Codec", "bodyText": "See https://issues.apache.org/jira/browse/HADOOP-17292 for details.\nThe change of mvn dependencies:\nFor Apache Hadoop Common:\n< [INFO] \\- org.wildfly.openssl:wildfly-openssl-java:jar:1.0.7.Final:provided                                                                                                                                                          \n---                                                                                                                                                                                                                                    \n> [INFO] +- org.wildfly.openssl:wildfly-openssl-java:jar:1.0.7.Final:provided                                                                                                                                                          \n> [INFO] \\- org.lz4:lz4-java:jar:1.7.1:provided     \n\nFor Apache Hadoop Kafka Library support:\n[INFO] +- org.apache.kafka:kafka-clients:jar:2.4.0:compile\n[INFO] |  +- com.github.luben:zstd-jni:jar:1.4.3-1:compile\n< [INFO] |  \\- org.lz4:lz4-java:jar:1.6.0:compile                                                                                                                                                                                      \n---                                                                                                                                                                                                                                    \n> [INFO] |  \\- org.lz4:lz4-java:jar:1.7.1:compile  \n\nFor Apache Hadoop Tools Dist:\n[INFO] +- org.apache.hadoop:hadoop-kafka:jar:3.4.0-SNAPSHOT:compile\n[INFO] |  \\- org.apache.kafka:kafka-clients:jar:2.4.0:compile\n[INFO] |     +- com.github.luben:zstd-jni:jar:1.4.3-1:compile\n< [INFO] |     \\- org.lz4:lz4-java:jar:1.6.0:compile                                                                                                                                                                                   \n---                                                                                                                                                                                                                                    \n> [INFO] |     \\- org.lz4:lz4-java:jar:1.7.1:compile", "createdAt": "2020-09-29T19:23:55Z", "url": "https://github.com/apache/hadoop/pull/2350", "merged": true, "mergeCommit": {"oid": "34aa6137bd890a565ace26be278a50f81b3dda20"}, "closed": true, "closedAt": "2020-11-18T20:03:26Z", "author": {"login": "viirya"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdNtmq4gFqTQ5ODgyMjQwOQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABddjJ24gH2gAyNDk1MDUxMTkyOmMwMmU4Y2E2YWUxOWZhODViMTYwZGY3YjRkY2I3NDBjZDdiN2VmMDU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4ODIyNDA5", "url": "https://github.com/apache/hadoop/pull/2350#pullrequestreview-498822409", "createdAt": "2020-09-29T19:43:00Z", "commit": {"oid": "d2d41750641f6453ab19616ac59d7219a2a9dceb"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxOTo0MzowMVrOHZ-d9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxOTo0NjoxMFrOHZ-kjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk5OTkyNg==", "bodyText": "compressDirectBuf?", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r496999926", "createdAt": "2020-09-29T19:43:01Z", "author": {"login": "dbtsai"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Compressor.java", "diffHunk": "@@ -236,7 +237,7 @@ public synchronized int compress(byte[] b, int off, int len)\n     }\n \n     // Compress data\n-    n = useLz4HC ? compressBytesDirectHC() : compressBytesDirect();\n+    n = compressBytesDirect();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2d41750641f6453ab19616ac59d7219a2a9dceb"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzAwMTI3MQ==", "bodyText": "indentation as you remove the { }", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r497001271", "createdAt": "2020-09-29T19:45:32Z", "author": {"login": "dbtsai"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodec.java", "diffHunk": "@@ -143,22 +143,16 @@ public void testSnappyCodec() throws IOException {\n   \n   @Test\n   public void testLz4Codec() throws IOException {\n-    if (NativeCodeLoader.isNativeCodeLoaded()) {\n-      if (Lz4Codec.isNativeCodeLoaded()) {\n-        conf.setBoolean(\n+    conf.setBoolean(\n             CommonConfigurationKeys.IO_COMPRESSION_CODEC_LZ4_USELZ4HC_KEY,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2d41750641f6453ab19616ac59d7219a2a9dceb"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzAwMTYxNA==", "bodyText": "Can we add a compatibility test like snappy?", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r497001614", "createdAt": "2020-09-29T19:46:10Z", "author": {"login": "dbtsai"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/CompressDecompressTester.java", "diffHunk": "@@ -494,8 +494,7 @@ public String getName() {\n   private static <T extends Compressor, E extends Decompressor> boolean isAvailable(TesterPair<T, E> pair) {\n     Compressor compressor = pair.compressor;\n \n-    if (compressor.getClass().isAssignableFrom(Lz4Compressor.class)\n-            && (NativeCodeLoader.isNativeCodeLoaded()))\n+    if (compressor.getClass().isAssignableFrom(Lz4Compressor.class))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2d41750641f6453ab19616ac59d7219a2a9dceb"}, "originalPosition": 6}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e300cb3e74efc9b55fe28663c044776f284638b7", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/e300cb3e74efc9b55fe28663c044776f284638b7", "committedDate": "2020-10-02T05:12:17Z", "message": "Add compatibility test."}, "afterCommit": {"oid": "10b027d05c9bf46aa3432dcd88e9902511387832", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/10b027d05c9bf46aa3432dcd88e9902511387832", "committedDate": "2020-10-02T05:15:13Z", "message": "Add compatibility test and fix style."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "10b027d05c9bf46aa3432dcd88e9902511387832", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/10b027d05c9bf46aa3432dcd88e9902511387832", "committedDate": "2020-10-02T05:15:13Z", "message": "Add compatibility test and fix style."}, "afterCommit": {"oid": "4aefff40c2f0c0a2074644d0de34f6f11bd50bc8", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/4aefff40c2f0c0a2074644d0de34f6f11bd50bc8", "committedDate": "2020-10-02T05:18:43Z", "message": "Add compatibility test and fix style."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fb75dfa19ac7edca1c236f737ac47797ec94fbc1", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/fb75dfa19ac7edca1c236f737ac47797ec94fbc1", "committedDate": "2020-10-03T23:16:30Z", "message": "Add lz4-java to test dependency."}, "afterCommit": {"oid": "cdb1a68fdf057c753d9d59e5d89af5fba8fa6724", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/cdb1a68fdf057c753d9d59e5d89af5fba8fa6724", "committedDate": "2020-10-03T23:17:43Z", "message": "Add lz4-java to test dependency."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cdb1a68fdf057c753d9d59e5d89af5fba8fa6724", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/cdb1a68fdf057c753d9d59e5d89af5fba8fa6724", "committedDate": "2020-10-03T23:17:43Z", "message": "Add lz4-java to test dependency."}, "afterCommit": {"oid": "44662282d18e52f0e8e3c2525fd99b3bc602bcc3", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/44662282d18e52f0e8e3c2525fd99b3bc602bcc3", "committedDate": "2020-10-07T17:35:51Z", "message": "Add lz4-java to test dependency."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA1ODM2NDU1", "url": "https://github.com/apache/hadoop/pull/2350#pullrequestreview-505836455", "createdAt": "2020-10-09T16:45:13Z", "commit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxNjo0NToxM1rOHfRYaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxNjo1MDoyOVrOHfRjUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU1MjY4MQ==", "bodyText": "put into the same import block as org.sjf4j", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502552681", "createdAt": "2020-10-09T16:45:13Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Compressor.java", "diffHunk": "@@ -22,9 +22,10 @@\n import java.nio.Buffer;\n import java.nio.ByteBuffer;\n \n+import net.jpountz.lz4.LZ4Factory;\n+import net.jpountz.lz4.LZ4Compressor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU1MzEwMQ==", "bodyText": "final?", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502553101", "createdAt": "2020-10-09T16:46:02Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Compressor.java", "diffHunk": "@@ -50,20 +51,7 @@\n \n   private final boolean useLz4HC;\n \n-  static {\n-    if (NativeCodeLoader.isNativeCodeLoaded()) {\n-      // Initialize the native library\n-      try {\n-        initIDs();\n-      } catch (Throwable t) {\n-        // Ignore failure to load/initialize lz4\n-        LOG.warn(t.toString());\n-      }\n-    } else {\n-      LOG.error(\"Cannot load \" + Lz4Compressor.class.getName() +\n-          \" without native hadoop library!\");\n-    }\n-  }\n+  private LZ4Compressor lz4Compressor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU1MzMzOA==", "bodyText": "again, not in same import block as org.apache", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502553338", "createdAt": "2020-10-09T16:46:25Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Decompressor.java", "diffHunk": "@@ -22,8 +22,9 @@\n import java.nio.Buffer;\n import java.nio.ByteBuffer;\n \n+import net.jpountz.lz4.LZ4Factory;\n+import net.jpountz.lz4.LZ4SafeDecompressor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU1NTA5Mg==", "bodyText": "Shame the constructor can't throw exceptions direct.\nCatch only the exception's known to be raised, and don't convert RTEs or, especially, Errors.", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502555092", "createdAt": "2020-10-09T16:49:48Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Decompressor.java", "diffHunk": "@@ -67,6 +55,15 @@\n   public Lz4Decompressor(int directBufferSize) {\n     this.directBufferSize = directBufferSize;\n \n+    try {\n+      LZ4Factory lz4Factory = LZ4Factory.fastestInstance();\n+      lz4Decompressor = lz4Factory.safeDecompressor();\n+    } catch (Throwable t) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU1NTQ3NQ==", "bodyText": "add +t to the end of the string, so the specific error text isn't lost", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502555475", "createdAt": "2020-10-09T16:50:29Z", "author": {"login": "steveloughran"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Decompressor.java", "diffHunk": "@@ -67,6 +55,15 @@\n   public Lz4Decompressor(int directBufferSize) {\n     this.directBufferSize = directBufferSize;\n \n+    try {\n+      LZ4Factory lz4Factory = LZ4Factory.fastestInstance();\n+      lz4Decompressor = lz4Factory.safeDecompressor();\n+    } catch (Throwable t) {\n+      throw new RuntimeException(\"lz4-java library is not available: \" +\n+              \"Lz4Decompressor has not been loaded. You need to add \" +\n+              \"lz4-java.jar to your CLASSPATH\", t);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA1ODUxMjcy", "url": "https://github.com/apache/hadoop/pull/2350#pullrequestreview-505851272", "createdAt": "2020-10-09T17:07:19Z", "commit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxNzowNzoyMFrOHfSFRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxNzo1MTo0MFrOHfTbEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU2NDE2Ng==", "bodyText": "The library also allow configuring the compression level, which perhaps we can add a Hadoop option to enable that later. This just use the default compression level.", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502564166", "createdAt": "2020-10-09T17:07:20Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Compressor.java", "diffHunk": "@@ -76,6 +64,19 @@ public Lz4Compressor(int directBufferSize, boolean useLz4HC) {\n     this.useLz4HC = useLz4HC;\n     this.directBufferSize = directBufferSize;\n \n+    try {\n+      LZ4Factory lz4Factory = LZ4Factory.fastestInstance();\n+      if (useLz4HC) {\n+        lz4Compressor = lz4Factory.highCompressor();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU2NTIwOQ==", "bodyText": "nit: seems we no longer need the field useLz4HC with this.", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502565209", "createdAt": "2020-10-09T17:09:28Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Compressor.java", "diffHunk": "@@ -76,6 +64,19 @@ public Lz4Compressor(int directBufferSize, boolean useLz4HC) {\n     this.useLz4HC = useLz4HC;\n     this.directBufferSize = directBufferSize;\n \n+    try {\n+      LZ4Factory lz4Factory = LZ4Factory.fastestInstance();\n+      if (useLz4HC) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU2NjE5MQ==", "bodyText": "seems some of the methods in this class look exactly the same as in SnappyCompressor - perhaps we can do some refactoring later.", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502566191", "createdAt": "2020-10-09T17:11:34Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Compressor.java", "diffHunk": "@@ -302,11 +303,20 @@ public synchronized long getBytesWritten() {\n   public synchronized void end() {\n   }\n \n-  private native static void initIDs();\n-\n-  private native int compressBytesDirect();\n-\n-  private native int compressBytesDirectHC();\n-\n-  public native static String getLibraryName();\n+  private int compressDirectBuf() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU3MTQyNg==", "bodyText": "I think this isn't necessary since it's called right before the call site?", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502571426", "createdAt": "2020-10-09T17:22:19Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Compressor.java", "diffHunk": "@@ -302,11 +303,20 @@ public synchronized long getBytesWritten() {\n   public synchronized void end() {\n   }\n \n-  private native static void initIDs();\n-\n-  private native int compressBytesDirect();\n-\n-  private native int compressBytesDirectHC();\n-\n-  public native static String getLibraryName();\n+  private int compressDirectBuf() {\n+    if (uncompressedDirectBufLen == 0) {\n+      return 0;\n+    } else {\n+      // Set the position and limit of `uncompressedDirectBuf` for reading\n+      uncompressedDirectBuf.limit(uncompressedDirectBufLen).position(0);\n+      compressedDirectBuf.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU3ODc3MQ==", "bodyText": "I don't think this will ever happen but it's not a big deal.", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502578771", "createdAt": "2020-10-09T17:36:19Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Decompressor.java", "diffHunk": "@@ -272,7 +269,19 @@ public synchronized void end() {\n     // do nothing\n   }\n \n-  private native static void initIDs();\n-\n-  private native int decompressBytesDirect();\n+  private int decompressDirectBuf() {\n+    if (compressedDirectBufLen == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU4MDgxMQ==", "bodyText": "nit: this comment doesn't add much value - it just state what is exactly being done in the code.", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502580811", "createdAt": "2020-10-09T17:40:21Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Decompressor.java", "diffHunk": "@@ -272,7 +269,19 @@ public synchronized void end() {\n     // do nothing\n   }\n \n-  private native static void initIDs();\n-\n-  private native int decompressBytesDirect();\n+  private int decompressDirectBuf() {\n+    if (compressedDirectBufLen == 0) {\n+      return 0;\n+    } else {\n+      // Set the position and limit of `compressedDirectBuf` for reading", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU4MTU0MQ==", "bodyText": "you can just call clear?", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502581541", "createdAt": "2020-10-09T17:41:50Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/lz4/Lz4Decompressor.java", "diffHunk": "@@ -272,7 +269,19 @@ public synchronized void end() {\n     // do nothing\n   }\n \n-  private native static void initIDs();\n-\n-  private native int decompressBytesDirect();\n+  private int decompressDirectBuf() {\n+    if (compressedDirectBufLen == 0) {\n+      return 0;\n+    } else {\n+      // Set the position and limit of `compressedDirectBuf` for reading\n+      compressedDirectBuf.limit(compressedDirectBufLen).position(0);\n+      lz4Decompressor.decompress((ByteBuffer) compressedDirectBuf,\n+              (ByteBuffer) uncompressedDirectBuf);\n+      compressedDirectBufLen = 0;\n+      compressedDirectBuf.limit(compressedDirectBuf.capacity()).position(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU4NDM2OQ==", "bodyText": "why is this needed?", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502584369", "createdAt": "2020-10-09T17:47:47Z", "author": {"login": "sunchao"}, "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/pom.xml", "diffHunk": "@@ -71,6 +71,11 @@\n       <artifactId>assertj-core</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU4NjEyOA==", "bodyText": "nit: perhaps some comments on this - not quite sure what it is testing.", "url": "https://github.com/apache/hadoop/pull/2350#discussion_r502586128", "createdAt": "2020-10-09T17:51:40Z", "author": {"login": "sunchao"}, "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4/TestLz4CompressorDecompressor.java", "diffHunk": "@@ -330,4 +328,33 @@ public void doWork() throws Exception {\n \n     ctx.waitFor(60000);\n   }\n+\n+  @Test\n+  public void testLz4Compatibility() throws Exception {\n+    Path filePath = new Path(TestLz4CompressorDecompressor.class", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121cf0bf2494af50a6cb58fb1cf0c6246b63ef6"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEwNjcxNzg1", "url": "https://github.com/apache/hadoop/pull/2350#pullrequestreview-510671785", "createdAt": "2020-10-16T17:33:29Z", "commit": {"oid": "8f89dd61aec43e5596de4c967a3193f38f8995ee"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8f89dd61aec43e5596de4c967a3193f38f8995ee", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/8f89dd61aec43e5596de4c967a3193f38f8995ee", "committedDate": "2020-10-14T06:58:44Z", "message": "Address review comments."}, "afterCommit": {"oid": "7835a2f2028f2e63ade7c2e3e1f03cdb9469d1ec", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/7835a2f2028f2e63ade7c2e3e1f03cdb9469d1ec", "committedDate": "2020-10-21T21:42:24Z", "message": "Address review comments."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8b573834ae9e407c8869f0500855de44ad495780", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/8b573834ae9e407c8869f0500855de44ad495780", "committedDate": "2020-10-21T21:50:20Z", "message": "Fix merging issue."}, "afterCommit": {"oid": "4fb61dec49f6be2722b53daf4437c6a8f7fad99d", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/4fb61dec49f6be2722b53daf4437c6a8f7fad99d", "committedDate": "2020-11-08T06:55:02Z", "message": "Fix merging issue."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI2ODExODE4", "url": "https://github.com/apache/hadoop/pull/2350#pullrequestreview-526811818", "createdAt": "2020-11-10T02:45:24Z", "commit": {"oid": "4fb61dec49f6be2722b53daf4437c6a8f7fad99d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f40b9658a2d6cd49166ccf20497f9d420625a302", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/f40b9658a2d6cd49166ccf20497f9d420625a302", "committedDate": "2020-11-17T23:50:34Z", "message": "Use lz4-java for Lz4Codec."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5571c254553931bd15420243a0a0a609ad138467", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/5571c254553931bd15420243a0a0a609ad138467", "committedDate": "2020-11-17T23:50:34Z", "message": "Add compatibility test and fix style."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ed789ed415533338473672ef1b3e999afaa2429", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/9ed789ed415533338473672ef1b3e999afaa2429", "committedDate": "2020-11-17T23:50:34Z", "message": "Copy lz4 c file and header."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1edddbdced3e3279e82cbce200b4044b7446bfa4", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/1edddbdced3e3279e82cbce200b4044b7446bfa4", "committedDate": "2020-11-17T23:50:34Z", "message": "Add lz4-java to test dependency."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ffda7e8ffa763ba1930a9a2013f9d3eeb75d2395", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/ffda7e8ffa763ba1930a9a2013f9d3eeb75d2395", "committedDate": "2020-11-17T23:50:34Z", "message": "Fix some style issues."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1fa9929dc12291daffd5ca7602ef2794b004592", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/d1fa9929dc12291daffd5ca7602ef2794b004592", "committedDate": "2020-11-17T23:50:34Z", "message": "Address review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c35a8ce80d6400af574c566a9bbe80ef682adb0e", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/c35a8ce80d6400af574c566a9bbe80ef682adb0e", "committedDate": "2020-11-17T23:50:34Z", "message": "Fix merging issue."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41e59b162b0ce265246361ac58841f1076960dc7", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/41e59b162b0ce265246361ac58841f1076960dc7", "committedDate": "2020-11-17T23:50:34Z", "message": "Separate import blocks."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6051ef6af5dea13d9856453402b007c1e4b873b9", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/6051ef6af5dea13d9856453402b007c1e4b873b9", "committedDate": "2020-11-10T04:42:17Z", "message": "Separate import blocks."}, "afterCommit": {"oid": "41e59b162b0ce265246361ac58841f1076960dc7", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/41e59b162b0ce265246361ac58841f1076960dc7", "committedDate": "2020-11-17T23:50:34Z", "message": "Separate import blocks."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c02e8ca6ae19fa85b160df7b4dcb740cd7b7ef05", "author": {"user": {"login": "viirya", "name": "Liang-Chi Hsieh"}}, "url": "https://github.com/apache/hadoop/commit/c02e8ca6ae19fa85b160df7b4dcb740cd7b7ef05", "committedDate": "2020-11-18T00:38:29Z", "message": "Just catch AssertionError and wrap it."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3743, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}