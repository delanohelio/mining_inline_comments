{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA5MjQzMDk1", "number": 2411, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxODoyMTo0OFrOEyB9sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxMzo0NTozN1rOE2xe-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwODk2NDMyOnYy", "diffSide": "RIGHT", "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQxODoyMTo0OVrOHoctsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNTo1NDoyOVrOHwjR7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE3NTUzNg==", "bodyText": "another issue: we currently don't bundle YARN test resources like capacity-scheduler.xml in hadoop-client-minicluster so this is a temporary workaround. I'll open another JIRA for this later.", "url": "https://github.com/apache/hadoop/pull/2411#discussion_r512175536", "createdAt": "2020-10-26T18:21:49Z", "author": {"login": "sunchao"}, "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "diffHunk": "@@ -73,13 +78,22 @@ public void clusterUp() throws IOException {\n         .numDataNodes(3)\n         .build();\n     cluster.waitActive();\n+\n+    conf.set(\"yarn.scheduler.capacity.root.queues\", \"default\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f2a4902cae57985f5ce8f241ac774ddba29fc39"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTgyMjc4OA==", "bodyText": "we leave out all of test/resources to stop log4j files, site configs etc getting onto the classpath of apps downstream -so making it impossible for them to choose their own options", "url": "https://github.com/apache/hadoop/pull/2411#discussion_r519822788", "createdAt": "2020-11-09T13:42:54Z", "author": {"login": "steveloughran"}, "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "diffHunk": "@@ -73,13 +78,22 @@ public void clusterUp() throws IOException {\n         .numDataNodes(3)\n         .build();\n     cluster.waitActive();\n+\n+    conf.set(\"yarn.scheduler.capacity.root.queues\", \"default\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE3NTUzNg=="}, "originalCommit": {"oid": "8f2a4902cae57985f5ce8f241ac774ddba29fc39"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA3MzY3NQ==", "bodyText": "maybe we should include them for test-only purpose? I think hadoop-client-minicluster should always be test scope right?", "url": "https://github.com/apache/hadoop/pull/2411#discussion_r520073675", "createdAt": "2020-11-09T19:41:29Z", "author": {"login": "sunchao"}, "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "diffHunk": "@@ -73,13 +78,22 @@ public void clusterUp() throws IOException {\n         .numDataNodes(3)\n         .build();\n     cluster.waitActive();\n+\n+    conf.set(\"yarn.scheduler.capacity.root.queues\", \"default\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE3NTUzNg=="}, "originalCommit": {"oid": "8f2a4902cae57985f5ce8f241ac774ddba29fc39"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY3MTcyNA==", "bodyText": "it may be test only, but the other test suite may have its own configs that it wants. If we put them in the test JAR, it becomes near impossible to change. People will hate us (more)", "url": "https://github.com/apache/hadoop/pull/2411#discussion_r520671724", "createdAt": "2020-11-10T15:54:29Z", "author": {"login": "steveloughran"}, "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "diffHunk": "@@ -73,13 +78,22 @@ public void clusterUp() throws IOException {\n         .numDataNodes(3)\n         .build();\n     cluster.waitActive();\n+\n+    conf.set(\"yarn.scheduler.capacity.root.queues\", \"default\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE3NTUzNg=="}, "originalCommit": {"oid": "8f2a4902cae57985f5ce8f241ac774ddba29fc39"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1ODY3NTU5OnYy", "diffSide": "RIGHT", "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxMzo0MToxNVrOHvvZvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxOTo0MzozM1rOHv-2Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTgyMTc1OA==", "bodyText": "should go straight after line 45 - no gap", "url": "https://github.com/apache/hadoop/pull/2411#discussion_r519821758", "createdAt": "2020-11-09T13:41:15Z", "author": {"login": "steveloughran"}, "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "diffHunk": "@@ -44,6 +44,10 @@\n import org.apache.hadoop.hdfs.web.WebHdfsTestUtil;\n import org.apache.hadoop.hdfs.web.WebHdfsConstants;\n \n+import org.apache.hadoop.yarn.server.MiniYARNCluster;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f2a4902cae57985f5ce8f241ac774ddba29fc39"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA3NDc5OQ==", "bodyText": "will fix. I was trying to follow the existing style though which separates imports based on package.", "url": "https://github.com/apache/hadoop/pull/2411#discussion_r520074799", "createdAt": "2020-11-09T19:43:33Z", "author": {"login": "sunchao"}, "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "diffHunk": "@@ -44,6 +44,10 @@\n import org.apache.hadoop.hdfs.web.WebHdfsTestUtil;\n import org.apache.hadoop.hdfs.web.WebHdfsConstants;\n \n+import org.apache.hadoop.yarn.server.MiniYARNCluster;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTgyMTc1OA=="}, "originalCommit": {"oid": "8f2a4902cae57985f5ce8f241ac774ddba29fc39"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1ODY3NjY3OnYy", "diffSide": "RIGHT", "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxMzo0MTozMVrOHvvabg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxMzo0MTozMVrOHvvabg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTgyMTkzNA==", "bodyText": "unused, according to checkstyle", "url": "https://github.com/apache/hadoop/pull/2411#discussion_r519821934", "createdAt": "2020-11-09T13:41:31Z", "author": {"login": "steveloughran"}, "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "diffHunk": "@@ -44,6 +44,10 @@\n import org.apache.hadoop.hdfs.web.WebHdfsTestUtil;\n import org.apache.hadoop.hdfs.web.WebHdfsConstants;\n \n+import org.apache.hadoop.yarn.server.MiniYARNCluster;\n+\n+import static org.junit.Assert.assertTrue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f2a4902cae57985f5ce8f241ac774ddba29fc39"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1ODY5MzA2OnYy", "diffSide": "RIGHT", "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxMzo0NTozN1rOHvvk9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQyMDoxNDo0NVrOHv_7qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTgyNDYyOQ==", "bodyText": "all services are closeable, so use IOUtil.cleanupWithLogger() & let it handle null checks and exceptions", "url": "https://github.com/apache/hadoop/pull/2411#discussion_r519824629", "createdAt": "2020-11-09T13:45:37Z", "author": {"login": "steveloughran"}, "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "diffHunk": "@@ -73,13 +78,22 @@ public void clusterUp() throws IOException {\n         .numDataNodes(3)\n         .build();\n     cluster.waitActive();\n+\n+    conf.set(\"yarn.scheduler.capacity.root.queues\", \"default\");\n+    conf.setInt(\"yarn.scheduler.capacity.root.default.capacity\", 100);\n+    yarnCluster = new MiniYARNCluster(getClass().getName(), 1, 1, 1, 1);\n+    yarnCluster.init(conf);\n+    yarnCluster.start();\n   }\n \n   @After\n   public void clusterDown() {\n     if (cluster != null) {\n       cluster.close();\n     }\n+    if (yarnCluster != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8f2a4902cae57985f5ce8f241ac774ddba29fc39"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA5MjU4Ng==", "bodyText": "Nice. Didn't know this util method, but seems we can only use it with yarnCluster.", "url": "https://github.com/apache/hadoop/pull/2411#discussion_r520092586", "createdAt": "2020-11-09T20:14:45Z", "author": {"login": "sunchao"}, "path": "hadoop-client-modules/hadoop-client-integration-tests/src/test/java/org/apache/hadoop/example/ITUseMiniCluster.java", "diffHunk": "@@ -73,13 +78,22 @@ public void clusterUp() throws IOException {\n         .numDataNodes(3)\n         .build();\n     cluster.waitActive();\n+\n+    conf.set(\"yarn.scheduler.capacity.root.queues\", \"default\");\n+    conf.setInt(\"yarn.scheduler.capacity.root.default.capacity\", 100);\n+    yarnCluster = new MiniYARNCluster(getClass().getName(), 1, 1, 1, 1);\n+    yarnCluster.init(conf);\n+    yarnCluster.start();\n   }\n \n   @After\n   public void clusterDown() {\n     if (cluster != null) {\n       cluster.close();\n     }\n+    if (yarnCluster != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTgyNDYyOQ=="}, "originalCommit": {"oid": "8f2a4902cae57985f5ce8f241ac774ddba29fc39"}, "originalPosition": 36}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3232, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}