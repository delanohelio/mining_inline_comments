{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2NjE4Mjg3", "number": 1893, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDo0MzozOFrODofo9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDoyOToxOFrODoi2_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzg4MDIzOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDo0MzozOFrOF3FCiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QxNjoxNjoyNlrOF3jrZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5ODU2OQ==", "bodyText": "that;s just a lambda expression, you should be able to go es.submit(() -> { touch(filename); return null; }", "url": "https://github.com/apache/hadoop/pull/1893#discussion_r393298569", "createdAt": "2020-03-16T20:43:38Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsClient.java", "diffHunk": "@@ -75,4 +89,80 @@ public void testUnknownHost() throws Exception {\n             \"UnknownHostException: \" + fakeAccountName,\n             () -> FileSystem.get(conf.getRawConfiguration()));\n   }\n+\n+  @Test\n+  public void testListPathWithValidListMaxResultsValues()\n+      throws IOException, ExecutionException, InterruptedException {\n+    final int fileCount = 10;\n+    final String directory = \"testWithValidListMaxResultsValues\";\n+    createDirectoryWithNFiles(directory, fileCount);\n+    final int[] testData = {fileCount + 100, fileCount + 1, fileCount,\n+        fileCount - 1, 1};\n+    for (int i = 0; i < testData.length; i++) {\n+      int listMaxResults = testData[i];\n+      setListMaxResults(listMaxResults);\n+      int expectedListResultsSize =\n+          listMaxResults > fileCount ? fileCount : listMaxResults;\n+      assertThat(listPath(directory).size(),\n+          is(equalTo(expectedListResultsSize)));\n+    }\n+  }\n+\n+  @Test\n+  public void testListPathWithValueGreaterThanServerMaximum()\n+      throws IOException, ExecutionException, InterruptedException {\n+    setListMaxResults(LIST_MAX_RESULTS_SERVER + 100);\n+    final String directory = \"testWithValueGreaterThanServerMaximum\";\n+    createDirectoryWithNFiles(directory, LIST_MAX_RESULTS_SERVER + 200);\n+    assertThat(listPath(directory).size(),\n+        is(equalTo(LIST_MAX_RESULTS_SERVER)));\n+  }\n+\n+  @Test\n+  public void testListPathWithInvalidListMaxResultsValues() throws Exception {\n+    for (int i = -1; i < 1; i++) {\n+      setListMaxResults(i);\n+      intercept(AbfsRestOperationException.class, \"Operation failed: \\\"One of \"\n+          + \"the query parameters specified in the request URI is outside\" + \" \"\n+          + \"the permissible range.\", () -> listPath(\"directory\"));\n+    }\n+  }\n+\n+  private List<ListResultEntrySchema> listPath(String directory)\n+      throws IOException {\n+    return getFileSystem().getAbfsClient()\n+        .listPath(directory, false, getListMaxResults(), null).getResult()\n+        .getListResultSchema().paths();\n+  }\n+\n+  private int getListMaxResults() throws IOException {\n+    return getFileSystem().getAbfsStore().getAbfsConfiguration()\n+        .getListMaxResults();\n+  }\n+\n+  private void setListMaxResults(int listMaxResults) throws IOException {\n+    getFileSystem().getAbfsStore().getAbfsConfiguration()\n+        .setListMaxResults(listMaxResults);\n+  }\n+\n+  private void createDirectoryWithNFiles(String directory, int n)\n+      throws ExecutionException, InterruptedException {\n+    final List<Future<Void>> tasks = new ArrayList<>();\n+    ExecutorService es = Executors.newFixedThreadPool(10);\n+    for (int i = 0; i < n; i++) {\n+      final Path fileName = new Path(\"/\" + directory + \"/test\" + i);\n+      Callable<Void> callable = new Callable<Void>() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzgwMDU1MQ==", "bodyText": "Done", "url": "https://github.com/apache/hadoop/pull/1893#discussion_r393800551", "createdAt": "2020-03-17T16:16:26Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsClient.java", "diffHunk": "@@ -75,4 +89,80 @@ public void testUnknownHost() throws Exception {\n             \"UnknownHostException: \" + fakeAccountName,\n             () -> FileSystem.get(conf.getRawConfiguration()));\n   }\n+\n+  @Test\n+  public void testListPathWithValidListMaxResultsValues()\n+      throws IOException, ExecutionException, InterruptedException {\n+    final int fileCount = 10;\n+    final String directory = \"testWithValidListMaxResultsValues\";\n+    createDirectoryWithNFiles(directory, fileCount);\n+    final int[] testData = {fileCount + 100, fileCount + 1, fileCount,\n+        fileCount - 1, 1};\n+    for (int i = 0; i < testData.length; i++) {\n+      int listMaxResults = testData[i];\n+      setListMaxResults(listMaxResults);\n+      int expectedListResultsSize =\n+          listMaxResults > fileCount ? fileCount : listMaxResults;\n+      assertThat(listPath(directory).size(),\n+          is(equalTo(expectedListResultsSize)));\n+    }\n+  }\n+\n+  @Test\n+  public void testListPathWithValueGreaterThanServerMaximum()\n+      throws IOException, ExecutionException, InterruptedException {\n+    setListMaxResults(LIST_MAX_RESULTS_SERVER + 100);\n+    final String directory = \"testWithValueGreaterThanServerMaximum\";\n+    createDirectoryWithNFiles(directory, LIST_MAX_RESULTS_SERVER + 200);\n+    assertThat(listPath(directory).size(),\n+        is(equalTo(LIST_MAX_RESULTS_SERVER)));\n+  }\n+\n+  @Test\n+  public void testListPathWithInvalidListMaxResultsValues() throws Exception {\n+    for (int i = -1; i < 1; i++) {\n+      setListMaxResults(i);\n+      intercept(AbfsRestOperationException.class, \"Operation failed: \\\"One of \"\n+          + \"the query parameters specified in the request URI is outside\" + \" \"\n+          + \"the permissible range.\", () -> listPath(\"directory\"));\n+    }\n+  }\n+\n+  private List<ListResultEntrySchema> listPath(String directory)\n+      throws IOException {\n+    return getFileSystem().getAbfsClient()\n+        .listPath(directory, false, getListMaxResults(), null).getResult()\n+        .getListResultSchema().paths();\n+  }\n+\n+  private int getListMaxResults() throws IOException {\n+    return getFileSystem().getAbfsStore().getAbfsConfiguration()\n+        .getListMaxResults();\n+  }\n+\n+  private void setListMaxResults(int listMaxResults) throws IOException {\n+    getFileSystem().getAbfsStore().getAbfsConfiguration()\n+        .setListMaxResults(listMaxResults);\n+  }\n+\n+  private void createDirectoryWithNFiles(String directory, int n)\n+      throws ExecutionException, InterruptedException {\n+    final List<Future<Void>> tasks = new ArrayList<>();\n+    ExecutorService es = Executors.newFixedThreadPool(10);\n+    for (int i = 0; i < n; i++) {\n+      final Path fileName = new Path(\"/\" + directory + \"/test\" + i);\n+      Callable<Void> callable = new Callable<Void>() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5ODU2OQ=="}, "originalCommit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzg4NDkwOnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDo0NTozMFrOF3FFpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QxNjoxNjozM1rOF3jrtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5OTM2Ng==", "bodyText": "use assertJ here and below. It is way better because of the better errors it gives, e.g.\nassertThat(listPath).describedAs(...).hasSize(...)", "url": "https://github.com/apache/hadoop/pull/1893#discussion_r393299366", "createdAt": "2020-03-16T20:45:30Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsClient.java", "diffHunk": "@@ -75,4 +89,80 @@ public void testUnknownHost() throws Exception {\n             \"UnknownHostException: \" + fakeAccountName,\n             () -> FileSystem.get(conf.getRawConfiguration()));\n   }\n+\n+  @Test\n+  public void testListPathWithValidListMaxResultsValues()\n+      throws IOException, ExecutionException, InterruptedException {\n+    final int fileCount = 10;\n+    final String directory = \"testWithValidListMaxResultsValues\";\n+    createDirectoryWithNFiles(directory, fileCount);\n+    final int[] testData = {fileCount + 100, fileCount + 1, fileCount,\n+        fileCount - 1, 1};\n+    for (int i = 0; i < testData.length; i++) {\n+      int listMaxResults = testData[i];\n+      setListMaxResults(listMaxResults);\n+      int expectedListResultsSize =\n+          listMaxResults > fileCount ? fileCount : listMaxResults;\n+      assertThat(listPath(directory).size(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzgwMDYzMA==", "bodyText": "Done", "url": "https://github.com/apache/hadoop/pull/1893#discussion_r393800630", "createdAt": "2020-03-17T16:16:33Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsClient.java", "diffHunk": "@@ -75,4 +89,80 @@ public void testUnknownHost() throws Exception {\n             \"UnknownHostException: \" + fakeAccountName,\n             () -> FileSystem.get(conf.getRawConfiguration()));\n   }\n+\n+  @Test\n+  public void testListPathWithValidListMaxResultsValues()\n+      throws IOException, ExecutionException, InterruptedException {\n+    final int fileCount = 10;\n+    final String directory = \"testWithValidListMaxResultsValues\";\n+    createDirectoryWithNFiles(directory, fileCount);\n+    final int[] testData = {fileCount + 100, fileCount + 1, fileCount,\n+        fileCount - 1, 1};\n+    for (int i = 0; i < testData.length; i++) {\n+      int listMaxResults = testData[i];\n+      setListMaxResults(listMaxResults);\n+      int expectedListResultsSize =\n+          listMaxResults > fileCount ? fileCount : listMaxResults;\n+      assertThat(listPath(directory).size(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5OTM2Ng=="}, "originalCommit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzODQwNzY3OnYy", "diffSide": "RIGHT", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDoyOToxOFrOF3KJXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwNDozMzoyMlrOF3Nqkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4MjIzNg==", "bodyText": "Do we need a MaxValue here?", "url": "https://github.com/apache/hadoop/pull/1893#discussion_r393382236", "createdAt": "2020-03-17T00:29:18Z", "author": {"login": "DadanielZ"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java", "diffHunk": "@@ -125,6 +125,11 @@\n       DefaultValue = MAX_CONCURRENT_WRITE_THREADS)\n   private int maxConcurrentWriteThreads;\n \n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = AZURE_LIST_MAX_RESULTS,\n+      MinValue = 1,\n+      DefaultValue = DEFAULT_AZURE_LIST_MAX_RESULTS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQzOTg5MA==", "bodyText": "Currently server has a maximum limit which is 5000. values >= 5000 will be defaulted to 5000. Did not want to keep max value 5000 here, in case server in future plans making changes to this.", "url": "https://github.com/apache/hadoop/pull/1893#discussion_r393439890", "createdAt": "2020-03-17T04:33:22Z", "author": {"login": "bilaharith"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java", "diffHunk": "@@ -125,6 +125,11 @@\n       DefaultValue = MAX_CONCURRENT_WRITE_THREADS)\n   private int maxConcurrentWriteThreads;\n \n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = AZURE_LIST_MAX_RESULTS,\n+      MinValue = 1,\n+      DefaultValue = DEFAULT_AZURE_LIST_MAX_RESULTS)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4MjIzNg=="}, "originalCommit": {"oid": "7291934705c45bf659a5e76a166c291027601819"}, "originalPosition": 6}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3621, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}