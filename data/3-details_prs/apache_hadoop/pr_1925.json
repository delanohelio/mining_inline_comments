{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk1NzcwMzg0", "number": 1925, "title": "HADOOP-16948. Support single writer dirs.", "bodyText": "So far, I have tested this patch by opening an output stream, writing, and syncing (via hflush or hsync). Then I broke the lease on the file and tried to write and sync again to the original output stream, obtaining an expected exception. After that, I closed the file and verified that the file contained the data from the first write but not the second write.", "createdAt": "2020-03-30T16:43:36Z", "url": "https://github.com/apache/hadoop/pull/1925", "merged": true, "mergeCommit": {"oid": "c1fde4fe94f268c6d5515b421ac47345dca8163d"}, "closed": true, "closedAt": "2021-04-12T23:47:59Z", "author": {"login": "billierinaldi"}, "timelineItems": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcTXBC0AFqTM4NTU0MzEyNg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABeMdlEegFqTYzMzg1NzM3OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NTQzMTI2", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-385543126", "createdAt": "2020-04-01T12:39:36Z", "commit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjozOTozNlrOF--qHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjozOTozNlrOF--qHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MjYyMQ==", "bodyText": "this seems to be recurrent merge pain point: too many patches adding more things to every rest call.\nProposed: how about adding a RestOperationContext struct which gets passed down, leaseId would go in there, and later other stuff (statistics, trace context, etc) ?", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401582621", "createdAt": "2020-04-01T12:39:36Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -328,13 +406,16 @@ public AbfsRestOperation renamePath(String source, final String destination, fin\n   }\n \n   public AbfsRestOperation append(final String path, final long position, final byte[] buffer, final int offset,\n-                                  final int length, boolean flush, boolean isClose)\n+                                  final int length, boolean flush, boolean isClose, final String leaseId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "originalPosition": 97}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NTQ0MDc0", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-385544074", "createdAt": "2020-04-01T12:40:51Z", "commit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0MDo1MVrOF--tMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0MDo1MVrOF--tMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MzQxMQ==", "bodyText": "PathIOException with path; make error string a const to use when matching in tests. Consider also a new LeaseRequiredException if that helps testing", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401583411", "createdAt": "2020-04-01T12:40:51Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -168,6 +177,10 @@ public synchronized void write(final byte[] data, final int off, final int lengt\n       throw new IndexOutOfBoundsException();\n     }\n \n+    if (lease != null && lease.isFreed()) {\n+      throw new IOException(\"Attempted to write to file without lease: \" + path);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NTQ0MTkx", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-385544191", "createdAt": "2020-04-01T12:41:00Z", "commit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0MTowMFrOF--teA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0MTowMFrOF--teA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MzQ4MA==", "bodyText": "will this ever fail?", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401583480", "createdAt": "2020-04-01T12:41:00Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -261,6 +274,9 @@ public synchronized void close() throws IOException {\n       // See HADOOP-16785\n       throw wrapException(path, e.getMessage(), e);\n     } finally {\n+      if (lease != null) {\n+        lease.free();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NTQ0NjIw", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-385544620", "createdAt": "2020-04-01T12:41:34Z", "commit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0MTozNFrOF--u3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0MTozNFrOF--u3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MzgzNw==", "bodyText": "we are on SLF4J now", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401583837", "createdAt": "2020-04-01T12:41:34Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.commons.logging.Log;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NTQ1Mzc5", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-385545379", "createdAt": "2020-04-01T12:42:38Z", "commit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0MjozOVrOF--xLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0MjozOVrOF--xLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4NDQzMA==", "bodyText": "switch to SLF4J logging style; include full stack @ debug level", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401584430", "createdAt": "2020-04-01T12:42:39Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely\n+ * using a background thread. Use it to synchronize distributed processes,\n+ * or to prevent writes to the blob by other processes that don't\n+ * have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is\n+ * acquired.\n+ *\n+ * Call free() to release the Lease.\n+ *\n+ * You can use this Lease like a distributed lock. If the holder process\n+ * dies, the lease will time out since it won't be renewed.\n+ *\n+ * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n+ */\n+public class SelfRenewingLease {\n+\n+  private final AzureBlobFileSystemStore store;\n+  private final Path path;\n+  private Thread renewer;\n+  private volatile boolean leaseFreed;\n+  private String leaseID = null;\n+  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n+\n+  // Time to wait to renew lease in milliseconds\n+  public static final int LEASE_RENEWAL_PERIOD = 40000;\n+  private static final Log LOG = LogFactory.getLog(SelfRenewingLease.class);\n+\n+  // Used to allocate thread serial numbers in thread name\n+  private static AtomicInteger threadNumber = new AtomicInteger(0);\n+\n+\n+  // Time to wait to retry getting the lease in milliseconds\n+  @VisibleForTesting\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n+\n+  public SelfRenewingLease(AzureBlobFileSystemStore store, Path path) {\n+\n+    this.leaseFreed = false;\n+    this.store = store;\n+    this.path = path;\n+\n+    // Keep trying to get the lease until you get it.\n+    while(leaseID == null) {\n+      try {\n+        leaseID = store.acquireLease(this.path, LEASE_TIMEOUT);\n+      } catch (IOException e) {\n+        LOG.info(\"Caught exception when trying to get lease on blob \" + path + \". \" + e.getMessage());\n+      }\n+      if (leaseID == null) {\n+        try {\n+          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);\n+        } catch (InterruptedException e) {\n+\n+          // Restore the interrupted status\n+          Thread.currentThread().interrupt();\n+        }\n+      }\n+    }\n+    renewer = new Thread(new Renewer());\n+\n+    // A Renewer running should not keep JVM from exiting, so make it a daemon.\n+    renewer.setDaemon(true);\n+    renewer.setName(\"AzureLeaseRenewer-\" + threadNumber.getAndIncrement());\n+    renewer.start();\n+    LOG.debug(\"Acquired lease \" + leaseID + \" on \" + path\n+        + \" managed by thread \" + renewer.getName());\n+  }\n+\n+  /**\n+   * Free the lease and stop the keep-alive thread.\n+   */\n+  public void free() {\n+    try {\n+      store.releaseLease(path, leaseID);\n+    } catch (IOException e) {\n+      LOG.info(\"Exception when trying to free lease \" + leaseID + \" on \" + path + \". \" + e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "originalPosition": 108}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1NTQ2MjUx", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-385546251", "createdAt": "2020-04-01T12:43:50Z", "commit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0Mzo1MVrOF--z_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo0Mzo1MVrOF--z_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4NTE1MA==", "bodyText": "should be tied in to the FileSystem instance lifecycle too: an FS instance should really have a weak ref to all leases created under it, and fs.close to stop them all", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401585150", "createdAt": "2020-04-01T12:43:51Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely\n+ * using a background thread. Use it to synchronize distributed processes,\n+ * or to prevent writes to the blob by other processes that don't\n+ * have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is\n+ * acquired.\n+ *\n+ * Call free() to release the Lease.\n+ *\n+ * You can use this Lease like a distributed lock. If the holder process\n+ * dies, the lease will time out since it won't be renewed.\n+ *\n+ * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n+ */\n+public class SelfRenewingLease {\n+\n+  private final AzureBlobFileSystemStore store;\n+  private final Path path;\n+  private Thread renewer;\n+  private volatile boolean leaseFreed;\n+  private String leaseID = null;\n+  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n+\n+  // Time to wait to renew lease in milliseconds\n+  public static final int LEASE_RENEWAL_PERIOD = 40000;\n+  private static final Log LOG = LogFactory.getLog(SelfRenewingLease.class);\n+\n+  // Used to allocate thread serial numbers in thread name\n+  private static AtomicInteger threadNumber = new AtomicInteger(0);\n+\n+\n+  // Time to wait to retry getting the lease in milliseconds\n+  @VisibleForTesting\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n+\n+  public SelfRenewingLease(AzureBlobFileSystemStore store, Path path) {\n+\n+    this.leaseFreed = false;\n+    this.store = store;\n+    this.path = path;\n+\n+    // Keep trying to get the lease until you get it.\n+    while(leaseID == null) {\n+      try {\n+        leaseID = store.acquireLease(this.path, LEASE_TIMEOUT);\n+      } catch (IOException e) {\n+        LOG.info(\"Caught exception when trying to get lease on blob \" + path + \". \" + e.getMessage());\n+      }\n+      if (leaseID == null) {\n+        try {\n+          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);\n+        } catch (InterruptedException e) {\n+\n+          // Restore the interrupted status\n+          Thread.currentThread().interrupt();\n+        }\n+      }\n+    }\n+    renewer = new Thread(new Renewer());\n+\n+    // A Renewer running should not keep JVM from exiting, so make it a daemon.\n+    renewer.setDaemon(true);\n+    renewer.setName(\"AzureLeaseRenewer-\" + threadNumber.getAndIncrement());\n+    renewer.start();\n+    LOG.debug(\"Acquired lease \" + leaseID + \" on \" + path\n+        + \" managed by thread \" + renewer.getName());\n+  }\n+\n+  /**\n+   * Free the lease and stop the keep-alive thread.\n+   */\n+  public void free() {\n+    try {\n+      store.releaseLease(path, leaseID);\n+    } catch (IOException e) {\n+      LOG.info(\"Exception when trying to free lease \" + leaseID + \" on \" + path + \". \" + e.getMessage());\n+    } finally {\n+\n+      // Even if releasing the lease fails (e.g. because the file was deleted),\n+      // make sure to record that we freed the lease, to terminate the\n+      // keep-alive thread.\n+      leaseFreed = true;\n+      LOG.debug(\"Freed lease \" + leaseID + \" on \" + path\n+          + \" managed by thread \" + renewer.getName());\n+    }\n+  }\n+\n+  public boolean isFreed() {\n+    return leaseFreed;\n+  }\n+\n+  public String getLeaseID() {\n+    return leaseID;\n+  }\n+\n+  private class Renewer implements Runnable {\n+\n+    /**\n+     * Start a keep-alive thread that will continue to renew\n+     * the lease until it is freed or the process dies.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a"}, "originalPosition": 132}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/d98c26ca2a785f2523c75b59b8eb1e356af56f4a", "committedDate": "2020-03-30T16:23:38Z", "message": "HADOOP-16948. Support single writer dirs."}, "afterCommit": {"oid": "d6658798a5140edf4743e47ef0ff1a08f2142551", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/d6658798a5140edf4743e47ef0ff1a08f2142551", "committedDate": "2020-10-27T21:11:28Z", "message": "HADOOP-16948. Support single writer dirs."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE5OTIzNTQ2", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-519923546", "createdAt": "2020-10-29T17:45:18Z", "commit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxNzo0NToxOFrOHqni7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxNzo0OTo1OVrOHqnvqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ1MDE1Ng==", "bodyText": "This likely to take time? I'm worried about what happens if there's network problems and this gets invoked. Ideally this would be done in parallel, but abfs doesnt (yet) have a thread pool", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r514450156", "createdAt": "2020-10-29T17:45:18Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -243,6 +252,16 @@ public String getPrimaryGroup() {\n \n   @Override\n   public void close() throws IOException {\n+    for (SelfRenewingLease lease : leaseRefs.keySet()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ1MDQ5NQ==", "bodyText": "go on, add some javadocs", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r514450495", "createdAt": "2020-10-29T17:45:47Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -685,10 +712,38 @@ public OutputStream openFileForWrite(final Path path, final FileSystem.Statistic\n           statistics,\n           relativePath,\n           offset,\n-          populateAbfsOutputStreamContext(isAppendBlob));\n+          leaseRefs,\n+          populateAbfsOutputStreamContext(isAppendBlob, enableSingleWriter));\n     }\n   }\n \n+  public String acquireLease(final Path path, final int duration) throws AzureBlobFileSystemException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ1MjI5MQ==", "bodyText": "as well as the usual import grouping/ordering, we've gone to shaded guava on trunk", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r514452291", "createdAt": "2020-10-29T17:48:23Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import com.google.common.base.Preconditions;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ1MzQxNg==", "bodyText": "Prefer you use our normal RetryPolicy if possible", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r514453416", "createdAt": "2020-10-29T17:49:59Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely\n+ * using a background thread. Use it to synchronize distributed processes,\n+ * or to prevent writes to the blob by other processes that don't\n+ * have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is\n+ * acquired.\n+ *\n+ * Call free() to release the Lease.\n+ *\n+ * You can use this Lease like a distributed lock. If the holder process\n+ * dies, the lease will time out since it won't be renewed.\n+ *\n+ * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n+ */\n+public final class SelfRenewingLease {\n+\n+  private final AbfsClient client;\n+  private final Path path;\n+  private Thread renewer;\n+  private volatile boolean leaseFreed;\n+  private String leaseID = null;\n+  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n+\n+  // Time to wait to renew lease in milliseconds\n+  public static final int LEASE_RENEWAL_PERIOD = 40000;\n+  public static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+\n+  // Used to allocate thread serial numbers in thread name\n+  private static AtomicInteger threadNumber = new AtomicInteger(0);\n+\n+\n+  // Time to wait to retry getting the lease in milliseconds\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n+  static final int LEASE_MAX_RETRIES = 5;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Exception innerException) {\n+      super(ERR_ACQUIRING_LEASE, innerException);\n+    }\n+  }\n+\n+  public SelfRenewingLease(AbfsClient client, Path path) throws AzureBlobFileSystemException {\n+\n+    this.leaseFreed = false;\n+    this.client = client;\n+    this.path = path;\n+\n+    // Try to get the lease a specified number of times, else throw an error\n+    int numRetries = 0;\n+    while (leaseID == null && numRetries < LEASE_MAX_RETRIES) {\n+      numRetries++;\n+      try {\n+        LOG.debug(\"lease path: {}\", path);\n+        final AbfsRestOperation op =\n+            client.acquireLease(getRelativePath(path),\n+                LEASE_TIMEOUT);\n+\n+        leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n+      } catch (IOException e) {\n+        if (numRetries < LEASE_MAX_RETRIES) {\n+          LOG.info(\"Caught exception when trying to acquire lease on blob {}, retrying: {}\", path,\n+              e.getMessage());\n+          LOG.debug(\"Exception acquiring lease\", e);\n+        } else {\n+          throw new LeaseException(e);\n+        }\n+      }\n+      if (leaseID == null) {\n+        try {\n+          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "originalPosition": 104}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM5NDk4NTMw", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-539498530", "createdAt": "2020-11-26T18:11:37Z", "commit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxODoxMTozOFrOH6ke6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQxODoxNDo1M1rOH6ki_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3NzE5NA==", "bodyText": "how about using DurationInfo in the try with resources (logging @ debug) to track how long acquire/release took. I can imagine it can take a while to acquire. Indeed, do we have to worry about timeouts, heartbeats, etc?", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r531177194", "createdAt": "2020-11-26T18:11:38Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -475,6 +475,55 @@ public FileStatus getFileStatus(final Path f) throws IOException {\n     }\n   }\n \n+  public String acquireLease(final Path f, final int duration) throws IOException {\n+    LOG.debug(\"AzureBlobFileSystem.acquireLease path: {}\", f);\n+\n+    Path qualifiedPath = makeQualified(f);\n+\n+    try {\n+      return abfsStore.acquireLease(qualifiedPath, duration);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3NzY2MQ==", "bodyText": "o.a.h.utils.IOUtils.close methods do this", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r531177661", "createdAt": "2020-11-26T18:13:12Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+            e.getMessage().contains(ERR_PARALLEL_ACCESS_DETECTED));\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {\n+      out.write(1);\n+      out.hsync();\n+      Assert.fail(\"Expected exception on write after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+    try {\n+      out.close();\n+      Assert.fail(\"Expected exception on close after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+\n+    Assert.assertTrue(((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed());\n+\n+    try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+      out2.write(2);\n+      out2.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedAfterBreak() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = null;\n+    try {\n+      out = fs.create(testFilePath);\n+      out.write(0);\n+\n+      fs.breakLease(testFilePath);\n+      while (!((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed()) {\n+        try {\n+          Thread.sleep(1000);\n+        } catch (InterruptedException e) {\n+        }\n+      }\n+    } finally {\n+      try {\n+        if (out != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3NzkyMQ==", "bodyText": "GenericTestUtils lets you assert something is in the error message. Its critical to rethrow (maybe wrapped) the exception if it is not the one you were expecting", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r531177921", "createdAt": "2020-11-26T18:14:02Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+            e.getMessage().contains(ERR_PARALLEL_ACCESS_DETECTED));\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {\n+      out.write(1);\n+      out.hsync();\n+      Assert.fail(\"Expected exception on write after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+    try {\n+      out.close();\n+      Assert.fail(\"Expected exception on close after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+\n+    Assert.assertTrue(((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed());\n+\n+    try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+      out2.write(2);\n+      out2.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedAfterBreak() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = null;\n+    try {\n+      out = fs.create(testFilePath);\n+      out.write(0);\n+\n+      fs.breakLease(testFilePath);\n+      while (!((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed()) {\n+        try {\n+          Thread.sleep(1000);\n+        } catch (InterruptedException e) {\n+        }\n+      }\n+    } finally {\n+      try {\n+        if (out != null) {\n+          out.close();\n+        }\n+        // exception might or might not occur\n+      } catch (IOException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "originalPosition": 242}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3ODIzNw==", "bodyText": "and add a message to raise if the condition is met.\nnote, it's ok to use AssertJ for your asserts, we are adopting it more broadly and enjoying its diagnostics.", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r531178237", "createdAt": "2020-11-26T18:14:53Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+            e.getMessage().contains(ERR_PARALLEL_ACCESS_DETECTED));\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {\n+      out.write(1);\n+      out.hsync();\n+      Assert.fail(\"Expected exception on write after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+    try {\n+      out.close();\n+      Assert.fail(\"Expected exception on close after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+\n+    Assert.assertTrue(((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed());\n+\n+    try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+      out2.write(2);\n+      out2.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedAfterBreak() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = null;\n+    try {\n+      out = fs.create(testFilePath);\n+      out.write(0);\n+\n+      fs.breakLease(testFilePath);\n+      while (!((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed()) {\n+        try {\n+          Thread.sleep(1000);\n+        } catch (InterruptedException e) {\n+        }\n+      }\n+    } finally {\n+      try {\n+        if (out != null) {\n+          out.close();\n+        }\n+        // exception might or might not occur\n+      } catch (IOException e) {\n+        Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+            e.getMessage().contains(ERR_LEASE_EXPIRED));\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8"}, "originalPosition": 247}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bb65e714888f104676915e8c54a0c2b00b3168e8", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/bb65e714888f104676915e8c54a0c2b00b3168e8", "committedDate": "2020-10-28T18:01:51Z", "message": "HADOOP-16948. Fix remaining checkstyle problems."}, "afterCommit": {"oid": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "committedDate": "2021-01-14T15:28:23Z", "message": "HADOOP-16948. Convert ABFS client to use an executor for lease ops"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY5MjM4MTg3", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-569238187", "createdAt": "2021-01-15T13:00:06Z", "commit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzowMDowN1rOIUbXfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzoyMzozOVrOIUcHlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MDgxMw==", "bodyText": "can you pull up to the .thirdparty section and add a newline after. Our guava shading project is confusing IDEs and making backporting/cherrypicking harder", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558290813", "createdAt": "2021-01-15T13:00:07Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -29,13 +29,23 @@\n import java.util.ArrayList;\n import java.util.List;\n import java.util.Locale;\n+import java.util.UUID;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n \n import org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting;\n import org.apache.hadoop.thirdparty.com.google.common.base.Strings;\n import org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory;\n import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n import org.apache.hadoop.fs.azurebfs.constants.HttpQueryParams;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MTc4OQ==", "bodyText": "Prefer you use HadoopExecutors here.", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558291789", "createdAt": "2021-01-15T13:01:59Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -106,6 +118,9 @@ private AbfsClient(final URL baseUrl, final SharedKeyCredentials sharedKeyCreden\n     this.userAgent = initializeUserAgent(abfsConfiguration, sslProviderName);\n     this.abfsPerfTracker = abfsClientContext.getAbfsPerfTracker();\n     this.abfsCounters = abfsClientContext.getAbfsCounters();\n+\n+    this.executorService = MoreExecutors.listeningDecorator(\n+        Executors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MTk1OQ==", "bodyText": "HadoopExecutors.shutdown has some error handling here", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558291959", "createdAt": "2021-01-15T13:02:20Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -129,6 +144,7 @@ public void close() throws IOException {\n     if (tokenProvider instanceof Closeable) {\n       IOUtils.cleanupWithLogger(LOG, (Closeable) tokenProvider);\n     }\n+    executorService.shutdownNow();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MjQxMQ==", "bodyText": "if the RestOperation doesn't log anything, add something here. Will help debug locking problems", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558292411", "createdAt": "2021-01-15T13:03:23Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -306,6 +322,83 @@ public AbfsRestOperation createPath(final String path, final boolean isFile, fin\n     return op;\n   }\n \n+  public AbfsRestOperation acquireLease(final String path, int duration) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, ACQUIRE_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_DURATION, Integer.toString(duration)));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_PROPOSED_LEASE_ID, UUID.randomUUID().toString()));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MjYzMg==", "bodyText": "add a log if needed", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558292632", "createdAt": "2021-01-15T13:03:52Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -306,6 +322,83 @@ public AbfsRestOperation createPath(final String path, final boolean isFile, fin\n     return op;\n   }\n \n+  public AbfsRestOperation acquireLease(final String path, int duration) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, ACQUIRE_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_DURATION, Integer.toString(duration)));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_PROPOSED_LEASE_ID, UUID.randomUUID().toString()));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(\n+        AbfsRestOperationType.LeasePath,\n+        this,\n+        HTTP_METHOD_POST,\n+        url,\n+        requestHeaders);\n+    op.execute();\n+    return op;\n+  }\n+\n+  public AbfsRestOperation renewLease(final String path, final String leaseId) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, RENEW_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ID, leaseId));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MjY5Nw==", "bodyText": "+log", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558292697", "createdAt": "2021-01-15T13:03:59Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -306,6 +322,83 @@ public AbfsRestOperation createPath(final String path, final boolean isFile, fin\n     return op;\n   }\n \n+  public AbfsRestOperation acquireLease(final String path, int duration) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, ACQUIRE_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_DURATION, Integer.toString(duration)));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_PROPOSED_LEASE_ID, UUID.randomUUID().toString()));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(\n+        AbfsRestOperationType.LeasePath,\n+        this,\n+        HTTP_METHOD_POST,\n+        url,\n+        requestHeaders);\n+    op.execute();\n+    return op;\n+  }\n+\n+  public AbfsRestOperation renewLease(final String path, final String leaseId) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, RENEW_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ID, leaseId));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(\n+        AbfsRestOperationType.LeasePath,\n+        this,\n+        HTTP_METHOD_POST,\n+        url,\n+        requestHeaders);\n+    op.execute();\n+    return op;\n+  }\n+\n+  public AbfsRestOperation releaseLease(final String path, final String leaseId) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, RELEASE_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ID, leaseId));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MzYzNQ==", "bodyText": "this should go into the AbfsOutputStreamContext, its where we are adding more state for a stream constructor", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558293635", "createdAt": "2021-01-15T13:05:51Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -113,7 +120,8 @@ public AbfsOutputStream(\n           final Statistics statistics,\n           final String path,\n           final long position,\n-          AbfsOutputStreamContext abfsOutputStreamContext) {\n+          final Map<SelfRenewingLease, Object> leaseRefs,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5NDM4OQ==", "bodyText": "is isLeaseFreed()", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558294389", "createdAt": "2021-01-15T13:07:16Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -209,6 +226,10 @@ public synchronized void write(final byte[] data, final int off, final int lengt\n       throw new IndexOutOfBoundsException();\n     }\n \n+    if (lease != null && lease.isFreed()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5NDQ3MQ==", "bodyText": "use hasLease()", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558294471", "createdAt": "2021-01-15T13:07:29Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -312,6 +333,10 @@ public synchronized void close() throws IOException {\n       // See HADOOP-16785\n       throw wrapException(path, e.getMessage(), e);\n     } finally {\n+      if (lease != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5ODM1Mw==", "bodyText": "import ordering. should be java.* javax.* \\n non-asf-and-hadoop.thirdparty \\n o.a.a", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558298353", "createdAt": "2021-01-15T13:14:48Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.Path;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5ODgwMQ==", "bodyText": "keep t's stack trace by passing up to superclass or in initCause()", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558298801", "createdAt": "2021-01-15T13:15:38Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n+import static java.net.HttpURLConnection.HTTP_INTERNAL_ERROR;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n+ */\n+public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+\n+  static final int LEASE_DURATION = 60; // Lease duration in seconds\n+  static final int LEASE_RENEWAL_PERIOD = 40; // Lease renewal interval in seconds\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5OTQyMQ==", "bodyText": "move to lower group", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558299421", "createdAt": "2021-01-15T13:16:48Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -39,6 +39,7 @@\n \n import org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting;\n import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n+import org.apache.hadoop.util.DurationInfo;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMDA5NA==", "bodyText": "do we need to worry about running out of workers here, timeouts etc?", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558300094", "createdAt": "2021-01-15T13:17:59Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -243,7 +255,24 @@ public String getPrimaryGroup() {\n \n   @Override\n   public void close() throws IOException {\n-    IOUtils.cleanupWithLogger(LOG, client);\n+    List<ListenableFuture<?>> futures = new ArrayList<>();\n+    for (SelfRenewingLease lease : leaseRefs.keySet()) {\n+      if (lease == null) {\n+        continue;\n+      }\n+      ListenableFuture<?> future = client.submit(() -> lease.free());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMTAxNA==", "bodyText": "usual comment about import ordering.", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558301014", "createdAt": "2021-01-15T13:19:43Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.conf.Configuration;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMjkxNA==", "bodyText": "use LambdaTestUtils; return a string with that error message in the closure for it to be used in the exception. Ideally add out.toString() too. eg.\nintercept(ioe, ERR_LEASE_EXPIRED, () -> {\n  out..write(1);\n  out.hsync();\n  return \"expected exception but got \" + out;\n  });", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558302914", "createdAt": "2021-01-15T13:23:14Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n+import static org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys.FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_ID_SPECIFIED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+  private final boolean isHNSEnabled;\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+\n+    this.isHNSEnabled = getConfiguration()\n+        .getBoolean(FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT, false);\n+  }\n+\n+  private AzureBlobFileSystem getCustomFileSystem(String singleWriterDirs, int numLeaseThreads)\n+      throws Exception {\n+    Configuration conf = getRawConfiguration();\n+    conf.setBoolean(String.format(\"fs.%s.impl.disable.cache\", getAbfsScheme()), true);\n+    conf.set(FS_AZURE_SINGLE_WRITER_KEY, singleWriterDirs);\n+    conf.setInt(FS_AZURE_LEASE_THREADS, numLeaseThreads);\n+    return getFileSystem(conf);\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testNoLeaseThreads() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 0);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.fail(\"No failure when lease requested with 0 lease threads\");\n+    } catch (Exception e) {\n+      GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_THREADS, e);\n+    }\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws Exception {\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    final AzureBlobFileSystem fs =\n+        getCustomFileSystem(testFilePath.getParent().getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        if (isHNSEnabled) {\n+          GenericTestUtils.assertExceptionContains(ERR_PARALLEL_ACCESS_DETECTED, e);\n+        } else {\n+          GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_ID_SPECIFIED, e);\n+        }\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 209}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzEyNw==", "bodyText": "do we really want a failure in close?", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558303127", "createdAt": "2021-01-15T13:23:39Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n+import static org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys.FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_ID_SPECIFIED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+  private final boolean isHNSEnabled;\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+\n+    this.isHNSEnabled = getConfiguration()\n+        .getBoolean(FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT, false);\n+  }\n+\n+  private AzureBlobFileSystem getCustomFileSystem(String singleWriterDirs, int numLeaseThreads)\n+      throws Exception {\n+    Configuration conf = getRawConfiguration();\n+    conf.setBoolean(String.format(\"fs.%s.impl.disable.cache\", getAbfsScheme()), true);\n+    conf.set(FS_AZURE_SINGLE_WRITER_KEY, singleWriterDirs);\n+    conf.setInt(FS_AZURE_LEASE_THREADS, numLeaseThreads);\n+    return getFileSystem(conf);\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testNoLeaseThreads() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 0);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.fail(\"No failure when lease requested with 0 lease threads\");\n+    } catch (Exception e) {\n+      GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_THREADS, e);\n+    }\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws Exception {\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    final AzureBlobFileSystem fs =\n+        getCustomFileSystem(testFilePath.getParent().getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        if (isHNSEnabled) {\n+          GenericTestUtils.assertExceptionContains(ERR_PARALLEL_ACCESS_DETECTED, e);\n+        } else {\n+          GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_ID_SPECIFIED, e);\n+        }\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {\n+      out.write(1);\n+      out.hsync();\n+      Assert.fail(\"Expected exception on write after lease break\");\n+    } catch (IOException e) {\n+      GenericTestUtils.assertExceptionContains(ERR_LEASE_EXPIRED, e);\n+    }\n+    try {\n+      out.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 217}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxMTg3NjM3", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-571187637", "createdAt": "2021-01-19T12:17:43Z", "commit": {"oid": "978cedb7b63d6a1b09db291511cc87ae53c7cab0"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMjoxNzo0M1rOIWL9QQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMjoyNDoyMlrOIWMLVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNTQ4OQ==", "bodyText": "can you make sure this executor marks its threads as daemons. Otherwise processes can hang during shutdown. @bgaborg has encountered this elsewhere", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560135489", "createdAt": "2021-01-19T12:17:43Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -120,7 +120,7 @@ private AbfsClient(final URL baseUrl, final SharedKeyCredentials sharedKeyCreden\n     this.abfsCounters = abfsClientContext.getAbfsCounters();\n \n     this.executorService = MoreExecutors.listeningDecorator(\n-        Executors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads()));\n+        HadoopExecutors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "978cedb7b63d6a1b09db291511cc87ae53c7cab0"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNjUxNA==", "bodyText": "I think I'd keep that t text in the superclass text, in case a deep tree causes the nested cause not to be listed.\nbut: use toString() (implicitly) rather than getMessage, because some exceptions (NPW) have a null message.", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560136514", "createdAt": "2021-01-19T12:19:31Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -71,7 +72,7 @@\n \n   public static class LeaseException extends AzureBlobFileSystemException {\n     public LeaseException(Throwable t) {\n-      super(ERR_ACQUIRING_LEASE + \": \" + t.getMessage());\n+      super(ERR_ACQUIRING_LEASE, t);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "978cedb7b63d6a1b09db291511cc87ae53c7cab0"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNzE3Mg==", "bodyText": "just rethrow it or wrap in an assertion error. we need that full stack trace", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560137172", "createdAt": "2021-01-19T12:20:36Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -146,8 +150,7 @@ private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expec\n         out2.hsync();\n       } catch (IOException e) {\n         if (expectException) {\n-          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n-              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+          GenericTestUtils.assertExceptionContains(ERR_ACQUIRING_LEASE, e);\n         } else {\n           Assert.fail(\"Unexpected exception \" + e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "978cedb7b63d6a1b09db291511cc87ae53c7cab0"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNzU1Nw==", "bodyText": "should it be doing that flush?", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560137557", "createdAt": "2021-01-19T12:21:23Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n+import static org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys.FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_ID_SPECIFIED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+  private final boolean isHNSEnabled;\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+\n+    this.isHNSEnabled = getConfiguration()\n+        .getBoolean(FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT, false);\n+  }\n+\n+  private AzureBlobFileSystem getCustomFileSystem(String singleWriterDirs, int numLeaseThreads)\n+      throws Exception {\n+    Configuration conf = getRawConfiguration();\n+    conf.setBoolean(String.format(\"fs.%s.impl.disable.cache\", getAbfsScheme()), true);\n+    conf.set(FS_AZURE_SINGLE_WRITER_KEY, singleWriterDirs);\n+    conf.setInt(FS_AZURE_LEASE_THREADS, numLeaseThreads);\n+    return getFileSystem(conf);\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testNoLeaseThreads() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 0);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.fail(\"No failure when lease requested with 0 lease threads\");\n+    } catch (Exception e) {\n+      GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_THREADS, e);\n+    }\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws Exception {\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    final AzureBlobFileSystem fs =\n+        getCustomFileSystem(testFilePath.getParent().getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        if (isHNSEnabled) {\n+          GenericTestUtils.assertExceptionContains(ERR_PARALLEL_ACCESS_DETECTED, e);\n+        } else {\n+          GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_ID_SPECIFIED, e);\n+        }\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {\n+      out.write(1);\n+      out.hsync();\n+      Assert.fail(\"Expected exception on write after lease break\");\n+    } catch (IOException e) {\n+      GenericTestUtils.assertExceptionContains(ERR_LEASE_EXPIRED, e);\n+    }\n+    try {\n+      out.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzEyNw=="}, "originalCommit": {"oid": "c4082f019e25b010c1c36f0688cf0cb676b727d7"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzOTA5Mg==", "bodyText": "little architecture question. Would this be better in the Store than the FS? I don't know, and it is higher level than the Rest API, isn't it? Which implies this is the right place.", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560139092", "createdAt": "2021-01-19T12:24:22Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -476,6 +476,20 @@ public FileStatus getFileStatus(final Path f) throws IOException {\n     }\n   }\n \n+  /**\n+   * Acquire a lease on an ABFS file for a specified duration. This requires the file to exist.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "978cedb7b63d6a1b09db291511cc87ae53c7cab0"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTg1ODIyMTkz", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-585822193", "createdAt": "2021-02-08T18:58:07Z", "commit": {"oid": "978cedb7b63d6a1b09db291511cc87ae53c7cab0"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxODo1ODowN1rOIhx6TA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOFQxODo1ODowN1rOIhx6TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjI5MTY2MA==", "bodyText": "good writeup\n\nis there any validation here, that if a path in the local FS is to be leased then the executor count must be >1?\nwhat if I'm working with >1 FS? Will this configuration be per-fs? Or does it take a list of paths which can be full URIs to paths in a store? That's what we ended up doing with s3a authoritative paths0", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r572291660", "createdAt": "2021-02-08T18:58:07Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/site/markdown/abfs.md", "diffHunk": "@@ -877,6 +877,21 @@ enabled for your Azure Storage account.\"\n The directories can be specified as comma separated values. By default the value\n is \"/hbase\"\n \n+### <a name=\"singlewriteroptions\"></a> Single Writer Options\n+`fs.azure.singlewriter.directories`: Directories for single writer support\n+can be specified comma separated in this config. By default, multiple\n+clients will be able to write to the same file simultaneously. When writing\n+to files contained within the directories specified in this config, the\n+client will obtain a lease on the file that will prevent any other clients\n+from writing to the file. The lease will be renewed by the client until the\n+output stream is closed, after which it will be released. To revoke a client's\n+write access for a file, the AzureBlobFilesystem breakLease method may be\n+ called.\n+\n+`fs.azure.lease.threads`: This is the size of the thread pool that will be\n+used for lease operations for single writer directories. By default the value\n+is 0, so it must be set to at least 1 to support single writer directories.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "978cedb7b63d6a1b09db291511cc87ae53c7cab0"}, "originalPosition": 17}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "978cedb7b63d6a1b09db291511cc87ae53c7cab0", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/978cedb7b63d6a1b09db291511cc87ae53c7cab0", "committedDate": "2021-01-17T20:15:57Z", "message": "HADOOP-16948. Address review comments"}, "afterCommit": {"oid": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/a176dc742dcae1efc5a3515f5fba53e4198861ae", "committedDate": "2021-03-03T00:00:26Z", "message": "HADOOP-16948. Add error messages to test assertions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA1MTk4ODM2", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-605198836", "createdAt": "2021-03-05T14:13:53Z", "commit": {"oid": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjExNjE4MDk1", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-611618095", "createdAt": "2021-03-13T18:17:21Z", "commit": {"oid": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xM1QxODoxNzoyMVrOI2RqEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xM1QxODoyMTozNlrOI2Rr9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzMxNQ==", "bodyText": "Background threads that will renew lease every 67% of lease i.e. 10 seconds for 15 second lease and 40 seconds for 60 second lease will add extra cost to customers", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r593783315", "createdAt": "2021-03-13T18:17:21Z", "author": {"login": "snehavarma"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n+ */\n+public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+\n+  static final float LEASE_RENEWAL_PERCENT_OF_DURATION = 0.67f; // Lease renewal percent of duration\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+  private final int duration;\n+  private final int renewalPeriod;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n+    }\n+  }\n+\n+  public SelfRenewingLease(AbfsClient client, String path, int duration) throws AzureBlobFileSystemException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzcwMQ==", "bodyText": "Please check if infinite lease is sufficient for your use case.", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r593783701", "createdAt": "2021-03-13T18:20:14Z", "author": {"login": "snehavarma"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n+ */\n+public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4Mzc5Nw==", "bodyText": "Error handling for cases when append may take more time than lease expiry needs to be added incase there is a finite lease.", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r593783797", "createdAt": "2021-03-13T18:21:36Z", "author": {"login": "snehavarma"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n+ */\n+public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+\n+  static final float LEASE_RENEWAL_PERCENT_OF_DURATION = 0.67f; // Lease renewal percent of duration\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+  private final int duration;\n+  private final int renewalPeriod;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n+    }\n+  }\n+\n+  public SelfRenewingLease(AbfsClient client, String path, int duration) throws AzureBlobFileSystemException {\n+    this.leaseFreed = false;\n+    this.client = client;\n+    this.path = path;\n+    this.duration = duration;\n+    this.renewalPeriod = (int) (LEASE_RENEWAL_PERCENT_OF_DURATION * this.duration);\n+\n+    if (client.getNumLeaseThreads() < 1) {\n+      throw new LeaseException(ERR_NO_LEASE_THREADS);\n+    }\n+\n+    // Try to get the lease a specified number of times, else throw an error\n+    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n+        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n+    acquireLease(retryPolicy, 0, 0);\n+\n+    while (leaseID == null && exception == null) {\n+    }\n+    if (exception != null) {\n+      LOG.error(\"Failed to acquire lease on {}\", path);\n+      throw new LeaseException(exception);\n+    }\n+\n+    if (duration != INFINITE_LEASE_DURATION) {\n+      renewLease(renewalPeriod);\n+    }\n+\n+    LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+  }\n+\n+  private void acquireLease(RetryPolicy retryPolicy, int numRetries, long delay)\n+      throws LeaseException {\n+    LOG.debug(\"Attempting to acquire lease on {}, retry {}\", path, numRetries);\n+    if (future != null && !future.isDone()) {\n+      throw new LeaseException(ERR_LEASE_FUTURE_EXISTS);\n+    }\n+    future = client.schedule(() -> client.acquireLease(path, duration),\n+        delay, TimeUnit.SECONDS);\n+    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n+      @Override\n+      public void onSuccess(@Nullable AbfsRestOperation op) {\n+        leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n+        LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+      }\n+\n+      @Override\n+      public void onFailure(Throwable throwable) {\n+        try {\n+          if (RetryPolicy.RetryAction.RetryDecision.RETRY\n+              == retryPolicy.shouldRetry(null, numRetries, 0, true).action) {\n+            LOG.debug(\"Failed acquire lease on {}, retrying: {}\", path, throwable);\n+            acquireLease(retryPolicy, numRetries + 1, LEASE_ACQUIRE_RETRY_INTERVAL);\n+          } else {\n+            exception = throwable;\n+          }\n+        } catch (Exception e) {\n+          exception = throwable;\n+        }\n+      }\n+    });\n+  }\n+\n+  private void renewLease(long delay) {\n+    LOG.debug(\"Attempting to renew lease on {}, renew lease id {}, delay {}\", path, leaseID, delay);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e"}, "originalPosition": 146}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEyNjc2MTEx", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-612676111", "createdAt": "2021-03-15T21:56:17Z", "commit": {"oid": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xNVQyMTo1NjoxN1rOI3KRaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xNVQyMTo1NjoxN1rOI3KRaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDcxMDg5MQ==", "bodyText": "this code should not be required", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r594710891", "createdAt": "2021-03-15T21:56:17Z", "author": {"login": "snehavarma"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -702,15 +735,72 @@ public OutputStream openFileForWrite(final Path path, final FileSystem.Statistic\n         isAppendBlob = true;\n       }\n \n+      SelfRenewingLease lease = maybeCreateLease(relativePath);\n+\n       return new AbfsOutputStream(\n           client,\n           statistics,\n           relativePath,\n           offset,\n-          populateAbfsOutputStreamContext(isAppendBlob));\n+          populateAbfsOutputStreamContext(isAppendBlob, lease));\n     }\n   }\n \n+  /**\n+   * Acquire a lease on an ABFS file for a specified duration. This requires the file to exist.\n+   *\n+   * @param path file name\n+   * @param duration time lease will be held before expiring\n+   * @return the acquired lease ID\n+   * @throws AzureBlobFileSystemException on any exception while acquiring the lease\n+   */\n+  public String acquireLease(final Path path, final int duration) throws AzureBlobFileSystemException {\n+    LOG.debug(\"lease path: {}\", path);\n+\n+    final AbfsRestOperation op =\n+        client.acquireLease(getRelativePath(path), duration);\n+\n+    return op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n+  }\n+\n+  /**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e"}, "originalPosition": 153}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/5a2ef896128b2aecf5ff2c9b83281d1d517628db", "committedDate": "2021-03-16T21:48:10Z", "message": "HADOOP-16948. Support single writer dirs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86246dc3243ff290766d1a760d128e0194f26a13", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/86246dc3243ff290766d1a760d128e0194f26a13", "committedDate": "2021-03-16T21:48:10Z", "message": "HADOOP-16948. Fix findbugs and checkstyle problems."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe3dd135a060400cb761799f8fd1d189deadcd7e", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/fe3dd135a060400cb761799f8fd1d189deadcd7e", "committedDate": "2021-03-16T21:48:10Z", "message": "HADOOP-16948. Fix remaining checkstyle problems."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1cd1a927f0b63b8c5153a4d8c8c30c10d7e4bb79", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/1cd1a927f0b63b8c5153a4d8c8c30c10d7e4bb79", "committedDate": "2021-03-16T21:48:10Z", "message": "HADOOP-16948. Add DurationInfo, retry policy for acquiring lease, and javadocs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eeb4ba0f9bc6986d84ea176d8f02ef73cc2fb0e3", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/eeb4ba0f9bc6986d84ea176d8f02ef73cc2fb0e3", "committedDate": "2021-03-16T21:48:11Z", "message": "HADOOP-16948. Convert ABFS client to use an executor for lease ops"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e91f6165f8bf599a72bc4e826ef2c19474b1b60", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/8e91f6165f8bf599a72bc4e826ef2c19474b1b60", "committedDate": "2021-03-16T21:48:11Z", "message": "HADOOP-16948. Fix ABFS lease test for non-HNS"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8eceabb9052daaac60a4fac203ee85073b7ac118", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/8eceabb9052daaac60a4fac203ee85073b7ac118", "committedDate": "2021-03-16T21:48:11Z", "message": "HADOOP-16948. Fix checkstyle and javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "42f68c2a835ed74fd788e8b87ed19231ce0eded1", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/42f68c2a835ed74fd788e8b87ed19231ce0eded1", "committedDate": "2021-03-16T21:48:11Z", "message": "HADOOP-16948. Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f3d6897f7cd1cc43061e144abe73c8da18de93d", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/9f3d6897f7cd1cc43061e144abe73c8da18de93d", "committedDate": "2021-03-16T21:48:11Z", "message": "HADOOP-16948. Use daemon threads for ABFS lease ops"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d67882f80615f8467716a3ed37c10e38249f2afa", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/d67882f80615f8467716a3ed37c10e38249f2afa", "committedDate": "2021-03-16T21:48:11Z", "message": "HADOOP-16948. Make lease duration configurable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f00c1459e99b6cdd88ffc55af66fdb44267837bc", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f00c1459e99b6cdd88ffc55af66fdb44267837bc", "committedDate": "2021-03-16T21:48:11Z", "message": "HADOOP-16948. Add error messages to test assertions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f00178355c66810ce7664e21a366cd24fc4c1965", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/f00178355c66810ce7664e21a366cd24fc4c1965", "committedDate": "2021-03-16T21:48:11Z", "message": "HADOOP-16948. Remove extra isSingleWriterKey call"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "92e7343b26eb67cf7f2a6ebc885fdd6eb9c9b551", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/92e7343b26eb67cf7f2a6ebc885fdd6eb9c9b551", "committedDate": "2021-03-16T21:48:12Z", "message": "HADOOP-16948. Use only infinite lease duration due to cost of renewal ops"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eca41b4d4ad9aab9ea5caf0df348ddaa824797bc", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/eca41b4d4ad9aab9ea5caf0df348ddaa824797bc", "committedDate": "2021-03-16T21:48:12Z", "message": "HADOOP-16948. Remove acquire/renew/release lease methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "822615efbf93f3c4056ae62284c631f4bc46554c", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/822615efbf93f3c4056ae62284c631f4bc46554c", "committedDate": "2021-03-16T21:48:12Z", "message": "HADOOP-16948. Rename single writer dirs to infinite lease dirs"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "beade4cbd935befb69d109ccdacb27b9c7308c17", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/beade4cbd935befb69d109ccdacb27b9c7308c17", "committedDate": "2021-03-16T20:58:40Z", "message": "HADOOP-16948. Rename single writer dirs to infinite lease dirs"}, "afterCommit": {"oid": "822615efbf93f3c4056ae62284c631f4bc46554c", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/822615efbf93f3c4056ae62284c631f4bc46554c", "committedDate": "2021-03-16T21:48:12Z", "message": "HADOOP-16948. Rename single writer dirs to infinite lease dirs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22", "committedDate": "2021-03-17T04:44:31Z", "message": "HADOOP-16948. Fix checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzOTM1NzQz", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-613935743", "createdAt": "2021-03-17T05:38:27Z", "commit": {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xN1QwNTozODoyN1rOI4INJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xN1QwNTozODoyN1rOI4INJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTcyNTYwNA==", "bodyText": "Do we need these? i.e. Lease threads", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r595725604", "createdAt": "2021-03-17T05:38:27Z", "author": {"login": "snehavarma"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java", "diffHunk": "@@ -208,6 +209,15 @@\n       DefaultValue = DEFAULT_FS_AZURE_APPEND_BLOB_DIRECTORIES)\n   private String azureAppendBlobDirs;\n \n+  @StringConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_INFINITE_LEASE_KEY,\n+      DefaultValue = DEFAULT_FS_AZURE_INFINITE_LEASE_DIRECTORIES)\n+  private String azureInfiniteLeaseDirs;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_LEASE_THREADS,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22"}, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzOTQ1NzI2", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-613945726", "createdAt": "2021-03-17T06:03:35Z", "commit": {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xN1QwNjowMzozNVrOI4IupA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xN1QwNjowMzozNVrOI4IupA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTczNDE4MA==", "bodyText": "Is the feature for both namespace and flatnamespace enabled accounts?", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r595734180", "createdAt": "2021-03-17T06:03:35Z", "author": {"login": "snehavarma"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java", "diffHunk": "@@ -208,6 +209,15 @@\n       DefaultValue = DEFAULT_FS_AZURE_APPEND_BLOB_DIRECTORIES)\n   private String azureAppendBlobDirs;\n \n+  @StringConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_INFINITE_LEASE_KEY,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjE1MDgyNTE5", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-615082519", "createdAt": "2021-03-18T08:17:00Z", "commit": {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjE3MDQ5NjQx", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-617049641", "createdAt": "2021-03-21T18:44:54Z", "commit": {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0yMVQxODo0NDo1NFrOI6mmZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0yMVQxODo0NTozOVrOI6mnAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5ODMyMDc0MA==", "bodyText": "This looks a CPU-heavy loop. I know it makes for a more responsive app, but it's a busy wait. Any way to replace with some concurrency class?", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r598320740", "createdAt": "2021-03-21T18:44:54Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * AbfsLease manages an Azure blob lease. It acquires an infinite lease on instantiation and\n+ * releases the lease when free() is called. Use it to prevent writes to the blob by other\n+ * processes that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, AzureBlobFileSystem breakLease\n+ * will need to be called before another client will be able to write to the file.\n+ */\n+public final class AbfsLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(AbfsLease.class);\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n+    }\n+  }\n+\n+  public AbfsLease(AbfsClient client, String path) throws AzureBlobFileSystemException {\n+    this.leaseFreed = false;\n+    this.client = client;\n+    this.path = path;\n+\n+    if (client.getNumLeaseThreads() < 1) {\n+      throw new LeaseException(ERR_NO_LEASE_THREADS);\n+    }\n+\n+    // Try to get the lease a specified number of times, else throw an error\n+    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n+        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n+    acquireLease(retryPolicy, 0, 0);\n+\n+    while (leaseID == null && exception == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5ODMyMDg5OQ==", "bodyText": "Failed to", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r598320899", "createdAt": "2021-03-21T18:45:39Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * AbfsLease manages an Azure blob lease. It acquires an infinite lease on instantiation and\n+ * releases the lease when free() is called. Use it to prevent writes to the blob by other\n+ * processes that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, AzureBlobFileSystem breakLease\n+ * will need to be called before another client will be able to write to the file.\n+ */\n+public final class AbfsLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(AbfsLease.class);\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n+    }\n+  }\n+\n+  public AbfsLease(AbfsClient client, String path) throws AzureBlobFileSystemException {\n+    this.leaseFreed = false;\n+    this.client = client;\n+    this.path = path;\n+\n+    if (client.getNumLeaseThreads() < 1) {\n+      throw new LeaseException(ERR_NO_LEASE_THREADS);\n+    }\n+\n+    // Try to get the lease a specified number of times, else throw an error\n+    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n+        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n+    acquireLease(retryPolicy, 0, 0);\n+\n+    while (leaseID == null && exception == null) {\n+    }\n+    if (exception != null) {\n+      LOG.error(\"Failed to acquire lease on {}\", path);\n+      throw new LeaseException(exception);\n+    }\n+\n+    LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+  }\n+\n+  private void acquireLease(RetryPolicy retryPolicy, int numRetries, long delay)\n+      throws LeaseException {\n+    LOG.debug(\"Attempting to acquire lease on {}, retry {}\", path, numRetries);\n+    if (future != null && !future.isDone()) {\n+      throw new LeaseException(ERR_LEASE_FUTURE_EXISTS);\n+    }\n+    future = client.schedule(() -> client.acquireLease(path, INFINITE_LEASE_DURATION),\n+        delay, TimeUnit.SECONDS);\n+    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n+      @Override\n+      public void onSuccess(@Nullable AbfsRestOperation op) {\n+        leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n+        LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+      }\n+\n+      @Override\n+      public void onFailure(Throwable throwable) {\n+        try {\n+          if (RetryPolicy.RetryAction.RetryDecision.RETRY\n+              == retryPolicy.shouldRetry(null, numRetries, 0, true).action) {\n+            LOG.debug(\"Failed acquire lease on {}, retrying: {}\", path, throwable);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22"}, "originalPosition": 120}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b6803cfa25040895401bc7b6fdeccc2a96e2da7b", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/b6803cfa25040895401bc7b6fdeccc2a96e2da7b", "committedDate": "2021-03-22T14:26:15Z", "message": "HADOOP-16948. Wait for acquire lease future"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4fdfc08089b7a126a8c455ba663637f247ae4d29", "author": {"user": {"login": "billierinaldi", "name": null}}, "url": "https://github.com/apache/hadoop/commit/4fdfc08089b7a126a8c455ba663637f247ae4d29", "committedDate": "2021-03-23T02:01:24Z", "message": "HADOOP-16948. Add unit test for acquire lease failure"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjE4OTQ4NTg4", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-618948588", "createdAt": "2021-03-23T18:42:59Z", "commit": {"oid": "b6803cfa25040895401bc7b6fdeccc2a96e2da7b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0yM1QxODo0Mjo1OVrOI8DYIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0yM1QxODo0Mjo1OVrOI8DYIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5OTg0MDgwMg==", "bodyText": "if this raises an exception, is there any way the while loop will exit?", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r599840802", "createdAt": "2021-03-23T18:42:59Z", "author": {"login": "steveloughran"}, "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java", "diffHunk": "@@ -88,6 +88,12 @@ public AbfsLease(AbfsClient client, String path) throws AzureBlobFileSystemExcep\n     acquireLease(retryPolicy, 0, 0);\n \n     while (leaseID == null && exception == null) {\n+      try {\n+        future.get();\n+      } catch (Exception e) {\n+        LOG.debug(\"Got exception waiting for acquire lease future. Checking if lease ID or \"\n+            + \"exception have been set\", e);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6803cfa25040895401bc7b6fdeccc2a96e2da7b"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjMzODU3Mzc5", "url": "https://github.com/apache/hadoop/pull/1925#pullrequestreview-633857379", "createdAt": "2021-04-12T18:43:13Z", "commit": {"oid": "4fdfc08089b7a126a8c455ba663637f247ae4d29"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4548, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}