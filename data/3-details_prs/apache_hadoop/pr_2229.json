{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY4MjQyMTMx", "number": 2229, "title": "HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside.", "bodyText": "https://issues.apache.org/jira/browse/HDFS-15533", "createdAt": "2020-08-15T01:36:16Z", "url": "https://github.com/apache/hadoop/pull/2229", "merged": true, "mergeCommit": {"oid": "dd013f2fdf1ecbeb6c877e26951cd0d8922058b0"}, "closed": true, "closedAt": "2020-08-19T16:30:42Z", "author": {"login": "umamaheswararao"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc-_AQQgH2gAyNDY4MjQyMTMxOjMzOTAyYjBlMzZjOWQxZjQxMTk1ZDlmYzMxYWYyMWY1ZGU1ZjIyMmQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdAW1MfgFqTQ3MDIxMDA3Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "33902b0e36c9d1f41195d9fc31af21f5de5f222d", "author": {"user": {"login": "umamaheswararao", "name": "Uma Maheswara Rao G"}}, "url": "https://github.com/apache/hadoop/commit/33902b0e36c9d1f41195d9fc31af21f5de5f222d", "committedDate": "2020-08-15T01:33:41Z", "message": "HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3OTQ1ODMx", "url": "https://github.com/apache/hadoop/pull/2229#pullrequestreview-467945831", "createdAt": "2020-08-15T04:07:18Z", "commit": {"oid": "33902b0e36c9d1f41195d9fc31af21f5de5f222d"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQwNDowNzoxOFrOHBHkTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQwNDo1Mjo1MVrOHBHxkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNDYwNg==", "bodyText": "Do we need to initialize twice? It is already done above at L132", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470934606", "createdAt": "2020-08-15T04:07:18Z", "author": {"login": "ayushtkn"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "33902b0e36c9d1f41195d9fc31af21f5de5f222d"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNDk5OQ==", "bodyText": "Does this make having a fallback mandatory and that too, to HDFS? May be people would want to have a different FS fallback, or not have a fallback, and they might not be using non-path API's as well. Can't we just not throw UnsupportedOperationException if defaultDFS is null?", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470934999", "createdAt": "2020-08-15T04:12:26Z", "author": {"login": "ayushtkn"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);\n+      return;\n+    }\n+    setConf(conf);\n+    // A child DFS with the current initialized URI. This must be same as\n+    // fallback fs. The fallback must point to root of your filesystems.\n+    // Some APIs(without path in argument, for example isInSafeMode) will\n+    // support only for base cluster filesystem. Only that APIs will use this\n+    // fs.\n+    defaultDFS = (DistributedFileSystem) this.vfs.getFallbackFileSystem();\n+    Preconditions\n+        .checkNotNull(\"In ViewHDFS fallback link is mandatory.\", defaultDFS);\n+    // Please don't access internal dfs directly except in tests.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "33902b0e36c9d1f41195d9fc31af21f5de5f222d"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNTgwMQ==", "bodyText": "Why are we removing this? The logic still stays, Namenode Can not get initialized with a Non-DFS filesystems? Will HDFS-15450, not resurface, if something ViewFileSystemOverloadScheme is configured, not this new one?\nIt shouldn't be done with new one available, but still we should have logics to handle if not", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470935801", "createdAt": "2020-08-15T04:23:04Z", "author": {"login": "ayushtkn"}, "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java", "diffHunk": "@@ -727,11 +727,6 @@ protected void initialize(Configuration conf) throws IOException {\n           intervals);\n       }\n     }\n-    // Currently NN uses FileSystem.get to initialize DFS in startTrashEmptier.\n-    // If fs.hdfs.impl was overridden by core-site.xml, we may get other\n-    // filesystem. To make sure we get DFS, we are setting fs.hdfs.impl to DFS.\n-    // HDFS-15450\n-    conf.set(FS_HDFS_IMPL_KEY, DistributedFileSystem.class.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "33902b0e36c9d1f41195d9fc31af21f5de5f222d"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzUwNA==", "bodyText": "Can give result from DefaultDFS?\nIf not, correct the API name", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470937504", "createdAt": "2020-08-15T04:45:52Z", "author": {"login": "ayushtkn"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);\n+      return;\n+    }\n+    setConf(conf);\n+    // A child DFS with the current initialized URI. This must be same as\n+    // fallback fs. The fallback must point to root of your filesystems.\n+    // Some APIs(without path in argument, for example isInSafeMode) will\n+    // support only for base cluster filesystem. Only that APIs will use this\n+    // fs.\n+    defaultDFS = (DistributedFileSystem) this.vfs.getFallbackFileSystem();\n+    Preconditions\n+        .checkNotNull(\"In ViewHDFS fallback link is mandatory.\", defaultDFS);\n+    // Please don't access internal dfs directly except in tests.\n+    dfs = defaultDFS.dfs;\n+  }\n+\n+  @Override\n+  DFSClient initDFSClient(URI uri, Configuration conf) throws IOException {\n+    if(this.vfs==null) {\n+      return super.initDFSClient(uri, conf);\n+    }\n+    return null;\n+  }\n+\n+  public ViewDistributedFileSystem() {\n+  }\n+\n+  private ViewFileSystemOverloadScheme tryInitializeMountingViewFs(URI uri,\n+      Configuration conf) throws IOException {\n+    ViewFileSystemOverloadScheme vfs = new ViewFileSystemOverloadScheme();\n+    vfs.setSupportAutoAddingFallbackOnNoMounts(false);\n+    vfs.initialize(uri, conf);\n+    return vfs;\n+  }\n+\n+  @Override\n+  public URI getUri() {\n+    if (this.vfs == null) {\n+      return super.getUri();\n+    }\n+    return this.vfs.getUri();\n+  }\n+\n+  @Override\n+  public String getScheme() {\n+    if (this.vfs == null) {\n+      return super.getScheme();\n+    }\n+    return this.vfs.getScheme();\n+  }\n+\n+  @Override\n+  public Path getWorkingDirectory() {\n+    if (this.vfs == null) {\n+      return super.getWorkingDirectory();\n+    }\n+    return this.vfs.getWorkingDirectory();\n+  }\n+\n+  @Override\n+  public void setWorkingDirectory(Path dir) {\n+    if (this.vfs == null) {\n+      super.setWorkingDirectory(dir);\n+      return;\n+    }\n+    this.vfs.setWorkingDirectory(dir);\n+  }\n+\n+  @Override\n+  public Path getHomeDirectory() {\n+    if (this.vfs == null) {\n+      return super.getHomeDirectory();\n+    }\n+    return this.vfs.getHomeDirectory();\n+  }\n+\n+  @Override\n+  /**\n+   * Returns only default cluster getHedgedReadMetrics.\n+   */ public DFSHedgedReadMetrics getHedgedReadMetrics() {\n+     if(this.vfs==null){\n+       return super.getHedgedReadMetrics();\n+     }\n+    return defaultDFS.getHedgedReadMetrics();\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(FileStatus fs, long start,\n+      long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(fs, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(fs, start, len);\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(Path p, final long start,\n+      final long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(p, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(p, start, len);\n+  }\n+\n+  @Override\n+  public void setVerifyChecksum(final boolean verifyChecksum) {\n+    if (this.vfs == null) {\n+      super.setVerifyChecksum(verifyChecksum);\n+      return;\n+    }\n+    this.vfs.setVerifyChecksum(verifyChecksum);\n+  }\n+\n+  @Override\n+  public boolean recoverLease(final Path f) throws IOException {\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"recoverLease\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .recoverLease(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(final Path f, final int bufferSize)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.open(f, bufferSize);\n+    }\n+\n+    return this.vfs.open(f, bufferSize);\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(PathHandle fd, int bufferSize)\n+      throws IOException {\n+    return this.vfs.open(fd, bufferSize);\n+  }\n+\n+  @Override\n+  protected HdfsPathHandle createPathHandle(FileStatus st,\n+      Options.HandleOpt... opts) {\n+    if (this.vfs == null) {\n+      return super.createPathHandle(st, opts);\n+    }\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(final Path f, final int bufferSize,\n+      final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, bufferSize, progress);\n+    }\n+    return this.vfs.append(f, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress,\n+      final InetSocketAddress[] favoredNodes) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress,\n+            favoredNodes);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream create(Path f, FsPermission permission,\n+      boolean overwrite, int bufferSize, short replication, long blockSize,\n+      Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress);\n+    }\n+    return this.vfs\n+        .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+            progress);\n+  }\n+\n+  @Override\n+  public HdfsDataOutputStream create(final Path f,\n+      final FsPermission permission, final boolean overwrite,\n+      final int bufferSize, final short replication, final long blockSize,\n+      final Progressable progress, final InetSocketAddress[] favoredNodes)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .create(mountPathInfo.getPathOnTarget(), permission, overwrite,\n+            bufferSize, replication, blockSize, progress, favoredNodes);\n+  }\n+\n+  @Override\n+  //DFS specific API\n+  public FSDataOutputStream create(final Path f, final FsPermission permission,\n+      final EnumSet<CreateFlag> cflags, final int bufferSize,\n+      final short replication, final long blockSize,\n+      final Progressable progress, final Options.ChecksumOpt checksumOpt)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, cflags, bufferSize, replication, blockSize,\n+              progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return mountPathInfo.getTargetFs()\n+        .create(mountPathInfo.getPathOnTarget(), permission, cflags, bufferSize,\n+            replication, blockSize, progress, checksumOpt);\n+  }\n+\n+  void checkDFS(FileSystem fs, String methodName) {\n+    if (!(fs instanceof DistributedFileSystem)) {\n+      throw new UnsupportedOperationException(\n+          \"This API:\" + methodName + \" is specific to DFS. Can't run on other fs:\" + fs\n+              .getUri());\n+    }\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected HdfsDataOutputStream primitiveCreate(Path f,\n+      FsPermission absolutePermission, EnumSet<CreateFlag> flag, int bufferSize,\n+      short replication, long blockSize, Progressable progress,\n+      Options.ChecksumOpt checksumOpt) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+              blockSize, progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveCreate\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+            blockSize, progress, checksumOpt);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream createNonRecursive(Path f, FsPermission permission,\n+      EnumSet<CreateFlag> flags, int bufferSize, short replication,\n+      long blockSize, Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .createNonRecursive(f, permission, flags, bufferSize, replication,\n+              bufferSize, progress);\n+    }\n+    return this.vfs\n+        .createNonRecursive(f, permission, flags, bufferSize, replication,\n+            bufferSize, progress);\n+  }\n+\n+  @Override\n+  public boolean setReplication(final Path f, final short replication)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.setReplication(f, replication);\n+    }\n+    return this.vfs.setReplication(f, replication);\n+  }\n+\n+  @Override\n+  public void setStoragePolicy(Path src, String policyName) throws IOException {\n+    if (this.vfs == null) {\n+      super.setStoragePolicy(src, policyName);\n+      return;\n+    }\n+    this.vfs.setStoragePolicy(src, policyName);\n+  }\n+\n+  @Override\n+  public void unsetStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.unsetStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.unsetStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public BlockStoragePolicySpi getStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicy(src);\n+    }\n+    return this.vfs.getStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public Collection<BlockStoragePolicy> getAllStoragePolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllStoragePolicies();\n+    }\n+    Collection<? extends BlockStoragePolicySpi> allStoragePolicies =\n+        this.vfs.getAllStoragePolicies();\n+    return (Collection<BlockStoragePolicy>) allStoragePolicies;\n+  }\n+\n+  @Override\n+  public long getBytesWithFutureGenerationStamps() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getBytesWithFutureGenerationStamps();\n+    }\n+    return defaultDFS.getBytesWithFutureGenerationStamps();\n+  }\n+\n+  @Deprecated\n+  @Override\n+  public BlockStoragePolicy[] getStoragePolicies() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicies();\n+    }\n+    return defaultDFS.getStoragePolicies();\n+  }\n+\n+  @Override\n+  //Make sure your target fs supports this API, otherwise you will get\n+  // Unsupported operation exception.\n+  public void concat(Path trg, Path[] psrcs) throws IOException {\n+    if (this.vfs == null) {\n+      super.concat(trg, psrcs);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(trg, getConf());\n+    mountPathInfo.getTargetFs().concat(mountPathInfo.getPathOnTarget(), psrcs);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public boolean rename(final Path src, final Path dst) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rename(src, dst);\n+    }\n+    if (getMountPoints().length == 0) {\n+      return this.defaultDFS.rename(src, dst);\n+    }\n+    return this.vfs.rename(src, dst);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void rename(Path src, Path dst, final Options.Rename... options)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.rename(src, dst, options);\n+      return;\n+    }\n+\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountSrcPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountSrcPathInfo.getTargetFs(), \"rename\");\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountDstPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountDstPathInfo.getTargetFs(), \"rename\");\n+\n+    //Check both in same cluster.\n+    if (!mountSrcPathInfo.getTargetFs().getUri()\n+        .equals(mountDstPathInfo.getTargetFs().getUri())) {\n+      throw new HadoopIllegalArgumentException(\n+          \"Can't rename across file systems.\");\n+    }\n+\n+    ((DistributedFileSystem) mountSrcPathInfo.getTargetFs())\n+        .rename(mountSrcPathInfo.getPathOnTarget(),\n+            mountDstPathInfo.getPathOnTarget(), options);\n+  }\n+\n+  @Override\n+  public boolean truncate(final Path f, final long newLength)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.truncate(f, newLength);\n+    }\n+    return this.vfs.truncate(f, newLength);\n+  }\n+\n+  public boolean delete(final Path f, final boolean recursive)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.delete(f, recursive);\n+    }\n+    return this.vfs.delete(f, recursive);\n+  }\n+\n+  @Override\n+  public ContentSummary getContentSummary(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getContentSummary(f);\n+    }\n+    return this.vfs.getContentSummary(f);\n+  }\n+\n+  @Override\n+  public QuotaUsage getQuotaUsage(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getQuotaUsage(f);\n+    }\n+    return this.vfs.getQuotaUsage(f);\n+  }\n+\n+  @Override\n+  public void setQuota(Path src, final long namespaceQuota,\n+      final long storagespaceQuota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuota(src, namespaceQuota, storagespaceQuota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuota(mountPathInfo.getPathOnTarget(), namespaceQuota,\n+            storagespaceQuota);\n+  }\n+\n+  @Override\n+  public void setQuotaByStorageType(Path src, final StorageType type,\n+      final long quota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuotaByStorageType(src, type, quota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuotaByStorageType(mountPathInfo.getPathOnTarget(), type, quota);\n+  }\n+\n+  @Override\n+  public FileStatus[] listStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatus(p);\n+    }\n+    return this.vfs.listStatus(p);\n+  }\n+\n+  @Override\n+  public RemoteIterator<LocatedFileStatus> listLocatedStatus(final Path f,\n+      final PathFilter filter) throws FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.listLocatedStatus(f, filter);\n+    }\n+    return this.vfs.listLocatedStatus(f, filter);\n+  }\n+\n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(final Path p)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatusIterator(p);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(p, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listStatusIterator(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<FileStatus>> batchedListStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListStatusIterator(paths);\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<LocatedFileStatus>> batchedListLocatedStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListLocatedStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListLocatedStatusIterator(paths);\n+  }\n+\n+  public boolean mkdir(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdir(f, permission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"mkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .mkdir(mountPathInfo.getPathOnTarget(), permission);\n+  }\n+\n+  @Override\n+  public boolean mkdirs(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdirs(f, permission);\n+    }\n+    return this.vfs.mkdirs(f, permission);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  protected boolean primitiveMkdir(Path f, FsPermission absolutePermission)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.primitiveMkdir(f, absolutePermission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveMkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveMkdir(mountPathInfo.getPathOnTarget(), absolutePermission);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    if (this.vfs != null) {\n+      this.vfs.close();\n+    }\n+    super.close();\n+  }\n+\n+  @InterfaceAudience.Private\n+  public DFSClient getClient() {\n+    if (this.vfs == null) {\n+      return super.getClient();\n+    }\n+    return defaultDFS.getClient();\n+  }\n+\n+  @Override\n+  public FsStatus getStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStatus(p);\n+    }\n+    return this.vfs.getStatus(p);\n+  }\n+\n+  @Override\n+  public long getMissingBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getPendingDeletionBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getPendingDeletionBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getPendingDeletionBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getMissingReplOneBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingReplOneBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingReplOneBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getLowRedundancyBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getLowRedundancyBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getLowRedundancyBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getCorruptBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getCorruptBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getCorruptBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<Path> listCorruptFileBlocks(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCorruptFileBlocks(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listCorruptFileBlocks(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats();\n+    }\n+    return defaultDFS.getDataNodeStats();\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats(\n+      final HdfsConstants.DatanodeReportType type) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats(type);\n+    }\n+    return defaultDFS.getDataNodeStats(type);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action);\n+    }\n+    return defaultDFS.setSafeMode(action);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action,\n+      boolean isChecked) throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action, isChecked);\n+    }\n+    return defaultDFS.setSafeMode(action, isChecked);\n+  }\n+\n+  @Override\n+  public boolean saveNamespace(long timeWindow, long txGap) throws IOException {\n+    if (this.vfs == null) {\n+      return super.saveNamespace(timeWindow, txGap);\n+    }\n+    return defaultDFS.saveNamespace(timeWindow, txGap);\n+  }\n+\n+  @Override\n+  public void saveNamespace() throws IOException {\n+    if (this.vfs == null) {\n+      super.saveNamespace();\n+      return;\n+    }\n+    defaultDFS.saveNamespace();\n+  }\n+\n+  @Override\n+  public long rollEdits() throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollEdits();\n+    }\n+    return defaultDFS.rollEdits();\n+  }\n+\n+  @Override\n+  public boolean restoreFailedStorage(String arg) throws IOException {\n+    if (this.vfs == null) {\n+      return super.restoreFailedStorage(arg);\n+    }\n+    return defaultDFS.restoreFailedStorage(arg);\n+  }\n+\n+  @Override\n+  public void refreshNodes() throws IOException {\n+    if (this.vfs == null) {\n+      super.refreshNodes();\n+      return;\n+    }\n+    defaultDFS.refreshNodes();\n+  }\n+\n+  @Override\n+  public void finalizeUpgrade() throws IOException {\n+    if (this.vfs == null) {\n+      super.finalizeUpgrade();\n+      return;\n+    }\n+    defaultDFS.finalizeUpgrade();\n+  }\n+\n+  @Override\n+  public boolean upgradeStatus() throws IOException {\n+    if (this.vfs == null) {\n+      return super.upgradeStatus();\n+    }\n+    return defaultDFS.upgradeStatus();\n+  }\n+\n+  @Override\n+  public RollingUpgradeInfo rollingUpgrade(\n+      HdfsConstants.RollingUpgradeAction action) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollingUpgrade(action);\n+    }\n+    return defaultDFS.rollingUpgrade(action);\n+  }\n+\n+  @Override\n+  public void metaSave(String pathname) throws IOException {\n+    if (this.vfs == null) {\n+      super.metaSave(pathname);\n+      return;\n+    }\n+    defaultDFS.metaSave(pathname);\n+  }\n+\n+  @Override\n+  public FsServerDefaults getServerDefaults() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getServerDefaults();\n+    }\n+    //TODO: Need to revisit.\n+    return defaultDFS.getServerDefaults();\n+  }\n+\n+  @Override\n+  public FileStatus getFileStatus(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileStatus(f);\n+    }\n+    return this.vfs.getFileStatus(f);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void createSymlink(final Path target, final Path link,\n+      final boolean createParent) throws IOException {\n+     // Regular DFS behavior\n+    if (this.vfs == null) {\n+      super.createSymlink(target, link, createParent);\n+      return;\n+    }\n+\n+    // Mounting ViewHDFS behavior\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(target, getConf());\n+    mountPathInfo.getTargetFs()\n+        .createSymlink(mountPathInfo.getPathOnTarget(), link, createParent);\n+  }\n+\n+  @Override\n+  public boolean supportsSymlinks() {\n+    if (this.vfs == null) {\n+      return super.supportsSymlinks();\n+    }\n+    // TODO: we can enabled later if we want to support symlinks.\n+    return false;\n+  }\n+\n+  @Override\n+  public FileStatus getFileLinkStatus(final Path f) throws IOException {\n+     if(this.vfs==null){\n+       return super.getFileLinkStatus(f);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getFileLinkStatus(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path getLinkTarget(Path path) throws IOException {\n+    if(this.vfs==null){\n+      return super.getLinkTarget(path);\n+    }\n+    return this.vfs.getLinkTarget(path);\n+  }\n+\n+  @Override\n+  protected Path resolveLink(Path f) throws IOException {\n+    if(this.vfs==null){\n+      return super.resolveLink(f);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"resolveLink\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .resolveLink(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FileChecksum getFileChecksum(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileChecksum(f);\n+    }\n+    return this.vfs.getFileChecksum(f);\n+  }\n+\n+  @Override\n+  public void setPermission(final Path f, final FsPermission permission)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setPermission(f, permission);\n+      return;\n+    }\n+    this.vfs.setPermission(f, permission);\n+  }\n+\n+  @Override\n+  public void setOwner(final Path f, final String username,\n+      final String groupname)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setOwner(f, username, groupname);\n+      return;\n+    }\n+    this.vfs.setOwner(f, username, groupname);\n+  }\n+\n+  @Override\n+  public void setTimes(final Path f, final long mtime, final long atime)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setTimes(f, mtime, atime);\n+      return;\n+    }\n+    this.vfs.setTimes(f, mtime, atime);\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected int getDefaultPort() {\n+    return super.getDefaultPort();\n+  }\n+\n+  @Override\n+  public Token<DelegationTokenIdentifier> getDelegationToken(String renewer)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDelegationToken(renewer);\n+    }\n+    //Let applications call getDelegationTokenIssuers and get respective\n+    // delegation tokens from child fs.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void setBalancerBandwidth(long bandwidth) throws IOException {\n+    if (this.vfs == null) {\n+      super.setBalancerBandwidth(bandwidth);\n+      return;\n+    }\n+    defaultDFS.setBalancerBandwidth(bandwidth);\n+  }\n+\n+  @Override\n+  public String getCanonicalServiceName() {\n+    if (this.vfs == null) {\n+      return super.getCanonicalServiceName();\n+    }\n+    return defaultDFS.getCanonicalServiceName();\n+  }\n+\n+  @Override\n+  protected URI canonicalizeUri(URI uri) {\n+    if (this.vfs == null) {\n+      return super.canonicalizeUri(uri);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo = null;\n+    try {\n+      mountPathInfo = this.vfs.getMountPathInfo(new Path(uri), getConf());\n+    } catch (IOException e) {\n+      //LOG.error(\"Failed to resolve the uri as mount path\", e);\n+      return null;\n+    }\n+    checkDFS(mountPathInfo.getTargetFs(), \"canonicalizeUri\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .canonicalizeUri(uri);\n+  }\n+\n+  @Override\n+  public boolean isInSafeMode() throws IOException {\n+    if (this.vfs == null) {\n+      return super.isInSafeMode();\n+    }\n+    return defaultDFS.isInSafeMode();\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  public void allowSnapshot(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.allowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"allowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .allowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void disallowSnapshot(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.disallowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"disallowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .disallowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path createSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.createSnapshot(path, snapshotName);\n+    }\n+    return this.vfs.createSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public void renameSnapshot(Path path, String snapshotOldName,\n+      String snapshotNewName) throws IOException {\n+    if (this.vfs == null) {\n+      super.renameSnapshot(path, snapshotOldName, snapshotOldName);\n+      return;\n+    }\n+    this.vfs.renameSnapshot(path, snapshotOldName, snapshotNewName);\n+  }\n+\n+  @Override\n+  //Ony for HDFS users\n+  public SnapshottableDirectoryStatus[] getSnapshottableDirListing()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getSnapshottableDirListing();\n+    }\n+    return defaultDFS.getSnapshottableDirListing();\n+  }\n+\n+  @Override\n+  public void deleteSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.deleteSnapshot(path, snapshotName);\n+      return;\n+    }\n+    this.vfs.deleteSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public RemoteIterator<SnapshotDiffReportListing> snapshotDiffReportListingRemoteIterator(\n+      final Path snapshotDir, final String fromSnapshot,\n+      final String toSnapshot) throws IOException {\n+     if(this.vfs ==null){\n+       return super.snapshotDiffReportListingRemoteIterator(snapshotDir, fromSnapshot,\n+           toSnapshot);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(),\n+        \"snapshotDiffReportListingRemoteIterator\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .snapshotDiffReportListingRemoteIterator(\n+            mountPathInfo.getPathOnTarget(), fromSnapshot, toSnapshot);\n+  }\n+\n+  @Override\n+  public SnapshotDiffReport getSnapshotDiffReport(final Path snapshotDir,\n+      final String fromSnapshot, final String toSnapshot) throws IOException {\n+    if(this.vfs ==null){\n+      return super.getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+          toSnapshot);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getSnapshotDiffReport\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+            toSnapshot);\n+  }\n+\n+  @Override\n+  public boolean isFileClosed(final Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.isFileClosed(src);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"isFileClosed\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .isFileClosed(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info, flags);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info, flags);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void removeCacheDirective(long id) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCacheDirective(id);\n+      return;\n+    }\n+    //defaultDFS.removeCacheDirective(id);\n+    //TODO: ? this can create issues in default cluster\n+    // if user intention is to call on specific mount.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public RemoteIterator<CacheDirectiveEntry> listCacheDirectives(\n+      CacheDirectiveInfo filter) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCacheDirectives(filter);\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void addCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.addCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void removeCachePool(String poolName) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCachePool(poolName);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<CachePoolEntry> listCachePools() throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCachePools();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyAclEntries(Path path, List<AclEntry> aclSpec)\n+      throws IOException {\n+    this.vfs.modifyAclEntries(path, aclSpec);\n+  }\n+\n+  @Override\n+  public void removeAclEntries(Path path, List<AclEntry> aclSpec)\n+      throws IOException {\n+    this.vfs.removeAclEntries(path, aclSpec);\n+  }\n+\n+  @Override\n+  public void removeDefaultAcl(Path path) throws IOException {\n+    this.vfs.removeDefaultAcl(path);\n+  }\n+\n+  @Override\n+  public void removeAcl(Path path) throws IOException {\n+    this.vfs.removeAcl(path);\n+  }\n+\n+  @Override\n+  public void setAcl(Path path, List<AclEntry> aclSpec) throws IOException {\n+    if (this.vfs == null) {\n+      super.setAcl(path, aclSpec);\n+      return;\n+    }\n+    this.vfs.setAcl(path, aclSpec);\n+  }\n+\n+  @Override\n+  public AclStatus getAclStatus(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAclStatus(path);\n+    }\n+    return this.vfs.getAclStatus(path);\n+  }\n+\n+  @Override\n+  public void createEncryptionZone(final Path path, final String keyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.createEncryptionZone(path, keyName);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"createEncryptionZone\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .createEncryptionZone(mountPathInfo.getPathOnTarget(), keyName);\n+  }\n+\n+  @Override\n+  public EncryptionZone getEZForPath(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getEZForPath(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getEZForPath\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getEZForPath(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<EncryptionZone> listEncryptionZones()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listEncryptionZones();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listEncryptionZones is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void reencryptEncryptionZone(final Path zone,\n+      final HdfsConstants.ReencryptAction action) throws IOException {\n+    if (this.vfs == null) {\n+      super.reencryptEncryptionZone(zone, action);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(zone, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"reencryptEncryptionZone\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .reencryptEncryptionZone(mountPathInfo.getPathOnTarget(), action);\n+  }\n+\n+  @Override\n+  public RemoteIterator<ZoneReencryptionStatus> listReencryptionStatus()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listReencryptionStatus();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listReencryptionStatus is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public FileEncryptionInfo getFileEncryptionInfo(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileEncryptionInfo(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getFileEncryptionInfo\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getFileEncryptionInfo(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void provisionEZTrash(final Path path,\n+      final FsPermission trashPermission) throws IOException {\n+    if (this.vfs == null) {\n+      super.provisionEZTrash(path, trashPermission);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"provisionEZTrash\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .provisionEZTrash(mountPathInfo.getPathOnTarget(), trashPermission);\n+  }\n+\n+  @Override\n+  public void setXAttr(Path path, String name, byte[] value,\n+      EnumSet<XAttrSetFlag> flag) throws IOException {\n+    if (this.vfs == null) {\n+      super.setXAttr(path, name, value, flag);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setXAttr(mountPathInfo.getPathOnTarget(), name, value, flag);\n+  }\n+\n+  @Override\n+  public byte[] getXAttr(Path path, String name) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttr(path, name);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttr(mountPathInfo.getPathOnTarget(), name);\n+  }\n+\n+  @Override\n+  public Map<String, byte[]> getXAttrs(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttrs(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttrs(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Map<String, byte[]> getXAttrs(Path path, List<String> names)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttrs(path, names);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttrs(mountPathInfo.getPathOnTarget(), names);\n+  }\n+\n+  @Override\n+  public List<String> listXAttrs(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listXAttrs(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listXAttrs(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void removeXAttr(Path path, String name) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeXAttr(path, name);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    mountPathInfo.getTargetFs()\n+        .removeXAttr(mountPathInfo.getPathOnTarget(), name);\n+  }\n+\n+  @Override\n+  public void access(Path path, FsAction mode)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.access(path, mode);\n+      return;\n+    }\n+    this.vfs.access(path, mode);\n+  }\n+\n+  @Override\n+  public URI getKeyProviderUri() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getKeyProviderUri();\n+    }\n+    return defaultDFS.getKeyProviderUri();\n+  }\n+\n+  @Override\n+  public KeyProvider getKeyProvider() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getKeyProvider();\n+    }\n+    return defaultDFS.getKeyProvider();\n+  }\n+\n+  @Override\n+  public DelegationTokenIssuer[] getAdditionalTokenIssuers()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getChildFileSystems();\n+    }\n+\n+    return this.vfs.getChildFileSystems();\n+  }\n+\n+  @Override\n+  public DFSInotifyEventInputStream getInotifyEventStream() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getInotifyEventStream();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getInotifyEventStream is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public DFSInotifyEventInputStream getInotifyEventStream(long lastReadTxid)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getInotifyEventStream();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getInotifyEventStream is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  // DFS only API.\n+  public void setErasureCodingPolicy(final Path path, final String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.setErasureCodingPolicy(path, ecPolicyName);\n+      return;\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"setErasureCodingPolicy\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .setErasureCodingPolicy(mountPathInfo.getPathOnTarget(), ecPolicyName);\n+  }\n+\n+  @Override\n+  public void satisfyStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.satisfyStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.satisfyStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public ErasureCodingPolicy getErasureCodingPolicy(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getErasureCodingPolicy(path);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getErasureCodingPolicy\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getErasureCodingPolicy(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Collection<ErasureCodingPolicyInfo> getAllErasureCodingPolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllErasureCodingPolicies();\n+    }\n+    return defaultDFS.getAllErasureCodingPolicies();\n+  }\n+\n+  @Override\n+  public Map<String, String> getAllErasureCodingCodecs() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllErasureCodingCodecs();\n+    }\n+    return defaultDFS.getAllErasureCodingCodecs();\n+  }\n+\n+  @Override\n+  public AddErasureCodingPolicyResponse[] addErasureCodingPolicies(\n+      ErasureCodingPolicy[] policies) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addErasureCodingPolicies(policies);\n+    }\n+    return defaultDFS.addErasureCodingPolicies(policies);\n+  }\n+\n+  @Override\n+  public void removeErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.removeErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.removeErasureCodingPolicy(ecPolicyName);\n+  }\n+\n+  @Override\n+  public void enableErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.enableErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.enableErasureCodingPolicy(ecPolicyName);\n+  }\n+\n+  @Override\n+  public void disableErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.disableErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.disableErasureCodingPolicy(ecPolicyName);\n+  }\n+\n+  @Override\n+  public void unsetErasureCodingPolicy(final Path path) throws IOException {\n+\n+    if (this.vfs == null) {\n+      super.unsetErasureCodingPolicy(path);\n+      return;\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"unsetErasureCodingPolicy\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .unsetErasureCodingPolicy(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public ECTopologyVerifierResult getECTopologyResultForPolicies(\n+      final String... policyNames) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getECTopologyResultForPolicies(policyNames);\n+    }\n+    throw new UnsupportedOperationException(\n+        \"unsetErasureCodingPolicy is not supported in ViewDFS\");\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "33902b0e36c9d1f41195d9fc31af21f5de5f222d"}, "originalPosition": 1650}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzc1Nw==", "bodyText": "I doubt this. Shouldn't enable/disable/add/remove EC Policy go to all underlying child DFS rather than defaultDFS?", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470937757", "createdAt": "2020-08-15T04:49:41Z", "author": {"login": "ayushtkn"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);\n+      return;\n+    }\n+    setConf(conf);\n+    // A child DFS with the current initialized URI. This must be same as\n+    // fallback fs. The fallback must point to root of your filesystems.\n+    // Some APIs(without path in argument, for example isInSafeMode) will\n+    // support only for base cluster filesystem. Only that APIs will use this\n+    // fs.\n+    defaultDFS = (DistributedFileSystem) this.vfs.getFallbackFileSystem();\n+    Preconditions\n+        .checkNotNull(\"In ViewHDFS fallback link is mandatory.\", defaultDFS);\n+    // Please don't access internal dfs directly except in tests.\n+    dfs = defaultDFS.dfs;\n+  }\n+\n+  @Override\n+  DFSClient initDFSClient(URI uri, Configuration conf) throws IOException {\n+    if(this.vfs==null) {\n+      return super.initDFSClient(uri, conf);\n+    }\n+    return null;\n+  }\n+\n+  public ViewDistributedFileSystem() {\n+  }\n+\n+  private ViewFileSystemOverloadScheme tryInitializeMountingViewFs(URI uri,\n+      Configuration conf) throws IOException {\n+    ViewFileSystemOverloadScheme vfs = new ViewFileSystemOverloadScheme();\n+    vfs.setSupportAutoAddingFallbackOnNoMounts(false);\n+    vfs.initialize(uri, conf);\n+    return vfs;\n+  }\n+\n+  @Override\n+  public URI getUri() {\n+    if (this.vfs == null) {\n+      return super.getUri();\n+    }\n+    return this.vfs.getUri();\n+  }\n+\n+  @Override\n+  public String getScheme() {\n+    if (this.vfs == null) {\n+      return super.getScheme();\n+    }\n+    return this.vfs.getScheme();\n+  }\n+\n+  @Override\n+  public Path getWorkingDirectory() {\n+    if (this.vfs == null) {\n+      return super.getWorkingDirectory();\n+    }\n+    return this.vfs.getWorkingDirectory();\n+  }\n+\n+  @Override\n+  public void setWorkingDirectory(Path dir) {\n+    if (this.vfs == null) {\n+      super.setWorkingDirectory(dir);\n+      return;\n+    }\n+    this.vfs.setWorkingDirectory(dir);\n+  }\n+\n+  @Override\n+  public Path getHomeDirectory() {\n+    if (this.vfs == null) {\n+      return super.getHomeDirectory();\n+    }\n+    return this.vfs.getHomeDirectory();\n+  }\n+\n+  @Override\n+  /**\n+   * Returns only default cluster getHedgedReadMetrics.\n+   */ public DFSHedgedReadMetrics getHedgedReadMetrics() {\n+     if(this.vfs==null){\n+       return super.getHedgedReadMetrics();\n+     }\n+    return defaultDFS.getHedgedReadMetrics();\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(FileStatus fs, long start,\n+      long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(fs, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(fs, start, len);\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(Path p, final long start,\n+      final long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(p, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(p, start, len);\n+  }\n+\n+  @Override\n+  public void setVerifyChecksum(final boolean verifyChecksum) {\n+    if (this.vfs == null) {\n+      super.setVerifyChecksum(verifyChecksum);\n+      return;\n+    }\n+    this.vfs.setVerifyChecksum(verifyChecksum);\n+  }\n+\n+  @Override\n+  public boolean recoverLease(final Path f) throws IOException {\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"recoverLease\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .recoverLease(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(final Path f, final int bufferSize)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.open(f, bufferSize);\n+    }\n+\n+    return this.vfs.open(f, bufferSize);\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(PathHandle fd, int bufferSize)\n+      throws IOException {\n+    return this.vfs.open(fd, bufferSize);\n+  }\n+\n+  @Override\n+  protected HdfsPathHandle createPathHandle(FileStatus st,\n+      Options.HandleOpt... opts) {\n+    if (this.vfs == null) {\n+      return super.createPathHandle(st, opts);\n+    }\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(final Path f, final int bufferSize,\n+      final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, bufferSize, progress);\n+    }\n+    return this.vfs.append(f, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress,\n+      final InetSocketAddress[] favoredNodes) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress,\n+            favoredNodes);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream create(Path f, FsPermission permission,\n+      boolean overwrite, int bufferSize, short replication, long blockSize,\n+      Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress);\n+    }\n+    return this.vfs\n+        .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+            progress);\n+  }\n+\n+  @Override\n+  public HdfsDataOutputStream create(final Path f,\n+      final FsPermission permission, final boolean overwrite,\n+      final int bufferSize, final short replication, final long blockSize,\n+      final Progressable progress, final InetSocketAddress[] favoredNodes)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .create(mountPathInfo.getPathOnTarget(), permission, overwrite,\n+            bufferSize, replication, blockSize, progress, favoredNodes);\n+  }\n+\n+  @Override\n+  //DFS specific API\n+  public FSDataOutputStream create(final Path f, final FsPermission permission,\n+      final EnumSet<CreateFlag> cflags, final int bufferSize,\n+      final short replication, final long blockSize,\n+      final Progressable progress, final Options.ChecksumOpt checksumOpt)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, cflags, bufferSize, replication, blockSize,\n+              progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return mountPathInfo.getTargetFs()\n+        .create(mountPathInfo.getPathOnTarget(), permission, cflags, bufferSize,\n+            replication, blockSize, progress, checksumOpt);\n+  }\n+\n+  void checkDFS(FileSystem fs, String methodName) {\n+    if (!(fs instanceof DistributedFileSystem)) {\n+      throw new UnsupportedOperationException(\n+          \"This API:\" + methodName + \" is specific to DFS. Can't run on other fs:\" + fs\n+              .getUri());\n+    }\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected HdfsDataOutputStream primitiveCreate(Path f,\n+      FsPermission absolutePermission, EnumSet<CreateFlag> flag, int bufferSize,\n+      short replication, long blockSize, Progressable progress,\n+      Options.ChecksumOpt checksumOpt) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+              blockSize, progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveCreate\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+            blockSize, progress, checksumOpt);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream createNonRecursive(Path f, FsPermission permission,\n+      EnumSet<CreateFlag> flags, int bufferSize, short replication,\n+      long blockSize, Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .createNonRecursive(f, permission, flags, bufferSize, replication,\n+              bufferSize, progress);\n+    }\n+    return this.vfs\n+        .createNonRecursive(f, permission, flags, bufferSize, replication,\n+            bufferSize, progress);\n+  }\n+\n+  @Override\n+  public boolean setReplication(final Path f, final short replication)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.setReplication(f, replication);\n+    }\n+    return this.vfs.setReplication(f, replication);\n+  }\n+\n+  @Override\n+  public void setStoragePolicy(Path src, String policyName) throws IOException {\n+    if (this.vfs == null) {\n+      super.setStoragePolicy(src, policyName);\n+      return;\n+    }\n+    this.vfs.setStoragePolicy(src, policyName);\n+  }\n+\n+  @Override\n+  public void unsetStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.unsetStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.unsetStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public BlockStoragePolicySpi getStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicy(src);\n+    }\n+    return this.vfs.getStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public Collection<BlockStoragePolicy> getAllStoragePolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllStoragePolicies();\n+    }\n+    Collection<? extends BlockStoragePolicySpi> allStoragePolicies =\n+        this.vfs.getAllStoragePolicies();\n+    return (Collection<BlockStoragePolicy>) allStoragePolicies;\n+  }\n+\n+  @Override\n+  public long getBytesWithFutureGenerationStamps() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getBytesWithFutureGenerationStamps();\n+    }\n+    return defaultDFS.getBytesWithFutureGenerationStamps();\n+  }\n+\n+  @Deprecated\n+  @Override\n+  public BlockStoragePolicy[] getStoragePolicies() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicies();\n+    }\n+    return defaultDFS.getStoragePolicies();\n+  }\n+\n+  @Override\n+  //Make sure your target fs supports this API, otherwise you will get\n+  // Unsupported operation exception.\n+  public void concat(Path trg, Path[] psrcs) throws IOException {\n+    if (this.vfs == null) {\n+      super.concat(trg, psrcs);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(trg, getConf());\n+    mountPathInfo.getTargetFs().concat(mountPathInfo.getPathOnTarget(), psrcs);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public boolean rename(final Path src, final Path dst) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rename(src, dst);\n+    }\n+    if (getMountPoints().length == 0) {\n+      return this.defaultDFS.rename(src, dst);\n+    }\n+    return this.vfs.rename(src, dst);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void rename(Path src, Path dst, final Options.Rename... options)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.rename(src, dst, options);\n+      return;\n+    }\n+\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountSrcPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountSrcPathInfo.getTargetFs(), \"rename\");\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountDstPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountDstPathInfo.getTargetFs(), \"rename\");\n+\n+    //Check both in same cluster.\n+    if (!mountSrcPathInfo.getTargetFs().getUri()\n+        .equals(mountDstPathInfo.getTargetFs().getUri())) {\n+      throw new HadoopIllegalArgumentException(\n+          \"Can't rename across file systems.\");\n+    }\n+\n+    ((DistributedFileSystem) mountSrcPathInfo.getTargetFs())\n+        .rename(mountSrcPathInfo.getPathOnTarget(),\n+            mountDstPathInfo.getPathOnTarget(), options);\n+  }\n+\n+  @Override\n+  public boolean truncate(final Path f, final long newLength)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.truncate(f, newLength);\n+    }\n+    return this.vfs.truncate(f, newLength);\n+  }\n+\n+  public boolean delete(final Path f, final boolean recursive)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.delete(f, recursive);\n+    }\n+    return this.vfs.delete(f, recursive);\n+  }\n+\n+  @Override\n+  public ContentSummary getContentSummary(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getContentSummary(f);\n+    }\n+    return this.vfs.getContentSummary(f);\n+  }\n+\n+  @Override\n+  public QuotaUsage getQuotaUsage(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getQuotaUsage(f);\n+    }\n+    return this.vfs.getQuotaUsage(f);\n+  }\n+\n+  @Override\n+  public void setQuota(Path src, final long namespaceQuota,\n+      final long storagespaceQuota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuota(src, namespaceQuota, storagespaceQuota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuota(mountPathInfo.getPathOnTarget(), namespaceQuota,\n+            storagespaceQuota);\n+  }\n+\n+  @Override\n+  public void setQuotaByStorageType(Path src, final StorageType type,\n+      final long quota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuotaByStorageType(src, type, quota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuotaByStorageType(mountPathInfo.getPathOnTarget(), type, quota);\n+  }\n+\n+  @Override\n+  public FileStatus[] listStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatus(p);\n+    }\n+    return this.vfs.listStatus(p);\n+  }\n+\n+  @Override\n+  public RemoteIterator<LocatedFileStatus> listLocatedStatus(final Path f,\n+      final PathFilter filter) throws FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.listLocatedStatus(f, filter);\n+    }\n+    return this.vfs.listLocatedStatus(f, filter);\n+  }\n+\n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(final Path p)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatusIterator(p);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(p, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listStatusIterator(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<FileStatus>> batchedListStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListStatusIterator(paths);\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<LocatedFileStatus>> batchedListLocatedStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListLocatedStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListLocatedStatusIterator(paths);\n+  }\n+\n+  public boolean mkdir(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdir(f, permission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"mkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .mkdir(mountPathInfo.getPathOnTarget(), permission);\n+  }\n+\n+  @Override\n+  public boolean mkdirs(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdirs(f, permission);\n+    }\n+    return this.vfs.mkdirs(f, permission);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  protected boolean primitiveMkdir(Path f, FsPermission absolutePermission)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.primitiveMkdir(f, absolutePermission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveMkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveMkdir(mountPathInfo.getPathOnTarget(), absolutePermission);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    if (this.vfs != null) {\n+      this.vfs.close();\n+    }\n+    super.close();\n+  }\n+\n+  @InterfaceAudience.Private\n+  public DFSClient getClient() {\n+    if (this.vfs == null) {\n+      return super.getClient();\n+    }\n+    return defaultDFS.getClient();\n+  }\n+\n+  @Override\n+  public FsStatus getStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStatus(p);\n+    }\n+    return this.vfs.getStatus(p);\n+  }\n+\n+  @Override\n+  public long getMissingBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getPendingDeletionBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getPendingDeletionBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getPendingDeletionBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getMissingReplOneBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingReplOneBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingReplOneBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getLowRedundancyBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getLowRedundancyBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getLowRedundancyBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getCorruptBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getCorruptBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getCorruptBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<Path> listCorruptFileBlocks(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCorruptFileBlocks(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listCorruptFileBlocks(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats();\n+    }\n+    return defaultDFS.getDataNodeStats();\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats(\n+      final HdfsConstants.DatanodeReportType type) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats(type);\n+    }\n+    return defaultDFS.getDataNodeStats(type);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action);\n+    }\n+    return defaultDFS.setSafeMode(action);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action,\n+      boolean isChecked) throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action, isChecked);\n+    }\n+    return defaultDFS.setSafeMode(action, isChecked);\n+  }\n+\n+  @Override\n+  public boolean saveNamespace(long timeWindow, long txGap) throws IOException {\n+    if (this.vfs == null) {\n+      return super.saveNamespace(timeWindow, txGap);\n+    }\n+    return defaultDFS.saveNamespace(timeWindow, txGap);\n+  }\n+\n+  @Override\n+  public void saveNamespace() throws IOException {\n+    if (this.vfs == null) {\n+      super.saveNamespace();\n+      return;\n+    }\n+    defaultDFS.saveNamespace();\n+  }\n+\n+  @Override\n+  public long rollEdits() throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollEdits();\n+    }\n+    return defaultDFS.rollEdits();\n+  }\n+\n+  @Override\n+  public boolean restoreFailedStorage(String arg) throws IOException {\n+    if (this.vfs == null) {\n+      return super.restoreFailedStorage(arg);\n+    }\n+    return defaultDFS.restoreFailedStorage(arg);\n+  }\n+\n+  @Override\n+  public void refreshNodes() throws IOException {\n+    if (this.vfs == null) {\n+      super.refreshNodes();\n+      return;\n+    }\n+    defaultDFS.refreshNodes();\n+  }\n+\n+  @Override\n+  public void finalizeUpgrade() throws IOException {\n+    if (this.vfs == null) {\n+      super.finalizeUpgrade();\n+      return;\n+    }\n+    defaultDFS.finalizeUpgrade();\n+  }\n+\n+  @Override\n+  public boolean upgradeStatus() throws IOException {\n+    if (this.vfs == null) {\n+      return super.upgradeStatus();\n+    }\n+    return defaultDFS.upgradeStatus();\n+  }\n+\n+  @Override\n+  public RollingUpgradeInfo rollingUpgrade(\n+      HdfsConstants.RollingUpgradeAction action) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollingUpgrade(action);\n+    }\n+    return defaultDFS.rollingUpgrade(action);\n+  }\n+\n+  @Override\n+  public void metaSave(String pathname) throws IOException {\n+    if (this.vfs == null) {\n+      super.metaSave(pathname);\n+      return;\n+    }\n+    defaultDFS.metaSave(pathname);\n+  }\n+\n+  @Override\n+  public FsServerDefaults getServerDefaults() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getServerDefaults();\n+    }\n+    //TODO: Need to revisit.\n+    return defaultDFS.getServerDefaults();\n+  }\n+\n+  @Override\n+  public FileStatus getFileStatus(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileStatus(f);\n+    }\n+    return this.vfs.getFileStatus(f);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void createSymlink(final Path target, final Path link,\n+      final boolean createParent) throws IOException {\n+     // Regular DFS behavior\n+    if (this.vfs == null) {\n+      super.createSymlink(target, link, createParent);\n+      return;\n+    }\n+\n+    // Mounting ViewHDFS behavior\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(target, getConf());\n+    mountPathInfo.getTargetFs()\n+        .createSymlink(mountPathInfo.getPathOnTarget(), link, createParent);\n+  }\n+\n+  @Override\n+  public boolean supportsSymlinks() {\n+    if (this.vfs == null) {\n+      return super.supportsSymlinks();\n+    }\n+    // TODO: we can enabled later if we want to support symlinks.\n+    return false;\n+  }\n+\n+  @Override\n+  public FileStatus getFileLinkStatus(final Path f) throws IOException {\n+     if(this.vfs==null){\n+       return super.getFileLinkStatus(f);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getFileLinkStatus(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path getLinkTarget(Path path) throws IOException {\n+    if(this.vfs==null){\n+      return super.getLinkTarget(path);\n+    }\n+    return this.vfs.getLinkTarget(path);\n+  }\n+\n+  @Override\n+  protected Path resolveLink(Path f) throws IOException {\n+    if(this.vfs==null){\n+      return super.resolveLink(f);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"resolveLink\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .resolveLink(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FileChecksum getFileChecksum(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileChecksum(f);\n+    }\n+    return this.vfs.getFileChecksum(f);\n+  }\n+\n+  @Override\n+  public void setPermission(final Path f, final FsPermission permission)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setPermission(f, permission);\n+      return;\n+    }\n+    this.vfs.setPermission(f, permission);\n+  }\n+\n+  @Override\n+  public void setOwner(final Path f, final String username,\n+      final String groupname)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setOwner(f, username, groupname);\n+      return;\n+    }\n+    this.vfs.setOwner(f, username, groupname);\n+  }\n+\n+  @Override\n+  public void setTimes(final Path f, final long mtime, final long atime)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setTimes(f, mtime, atime);\n+      return;\n+    }\n+    this.vfs.setTimes(f, mtime, atime);\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected int getDefaultPort() {\n+    return super.getDefaultPort();\n+  }\n+\n+  @Override\n+  public Token<DelegationTokenIdentifier> getDelegationToken(String renewer)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDelegationToken(renewer);\n+    }\n+    //Let applications call getDelegationTokenIssuers and get respective\n+    // delegation tokens from child fs.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void setBalancerBandwidth(long bandwidth) throws IOException {\n+    if (this.vfs == null) {\n+      super.setBalancerBandwidth(bandwidth);\n+      return;\n+    }\n+    defaultDFS.setBalancerBandwidth(bandwidth);\n+  }\n+\n+  @Override\n+  public String getCanonicalServiceName() {\n+    if (this.vfs == null) {\n+      return super.getCanonicalServiceName();\n+    }\n+    return defaultDFS.getCanonicalServiceName();\n+  }\n+\n+  @Override\n+  protected URI canonicalizeUri(URI uri) {\n+    if (this.vfs == null) {\n+      return super.canonicalizeUri(uri);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo = null;\n+    try {\n+      mountPathInfo = this.vfs.getMountPathInfo(new Path(uri), getConf());\n+    } catch (IOException e) {\n+      //LOG.error(\"Failed to resolve the uri as mount path\", e);\n+      return null;\n+    }\n+    checkDFS(mountPathInfo.getTargetFs(), \"canonicalizeUri\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .canonicalizeUri(uri);\n+  }\n+\n+  @Override\n+  public boolean isInSafeMode() throws IOException {\n+    if (this.vfs == null) {\n+      return super.isInSafeMode();\n+    }\n+    return defaultDFS.isInSafeMode();\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  public void allowSnapshot(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.allowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"allowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .allowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void disallowSnapshot(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.disallowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"disallowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .disallowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path createSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.createSnapshot(path, snapshotName);\n+    }\n+    return this.vfs.createSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public void renameSnapshot(Path path, String snapshotOldName,\n+      String snapshotNewName) throws IOException {\n+    if (this.vfs == null) {\n+      super.renameSnapshot(path, snapshotOldName, snapshotOldName);\n+      return;\n+    }\n+    this.vfs.renameSnapshot(path, snapshotOldName, snapshotNewName);\n+  }\n+\n+  @Override\n+  //Ony for HDFS users\n+  public SnapshottableDirectoryStatus[] getSnapshottableDirListing()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getSnapshottableDirListing();\n+    }\n+    return defaultDFS.getSnapshottableDirListing();\n+  }\n+\n+  @Override\n+  public void deleteSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.deleteSnapshot(path, snapshotName);\n+      return;\n+    }\n+    this.vfs.deleteSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public RemoteIterator<SnapshotDiffReportListing> snapshotDiffReportListingRemoteIterator(\n+      final Path snapshotDir, final String fromSnapshot,\n+      final String toSnapshot) throws IOException {\n+     if(this.vfs ==null){\n+       return super.snapshotDiffReportListingRemoteIterator(snapshotDir, fromSnapshot,\n+           toSnapshot);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(),\n+        \"snapshotDiffReportListingRemoteIterator\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .snapshotDiffReportListingRemoteIterator(\n+            mountPathInfo.getPathOnTarget(), fromSnapshot, toSnapshot);\n+  }\n+\n+  @Override\n+  public SnapshotDiffReport getSnapshotDiffReport(final Path snapshotDir,\n+      final String fromSnapshot, final String toSnapshot) throws IOException {\n+    if(this.vfs ==null){\n+      return super.getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+          toSnapshot);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getSnapshotDiffReport\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+            toSnapshot);\n+  }\n+\n+  @Override\n+  public boolean isFileClosed(final Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.isFileClosed(src);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"isFileClosed\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .isFileClosed(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info, flags);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info, flags);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void removeCacheDirective(long id) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCacheDirective(id);\n+      return;\n+    }\n+    //defaultDFS.removeCacheDirective(id);\n+    //TODO: ? this can create issues in default cluster\n+    // if user intention is to call on specific mount.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public RemoteIterator<CacheDirectiveEntry> listCacheDirectives(\n+      CacheDirectiveInfo filter) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCacheDirectives(filter);\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void addCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.addCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void removeCachePool(String poolName) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCachePool(poolName);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<CachePoolEntry> listCachePools() throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCachePools();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyAclEntries(Path path, List<AclEntry> aclSpec)\n+      throws IOException {\n+    this.vfs.modifyAclEntries(path, aclSpec);\n+  }\n+\n+  @Override\n+  public void removeAclEntries(Path path, List<AclEntry> aclSpec)\n+      throws IOException {\n+    this.vfs.removeAclEntries(path, aclSpec);\n+  }\n+\n+  @Override\n+  public void removeDefaultAcl(Path path) throws IOException {\n+    this.vfs.removeDefaultAcl(path);\n+  }\n+\n+  @Override\n+  public void removeAcl(Path path) throws IOException {\n+    this.vfs.removeAcl(path);\n+  }\n+\n+  @Override\n+  public void setAcl(Path path, List<AclEntry> aclSpec) throws IOException {\n+    if (this.vfs == null) {\n+      super.setAcl(path, aclSpec);\n+      return;\n+    }\n+    this.vfs.setAcl(path, aclSpec);\n+  }\n+\n+  @Override\n+  public AclStatus getAclStatus(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAclStatus(path);\n+    }\n+    return this.vfs.getAclStatus(path);\n+  }\n+\n+  @Override\n+  public void createEncryptionZone(final Path path, final String keyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.createEncryptionZone(path, keyName);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"createEncryptionZone\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .createEncryptionZone(mountPathInfo.getPathOnTarget(), keyName);\n+  }\n+\n+  @Override\n+  public EncryptionZone getEZForPath(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getEZForPath(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getEZForPath\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getEZForPath(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<EncryptionZone> listEncryptionZones()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listEncryptionZones();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listEncryptionZones is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void reencryptEncryptionZone(final Path zone,\n+      final HdfsConstants.ReencryptAction action) throws IOException {\n+    if (this.vfs == null) {\n+      super.reencryptEncryptionZone(zone, action);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(zone, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"reencryptEncryptionZone\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .reencryptEncryptionZone(mountPathInfo.getPathOnTarget(), action);\n+  }\n+\n+  @Override\n+  public RemoteIterator<ZoneReencryptionStatus> listReencryptionStatus()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listReencryptionStatus();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listReencryptionStatus is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public FileEncryptionInfo getFileEncryptionInfo(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileEncryptionInfo(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getFileEncryptionInfo\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getFileEncryptionInfo(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void provisionEZTrash(final Path path,\n+      final FsPermission trashPermission) throws IOException {\n+    if (this.vfs == null) {\n+      super.provisionEZTrash(path, trashPermission);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"provisionEZTrash\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .provisionEZTrash(mountPathInfo.getPathOnTarget(), trashPermission);\n+  }\n+\n+  @Override\n+  public void setXAttr(Path path, String name, byte[] value,\n+      EnumSet<XAttrSetFlag> flag) throws IOException {\n+    if (this.vfs == null) {\n+      super.setXAttr(path, name, value, flag);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setXAttr(mountPathInfo.getPathOnTarget(), name, value, flag);\n+  }\n+\n+  @Override\n+  public byte[] getXAttr(Path path, String name) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttr(path, name);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttr(mountPathInfo.getPathOnTarget(), name);\n+  }\n+\n+  @Override\n+  public Map<String, byte[]> getXAttrs(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttrs(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttrs(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Map<String, byte[]> getXAttrs(Path path, List<String> names)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttrs(path, names);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttrs(mountPathInfo.getPathOnTarget(), names);\n+  }\n+\n+  @Override\n+  public List<String> listXAttrs(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listXAttrs(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listXAttrs(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void removeXAttr(Path path, String name) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeXAttr(path, name);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    mountPathInfo.getTargetFs()\n+        .removeXAttr(mountPathInfo.getPathOnTarget(), name);\n+  }\n+\n+  @Override\n+  public void access(Path path, FsAction mode)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.access(path, mode);\n+      return;\n+    }\n+    this.vfs.access(path, mode);\n+  }\n+\n+  @Override\n+  public URI getKeyProviderUri() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getKeyProviderUri();\n+    }\n+    return defaultDFS.getKeyProviderUri();\n+  }\n+\n+  @Override\n+  public KeyProvider getKeyProvider() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getKeyProvider();\n+    }\n+    return defaultDFS.getKeyProvider();\n+  }\n+\n+  @Override\n+  public DelegationTokenIssuer[] getAdditionalTokenIssuers()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getChildFileSystems();\n+    }\n+\n+    return this.vfs.getChildFileSystems();\n+  }\n+\n+  @Override\n+  public DFSInotifyEventInputStream getInotifyEventStream() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getInotifyEventStream();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getInotifyEventStream is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public DFSInotifyEventInputStream getInotifyEventStream(long lastReadTxid)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getInotifyEventStream();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getInotifyEventStream is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  // DFS only API.\n+  public void setErasureCodingPolicy(final Path path, final String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.setErasureCodingPolicy(path, ecPolicyName);\n+      return;\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"setErasureCodingPolicy\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .setErasureCodingPolicy(mountPathInfo.getPathOnTarget(), ecPolicyName);\n+  }\n+\n+  @Override\n+  public void satisfyStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.satisfyStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.satisfyStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public ErasureCodingPolicy getErasureCodingPolicy(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getErasureCodingPolicy(path);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getErasureCodingPolicy\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getErasureCodingPolicy(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Collection<ErasureCodingPolicyInfo> getAllErasureCodingPolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllErasureCodingPolicies();\n+    }\n+    return defaultDFS.getAllErasureCodingPolicies();\n+  }\n+\n+  @Override\n+  public Map<String, String> getAllErasureCodingCodecs() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllErasureCodingCodecs();\n+    }\n+    return defaultDFS.getAllErasureCodingCodecs();\n+  }\n+\n+  @Override\n+  public AddErasureCodingPolicyResponse[] addErasureCodingPolicies(\n+      ErasureCodingPolicy[] policies) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addErasureCodingPolicies(policies);\n+    }\n+    return defaultDFS.addErasureCodingPolicies(policies);\n+  }\n+\n+  @Override\n+  public void removeErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.removeErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.removeErasureCodingPolicy(ecPolicyName);\n+  }\n+\n+  @Override\n+  public void enableErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.enableErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.enableErasureCodingPolicy(ecPolicyName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "33902b0e36c9d1f41195d9fc31af21f5de5f222d"}, "originalPosition": 1614}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzODAwMw==", "bodyText": "API name in exception.\nWhy can't we support cache commands, similar to other ones?", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470938003", "createdAt": "2020-08-15T04:52:51Z", "author": {"login": "ayushtkn"}, "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);\n+      return;\n+    }\n+    setConf(conf);\n+    // A child DFS with the current initialized URI. This must be same as\n+    // fallback fs. The fallback must point to root of your filesystems.\n+    // Some APIs(without path in argument, for example isInSafeMode) will\n+    // support only for base cluster filesystem. Only that APIs will use this\n+    // fs.\n+    defaultDFS = (DistributedFileSystem) this.vfs.getFallbackFileSystem();\n+    Preconditions\n+        .checkNotNull(\"In ViewHDFS fallback link is mandatory.\", defaultDFS);\n+    // Please don't access internal dfs directly except in tests.\n+    dfs = defaultDFS.dfs;\n+  }\n+\n+  @Override\n+  DFSClient initDFSClient(URI uri, Configuration conf) throws IOException {\n+    if(this.vfs==null) {\n+      return super.initDFSClient(uri, conf);\n+    }\n+    return null;\n+  }\n+\n+  public ViewDistributedFileSystem() {\n+  }\n+\n+  private ViewFileSystemOverloadScheme tryInitializeMountingViewFs(URI uri,\n+      Configuration conf) throws IOException {\n+    ViewFileSystemOverloadScheme vfs = new ViewFileSystemOverloadScheme();\n+    vfs.setSupportAutoAddingFallbackOnNoMounts(false);\n+    vfs.initialize(uri, conf);\n+    return vfs;\n+  }\n+\n+  @Override\n+  public URI getUri() {\n+    if (this.vfs == null) {\n+      return super.getUri();\n+    }\n+    return this.vfs.getUri();\n+  }\n+\n+  @Override\n+  public String getScheme() {\n+    if (this.vfs == null) {\n+      return super.getScheme();\n+    }\n+    return this.vfs.getScheme();\n+  }\n+\n+  @Override\n+  public Path getWorkingDirectory() {\n+    if (this.vfs == null) {\n+      return super.getWorkingDirectory();\n+    }\n+    return this.vfs.getWorkingDirectory();\n+  }\n+\n+  @Override\n+  public void setWorkingDirectory(Path dir) {\n+    if (this.vfs == null) {\n+      super.setWorkingDirectory(dir);\n+      return;\n+    }\n+    this.vfs.setWorkingDirectory(dir);\n+  }\n+\n+  @Override\n+  public Path getHomeDirectory() {\n+    if (this.vfs == null) {\n+      return super.getHomeDirectory();\n+    }\n+    return this.vfs.getHomeDirectory();\n+  }\n+\n+  @Override\n+  /**\n+   * Returns only default cluster getHedgedReadMetrics.\n+   */ public DFSHedgedReadMetrics getHedgedReadMetrics() {\n+     if(this.vfs==null){\n+       return super.getHedgedReadMetrics();\n+     }\n+    return defaultDFS.getHedgedReadMetrics();\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(FileStatus fs, long start,\n+      long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(fs, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(fs, start, len);\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(Path p, final long start,\n+      final long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(p, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(p, start, len);\n+  }\n+\n+  @Override\n+  public void setVerifyChecksum(final boolean verifyChecksum) {\n+    if (this.vfs == null) {\n+      super.setVerifyChecksum(verifyChecksum);\n+      return;\n+    }\n+    this.vfs.setVerifyChecksum(verifyChecksum);\n+  }\n+\n+  @Override\n+  public boolean recoverLease(final Path f) throws IOException {\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"recoverLease\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .recoverLease(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(final Path f, final int bufferSize)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.open(f, bufferSize);\n+    }\n+\n+    return this.vfs.open(f, bufferSize);\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(PathHandle fd, int bufferSize)\n+      throws IOException {\n+    return this.vfs.open(fd, bufferSize);\n+  }\n+\n+  @Override\n+  protected HdfsPathHandle createPathHandle(FileStatus st,\n+      Options.HandleOpt... opts) {\n+    if (this.vfs == null) {\n+      return super.createPathHandle(st, opts);\n+    }\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(final Path f, final int bufferSize,\n+      final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, bufferSize, progress);\n+    }\n+    return this.vfs.append(f, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress,\n+      final InetSocketAddress[] favoredNodes) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress,\n+            favoredNodes);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream create(Path f, FsPermission permission,\n+      boolean overwrite, int bufferSize, short replication, long blockSize,\n+      Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress);\n+    }\n+    return this.vfs\n+        .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+            progress);\n+  }\n+\n+  @Override\n+  public HdfsDataOutputStream create(final Path f,\n+      final FsPermission permission, final boolean overwrite,\n+      final int bufferSize, final short replication, final long blockSize,\n+      final Progressable progress, final InetSocketAddress[] favoredNodes)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .create(mountPathInfo.getPathOnTarget(), permission, overwrite,\n+            bufferSize, replication, blockSize, progress, favoredNodes);\n+  }\n+\n+  @Override\n+  //DFS specific API\n+  public FSDataOutputStream create(final Path f, final FsPermission permission,\n+      final EnumSet<CreateFlag> cflags, final int bufferSize,\n+      final short replication, final long blockSize,\n+      final Progressable progress, final Options.ChecksumOpt checksumOpt)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, cflags, bufferSize, replication, blockSize,\n+              progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return mountPathInfo.getTargetFs()\n+        .create(mountPathInfo.getPathOnTarget(), permission, cflags, bufferSize,\n+            replication, blockSize, progress, checksumOpt);\n+  }\n+\n+  void checkDFS(FileSystem fs, String methodName) {\n+    if (!(fs instanceof DistributedFileSystem)) {\n+      throw new UnsupportedOperationException(\n+          \"This API:\" + methodName + \" is specific to DFS. Can't run on other fs:\" + fs\n+              .getUri());\n+    }\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected HdfsDataOutputStream primitiveCreate(Path f,\n+      FsPermission absolutePermission, EnumSet<CreateFlag> flag, int bufferSize,\n+      short replication, long blockSize, Progressable progress,\n+      Options.ChecksumOpt checksumOpt) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+              blockSize, progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveCreate\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+            blockSize, progress, checksumOpt);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream createNonRecursive(Path f, FsPermission permission,\n+      EnumSet<CreateFlag> flags, int bufferSize, short replication,\n+      long blockSize, Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .createNonRecursive(f, permission, flags, bufferSize, replication,\n+              bufferSize, progress);\n+    }\n+    return this.vfs\n+        .createNonRecursive(f, permission, flags, bufferSize, replication,\n+            bufferSize, progress);\n+  }\n+\n+  @Override\n+  public boolean setReplication(final Path f, final short replication)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.setReplication(f, replication);\n+    }\n+    return this.vfs.setReplication(f, replication);\n+  }\n+\n+  @Override\n+  public void setStoragePolicy(Path src, String policyName) throws IOException {\n+    if (this.vfs == null) {\n+      super.setStoragePolicy(src, policyName);\n+      return;\n+    }\n+    this.vfs.setStoragePolicy(src, policyName);\n+  }\n+\n+  @Override\n+  public void unsetStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.unsetStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.unsetStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public BlockStoragePolicySpi getStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicy(src);\n+    }\n+    return this.vfs.getStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public Collection<BlockStoragePolicy> getAllStoragePolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllStoragePolicies();\n+    }\n+    Collection<? extends BlockStoragePolicySpi> allStoragePolicies =\n+        this.vfs.getAllStoragePolicies();\n+    return (Collection<BlockStoragePolicy>) allStoragePolicies;\n+  }\n+\n+  @Override\n+  public long getBytesWithFutureGenerationStamps() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getBytesWithFutureGenerationStamps();\n+    }\n+    return defaultDFS.getBytesWithFutureGenerationStamps();\n+  }\n+\n+  @Deprecated\n+  @Override\n+  public BlockStoragePolicy[] getStoragePolicies() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicies();\n+    }\n+    return defaultDFS.getStoragePolicies();\n+  }\n+\n+  @Override\n+  //Make sure your target fs supports this API, otherwise you will get\n+  // Unsupported operation exception.\n+  public void concat(Path trg, Path[] psrcs) throws IOException {\n+    if (this.vfs == null) {\n+      super.concat(trg, psrcs);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(trg, getConf());\n+    mountPathInfo.getTargetFs().concat(mountPathInfo.getPathOnTarget(), psrcs);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public boolean rename(final Path src, final Path dst) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rename(src, dst);\n+    }\n+    if (getMountPoints().length == 0) {\n+      return this.defaultDFS.rename(src, dst);\n+    }\n+    return this.vfs.rename(src, dst);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void rename(Path src, Path dst, final Options.Rename... options)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.rename(src, dst, options);\n+      return;\n+    }\n+\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountSrcPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountSrcPathInfo.getTargetFs(), \"rename\");\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountDstPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountDstPathInfo.getTargetFs(), \"rename\");\n+\n+    //Check both in same cluster.\n+    if (!mountSrcPathInfo.getTargetFs().getUri()\n+        .equals(mountDstPathInfo.getTargetFs().getUri())) {\n+      throw new HadoopIllegalArgumentException(\n+          \"Can't rename across file systems.\");\n+    }\n+\n+    ((DistributedFileSystem) mountSrcPathInfo.getTargetFs())\n+        .rename(mountSrcPathInfo.getPathOnTarget(),\n+            mountDstPathInfo.getPathOnTarget(), options);\n+  }\n+\n+  @Override\n+  public boolean truncate(final Path f, final long newLength)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.truncate(f, newLength);\n+    }\n+    return this.vfs.truncate(f, newLength);\n+  }\n+\n+  public boolean delete(final Path f, final boolean recursive)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.delete(f, recursive);\n+    }\n+    return this.vfs.delete(f, recursive);\n+  }\n+\n+  @Override\n+  public ContentSummary getContentSummary(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getContentSummary(f);\n+    }\n+    return this.vfs.getContentSummary(f);\n+  }\n+\n+  @Override\n+  public QuotaUsage getQuotaUsage(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getQuotaUsage(f);\n+    }\n+    return this.vfs.getQuotaUsage(f);\n+  }\n+\n+  @Override\n+  public void setQuota(Path src, final long namespaceQuota,\n+      final long storagespaceQuota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuota(src, namespaceQuota, storagespaceQuota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuota(mountPathInfo.getPathOnTarget(), namespaceQuota,\n+            storagespaceQuota);\n+  }\n+\n+  @Override\n+  public void setQuotaByStorageType(Path src, final StorageType type,\n+      final long quota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuotaByStorageType(src, type, quota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuotaByStorageType(mountPathInfo.getPathOnTarget(), type, quota);\n+  }\n+\n+  @Override\n+  public FileStatus[] listStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatus(p);\n+    }\n+    return this.vfs.listStatus(p);\n+  }\n+\n+  @Override\n+  public RemoteIterator<LocatedFileStatus> listLocatedStatus(final Path f,\n+      final PathFilter filter) throws FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.listLocatedStatus(f, filter);\n+    }\n+    return this.vfs.listLocatedStatus(f, filter);\n+  }\n+\n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(final Path p)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatusIterator(p);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(p, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listStatusIterator(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<FileStatus>> batchedListStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListStatusIterator(paths);\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<LocatedFileStatus>> batchedListLocatedStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListLocatedStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListLocatedStatusIterator(paths);\n+  }\n+\n+  public boolean mkdir(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdir(f, permission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"mkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .mkdir(mountPathInfo.getPathOnTarget(), permission);\n+  }\n+\n+  @Override\n+  public boolean mkdirs(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdirs(f, permission);\n+    }\n+    return this.vfs.mkdirs(f, permission);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  protected boolean primitiveMkdir(Path f, FsPermission absolutePermission)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.primitiveMkdir(f, absolutePermission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveMkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveMkdir(mountPathInfo.getPathOnTarget(), absolutePermission);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    if (this.vfs != null) {\n+      this.vfs.close();\n+    }\n+    super.close();\n+  }\n+\n+  @InterfaceAudience.Private\n+  public DFSClient getClient() {\n+    if (this.vfs == null) {\n+      return super.getClient();\n+    }\n+    return defaultDFS.getClient();\n+  }\n+\n+  @Override\n+  public FsStatus getStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStatus(p);\n+    }\n+    return this.vfs.getStatus(p);\n+  }\n+\n+  @Override\n+  public long getMissingBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getPendingDeletionBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getPendingDeletionBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getPendingDeletionBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getMissingReplOneBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingReplOneBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingReplOneBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getLowRedundancyBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getLowRedundancyBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getLowRedundancyBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getCorruptBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getCorruptBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getCorruptBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<Path> listCorruptFileBlocks(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCorruptFileBlocks(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listCorruptFileBlocks(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats();\n+    }\n+    return defaultDFS.getDataNodeStats();\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats(\n+      final HdfsConstants.DatanodeReportType type) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats(type);\n+    }\n+    return defaultDFS.getDataNodeStats(type);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action);\n+    }\n+    return defaultDFS.setSafeMode(action);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action,\n+      boolean isChecked) throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action, isChecked);\n+    }\n+    return defaultDFS.setSafeMode(action, isChecked);\n+  }\n+\n+  @Override\n+  public boolean saveNamespace(long timeWindow, long txGap) throws IOException {\n+    if (this.vfs == null) {\n+      return super.saveNamespace(timeWindow, txGap);\n+    }\n+    return defaultDFS.saveNamespace(timeWindow, txGap);\n+  }\n+\n+  @Override\n+  public void saveNamespace() throws IOException {\n+    if (this.vfs == null) {\n+      super.saveNamespace();\n+      return;\n+    }\n+    defaultDFS.saveNamespace();\n+  }\n+\n+  @Override\n+  public long rollEdits() throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollEdits();\n+    }\n+    return defaultDFS.rollEdits();\n+  }\n+\n+  @Override\n+  public boolean restoreFailedStorage(String arg) throws IOException {\n+    if (this.vfs == null) {\n+      return super.restoreFailedStorage(arg);\n+    }\n+    return defaultDFS.restoreFailedStorage(arg);\n+  }\n+\n+  @Override\n+  public void refreshNodes() throws IOException {\n+    if (this.vfs == null) {\n+      super.refreshNodes();\n+      return;\n+    }\n+    defaultDFS.refreshNodes();\n+  }\n+\n+  @Override\n+  public void finalizeUpgrade() throws IOException {\n+    if (this.vfs == null) {\n+      super.finalizeUpgrade();\n+      return;\n+    }\n+    defaultDFS.finalizeUpgrade();\n+  }\n+\n+  @Override\n+  public boolean upgradeStatus() throws IOException {\n+    if (this.vfs == null) {\n+      return super.upgradeStatus();\n+    }\n+    return defaultDFS.upgradeStatus();\n+  }\n+\n+  @Override\n+  public RollingUpgradeInfo rollingUpgrade(\n+      HdfsConstants.RollingUpgradeAction action) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollingUpgrade(action);\n+    }\n+    return defaultDFS.rollingUpgrade(action);\n+  }\n+\n+  @Override\n+  public void metaSave(String pathname) throws IOException {\n+    if (this.vfs == null) {\n+      super.metaSave(pathname);\n+      return;\n+    }\n+    defaultDFS.metaSave(pathname);\n+  }\n+\n+  @Override\n+  public FsServerDefaults getServerDefaults() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getServerDefaults();\n+    }\n+    //TODO: Need to revisit.\n+    return defaultDFS.getServerDefaults();\n+  }\n+\n+  @Override\n+  public FileStatus getFileStatus(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileStatus(f);\n+    }\n+    return this.vfs.getFileStatus(f);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void createSymlink(final Path target, final Path link,\n+      final boolean createParent) throws IOException {\n+     // Regular DFS behavior\n+    if (this.vfs == null) {\n+      super.createSymlink(target, link, createParent);\n+      return;\n+    }\n+\n+    // Mounting ViewHDFS behavior\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(target, getConf());\n+    mountPathInfo.getTargetFs()\n+        .createSymlink(mountPathInfo.getPathOnTarget(), link, createParent);\n+  }\n+\n+  @Override\n+  public boolean supportsSymlinks() {\n+    if (this.vfs == null) {\n+      return super.supportsSymlinks();\n+    }\n+    // TODO: we can enabled later if we want to support symlinks.\n+    return false;\n+  }\n+\n+  @Override\n+  public FileStatus getFileLinkStatus(final Path f) throws IOException {\n+     if(this.vfs==null){\n+       return super.getFileLinkStatus(f);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getFileLinkStatus(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path getLinkTarget(Path path) throws IOException {\n+    if(this.vfs==null){\n+      return super.getLinkTarget(path);\n+    }\n+    return this.vfs.getLinkTarget(path);\n+  }\n+\n+  @Override\n+  protected Path resolveLink(Path f) throws IOException {\n+    if(this.vfs==null){\n+      return super.resolveLink(f);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"resolveLink\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .resolveLink(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FileChecksum getFileChecksum(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileChecksum(f);\n+    }\n+    return this.vfs.getFileChecksum(f);\n+  }\n+\n+  @Override\n+  public void setPermission(final Path f, final FsPermission permission)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setPermission(f, permission);\n+      return;\n+    }\n+    this.vfs.setPermission(f, permission);\n+  }\n+\n+  @Override\n+  public void setOwner(final Path f, final String username,\n+      final String groupname)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setOwner(f, username, groupname);\n+      return;\n+    }\n+    this.vfs.setOwner(f, username, groupname);\n+  }\n+\n+  @Override\n+  public void setTimes(final Path f, final long mtime, final long atime)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setTimes(f, mtime, atime);\n+      return;\n+    }\n+    this.vfs.setTimes(f, mtime, atime);\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected int getDefaultPort() {\n+    return super.getDefaultPort();\n+  }\n+\n+  @Override\n+  public Token<DelegationTokenIdentifier> getDelegationToken(String renewer)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDelegationToken(renewer);\n+    }\n+    //Let applications call getDelegationTokenIssuers and get respective\n+    // delegation tokens from child fs.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void setBalancerBandwidth(long bandwidth) throws IOException {\n+    if (this.vfs == null) {\n+      super.setBalancerBandwidth(bandwidth);\n+      return;\n+    }\n+    defaultDFS.setBalancerBandwidth(bandwidth);\n+  }\n+\n+  @Override\n+  public String getCanonicalServiceName() {\n+    if (this.vfs == null) {\n+      return super.getCanonicalServiceName();\n+    }\n+    return defaultDFS.getCanonicalServiceName();\n+  }\n+\n+  @Override\n+  protected URI canonicalizeUri(URI uri) {\n+    if (this.vfs == null) {\n+      return super.canonicalizeUri(uri);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo = null;\n+    try {\n+      mountPathInfo = this.vfs.getMountPathInfo(new Path(uri), getConf());\n+    } catch (IOException e) {\n+      //LOG.error(\"Failed to resolve the uri as mount path\", e);\n+      return null;\n+    }\n+    checkDFS(mountPathInfo.getTargetFs(), \"canonicalizeUri\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .canonicalizeUri(uri);\n+  }\n+\n+  @Override\n+  public boolean isInSafeMode() throws IOException {\n+    if (this.vfs == null) {\n+      return super.isInSafeMode();\n+    }\n+    return defaultDFS.isInSafeMode();\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  public void allowSnapshot(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.allowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"allowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .allowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void disallowSnapshot(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.disallowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"disallowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .disallowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path createSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.createSnapshot(path, snapshotName);\n+    }\n+    return this.vfs.createSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public void renameSnapshot(Path path, String snapshotOldName,\n+      String snapshotNewName) throws IOException {\n+    if (this.vfs == null) {\n+      super.renameSnapshot(path, snapshotOldName, snapshotOldName);\n+      return;\n+    }\n+    this.vfs.renameSnapshot(path, snapshotOldName, snapshotNewName);\n+  }\n+\n+  @Override\n+  //Ony for HDFS users\n+  public SnapshottableDirectoryStatus[] getSnapshottableDirListing()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getSnapshottableDirListing();\n+    }\n+    return defaultDFS.getSnapshottableDirListing();\n+  }\n+\n+  @Override\n+  public void deleteSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.deleteSnapshot(path, snapshotName);\n+      return;\n+    }\n+    this.vfs.deleteSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public RemoteIterator<SnapshotDiffReportListing> snapshotDiffReportListingRemoteIterator(\n+      final Path snapshotDir, final String fromSnapshot,\n+      final String toSnapshot) throws IOException {\n+     if(this.vfs ==null){\n+       return super.snapshotDiffReportListingRemoteIterator(snapshotDir, fromSnapshot,\n+           toSnapshot);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(),\n+        \"snapshotDiffReportListingRemoteIterator\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .snapshotDiffReportListingRemoteIterator(\n+            mountPathInfo.getPathOnTarget(), fromSnapshot, toSnapshot);\n+  }\n+\n+  @Override\n+  public SnapshotDiffReport getSnapshotDiffReport(final Path snapshotDir,\n+      final String fromSnapshot, final String toSnapshot) throws IOException {\n+    if(this.vfs ==null){\n+      return super.getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+          toSnapshot);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getSnapshotDiffReport\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+            toSnapshot);\n+  }\n+\n+  @Override\n+  public boolean isFileClosed(final Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.isFileClosed(src);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"isFileClosed\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .isFileClosed(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info, flags);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info, flags);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void removeCacheDirective(long id) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCacheDirective(id);\n+      return;\n+    }\n+    //defaultDFS.removeCacheDirective(id);\n+    //TODO: ? this can create issues in default cluster\n+    // if user intention is to call on specific mount.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public RemoteIterator<CacheDirectiveEntry> listCacheDirectives(\n+      CacheDirectiveInfo filter) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCacheDirectives(filter);\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void addCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.addCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "33902b0e36c9d1f41195d9fc31af21f5de5f222d"}, "originalPosition": 1259}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "707e34ad43fb069d8fc5fc94a9d35804eb5eac43", "author": {"user": {"login": "umamaheswararao", "name": "Uma Maheswara Rao G"}}, "url": "https://github.com/apache/hadoop/commit/707e34ad43fb069d8fc5fc94a9d35804eb5eac43", "committedDate": "2020-08-15T09:21:24Z", "message": "HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dea727ce138877139190204a4e1b50c8106dbeb2", "author": {"user": {"login": "umamaheswararao", "name": "Uma Maheswara Rao G"}}, "url": "https://github.com/apache/hadoop/commit/dea727ce138877139190204a4e1b50c8106dbeb2", "committedDate": "2020-08-16T00:00:48Z", "message": "HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c79ce86b454329aa06ed8b9aa0346194e149a0f3", "author": {"user": {"login": "umamaheswararao", "name": "Uma Maheswara Rao G"}}, "url": "https://github.com/apache/hadoop/commit/c79ce86b454329aa06ed8b9aa0346194e149a0f3", "committedDate": "2020-08-16T23:52:59Z", "message": "HDFS-15533: All EC APIs will be delegated all child APIs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "933b64846f25365dbea47dc438ec86f7abbd883c", "author": {"user": {"login": "umamaheswararao", "name": "Uma Maheswara Rao G"}}, "url": "https://github.com/apache/hadoop/commit/933b64846f25365dbea47dc438ec86f7abbd883c", "committedDate": "2020-08-18T22:43:26Z", "message": "HDFS-15533: All CachePool APIs changed to delegate to all childfs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwMjEwMDcz", "url": "https://github.com/apache/hadoop/pull/2229#pullrequestreview-470210073", "createdAt": "2020-08-19T07:53:15Z", "commit": {"oid": "933b64846f25365dbea47dc438ec86f7abbd883c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3919, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}