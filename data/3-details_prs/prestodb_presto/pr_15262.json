{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk3MDk2MTcw", "number": 15262, "title": "Disable broadcast join optimization for Presto on Spark", "bodyText": "Nullifying iterator does not work if the executor containers are reused, as the broadcast variables persistent between tasks. Nullifying a broadcast variable will make it invalid for the next task run on the same executor.\nAs a workaround for increased broadcast memory on executors compression has been added and additional check for broadcast size is added.\n== NO RELEASE NOTE ==", "createdAt": "2020-10-02T19:30:56Z", "url": "https://github.com/prestodb/presto/pull/15262", "merged": true, "mergeCommit": {"oid": "79a8c8f5d30878e60e1baca06d5e1f4e7c457ec5"}, "closed": true, "closedAt": "2020-10-05T17:13:33Z", "author": {"login": "arhimondr"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdOnMuHAH2gAyNDk3MDk2MTcwOmZiZDRiYmIzN2RkMGQ2NjQ5ZGZlYzQ2NjhkNGEwODlkMjIyYmFiZTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdOtpYRAFqTUwMTQ3NzQxOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "fbd4bbb37dd0d6649dfec4668d4a089d222babe9", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/fbd4bbb37dd0d6649dfec4668d4a089d222babe9", "committedDate": "2020-10-02T14:52:22Z", "message": "Revert \"Enable nullifying iterator for broadcast join\"\n\nThis reverts commit 8ae554dc9c1434c3e22b1c6c94fc45ed478012fa."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a8a6cdf71754f9cd73c4fcfb835b0bbc79a09193", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/a8a6cdf71754f9cd73c4fcfb835b0bbc79a09193", "committedDate": "2020-10-02T14:52:22Z", "message": "Make sure PagesSerde is not used in a non thread safe manner"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8fadf5aa929a0fe70b966831dc9f13036cf2d9c", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/b8fadf5aa929a0fe70b966831dc9f13036cf2d9c", "committedDate": "2020-10-02T15:14:57Z", "message": "Compress broadcast pages in Presto on Spark to save memory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/451242d5ac49bed60f10e48e5b251e8989fc7c6b", "committedDate": "2020-10-02T15:14:57Z", "message": "Enforce broadcast memory limits in Presto on Spark"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNDIwMTYx", "url": "https://github.com/prestodb/presto/pull/15262#pullrequestreview-501420161", "createdAt": "2020-10-02T20:14:12Z", "commit": {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNDIwNjQ5", "url": "https://github.com/prestodb/presto/pull/15262#pullrequestreview-501420649", "createdAt": "2020-10-02T20:15:06Z", "commit": {"oid": "b8fadf5aa929a0fe70b966831dc9f13036cf2d9c"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMDoxNTowNlrOHb6ZsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoyMjoyNlrOHb9CTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAzMDQ0OQ==", "bodyText": "I really think we should have something like presto-compression to avoid code duplication =)", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499030449", "createdAt": "2020-10-02T20:15:06Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/util/PrestoSparkUtils.java", "diffHunk": "@@ -83,8 +89,75 @@ public static PagesSerde createPagesSerde(BlockEncodingManager blockEncodingMana\n     {\n         return new PagesSerde(\n                 blockEncodingManager,\n-                Optional.empty(),\n-                Optional.empty(),\n+                Optional.of(createPageCompressor()),\n+                Optional.of(createPageDecompressor()),\n                 Optional.empty());\n     }\n+\n+    private static PageCompressor createPageCompressor()\n+    {\n+        // based on ZstdJniCompressor", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8fadf5aa929a0fe70b966831dc9f13036cf2d9c"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzUwMA==", "bodyText": "just double check: this is consistent with how Presto classic checks max broadcast size right?\nAlso I feel in theory we can do the check on driver ? (before broadcast the data)", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499073500", "createdAt": "2020-10-02T22:21:57Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -897,9 +900,29 @@ else if (executionException instanceof PrestoSparkExecutionException) {\n                 PlanFragment childFragment = child.getFragment();\n                 if (childFragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION)) {\n                     RddAndMore<PrestoSparkSerializedPage> childRdd = createRdd(child, PrestoSparkSerializedPage.class);\n+\n+                    // TODO: The driver might still OOM on a very large broadcast, think of how to prevent that from happening\n                     List<PrestoSparkSerializedPage> broadcastPages = childRdd.collectAndDestroyDependencies().stream()\n                             .map(Tuple2::_2)\n                             .collect(toList());\n+\n+                    int compressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(page -> page.getBytes().length)\n+                            .sum();\n+                    int uncompressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(PrestoSparkSerializedPage::getUncompressedSizeInBytes)\n+                            .sum();\n+                    DataSize maxBroadcastSize = getQueryMaxBroadcastMemory(session);\n+                    long maxBroadcastSizeInBytes = maxBroadcastSize.toBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzYxMg==", "bodyText": "i assume you can do this check even before uncompressed the data?", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499073612", "createdAt": "2020-10-02T22:22:26Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -897,9 +900,29 @@ else if (executionException instanceof PrestoSparkExecutionException) {\n                 PlanFragment childFragment = child.getFragment();\n                 if (childFragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION)) {\n                     RddAndMore<PrestoSparkSerializedPage> childRdd = createRdd(child, PrestoSparkSerializedPage.class);\n+\n+                    // TODO: The driver might still OOM on a very large broadcast, think of how to prevent that from happening\n                     List<PrestoSparkSerializedPage> broadcastPages = childRdd.collectAndDestroyDependencies().stream()\n                             .map(Tuple2::_2)\n                             .collect(toList());\n+\n+                    int compressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(page -> page.getBytes().length)\n+                            .sum();\n+                    int uncompressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(PrestoSparkSerializedPage::getUncompressedSizeInBytes)\n+                            .sum();\n+                    DataSize maxBroadcastSize = getQueryMaxBroadcastMemory(session);\n+                    long maxBroadcastSizeInBytes = maxBroadcastSize.toBytes();\n+\n+                    if (compressedBroadcastSizeInBytes > maxBroadcastSizeInBytes) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNDc3NDE4", "url": "https://github.com/prestodb/presto/pull/15262#pullrequestreview-501477418", "createdAt": "2020-10-02T22:23:06Z", "commit": {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4838, "cost": 1, "resetAt": "2021-10-28T20:13:43Z"}}}