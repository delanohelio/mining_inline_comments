{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE0NzAyMzkx", "number": 14495, "title": "Initial implementation of Broadcast join for Presto on Spark", "bodyText": "Required by #13856\n== NO RELEASE NOTE ==", "createdAt": "2020-05-07T13:54:21Z", "url": "https://github.com/prestodb/presto/pull/14495", "merged": true, "mergeCommit": {"oid": "fac749a71afe65cbf07e9e3e73145b7171ab93ec"}, "closed": true, "closedAt": "2020-05-12T10:38:57Z", "author": {"login": "arhimondr"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcfLDC6gFqTQwNzg2MzI5Ng==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcghDMigBqjMzMjY2NTE1NDQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3ODYzMjk2", "url": "https://github.com/prestodb/presto/pull/14495#pullrequestreview-407863296", "createdAt": "2020-05-07T21:51:33Z", "commit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QyMTo1MTozM1rOGSRnIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwNToyNTo0NlrOGSZgQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgxNjA5Nw==", "bodyText": "what about naming them as shuffleInputs and broadcastInputs or some thing similar? :)", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421816097", "createdAt": "2020-05-07T21:51:33Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceFactory.java", "diffHunk": "@@ -29,24 +32,46 @@\n import java.util.Map;\n \n import static com.facebook.presto.spark.util.PrestoSparkUtils.transformRowsToPages;\n-import static java.lang.String.format;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.Iterators.concat;\n+import static com.google.common.collect.Iterators.transform;\n import static java.util.Objects.requireNonNull;\n \n public class PrestoSparkRemoteSourceFactory\n         implements RemoteSourceFactory\n {\n-    private final Map<PlanNodeId, Iterator<PrestoSparkRow>> inputs;\n+    private final PagesSerde pagesSerde;\n+    private final Map<PlanNodeId, Iterator<PrestoSparkRow>> rowInputs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgxODUzNQ==", "bodyText": "nit: One way to avoid nested transform is to inline the operation with lambda:\n            Iterator<Page> iterator = transform(\n                    pageInputs.get(planNodeId),\n                    prestoSparkSerializedPage -> pagesSerde.deserialize(toSerializedPage(prestoSparkSerializedPage))\n            );\nBut I can see why you want to use nested transform, and I have no strong opinion here :)", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421818535", "createdAt": "2020-05-07T21:57:11Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceFactory.java", "diffHunk": "@@ -29,24 +32,46 @@\n import java.util.Map;\n \n import static com.facebook.presto.spark.util.PrestoSparkUtils.transformRowsToPages;\n-import static java.lang.String.format;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.Iterators.concat;\n+import static com.google.common.collect.Iterators.transform;\n import static java.util.Objects.requireNonNull;\n \n public class PrestoSparkRemoteSourceFactory\n         implements RemoteSourceFactory\n {\n-    private final Map<PlanNodeId, Iterator<PrestoSparkRow>> inputs;\n+    private final PagesSerde pagesSerde;\n+    private final Map<PlanNodeId, Iterator<PrestoSparkRow>> rowInputs;\n+    private final Map<PlanNodeId, Iterator<PrestoSparkSerializedPage>> pageInputs;\n \n-    public PrestoSparkRemoteSourceFactory(Map<PlanNodeId, Iterator<PrestoSparkRow>> inputs)\n+    public PrestoSparkRemoteSourceFactory(\n+            PagesSerde pagesSerde,\n+            Map<PlanNodeId, Iterator<PrestoSparkRow>> rowInputs,\n+            Map<PlanNodeId, Iterator<PrestoSparkSerializedPage>> pageInputs)\n     {\n-        this.inputs = ImmutableMap.copyOf(requireNonNull(inputs, \"inputs is null\"));\n+        this.pagesSerde = requireNonNull(pagesSerde, \"pagesSerde is null\");\n+        this.rowInputs = ImmutableMap.copyOf(requireNonNull(rowInputs, \"rowInputs is null\"));\n+        this.pageInputs = ImmutableMap.copyOf(requireNonNull(pageInputs, \"pageInputs is null\"));\n     }\n \n     @Override\n     public OperatorFactory createRemoteSource(Session session, int operatorId, PlanNodeId planNodeId, List<Type> types)\n     {\n-        Iterator<PrestoSparkRow> rowsIterator = requireNonNull(inputs.get(planNodeId), format(\"input is missing for plan node: %s\", planNodeId));\n-        Iterator<Page> pagesIterator = transformRowsToPages(rowsIterator, types);\n+        Iterator<Page> pagesIterator = null;\n+        if (rowInputs.containsKey(planNodeId)) {\n+            Iterator<PrestoSparkRow> rowsIterator = rowInputs.get(planNodeId);\n+            pagesIterator = transformRowsToPages(rowsIterator, types);\n+        }\n+        if (pageInputs.containsKey(planNodeId)) {\n+            Iterator<Page> iterator = transform(transform(pageInputs.get(planNodeId), PrestoSparkUtils::toSerializedPage), pagesSerde::deserialize);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgxOTc5MQ==", "bodyText": "curious: in which situation the planNodeId is only contained in broadcastInputs but not shuffleInputs?", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421819791", "createdAt": "2020-05-07T22:00:05Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceFactory.java", "diffHunk": "@@ -29,24 +32,46 @@\n import java.util.Map;\n \n import static com.facebook.presto.spark.util.PrestoSparkUtils.transformRowsToPages;\n-import static java.lang.String.format;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.Iterators.concat;\n+import static com.google.common.collect.Iterators.transform;\n import static java.util.Objects.requireNonNull;\n \n public class PrestoSparkRemoteSourceFactory\n         implements RemoteSourceFactory\n {\n-    private final Map<PlanNodeId, Iterator<PrestoSparkRow>> inputs;\n+    private final PagesSerde pagesSerde;\n+    private final Map<PlanNodeId, Iterator<PrestoSparkRow>> rowInputs;\n+    private final Map<PlanNodeId, Iterator<PrestoSparkSerializedPage>> pageInputs;\n \n-    public PrestoSparkRemoteSourceFactory(Map<PlanNodeId, Iterator<PrestoSparkRow>> inputs)\n+    public PrestoSparkRemoteSourceFactory(\n+            PagesSerde pagesSerde,\n+            Map<PlanNodeId, Iterator<PrestoSparkRow>> rowInputs,\n+            Map<PlanNodeId, Iterator<PrestoSparkSerializedPage>> pageInputs)\n     {\n-        this.inputs = ImmutableMap.copyOf(requireNonNull(inputs, \"inputs is null\"));\n+        this.pagesSerde = requireNonNull(pagesSerde, \"pagesSerde is null\");\n+        this.rowInputs = ImmutableMap.copyOf(requireNonNull(rowInputs, \"rowInputs is null\"));\n+        this.pageInputs = ImmutableMap.copyOf(requireNonNull(pageInputs, \"pageInputs is null\"));\n     }\n \n     @Override\n     public OperatorFactory createRemoteSource(Session session, int operatorId, PlanNodeId planNodeId, List<Type> types)\n     {\n-        Iterator<PrestoSparkRow> rowsIterator = requireNonNull(inputs.get(planNodeId), format(\"input is missing for plan node: %s\", planNodeId));\n-        Iterator<Page> pagesIterator = transformRowsToPages(rowsIterator, types);\n+        Iterator<Page> pagesIterator = null;\n+        if (rowInputs.containsKey(planNodeId)) {\n+            Iterator<PrestoSparkRow> rowsIterator = rowInputs.get(planNodeId);\n+            pagesIterator = transformRowsToPages(rowsIterator, types);\n+        }\n+        if (pageInputs.containsKey(planNodeId)) {\n+            Iterator<Page> iterator = transform(transform(pageInputs.get(planNodeId), PrestoSparkUtils::toSerializedPage), pagesSerde::deserialize);\n+            if (pagesIterator == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgyMTYxMg==", "bodyText": "So, it looks like shuffle input and broadcast input will be present EXACTLY once. Two questions:\n\nCan we guard this condition? (e.g. One and only input will be present -- either broadcast or shuffle)\nIn PrestoSparkRemoteSourceFactory , from the code it looks like both shuffle input and broadcast input can present?", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421821612", "createdAt": "2020-05-07T22:04:33Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java", "diffHunk": "@@ -228,14 +237,33 @@ public IPrestoSparkTaskExecutor create(\n         PrestoSparkRowBuffer rowBuffer = new PrestoSparkRowBuffer(memoryManager);\n \n         ImmutableMap.Builder<PlanNodeId, Iterator<PrestoSparkRow>> shuffleInputs = ImmutableMap.builder();\n+        ImmutableMap.Builder<PlanNodeId, Iterator<PrestoSparkSerializedPage>> broadcastInputs = ImmutableMap.builder();\n         for (RemoteSourceNode remoteSource : fragment.getRemoteSourceNodes()) {\n-            ImmutableList.Builder<Iterator<PrestoSparkRow>> remoteSourceInputs = ImmutableList.builder();\n+            List<Iterator<PrestoSparkRow>> shuffleRemoteSourceInputs = new ArrayList<>();\n+            List<Iterator<PrestoSparkSerializedPage>> broadcastRemoteSourceInputs = new ArrayList<>();\n             for (PlanFragmentId sourceFragmentId : remoteSource.getSourceFragmentIds()) {\n-                Iterator<Tuple2<Integer, PrestoSparkRow>> input = inputs.getShuffleInputs().get(sourceFragmentId.toString());\n-                checkArgument(input != null, \"input is missing for fragmentId: %s\", sourceFragmentId);\n-                remoteSourceInputs.add(Iterators.transform(input, tuple -> tuple._2));\n+                Iterator<Tuple2<Integer, PrestoSparkRow>> shuffleInput = inputs.getShuffleInputs().get(sourceFragmentId.toString());\n+                if (shuffleInput != null) {\n+                    shuffleRemoteSourceInputs.add(Iterators.transform(shuffleInput, tuple -> tuple._2));\n+                    continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk0MTU3Mg==", "bodyText": "It loos like this Iterators.concat is essentially doing a \"flatmap\" operation over all the remote source inputs.\nI understand for shuffle remote source, there can be one RemoteSourceNode corresponding to multiple inputs (e.g. UNION). But will this also be the case for broadcast remote source ?", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421941572", "createdAt": "2020-05-08T05:11:25Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java", "diffHunk": "@@ -228,14 +237,33 @@ public IPrestoSparkTaskExecutor create(\n         PrestoSparkRowBuffer rowBuffer = new PrestoSparkRowBuffer(memoryManager);\n \n         ImmutableMap.Builder<PlanNodeId, Iterator<PrestoSparkRow>> shuffleInputs = ImmutableMap.builder();\n+        ImmutableMap.Builder<PlanNodeId, Iterator<PrestoSparkSerializedPage>> broadcastInputs = ImmutableMap.builder();\n         for (RemoteSourceNode remoteSource : fragment.getRemoteSourceNodes()) {\n-            ImmutableList.Builder<Iterator<PrestoSparkRow>> remoteSourceInputs = ImmutableList.builder();\n+            List<Iterator<PrestoSparkRow>> shuffleRemoteSourceInputs = new ArrayList<>();\n+            List<Iterator<PrestoSparkSerializedPage>> broadcastRemoteSourceInputs = new ArrayList<>();\n             for (PlanFragmentId sourceFragmentId : remoteSource.getSourceFragmentIds()) {\n-                Iterator<Tuple2<Integer, PrestoSparkRow>> input = inputs.getShuffleInputs().get(sourceFragmentId.toString());\n-                checkArgument(input != null, \"input is missing for fragmentId: %s\", sourceFragmentId);\n-                remoteSourceInputs.add(Iterators.transform(input, tuple -> tuple._2));\n+                Iterator<Tuple2<Integer, PrestoSparkRow>> shuffleInput = inputs.getShuffleInputs().get(sourceFragmentId.toString());\n+                if (shuffleInput != null) {\n+                    shuffleRemoteSourceInputs.add(Iterators.transform(shuffleInput, tuple -> tuple._2));\n+                    continue;\n+                }\n+                Broadcast<List<PrestoSparkSerializedPage>> broadcastInput = inputs.getBroadcastInputs().get(sourceFragmentId.toString());\n+                if (broadcastInput != null) {\n+                    // TODO: Enable NullifyingIterator once migrated to one task per JVM model\n+                    // NullifyingIterator removes element from the list upon return\n+                    // This allows GC to gradually reclaim memory\n+                    // broadcastRemoteSourceInputs.add(getNullifyingIterator(broadcastInput.value()));\n+                    broadcastRemoteSourceInputs.add(broadcastInput.value().iterator());\n+                    continue;\n+                }\n+                throw new IllegalArgumentException(\"Input not found for sourceFragmentId: \" + sourceFragmentId);\n+            }\n+            if (!shuffleRemoteSourceInputs.isEmpty()) {\n+                shuffleInputs.put(remoteSource.getId(), Iterators.concat(shuffleRemoteSourceInputs.iterator()));\n+            }\n+            if (!broadcastRemoteSourceInputs.isEmpty()) {\n+                broadcastInputs.put(remoteSource.getId(), Iterators.concat(broadcastRemoteSourceInputs.iterator()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk0MzM0OA==", "bodyText": "Curious: can we just do actualInputs.equals(expectedInputs)?", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421943348", "createdAt": "2020-05-08T05:18:18Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -220,13 +227,16 @@ private static Partitioner createPartitioner(PartitioningHandle partitioning, in\n                 .flatMap(List::stream)\n                 .collect(toImmutableSet());\n \n-        Set<PlanFragmentId> missingInputs = difference(expectedInputs, rddInputs.keySet());\n-        Set<PlanFragmentId> extraInputs = difference(rddInputs.keySet(), expectedInputs);\n+        Set<PlanFragmentId> actualInputs = union(rddInputs.keySet(), broadcastInputs.keySet());\n+\n+        Set<PlanFragmentId> missingInputs = difference(expectedInputs, actualInputs);\n+        Set<PlanFragmentId> extraInputs = difference(actualInputs, expectedInputs);\n         checkArgument(\n                 missingInputs.isEmpty() && extraInputs.isEmpty(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk0MzgxMQ==", "bodyText": "nit: is it possible to check all remote sources node is reading from broadcast source? If the check is not easy then no worry.", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421943811", "createdAt": "2020-05-08T05:19:48Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -269,11 +281,9 @@ private static Partitioner createPartitioner(PartitioningHandle partitioning, in\n             PlanFragment fragment,\n             PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n             CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n-            TableWriteInfo tableWriteInfo)\n+            TableWriteInfo tableWriteInfo,\n+            Map<PlanFragmentId, Broadcast<List<PrestoSparkSerializedPage>>> broadcastInputs)\n     {\n-        // TODO: Possible in case of a broadcast join\n-        checkArgument(fragment.getRemoteSourceNodes().isEmpty(), \"source task with remote sources is not supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk0NDQxOA==", "bodyText": "nit: what about add a new line before .collect?", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421944418", "createdAt": "2020-05-08T05:22:09Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -377,4 +390,9 @@ private PrestoSparkTaskDescriptor createSourceTaskDescriptor(\n                 .where(TableScanNode.class::isInstance)\n                 .findAll();\n     }\n+\n+    private static Map<String, Broadcast<List<PrestoSparkSerializedPage>>> toTaskProcessorBroadcastInputs(Map<PlanFragmentId, Broadcast<List<PrestoSparkSerializedPage>>> broadcastInputs)\n+    {\n+        return broadcastInputs.entrySet().stream().collect(toImmutableMap(entry -> entry.getKey().toString(), Map.Entry::getValue));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk0NTQxMA==", "bodyText": "nit: consider use BlockUtil#compactArray", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421945410", "createdAt": "2020-05-08T05:25:46Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/util/PrestoSparkUtils.java", "diffHunk": "@@ -58,4 +64,48 @@ protected Page computeNext()\n             }\n         };\n     }\n+\n+    public static PrestoSparkSerializedPage toPrestoSparkSerializedPage(SerializedPage serializedPage)\n+    {\n+        Slice slice = serializedPage.getSlice();\n+        checkArgument(slice.hasByteArray(), \"slice is expected to be based on a byte array\");\n+        byte[] array = slice.byteArray();\n+        if (slice.byteArrayOffset() != 0 || slice.length() != array.length) {\n+            array = copyOfRange(array, slice.byteArrayOffset(), slice.byteArrayOffset() + slice.length());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4MDE2MjUy", "url": "https://github.com/prestodb/presto/pull/14495#pullrequestreview-408016252", "createdAt": "2020-05-08T06:05:06Z", "commit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwNjowNTowNlrOGSaMrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwNjowNTowNlrOGSaMrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1Njc4Mg==", "bodyText": "It looks to me this method actually returns two values:\n\nAn RDD JavaPairRDD<Integer, PrestoSparkRow> that transform Presto SubPlan to Spark RDD.\nA List of Broadcast, indicates \"we have done these Broadcast in preparing for executing this RDD\". As a result,  once the returned RDD finish execution, the broadcasts should be destroyed.\n\nHowever, this seems a bit difficult to understand -- as the broadcasts list is stateful and get appended in the recursive call. I am wondering if it is possible to have a RddAndBroadcast class to return both the RDD and the broadcasts? (Or even RddAndMore, see our TableAndMore, PartitionAndMore classes in SemiTransactionMetastore :D )", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r421956782", "createdAt": "2020-05-08T06:05:06Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -385,29 +403,54 @@ private PrestoSparkQueryExecution(\n                 SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n \n                 SubPlan child = getOnlyElement(root.getChildren());\n-                JavaPairRDD<Integer, PrestoSparkRow> rdd = createRdd(child);\n+                JavaPairRDD<Integer, PrestoSparkRow> rdd = createRdd(child, broadcastsToDestroy);\n                 List<Tuple2<Integer, PrestoSparkRow>> sparkDriverInput = rdd.collect();\n+                broadcastsToDestroy.forEach(Broadcast::destroy);\n                 return ImmutableList.copyOf(executorFactoryProvider.get().create(\n                         0,\n                         0,\n                         serializedTaskDescriptor,\n-                        new PrestoSparkTaskInputs(ImmutableMap.of(child.getFragment().getId().toString(), sparkDriverInput.iterator())),\n+                        new PrestoSparkTaskInputs(ImmutableMap.of(child.getFragment().getId().toString(), sparkDriverInput.iterator()), ImmutableMap.of()),\n                         taskStatsCollector));\n             }\n \n-            return createRdd(root).collect();\n+            List<Tuple2<Integer, PrestoSparkRow>> result = createRdd(root, broadcastsToDestroy).collect();\n+            broadcastsToDestroy.forEach(Broadcast::destroy);\n+            return result;\n         }\n \n-        private JavaPairRDD<Integer, PrestoSparkRow> createRdd(SubPlan subPlan)\n+        private JavaPairRDD<Integer, PrestoSparkRow> createRdd(SubPlan subPlan, List<Broadcast<?>> broadcasts)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 161}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4NzkwNTA5", "url": "https://github.com/prestodb/presto/pull/14495#pullrequestreview-408790509", "createdAt": "2020-05-10T23:07:01Z", "commit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQyMzowNzowMlrOGTIZTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQyMzowNzowMlrOGTIZTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjcxMzY3OQ==", "bodyText": "nit: what about fragementIdToBroadcastInputs? Same for the other variables in this class.", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r422713679", "createdAt": "2020-05-10T23:07:02Z", "author": {"login": "wenleix"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/TaskProcessors.java", "diffHunk": "@@ -34,7 +37,8 @@ private TaskProcessors() {}\n \n     public static PairFlatMapFunction<Iterator<SerializedPrestoSparkTaskDescriptor>, Integer, PrestoSparkRow> createTaskProcessor(\n             PrestoSparkTaskExecutorFactoryProvider taskExecutorFactoryProvider,\n-            CollectionAccumulator<SerializedTaskStats> taskStatsCollector)\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            Map<String, Broadcast<List<PrestoSparkSerializedPage>>> broadcastInputs)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4ODYwODI4", "url": "https://github.com/prestodb/presto/pull/14495#pullrequestreview-408860828", "createdAt": "2020-05-11T05:03:46Z", "commit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwNTowMzo0N1rOGTMkuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwNTowMzo0N1rOGTMkuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjc4MjEzNw==", "bodyText": "Similar to https://github.com/apache/spark/blob/5d5866be12259c40972f7404f64d830cab87401f/sql/core/src/main/scala/org/apache/spark/sql/execution/exchange/BroadcastExchangeExec.scala#L109-L112 , it might help to have some sanity check on data being broadcasted to prevent Driver from OOM. This can be left as a future work.", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r422782137", "createdAt": "2020-05-11T05:03:47Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -385,29 +403,54 @@ private PrestoSparkQueryExecution(\n                 SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n \n                 SubPlan child = getOnlyElement(root.getChildren());\n-                JavaPairRDD<Integer, PrestoSparkRow> rdd = createRdd(child);\n+                JavaPairRDD<Integer, PrestoSparkRow> rdd = createRdd(child, broadcastsToDestroy);\n                 List<Tuple2<Integer, PrestoSparkRow>> sparkDriverInput = rdd.collect();\n+                broadcastsToDestroy.forEach(Broadcast::destroy);\n                 return ImmutableList.copyOf(executorFactoryProvider.get().create(\n                         0,\n                         0,\n                         serializedTaskDescriptor,\n-                        new PrestoSparkTaskInputs(ImmutableMap.of(child.getFragment().getId().toString(), sparkDriverInput.iterator())),\n+                        new PrestoSparkTaskInputs(ImmutableMap.of(child.getFragment().getId().toString(), sparkDriverInput.iterator()), ImmutableMap.of()),\n                         taskStatsCollector));\n             }\n \n-            return createRdd(root).collect();\n+            List<Tuple2<Integer, PrestoSparkRow>> result = createRdd(root, broadcastsToDestroy).collect();\n+            broadcastsToDestroy.forEach(Broadcast::destroy);\n+            return result;\n         }\n \n-        private JavaPairRDD<Integer, PrestoSparkRow> createRdd(SubPlan subPlan)\n+        private JavaPairRDD<Integer, PrestoSparkRow> createRdd(SubPlan subPlan, List<Broadcast<?>> broadcasts)\n         {\n-            PlanFragment fragment = subPlan.getFragment();\n-            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs = subPlan.getChildren().stream()\n-                    .collect(toImmutableMap(children -> children.getFragment().getId(), this::createRdd));\n+            ImmutableMap.Builder<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs = ImmutableMap.builder();\n+            ImmutableMap.Builder<PlanFragmentId, Broadcast<List<PrestoSparkSerializedPage>>> broadcastInputs = ImmutableMap.builder();\n+            for (SubPlan child : subPlan.getChildren()) {\n+                PlanFragment childFragment = child.getFragment();\n+                if (childFragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION)) {\n+                    List<Broadcast<?>> broadcastsToDestroy = new ArrayList<>();\n+                    JavaPairRDD<Integer, PrestoSparkRow> childRdd = createRdd(child, broadcastsToDestroy);\n+                    List<Tuple2<Integer, PrestoSparkRow>> broadcastRows = childRdd.collect();\n+                    // TODO: Transform rows to pages on executors (using `RDD#map` function)\n+                    // TODO: Transforming it on coordinator results in 2x memory utilization as both,\n+                    // TODO: rows and pages have to be kept in memory all at the same time\n+                    Iterator<Page> pagesIterator = transformRowsToPages(transform(broadcastRows.iterator(), Tuple2::_2), childFragment.getTypes());\n+                    Iterator<PrestoSparkSerializedPage> serializedPagesIterator = transform(transform(pagesIterator, pagesSerde::serialize), PrestoSparkUtils::toPrestoSparkSerializedPage);\n+                    List<PrestoSparkSerializedPage> serializedPages = new ArrayList<>();\n+                    serializedPagesIterator.forEachRemaining(serializedPages::add);\n+                    Broadcast<List<PrestoSparkSerializedPage>> broadcast = sparkContext.broadcast(serializedPages);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc"}, "originalPosition": 181}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4ODYzMTU4", "url": "https://github.com/prestodb/presto/pull/14495#pullrequestreview-408863158", "createdAt": "2020-05-11T05:12:09Z", "commit": {"oid": "3d4bd6d4836e14974b9247082f649bc5bad82938"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwNToxMjowOVrOGTMs8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQwNToyMzoyMFrOGTM5Ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjc4NDI0MA==", "bodyText": "When supporting bucket table join unbucketed table, does the join stage consider as SourceTask? -- it has to read from table, but also it's sort of a \"intermediate task\" since it has shuffle inputs.", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r422784240", "createdAt": "2020-05-11T05:12:09Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -15,283 +15,367 @@\n \n import com.facebook.airlift.json.JsonCodec;\n import com.facebook.presto.Session;\n+import com.facebook.presto.execution.Lifespan;\n import com.facebook.presto.execution.ScheduledSplit;\n import com.facebook.presto.execution.TaskSource;\n import com.facebook.presto.execution.scheduler.TableWriteInfo;\n+import com.facebook.presto.metadata.Metadata;\n+import com.facebook.presto.metadata.Split;\n import com.facebook.presto.spark.PrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.IntegerIdentityPartitioner;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkTaskExecutorFactoryProvider;\n import com.facebook.presto.spark.classloader_interface.SerializedPrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.SerializedTaskStats;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.split.SplitManager;\n+import com.facebook.presto.split.SplitSource;\n import com.facebook.presto.sql.planner.PartitioningHandle;\n import com.facebook.presto.sql.planner.PlanFragment;\n+import com.facebook.presto.sql.planner.SystemPartitioningHandle;\n import com.facebook.presto.sql.planner.plan.PlanFragmentId;\n import com.facebook.presto.sql.planner.plan.RemoteSourceNode;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableSet;\n+import org.apache.spark.Partitioner;\n import org.apache.spark.api.java.JavaPairRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.api.java.function.FlatMapFunction2;\n+import org.apache.spark.api.java.function.PairFlatMapFunction;\n import org.apache.spark.util.CollectionAccumulator;\n+import scala.Tuple2;\n \n import javax.inject.Inject;\n \n import java.util.ArrayList;\n+import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n import java.util.Optional;\n import java.util.Set;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n+import static com.facebook.airlift.concurrent.MoreFutures.getFutureValue;\n import static com.facebook.presto.SystemSessionProperties.getHashPartitionCount;\n import static com.facebook.presto.spark.PrestoSparkSessionProperties.getSparkInitialPartitionCount;\n import static com.facebook.presto.spark.classloader_interface.TaskProcessors.createTaskProcessor;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static com.facebook.presto.spi.connector.ConnectorSplitManager.SplitSchedulingStrategy.UNGROUPED_SCHEDULING;\n+import static com.facebook.presto.spi.connector.NotPartitionedPartitionHandle.NOT_PARTITIONED;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.ARBITRARY_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.COORDINATOR_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_ARBITRARY_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_BROADCAST_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_HASH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_PASSTHROUGH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SCALED_WRITER_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SINGLE_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SOURCE_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.optimizations.PlanNodeSearcher.searchFrom;\n import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Verify.verify;\n import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n import static com.google.common.collect.Iterables.getOnlyElement;\n+import static com.google.common.collect.Sets.difference;\n+import static java.lang.String.format;\n+import static java.util.Collections.shuffle;\n import static java.util.Objects.requireNonNull;\n import static java.util.function.Function.identity;\n import static java.util.stream.Collectors.mapping;\n import static java.util.stream.Collectors.toSet;\n \n public class PrestoSparkRddFactory\n {\n-    private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec;\n+    private final SplitManager splitManager;\n+    private final Metadata metadata;\n+    private final JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec;\n \n     @Inject\n-    public PrestoSparkRddFactory(JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec)\n+    public PrestoSparkRddFactory(SplitManager splitManager, Metadata metadata, JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec)\n     {\n-        this.sparkTaskRequestJsonCodec = requireNonNull(sparkTaskRequestJsonCodec, \"sparkTaskRequestJsonCodec is null\");\n+        this.splitManager = requireNonNull(splitManager, \"splitManager is null\");\n+        this.metadata = requireNonNull(metadata, \"metadata is null\");\n+        this.taskDescriptorJsonCodec = requireNonNull(taskDescriptorJsonCodec, \"taskDescriptorJsonCodec is null\");\n     }\n \n     public JavaPairRDD<Integer, PrestoSparkRow> createSparkRdd(\n             JavaSparkContext sparkContext,\n             Session session,\n-            PrestoSparkPlan prestoSparkPlan,\n-            PrestoSparkTaskExecutorFactoryProvider taskExecutorFactoryProvider,\n-            CollectionAccumulator<SerializedTaskStats> taskStatsCollector)\n+            PlanFragment fragment,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n     {\n-        RddFactory rddFactory = new RddFactory(\n-                session,\n-                sparkTaskRequestJsonCodec,\n-                sparkContext,\n-                taskExecutorFactoryProvider,\n-                getSparkInitialPartitionCount(session),\n-                getHashPartitionCount(session),\n-                taskStatsCollector,\n-                prestoSparkPlan.getTableWriteInfo());\n-        return rddFactory.createRdd(prestoSparkPlan.getPlan());\n-    }\n+        checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n \n-    private static class RddFactory\n-    {\n-        private final Session session;\n-        private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec;\n-        private final JavaSparkContext sparkContext;\n-        private final PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider;\n-        private final int initialSparkPartitionCount;\n-        private final int hashPartitionCount;\n-        private final CollectionAccumulator<SerializedTaskStats> taskStatsCollector;\n-        private final TableWriteInfo tableWriteInfo;\n-\n-        private RddFactory(\n-                Session session,\n-                JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec,\n-                JavaSparkContext sparkContext,\n-                PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n-                int initialSparkPartitionCount,\n-                int hashPartitionCount,\n-                CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n-                TableWriteInfo tableWriteInfo)\n-        {\n-            this.session = requireNonNull(session, \"session is null\");\n-            this.sparkTaskDescriptorJsonCodec = requireNonNull(sparkTaskDescriptorJsonCodec, \"sparkTaskDescriptorJsonCodec is null\");\n-            this.sparkContext = requireNonNull(sparkContext, \"sparkContext is null\");\n-            this.executorFactoryProvider = requireNonNull(executorFactoryProvider, \"executorFactoryProvider is null\");\n-            this.initialSparkPartitionCount = initialSparkPartitionCount;\n-            this.hashPartitionCount = hashPartitionCount;\n-            this.taskStatsCollector = requireNonNull(taskStatsCollector, \"taskStatsCollector is null\");\n-            this.tableWriteInfo = requireNonNull(tableWriteInfo, \"tableWriteInfo is null\");\n+        PartitioningHandle partitioning = fragment.getPartitioning();\n+\n+        if (!(partitioning.getConnectorHandle() instanceof SystemPartitioningHandle)) {\n+            // TODO: add support for bucketed table\n+            throw new PrestoException(NOT_SUPPORTED, \"Partitioned (bucketed) tables are not yet supported by Presto on Spark\");\n         }\n \n-        public JavaPairRDD<Integer, PrestoSparkRow> createRdd(PrestoSparkSubPlan subPlan)\n-        {\n-            PlanFragment fragment;\n-            // TODO: fragment adaption should be done prior to RDD creation\n-            if (subPlan.getFragment().getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n-                fragment = subPlan.getFragment().withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n-            }\n-            else {\n-                fragment = subPlan.getFragment();\n-            }\n+        if (partitioning.equals(SCALED_WRITER_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"Automatic writers scaling is not supported by Presto on Spark\");\n+        }\n \n-            checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n+        checkArgument(!partitioning.equals(COORDINATOR_DISTRIBUTION), \"COORDINATOR_DISTRIBUTION fragment must be run on the driver\");\n+        checkArgument(!partitioning.equals(FIXED_BROADCAST_DISTRIBUTION), \"FIXED_BROADCAST_DISTRIBUTION can only be set as an output partitioning scheme, and not as a fragment distribution\");\n+        checkArgument(!partitioning.equals(FIXED_PASSTHROUGH_DISTRIBUTION), \"FIXED_PASSTHROUGH_DISTRIBUTION can only be set as local exchange partitioning\");\n \n-            // scans\n-            List<PlanNodeId> tableScans = fragment.getTableScanSchedulingOrder();\n+        // TODO: ARBITRARY_DISTRIBUTION is something very weird.\n+        // TODO: It doesn't have partitioning function, and it is never set as a fragment partitioning.\n+        // TODO: We should consider removing ARBITRARY_DISTRIBUTION.\n+        checkArgument(!partitioning.equals(ARBITRARY_DISTRIBUTION), \"ARBITRARY_DISTRIBUTION is not expected to be set as a fragment distribution\");\n \n-            // source stages\n-            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n-            checkArgument(tableScans.isEmpty() || remoteSources.isEmpty(), \"stages that have both, remote sources and table scans, are not supported\");\n+        int hashPartitionCount = getHashPartitionCount(session);\n \n-            if (!tableScans.isEmpty()) {\n-                checkArgument(fragment.getPartitioning().equals(SOURCE_DISTRIBUTION), \"unexpected table scan partitioning: %s\", fragment.getPartitioning());\n+        // configure number of output partitions\n+        if (fragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n+            fragment = fragment.withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n+        }\n \n-                // get all scheduled splits\n-                List<ScheduledSplit> scheduledSplits = subPlan.getTaskSources().stream()\n-                        .flatMap(taskSource -> taskSource.getSplits().stream())\n-                        .collect(toImmutableList());\n+        if (partitioning.equals(SINGLE_DISTRIBUTION) || partitioning.equals(FIXED_HASH_DISTRIBUTION) || partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            checkArgument(\n+                    fragment.getTableScanSchedulingOrder().isEmpty(),\n+                    \"Fragment with is not expected to have table scans. fragmentId: %s, fragment partitioning %s\",\n+                    fragment.getId(),\n+                    fragment.getPartitioning());\n+\n+            for (RemoteSourceNode remoteSource : fragment.getRemoteSourceNodes()) {\n+                if (remoteSource.isEnsureSourceOrdering() || remoteSource.getOrderingScheme().isPresent()) {\n+                    throw new PrestoException(NOT_SUPPORTED, format(\n+                            \"Order sensitive exchange is not supported by Presto on Spark. fragmentId: %s, sourceFragmentIds: %s\",\n+                            fragment.getId(),\n+                            remoteSource.getSourceFragmentIds()));\n+                }\n+            }\n \n-                // get scheduled splits by task\n-                List<List<ScheduledSplit>> assignedSplits = assignSplitsToTasks(scheduledSplits, initialSparkPartitionCount);\n+            Partitioner inputPartitioner = createPartitioner(\n+                    partitioning,\n+                    // TODO: consider using getMaxTasksPerStage\n+                    hashPartitionCount);\n \n-                List<SerializedPrestoSparkTaskDescriptor> serializedRequests = assignedSplits.stream()\n-                        .map(splits -> createTaskDescriptor(fragment, splits))\n-                        .map(sparkTaskDescriptorJsonCodec::toJsonBytes)\n-                        .map(SerializedPrestoSparkTaskDescriptor::new)\n-                        .collect(toImmutableList());\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> partitionedInputs = rddInputs.entrySet().stream()\n+                    .collect(toImmutableMap(Map.Entry::getKey, entry -> entry.getValue().partitionBy(inputPartitioner)));\n \n-                return sparkContext.parallelize(serializedRequests, initialSparkPartitionCount)\n-                        .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, taskStatsCollector));\n-            }\n+            return createIntermediateRdd(\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo,\n+                    partitionedInputs);\n+        }\n+        else if (partitioning.equals(SOURCE_DISTRIBUTION)) {\n+            checkArgument(rddInputs.isEmpty(), \"rddInputs is expected to be empty for SOURCE_DISTRIBUTION fragment: %s\", fragment.getId());\n+            return createSourceRdd(\n+                    sparkContext,\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s, fragmentId: %s\", partitioning, fragment.getId()));\n+        }\n+    }\n \n-            List<PrestoSparkSubPlan> children = subPlan.getChildren();\n-            checkArgument(\n-                    remoteSources.size() == children.size(),\n-                    \"number of remote sources doesn't match the number of child stages: %s != %s\",\n-                    remoteSources.size(),\n-                    children.size());\n-\n-            if (children.size() == 1) {\n-                // Single remote source\n-                PrestoSparkSubPlan childSubPlan = getOnlyElement(children);\n-                JavaPairRDD<Integer, PrestoSparkRow> childRdd = createRdd(childSubPlan);\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-\n-                if (partitioning.equals(COORDINATOR_DISTRIBUTION)) {\n-                    // coordinator side work will be handled after JavaPairRDD#collect() call in PrestoSparkExecution\n-                    return childRdd;\n-                }\n+    private static Partitioner createPartitioner(PartitioningHandle partitioning, int partitionCount)\n+    {\n+        if (partitioning.equals(SINGLE_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(1);\n+        }\n+        if (partitioning.equals(FIXED_HASH_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(partitionCount);\n+        }\n+        if (partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"FIXED_ARBITRARY_DISTRIBUTION partitioning is not yet supported\");\n+        }\n+        throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s\", partitioning));\n+    }\n \n-                PlanFragment childFragment = childSubPlan.getFragment();\n-                RemoteSourceNode remoteSource = getOnlyElement(remoteSources);\n-                List<PlanFragmentId> sourceFragmentIds = remoteSource.getSourceFragmentIds();\n-                checkArgument(sourceFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(childFragment.getId().equals(getOnlyElement(sourceFragmentIds)));\n-\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                if (partitioning.equals(FIXED_HASH_DISTRIBUTION) ||\n-                        // when single distribution - there will be a single partition 0\n-                        partitioning.equals(SINGLE_DISTRIBUTION)) {\n-                    String planNodeId = remoteSource.getId().toString();\n-                    return childRdd\n-                            .partitionBy(partitioning.equals(FIXED_HASH_DISTRIBUTION) ? new IntegerIdentityPartitioner(hashPartitionCount) : new IntegerIdentityPartitioner(1))\n-                            .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, planNodeId, taskStatsCollector));\n-                }\n-                else {\n-                    // TODO: support (or do check state over) the following fragment partitioning:\n-                    //  - SOURCE_DISTRIBUTION\n-                    //  - FIXED_PASSTHROUGH_DISTRIBUTION\n-                    //  - ARBITRARY_DISTRIBUTION\n-                    //  - SCALED_WRITER_DISTRIBUTION\n-                    //  - FIXED_BROADCAST_DISTRIBUTION\n-                    //  - FIXED_ARBITRARY_DISTRIBUTION\n-                    throw new IllegalArgumentException(\"Unsupported fragment partitioning: \" + partitioning);\n-                }\n-            }\n-            else if (children.size() == 2) {\n-                // TODO: support N way join\n-                PrestoSparkSubPlan leftSubPlan = children.get(0);\n-                PrestoSparkSubPlan rightSubPlan = children.get(1);\n-\n-                RemoteSourceNode leftRemoteSource = remoteSources.get(0);\n-                RemoteSourceNode rightRemoteSource = remoteSources.get(1);\n-\n-                // We need String representation since PlanNodeId is not serializable...\n-                String leftRemoteSourcePlanId = leftRemoteSource.getId().toString();\n-                String rightRemoteSourcePlanId = rightRemoteSource.getId().toString();\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> leftChildRdd = createRdd(leftSubPlan);\n-                JavaPairRDD<Integer, PrestoSparkRow> rightChildRdd = createRdd(rightSubPlan);\n-\n-                PlanFragment leftFragment = leftSubPlan.getFragment();\n-                PlanFragment rightFragment = rightSubPlan.getFragment();\n-\n-                List<PlanFragmentId> leftFragmentIds = leftRemoteSource.getSourceFragmentIds();\n-                checkArgument(leftFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(leftFragment.getId().equals(getOnlyElement(leftFragmentIds)));\n-                List<PlanFragmentId> rightFragmentIds = rightRemoteSource.getSourceFragmentIds();\n-                checkArgument(rightFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(rightFragment.getId().equals(getOnlyElement(rightFragmentIds)));\n-\n-                // This fragment only contains remote source, thus there is no splits\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-                checkArgument(partitioning.equals(FIXED_HASH_DISTRIBUTION));\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledLeftChildRdd = leftChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledRightChildRdd = rightChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                return JavaPairRDD.fromJavaRDD(\n-                        shuffledLeftChildRdd.zipPartitions(\n-                                shuffledRightChildRdd,\n-                                createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, leftRemoteSourcePlanId, rightRemoteSourcePlanId, taskStatsCollector)));\n-            }\n-            else {\n-                throw new UnsupportedOperationException();\n-            }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createIntermediateRdd(\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs)\n+    {\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        verify(tableScans.isEmpty(), \"no table scans is expected\");\n+\n+        Set<PlanFragmentId> expectedInputs = fragment.getRemoteSourceNodes().stream()\n+                .map(RemoteSourceNode::getSourceFragmentIds)\n+                .flatMap(List::stream)\n+                .collect(toImmutableSet());\n+\n+        Set<PlanFragmentId> missingInputs = difference(expectedInputs, rddInputs.keySet());\n+        Set<PlanFragmentId> extraInputs = difference(rddInputs.keySet(), expectedInputs);\n+        checkArgument(\n+                missingInputs.isEmpty() && extraInputs.isEmpty(),\n+                \"rddInputs mismatch discovered. expected: %s, actual: %s\",\n+                expectedInputs,\n+                rddInputs.keySet());\n+\n+        PrestoSparkTaskDescriptor taskDescriptor = createIntermediateTaskDescriptor(session, tableWriteInfo, fragment);\n+        SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(taskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n+\n+        if (rddInputs.size() == 1) {\n+            RemoteSourceNode remoteSourceNode = getOnlyElement(fragment.getRemoteSourceNodes());\n+            PairFlatMapFunction<Iterator<Tuple2<Integer, PrestoSparkRow>>, Integer, PrestoSparkRow> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            remoteSourceNode.getId().toString(),\n+                            taskStatsCollector);\n+            return getOnlyElement(rddInputs.values())\n+                    .mapPartitionsToPair(taskProcessor);\n+        }\n+        else if (rddInputs.size() == 2) {\n+            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n+            checkArgument(remoteSources.size() == 2, \"two remote sources are expected, got: %s\", remoteSources.size());\n+            RemoteSourceNode firstRemoteSource = remoteSources.get(0);\n+            RemoteSourceNode secondRemoteSource = remoteSources.get(1);\n+            JavaPairRDD<Integer, PrestoSparkRow> firstRdd = rddInputs.get(firstRemoteSource.getSourceFragmentIds().get(0));\n+            JavaPairRDD<Integer, PrestoSparkRow> secondRdd = rddInputs.get(secondRemoteSource.getSourceFragmentIds().get(0));\n+            FlatMapFunction2<Iterator<Tuple2<Integer, PrestoSparkRow>>, Iterator<Tuple2<Integer, PrestoSparkRow>>, Tuple2<Integer, PrestoSparkRow>> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            firstRemoteSource.getId().toString(),\n+                            secondRemoteSource.getId().toString(),\n+                            taskStatsCollector);\n+            return JavaPairRDD.fromJavaRDD(\n+                    firstRdd.zipPartitions(\n+                            secondRdd,\n+                            taskProcessor));\n         }\n \n-        private static List<List<ScheduledSplit>> assignSplitsToTasks(List<ScheduledSplit> scheduledSplits, int numTasks)\n-        {\n-            List<List<ScheduledSplit>> assignedSplits = new ArrayList<>();\n-            for (int i = 0; i < numTasks; i++) {\n-                assignedSplits.add(new ArrayList<>());\n-            }\n+        throw new IllegalArgumentException(format(\"unsupported number of inputs: %s\", rddInputs.size()));\n+    }\n \n-            for (ScheduledSplit split : scheduledSplits) {\n-                int taskId = Objects.hash(split.getPlanNodeId(), split.getSequenceId()) % numTasks;\n-                if (taskId < 0) {\n-                    taskId += numTasks;\n-                }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createSourceRdd(\n+            JavaSparkContext sparkContext,\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n+    {\n+        // TODO: Possible in case of a broadcast join\n+        checkArgument(fragment.getRemoteSourceNodes().isEmpty(), \"source task with remote sources is not supported\");\n+\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        checkArgument(\n+                tableScans.size() == 1,\n+                \"exactly one table scan is expected in SOURCE_DISTRIBUTION fragment. fragmentId: %s, actual number of table scans: %s\",\n+                fragment.getId(),\n+                tableScans.size());\n+        verify(tableScans.size() == fragment.getTableScanSchedulingOrder().size());\n+\n+        TableScanNode tableScan = tableScans.get(0);\n+\n+        List<ScheduledSplit> splits = getSplits(session, tableScan);\n+        shuffle(splits);\n+        int initialPartitionCount = getSparkInitialPartitionCount(session);\n+        int numTasks = Math.min(splits.size(), initialPartitionCount);\n+        if (numTasks == 0) {\n+            return JavaPairRDD.fromJavaRDD(sparkContext.emptyRDD());\n+        }\n \n-                assignedSplits.get(taskId).add(split);\n-            }\n+        List<List<ScheduledSplit>> assignedSplits = assignSplitsToTasks(splits, numTasks);\n \n-            return assignedSplits;\n+        // let the garbage collector reclaim the memory used by the decoded splits as soon as the task descriptor is encoded\n+        splits = null;\n+\n+        ImmutableList.Builder<SerializedPrestoSparkTaskDescriptor> serializedTaskDescriptors = ImmutableList.builder();\n+        for (int i = 0; i < assignedSplits.size(); i++) {\n+            List<ScheduledSplit> splitBatch = assignedSplits.get(i);\n+            PrestoSparkTaskDescriptor taskDescriptor = createSourceTaskDescriptor(session, tableWriteInfo, fragment, splitBatch);\n+            // TODO: consider more efficient serialization or apply compression to save precious memory on the Driver\n+            byte[] jsonSerializedTaskDescriptor = taskDescriptorJsonCodec.toJsonBytes(taskDescriptor);\n+            serializedTaskDescriptors.add(new SerializedPrestoSparkTaskDescriptor(jsonSerializedTaskDescriptor));\n+            // let the garbage collector reclaim the memory used by the decoded splits as soon as the task descriptor is encoded\n+            assignedSplits.set(i, null);\n         }\n \n-        private PrestoSparkTaskDescriptor createTaskDescriptor(PlanFragment fragment, List<ScheduledSplit> splits)\n-        {\n-            Map<PlanNodeId, Set<ScheduledSplit>> splitsByPlanNode = splits.stream()\n-                    .collect(Collectors.groupingBy(\n-                            ScheduledSplit::getPlanNodeId,\n-                            mapping(identity(), toSet())));\n-\n-            List<TaskSource> taskSourceByPlanNode = splitsByPlanNode.entrySet().stream()\n-                    .map(entry -> new TaskSource(\n-                            entry.getKey(),\n-                            entry.getValue(),\n-                            ImmutableSet.of(),\n-                            true))\n-                    .collect(toImmutableList());\n-\n-            return new PrestoSparkTaskDescriptor(\n-                    session.toSessionRepresentation(),\n-                    session.getIdentity().getExtraCredentials(),\n-                    fragment,\n-                    taskSourceByPlanNode,\n-                    tableWriteInfo);\n+        return sparkContext.parallelize(serializedTaskDescriptors.build(), numTasks)\n+                .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, taskStatsCollector));\n+    }\n+\n+    private List<ScheduledSplit> getSplits(Session session, TableScanNode tableScan)\n+    {\n+        List<ScheduledSplit> splits = new ArrayList<>();\n+        SplitSource splitSource = splitManager.getSplits(session, tableScan.getTable(), UNGROUPED_SCHEDULING);\n+        long sequenceId = 0;\n+        while (!splitSource.isFinished()) {\n+            List<Split> splitBatch = getFutureValue(splitSource.getNextBatch(NOT_PARTITIONED, Lifespan.taskWide(), 1000)).getSplits();\n+            for (Split split : splitBatch) {\n+                splits.add(new ScheduledSplit(sequenceId++, tableScan.getId(), split));\n+            }\n+        }\n+        return splits;\n+    }\n+\n+    private static List<List<ScheduledSplit>> assignSplitsToTasks(List<ScheduledSplit> splits, int numTasks)\n+    {\n+        checkArgument(numTasks > 0, \"numTasks must be greater then zero\");\n+        List<List<ScheduledSplit>> assignedSplits = new ArrayList<>();\n+        for (int i = 0; i < numTasks; i++) {\n+            assignedSplits.add(new ArrayList<>());\n+        }\n+        for (int splitIndex = 0; splitIndex < splits.size(); splitIndex++) {\n+            assignedSplits.get(splitIndex % numTasks).add(splits.get(splitIndex));\n         }\n+        return assignedSplits;\n+    }\n+\n+    private PrestoSparkTaskDescriptor createIntermediateTaskDescriptor(Session session, TableWriteInfo tableWriteInfo, PlanFragment fragment)\n+    {\n+        return createSourceTaskDescriptor(session, tableWriteInfo, fragment, ImmutableList.of());\n+    }\n+\n+    private PrestoSparkTaskDescriptor createSourceTaskDescriptor(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4bd6d4836e14974b9247082f649bc5bad82938"}, "originalPosition": 535}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjc4NDcyOQ==", "bodyText": "nit: getOnlyElement", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r422784729", "createdAt": "2020-05-11T05:13:54Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -15,283 +15,367 @@\n \n import com.facebook.airlift.json.JsonCodec;\n import com.facebook.presto.Session;\n+import com.facebook.presto.execution.Lifespan;\n import com.facebook.presto.execution.ScheduledSplit;\n import com.facebook.presto.execution.TaskSource;\n import com.facebook.presto.execution.scheduler.TableWriteInfo;\n+import com.facebook.presto.metadata.Metadata;\n+import com.facebook.presto.metadata.Split;\n import com.facebook.presto.spark.PrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.IntegerIdentityPartitioner;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkTaskExecutorFactoryProvider;\n import com.facebook.presto.spark.classloader_interface.SerializedPrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.SerializedTaskStats;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.split.SplitManager;\n+import com.facebook.presto.split.SplitSource;\n import com.facebook.presto.sql.planner.PartitioningHandle;\n import com.facebook.presto.sql.planner.PlanFragment;\n+import com.facebook.presto.sql.planner.SystemPartitioningHandle;\n import com.facebook.presto.sql.planner.plan.PlanFragmentId;\n import com.facebook.presto.sql.planner.plan.RemoteSourceNode;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableSet;\n+import org.apache.spark.Partitioner;\n import org.apache.spark.api.java.JavaPairRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.api.java.function.FlatMapFunction2;\n+import org.apache.spark.api.java.function.PairFlatMapFunction;\n import org.apache.spark.util.CollectionAccumulator;\n+import scala.Tuple2;\n \n import javax.inject.Inject;\n \n import java.util.ArrayList;\n+import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n import java.util.Optional;\n import java.util.Set;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n+import static com.facebook.airlift.concurrent.MoreFutures.getFutureValue;\n import static com.facebook.presto.SystemSessionProperties.getHashPartitionCount;\n import static com.facebook.presto.spark.PrestoSparkSessionProperties.getSparkInitialPartitionCount;\n import static com.facebook.presto.spark.classloader_interface.TaskProcessors.createTaskProcessor;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static com.facebook.presto.spi.connector.ConnectorSplitManager.SplitSchedulingStrategy.UNGROUPED_SCHEDULING;\n+import static com.facebook.presto.spi.connector.NotPartitionedPartitionHandle.NOT_PARTITIONED;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.ARBITRARY_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.COORDINATOR_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_ARBITRARY_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_BROADCAST_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_HASH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_PASSTHROUGH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SCALED_WRITER_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SINGLE_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SOURCE_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.optimizations.PlanNodeSearcher.searchFrom;\n import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Verify.verify;\n import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n import static com.google.common.collect.Iterables.getOnlyElement;\n+import static com.google.common.collect.Sets.difference;\n+import static java.lang.String.format;\n+import static java.util.Collections.shuffle;\n import static java.util.Objects.requireNonNull;\n import static java.util.function.Function.identity;\n import static java.util.stream.Collectors.mapping;\n import static java.util.stream.Collectors.toSet;\n \n public class PrestoSparkRddFactory\n {\n-    private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec;\n+    private final SplitManager splitManager;\n+    private final Metadata metadata;\n+    private final JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec;\n \n     @Inject\n-    public PrestoSparkRddFactory(JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec)\n+    public PrestoSparkRddFactory(SplitManager splitManager, Metadata metadata, JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec)\n     {\n-        this.sparkTaskRequestJsonCodec = requireNonNull(sparkTaskRequestJsonCodec, \"sparkTaskRequestJsonCodec is null\");\n+        this.splitManager = requireNonNull(splitManager, \"splitManager is null\");\n+        this.metadata = requireNonNull(metadata, \"metadata is null\");\n+        this.taskDescriptorJsonCodec = requireNonNull(taskDescriptorJsonCodec, \"taskDescriptorJsonCodec is null\");\n     }\n \n     public JavaPairRDD<Integer, PrestoSparkRow> createSparkRdd(\n             JavaSparkContext sparkContext,\n             Session session,\n-            PrestoSparkPlan prestoSparkPlan,\n-            PrestoSparkTaskExecutorFactoryProvider taskExecutorFactoryProvider,\n-            CollectionAccumulator<SerializedTaskStats> taskStatsCollector)\n+            PlanFragment fragment,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n     {\n-        RddFactory rddFactory = new RddFactory(\n-                session,\n-                sparkTaskRequestJsonCodec,\n-                sparkContext,\n-                taskExecutorFactoryProvider,\n-                getSparkInitialPartitionCount(session),\n-                getHashPartitionCount(session),\n-                taskStatsCollector,\n-                prestoSparkPlan.getTableWriteInfo());\n-        return rddFactory.createRdd(prestoSparkPlan.getPlan());\n-    }\n+        checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n \n-    private static class RddFactory\n-    {\n-        private final Session session;\n-        private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec;\n-        private final JavaSparkContext sparkContext;\n-        private final PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider;\n-        private final int initialSparkPartitionCount;\n-        private final int hashPartitionCount;\n-        private final CollectionAccumulator<SerializedTaskStats> taskStatsCollector;\n-        private final TableWriteInfo tableWriteInfo;\n-\n-        private RddFactory(\n-                Session session,\n-                JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec,\n-                JavaSparkContext sparkContext,\n-                PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n-                int initialSparkPartitionCount,\n-                int hashPartitionCount,\n-                CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n-                TableWriteInfo tableWriteInfo)\n-        {\n-            this.session = requireNonNull(session, \"session is null\");\n-            this.sparkTaskDescriptorJsonCodec = requireNonNull(sparkTaskDescriptorJsonCodec, \"sparkTaskDescriptorJsonCodec is null\");\n-            this.sparkContext = requireNonNull(sparkContext, \"sparkContext is null\");\n-            this.executorFactoryProvider = requireNonNull(executorFactoryProvider, \"executorFactoryProvider is null\");\n-            this.initialSparkPartitionCount = initialSparkPartitionCount;\n-            this.hashPartitionCount = hashPartitionCount;\n-            this.taskStatsCollector = requireNonNull(taskStatsCollector, \"taskStatsCollector is null\");\n-            this.tableWriteInfo = requireNonNull(tableWriteInfo, \"tableWriteInfo is null\");\n+        PartitioningHandle partitioning = fragment.getPartitioning();\n+\n+        if (!(partitioning.getConnectorHandle() instanceof SystemPartitioningHandle)) {\n+            // TODO: add support for bucketed table\n+            throw new PrestoException(NOT_SUPPORTED, \"Partitioned (bucketed) tables are not yet supported by Presto on Spark\");\n         }\n \n-        public JavaPairRDD<Integer, PrestoSparkRow> createRdd(PrestoSparkSubPlan subPlan)\n-        {\n-            PlanFragment fragment;\n-            // TODO: fragment adaption should be done prior to RDD creation\n-            if (subPlan.getFragment().getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n-                fragment = subPlan.getFragment().withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n-            }\n-            else {\n-                fragment = subPlan.getFragment();\n-            }\n+        if (partitioning.equals(SCALED_WRITER_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"Automatic writers scaling is not supported by Presto on Spark\");\n+        }\n \n-            checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n+        checkArgument(!partitioning.equals(COORDINATOR_DISTRIBUTION), \"COORDINATOR_DISTRIBUTION fragment must be run on the driver\");\n+        checkArgument(!partitioning.equals(FIXED_BROADCAST_DISTRIBUTION), \"FIXED_BROADCAST_DISTRIBUTION can only be set as an output partitioning scheme, and not as a fragment distribution\");\n+        checkArgument(!partitioning.equals(FIXED_PASSTHROUGH_DISTRIBUTION), \"FIXED_PASSTHROUGH_DISTRIBUTION can only be set as local exchange partitioning\");\n \n-            // scans\n-            List<PlanNodeId> tableScans = fragment.getTableScanSchedulingOrder();\n+        // TODO: ARBITRARY_DISTRIBUTION is something very weird.\n+        // TODO: It doesn't have partitioning function, and it is never set as a fragment partitioning.\n+        // TODO: We should consider removing ARBITRARY_DISTRIBUTION.\n+        checkArgument(!partitioning.equals(ARBITRARY_DISTRIBUTION), \"ARBITRARY_DISTRIBUTION is not expected to be set as a fragment distribution\");\n \n-            // source stages\n-            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n-            checkArgument(tableScans.isEmpty() || remoteSources.isEmpty(), \"stages that have both, remote sources and table scans, are not supported\");\n+        int hashPartitionCount = getHashPartitionCount(session);\n \n-            if (!tableScans.isEmpty()) {\n-                checkArgument(fragment.getPartitioning().equals(SOURCE_DISTRIBUTION), \"unexpected table scan partitioning: %s\", fragment.getPartitioning());\n+        // configure number of output partitions\n+        if (fragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n+            fragment = fragment.withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n+        }\n \n-                // get all scheduled splits\n-                List<ScheduledSplit> scheduledSplits = subPlan.getTaskSources().stream()\n-                        .flatMap(taskSource -> taskSource.getSplits().stream())\n-                        .collect(toImmutableList());\n+        if (partitioning.equals(SINGLE_DISTRIBUTION) || partitioning.equals(FIXED_HASH_DISTRIBUTION) || partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            checkArgument(\n+                    fragment.getTableScanSchedulingOrder().isEmpty(),\n+                    \"Fragment with is not expected to have table scans. fragmentId: %s, fragment partitioning %s\",\n+                    fragment.getId(),\n+                    fragment.getPartitioning());\n+\n+            for (RemoteSourceNode remoteSource : fragment.getRemoteSourceNodes()) {\n+                if (remoteSource.isEnsureSourceOrdering() || remoteSource.getOrderingScheme().isPresent()) {\n+                    throw new PrestoException(NOT_SUPPORTED, format(\n+                            \"Order sensitive exchange is not supported by Presto on Spark. fragmentId: %s, sourceFragmentIds: %s\",\n+                            fragment.getId(),\n+                            remoteSource.getSourceFragmentIds()));\n+                }\n+            }\n \n-                // get scheduled splits by task\n-                List<List<ScheduledSplit>> assignedSplits = assignSplitsToTasks(scheduledSplits, initialSparkPartitionCount);\n+            Partitioner inputPartitioner = createPartitioner(\n+                    partitioning,\n+                    // TODO: consider using getMaxTasksPerStage\n+                    hashPartitionCount);\n \n-                List<SerializedPrestoSparkTaskDescriptor> serializedRequests = assignedSplits.stream()\n-                        .map(splits -> createTaskDescriptor(fragment, splits))\n-                        .map(sparkTaskDescriptorJsonCodec::toJsonBytes)\n-                        .map(SerializedPrestoSparkTaskDescriptor::new)\n-                        .collect(toImmutableList());\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> partitionedInputs = rddInputs.entrySet().stream()\n+                    .collect(toImmutableMap(Map.Entry::getKey, entry -> entry.getValue().partitionBy(inputPartitioner)));\n \n-                return sparkContext.parallelize(serializedRequests, initialSparkPartitionCount)\n-                        .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, taskStatsCollector));\n-            }\n+            return createIntermediateRdd(\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo,\n+                    partitionedInputs);\n+        }\n+        else if (partitioning.equals(SOURCE_DISTRIBUTION)) {\n+            checkArgument(rddInputs.isEmpty(), \"rddInputs is expected to be empty for SOURCE_DISTRIBUTION fragment: %s\", fragment.getId());\n+            return createSourceRdd(\n+                    sparkContext,\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s, fragmentId: %s\", partitioning, fragment.getId()));\n+        }\n+    }\n \n-            List<PrestoSparkSubPlan> children = subPlan.getChildren();\n-            checkArgument(\n-                    remoteSources.size() == children.size(),\n-                    \"number of remote sources doesn't match the number of child stages: %s != %s\",\n-                    remoteSources.size(),\n-                    children.size());\n-\n-            if (children.size() == 1) {\n-                // Single remote source\n-                PrestoSparkSubPlan childSubPlan = getOnlyElement(children);\n-                JavaPairRDD<Integer, PrestoSparkRow> childRdd = createRdd(childSubPlan);\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-\n-                if (partitioning.equals(COORDINATOR_DISTRIBUTION)) {\n-                    // coordinator side work will be handled after JavaPairRDD#collect() call in PrestoSparkExecution\n-                    return childRdd;\n-                }\n+    private static Partitioner createPartitioner(PartitioningHandle partitioning, int partitionCount)\n+    {\n+        if (partitioning.equals(SINGLE_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(1);\n+        }\n+        if (partitioning.equals(FIXED_HASH_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(partitionCount);\n+        }\n+        if (partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"FIXED_ARBITRARY_DISTRIBUTION partitioning is not yet supported\");\n+        }\n+        throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s\", partitioning));\n+    }\n \n-                PlanFragment childFragment = childSubPlan.getFragment();\n-                RemoteSourceNode remoteSource = getOnlyElement(remoteSources);\n-                List<PlanFragmentId> sourceFragmentIds = remoteSource.getSourceFragmentIds();\n-                checkArgument(sourceFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(childFragment.getId().equals(getOnlyElement(sourceFragmentIds)));\n-\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                if (partitioning.equals(FIXED_HASH_DISTRIBUTION) ||\n-                        // when single distribution - there will be a single partition 0\n-                        partitioning.equals(SINGLE_DISTRIBUTION)) {\n-                    String planNodeId = remoteSource.getId().toString();\n-                    return childRdd\n-                            .partitionBy(partitioning.equals(FIXED_HASH_DISTRIBUTION) ? new IntegerIdentityPartitioner(hashPartitionCount) : new IntegerIdentityPartitioner(1))\n-                            .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, planNodeId, taskStatsCollector));\n-                }\n-                else {\n-                    // TODO: support (or do check state over) the following fragment partitioning:\n-                    //  - SOURCE_DISTRIBUTION\n-                    //  - FIXED_PASSTHROUGH_DISTRIBUTION\n-                    //  - ARBITRARY_DISTRIBUTION\n-                    //  - SCALED_WRITER_DISTRIBUTION\n-                    //  - FIXED_BROADCAST_DISTRIBUTION\n-                    //  - FIXED_ARBITRARY_DISTRIBUTION\n-                    throw new IllegalArgumentException(\"Unsupported fragment partitioning: \" + partitioning);\n-                }\n-            }\n-            else if (children.size() == 2) {\n-                // TODO: support N way join\n-                PrestoSparkSubPlan leftSubPlan = children.get(0);\n-                PrestoSparkSubPlan rightSubPlan = children.get(1);\n-\n-                RemoteSourceNode leftRemoteSource = remoteSources.get(0);\n-                RemoteSourceNode rightRemoteSource = remoteSources.get(1);\n-\n-                // We need String representation since PlanNodeId is not serializable...\n-                String leftRemoteSourcePlanId = leftRemoteSource.getId().toString();\n-                String rightRemoteSourcePlanId = rightRemoteSource.getId().toString();\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> leftChildRdd = createRdd(leftSubPlan);\n-                JavaPairRDD<Integer, PrestoSparkRow> rightChildRdd = createRdd(rightSubPlan);\n-\n-                PlanFragment leftFragment = leftSubPlan.getFragment();\n-                PlanFragment rightFragment = rightSubPlan.getFragment();\n-\n-                List<PlanFragmentId> leftFragmentIds = leftRemoteSource.getSourceFragmentIds();\n-                checkArgument(leftFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(leftFragment.getId().equals(getOnlyElement(leftFragmentIds)));\n-                List<PlanFragmentId> rightFragmentIds = rightRemoteSource.getSourceFragmentIds();\n-                checkArgument(rightFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(rightFragment.getId().equals(getOnlyElement(rightFragmentIds)));\n-\n-                // This fragment only contains remote source, thus there is no splits\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-                checkArgument(partitioning.equals(FIXED_HASH_DISTRIBUTION));\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledLeftChildRdd = leftChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledRightChildRdd = rightChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                return JavaPairRDD.fromJavaRDD(\n-                        shuffledLeftChildRdd.zipPartitions(\n-                                shuffledRightChildRdd,\n-                                createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, leftRemoteSourcePlanId, rightRemoteSourcePlanId, taskStatsCollector)));\n-            }\n-            else {\n-                throw new UnsupportedOperationException();\n-            }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createIntermediateRdd(\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs)\n+    {\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        verify(tableScans.isEmpty(), \"no table scans is expected\");\n+\n+        Set<PlanFragmentId> expectedInputs = fragment.getRemoteSourceNodes().stream()\n+                .map(RemoteSourceNode::getSourceFragmentIds)\n+                .flatMap(List::stream)\n+                .collect(toImmutableSet());\n+\n+        Set<PlanFragmentId> missingInputs = difference(expectedInputs, rddInputs.keySet());\n+        Set<PlanFragmentId> extraInputs = difference(rddInputs.keySet(), expectedInputs);\n+        checkArgument(\n+                missingInputs.isEmpty() && extraInputs.isEmpty(),\n+                \"rddInputs mismatch discovered. expected: %s, actual: %s\",\n+                expectedInputs,\n+                rddInputs.keySet());\n+\n+        PrestoSparkTaskDescriptor taskDescriptor = createIntermediateTaskDescriptor(session, tableWriteInfo, fragment);\n+        SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(taskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n+\n+        if (rddInputs.size() == 1) {\n+            RemoteSourceNode remoteSourceNode = getOnlyElement(fragment.getRemoteSourceNodes());\n+            PairFlatMapFunction<Iterator<Tuple2<Integer, PrestoSparkRow>>, Integer, PrestoSparkRow> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            remoteSourceNode.getId().toString(),\n+                            taskStatsCollector);\n+            return getOnlyElement(rddInputs.values())\n+                    .mapPartitionsToPair(taskProcessor);\n+        }\n+        else if (rddInputs.size() == 2) {\n+            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n+            checkArgument(remoteSources.size() == 2, \"two remote sources are expected, got: %s\", remoteSources.size());\n+            RemoteSourceNode firstRemoteSource = remoteSources.get(0);\n+            RemoteSourceNode secondRemoteSource = remoteSources.get(1);\n+            JavaPairRDD<Integer, PrestoSparkRow> firstRdd = rddInputs.get(firstRemoteSource.getSourceFragmentIds().get(0));\n+            JavaPairRDD<Integer, PrestoSparkRow> secondRdd = rddInputs.get(secondRemoteSource.getSourceFragmentIds().get(0));\n+            FlatMapFunction2<Iterator<Tuple2<Integer, PrestoSparkRow>>, Iterator<Tuple2<Integer, PrestoSparkRow>>, Tuple2<Integer, PrestoSparkRow>> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            firstRemoteSource.getId().toString(),\n+                            secondRemoteSource.getId().toString(),\n+                            taskStatsCollector);\n+            return JavaPairRDD.fromJavaRDD(\n+                    firstRdd.zipPartitions(\n+                            secondRdd,\n+                            taskProcessor));\n         }\n \n-        private static List<List<ScheduledSplit>> assignSplitsToTasks(List<ScheduledSplit> scheduledSplits, int numTasks)\n-        {\n-            List<List<ScheduledSplit>> assignedSplits = new ArrayList<>();\n-            for (int i = 0; i < numTasks; i++) {\n-                assignedSplits.add(new ArrayList<>());\n-            }\n+        throw new IllegalArgumentException(format(\"unsupported number of inputs: %s\", rddInputs.size()));\n+    }\n \n-            for (ScheduledSplit split : scheduledSplits) {\n-                int taskId = Objects.hash(split.getPlanNodeId(), split.getSequenceId()) % numTasks;\n-                if (taskId < 0) {\n-                    taskId += numTasks;\n-                }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createSourceRdd(\n+            JavaSparkContext sparkContext,\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n+    {\n+        // TODO: Possible in case of a broadcast join\n+        checkArgument(fragment.getRemoteSourceNodes().isEmpty(), \"source task with remote sources is not supported\");\n+\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        checkArgument(\n+                tableScans.size() == 1,\n+                \"exactly one table scan is expected in SOURCE_DISTRIBUTION fragment. fragmentId: %s, actual number of table scans: %s\",\n+                fragment.getId(),\n+                tableScans.size());\n+        verify(tableScans.size() == fragment.getTableScanSchedulingOrder().size());\n+\n+        TableScanNode tableScan = tableScans.get(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4bd6d4836e14974b9247082f649bc5bad82938"}, "originalPosition": 449}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjc4NDk0OA==", "bodyText": "hmm. maybe we can make the previous checkArugment to assert both tableScan.size() == 1 && fragment.getTableScanSchedulingOrder().size() == 1?", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r422784948", "createdAt": "2020-05-11T05:14:48Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -15,283 +15,367 @@\n \n import com.facebook.airlift.json.JsonCodec;\n import com.facebook.presto.Session;\n+import com.facebook.presto.execution.Lifespan;\n import com.facebook.presto.execution.ScheduledSplit;\n import com.facebook.presto.execution.TaskSource;\n import com.facebook.presto.execution.scheduler.TableWriteInfo;\n+import com.facebook.presto.metadata.Metadata;\n+import com.facebook.presto.metadata.Split;\n import com.facebook.presto.spark.PrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.IntegerIdentityPartitioner;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkTaskExecutorFactoryProvider;\n import com.facebook.presto.spark.classloader_interface.SerializedPrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.SerializedTaskStats;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.split.SplitManager;\n+import com.facebook.presto.split.SplitSource;\n import com.facebook.presto.sql.planner.PartitioningHandle;\n import com.facebook.presto.sql.planner.PlanFragment;\n+import com.facebook.presto.sql.planner.SystemPartitioningHandle;\n import com.facebook.presto.sql.planner.plan.PlanFragmentId;\n import com.facebook.presto.sql.planner.plan.RemoteSourceNode;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableSet;\n+import org.apache.spark.Partitioner;\n import org.apache.spark.api.java.JavaPairRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.api.java.function.FlatMapFunction2;\n+import org.apache.spark.api.java.function.PairFlatMapFunction;\n import org.apache.spark.util.CollectionAccumulator;\n+import scala.Tuple2;\n \n import javax.inject.Inject;\n \n import java.util.ArrayList;\n+import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n import java.util.Optional;\n import java.util.Set;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n+import static com.facebook.airlift.concurrent.MoreFutures.getFutureValue;\n import static com.facebook.presto.SystemSessionProperties.getHashPartitionCount;\n import static com.facebook.presto.spark.PrestoSparkSessionProperties.getSparkInitialPartitionCount;\n import static com.facebook.presto.spark.classloader_interface.TaskProcessors.createTaskProcessor;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static com.facebook.presto.spi.connector.ConnectorSplitManager.SplitSchedulingStrategy.UNGROUPED_SCHEDULING;\n+import static com.facebook.presto.spi.connector.NotPartitionedPartitionHandle.NOT_PARTITIONED;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.ARBITRARY_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.COORDINATOR_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_ARBITRARY_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_BROADCAST_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_HASH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_PASSTHROUGH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SCALED_WRITER_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SINGLE_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SOURCE_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.optimizations.PlanNodeSearcher.searchFrom;\n import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Verify.verify;\n import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n import static com.google.common.collect.Iterables.getOnlyElement;\n+import static com.google.common.collect.Sets.difference;\n+import static java.lang.String.format;\n+import static java.util.Collections.shuffle;\n import static java.util.Objects.requireNonNull;\n import static java.util.function.Function.identity;\n import static java.util.stream.Collectors.mapping;\n import static java.util.stream.Collectors.toSet;\n \n public class PrestoSparkRddFactory\n {\n-    private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec;\n+    private final SplitManager splitManager;\n+    private final Metadata metadata;\n+    private final JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec;\n \n     @Inject\n-    public PrestoSparkRddFactory(JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec)\n+    public PrestoSparkRddFactory(SplitManager splitManager, Metadata metadata, JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec)\n     {\n-        this.sparkTaskRequestJsonCodec = requireNonNull(sparkTaskRequestJsonCodec, \"sparkTaskRequestJsonCodec is null\");\n+        this.splitManager = requireNonNull(splitManager, \"splitManager is null\");\n+        this.metadata = requireNonNull(metadata, \"metadata is null\");\n+        this.taskDescriptorJsonCodec = requireNonNull(taskDescriptorJsonCodec, \"taskDescriptorJsonCodec is null\");\n     }\n \n     public JavaPairRDD<Integer, PrestoSparkRow> createSparkRdd(\n             JavaSparkContext sparkContext,\n             Session session,\n-            PrestoSparkPlan prestoSparkPlan,\n-            PrestoSparkTaskExecutorFactoryProvider taskExecutorFactoryProvider,\n-            CollectionAccumulator<SerializedTaskStats> taskStatsCollector)\n+            PlanFragment fragment,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n     {\n-        RddFactory rddFactory = new RddFactory(\n-                session,\n-                sparkTaskRequestJsonCodec,\n-                sparkContext,\n-                taskExecutorFactoryProvider,\n-                getSparkInitialPartitionCount(session),\n-                getHashPartitionCount(session),\n-                taskStatsCollector,\n-                prestoSparkPlan.getTableWriteInfo());\n-        return rddFactory.createRdd(prestoSparkPlan.getPlan());\n-    }\n+        checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n \n-    private static class RddFactory\n-    {\n-        private final Session session;\n-        private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec;\n-        private final JavaSparkContext sparkContext;\n-        private final PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider;\n-        private final int initialSparkPartitionCount;\n-        private final int hashPartitionCount;\n-        private final CollectionAccumulator<SerializedTaskStats> taskStatsCollector;\n-        private final TableWriteInfo tableWriteInfo;\n-\n-        private RddFactory(\n-                Session session,\n-                JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec,\n-                JavaSparkContext sparkContext,\n-                PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n-                int initialSparkPartitionCount,\n-                int hashPartitionCount,\n-                CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n-                TableWriteInfo tableWriteInfo)\n-        {\n-            this.session = requireNonNull(session, \"session is null\");\n-            this.sparkTaskDescriptorJsonCodec = requireNonNull(sparkTaskDescriptorJsonCodec, \"sparkTaskDescriptorJsonCodec is null\");\n-            this.sparkContext = requireNonNull(sparkContext, \"sparkContext is null\");\n-            this.executorFactoryProvider = requireNonNull(executorFactoryProvider, \"executorFactoryProvider is null\");\n-            this.initialSparkPartitionCount = initialSparkPartitionCount;\n-            this.hashPartitionCount = hashPartitionCount;\n-            this.taskStatsCollector = requireNonNull(taskStatsCollector, \"taskStatsCollector is null\");\n-            this.tableWriteInfo = requireNonNull(tableWriteInfo, \"tableWriteInfo is null\");\n+        PartitioningHandle partitioning = fragment.getPartitioning();\n+\n+        if (!(partitioning.getConnectorHandle() instanceof SystemPartitioningHandle)) {\n+            // TODO: add support for bucketed table\n+            throw new PrestoException(NOT_SUPPORTED, \"Partitioned (bucketed) tables are not yet supported by Presto on Spark\");\n         }\n \n-        public JavaPairRDD<Integer, PrestoSparkRow> createRdd(PrestoSparkSubPlan subPlan)\n-        {\n-            PlanFragment fragment;\n-            // TODO: fragment adaption should be done prior to RDD creation\n-            if (subPlan.getFragment().getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n-                fragment = subPlan.getFragment().withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n-            }\n-            else {\n-                fragment = subPlan.getFragment();\n-            }\n+        if (partitioning.equals(SCALED_WRITER_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"Automatic writers scaling is not supported by Presto on Spark\");\n+        }\n \n-            checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n+        checkArgument(!partitioning.equals(COORDINATOR_DISTRIBUTION), \"COORDINATOR_DISTRIBUTION fragment must be run on the driver\");\n+        checkArgument(!partitioning.equals(FIXED_BROADCAST_DISTRIBUTION), \"FIXED_BROADCAST_DISTRIBUTION can only be set as an output partitioning scheme, and not as a fragment distribution\");\n+        checkArgument(!partitioning.equals(FIXED_PASSTHROUGH_DISTRIBUTION), \"FIXED_PASSTHROUGH_DISTRIBUTION can only be set as local exchange partitioning\");\n \n-            // scans\n-            List<PlanNodeId> tableScans = fragment.getTableScanSchedulingOrder();\n+        // TODO: ARBITRARY_DISTRIBUTION is something very weird.\n+        // TODO: It doesn't have partitioning function, and it is never set as a fragment partitioning.\n+        // TODO: We should consider removing ARBITRARY_DISTRIBUTION.\n+        checkArgument(!partitioning.equals(ARBITRARY_DISTRIBUTION), \"ARBITRARY_DISTRIBUTION is not expected to be set as a fragment distribution\");\n \n-            // source stages\n-            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n-            checkArgument(tableScans.isEmpty() || remoteSources.isEmpty(), \"stages that have both, remote sources and table scans, are not supported\");\n+        int hashPartitionCount = getHashPartitionCount(session);\n \n-            if (!tableScans.isEmpty()) {\n-                checkArgument(fragment.getPartitioning().equals(SOURCE_DISTRIBUTION), \"unexpected table scan partitioning: %s\", fragment.getPartitioning());\n+        // configure number of output partitions\n+        if (fragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n+            fragment = fragment.withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n+        }\n \n-                // get all scheduled splits\n-                List<ScheduledSplit> scheduledSplits = subPlan.getTaskSources().stream()\n-                        .flatMap(taskSource -> taskSource.getSplits().stream())\n-                        .collect(toImmutableList());\n+        if (partitioning.equals(SINGLE_DISTRIBUTION) || partitioning.equals(FIXED_HASH_DISTRIBUTION) || partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            checkArgument(\n+                    fragment.getTableScanSchedulingOrder().isEmpty(),\n+                    \"Fragment with is not expected to have table scans. fragmentId: %s, fragment partitioning %s\",\n+                    fragment.getId(),\n+                    fragment.getPartitioning());\n+\n+            for (RemoteSourceNode remoteSource : fragment.getRemoteSourceNodes()) {\n+                if (remoteSource.isEnsureSourceOrdering() || remoteSource.getOrderingScheme().isPresent()) {\n+                    throw new PrestoException(NOT_SUPPORTED, format(\n+                            \"Order sensitive exchange is not supported by Presto on Spark. fragmentId: %s, sourceFragmentIds: %s\",\n+                            fragment.getId(),\n+                            remoteSource.getSourceFragmentIds()));\n+                }\n+            }\n \n-                // get scheduled splits by task\n-                List<List<ScheduledSplit>> assignedSplits = assignSplitsToTasks(scheduledSplits, initialSparkPartitionCount);\n+            Partitioner inputPartitioner = createPartitioner(\n+                    partitioning,\n+                    // TODO: consider using getMaxTasksPerStage\n+                    hashPartitionCount);\n \n-                List<SerializedPrestoSparkTaskDescriptor> serializedRequests = assignedSplits.stream()\n-                        .map(splits -> createTaskDescriptor(fragment, splits))\n-                        .map(sparkTaskDescriptorJsonCodec::toJsonBytes)\n-                        .map(SerializedPrestoSparkTaskDescriptor::new)\n-                        .collect(toImmutableList());\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> partitionedInputs = rddInputs.entrySet().stream()\n+                    .collect(toImmutableMap(Map.Entry::getKey, entry -> entry.getValue().partitionBy(inputPartitioner)));\n \n-                return sparkContext.parallelize(serializedRequests, initialSparkPartitionCount)\n-                        .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, taskStatsCollector));\n-            }\n+            return createIntermediateRdd(\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo,\n+                    partitionedInputs);\n+        }\n+        else if (partitioning.equals(SOURCE_DISTRIBUTION)) {\n+            checkArgument(rddInputs.isEmpty(), \"rddInputs is expected to be empty for SOURCE_DISTRIBUTION fragment: %s\", fragment.getId());\n+            return createSourceRdd(\n+                    sparkContext,\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s, fragmentId: %s\", partitioning, fragment.getId()));\n+        }\n+    }\n \n-            List<PrestoSparkSubPlan> children = subPlan.getChildren();\n-            checkArgument(\n-                    remoteSources.size() == children.size(),\n-                    \"number of remote sources doesn't match the number of child stages: %s != %s\",\n-                    remoteSources.size(),\n-                    children.size());\n-\n-            if (children.size() == 1) {\n-                // Single remote source\n-                PrestoSparkSubPlan childSubPlan = getOnlyElement(children);\n-                JavaPairRDD<Integer, PrestoSparkRow> childRdd = createRdd(childSubPlan);\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-\n-                if (partitioning.equals(COORDINATOR_DISTRIBUTION)) {\n-                    // coordinator side work will be handled after JavaPairRDD#collect() call in PrestoSparkExecution\n-                    return childRdd;\n-                }\n+    private static Partitioner createPartitioner(PartitioningHandle partitioning, int partitionCount)\n+    {\n+        if (partitioning.equals(SINGLE_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(1);\n+        }\n+        if (partitioning.equals(FIXED_HASH_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(partitionCount);\n+        }\n+        if (partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"FIXED_ARBITRARY_DISTRIBUTION partitioning is not yet supported\");\n+        }\n+        throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s\", partitioning));\n+    }\n \n-                PlanFragment childFragment = childSubPlan.getFragment();\n-                RemoteSourceNode remoteSource = getOnlyElement(remoteSources);\n-                List<PlanFragmentId> sourceFragmentIds = remoteSource.getSourceFragmentIds();\n-                checkArgument(sourceFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(childFragment.getId().equals(getOnlyElement(sourceFragmentIds)));\n-\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                if (partitioning.equals(FIXED_HASH_DISTRIBUTION) ||\n-                        // when single distribution - there will be a single partition 0\n-                        partitioning.equals(SINGLE_DISTRIBUTION)) {\n-                    String planNodeId = remoteSource.getId().toString();\n-                    return childRdd\n-                            .partitionBy(partitioning.equals(FIXED_HASH_DISTRIBUTION) ? new IntegerIdentityPartitioner(hashPartitionCount) : new IntegerIdentityPartitioner(1))\n-                            .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, planNodeId, taskStatsCollector));\n-                }\n-                else {\n-                    // TODO: support (or do check state over) the following fragment partitioning:\n-                    //  - SOURCE_DISTRIBUTION\n-                    //  - FIXED_PASSTHROUGH_DISTRIBUTION\n-                    //  - ARBITRARY_DISTRIBUTION\n-                    //  - SCALED_WRITER_DISTRIBUTION\n-                    //  - FIXED_BROADCAST_DISTRIBUTION\n-                    //  - FIXED_ARBITRARY_DISTRIBUTION\n-                    throw new IllegalArgumentException(\"Unsupported fragment partitioning: \" + partitioning);\n-                }\n-            }\n-            else if (children.size() == 2) {\n-                // TODO: support N way join\n-                PrestoSparkSubPlan leftSubPlan = children.get(0);\n-                PrestoSparkSubPlan rightSubPlan = children.get(1);\n-\n-                RemoteSourceNode leftRemoteSource = remoteSources.get(0);\n-                RemoteSourceNode rightRemoteSource = remoteSources.get(1);\n-\n-                // We need String representation since PlanNodeId is not serializable...\n-                String leftRemoteSourcePlanId = leftRemoteSource.getId().toString();\n-                String rightRemoteSourcePlanId = rightRemoteSource.getId().toString();\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> leftChildRdd = createRdd(leftSubPlan);\n-                JavaPairRDD<Integer, PrestoSparkRow> rightChildRdd = createRdd(rightSubPlan);\n-\n-                PlanFragment leftFragment = leftSubPlan.getFragment();\n-                PlanFragment rightFragment = rightSubPlan.getFragment();\n-\n-                List<PlanFragmentId> leftFragmentIds = leftRemoteSource.getSourceFragmentIds();\n-                checkArgument(leftFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(leftFragment.getId().equals(getOnlyElement(leftFragmentIds)));\n-                List<PlanFragmentId> rightFragmentIds = rightRemoteSource.getSourceFragmentIds();\n-                checkArgument(rightFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(rightFragment.getId().equals(getOnlyElement(rightFragmentIds)));\n-\n-                // This fragment only contains remote source, thus there is no splits\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-                checkArgument(partitioning.equals(FIXED_HASH_DISTRIBUTION));\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledLeftChildRdd = leftChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledRightChildRdd = rightChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                return JavaPairRDD.fromJavaRDD(\n-                        shuffledLeftChildRdd.zipPartitions(\n-                                shuffledRightChildRdd,\n-                                createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, leftRemoteSourcePlanId, rightRemoteSourcePlanId, taskStatsCollector)));\n-            }\n-            else {\n-                throw new UnsupportedOperationException();\n-            }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createIntermediateRdd(\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs)\n+    {\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        verify(tableScans.isEmpty(), \"no table scans is expected\");\n+\n+        Set<PlanFragmentId> expectedInputs = fragment.getRemoteSourceNodes().stream()\n+                .map(RemoteSourceNode::getSourceFragmentIds)\n+                .flatMap(List::stream)\n+                .collect(toImmutableSet());\n+\n+        Set<PlanFragmentId> missingInputs = difference(expectedInputs, rddInputs.keySet());\n+        Set<PlanFragmentId> extraInputs = difference(rddInputs.keySet(), expectedInputs);\n+        checkArgument(\n+                missingInputs.isEmpty() && extraInputs.isEmpty(),\n+                \"rddInputs mismatch discovered. expected: %s, actual: %s\",\n+                expectedInputs,\n+                rddInputs.keySet());\n+\n+        PrestoSparkTaskDescriptor taskDescriptor = createIntermediateTaskDescriptor(session, tableWriteInfo, fragment);\n+        SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(taskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n+\n+        if (rddInputs.size() == 1) {\n+            RemoteSourceNode remoteSourceNode = getOnlyElement(fragment.getRemoteSourceNodes());\n+            PairFlatMapFunction<Iterator<Tuple2<Integer, PrestoSparkRow>>, Integer, PrestoSparkRow> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            remoteSourceNode.getId().toString(),\n+                            taskStatsCollector);\n+            return getOnlyElement(rddInputs.values())\n+                    .mapPartitionsToPair(taskProcessor);\n+        }\n+        else if (rddInputs.size() == 2) {\n+            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n+            checkArgument(remoteSources.size() == 2, \"two remote sources are expected, got: %s\", remoteSources.size());\n+            RemoteSourceNode firstRemoteSource = remoteSources.get(0);\n+            RemoteSourceNode secondRemoteSource = remoteSources.get(1);\n+            JavaPairRDD<Integer, PrestoSparkRow> firstRdd = rddInputs.get(firstRemoteSource.getSourceFragmentIds().get(0));\n+            JavaPairRDD<Integer, PrestoSparkRow> secondRdd = rddInputs.get(secondRemoteSource.getSourceFragmentIds().get(0));\n+            FlatMapFunction2<Iterator<Tuple2<Integer, PrestoSparkRow>>, Iterator<Tuple2<Integer, PrestoSparkRow>>, Tuple2<Integer, PrestoSparkRow>> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            firstRemoteSource.getId().toString(),\n+                            secondRemoteSource.getId().toString(),\n+                            taskStatsCollector);\n+            return JavaPairRDD.fromJavaRDD(\n+                    firstRdd.zipPartitions(\n+                            secondRdd,\n+                            taskProcessor));\n         }\n \n-        private static List<List<ScheduledSplit>> assignSplitsToTasks(List<ScheduledSplit> scheduledSplits, int numTasks)\n-        {\n-            List<List<ScheduledSplit>> assignedSplits = new ArrayList<>();\n-            for (int i = 0; i < numTasks; i++) {\n-                assignedSplits.add(new ArrayList<>());\n-            }\n+        throw new IllegalArgumentException(format(\"unsupported number of inputs: %s\", rddInputs.size()));\n+    }\n \n-            for (ScheduledSplit split : scheduledSplits) {\n-                int taskId = Objects.hash(split.getPlanNodeId(), split.getSequenceId()) % numTasks;\n-                if (taskId < 0) {\n-                    taskId += numTasks;\n-                }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createSourceRdd(\n+            JavaSparkContext sparkContext,\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n+    {\n+        // TODO: Possible in case of a broadcast join\n+        checkArgument(fragment.getRemoteSourceNodes().isEmpty(), \"source task with remote sources is not supported\");\n+\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        checkArgument(\n+                tableScans.size() == 1,\n+                \"exactly one table scan is expected in SOURCE_DISTRIBUTION fragment. fragmentId: %s, actual number of table scans: %s\",\n+                fragment.getId(),\n+                tableScans.size());\n+        verify(tableScans.size() == fragment.getTableScanSchedulingOrder().size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4bd6d4836e14974b9247082f649bc5bad82938"}, "originalPosition": 447}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjc4NTQ4Ng==", "bodyText": "I am not sure. If so then we should also use getMaxTasksPerStage for the initial partition count : \n  \n    \n      presto/presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java\n    \n    \n        Lines 161 to 162\n      in\n      472538a\n    \n    \n    \n    \n\n        \n          \n           return sparkContext.parallelize(serializedRequests, initialSparkPartitionCount) \n        \n\n        \n          \n                   .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, taskStatsCollector));", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r422785486", "createdAt": "2020-05-11T05:16:49Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -15,283 +15,367 @@\n \n import com.facebook.airlift.json.JsonCodec;\n import com.facebook.presto.Session;\n+import com.facebook.presto.execution.Lifespan;\n import com.facebook.presto.execution.ScheduledSplit;\n import com.facebook.presto.execution.TaskSource;\n import com.facebook.presto.execution.scheduler.TableWriteInfo;\n+import com.facebook.presto.metadata.Metadata;\n+import com.facebook.presto.metadata.Split;\n import com.facebook.presto.spark.PrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.IntegerIdentityPartitioner;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkTaskExecutorFactoryProvider;\n import com.facebook.presto.spark.classloader_interface.SerializedPrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.SerializedTaskStats;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.split.SplitManager;\n+import com.facebook.presto.split.SplitSource;\n import com.facebook.presto.sql.planner.PartitioningHandle;\n import com.facebook.presto.sql.planner.PlanFragment;\n+import com.facebook.presto.sql.planner.SystemPartitioningHandle;\n import com.facebook.presto.sql.planner.plan.PlanFragmentId;\n import com.facebook.presto.sql.planner.plan.RemoteSourceNode;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableSet;\n+import org.apache.spark.Partitioner;\n import org.apache.spark.api.java.JavaPairRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.api.java.function.FlatMapFunction2;\n+import org.apache.spark.api.java.function.PairFlatMapFunction;\n import org.apache.spark.util.CollectionAccumulator;\n+import scala.Tuple2;\n \n import javax.inject.Inject;\n \n import java.util.ArrayList;\n+import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n import java.util.Optional;\n import java.util.Set;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n+import static com.facebook.airlift.concurrent.MoreFutures.getFutureValue;\n import static com.facebook.presto.SystemSessionProperties.getHashPartitionCount;\n import static com.facebook.presto.spark.PrestoSparkSessionProperties.getSparkInitialPartitionCount;\n import static com.facebook.presto.spark.classloader_interface.TaskProcessors.createTaskProcessor;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static com.facebook.presto.spi.connector.ConnectorSplitManager.SplitSchedulingStrategy.UNGROUPED_SCHEDULING;\n+import static com.facebook.presto.spi.connector.NotPartitionedPartitionHandle.NOT_PARTITIONED;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.ARBITRARY_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.COORDINATOR_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_ARBITRARY_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_BROADCAST_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_HASH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_PASSTHROUGH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SCALED_WRITER_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SINGLE_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SOURCE_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.optimizations.PlanNodeSearcher.searchFrom;\n import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Verify.verify;\n import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n import static com.google.common.collect.Iterables.getOnlyElement;\n+import static com.google.common.collect.Sets.difference;\n+import static java.lang.String.format;\n+import static java.util.Collections.shuffle;\n import static java.util.Objects.requireNonNull;\n import static java.util.function.Function.identity;\n import static java.util.stream.Collectors.mapping;\n import static java.util.stream.Collectors.toSet;\n \n public class PrestoSparkRddFactory\n {\n-    private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec;\n+    private final SplitManager splitManager;\n+    private final Metadata metadata;\n+    private final JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec;\n \n     @Inject\n-    public PrestoSparkRddFactory(JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec)\n+    public PrestoSparkRddFactory(SplitManager splitManager, Metadata metadata, JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec)\n     {\n-        this.sparkTaskRequestJsonCodec = requireNonNull(sparkTaskRequestJsonCodec, \"sparkTaskRequestJsonCodec is null\");\n+        this.splitManager = requireNonNull(splitManager, \"splitManager is null\");\n+        this.metadata = requireNonNull(metadata, \"metadata is null\");\n+        this.taskDescriptorJsonCodec = requireNonNull(taskDescriptorJsonCodec, \"taskDescriptorJsonCodec is null\");\n     }\n \n     public JavaPairRDD<Integer, PrestoSparkRow> createSparkRdd(\n             JavaSparkContext sparkContext,\n             Session session,\n-            PrestoSparkPlan prestoSparkPlan,\n-            PrestoSparkTaskExecutorFactoryProvider taskExecutorFactoryProvider,\n-            CollectionAccumulator<SerializedTaskStats> taskStatsCollector)\n+            PlanFragment fragment,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n     {\n-        RddFactory rddFactory = new RddFactory(\n-                session,\n-                sparkTaskRequestJsonCodec,\n-                sparkContext,\n-                taskExecutorFactoryProvider,\n-                getSparkInitialPartitionCount(session),\n-                getHashPartitionCount(session),\n-                taskStatsCollector,\n-                prestoSparkPlan.getTableWriteInfo());\n-        return rddFactory.createRdd(prestoSparkPlan.getPlan());\n-    }\n+        checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n \n-    private static class RddFactory\n-    {\n-        private final Session session;\n-        private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec;\n-        private final JavaSparkContext sparkContext;\n-        private final PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider;\n-        private final int initialSparkPartitionCount;\n-        private final int hashPartitionCount;\n-        private final CollectionAccumulator<SerializedTaskStats> taskStatsCollector;\n-        private final TableWriteInfo tableWriteInfo;\n-\n-        private RddFactory(\n-                Session session,\n-                JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec,\n-                JavaSparkContext sparkContext,\n-                PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n-                int initialSparkPartitionCount,\n-                int hashPartitionCount,\n-                CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n-                TableWriteInfo tableWriteInfo)\n-        {\n-            this.session = requireNonNull(session, \"session is null\");\n-            this.sparkTaskDescriptorJsonCodec = requireNonNull(sparkTaskDescriptorJsonCodec, \"sparkTaskDescriptorJsonCodec is null\");\n-            this.sparkContext = requireNonNull(sparkContext, \"sparkContext is null\");\n-            this.executorFactoryProvider = requireNonNull(executorFactoryProvider, \"executorFactoryProvider is null\");\n-            this.initialSparkPartitionCount = initialSparkPartitionCount;\n-            this.hashPartitionCount = hashPartitionCount;\n-            this.taskStatsCollector = requireNonNull(taskStatsCollector, \"taskStatsCollector is null\");\n-            this.tableWriteInfo = requireNonNull(tableWriteInfo, \"tableWriteInfo is null\");\n+        PartitioningHandle partitioning = fragment.getPartitioning();\n+\n+        if (!(partitioning.getConnectorHandle() instanceof SystemPartitioningHandle)) {\n+            // TODO: add support for bucketed table\n+            throw new PrestoException(NOT_SUPPORTED, \"Partitioned (bucketed) tables are not yet supported by Presto on Spark\");\n         }\n \n-        public JavaPairRDD<Integer, PrestoSparkRow> createRdd(PrestoSparkSubPlan subPlan)\n-        {\n-            PlanFragment fragment;\n-            // TODO: fragment adaption should be done prior to RDD creation\n-            if (subPlan.getFragment().getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n-                fragment = subPlan.getFragment().withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n-            }\n-            else {\n-                fragment = subPlan.getFragment();\n-            }\n+        if (partitioning.equals(SCALED_WRITER_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"Automatic writers scaling is not supported by Presto on Spark\");\n+        }\n \n-            checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n+        checkArgument(!partitioning.equals(COORDINATOR_DISTRIBUTION), \"COORDINATOR_DISTRIBUTION fragment must be run on the driver\");\n+        checkArgument(!partitioning.equals(FIXED_BROADCAST_DISTRIBUTION), \"FIXED_BROADCAST_DISTRIBUTION can only be set as an output partitioning scheme, and not as a fragment distribution\");\n+        checkArgument(!partitioning.equals(FIXED_PASSTHROUGH_DISTRIBUTION), \"FIXED_PASSTHROUGH_DISTRIBUTION can only be set as local exchange partitioning\");\n \n-            // scans\n-            List<PlanNodeId> tableScans = fragment.getTableScanSchedulingOrder();\n+        // TODO: ARBITRARY_DISTRIBUTION is something very weird.\n+        // TODO: It doesn't have partitioning function, and it is never set as a fragment partitioning.\n+        // TODO: We should consider removing ARBITRARY_DISTRIBUTION.\n+        checkArgument(!partitioning.equals(ARBITRARY_DISTRIBUTION), \"ARBITRARY_DISTRIBUTION is not expected to be set as a fragment distribution\");\n \n-            // source stages\n-            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n-            checkArgument(tableScans.isEmpty() || remoteSources.isEmpty(), \"stages that have both, remote sources and table scans, are not supported\");\n+        int hashPartitionCount = getHashPartitionCount(session);\n \n-            if (!tableScans.isEmpty()) {\n-                checkArgument(fragment.getPartitioning().equals(SOURCE_DISTRIBUTION), \"unexpected table scan partitioning: %s\", fragment.getPartitioning());\n+        // configure number of output partitions\n+        if (fragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n+            fragment = fragment.withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n+        }\n \n-                // get all scheduled splits\n-                List<ScheduledSplit> scheduledSplits = subPlan.getTaskSources().stream()\n-                        .flatMap(taskSource -> taskSource.getSplits().stream())\n-                        .collect(toImmutableList());\n+        if (partitioning.equals(SINGLE_DISTRIBUTION) || partitioning.equals(FIXED_HASH_DISTRIBUTION) || partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            checkArgument(\n+                    fragment.getTableScanSchedulingOrder().isEmpty(),\n+                    \"Fragment with is not expected to have table scans. fragmentId: %s, fragment partitioning %s\",\n+                    fragment.getId(),\n+                    fragment.getPartitioning());\n+\n+            for (RemoteSourceNode remoteSource : fragment.getRemoteSourceNodes()) {\n+                if (remoteSource.isEnsureSourceOrdering() || remoteSource.getOrderingScheme().isPresent()) {\n+                    throw new PrestoException(NOT_SUPPORTED, format(\n+                            \"Order sensitive exchange is not supported by Presto on Spark. fragmentId: %s, sourceFragmentIds: %s\",\n+                            fragment.getId(),\n+                            remoteSource.getSourceFragmentIds()));\n+                }\n+            }\n \n-                // get scheduled splits by task\n-                List<List<ScheduledSplit>> assignedSplits = assignSplitsToTasks(scheduledSplits, initialSparkPartitionCount);\n+            Partitioner inputPartitioner = createPartitioner(\n+                    partitioning,\n+                    // TODO: consider using getMaxTasksPerStage", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4bd6d4836e14974b9247082f649bc5bad82938"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjc4NjMzNA==", "bodyText": "nit: Add a TODO state we want to refactor List<List<ScheduledSplit>> to be a dedicated class such as SplitAssignment.\nThe motivation is while I suggest this part of code, when I reread my own code my first question is : hmm... what's this List of List? ...", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r422786334", "createdAt": "2020-05-11T05:19:45Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -15,283 +15,367 @@\n \n import com.facebook.airlift.json.JsonCodec;\n import com.facebook.presto.Session;\n+import com.facebook.presto.execution.Lifespan;\n import com.facebook.presto.execution.ScheduledSplit;\n import com.facebook.presto.execution.TaskSource;\n import com.facebook.presto.execution.scheduler.TableWriteInfo;\n+import com.facebook.presto.metadata.Metadata;\n+import com.facebook.presto.metadata.Split;\n import com.facebook.presto.spark.PrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.IntegerIdentityPartitioner;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkTaskExecutorFactoryProvider;\n import com.facebook.presto.spark.classloader_interface.SerializedPrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.SerializedTaskStats;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.split.SplitManager;\n+import com.facebook.presto.split.SplitSource;\n import com.facebook.presto.sql.planner.PartitioningHandle;\n import com.facebook.presto.sql.planner.PlanFragment;\n+import com.facebook.presto.sql.planner.SystemPartitioningHandle;\n import com.facebook.presto.sql.planner.plan.PlanFragmentId;\n import com.facebook.presto.sql.planner.plan.RemoteSourceNode;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableSet;\n+import org.apache.spark.Partitioner;\n import org.apache.spark.api.java.JavaPairRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.api.java.function.FlatMapFunction2;\n+import org.apache.spark.api.java.function.PairFlatMapFunction;\n import org.apache.spark.util.CollectionAccumulator;\n+import scala.Tuple2;\n \n import javax.inject.Inject;\n \n import java.util.ArrayList;\n+import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n import java.util.Optional;\n import java.util.Set;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n+import static com.facebook.airlift.concurrent.MoreFutures.getFutureValue;\n import static com.facebook.presto.SystemSessionProperties.getHashPartitionCount;\n import static com.facebook.presto.spark.PrestoSparkSessionProperties.getSparkInitialPartitionCount;\n import static com.facebook.presto.spark.classloader_interface.TaskProcessors.createTaskProcessor;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static com.facebook.presto.spi.connector.ConnectorSplitManager.SplitSchedulingStrategy.UNGROUPED_SCHEDULING;\n+import static com.facebook.presto.spi.connector.NotPartitionedPartitionHandle.NOT_PARTITIONED;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.ARBITRARY_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.COORDINATOR_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_ARBITRARY_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_BROADCAST_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_HASH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_PASSTHROUGH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SCALED_WRITER_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SINGLE_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SOURCE_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.optimizations.PlanNodeSearcher.searchFrom;\n import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Verify.verify;\n import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n import static com.google.common.collect.Iterables.getOnlyElement;\n+import static com.google.common.collect.Sets.difference;\n+import static java.lang.String.format;\n+import static java.util.Collections.shuffle;\n import static java.util.Objects.requireNonNull;\n import static java.util.function.Function.identity;\n import static java.util.stream.Collectors.mapping;\n import static java.util.stream.Collectors.toSet;\n \n public class PrestoSparkRddFactory\n {\n-    private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec;\n+    private final SplitManager splitManager;\n+    private final Metadata metadata;\n+    private final JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec;\n \n     @Inject\n-    public PrestoSparkRddFactory(JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec)\n+    public PrestoSparkRddFactory(SplitManager splitManager, Metadata metadata, JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec)\n     {\n-        this.sparkTaskRequestJsonCodec = requireNonNull(sparkTaskRequestJsonCodec, \"sparkTaskRequestJsonCodec is null\");\n+        this.splitManager = requireNonNull(splitManager, \"splitManager is null\");\n+        this.metadata = requireNonNull(metadata, \"metadata is null\");\n+        this.taskDescriptorJsonCodec = requireNonNull(taskDescriptorJsonCodec, \"taskDescriptorJsonCodec is null\");\n     }\n \n     public JavaPairRDD<Integer, PrestoSparkRow> createSparkRdd(\n             JavaSparkContext sparkContext,\n             Session session,\n-            PrestoSparkPlan prestoSparkPlan,\n-            PrestoSparkTaskExecutorFactoryProvider taskExecutorFactoryProvider,\n-            CollectionAccumulator<SerializedTaskStats> taskStatsCollector)\n+            PlanFragment fragment,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n     {\n-        RddFactory rddFactory = new RddFactory(\n-                session,\n-                sparkTaskRequestJsonCodec,\n-                sparkContext,\n-                taskExecutorFactoryProvider,\n-                getSparkInitialPartitionCount(session),\n-                getHashPartitionCount(session),\n-                taskStatsCollector,\n-                prestoSparkPlan.getTableWriteInfo());\n-        return rddFactory.createRdd(prestoSparkPlan.getPlan());\n-    }\n+        checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n \n-    private static class RddFactory\n-    {\n-        private final Session session;\n-        private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec;\n-        private final JavaSparkContext sparkContext;\n-        private final PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider;\n-        private final int initialSparkPartitionCount;\n-        private final int hashPartitionCount;\n-        private final CollectionAccumulator<SerializedTaskStats> taskStatsCollector;\n-        private final TableWriteInfo tableWriteInfo;\n-\n-        private RddFactory(\n-                Session session,\n-                JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec,\n-                JavaSparkContext sparkContext,\n-                PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n-                int initialSparkPartitionCount,\n-                int hashPartitionCount,\n-                CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n-                TableWriteInfo tableWriteInfo)\n-        {\n-            this.session = requireNonNull(session, \"session is null\");\n-            this.sparkTaskDescriptorJsonCodec = requireNonNull(sparkTaskDescriptorJsonCodec, \"sparkTaskDescriptorJsonCodec is null\");\n-            this.sparkContext = requireNonNull(sparkContext, \"sparkContext is null\");\n-            this.executorFactoryProvider = requireNonNull(executorFactoryProvider, \"executorFactoryProvider is null\");\n-            this.initialSparkPartitionCount = initialSparkPartitionCount;\n-            this.hashPartitionCount = hashPartitionCount;\n-            this.taskStatsCollector = requireNonNull(taskStatsCollector, \"taskStatsCollector is null\");\n-            this.tableWriteInfo = requireNonNull(tableWriteInfo, \"tableWriteInfo is null\");\n+        PartitioningHandle partitioning = fragment.getPartitioning();\n+\n+        if (!(partitioning.getConnectorHandle() instanceof SystemPartitioningHandle)) {\n+            // TODO: add support for bucketed table\n+            throw new PrestoException(NOT_SUPPORTED, \"Partitioned (bucketed) tables are not yet supported by Presto on Spark\");\n         }\n \n-        public JavaPairRDD<Integer, PrestoSparkRow> createRdd(PrestoSparkSubPlan subPlan)\n-        {\n-            PlanFragment fragment;\n-            // TODO: fragment adaption should be done prior to RDD creation\n-            if (subPlan.getFragment().getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n-                fragment = subPlan.getFragment().withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n-            }\n-            else {\n-                fragment = subPlan.getFragment();\n-            }\n+        if (partitioning.equals(SCALED_WRITER_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"Automatic writers scaling is not supported by Presto on Spark\");\n+        }\n \n-            checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n+        checkArgument(!partitioning.equals(COORDINATOR_DISTRIBUTION), \"COORDINATOR_DISTRIBUTION fragment must be run on the driver\");\n+        checkArgument(!partitioning.equals(FIXED_BROADCAST_DISTRIBUTION), \"FIXED_BROADCAST_DISTRIBUTION can only be set as an output partitioning scheme, and not as a fragment distribution\");\n+        checkArgument(!partitioning.equals(FIXED_PASSTHROUGH_DISTRIBUTION), \"FIXED_PASSTHROUGH_DISTRIBUTION can only be set as local exchange partitioning\");\n \n-            // scans\n-            List<PlanNodeId> tableScans = fragment.getTableScanSchedulingOrder();\n+        // TODO: ARBITRARY_DISTRIBUTION is something very weird.\n+        // TODO: It doesn't have partitioning function, and it is never set as a fragment partitioning.\n+        // TODO: We should consider removing ARBITRARY_DISTRIBUTION.\n+        checkArgument(!partitioning.equals(ARBITRARY_DISTRIBUTION), \"ARBITRARY_DISTRIBUTION is not expected to be set as a fragment distribution\");\n \n-            // source stages\n-            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n-            checkArgument(tableScans.isEmpty() || remoteSources.isEmpty(), \"stages that have both, remote sources and table scans, are not supported\");\n+        int hashPartitionCount = getHashPartitionCount(session);\n \n-            if (!tableScans.isEmpty()) {\n-                checkArgument(fragment.getPartitioning().equals(SOURCE_DISTRIBUTION), \"unexpected table scan partitioning: %s\", fragment.getPartitioning());\n+        // configure number of output partitions\n+        if (fragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n+            fragment = fragment.withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n+        }\n \n-                // get all scheduled splits\n-                List<ScheduledSplit> scheduledSplits = subPlan.getTaskSources().stream()\n-                        .flatMap(taskSource -> taskSource.getSplits().stream())\n-                        .collect(toImmutableList());\n+        if (partitioning.equals(SINGLE_DISTRIBUTION) || partitioning.equals(FIXED_HASH_DISTRIBUTION) || partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            checkArgument(\n+                    fragment.getTableScanSchedulingOrder().isEmpty(),\n+                    \"Fragment with is not expected to have table scans. fragmentId: %s, fragment partitioning %s\",\n+                    fragment.getId(),\n+                    fragment.getPartitioning());\n+\n+            for (RemoteSourceNode remoteSource : fragment.getRemoteSourceNodes()) {\n+                if (remoteSource.isEnsureSourceOrdering() || remoteSource.getOrderingScheme().isPresent()) {\n+                    throw new PrestoException(NOT_SUPPORTED, format(\n+                            \"Order sensitive exchange is not supported by Presto on Spark. fragmentId: %s, sourceFragmentIds: %s\",\n+                            fragment.getId(),\n+                            remoteSource.getSourceFragmentIds()));\n+                }\n+            }\n \n-                // get scheduled splits by task\n-                List<List<ScheduledSplit>> assignedSplits = assignSplitsToTasks(scheduledSplits, initialSparkPartitionCount);\n+            Partitioner inputPartitioner = createPartitioner(\n+                    partitioning,\n+                    // TODO: consider using getMaxTasksPerStage\n+                    hashPartitionCount);\n \n-                List<SerializedPrestoSparkTaskDescriptor> serializedRequests = assignedSplits.stream()\n-                        .map(splits -> createTaskDescriptor(fragment, splits))\n-                        .map(sparkTaskDescriptorJsonCodec::toJsonBytes)\n-                        .map(SerializedPrestoSparkTaskDescriptor::new)\n-                        .collect(toImmutableList());\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> partitionedInputs = rddInputs.entrySet().stream()\n+                    .collect(toImmutableMap(Map.Entry::getKey, entry -> entry.getValue().partitionBy(inputPartitioner)));\n \n-                return sparkContext.parallelize(serializedRequests, initialSparkPartitionCount)\n-                        .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, taskStatsCollector));\n-            }\n+            return createIntermediateRdd(\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo,\n+                    partitionedInputs);\n+        }\n+        else if (partitioning.equals(SOURCE_DISTRIBUTION)) {\n+            checkArgument(rddInputs.isEmpty(), \"rddInputs is expected to be empty for SOURCE_DISTRIBUTION fragment: %s\", fragment.getId());\n+            return createSourceRdd(\n+                    sparkContext,\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s, fragmentId: %s\", partitioning, fragment.getId()));\n+        }\n+    }\n \n-            List<PrestoSparkSubPlan> children = subPlan.getChildren();\n-            checkArgument(\n-                    remoteSources.size() == children.size(),\n-                    \"number of remote sources doesn't match the number of child stages: %s != %s\",\n-                    remoteSources.size(),\n-                    children.size());\n-\n-            if (children.size() == 1) {\n-                // Single remote source\n-                PrestoSparkSubPlan childSubPlan = getOnlyElement(children);\n-                JavaPairRDD<Integer, PrestoSparkRow> childRdd = createRdd(childSubPlan);\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-\n-                if (partitioning.equals(COORDINATOR_DISTRIBUTION)) {\n-                    // coordinator side work will be handled after JavaPairRDD#collect() call in PrestoSparkExecution\n-                    return childRdd;\n-                }\n+    private static Partitioner createPartitioner(PartitioningHandle partitioning, int partitionCount)\n+    {\n+        if (partitioning.equals(SINGLE_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(1);\n+        }\n+        if (partitioning.equals(FIXED_HASH_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(partitionCount);\n+        }\n+        if (partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"FIXED_ARBITRARY_DISTRIBUTION partitioning is not yet supported\");\n+        }\n+        throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s\", partitioning));\n+    }\n \n-                PlanFragment childFragment = childSubPlan.getFragment();\n-                RemoteSourceNode remoteSource = getOnlyElement(remoteSources);\n-                List<PlanFragmentId> sourceFragmentIds = remoteSource.getSourceFragmentIds();\n-                checkArgument(sourceFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(childFragment.getId().equals(getOnlyElement(sourceFragmentIds)));\n-\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                if (partitioning.equals(FIXED_HASH_DISTRIBUTION) ||\n-                        // when single distribution - there will be a single partition 0\n-                        partitioning.equals(SINGLE_DISTRIBUTION)) {\n-                    String planNodeId = remoteSource.getId().toString();\n-                    return childRdd\n-                            .partitionBy(partitioning.equals(FIXED_HASH_DISTRIBUTION) ? new IntegerIdentityPartitioner(hashPartitionCount) : new IntegerIdentityPartitioner(1))\n-                            .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, planNodeId, taskStatsCollector));\n-                }\n-                else {\n-                    // TODO: support (or do check state over) the following fragment partitioning:\n-                    //  - SOURCE_DISTRIBUTION\n-                    //  - FIXED_PASSTHROUGH_DISTRIBUTION\n-                    //  - ARBITRARY_DISTRIBUTION\n-                    //  - SCALED_WRITER_DISTRIBUTION\n-                    //  - FIXED_BROADCAST_DISTRIBUTION\n-                    //  - FIXED_ARBITRARY_DISTRIBUTION\n-                    throw new IllegalArgumentException(\"Unsupported fragment partitioning: \" + partitioning);\n-                }\n-            }\n-            else if (children.size() == 2) {\n-                // TODO: support N way join\n-                PrestoSparkSubPlan leftSubPlan = children.get(0);\n-                PrestoSparkSubPlan rightSubPlan = children.get(1);\n-\n-                RemoteSourceNode leftRemoteSource = remoteSources.get(0);\n-                RemoteSourceNode rightRemoteSource = remoteSources.get(1);\n-\n-                // We need String representation since PlanNodeId is not serializable...\n-                String leftRemoteSourcePlanId = leftRemoteSource.getId().toString();\n-                String rightRemoteSourcePlanId = rightRemoteSource.getId().toString();\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> leftChildRdd = createRdd(leftSubPlan);\n-                JavaPairRDD<Integer, PrestoSparkRow> rightChildRdd = createRdd(rightSubPlan);\n-\n-                PlanFragment leftFragment = leftSubPlan.getFragment();\n-                PlanFragment rightFragment = rightSubPlan.getFragment();\n-\n-                List<PlanFragmentId> leftFragmentIds = leftRemoteSource.getSourceFragmentIds();\n-                checkArgument(leftFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(leftFragment.getId().equals(getOnlyElement(leftFragmentIds)));\n-                List<PlanFragmentId> rightFragmentIds = rightRemoteSource.getSourceFragmentIds();\n-                checkArgument(rightFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(rightFragment.getId().equals(getOnlyElement(rightFragmentIds)));\n-\n-                // This fragment only contains remote source, thus there is no splits\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-                checkArgument(partitioning.equals(FIXED_HASH_DISTRIBUTION));\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledLeftChildRdd = leftChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledRightChildRdd = rightChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                return JavaPairRDD.fromJavaRDD(\n-                        shuffledLeftChildRdd.zipPartitions(\n-                                shuffledRightChildRdd,\n-                                createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, leftRemoteSourcePlanId, rightRemoteSourcePlanId, taskStatsCollector)));\n-            }\n-            else {\n-                throw new UnsupportedOperationException();\n-            }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createIntermediateRdd(\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs)\n+    {\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        verify(tableScans.isEmpty(), \"no table scans is expected\");\n+\n+        Set<PlanFragmentId> expectedInputs = fragment.getRemoteSourceNodes().stream()\n+                .map(RemoteSourceNode::getSourceFragmentIds)\n+                .flatMap(List::stream)\n+                .collect(toImmutableSet());\n+\n+        Set<PlanFragmentId> missingInputs = difference(expectedInputs, rddInputs.keySet());\n+        Set<PlanFragmentId> extraInputs = difference(rddInputs.keySet(), expectedInputs);\n+        checkArgument(\n+                missingInputs.isEmpty() && extraInputs.isEmpty(),\n+                \"rddInputs mismatch discovered. expected: %s, actual: %s\",\n+                expectedInputs,\n+                rddInputs.keySet());\n+\n+        PrestoSparkTaskDescriptor taskDescriptor = createIntermediateTaskDescriptor(session, tableWriteInfo, fragment);\n+        SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(taskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n+\n+        if (rddInputs.size() == 1) {\n+            RemoteSourceNode remoteSourceNode = getOnlyElement(fragment.getRemoteSourceNodes());\n+            PairFlatMapFunction<Iterator<Tuple2<Integer, PrestoSparkRow>>, Integer, PrestoSparkRow> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            remoteSourceNode.getId().toString(),\n+                            taskStatsCollector);\n+            return getOnlyElement(rddInputs.values())\n+                    .mapPartitionsToPair(taskProcessor);\n+        }\n+        else if (rddInputs.size() == 2) {\n+            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n+            checkArgument(remoteSources.size() == 2, \"two remote sources are expected, got: %s\", remoteSources.size());\n+            RemoteSourceNode firstRemoteSource = remoteSources.get(0);\n+            RemoteSourceNode secondRemoteSource = remoteSources.get(1);\n+            JavaPairRDD<Integer, PrestoSparkRow> firstRdd = rddInputs.get(firstRemoteSource.getSourceFragmentIds().get(0));\n+            JavaPairRDD<Integer, PrestoSparkRow> secondRdd = rddInputs.get(secondRemoteSource.getSourceFragmentIds().get(0));\n+            FlatMapFunction2<Iterator<Tuple2<Integer, PrestoSparkRow>>, Iterator<Tuple2<Integer, PrestoSparkRow>>, Tuple2<Integer, PrestoSparkRow>> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            firstRemoteSource.getId().toString(),\n+                            secondRemoteSource.getId().toString(),\n+                            taskStatsCollector);\n+            return JavaPairRDD.fromJavaRDD(\n+                    firstRdd.zipPartitions(\n+                            secondRdd,\n+                            taskProcessor));\n         }\n \n-        private static List<List<ScheduledSplit>> assignSplitsToTasks(List<ScheduledSplit> scheduledSplits, int numTasks)\n-        {\n-            List<List<ScheduledSplit>> assignedSplits = new ArrayList<>();\n-            for (int i = 0; i < numTasks; i++) {\n-                assignedSplits.add(new ArrayList<>());\n-            }\n+        throw new IllegalArgumentException(format(\"unsupported number of inputs: %s\", rddInputs.size()));\n+    }\n \n-            for (ScheduledSplit split : scheduledSplits) {\n-                int taskId = Objects.hash(split.getPlanNodeId(), split.getSequenceId()) % numTasks;\n-                if (taskId < 0) {\n-                    taskId += numTasks;\n-                }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createSourceRdd(\n+            JavaSparkContext sparkContext,\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n+    {\n+        // TODO: Possible in case of a broadcast join\n+        checkArgument(fragment.getRemoteSourceNodes().isEmpty(), \"source task with remote sources is not supported\");\n+\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        checkArgument(\n+                tableScans.size() == 1,\n+                \"exactly one table scan is expected in SOURCE_DISTRIBUTION fragment. fragmentId: %s, actual number of table scans: %s\",\n+                fragment.getId(),\n+                tableScans.size());\n+        verify(tableScans.size() == fragment.getTableScanSchedulingOrder().size());\n+\n+        TableScanNode tableScan = tableScans.get(0);\n+\n+        List<ScheduledSplit> splits = getSplits(session, tableScan);\n+        shuffle(splits);\n+        int initialPartitionCount = getSparkInitialPartitionCount(session);\n+        int numTasks = Math.min(splits.size(), initialPartitionCount);\n+        if (numTasks == 0) {\n+            return JavaPairRDD.fromJavaRDD(sparkContext.emptyRDD());\n+        }\n \n-                assignedSplits.get(taskId).add(split);\n-            }\n+        List<List<ScheduledSplit>> assignedSplits = assignSplitsToTasks(splits, numTasks);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4bd6d4836e14974b9247082f649bc5bad82938"}, "originalPosition": 461}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjc4NzM4Nw==", "bodyText": "As a TODO, I think someday we want to have dedicated class for assignedSplits; just use a Map<Integer, List<Split>> and remove the map entry would also be better than set some element in list as null XDDD.", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r422787387", "createdAt": "2020-05-11T05:23:20Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -15,283 +15,367 @@\n \n import com.facebook.airlift.json.JsonCodec;\n import com.facebook.presto.Session;\n+import com.facebook.presto.execution.Lifespan;\n import com.facebook.presto.execution.ScheduledSplit;\n import com.facebook.presto.execution.TaskSource;\n import com.facebook.presto.execution.scheduler.TableWriteInfo;\n+import com.facebook.presto.metadata.Metadata;\n+import com.facebook.presto.metadata.Split;\n import com.facebook.presto.spark.PrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.IntegerIdentityPartitioner;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n import com.facebook.presto.spark.classloader_interface.PrestoSparkTaskExecutorFactoryProvider;\n import com.facebook.presto.spark.classloader_interface.SerializedPrestoSparkTaskDescriptor;\n import com.facebook.presto.spark.classloader_interface.SerializedTaskStats;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.split.SplitManager;\n+import com.facebook.presto.split.SplitSource;\n import com.facebook.presto.sql.planner.PartitioningHandle;\n import com.facebook.presto.sql.planner.PlanFragment;\n+import com.facebook.presto.sql.planner.SystemPartitioningHandle;\n import com.facebook.presto.sql.planner.plan.PlanFragmentId;\n import com.facebook.presto.sql.planner.plan.RemoteSourceNode;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableSet;\n+import org.apache.spark.Partitioner;\n import org.apache.spark.api.java.JavaPairRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.api.java.function.FlatMapFunction2;\n+import org.apache.spark.api.java.function.PairFlatMapFunction;\n import org.apache.spark.util.CollectionAccumulator;\n+import scala.Tuple2;\n \n import javax.inject.Inject;\n \n import java.util.ArrayList;\n+import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n import java.util.Optional;\n import java.util.Set;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n+import static com.facebook.airlift.concurrent.MoreFutures.getFutureValue;\n import static com.facebook.presto.SystemSessionProperties.getHashPartitionCount;\n import static com.facebook.presto.spark.PrestoSparkSessionProperties.getSparkInitialPartitionCount;\n import static com.facebook.presto.spark.classloader_interface.TaskProcessors.createTaskProcessor;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static com.facebook.presto.spi.connector.ConnectorSplitManager.SplitSchedulingStrategy.UNGROUPED_SCHEDULING;\n+import static com.facebook.presto.spi.connector.NotPartitionedPartitionHandle.NOT_PARTITIONED;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.ARBITRARY_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.COORDINATOR_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_ARBITRARY_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_BROADCAST_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_HASH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.FIXED_PASSTHROUGH_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SCALED_WRITER_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SINGLE_DISTRIBUTION;\n import static com.facebook.presto.sql.planner.SystemPartitioningHandle.SOURCE_DISTRIBUTION;\n+import static com.facebook.presto.sql.planner.optimizations.PlanNodeSearcher.searchFrom;\n import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Verify.verify;\n import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n import static com.google.common.collect.Iterables.getOnlyElement;\n+import static com.google.common.collect.Sets.difference;\n+import static java.lang.String.format;\n+import static java.util.Collections.shuffle;\n import static java.util.Objects.requireNonNull;\n import static java.util.function.Function.identity;\n import static java.util.stream.Collectors.mapping;\n import static java.util.stream.Collectors.toSet;\n \n public class PrestoSparkRddFactory\n {\n-    private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec;\n+    private final SplitManager splitManager;\n+    private final Metadata metadata;\n+    private final JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec;\n \n     @Inject\n-    public PrestoSparkRddFactory(JsonCodec<PrestoSparkTaskDescriptor> sparkTaskRequestJsonCodec)\n+    public PrestoSparkRddFactory(SplitManager splitManager, Metadata metadata, JsonCodec<PrestoSparkTaskDescriptor> taskDescriptorJsonCodec)\n     {\n-        this.sparkTaskRequestJsonCodec = requireNonNull(sparkTaskRequestJsonCodec, \"sparkTaskRequestJsonCodec is null\");\n+        this.splitManager = requireNonNull(splitManager, \"splitManager is null\");\n+        this.metadata = requireNonNull(metadata, \"metadata is null\");\n+        this.taskDescriptorJsonCodec = requireNonNull(taskDescriptorJsonCodec, \"taskDescriptorJsonCodec is null\");\n     }\n \n     public JavaPairRDD<Integer, PrestoSparkRow> createSparkRdd(\n             JavaSparkContext sparkContext,\n             Session session,\n-            PrestoSparkPlan prestoSparkPlan,\n-            PrestoSparkTaskExecutorFactoryProvider taskExecutorFactoryProvider,\n-            CollectionAccumulator<SerializedTaskStats> taskStatsCollector)\n+            PlanFragment fragment,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n     {\n-        RddFactory rddFactory = new RddFactory(\n-                session,\n-                sparkTaskRequestJsonCodec,\n-                sparkContext,\n-                taskExecutorFactoryProvider,\n-                getSparkInitialPartitionCount(session),\n-                getHashPartitionCount(session),\n-                taskStatsCollector,\n-                prestoSparkPlan.getTableWriteInfo());\n-        return rddFactory.createRdd(prestoSparkPlan.getPlan());\n-    }\n+        checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n \n-    private static class RddFactory\n-    {\n-        private final Session session;\n-        private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec;\n-        private final JavaSparkContext sparkContext;\n-        private final PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider;\n-        private final int initialSparkPartitionCount;\n-        private final int hashPartitionCount;\n-        private final CollectionAccumulator<SerializedTaskStats> taskStatsCollector;\n-        private final TableWriteInfo tableWriteInfo;\n-\n-        private RddFactory(\n-                Session session,\n-                JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec,\n-                JavaSparkContext sparkContext,\n-                PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n-                int initialSparkPartitionCount,\n-                int hashPartitionCount,\n-                CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n-                TableWriteInfo tableWriteInfo)\n-        {\n-            this.session = requireNonNull(session, \"session is null\");\n-            this.sparkTaskDescriptorJsonCodec = requireNonNull(sparkTaskDescriptorJsonCodec, \"sparkTaskDescriptorJsonCodec is null\");\n-            this.sparkContext = requireNonNull(sparkContext, \"sparkContext is null\");\n-            this.executorFactoryProvider = requireNonNull(executorFactoryProvider, \"executorFactoryProvider is null\");\n-            this.initialSparkPartitionCount = initialSparkPartitionCount;\n-            this.hashPartitionCount = hashPartitionCount;\n-            this.taskStatsCollector = requireNonNull(taskStatsCollector, \"taskStatsCollector is null\");\n-            this.tableWriteInfo = requireNonNull(tableWriteInfo, \"tableWriteInfo is null\");\n+        PartitioningHandle partitioning = fragment.getPartitioning();\n+\n+        if (!(partitioning.getConnectorHandle() instanceof SystemPartitioningHandle)) {\n+            // TODO: add support for bucketed table\n+            throw new PrestoException(NOT_SUPPORTED, \"Partitioned (bucketed) tables are not yet supported by Presto on Spark\");\n         }\n \n-        public JavaPairRDD<Integer, PrestoSparkRow> createRdd(PrestoSparkSubPlan subPlan)\n-        {\n-            PlanFragment fragment;\n-            // TODO: fragment adaption should be done prior to RDD creation\n-            if (subPlan.getFragment().getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n-                fragment = subPlan.getFragment().withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n-            }\n-            else {\n-                fragment = subPlan.getFragment();\n-            }\n+        if (partitioning.equals(SCALED_WRITER_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"Automatic writers scaling is not supported by Presto on Spark\");\n+        }\n \n-            checkArgument(!fragment.getStageExecutionDescriptor().isStageGroupedExecution(), \"unexpected grouped execution fragment: %s\", fragment.getId());\n+        checkArgument(!partitioning.equals(COORDINATOR_DISTRIBUTION), \"COORDINATOR_DISTRIBUTION fragment must be run on the driver\");\n+        checkArgument(!partitioning.equals(FIXED_BROADCAST_DISTRIBUTION), \"FIXED_BROADCAST_DISTRIBUTION can only be set as an output partitioning scheme, and not as a fragment distribution\");\n+        checkArgument(!partitioning.equals(FIXED_PASSTHROUGH_DISTRIBUTION), \"FIXED_PASSTHROUGH_DISTRIBUTION can only be set as local exchange partitioning\");\n \n-            // scans\n-            List<PlanNodeId> tableScans = fragment.getTableScanSchedulingOrder();\n+        // TODO: ARBITRARY_DISTRIBUTION is something very weird.\n+        // TODO: It doesn't have partitioning function, and it is never set as a fragment partitioning.\n+        // TODO: We should consider removing ARBITRARY_DISTRIBUTION.\n+        checkArgument(!partitioning.equals(ARBITRARY_DISTRIBUTION), \"ARBITRARY_DISTRIBUTION is not expected to be set as a fragment distribution\");\n \n-            // source stages\n-            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n-            checkArgument(tableScans.isEmpty() || remoteSources.isEmpty(), \"stages that have both, remote sources and table scans, are not supported\");\n+        int hashPartitionCount = getHashPartitionCount(session);\n \n-            if (!tableScans.isEmpty()) {\n-                checkArgument(fragment.getPartitioning().equals(SOURCE_DISTRIBUTION), \"unexpected table scan partitioning: %s\", fragment.getPartitioning());\n+        // configure number of output partitions\n+        if (fragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_HASH_DISTRIBUTION)) {\n+            fragment = fragment.withBucketToPartition(Optional.of(IntStream.range(0, hashPartitionCount).toArray()));\n+        }\n \n-                // get all scheduled splits\n-                List<ScheduledSplit> scheduledSplits = subPlan.getTaskSources().stream()\n-                        .flatMap(taskSource -> taskSource.getSplits().stream())\n-                        .collect(toImmutableList());\n+        if (partitioning.equals(SINGLE_DISTRIBUTION) || partitioning.equals(FIXED_HASH_DISTRIBUTION) || partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            checkArgument(\n+                    fragment.getTableScanSchedulingOrder().isEmpty(),\n+                    \"Fragment with is not expected to have table scans. fragmentId: %s, fragment partitioning %s\",\n+                    fragment.getId(),\n+                    fragment.getPartitioning());\n+\n+            for (RemoteSourceNode remoteSource : fragment.getRemoteSourceNodes()) {\n+                if (remoteSource.isEnsureSourceOrdering() || remoteSource.getOrderingScheme().isPresent()) {\n+                    throw new PrestoException(NOT_SUPPORTED, format(\n+                            \"Order sensitive exchange is not supported by Presto on Spark. fragmentId: %s, sourceFragmentIds: %s\",\n+                            fragment.getId(),\n+                            remoteSource.getSourceFragmentIds()));\n+                }\n+            }\n \n-                // get scheduled splits by task\n-                List<List<ScheduledSplit>> assignedSplits = assignSplitsToTasks(scheduledSplits, initialSparkPartitionCount);\n+            Partitioner inputPartitioner = createPartitioner(\n+                    partitioning,\n+                    // TODO: consider using getMaxTasksPerStage\n+                    hashPartitionCount);\n \n-                List<SerializedPrestoSparkTaskDescriptor> serializedRequests = assignedSplits.stream()\n-                        .map(splits -> createTaskDescriptor(fragment, splits))\n-                        .map(sparkTaskDescriptorJsonCodec::toJsonBytes)\n-                        .map(SerializedPrestoSparkTaskDescriptor::new)\n-                        .collect(toImmutableList());\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> partitionedInputs = rddInputs.entrySet().stream()\n+                    .collect(toImmutableMap(Map.Entry::getKey, entry -> entry.getValue().partitionBy(inputPartitioner)));\n \n-                return sparkContext.parallelize(serializedRequests, initialSparkPartitionCount)\n-                        .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, taskStatsCollector));\n-            }\n+            return createIntermediateRdd(\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo,\n+                    partitionedInputs);\n+        }\n+        else if (partitioning.equals(SOURCE_DISTRIBUTION)) {\n+            checkArgument(rddInputs.isEmpty(), \"rddInputs is expected to be empty for SOURCE_DISTRIBUTION fragment: %s\", fragment.getId());\n+            return createSourceRdd(\n+                    sparkContext,\n+                    session,\n+                    fragment,\n+                    executorFactoryProvider,\n+                    taskStatsCollector,\n+                    tableWriteInfo);\n+        }\n+        else {\n+            throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s, fragmentId: %s\", partitioning, fragment.getId()));\n+        }\n+    }\n \n-            List<PrestoSparkSubPlan> children = subPlan.getChildren();\n-            checkArgument(\n-                    remoteSources.size() == children.size(),\n-                    \"number of remote sources doesn't match the number of child stages: %s != %s\",\n-                    remoteSources.size(),\n-                    children.size());\n-\n-            if (children.size() == 1) {\n-                // Single remote source\n-                PrestoSparkSubPlan childSubPlan = getOnlyElement(children);\n-                JavaPairRDD<Integer, PrestoSparkRow> childRdd = createRdd(childSubPlan);\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-\n-                if (partitioning.equals(COORDINATOR_DISTRIBUTION)) {\n-                    // coordinator side work will be handled after JavaPairRDD#collect() call in PrestoSparkExecution\n-                    return childRdd;\n-                }\n+    private static Partitioner createPartitioner(PartitioningHandle partitioning, int partitionCount)\n+    {\n+        if (partitioning.equals(SINGLE_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(1);\n+        }\n+        if (partitioning.equals(FIXED_HASH_DISTRIBUTION)) {\n+            return new IntegerIdentityPartitioner(partitionCount);\n+        }\n+        if (partitioning.equals(FIXED_ARBITRARY_DISTRIBUTION)) {\n+            throw new PrestoException(NOT_SUPPORTED, \"FIXED_ARBITRARY_DISTRIBUTION partitioning is not yet supported\");\n+        }\n+        throw new IllegalArgumentException(format(\"Unexpected fragment partitioning %s\", partitioning));\n+    }\n \n-                PlanFragment childFragment = childSubPlan.getFragment();\n-                RemoteSourceNode remoteSource = getOnlyElement(remoteSources);\n-                List<PlanFragmentId> sourceFragmentIds = remoteSource.getSourceFragmentIds();\n-                checkArgument(sourceFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(childFragment.getId().equals(getOnlyElement(sourceFragmentIds)));\n-\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                if (partitioning.equals(FIXED_HASH_DISTRIBUTION) ||\n-                        // when single distribution - there will be a single partition 0\n-                        partitioning.equals(SINGLE_DISTRIBUTION)) {\n-                    String planNodeId = remoteSource.getId().toString();\n-                    return childRdd\n-                            .partitionBy(partitioning.equals(FIXED_HASH_DISTRIBUTION) ? new IntegerIdentityPartitioner(hashPartitionCount) : new IntegerIdentityPartitioner(1))\n-                            .mapPartitionsToPair(createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, planNodeId, taskStatsCollector));\n-                }\n-                else {\n-                    // TODO: support (or do check state over) the following fragment partitioning:\n-                    //  - SOURCE_DISTRIBUTION\n-                    //  - FIXED_PASSTHROUGH_DISTRIBUTION\n-                    //  - ARBITRARY_DISTRIBUTION\n-                    //  - SCALED_WRITER_DISTRIBUTION\n-                    //  - FIXED_BROADCAST_DISTRIBUTION\n-                    //  - FIXED_ARBITRARY_DISTRIBUTION\n-                    throw new IllegalArgumentException(\"Unsupported fragment partitioning: \" + partitioning);\n-                }\n-            }\n-            else if (children.size() == 2) {\n-                // TODO: support N way join\n-                PrestoSparkSubPlan leftSubPlan = children.get(0);\n-                PrestoSparkSubPlan rightSubPlan = children.get(1);\n-\n-                RemoteSourceNode leftRemoteSource = remoteSources.get(0);\n-                RemoteSourceNode rightRemoteSource = remoteSources.get(1);\n-\n-                // We need String representation since PlanNodeId is not serializable...\n-                String leftRemoteSourcePlanId = leftRemoteSource.getId().toString();\n-                String rightRemoteSourcePlanId = rightRemoteSource.getId().toString();\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> leftChildRdd = createRdd(leftSubPlan);\n-                JavaPairRDD<Integer, PrestoSparkRow> rightChildRdd = createRdd(rightSubPlan);\n-\n-                PlanFragment leftFragment = leftSubPlan.getFragment();\n-                PlanFragment rightFragment = rightSubPlan.getFragment();\n-\n-                List<PlanFragmentId> leftFragmentIds = leftRemoteSource.getSourceFragmentIds();\n-                checkArgument(leftFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(leftFragment.getId().equals(getOnlyElement(leftFragmentIds)));\n-                List<PlanFragmentId> rightFragmentIds = rightRemoteSource.getSourceFragmentIds();\n-                checkArgument(rightFragmentIds.size() == 1, \"expected to have exactly only a single source fragment\");\n-                checkArgument(rightFragment.getId().equals(getOnlyElement(rightFragmentIds)));\n-\n-                // This fragment only contains remote source, thus there is no splits\n-                PrestoSparkTaskDescriptor taskDescriptor = createTaskDescriptor(fragment, ImmutableList.of());\n-                SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(sparkTaskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n-\n-                PartitioningHandle partitioning = fragment.getPartitioning();\n-                checkArgument(partitioning.equals(FIXED_HASH_DISTRIBUTION));\n-\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledLeftChildRdd = leftChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                JavaPairRDD<Integer, PrestoSparkRow> shuffledRightChildRdd = rightChildRdd.partitionBy(new IntegerIdentityPartitioner(hashPartitionCount));\n-                return JavaPairRDD.fromJavaRDD(\n-                        shuffledLeftChildRdd.zipPartitions(\n-                                shuffledRightChildRdd,\n-                                createTaskProcessor(executorFactoryProvider, serializedTaskDescriptor, leftRemoteSourcePlanId, rightRemoteSourcePlanId, taskStatsCollector)));\n-            }\n-            else {\n-                throw new UnsupportedOperationException();\n-            }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createIntermediateRdd(\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo,\n+            Map<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> rddInputs)\n+    {\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        verify(tableScans.isEmpty(), \"no table scans is expected\");\n+\n+        Set<PlanFragmentId> expectedInputs = fragment.getRemoteSourceNodes().stream()\n+                .map(RemoteSourceNode::getSourceFragmentIds)\n+                .flatMap(List::stream)\n+                .collect(toImmutableSet());\n+\n+        Set<PlanFragmentId> missingInputs = difference(expectedInputs, rddInputs.keySet());\n+        Set<PlanFragmentId> extraInputs = difference(rddInputs.keySet(), expectedInputs);\n+        checkArgument(\n+                missingInputs.isEmpty() && extraInputs.isEmpty(),\n+                \"rddInputs mismatch discovered. expected: %s, actual: %s\",\n+                expectedInputs,\n+                rddInputs.keySet());\n+\n+        PrestoSparkTaskDescriptor taskDescriptor = createIntermediateTaskDescriptor(session, tableWriteInfo, fragment);\n+        SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(taskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n+\n+        if (rddInputs.size() == 1) {\n+            RemoteSourceNode remoteSourceNode = getOnlyElement(fragment.getRemoteSourceNodes());\n+            PairFlatMapFunction<Iterator<Tuple2<Integer, PrestoSparkRow>>, Integer, PrestoSparkRow> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            remoteSourceNode.getId().toString(),\n+                            taskStatsCollector);\n+            return getOnlyElement(rddInputs.values())\n+                    .mapPartitionsToPair(taskProcessor);\n+        }\n+        else if (rddInputs.size() == 2) {\n+            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n+            checkArgument(remoteSources.size() == 2, \"two remote sources are expected, got: %s\", remoteSources.size());\n+            RemoteSourceNode firstRemoteSource = remoteSources.get(0);\n+            RemoteSourceNode secondRemoteSource = remoteSources.get(1);\n+            JavaPairRDD<Integer, PrestoSparkRow> firstRdd = rddInputs.get(firstRemoteSource.getSourceFragmentIds().get(0));\n+            JavaPairRDD<Integer, PrestoSparkRow> secondRdd = rddInputs.get(secondRemoteSource.getSourceFragmentIds().get(0));\n+            FlatMapFunction2<Iterator<Tuple2<Integer, PrestoSparkRow>>, Iterator<Tuple2<Integer, PrestoSparkRow>>, Tuple2<Integer, PrestoSparkRow>> taskProcessor =\n+                    createTaskProcessor(\n+                            executorFactoryProvider,\n+                            serializedTaskDescriptor,\n+                            firstRemoteSource.getId().toString(),\n+                            secondRemoteSource.getId().toString(),\n+                            taskStatsCollector);\n+            return JavaPairRDD.fromJavaRDD(\n+                    firstRdd.zipPartitions(\n+                            secondRdd,\n+                            taskProcessor));\n         }\n \n-        private static List<List<ScheduledSplit>> assignSplitsToTasks(List<ScheduledSplit> scheduledSplits, int numTasks)\n-        {\n-            List<List<ScheduledSplit>> assignedSplits = new ArrayList<>();\n-            for (int i = 0; i < numTasks; i++) {\n-                assignedSplits.add(new ArrayList<>());\n-            }\n+        throw new IllegalArgumentException(format(\"unsupported number of inputs: %s\", rddInputs.size()));\n+    }\n \n-            for (ScheduledSplit split : scheduledSplits) {\n-                int taskId = Objects.hash(split.getPlanNodeId(), split.getSequenceId()) % numTasks;\n-                if (taskId < 0) {\n-                    taskId += numTasks;\n-                }\n+    private JavaPairRDD<Integer, PrestoSparkRow> createSourceRdd(\n+            JavaSparkContext sparkContext,\n+            Session session,\n+            PlanFragment fragment,\n+            PrestoSparkTaskExecutorFactoryProvider executorFactoryProvider,\n+            CollectionAccumulator<SerializedTaskStats> taskStatsCollector,\n+            TableWriteInfo tableWriteInfo)\n+    {\n+        // TODO: Possible in case of a broadcast join\n+        checkArgument(fragment.getRemoteSourceNodes().isEmpty(), \"source task with remote sources is not supported\");\n+\n+        List<TableScanNode> tableScans = findTableScanNodes(fragment.getRoot());\n+        checkArgument(\n+                tableScans.size() == 1,\n+                \"exactly one table scan is expected in SOURCE_DISTRIBUTION fragment. fragmentId: %s, actual number of table scans: %s\",\n+                fragment.getId(),\n+                tableScans.size());\n+        verify(tableScans.size() == fragment.getTableScanSchedulingOrder().size());\n+\n+        TableScanNode tableScan = tableScans.get(0);\n+\n+        List<ScheduledSplit> splits = getSplits(session, tableScan);\n+        shuffle(splits);\n+        int initialPartitionCount = getSparkInitialPartitionCount(session);\n+        int numTasks = Math.min(splits.size(), initialPartitionCount);\n+        if (numTasks == 0) {\n+            return JavaPairRDD.fromJavaRDD(sparkContext.emptyRDD());\n+        }\n \n-                assignedSplits.get(taskId).add(split);\n-            }\n+        List<List<ScheduledSplit>> assignedSplits = assignSplitsToTasks(splits, numTasks);\n \n-            return assignedSplits;\n+        // let the garbage collector reclaim the memory used by the decoded splits as soon as the task descriptor is encoded\n+        splits = null;\n+\n+        ImmutableList.Builder<SerializedPrestoSparkTaskDescriptor> serializedTaskDescriptors = ImmutableList.builder();\n+        for (int i = 0; i < assignedSplits.size(); i++) {\n+            List<ScheduledSplit> splitBatch = assignedSplits.get(i);\n+            PrestoSparkTaskDescriptor taskDescriptor = createSourceTaskDescriptor(session, tableWriteInfo, fragment, splitBatch);\n+            // TODO: consider more efficient serialization or apply compression to save precious memory on the Driver\n+            byte[] jsonSerializedTaskDescriptor = taskDescriptorJsonCodec.toJsonBytes(taskDescriptor);\n+            serializedTaskDescriptors.add(new SerializedPrestoSparkTaskDescriptor(jsonSerializedTaskDescriptor));\n+            // let the garbage collector reclaim the memory used by the decoded splits as soon as the task descriptor is encoded\n+            assignedSplits.set(i, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4bd6d4836e14974b9247082f649bc5bad82938"}, "originalPosition": 475}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bb5b91389336b0fefa3f4c47d052b3cef1e333cc", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/bb5b91389336b0fefa3f4c47d052b3cef1e333cc", "committedDate": "2020-05-07T13:50:58Z", "message": "Implement broadcast join"}, "afterCommit": {"oid": "f55ec4371182ef29762745dd9b24c92c8f74847f", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/f55ec4371182ef29762745dd9b24c92c8f74847f", "committedDate": "2020-05-11T16:08:06Z", "message": "Implement broadcast join"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5Njk5Njc1", "url": "https://github.com/prestodb/presto/pull/14495#pullrequestreview-409699675", "createdAt": "2020-05-12T05:01:56Z", "commit": {"oid": "0cbff4c1ff0d65074cfc811b07111c3c496cb016"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwNTowMTo1N1rOGT2JCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwNTowMTo1N1rOGT2JCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzQ2MzE3OQ==", "bodyText": "Looks like you are already preparing for multi-way join  \ud83d\ude03", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r423463179", "createdAt": "2020-05-12T05:01:57Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/planner/PrestoSparkRddFactory.java", "diffHunk": "@@ -228,33 +229,31 @@ private static Partitioner createPartitioner(PartitioningHandle partitioning, in\n         SerializedPrestoSparkTaskDescriptor serializedTaskDescriptor = new SerializedPrestoSparkTaskDescriptor(taskDescriptorJsonCodec.toJsonBytes(taskDescriptor));\n \n         if (rddInputs.size() == 1) {\n-            RemoteSourceNode remoteSourceNode = getOnlyElement(fragment.getRemoteSourceNodes());\n+            Entry<PlanFragmentId, JavaPairRDD<Integer, PrestoSparkRow>> input = getOnlyElement(rddInputs.entrySet());\n             PairFlatMapFunction<Iterator<Tuple2<Integer, PrestoSparkRow>>, Integer, PrestoSparkRow> taskProcessor =\n                     createTaskProcessor(\n                             executorFactoryProvider,\n                             serializedTaskDescriptor,\n-                            remoteSourceNode.getId().toString(),\n+                            input.getKey().toString(),\n                             taskStatsCollector);\n-            return getOnlyElement(rddInputs.values())\n+            return input.getValue()\n                     .mapPartitionsToPair(taskProcessor);\n         }\n-        else if (rddInputs.size() == 2) {\n-            List<RemoteSourceNode> remoteSources = fragment.getRemoteSourceNodes();\n-            checkArgument(remoteSources.size() == 2, \"two remote sources are expected, got: %s\", remoteSources.size());\n-            RemoteSourceNode firstRemoteSource = remoteSources.get(0);\n-            RemoteSourceNode secondRemoteSource = remoteSources.get(1);\n-            JavaPairRDD<Integer, PrestoSparkRow> firstRdd = rddInputs.get(firstRemoteSource.getSourceFragmentIds().get(0));\n-            JavaPairRDD<Integer, PrestoSparkRow> secondRdd = rddInputs.get(secondRemoteSource.getSourceFragmentIds().get(0));\n+        if (rddInputs.size() == 2) {\n+            List<PlanFragmentId> fragmentIds = ImmutableList.copyOf(rddInputs.keySet());\n+            List<JavaPairRDD<Integer, PrestoSparkRow>> rdds = fragmentIds.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0cbff4c1ff0d65074cfc811b07111c3c496cb016"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5NzAwOTc0", "url": "https://github.com/prestodb/presto/pull/14495#pullrequestreview-409700974", "createdAt": "2020-05-12T05:06:07Z", "commit": {"oid": "f55ec4371182ef29762745dd9b24c92c8f74847f"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwNTowNjowN1rOGT2NPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwNTowODoxNlrOGT2Phg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzQ2NDI1Mw==", "bodyText": "Because of the continue in line 248, shuffleRemoteSourceInputs and broadcastRemoteSourceInputs cannot both be non-empty right? -- Maybe check shuffleInputs and broadcastInput cannot both present earlier?", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r423464253", "createdAt": "2020-05-12T05:06:07Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java", "diffHunk": "@@ -228,14 +237,34 @@ public IPrestoSparkTaskExecutor create(\n         PrestoSparkRowBuffer rowBuffer = new PrestoSparkRowBuffer(memoryManager);\n \n         ImmutableMap.Builder<PlanNodeId, Iterator<PrestoSparkRow>> shuffleInputs = ImmutableMap.builder();\n+        ImmutableMap.Builder<PlanNodeId, Iterator<PrestoSparkSerializedPage>> broadcastInputs = ImmutableMap.builder();\n         for (RemoteSourceNode remoteSource : fragment.getRemoteSourceNodes()) {\n-            ImmutableList.Builder<Iterator<PrestoSparkRow>> remoteSourceInputs = ImmutableList.builder();\n+            List<Iterator<PrestoSparkRow>> shuffleRemoteSourceInputs = new ArrayList<>();\n+            List<Iterator<PrestoSparkSerializedPage>> broadcastRemoteSourceInputs = new ArrayList<>();\n             for (PlanFragmentId sourceFragmentId : remoteSource.getSourceFragmentIds()) {\n-                Iterator<Tuple2<Integer, PrestoSparkRow>> input = inputs.getShuffleInputs().get(sourceFragmentId.toString());\n-                checkArgument(input != null, \"input is missing for fragmentId: %s\", sourceFragmentId);\n-                remoteSourceInputs.add(Iterators.transform(input, tuple -> tuple._2));\n+                Iterator<Tuple2<Integer, PrestoSparkRow>> shuffleInput = inputs.getShuffleInputs().get(sourceFragmentId.toString());\n+                if (shuffleInput != null) {\n+                    shuffleRemoteSourceInputs.add(Iterators.transform(shuffleInput, tuple -> tuple._2));\n+                    continue;\n+                }\n+                Broadcast<List<PrestoSparkSerializedPage>> broadcastInput = inputs.getBroadcastInputs().get(sourceFragmentId.toString());\n+                if (broadcastInput != null) {\n+                    // TODO: Enable NullifyingIterator once migrated to one task per JVM model\n+                    // NullifyingIterator removes element from the list upon return\n+                    // This allows GC to gradually reclaim memory\n+                    // broadcastRemoteSourceInputs.add(getNullifyingIterator(broadcastInput.value()));\n+                    broadcastRemoteSourceInputs.add(broadcastInput.value().iterator());\n+                    continue;\n+                }\n+                throw new IllegalArgumentException(\"Input not found for sourceFragmentId: \" + sourceFragmentId);\n+            }\n+            verify(shuffleRemoteSourceInputs.isEmpty() || broadcastRemoteSourceInputs.isEmpty(), \"single remote source cannot accept both, broadcast and shuffle inputs\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f55ec4371182ef29762745dd9b24c92c8f74847f"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzQ2NDgzOA==", "bodyText": "nice encapsulation!", "url": "https://github.com/prestodb/presto/pull/14495#discussion_r423464838", "createdAt": "2020-05-12T05:08:16Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -431,4 +472,37 @@ private QueryInfo createQueryInfo(Optional<Throwable> failure)\n             return null;\n         }\n     }\n+\n+    private static class RddAndMore\n+    {\n+        private final JavaPairRDD<Integer, PrestoSparkRow> rdd;\n+        private final List<Broadcast<?>> broadcastDependencies;\n+\n+        private boolean collected;\n+\n+        private RddAndMore(JavaPairRDD<Integer, PrestoSparkRow> rdd, List<Broadcast<?>> broadcastDependencies)\n+        {\n+            this.rdd = requireNonNull(rdd, \"rdd is null\");\n+            this.broadcastDependencies = ImmutableList.copyOf(requireNonNull(broadcastDependencies, \"broadcastDependencies is null\"));\n+        }\n+\n+        public List<Tuple2<Integer, PrestoSparkRow>> collectAndDestroyDependencies()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f55ec4371182ef29762745dd9b24c92c8f74847f"}, "originalPosition": 215}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "19b88805b09642277ee7f059b6009d6402f28dda", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/19b88805b09642277ee7f059b6009d6402f28dda", "committedDate": "2020-05-12T09:39:02Z", "message": "Refactor PrestoSparkRddFactory\n\nThis is preparation for Broadcast join implementation\n\nBroadcast join is special, as the broadcasted table must be first collected on the driver,\nso it can be broadcasted with a Broadcast variable. This results in more than a single\njob per query. This commit prepares the codebase to support more than a single job\nper query.\n\n- PrestoSparkRddFactory now creates RDD only for a single fragment, and not for a\n  fragment tree. The dependent RDD have to be provided as a parameter. This is needed\n  to allow Broadcast sources to be provided.\n- SubPlan traversal is now being done in PrestoSparkQueryExecutionFactory. This allows\n  us to execute dependency broadcast jobs in the `execute()` method.\n- PrestoSparkSplitEnumerator is removed and PrestoSparkPlan is inlined. Splits are lazily\n  enumerated in the PrestoSparkRddFactory to avoid enumerating splits that are only necessary\n  for the current job being executed. That allows us to save precious memory for the broadcast\n  table."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86c5eaf32c152c1331a12685b729960fc4d220c3", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/86c5eaf32c152c1331a12685b729960fc4d220c3", "committedDate": "2020-05-12T09:39:02Z", "message": "Improve rollback handling in PrestoSparkQueryExecutionFactory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b0e0857158ab230d6e6968b911a832d22ba0c226", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/b0e0857158ab230d6e6968b911a832d22ba0c226", "committedDate": "2020-05-12T09:39:02Z", "message": "Refactor PrestoSparkRemoteSourceOperator\n\nExtract transformation code into an iterator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "acf49bde88e5e862dfdf85d78365f76d3c930c42", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/acf49bde88e5e862dfdf85d78365f76d3c930c42", "committedDate": "2020-05-12T09:39:02Z", "message": "Refactor PrestoSparkTaskInputs\n\nUse fragmentId as a key as a single remote source may have multiple\nfragments as its input"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b1c048653ab294165e043d506b78dd31b603a1d3", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/b1c048653ab294165e043d506b78dd31b603a1d3", "committedDate": "2020-05-12T09:39:02Z", "message": "Increase visibility of BlockUtil"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f30d610b4fade23ba0e94c67189c9e8aaa8f4ba", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/7f30d610b4fade23ba0e94c67189c9e8aaa8f4ba", "committedDate": "2020-05-12T09:39:02Z", "message": "Implement broadcast join"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f55ec4371182ef29762745dd9b24c92c8f74847f", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/f55ec4371182ef29762745dd9b24c92c8f74847f", "committedDate": "2020-05-11T16:08:06Z", "message": "Implement broadcast join"}, "afterCommit": {"oid": "7f30d610b4fade23ba0e94c67189c9e8aaa8f4ba", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/7f30d610b4fade23ba0e94c67189c9e8aaa8f4ba", "committedDate": "2020-05-12T09:39:02Z", "message": "Implement broadcast join"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1586, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}