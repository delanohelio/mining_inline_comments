{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk3MDk2MTcw", "number": 15262, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMDoxNTowNlrOEp79Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoyMjoyNlrOEp9o7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNDA5NDMxOnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/util/PrestoSparkUtils.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMDoxNTowNlrOHb6ZsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjo1ODoyNlrOHcl2Bw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAzMDQ0OQ==", "bodyText": "I really think we should have something like presto-compression to avoid code duplication =)", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499030449", "createdAt": "2020-10-02T20:15:06Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/util/PrestoSparkUtils.java", "diffHunk": "@@ -83,8 +89,75 @@ public static PagesSerde createPagesSerde(BlockEncodingManager blockEncodingMana\n     {\n         return new PagesSerde(\n                 blockEncodingManager,\n-                Optional.empty(),\n-                Optional.empty(),\n+                Optional.of(createPageCompressor()),\n+                Optional.of(createPageDecompressor()),\n                 Optional.empty());\n     }\n+\n+    private static PageCompressor createPageCompressor()\n+    {\n+        // based on ZstdJniCompressor", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8fadf5aa929a0fe70b966831dc9f13036cf2d9c"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc0MjIxNQ==", "bodyText": "Yeah. I was thinking about that. I was trying to extract a dependency before copying. But given the amount of code, and relatively simple logic I decided to simply copy it for now.", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499742215", "createdAt": "2020-10-05T16:58:26Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/util/PrestoSparkUtils.java", "diffHunk": "@@ -83,8 +89,75 @@ public static PagesSerde createPagesSerde(BlockEncodingManager blockEncodingMana\n     {\n         return new PagesSerde(\n                 blockEncodingManager,\n-                Optional.empty(),\n-                Optional.empty(),\n+                Optional.of(createPageCompressor()),\n+                Optional.of(createPageDecompressor()),\n                 Optional.empty());\n     }\n+\n+    private static PageCompressor createPageCompressor()\n+    {\n+        // based on ZstdJniCompressor", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAzMDQ0OQ=="}, "originalCommit": {"oid": "b8fadf5aa929a0fe70b966831dc9f13036cf2d9c"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNDM2OTAxOnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoyMTo1N1rOHb9B3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjo1Njo1NFrOHclymA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzUwMA==", "bodyText": "just double check: this is consistent with how Presto classic checks max broadcast size right?\nAlso I feel in theory we can do the check on driver ? (before broadcast the data)", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499073500", "createdAt": "2020-10-02T22:21:57Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -897,9 +900,29 @@ else if (executionException instanceof PrestoSparkExecutionException) {\n                 PlanFragment childFragment = child.getFragment();\n                 if (childFragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION)) {\n                     RddAndMore<PrestoSparkSerializedPage> childRdd = createRdd(child, PrestoSparkSerializedPage.class);\n+\n+                    // TODO: The driver might still OOM on a very large broadcast, think of how to prevent that from happening\n                     List<PrestoSparkSerializedPage> broadcastPages = childRdd.collectAndDestroyDependencies().stream()\n                             .map(Tuple2::_2)\n                             .collect(toList());\n+\n+                    int compressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(page -> page.getBytes().length)\n+                            .sum();\n+                    int uncompressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(PrestoSparkSerializedPage::getUncompressedSizeInBytes)\n+                            .sum();\n+                    DataSize maxBroadcastSize = getQueryMaxBroadcastMemory(session);\n+                    long maxBroadcastSizeInBytes = maxBroadcastSize.toBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc0MTMzNg==", "bodyText": "just double check: this is consistent with how Presto classic checks max broadcast size right?\n\nYeah. The only difference that Presto Classic enforces that limit on a consumer side. Here we enforce it on a driver before even starting the downstream stage that is supposed to consume the broadcasted table.", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499741336", "createdAt": "2020-10-05T16:56:54Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -897,9 +900,29 @@ else if (executionException instanceof PrestoSparkExecutionException) {\n                 PlanFragment childFragment = child.getFragment();\n                 if (childFragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION)) {\n                     RddAndMore<PrestoSparkSerializedPage> childRdd = createRdd(child, PrestoSparkSerializedPage.class);\n+\n+                    // TODO: The driver might still OOM on a very large broadcast, think of how to prevent that from happening\n                     List<PrestoSparkSerializedPage> broadcastPages = childRdd.collectAndDestroyDependencies().stream()\n                             .map(Tuple2::_2)\n                             .collect(toList());\n+\n+                    int compressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(page -> page.getBytes().length)\n+                            .sum();\n+                    int uncompressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(PrestoSparkSerializedPage::getUncompressedSizeInBytes)\n+                            .sum();\n+                    DataSize maxBroadcastSize = getQueryMaxBroadcastMemory(session);\n+                    long maxBroadcastSizeInBytes = maxBroadcastSize.toBytes();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzUwMA=="}, "originalCommit": {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNDM2OTczOnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoyMjoyNlrOHb9CTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNjo1NzoyM1rOHclzqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzYxMg==", "bodyText": "i assume you can do this check even before uncompressed the data?", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499073612", "createdAt": "2020-10-02T22:22:26Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -897,9 +900,29 @@ else if (executionException instanceof PrestoSparkExecutionException) {\n                 PlanFragment childFragment = child.getFragment();\n                 if (childFragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION)) {\n                     RddAndMore<PrestoSparkSerializedPage> childRdd = createRdd(child, PrestoSparkSerializedPage.class);\n+\n+                    // TODO: The driver might still OOM on a very large broadcast, think of how to prevent that from happening\n                     List<PrestoSparkSerializedPage> broadcastPages = childRdd.collectAndDestroyDependencies().stream()\n                             .map(Tuple2::_2)\n                             .collect(toList());\n+\n+                    int compressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(page -> page.getBytes().length)\n+                            .sum();\n+                    int uncompressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(PrestoSparkSerializedPage::getUncompressedSizeInBytes)\n+                            .sum();\n+                    DataSize maxBroadcastSize = getQueryMaxBroadcastMemory(session);\n+                    long maxBroadcastSizeInBytes = maxBroadcastSize.toBytes();\n+\n+                    if (compressedBroadcastSizeInBytes > maxBroadcastSizeInBytes) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc0MTYxMA==", "bodyText": "Yup. Luckily we have the exact size of the uncompressed data, so we can check both before even uncompressing.", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499741610", "createdAt": "2020-10-05T16:57:23Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -897,9 +900,29 @@ else if (executionException instanceof PrestoSparkExecutionException) {\n                 PlanFragment childFragment = child.getFragment();\n                 if (childFragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION)) {\n                     RddAndMore<PrestoSparkSerializedPage> childRdd = createRdd(child, PrestoSparkSerializedPage.class);\n+\n+                    // TODO: The driver might still OOM on a very large broadcast, think of how to prevent that from happening\n                     List<PrestoSparkSerializedPage> broadcastPages = childRdd.collectAndDestroyDependencies().stream()\n                             .map(Tuple2::_2)\n                             .collect(toList());\n+\n+                    int compressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(page -> page.getBytes().length)\n+                            .sum();\n+                    int uncompressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(PrestoSparkSerializedPage::getUncompressedSizeInBytes)\n+                            .sum();\n+                    DataSize maxBroadcastSize = getQueryMaxBroadcastMemory(session);\n+                    long maxBroadcastSizeInBytes = maxBroadcastSize.toBytes();\n+\n+                    if (compressedBroadcastSizeInBytes > maxBroadcastSizeInBytes) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzYxMg=="}, "originalCommit": {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b"}, "originalPosition": 36}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3473, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}