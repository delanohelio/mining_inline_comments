{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY5ODM3MDY4", "number": 14040, "title": "Move Hive filter pushdown logic out of PickTableLayout", "bodyText": "== NO RELEASE NOTE ==", "createdAt": "2020-02-01T01:51:08Z", "url": "https://github.com/prestodb/presto/pull/14040", "merged": true, "mergeCommit": {"oid": "b1c5015c19910808e599c49a54325556373f8016"}, "closed": true, "closedAt": "2020-03-05T08:48:08Z", "author": {"login": "sachdevs"}, "timelineItems": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb_77QkgFqTM1MTg2NDUwNg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcKc5dvABqjMwOTgzNzM2NDg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxODY0NTA2", "url": "https://github.com/prestodb/presto/pull/14040#pullrequestreview-351864506", "createdAt": "2020-02-01T04:20:55Z", "commit": {"oid": "d74e26c2e63460610484c75369ad925154f7397a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNDoyMDo1NVrOFkcTTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQwNDoyMDo1NVrOFkcTTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc1Njc1MA==", "bodyText": "this should be injected into HiveConnector. No need to open an interface.", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r373756750", "createdAt": "2020-02-01T04:20:55Z", "author": {"login": "highker"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -2593,6 +2593,11 @@ public void revokeTablePrivileges(ConnectorSession session, SchemaTableName sche\n         return toCompletableFuture(stagingFileCommitter.commitFiles(session, handle.getSchemaName(), handle.getTableName(), getPartitionUpdates(fragments)));\n     }\n \n+    public FunctionMetadataManager getFunctionMetadataManager()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d74e26c2e63460610484c75369ad925154f7397a"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d74e26c2e63460610484c75369ad925154f7397a", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/d74e26c2e63460610484c75369ad925154f7397a", "committedDate": "2020-02-01T01:49:41Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "d3049bc52bee892f804ee2edb95d7f31cc526f8a", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/d3049bc52bee892f804ee2edb95d7f31cc526f8a", "committedDate": "2020-02-03T18:34:33Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d3049bc52bee892f804ee2edb95d7f31cc526f8a", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/d3049bc52bee892f804ee2edb95d7f31cc526f8a", "committedDate": "2020-02-03T18:34:33Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "5c5de97bcbf70f260298abb74cbe6b7f44084edc", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/5c5de97bcbf70f260298abb74cbe6b7f44084edc", "committedDate": "2020-02-03T20:56:33Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5c5de97bcbf70f260298abb74cbe6b7f44084edc", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/5c5de97bcbf70f260298abb74cbe6b7f44084edc", "committedDate": "2020-02-03T20:56:33Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "6db4a0a05338e05cf74d12276af8ea812bfd06b2", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/6db4a0a05338e05cf74d12276af8ea812bfd06b2", "committedDate": "2020-02-04T01:30:36Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6db4a0a05338e05cf74d12276af8ea812bfd06b2", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/6db4a0a05338e05cf74d12276af8ea812bfd06b2", "committedDate": "2020-02-04T01:30:36Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "a6df3ed20b4ae1f2dd23f79ba9595a23d9607da7", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/a6df3ed20b4ae1f2dd23f79ba9595a23d9607da7", "committedDate": "2020-02-05T20:58:28Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a6df3ed20b4ae1f2dd23f79ba9595a23d9607da7", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/a6df3ed20b4ae1f2dd23f79ba9595a23d9607da7", "committedDate": "2020-02-05T20:58:28Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "cba93ba95fcb2dd47b4b9be2c5344f549b68d8da", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/cba93ba95fcb2dd47b4b9be2c5344f549b68d8da", "committedDate": "2020-02-05T21:43:44Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cba93ba95fcb2dd47b4b9be2c5344f549b68d8da", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/cba93ba95fcb2dd47b4b9be2c5344f549b68d8da", "committedDate": "2020-02-05T21:43:44Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "155a2a17645fc737d90477f444576a1cb8b44f81", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/155a2a17645fc737d90477f444576a1cb8b44f81", "committedDate": "2020-02-07T22:12:55Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "155a2a17645fc737d90477f444576a1cb8b44f81", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/155a2a17645fc737d90477f444576a1cb8b44f81", "committedDate": "2020-02-07T22:12:55Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "6ea7eca7b9e073c2fcb777601b191b2d0007eeb9", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/6ea7eca7b9e073c2fcb777601b191b2d0007eeb9", "committedDate": "2020-02-07T22:23:19Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6ea7eca7b9e073c2fcb777601b191b2d0007eeb9", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/6ea7eca7b9e073c2fcb777601b191b2d0007eeb9", "committedDate": "2020-02-07T22:23:19Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "7453811611d6a1364f2ec185556170654630ad8f", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/7453811611d6a1364f2ec185556170654630ad8f", "committedDate": "2020-02-08T00:02:00Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTg2OTE5", "url": "https://github.com/prestodb/presto/pull/14040#pullrequestreview-355586919", "createdAt": "2020-02-09T06:38:55Z", "commit": {"oid": "7453811611d6a1364f2ec185556170654630ad8f"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOVQwNjozODo1NlrOFnTj_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOVQwNjozOTo0NVrOFnTkFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTI5NA==", "bodyText": "We should combine all these visitors into one. No need to separate them apart.", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r376759294", "createdAt": "2020-02-09T06:38:56Z", "author": {"login": "highker"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java", "diffHunk": "@@ -0,0 +1,527 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorPushdownFilterResult;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveFilterPushdownLogicalOptimizer\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdownLogicalOptimizer(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        PlanNode newPlan = maxSubplan.accept(new FilterVisitor(session, idAllocator, transactionManager), null);\n+        return newPlan.accept(new TableScanVisitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdownLogicalOptimizer::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    private abstract class Visitor", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7453811611d6a1364f2ec185556170654630ad8f"}, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTMxNw==", "bodyText": "This doesn't seem right. It should be return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());. Otherwise, the visitor will stop exploring for such case.", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r376759317", "createdAt": "2020-02-09T06:39:45Z", "author": {"login": "highker"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java", "diffHunk": "@@ -0,0 +1,527 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorPushdownFilterResult;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveFilterPushdownLogicalOptimizer\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdownLogicalOptimizer(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        PlanNode newPlan = maxSubplan.accept(new FilterVisitor(session, idAllocator, transactionManager), null);\n+        return newPlan.accept(new TableScanVisitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdownLogicalOptimizer::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    private abstract class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        protected final ConnectorSession session;\n+        protected final PlanNodeIdAllocator idAllocator;\n+        protected final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+    }\n+\n+    private class FilterVisitor\n+            extends Visitor\n+    {\n+        FilterVisitor(ConnectorSession session, PlanNodeIdAllocator idAllocator, HiveTransactionManager transactionManager)\n+        {\n+            super(session, idAllocator, transactionManager);\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return filter;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7453811611d6a1364f2ec185556170654630ad8f"}, "originalPosition": 288}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7453811611d6a1364f2ec185556170654630ad8f", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/7453811611d6a1364f2ec185556170654630ad8f", "committedDate": "2020-02-08T00:02:00Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "78504d28d98fbf4946ae4a228364d7a5cc6daa08", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/78504d28d98fbf4946ae4a228364d7a5cc6daa08", "committedDate": "2020-02-10T18:54:04Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "78504d28d98fbf4946ae4a228364d7a5cc6daa08", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/78504d28d98fbf4946ae4a228364d7a5cc6daa08", "committedDate": "2020-02-10T18:54:04Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "committedDate": "2020-02-10T23:37:40Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU2MzQ0NzIx", "url": "https://github.com/prestodb/presto/pull/14040#pullrequestreview-356344721", "createdAt": "2020-02-10T23:42:20Z", "commit": {"oid": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQyMzo0MjoyMVrOFn5n7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQyMzo0MjozMlrOFn5oJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM4Mjg5Mw==", "bodyText": "This part of the test verification can no longer occur in this way as we cannot explicitly call metadata.pushdownFilter", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377382893", "createdAt": "2020-02-10T23:42:21Z", "author": {"login": "sachdevs"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -2052,15 +2050,15 @@ private void doTestBucketedTableEvolution(HiveStorageFormat storageFormat, Schem\n \n             NullableValue singleBucket = NullableValue.of(INTEGER, 6L);\n             ConnectorTableLayoutHandle layoutHandle;\n-            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n-\n-                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n-                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-            }\n-            else {\n-                layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n-            }\n+//            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+//                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n+//\n+//                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n+//                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+//            }\n+//            else {\n+            layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n+//            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM4Mjk1MA==", "bodyText": "ditto.", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377382950", "createdAt": "2020-02-10T23:42:32Z", "author": {"login": "sachdevs"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -2373,12 +2371,12 @@ public void testPartitionSchemaNonCanonical()\n \n     private static ConnectorTableLayout getTableLayout(ConnectorSession session, ConnectorMetadata metadata, ConnectorTableHandle tableHandle, Constraint<ColumnHandle> constraint)\n     {\n-        if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-            assertTrue(constraint.getSummary().isAll());\n-\n-            ConnectorPushdownFilterResult pushdownFilterResult = metadata.pushdownFilter(session, tableHandle, TRUE_CONSTANT, Optional.empty());\n-            return pushdownFilterResult.getLayout();\n-        }\n+//        if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+//            assertTrue(constraint.getSummary().isAll());\n+//\n+//            ConnectorPushdownFilterResult pushdownFilterResult = metadata.pushdownFilter(session, tableHandle, TRUE_CONSTANT, Optional.empty());\n+//            return pushdownFilterResult.getLayout();\n+//        }\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8"}, "originalPosition": 128}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "committedDate": "2020-02-10T23:37:40Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "committedDate": "2020-02-11T19:48:24Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU3NzAwNDU3", "url": "https://github.com/prestodb/presto/pull/14040#pullrequestreview-357700457", "createdAt": "2020-02-12T18:50:39Z", "commit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQxODo1MDo0MFrOFo6b5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQxOTowNzo0NlrOFo6_gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0NDc3Mg==", "bodyText": "not used", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378444772", "createdAt": "2020-02-12T18:50:40Z", "author": {"login": "highker"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "originalPosition": 268}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0NTI1NQ==", "bodyText": "nit node", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378445255", "createdAt": "2020-02-12T18:51:33Z", "author": {"login": "highker"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode ret = new TableScanNode(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "originalPosition": 332}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0OTY1OQ==", "bodyText": "static", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378449659", "createdAt": "2020-02-12T18:59:31Z", "author": {"login": "highker"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode ret = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), ret, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return ret;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), TRUE_CONSTANT, tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            return new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    pushdownFilterResult.getLayout().getPredicate(),\n+                    TupleDomain.all());\n+        }\n+    }\n+\n+    private static class ConstraintEvaluator\n+    {\n+        private final Map<String, ColumnHandle> assignments;\n+        private final RowExpressionService evaluator;\n+        private final ConnectorSession session;\n+        private final RowExpression expression;\n+        private final Set<ColumnHandle> arguments;\n+\n+        public ConstraintEvaluator(RowExpressionService evaluator, ConnectorSession session, Map<String, ColumnHandle> assignments, RowExpression expression)\n+        {\n+            this.assignments = assignments;\n+            this.evaluator = evaluator;\n+            this.session = session;\n+            this.expression = expression;\n+\n+            arguments = ImmutableSet.copyOf(extractAll(expression)).stream()\n+                    .map(VariableReferenceExpression::getName)\n+                    .map(assignments::get)\n+                    .collect(toImmutableSet());\n+        }\n+\n+        private boolean isCandidate(Map<ColumnHandle, NullableValue> bindings)\n+        {\n+            if (intersection(bindings.keySet(), arguments).isEmpty()) {\n+                return true;\n+            }\n+\n+            Function<VariableReferenceExpression, Object> variableResolver = variable -> {\n+                ColumnHandle column = assignments.get(variable.getName());\n+                checkArgument(column != null, \"Missing column assignment for %s\", variable);\n+\n+                if (!bindings.containsKey(column)) {\n+                    return variable;\n+                }\n+\n+                return bindings.get(column).getValue();\n+            };\n+\n+            // Skip pruning if evaluation fails in a recoverable way. Failing here can cause\n+            // spurious query failures for partitions that would otherwise be filtered out.\n+            Object optimized = null;\n+            try {\n+                optimized = evaluator.getExpressionOptimizer().optimize(expression, OPTIMIZED, session, variableResolver);\n+            }\n+            catch (PrestoException e) {\n+                propagateIfUnhandled(e);\n+            }\n+\n+            // If any conjuncts evaluate to FALSE or null, then the whole predicate will never be true and so the partition should be pruned\n+            return !Boolean.FALSE.equals(optimized) && optimized != null && (!(optimized instanceof ConstantExpression) || !((ConstantExpression) optimized).isNull());\n+        }\n+\n+        private static void propagateIfUnhandled(PrestoException e)\n+                throws PrestoException\n+        {\n+            int errorCode = e.getErrorCode().getCode();\n+            if (errorCode == DIVISION_BY_ZERO.toErrorCode().getCode()\n+                    || errorCode == INVALID_CAST_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == INVALID_FUNCTION_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == NUMERIC_VALUE_OUT_OF_RANGE.toErrorCode().getCode()) {\n+                return;\n+            }\n+\n+            throw e;\n+        }\n+    }\n+\n+    private HiveMetadata getMetadata(TableHandle tableHandle)\n+    {\n+        ConnectorMetadata metadata = transactionManager.get(tableHandle.getTransaction());\n+        checkState(metadata instanceof HiveMetadata, \"metadata must be HiveMetadata\");\n+        return (HiveMetadata) metadata;\n+    }\n+\n+    private String getColumnName(ConnectorSession session, HiveMetadata metadata, ConnectorTableHandle tableHandle, ColumnHandle columnHandle)\n+    {\n+        return metadata.getColumnMetadata(session, tableHandle, columnHandle).getName();\n+    }\n+\n+    private boolean isPushdownFilterSupported(ConnectorSession session, TableHandle tableHandle)\n+    {\n+        checkArgument(tableHandle.getConnectorHandle() instanceof HiveTableHandle, \"pushdownFilter is never supported on a non-hive TableHandle\");\n+        if (((HiveTableHandle) tableHandle.getConnectorHandle()).getAnalyzePartitionValues().isPresent()) {\n+            return false;\n+        }\n+\n+        boolean pushdownFilterEnabled = HiveSessionProperties.isPushdownFilterEnabled(session);\n+        if (pushdownFilterEnabled) {\n+            HiveStorageFormat hiveStorageFormat = getHiveStorageFormat(getMetadata(tableHandle).getTableMetadata(session, tableHandle.getConnectorHandle()).getProperties());\n+            if (hiveStorageFormat == HiveStorageFormat.ORC || hiveStorageFormat == HiveStorageFormat.DWRF) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    private DomainTranslator.ExtractionResult intersectExtractionResult(DomainTranslator.ExtractionResult left, DomainTranslator.ExtractionResult right)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "originalPosition": 467}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0OTc4NQ==", "bodyText": "static, same for other helpers", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378449785", "createdAt": "2020-02-12T18:59:48Z", "author": {"login": "highker"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode ret = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), ret, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return ret;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), TRUE_CONSTANT, tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            return new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    pushdownFilterResult.getLayout().getPredicate(),\n+                    TupleDomain.all());\n+        }\n+    }\n+\n+    private static class ConstraintEvaluator\n+    {\n+        private final Map<String, ColumnHandle> assignments;\n+        private final RowExpressionService evaluator;\n+        private final ConnectorSession session;\n+        private final RowExpression expression;\n+        private final Set<ColumnHandle> arguments;\n+\n+        public ConstraintEvaluator(RowExpressionService evaluator, ConnectorSession session, Map<String, ColumnHandle> assignments, RowExpression expression)\n+        {\n+            this.assignments = assignments;\n+            this.evaluator = evaluator;\n+            this.session = session;\n+            this.expression = expression;\n+\n+            arguments = ImmutableSet.copyOf(extractAll(expression)).stream()\n+                    .map(VariableReferenceExpression::getName)\n+                    .map(assignments::get)\n+                    .collect(toImmutableSet());\n+        }\n+\n+        private boolean isCandidate(Map<ColumnHandle, NullableValue> bindings)\n+        {\n+            if (intersection(bindings.keySet(), arguments).isEmpty()) {\n+                return true;\n+            }\n+\n+            Function<VariableReferenceExpression, Object> variableResolver = variable -> {\n+                ColumnHandle column = assignments.get(variable.getName());\n+                checkArgument(column != null, \"Missing column assignment for %s\", variable);\n+\n+                if (!bindings.containsKey(column)) {\n+                    return variable;\n+                }\n+\n+                return bindings.get(column).getValue();\n+            };\n+\n+            // Skip pruning if evaluation fails in a recoverable way. Failing here can cause\n+            // spurious query failures for partitions that would otherwise be filtered out.\n+            Object optimized = null;\n+            try {\n+                optimized = evaluator.getExpressionOptimizer().optimize(expression, OPTIMIZED, session, variableResolver);\n+            }\n+            catch (PrestoException e) {\n+                propagateIfUnhandled(e);\n+            }\n+\n+            // If any conjuncts evaluate to FALSE or null, then the whole predicate will never be true and so the partition should be pruned\n+            return !Boolean.FALSE.equals(optimized) && optimized != null && (!(optimized instanceof ConstantExpression) || !((ConstantExpression) optimized).isNull());\n+        }\n+\n+        private static void propagateIfUnhandled(PrestoException e)\n+                throws PrestoException\n+        {\n+            int errorCode = e.getErrorCode().getCode();\n+            if (errorCode == DIVISION_BY_ZERO.toErrorCode().getCode()\n+                    || errorCode == INVALID_CAST_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == INVALID_FUNCTION_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == NUMERIC_VALUE_OUT_OF_RANGE.toErrorCode().getCode()) {\n+                return;\n+            }\n+\n+            throw e;\n+        }\n+    }\n+\n+    private HiveMetadata getMetadata(TableHandle tableHandle)\n+    {\n+        ConnectorMetadata metadata = transactionManager.get(tableHandle.getTransaction());\n+        checkState(metadata instanceof HiveMetadata, \"metadata must be HiveMetadata\");\n+        return (HiveMetadata) metadata;\n+    }\n+\n+    private String getColumnName(ConnectorSession session, HiveMetadata metadata, ConnectorTableHandle tableHandle, ColumnHandle columnHandle)\n+    {\n+        return metadata.getColumnMetadata(session, tableHandle, columnHandle).getName();\n+    }\n+\n+    private boolean isPushdownFilterSupported(ConnectorSession session, TableHandle tableHandle)\n+    {\n+        checkArgument(tableHandle.getConnectorHandle() instanceof HiveTableHandle, \"pushdownFilter is never supported on a non-hive TableHandle\");\n+        if (((HiveTableHandle) tableHandle.getConnectorHandle()).getAnalyzePartitionValues().isPresent()) {\n+            return false;\n+        }\n+\n+        boolean pushdownFilterEnabled = HiveSessionProperties.isPushdownFilterEnabled(session);\n+        if (pushdownFilterEnabled) {\n+            HiveStorageFormat hiveStorageFormat = getHiveStorageFormat(getMetadata(tableHandle).getTableMetadata(session, tableHandle.getConnectorHandle()).getProperties());\n+            if (hiveStorageFormat == HiveStorageFormat.ORC || hiveStorageFormat == HiveStorageFormat.DWRF) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    private DomainTranslator.ExtractionResult intersectExtractionResult(DomainTranslator.ExtractionResult left, DomainTranslator.ExtractionResult right)\n+    {\n+        RowExpression newRemainingExpression;\n+        if (right.getRemainingExpression().equals(TRUE_CONSTANT)) {\n+            newRemainingExpression = left.getRemainingExpression();\n+        }\n+        else if (left.getRemainingExpression().equals(TRUE_CONSTANT)) {\n+            newRemainingExpression = right.getRemainingExpression();\n+        }\n+        else {\n+            newRemainingExpression = and(left.getRemainingExpression(), right.getRemainingExpression());\n+        }\n+        return new DomainTranslator.ExtractionResult(left.getTupleDomain().intersect(right.getTupleDomain()), newRemainingExpression);\n+    }\n+\n+    private boolean isEntireColumn(Subfield subfield)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "originalPosition": 482}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MTE1OA==", "bodyText": "Explain more how to use ConnectorPlanOptimizer as the way to pushdown compute.", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378451158", "createdAt": "2020-02-12T19:02:26Z", "author": {"login": "highker"}, "path": "presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java", "diffHunk": "@@ -100,18 +99,11 @@\n     TableHandle getAlternativeTableHandle(Session session, TableHandle tableHandle, PartitioningHandle partitioningHandle);\n \n     /**\n-     * Experimental: if true, the engine will invoke pushdownFilter instead of getLayout.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n-     */\n-    boolean isPushdownFilterSupported(Session session, TableHandle tableHandle);\n-\n-    /**\n-     * Experimental: returns table layout that encapsulates the given filter.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n+     * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n+     * This function remains to ensure backwards compatibility, it needs to be removed.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MzIzOQ==", "bodyText": "Add a comment to explain \"new filters can be created and we need to merge them together\" something like that", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378453239", "createdAt": "2020-02-12T19:06:27Z", "author": {"login": "highker"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java", "diffHunk": "@@ -13,24 +13,53 @@\n  */\n package com.facebook.presto.hive.rule;\n \n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.connector.ConnectorPlanOptimizerProvider;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n import com.google.common.collect.ImmutableSet;\n+import com.google.inject.Inject;\n \n import java.util.Set;\n \n+import static java.util.Objects.requireNonNull;\n+\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    @Inject\n+    public HivePlanOptimizerProvider(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n     @Override\n     public Set<ConnectorPlanOptimizer> getLogicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));\n     }\n \n     @Override\n     public Set<ConnectorPlanOptimizer> getPhysicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MzgwMA==", "bodyText": "Just remove. They don't hold anymore", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378453800", "createdAt": "2020-02-12T19:07:36Z", "author": {"login": "highker"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1373,29 +1371,29 @@ protected void doTestMismatchSchemaTable(\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-            int filterCount = afterFilters.size();\n-            for (int i = 0; i < filterCount; i++) {\n-                RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-\n-                // Read all columns with a filter\n-                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n-\n-                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n-                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n-\n-                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n-\n-                // Read all columns except the ones used in the filter\n-                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n-\n-                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n-                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n-                        .collect(toList());\n-\n-                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n-                assertEquals(resultCount, expectedRows.size());\n-            }\n+//            int filterCount = afterFilters.size();\n+//            for (int i = 0; i < filterCount; i++) {\n+//                RowExpression predicate = afterFilters.get(i);\n+//                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+//\n+//                // Read all columns with a filter\n+//                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n+//\n+//                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n+//                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n+//\n+//                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n+//\n+//                // Read all columns except the ones used in the filter\n+//                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n+//\n+//                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n+//                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n+//                        .collect(toList());\n+//\n+//                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n+//                assertEquals(resultCount, expectedRows.size());\n+//            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1Mzg5MA==", "bodyText": "same", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378453890", "createdAt": "2020-02-12T19:07:46Z", "author": {"login": "highker"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -2052,15 +2050,15 @@ private void doTestBucketedTableEvolution(HiveStorageFormat storageFormat, Schem\n \n             NullableValue singleBucket = NullableValue.of(INTEGER, 6L);\n             ConnectorTableLayoutHandle layoutHandle;\n-            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n-\n-                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n-                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-            }\n-            else {\n-                layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n-            }\n+//            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+//                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n+//\n+//                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n+//                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+//            }\n+//            else {\n+            layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n+//            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "originalPosition": 108}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU3NzIyNjA5", "url": "https://github.com/prestodb/presto/pull/14040#pullrequestreview-357722609", "createdAt": "2020-02-12T19:23:02Z", "commit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQxOToyMzowMlrOFo7fdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQxOToyMzowMlrOFo7fdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA==", "bodyText": "@sachdevs Why is this code commented out?", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378462068", "createdAt": "2020-02-12T19:23:02Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1373,29 +1371,29 @@ protected void doTestMismatchSchemaTable(\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-            int filterCount = afterFilters.size();\n-            for (int i = 0; i < filterCount; i++) {\n-                RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-\n-                // Read all columns with a filter\n-                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n-\n-                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n-                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n-\n-                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n-\n-                // Read all columns except the ones used in the filter\n-                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n-\n-                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n-                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n-                        .collect(toList());\n-\n-                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n-                assertEquals(resultCount, expectedRows.size());\n-            }\n+//            int filterCount = afterFilters.size();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23"}, "originalPosition": 61}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "committedDate": "2020-02-11T19:48:24Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "committedDate": "2020-02-12T23:19:07Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU4Nzg3MTk5", "url": "https://github.com/prestodb/presto/pull/14040#pullrequestreview-358787199", "createdAt": "2020-02-14T08:49:50Z", "commit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwODo0OTo1MFrOFpvRyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwOToxMDoxMlrOFpv0Eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMDUzNg==", "bodyText": "Consider editing for brevity and clarity:\n/**\n * Runs during both logical and physical phases of connector-aided plan optimization.\n * In most cases filter pushdown will occur during logical phase. However, in cases \n * when new filter is added between logical and physical phases, e.g. a filter on a join \n * key from one side of a join is added to the other side, the new filter will get\n * merged with the one already pushed down.\n */", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379310536", "createdAt": "2020-02-14T08:49:50Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTIyOQ==", "bodyText": "perhaps, drop Connector prefix here: PushdownFilterResult\nmake private", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379311229", "createdAt": "2020-02-14T08:51:25Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTQzNQ==", "bodyText": "make this private", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379311435", "createdAt": "2020-02-14T08:51:51Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTcwMg==", "bodyText": "nit: put arguments on a single line: Visitor(ConnectorSession session, PlanNodeIdAllocator idAllocator)", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379311702", "createdAt": "2020-02-14T08:52:28Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "originalPosition": 269}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMzA5Mg==", "bodyText": "no need to create new object if source didn't change; perhaps, just call visitPlan: return visitPlan(filter, context);", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379313092", "createdAt": "2020-02-14T08:55:38Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "originalPosition": 300}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNDQ4OQ==", "bodyText": "move this variable up and re-use", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379314489", "createdAt": "2020-02-14T08:58:52Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode node = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), node, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return node;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), TRUE_CONSTANT, tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "originalPosition": 357}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNTU0NQ==", "bodyText": "any reason to make a new HiveFilterPushdown object here? Can the same object be re-used in logical and physical phases?", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379315545", "createdAt": "2020-02-14T09:01:14Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java", "diffHunk": "@@ -13,24 +13,54 @@\n  */\n package com.facebook.presto.hive.rule;\n \n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.connector.ConnectorPlanOptimizerProvider;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n import com.google.common.collect.ImmutableSet;\n+import com.google.inject.Inject;\n \n import java.util.Set;\n \n+import static java.util.Objects.requireNonNull;\n+\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    @Inject\n+    public HivePlanOptimizerProvider(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n     @Override\n     public Set<ConnectorPlanOptimizer> getLogicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));\n     }\n \n     @Override\n     public Set<ConnectorPlanOptimizer> getPhysicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        // New filters may be created in between logical optimization and physical optimization. Push those newly created filters as well.\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNzYxOA==", "bodyText": "Based on the description, I'd rename this method to isLegacyGetLayoutSupported. What kind of backwards compatibility is needed here?", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379317618", "createdAt": "2020-02-14T09:06:09Z", "author": {"login": "mbasmanova"}, "path": "presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java", "diffHunk": "@@ -100,18 +99,13 @@\n     TableHandle getAlternativeTableHandle(Session session, TableHandle tableHandle, PartitioningHandle partitioningHandle);\n \n     /**\n-     * Experimental: if true, the engine will invoke pushdownFilter instead of getLayout.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n-     */\n-    boolean isPushdownFilterSupported(Session session, TableHandle tableHandle);\n-\n-    /**\n-     * Experimental: returns table layout that encapsulates the given filter.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n+     * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n+     * This function remains to ensure backwards compatibility, it needs to be removed.\n+     * If filter pushdown is required, use a ConnectorPlanOptimizer in the respective connector in order\n+     * to push compute into it's TableScan.\n      */\n-    PushdownFilterResult pushdownFilter(Session session, TableHandle tableHandle, RowExpression filter);\n+    @Deprecated\n+    boolean isPredicatePushdownEnabled(Session session, TableHandle tableHandle);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxOTMxNA==", "bodyText": "perhaps, make com.facebook.presto.hive.rule.HiveFilterPushdown#pushdownFilter @VisibleForTesting and use here?", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379319314", "createdAt": "2020-02-14T09:10:12Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1373,30 +1371,6 @@ protected void doTestMismatchSchemaTable(\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-            int filterCount = afterFilters.size();\n-            for (int i = 0; i < filterCount; i++) {\n-                RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d"}, "originalPosition": 41}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "committedDate": "2020-02-12T23:19:07Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/11344ed62d98905bf429f35f8328988606319f8b", "committedDate": "2020-02-18T22:07:04Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwNzExOTU0", "url": "https://github.com/prestodb/presto/pull/14040#pullrequestreview-360711954", "createdAt": "2020-02-18T22:12:15Z", "commit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMjoxMjoxNVrOFrUXBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMjoxMjoxNVrOFrUXBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2NjY2Mw==", "bodyText": "I dont think we intended this Transaction interface to have a param for getMetastore - I dont see it being used anywhere (even in the internal codebase) am I missing something?", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r380966663", "createdAt": "2020-02-18T22:12:15Z", "author": {"login": "sachdevs"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1376,7 +1379,17 @@ protected void doTestMismatchSchemaTable(\n             int filterCount = afterFilters.size();\n             for (int i = 0; i < filterCount; i++) {\n                 RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+                ConnectorTableLayoutHandle layoutHandle = pushdownFilter(\n+                        session,\n+                        metadata,\n+                        transaction.getMetastore(\"\"), // function does not use param in all implementations?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b"}, "originalPosition": 95}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MzAzODM5", "url": "https://github.com/prestodb/presto/pull/14040#pullrequestreview-365303839", "createdAt": "2020-02-26T22:52:37Z", "commit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMjo1MjozN1rOFu_WBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMjo1NzozMFrOFu_d5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxNjY0NQ==", "bodyText": "Please, remove this method.", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384816645", "createdAt": "2020-02-26T22:52:37Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -2675,6 +2460,11 @@ public void revokeTablePrivileges(ConnectorSession session, SchemaTableName sche\n         return toCompletableFuture(stagingFileCommitter.commitFiles(session, handle.getSchemaName(), handle.getTableName(), getPartitionUpdates(fragments)));\n     }\n \n+    public FunctionMetadataManager getFunctionMetadataManager()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b"}, "originalPosition": 309}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxNzE0Mg==", "bodyText": "let's rename to isLegacyGetLayoutSupported; that name would match the description and the actual meaning more closely", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384817142", "createdAt": "2020-02-26T22:53:52Z", "author": {"login": "mbasmanova"}, "path": "presto-spi/src/main/java/com/facebook/presto/spi/connector/ConnectorMetadata.java", "diffHunk": "@@ -127,25 +125,14 @@ default ConnectorTableLayoutHandle getAlternativeLayoutHandle(ConnectorSession s\n     }\n \n     /**\n-     * Experimental: if true, the engine will invoke pushdownFilter instead of getTableLayouts.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n-     */\n-    @Experimental\n-    default boolean isPushdownFilterSupported(ConnectorSession session, ConnectorTableHandle tableHandle)\n-    {\n-        return false;\n-    }\n-\n-    /**\n-     * Experimental: returns table layout that encapsulates the given filter.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n+     * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n+     * This function remains to ensure backwards compatibility, it needs to be removed.\n      */\n+    @Deprecated\n     @Experimental\n-    default ConnectorPushdownFilterResult pushdownFilter(ConnectorSession session, ConnectorTableHandle tableHandle, RowExpression filter, Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    default boolean isPredicatePushdownEnabled(ConnectorSession session, ConnectorTableHandle tableHandle)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxNzgyNA==", "bodyText": "Please, move this variable up and reuse in the following places:\nHiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n...tableScan.getTable().getConnectorHandle()", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384817824", "createdAt": "2020-02-26T22:55:32Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,578 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Runs during both logical and physical phases of connector-aided plan optimization.\n+ * In most cases filter pushdown will occur during logical phase. However, in cases\n+ * when new filter is added between logical and physical phases, e.g. a filter on a join\n+ * key from one side of a join is added to the other side, the new filter will get\n+ * merged with the one already pushed down.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    protected final RowExpressionService rowExpressionService;\n+    protected final StandardFunctionResolution functionResolution;\n+    protected final HivePartitionManager partitionManager;\n+    protected final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        return pushdownFilter(\n+                session,\n+                metadata,\n+                metadata.getMetastore(),\n+                rowExpressionService,\n+                functionResolution,\n+                partitionManager,\n+                functionMetadataManager,\n+                tableHandle,\n+                filter,\n+                currentLayoutHandle);\n+    }\n+\n+    @VisibleForTesting\n+    public static ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            ConnectorMetadata metadata,\n+            SemiTransactionalHiveMetastore metastore,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metastore, tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(\n+                                        session,\n+                                        rowExpressionService,\n+                                        tableName,\n+                                        hivePartitionResult.getBucketHandle(),\n+                                        hivePartitionResult.getBucketFilter(),\n+                                        decomposedFilter.getRemainingExpression(),\n+                                        domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    @VisibleForTesting\n+    public static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return visitPlan(filter, context);\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            TableHandle handle = tableScan.getTable();\n+            HiveMetadata hiveMetadata = getMetadata(handle);\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, handle.getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(\n+                    session,\n+                    hiveMetadata,\n+                    handle.getConnectorHandle(),\n+                    replacedExpression,\n+                    handle.getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableScanNode node = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), node, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return node;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(\n+                    session,\n+                    hiveMetadata,\n+                    tableScan.getTable().getConnectorHandle(),\n+                    TRUE_CONSTANT,\n+                    tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b"}, "originalPosition": 404}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxODAzMg==", "bodyText": "no need to make new set object every time; change the variable type to Set", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384818032", "createdAt": "2020-02-26T22:56:01Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java", "diffHunk": "@@ -13,24 +13,51 @@\n  */\n package com.facebook.presto.hive.rule;\n \n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.connector.ConnectorPlanOptimizerProvider;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n import com.google.common.collect.ImmutableSet;\n+import com.google.inject.Inject;\n \n import java.util.Set;\n \n+import static java.util.Objects.requireNonNull;\n+\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n+    private final HiveFilterPushdown filterPushdownOptimizer;\n+\n+    @Inject\n+    public HivePlanOptimizerProvider(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        requireNonNull(transactionManager, \"transactionManager is null\");\n+        requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        requireNonNull(functionResolution, \"functionResolution is null\");\n+        requireNonNull(partitionManager, \"partitionManager is null\");\n+        requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+        this.filterPushdownOptimizer = new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager);\n+    }\n+\n     @Override\n     public Set<ConnectorPlanOptimizer> getLogicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(filterPushdownOptimizer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxODY2MA==", "bodyText": "@sachdevs Let's remove the parameter then. Just check prism connector first.", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384818660", "createdAt": "2020-02-26T22:57:30Z", "author": {"login": "mbasmanova"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1376,7 +1379,17 @@ protected void doTestMismatchSchemaTable(\n             int filterCount = afterFilters.size();\n             for (int i = 0; i < filterCount; i++) {\n                 RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+                ConnectorTableLayoutHandle layoutHandle = pushdownFilter(\n+                        session,\n+                        metadata,\n+                        transaction.getMetastore(\"\"), // function does not use param in all implementations?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2NjY2Mw=="}, "originalCommit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b"}, "originalPosition": 95}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "11344ed62d98905bf429f35f8328988606319f8b", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/11344ed62d98905bf429f35f8328988606319f8b", "committedDate": "2020-02-18T22:07:04Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "committedDate": "2020-03-04T00:24:46Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY4NDQ0MDEy", "url": "https://github.com/prestodb/presto/pull/14040#pullrequestreview-368444012", "createdAt": "2020-03-04T01:17:19Z", "commit": {"oid": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abf05811d635dc6c4df778ba1e872efded23a5db", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/abf05811d635dc6c4df778ba1e872efded23a5db", "committedDate": "2020-03-04T20:24:55Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "committedDate": "2020-03-04T00:24:46Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}, "afterCommit": {"oid": "abf05811d635dc6c4df778ba1e872efded23a5db", "author": {"user": {"login": "sachdevs", "name": "Saksham"}}, "url": "https://github.com/prestodb/presto/commit/abf05811d635dc6c4df778ba1e872efded23a5db", "committedDate": "2020-03-04T20:24:55Z", "message": "Move Hive filter pushdown logic out of PickTableLayout"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2534, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}