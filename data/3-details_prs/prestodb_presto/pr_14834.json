{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ4Mzc4NDcw", "number": 14834, "title": "Partial Aggregation Pushdown for ORC/Parquet", "bodyText": "Please make sure your submission complies with our Development, Formatting, and Commit Message guidelines.\nFill in the release notes towards the bottom of the PR description.\nSee Release Notes Guidelines for details.\n== RELEASE NOTES ==\n\nGeneral Changes\n* ...\n* ...\n\nHive Changes\n* ...\n* ...\n\nIf release note is NOT required, use:\n== NO RELEASE NOTE ==\n\nDepended by facebookexternal/presto-facebook#1153", "createdAt": "2020-07-13T17:01:23Z", "url": "https://github.com/prestodb/presto/pull/14834", "merged": true, "mergeCommit": {"oid": "61d5b873a8702c34f28a88e8fc79ec7fd48db410"}, "closed": true, "closedAt": "2020-09-08T22:11:37Z", "author": {"login": "ClarenceThreepwood"}, "timelineItems": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc3JPjXgFqTQ1MjY1MjQ2Ng==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdF98ysABqjM3MzMxNjc5MTE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyNjUyNDY2", "url": "https://github.com/prestodb/presto/pull/14834#pullrequestreview-452652466", "createdAt": "2020-07-21T16:55:45Z", "commit": {"oid": "1d255a6130fad7625791988bf75f447b44939712"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjo1NTo0NVrOG1BNsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjo1NTo0NVrOG1BNsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzYwMA==", "bodyText": "We don't have to just return TableScanNode. We could still have the AggNode -> TableScanNode to make the optimizer doesn't fail. This assumption holds given the input type for min/max is the same for its output.", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r458247600", "createdAt": "2020-07-21T16:55:45Z", "author": {"login": "highker"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    @Inject\n+    public HivePartialAggregationPushdown(\n+            FunctionMetadataManager functionMetadataManager,\n+            StandardFunctionResolution standardFunctionResolution,\n+            Supplier<TransactionalMetadata> metadataFactory)\n+    {\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"function manager is null\");\n+        this.standardFunctionResolution = requireNonNull(standardFunctionResolution, \"standard function resolution is null\");\n+        this.metadataFactory = requireNonNull(metadataFactory, \"metadata factory is null\");\n+    }\n+\n+    private static Optional<HiveTableHandle> getHiveTableHandle(TableScanNode tableScanNode)\n+    {\n+        TableHandle table = tableScanNode.getTable();\n+        if (table != null) {\n+            ConnectorTableHandle connectorHandle = table.getConnectorHandle();\n+            if (connectorHandle instanceof HiveTableHandle) {\n+                return Optional.of((HiveTableHandle) connectorHandle);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static PlanNode replaceChildren(PlanNode node, List<PlanNode> children)\n+    {\n+        return children.containsAll(node.getSources()) ? node : node.replaceChildren(children);\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan,\n+            ConnectorSession session,\n+            VariableAllocator variableAllocator,\n+            PlanNodeIdAllocator idAllocator)\n+    {\n+        if (!isPartialAggregationPushdownEnabled(session)) {\n+            return maxSubplan;\n+        }\n+        return maxSubplan.accept(new Visitor(variableAllocator, session, idAllocator), null);\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final ConnectorSession session;\n+        private final VariableAllocator variableAllocator;\n+\n+        public Visitor(VariableAllocator variableAllocator, ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = session;\n+            this.idAllocator = idAllocator;\n+            this.variableAllocator = variableAllocator;\n+        }\n+\n+        private Optional<PlanNode> tryPartialAggregationPushdown(PlanNode plan)\n+        {\n+            if (!(plan instanceof AggregationNode\n+                    && ((AggregationNode) plan).getStep().equals(PARTIAL)\n+                    && ((AggregationNode) plan).getSource() instanceof TableScanNode)) {\n+                return Optional.empty();\n+            }\n+\n+            AggregationNode partialAggregationNode = (AggregationNode) plan;\n+            if (partialAggregationNode.hasNonEmptyGroupingSet()) {\n+                return Optional.empty();\n+            }\n+            TableScanNode oldTableScanNode = (TableScanNode) partialAggregationNode.getSource();\n+            TableHandle oldTableHandle = oldTableScanNode.getTable();\n+            HiveTableHandle hiveTableHandle = getHiveTableHandle(oldTableScanNode).orElseThrow(() -> new PrestoException(NOT_FOUND, \"Hive table handle not found\"));\n+\n+            ConnectorTableMetadata connectorTableMetadata = metadataFactory.get().getTableMetadata(session, oldTableHandle.getConnectorHandle());\n+            Optional<Object> rawFormat = Optional.ofNullable(connectorTableMetadata.getProperties().get(HiveTableProperties.STORAGE_FORMAT_PROPERTY));\n+            if (!rawFormat.isPresent()) {\n+                return Optional.empty();\n+            }\n+            final HiveStorageFormat hiveStorageFormat = HiveStorageFormat.valueOf(rawFormat.get().toString());\n+            if (hiveStorageFormat != HiveStorageFormat.ORC && hiveStorageFormat != HiveStorageFormat.PARQUET) {\n+                return Optional.empty();\n+            }\n+\n+            /**\n+             * Aggregation push downs are supported only on primitive types and supported aggregation functions are:\n+             * count(*), count(columnName), min(columnName), max(columnName)\n+             */\n+            for (AggregationNode.Aggregation aggregation : partialAggregationNode.getAggregations().values()) {\n+                FunctionHandle functionHandle = aggregation.getFunctionHandle();\n+                if (!(standardFunctionResolution.isCountFunction(functionHandle) ||\n+                        standardFunctionResolution.isMaxFunction(functionHandle) ||\n+                        standardFunctionResolution.isMinFunction(functionHandle))) {\n+                    return Optional.empty();\n+                }\n+\n+                if (aggregation.getArguments().isEmpty() && !standardFunctionResolution.isCountFunction(functionHandle)) {\n+                    return Optional.empty();\n+                }\n+\n+                List<RowExpression> arguments = aggregation.getArguments();\n+                if (arguments.size() > 1) {\n+                    return Optional.empty();\n+                }\n+\n+                if (standardFunctionResolution.isMinFunction(functionHandle) || standardFunctionResolution.isMaxFunction(functionHandle)) {\n+                    // Only allow supported datatypes for min/max\n+                    Type type = arguments.get(0).getType();\n+                    if (BOOLEAN.equals(type) ||\n+                            type.getJavaType() == boolean.class ||\n+                            isRowType(type) ||\n+                            isArrayType(type) ||\n+                            isMapType(type)) {\n+                        return Optional.empty();\n+                    }\n+\n+                    if (hiveStorageFormat == HiveStorageFormat.ORC) {\n+                        if (TINYINT.equals(type) ||\n+                                VARBINARY.equals(type) ||\n+                                TIMESTAMP.equals(type)) {\n+                            return Optional.empty();\n+                        }\n+                    }\n+                }\n+            }\n+\n+            HiveTypeTranslator hiveTypeTranslator = new HiveTypeTranslator();\n+            Map<VariableReferenceExpression, ColumnHandle> assignments = new HashMap<>();\n+            for (Map.Entry<VariableReferenceExpression, AggregationNode.Aggregation> aggregationEntry : partialAggregationNode.getAggregations().entrySet()) {\n+                CallExpression callExpression = aggregationEntry.getValue().getCall();\n+                String colName = \"count_star\";\n+                int columnIndex = -20;\n+                HiveType hiveType = HiveType.toHiveType(hiveTypeTranslator, callExpression.getType());\n+                if (!callExpression.getArguments().isEmpty()) {\n+                    RowExpression column = callExpression.getArguments().get(0);\n+                    colName = column.toString();\n+                    HiveColumnHandle oldColumnHandle = (HiveColumnHandle) oldTableScanNode.getAssignments().get(column);\n+                    columnIndex = oldColumnHandle.getHiveColumnIndex();\n+                    hiveType = oldColumnHandle.getHiveType();\n+                }\n+\n+                ColumnHandle newColumnHandle = new HiveColumnHandle(\n+                        colName,\n+                        hiveType,\n+                        callExpression.getType().getTypeSignature(),\n+                        columnIndex,\n+                        HiveColumnHandle.ColumnType.AGGREGATED,\n+                        Optional.of(\"partial aggregation pushed down\"),\n+                        Optional.of(aggregationEntry.getValue()));\n+                assignments.put(aggregationEntry.getKey(), newColumnHandle);\n+            }\n+\n+            HiveTableLayoutHandle oldTableLayoutHandle = (HiveTableLayoutHandle) oldTableHandle.getLayout().get();\n+            HiveTableLayoutHandle newTableLayoutHandle = new HiveTableLayoutHandle(oldTableLayoutHandle.getSchemaTableName(),\n+                    oldTableLayoutHandle.getPartitionColumns(),\n+                    oldTableLayoutHandle.getDataColumns(),\n+                    oldTableLayoutHandle.getTableParameters(),\n+                    oldTableLayoutHandle.getPartitions().get(),\n+                    oldTableLayoutHandle.getDomainPredicate(),\n+                    oldTableLayoutHandle.getRemainingPredicate(),\n+                    oldTableLayoutHandle.getPredicateColumns(),\n+                    oldTableLayoutHandle.getPartitionColumnPredicate(),\n+                    oldTableLayoutHandle.getBucketHandle(),\n+                    oldTableLayoutHandle.getBucketFilter(),\n+                    oldTableLayoutHandle.isPushdownFilterEnabled(),\n+                    oldTableLayoutHandle.getLayoutString(),\n+                    oldTableLayoutHandle.getRequestedColumns(),\n+                    true);\n+\n+            TableHandle newTableHandle = new TableHandle(\n+                    oldTableHandle.getConnectorId(),\n+                    hiveTableHandle,\n+                    oldTableHandle.getTransaction(),\n+                    Optional.of(newTableLayoutHandle));\n+\n+            return Optional.of(new\n+\n+                    TableScanNode(\n+                    idAllocator.getNextId(),\n+                    newTableHandle,\n+                    ImmutableList.copyOf(partialAggregationNode.getOutputVariables()),\n+                    ImmutableMap.copyOf(assignments),\n+                    oldTableScanNode.getCurrentConstraint(),\n+                    oldTableScanNode.getEnforcedConstraint()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d255a6130fad7625791988bf75f447b44939712"}, "originalPosition": 246}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "76139cd20cfc500e6545e08f2fa5a25545d571a9", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/76139cd20cfc500e6545e08f2fa5a25545d571a9", "committedDate": "2020-08-17T18:47:10Z", "message": "throw error on null stats in orc"}, "afterCommit": {"oid": "9b53a7d45ee602c6aa82140768d4ecb7b1af1639", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/9b53a7d45ee602c6aa82140768d4ecb7b1af1639", "committedDate": "2020-08-17T21:41:18Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9b53a7d45ee602c6aa82140768d4ecb7b1af1639", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/9b53a7d45ee602c6aa82140768d4ecb7b1af1639", "committedDate": "2020-08-17T21:41:18Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "2e8acfd14d23a4736169c171d0955cc87b521471", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/2e8acfd14d23a4736169c171d0955cc87b521471", "committedDate": "2020-08-17T23:03:28Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2e8acfd14d23a4736169c171d0955cc87b521471", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/2e8acfd14d23a4736169c171d0955cc87b521471", "committedDate": "2020-08-17T23:03:28Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "ed7e2525eaffc89b2f057bf359277d944a58aa18", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/ed7e2525eaffc89b2f057bf359277d944a58aa18", "committedDate": "2020-08-18T00:37:38Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ed7e2525eaffc89b2f057bf359277d944a58aa18", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/ed7e2525eaffc89b2f057bf359277d944a58aa18", "committedDate": "2020-08-18T00:37:38Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "e50fbbcf7e048bb2d42461f92ccb371660bc648e", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/e50fbbcf7e048bb2d42461f92ccb371660bc648e", "committedDate": "2020-08-26T03:46:59Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e50fbbcf7e048bb2d42461f92ccb371660bc648e", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/e50fbbcf7e048bb2d42461f92ccb371660bc648e", "committedDate": "2020-08-26T03:46:59Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "0cabcd99a4e45fde14845e3a019ce608590d7773", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/0cabcd99a4e45fde14845e3a019ce608590d7773", "committedDate": "2020-08-26T06:53:52Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0cabcd99a4e45fde14845e3a019ce608590d7773", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/0cabcd99a4e45fde14845e3a019ce608590d7773", "committedDate": "2020-08-26T06:53:52Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/ed800f1a7409eda550397f6d76b1141764aae662", "committedDate": "2020-08-26T15:49:15Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc2ODg3MjQ4", "url": "https://github.com/prestodb/presto/pull/14834#pullrequestreview-476887248", "createdAt": "2020-08-27T16:25:40Z", "commit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "state": "COMMENTED", "comments": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxNjoyNTo0MFrOHIYBXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QyMDoxMzoxN1rOHIfqNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NDIyMQ==", "bodyText": "nit: Maybe also edit the comment to include partialAggregationsPushedDown? Though it is obvious but let's keep the comment up-to-date :)", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478544221", "createdAt": "2020-08-27T16:25:40Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java", "diffHunk": "@@ -387,7 +390,7 @@ private void invokeNoMoreSplitsIfNecessary()\n         // therefore we must not split files when it is enabled.\n         Properties schema = getHiveSchema(storage.getSerdeParameters(), table.getParameters());\n         // Skip header / footer lines are not splittable except for a special case when skip.header.line.count=1\n-        boolean splittable = !s3SelectPushdownEnabled && getFooterCount(schema) == 0 && getHeaderCount(schema) <= 1;\n+        boolean splittable = !s3SelectPushdownEnabled && !partialAggregationsPushedDown && getFooterCount(schema) == 0 && getHeaderCount(schema) <= 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NDgzMw==", "bodyText": "nit: enable", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478544833", "createdAt": "2020-08-27T16:26:38Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1438,4 +1441,30 @@ public boolean isParquetDereferencePushdownEnabled()\n     {\n         return this.parquetDereferencePushdownEnabled;\n     }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown\")\n+    @ConfigDescription(\"enabled partial aggregation pushdown\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NTEwNQ==", "bodyText": "nit: enable\nDo we really need a separate config?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478545105", "createdAt": "2020-08-27T16:27:00Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1438,4 +1441,30 @@ public boolean isParquetDereferencePushdownEnabled()\n     {\n         return this.parquetDereferencePushdownEnabled;\n     }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown\")\n+    @ConfigDescription(\"enabled partial aggregation pushdown\")\n+    public HiveClientConfig setPartialAggregationPushdownEnabled(boolean partialAggregationPushdownEnabled)\n+    {\n+        this.isPartialAggregationPushdownEnabled = partialAggregationPushdownEnabled;\n+        return this;\n+    }\n+\n+    public boolean isPartialAggregationPushdownEnabled()\n+    {\n+        return this.isPartialAggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown_for_variable_length_datatypes\")\n+    @ConfigDescription(\"enabled partial aggregation pushdown for variable length datatypes\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NTU0NQ==", "bodyText": "nit: static import", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478545545", "createdAt": "2020-08-27T16:27:44Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveColumnHandle.java", "diffHunk": "@@ -78,16 +82,19 @@ public HiveColumnHandle(\n             @JsonProperty(\"hiveColumnIndex\") int hiveColumnIndex,\n             @JsonProperty(\"columnType\") ColumnType columnType,\n             @JsonProperty(\"comment\") Optional<String> comment,\n-            @JsonProperty(\"requiredSubfields\") List<Subfield> requiredSubfields)\n+            @JsonProperty(\"requiredSubfields\") List<Subfield> requiredSubfields,\n+            @JsonProperty(\"partialAggregation\") Optional<AggregationNode.Aggregation> partialAggregation)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NjY4Ng==", "bodyText": "There is only three non-test callsites and the rest are tests. Maybe we don't need to introduce this new constructor?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478546686", "createdAt": "2020-08-27T16:29:32Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveColumnHandle.java", "diffHunk": "@@ -98,7 +105,19 @@ public HiveColumnHandle(\n             ColumnType columnType,\n             Optional<String> comment)\n     {\n-        this(name, hiveType, typeSignature, hiveColumnIndex, columnType, comment, ImmutableList.of());\n+        this(name, hiveType, typeSignature, hiveColumnIndex, columnType, comment, ImmutableList.of(), Optional.empty());\n+    }\n+\n+    public HiveColumnHandle(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0Njk3Ng==", "bodyText": "nit: unrelated change", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478546976", "createdAt": "2020-08-27T16:29:55Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveColumnHandle.java", "diffHunk": "@@ -165,7 +190,8 @@ public ColumnHandle withRequiredSubfields(List<Subfield> subfields)\n             // This column is already a pushed down subfield column\n             return this;\n         }\n-        return new HiveColumnHandle(name, hiveType, typeName, hiveColumnIndex, columnType, comment, subfields);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU1MjY3Mg==", "bodyText": "nit: maybe add a comment like INTERIM?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478552672", "createdAt": "2020-08-27T16:39:20Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePageSource.java", "diffHunk": "@@ -161,6 +161,8 @@ public Page getNextPage()\n                     case INTERIM:\n                         // interim columns don't show up in output\n                         break;\n+                    case AGGREGATED:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU1NjY5NQ==", "bodyText": "nit: Can we extract this into a separate method: isAggregationPushdownSupported(...)?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478556695", "createdAt": "2020-08-27T16:46:06Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.common.type.VarcharType.VARCHAR;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownForVariableLengthDatatypesEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    @Inject\n+    public HivePartialAggregationPushdown(\n+            FunctionMetadataManager functionMetadataManager,\n+            StandardFunctionResolution standardFunctionResolution,\n+            Supplier<TransactionalMetadata> metadataFactory)\n+    {\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"function manager is null\");\n+        this.standardFunctionResolution = requireNonNull(standardFunctionResolution, \"standard function resolution is null\");\n+        this.metadataFactory = requireNonNull(metadataFactory, \"metadata factory is null\");\n+    }\n+\n+    private static Optional<HiveTableHandle> getHiveTableHandle(TableScanNode tableScanNode)\n+    {\n+        TableHandle table = tableScanNode.getTable();\n+        if (table != null) {\n+            ConnectorTableHandle connectorHandle = table.getConnectorHandle();\n+            if (connectorHandle instanceof HiveTableHandle) {\n+                return Optional.of((HiveTableHandle) connectorHandle);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static PlanNode replaceChildren(PlanNode node, List<PlanNode> children)\n+    {\n+        return children.containsAll(node.getSources()) ? node : node.replaceChildren(children);\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan,\n+            ConnectorSession session,\n+            VariableAllocator variableAllocator,\n+            PlanNodeIdAllocator idAllocator)\n+    {\n+        if (!isPartialAggregationPushdownEnabled(session)) {\n+            return maxSubplan;\n+        }\n+        return maxSubplan.accept(new Visitor(variableAllocator, session, idAllocator), null);\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final ConnectorSession session;\n+        private final VariableAllocator variableAllocator;\n+\n+        public Visitor(VariableAllocator variableAllocator, ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = session;\n+            this.idAllocator = idAllocator;\n+            this.variableAllocator = variableAllocator;\n+        }\n+\n+        private Optional<PlanNode> tryPartialAggregationPushdown(PlanNode plan)\n+        {\n+            if (!(plan instanceof AggregationNode\n+                    && ((AggregationNode) plan).getStep().equals(PARTIAL)\n+                    && ((AggregationNode) plan).getSource() instanceof TableScanNode)) {\n+                return Optional.empty();\n+            }\n+\n+            AggregationNode partialAggregationNode = (AggregationNode) plan;\n+            if (partialAggregationNode.hasNonEmptyGroupingSet()) {\n+                return Optional.empty();\n+            }\n+            TableScanNode oldTableScanNode = (TableScanNode) partialAggregationNode.getSource();\n+            TableHandle oldTableHandle = oldTableScanNode.getTable();\n+            HiveTableHandle hiveTableHandle = getHiveTableHandle(oldTableScanNode).orElseThrow(() -> new PrestoException(NOT_FOUND, \"Hive table handle not found\"));\n+\n+            ConnectorTableMetadata connectorTableMetadata = metadataFactory.get().getTableMetadata(session, oldTableHandle.getConnectorHandle());\n+            Optional<Object> rawFormat = Optional.ofNullable(connectorTableMetadata.getProperties().get(HiveTableProperties.STORAGE_FORMAT_PROPERTY));\n+            if (!rawFormat.isPresent()) {\n+                return Optional.empty();\n+            }\n+            final HiveStorageFormat hiveStorageFormat = HiveStorageFormat.valueOf(rawFormat.get().toString());\n+            if (hiveStorageFormat != HiveStorageFormat.ORC && hiveStorageFormat != HiveStorageFormat.PARQUET) {\n+                return Optional.empty();\n+            }\n+\n+            /**\n+             * Aggregation push downs are supported only on primitive types and supported aggregation functions are:\n+             * count(*), count(columnName), min(columnName), max(columnName)\n+             */\n+            for (AggregationNode.Aggregation aggregation : partialAggregationNode.getAggregations().values()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU3MzA3NQ==", "bodyText": "nit: let's only declare these fields here and assign it in the else clause. It's a little bit confusing as one might interpret this as default.", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478573075", "createdAt": "2020-08-27T17:14:25Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.common.type.VarcharType.VARCHAR;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownForVariableLengthDatatypesEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    @Inject\n+    public HivePartialAggregationPushdown(\n+            FunctionMetadataManager functionMetadataManager,\n+            StandardFunctionResolution standardFunctionResolution,\n+            Supplier<TransactionalMetadata> metadataFactory)\n+    {\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"function manager is null\");\n+        this.standardFunctionResolution = requireNonNull(standardFunctionResolution, \"standard function resolution is null\");\n+        this.metadataFactory = requireNonNull(metadataFactory, \"metadata factory is null\");\n+    }\n+\n+    private static Optional<HiveTableHandle> getHiveTableHandle(TableScanNode tableScanNode)\n+    {\n+        TableHandle table = tableScanNode.getTable();\n+        if (table != null) {\n+            ConnectorTableHandle connectorHandle = table.getConnectorHandle();\n+            if (connectorHandle instanceof HiveTableHandle) {\n+                return Optional.of((HiveTableHandle) connectorHandle);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static PlanNode replaceChildren(PlanNode node, List<PlanNode> children)\n+    {\n+        return children.containsAll(node.getSources()) ? node : node.replaceChildren(children);\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan,\n+            ConnectorSession session,\n+            VariableAllocator variableAllocator,\n+            PlanNodeIdAllocator idAllocator)\n+    {\n+        if (!isPartialAggregationPushdownEnabled(session)) {\n+            return maxSubplan;\n+        }\n+        return maxSubplan.accept(new Visitor(variableAllocator, session, idAllocator), null);\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final ConnectorSession session;\n+        private final VariableAllocator variableAllocator;\n+\n+        public Visitor(VariableAllocator variableAllocator, ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = session;\n+            this.idAllocator = idAllocator;\n+            this.variableAllocator = variableAllocator;\n+        }\n+\n+        private Optional<PlanNode> tryPartialAggregationPushdown(PlanNode plan)\n+        {\n+            if (!(plan instanceof AggregationNode\n+                    && ((AggregationNode) plan).getStep().equals(PARTIAL)\n+                    && ((AggregationNode) plan).getSource() instanceof TableScanNode)) {\n+                return Optional.empty();\n+            }\n+\n+            AggregationNode partialAggregationNode = (AggregationNode) plan;\n+            if (partialAggregationNode.hasNonEmptyGroupingSet()) {\n+                return Optional.empty();\n+            }\n+            TableScanNode oldTableScanNode = (TableScanNode) partialAggregationNode.getSource();\n+            TableHandle oldTableHandle = oldTableScanNode.getTable();\n+            HiveTableHandle hiveTableHandle = getHiveTableHandle(oldTableScanNode).orElseThrow(() -> new PrestoException(NOT_FOUND, \"Hive table handle not found\"));\n+\n+            ConnectorTableMetadata connectorTableMetadata = metadataFactory.get().getTableMetadata(session, oldTableHandle.getConnectorHandle());\n+            Optional<Object> rawFormat = Optional.ofNullable(connectorTableMetadata.getProperties().get(HiveTableProperties.STORAGE_FORMAT_PROPERTY));\n+            if (!rawFormat.isPresent()) {\n+                return Optional.empty();\n+            }\n+            final HiveStorageFormat hiveStorageFormat = HiveStorageFormat.valueOf(rawFormat.get().toString());\n+            if (hiveStorageFormat != HiveStorageFormat.ORC && hiveStorageFormat != HiveStorageFormat.PARQUET) {\n+                return Optional.empty();\n+            }\n+\n+            /**\n+             * Aggregation push downs are supported only on primitive types and supported aggregation functions are:\n+             * count(*), count(columnName), min(columnName), max(columnName)\n+             */\n+            for (AggregationNode.Aggregation aggregation : partialAggregationNode.getAggregations().values()) {\n+                FunctionHandle functionHandle = aggregation.getFunctionHandle();\n+                if (!(standardFunctionResolution.isCountFunction(functionHandle) ||\n+                        standardFunctionResolution.isMaxFunction(functionHandle) ||\n+                        standardFunctionResolution.isMinFunction(functionHandle))) {\n+                    return Optional.empty();\n+                }\n+\n+                if (aggregation.getArguments().isEmpty() && !standardFunctionResolution.isCountFunction(functionHandle)) {\n+                    return Optional.empty();\n+                }\n+\n+                List<RowExpression> arguments = aggregation.getArguments();\n+                if (arguments.size() > 1) {\n+                    return Optional.empty();\n+                }\n+\n+                if (standardFunctionResolution.isMinFunction(functionHandle) || standardFunctionResolution.isMaxFunction(functionHandle)) {\n+                    // Only allow supported datatypes for min/max\n+                    Type type = arguments.get(0).getType();\n+                    if (BOOLEAN.equals(type) ||\n+                            type.getJavaType() == boolean.class ||\n+                            isRowType(type) ||\n+                            isArrayType(type) ||\n+                            isMapType(type)) {\n+                        return Optional.empty();\n+                    }\n+\n+                    if (hiveStorageFormat == HiveStorageFormat.ORC) {\n+                        if (TINYINT.equals(type) ||\n+                                VARBINARY.equals(type) ||\n+                                TIMESTAMP.equals(type)) {\n+                            return Optional.empty();\n+                        }\n+                    }\n+\n+                    if ((VARBINARY.equals(type) || VARCHAR.equals(type)) &&\n+                            !isPartialAggregationPushdownForVariableLengthDatatypesEnabled(session)) {\n+                        return Optional.empty();\n+                    }\n+                }\n+            }\n+\n+            HiveTypeTranslator hiveTypeTranslator = new HiveTypeTranslator();\n+            Map<VariableReferenceExpression, ColumnHandle> assignments = new HashMap<>();\n+            for (Map.Entry<VariableReferenceExpression, AggregationNode.Aggregation> aggregationEntry : partialAggregationNode.getAggregations().entrySet()) {\n+                CallExpression callExpression = aggregationEntry.getValue().getCall();\n+                String colName = \"count_star\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU3MzI1Ng==", "bodyText": "Curious: where does this -20 come from?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478573256", "createdAt": "2020-08-27T17:14:45Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.common.type.VarcharType.VARCHAR;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownForVariableLengthDatatypesEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    @Inject\n+    public HivePartialAggregationPushdown(\n+            FunctionMetadataManager functionMetadataManager,\n+            StandardFunctionResolution standardFunctionResolution,\n+            Supplier<TransactionalMetadata> metadataFactory)\n+    {\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"function manager is null\");\n+        this.standardFunctionResolution = requireNonNull(standardFunctionResolution, \"standard function resolution is null\");\n+        this.metadataFactory = requireNonNull(metadataFactory, \"metadata factory is null\");\n+    }\n+\n+    private static Optional<HiveTableHandle> getHiveTableHandle(TableScanNode tableScanNode)\n+    {\n+        TableHandle table = tableScanNode.getTable();\n+        if (table != null) {\n+            ConnectorTableHandle connectorHandle = table.getConnectorHandle();\n+            if (connectorHandle instanceof HiveTableHandle) {\n+                return Optional.of((HiveTableHandle) connectorHandle);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static PlanNode replaceChildren(PlanNode node, List<PlanNode> children)\n+    {\n+        return children.containsAll(node.getSources()) ? node : node.replaceChildren(children);\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan,\n+            ConnectorSession session,\n+            VariableAllocator variableAllocator,\n+            PlanNodeIdAllocator idAllocator)\n+    {\n+        if (!isPartialAggregationPushdownEnabled(session)) {\n+            return maxSubplan;\n+        }\n+        return maxSubplan.accept(new Visitor(variableAllocator, session, idAllocator), null);\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final ConnectorSession session;\n+        private final VariableAllocator variableAllocator;\n+\n+        public Visitor(VariableAllocator variableAllocator, ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = session;\n+            this.idAllocator = idAllocator;\n+            this.variableAllocator = variableAllocator;\n+        }\n+\n+        private Optional<PlanNode> tryPartialAggregationPushdown(PlanNode plan)\n+        {\n+            if (!(plan instanceof AggregationNode\n+                    && ((AggregationNode) plan).getStep().equals(PARTIAL)\n+                    && ((AggregationNode) plan).getSource() instanceof TableScanNode)) {\n+                return Optional.empty();\n+            }\n+\n+            AggregationNode partialAggregationNode = (AggregationNode) plan;\n+            if (partialAggregationNode.hasNonEmptyGroupingSet()) {\n+                return Optional.empty();\n+            }\n+            TableScanNode oldTableScanNode = (TableScanNode) partialAggregationNode.getSource();\n+            TableHandle oldTableHandle = oldTableScanNode.getTable();\n+            HiveTableHandle hiveTableHandle = getHiveTableHandle(oldTableScanNode).orElseThrow(() -> new PrestoException(NOT_FOUND, \"Hive table handle not found\"));\n+\n+            ConnectorTableMetadata connectorTableMetadata = metadataFactory.get().getTableMetadata(session, oldTableHandle.getConnectorHandle());\n+            Optional<Object> rawFormat = Optional.ofNullable(connectorTableMetadata.getProperties().get(HiveTableProperties.STORAGE_FORMAT_PROPERTY));\n+            if (!rawFormat.isPresent()) {\n+                return Optional.empty();\n+            }\n+            final HiveStorageFormat hiveStorageFormat = HiveStorageFormat.valueOf(rawFormat.get().toString());\n+            if (hiveStorageFormat != HiveStorageFormat.ORC && hiveStorageFormat != HiveStorageFormat.PARQUET) {\n+                return Optional.empty();\n+            }\n+\n+            /**\n+             * Aggregation push downs are supported only on primitive types and supported aggregation functions are:\n+             * count(*), count(columnName), min(columnName), max(columnName)\n+             */\n+            for (AggregationNode.Aggregation aggregation : partialAggregationNode.getAggregations().values()) {\n+                FunctionHandle functionHandle = aggregation.getFunctionHandle();\n+                if (!(standardFunctionResolution.isCountFunction(functionHandle) ||\n+                        standardFunctionResolution.isMaxFunction(functionHandle) ||\n+                        standardFunctionResolution.isMinFunction(functionHandle))) {\n+                    return Optional.empty();\n+                }\n+\n+                if (aggregation.getArguments().isEmpty() && !standardFunctionResolution.isCountFunction(functionHandle)) {\n+                    return Optional.empty();\n+                }\n+\n+                List<RowExpression> arguments = aggregation.getArguments();\n+                if (arguments.size() > 1) {\n+                    return Optional.empty();\n+                }\n+\n+                if (standardFunctionResolution.isMinFunction(functionHandle) || standardFunctionResolution.isMaxFunction(functionHandle)) {\n+                    // Only allow supported datatypes for min/max\n+                    Type type = arguments.get(0).getType();\n+                    if (BOOLEAN.equals(type) ||\n+                            type.getJavaType() == boolean.class ||\n+                            isRowType(type) ||\n+                            isArrayType(type) ||\n+                            isMapType(type)) {\n+                        return Optional.empty();\n+                    }\n+\n+                    if (hiveStorageFormat == HiveStorageFormat.ORC) {\n+                        if (TINYINT.equals(type) ||\n+                                VARBINARY.equals(type) ||\n+                                TIMESTAMP.equals(type)) {\n+                            return Optional.empty();\n+                        }\n+                    }\n+\n+                    if ((VARBINARY.equals(type) || VARCHAR.equals(type)) &&\n+                            !isPartialAggregationPushdownForVariableLengthDatatypesEnabled(session)) {\n+                        return Optional.empty();\n+                    }\n+                }\n+            }\n+\n+            HiveTypeTranslator hiveTypeTranslator = new HiveTypeTranslator();\n+            Map<VariableReferenceExpression, ColumnHandle> assignments = new HashMap<>();\n+            for (Map.Entry<VariableReferenceExpression, AggregationNode.Aggregation> aggregationEntry : partialAggregationNode.getAggregations().entrySet()) {\n+                CallExpression callExpression = aggregationEntry.getValue().getCall();\n+                String colName = \"count_star\";\n+                int columnIndex = -20;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU3NDA3Mw==", "bodyText": "Will always returning 0 here has side effect?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478574073", "createdAt": "2020-08-27T17:16:13Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/orc/AggregatedOrcPageSource.java", "diffHunk": "@@ -0,0 +1,253 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.orc;\n+\n+import com.facebook.presto.common.Page;\n+import com.facebook.presto.common.block.Block;\n+import com.facebook.presto.common.block.BlockBuilder;\n+import com.facebook.presto.common.type.Decimals;\n+import com.facebook.presto.common.type.FixedWidthType;\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.common.type.TypeManager;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveType;\n+import com.facebook.presto.orc.metadata.Footer;\n+import com.facebook.presto.orc.metadata.OrcType;\n+import com.facebook.presto.orc.metadata.statistics.ColumnStatistics;\n+import com.facebook.presto.spi.ConnectorPageSource;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import io.airlift.slice.Slice;\n+\n+import java.io.IOException;\n+import java.math.BigDecimal;\n+import java.util.List;\n+\n+import static java.lang.Float.floatToRawIntBits;\n+import static java.util.Objects.requireNonNull;\n+\n+public class AggregatedOrcPageSource\n+        implements ConnectorPageSource\n+{\n+    private final List<HiveColumnHandle> columnHandles;\n+    private final Footer footer;\n+    private final TypeManager typeManager;\n+    private final StandardFunctionResolution functionResolution;\n+\n+    private boolean completed;\n+    private long readTimeNanos;\n+    private long completedBytes;\n+\n+    public AggregatedOrcPageSource(List<HiveColumnHandle> columnHandles, Footer footer, TypeManager typeManager, StandardFunctionResolution functionResolution)\n+    {\n+        this.columnHandles = requireNonNull(columnHandles, \"columnHandles is null\");\n+        this.footer = requireNonNull(footer, \"footer is null\");\n+        this.typeManager = requireNonNull(typeManager, \"typeManager is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+    }\n+\n+    @Override\n+    public long getCompletedBytes()\n+    {\n+        return completedBytes;\n+    }\n+\n+    @Override\n+    public long getCompletedPositions()\n+    {\n+        return 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU4MTQxNQ==", "bodyText": "Since this always 1 any way, maybe make it a static constant?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478581415", "createdAt": "2020-08-27T17:29:09Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/orc/AggregatedOrcPageSource.java", "diffHunk": "@@ -0,0 +1,253 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.orc;\n+\n+import com.facebook.presto.common.Page;\n+import com.facebook.presto.common.block.Block;\n+import com.facebook.presto.common.block.BlockBuilder;\n+import com.facebook.presto.common.type.Decimals;\n+import com.facebook.presto.common.type.FixedWidthType;\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.common.type.TypeManager;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveType;\n+import com.facebook.presto.orc.metadata.Footer;\n+import com.facebook.presto.orc.metadata.OrcType;\n+import com.facebook.presto.orc.metadata.statistics.ColumnStatistics;\n+import com.facebook.presto.spi.ConnectorPageSource;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import io.airlift.slice.Slice;\n+\n+import java.io.IOException;\n+import java.math.BigDecimal;\n+import java.util.List;\n+\n+import static java.lang.Float.floatToRawIntBits;\n+import static java.util.Objects.requireNonNull;\n+\n+public class AggregatedOrcPageSource\n+        implements ConnectorPageSource\n+{\n+    private final List<HiveColumnHandle> columnHandles;\n+    private final Footer footer;\n+    private final TypeManager typeManager;\n+    private final StandardFunctionResolution functionResolution;\n+\n+    private boolean completed;\n+    private long readTimeNanos;\n+    private long completedBytes;\n+\n+    public AggregatedOrcPageSource(List<HiveColumnHandle> columnHandles, Footer footer, TypeManager typeManager, StandardFunctionResolution functionResolution)\n+    {\n+        this.columnHandles = requireNonNull(columnHandles, \"columnHandles is null\");\n+        this.footer = requireNonNull(footer, \"footer is null\");\n+        this.typeManager = requireNonNull(typeManager, \"typeManager is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+    }\n+\n+    @Override\n+    public long getCompletedBytes()\n+    {\n+        return completedBytes;\n+    }\n+\n+    @Override\n+    public long getCompletedPositions()\n+    {\n+        return 0;\n+    }\n+\n+    @Override\n+    public long getReadTimeNanos()\n+    {\n+        return readTimeNanos;\n+    }\n+\n+    @Override\n+    public boolean isFinished()\n+    {\n+        return completed;\n+    }\n+\n+    @Override\n+    public Page getNextPage()\n+    {\n+        if (completed) {\n+            return null;\n+        }\n+\n+        long start = System.nanoTime();\n+\n+        // Prepare the one required record by looking at the aggregations in pipeline and stats in footer\n+        final int batchSize = 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU4NDU2Mg==", "bodyText": "Is it possible to miss completed bytes counting if we enabled variable length data types and the aggregation is min/max?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478584562", "createdAt": "2020-08-27T17:34:17Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/orc/AggregatedOrcPageSource.java", "diffHunk": "@@ -0,0 +1,253 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.orc;\n+\n+import com.facebook.presto.common.Page;\n+import com.facebook.presto.common.block.Block;\n+import com.facebook.presto.common.block.BlockBuilder;\n+import com.facebook.presto.common.type.Decimals;\n+import com.facebook.presto.common.type.FixedWidthType;\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.common.type.TypeManager;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveType;\n+import com.facebook.presto.orc.metadata.Footer;\n+import com.facebook.presto.orc.metadata.OrcType;\n+import com.facebook.presto.orc.metadata.statistics.ColumnStatistics;\n+import com.facebook.presto.spi.ConnectorPageSource;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import io.airlift.slice.Slice;\n+\n+import java.io.IOException;\n+import java.math.BigDecimal;\n+import java.util.List;\n+\n+import static java.lang.Float.floatToRawIntBits;\n+import static java.util.Objects.requireNonNull;\n+\n+public class AggregatedOrcPageSource\n+        implements ConnectorPageSource\n+{\n+    private final List<HiveColumnHandle> columnHandles;\n+    private final Footer footer;\n+    private final TypeManager typeManager;\n+    private final StandardFunctionResolution functionResolution;\n+\n+    private boolean completed;\n+    private long readTimeNanos;\n+    private long completedBytes;\n+\n+    public AggregatedOrcPageSource(List<HiveColumnHandle> columnHandles, Footer footer, TypeManager typeManager, StandardFunctionResolution functionResolution)\n+    {\n+        this.columnHandles = requireNonNull(columnHandles, \"columnHandles is null\");\n+        this.footer = requireNonNull(footer, \"footer is null\");\n+        this.typeManager = requireNonNull(typeManager, \"typeManager is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+    }\n+\n+    @Override\n+    public long getCompletedBytes()\n+    {\n+        return completedBytes;\n+    }\n+\n+    @Override\n+    public long getCompletedPositions()\n+    {\n+        return 0;\n+    }\n+\n+    @Override\n+    public long getReadTimeNanos()\n+    {\n+        return readTimeNanos;\n+    }\n+\n+    @Override\n+    public boolean isFinished()\n+    {\n+        return completed;\n+    }\n+\n+    @Override\n+    public Page getNextPage()\n+    {\n+        if (completed) {\n+            return null;\n+        }\n+\n+        long start = System.nanoTime();\n+\n+        // Prepare the one required record by looking at the aggregations in pipeline and stats in footer\n+        final int batchSize = 1;\n+\n+        Block[] blocks = new Block[columnHandles.size()];\n+        for (int fieldId = 0; fieldId < blocks.length; fieldId++) {\n+            HiveColumnHandle columnHandle = columnHandles.get(fieldId);\n+            AggregationNode.Aggregation aggregation = columnHandle.getPartialAggregation().get();\n+            int columnIndex = columnHandle.getHiveColumnIndex();\n+            Type type = typeManager.getType(columnHandle.getTypeSignature());\n+            if (type instanceof FixedWidthType) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NzczOA==", "bodyText": "Do we need a try-catch for close like the existing code?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478667738", "createdAt": "2020-08-27T20:10:17Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/orc/OrcSelectivePageSourceFactory.java", "diffHunk": "@@ -333,6 +334,16 @@ public static OrcSelectivePageSource createOrcPageSource(\n             checkArgument(!domainPredicate.isNone(), \"Unexpected NONE domain\");\n \n             List<HiveColumnHandle> physicalColumns = getPhysicalHiveColumnHandles(columns, useOrcColumnNames, reader, path);\n+\n+            if (!physicalColumns.isEmpty() && physicalColumns.get(0).getColumnType() == AGGREGATED) {\n+                try {\n+                    return new AggregatedOrcPageSource(physicalColumns, reader.getFooter(), typeManager, functionResolution);\n+                }\n+                finally {\n+                    orcDataSource.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2ODU3MQ==", "bodyText": "nit: add try-finally and put DROP TABLE in finally", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478668571", "createdAt": "2020-08-27T20:11:44Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4774,6 +4774,238 @@ public void testPageFileCompression()\n         }\n     }\n \n+    @Test\n+    public void testPartialAggregatePushdownORC()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_orc_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'orc')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_orc_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.ORC);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_shortdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_longdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_string) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varchar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_singlechar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_char) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varbinary) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_date) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_timestamp) FROM test_orc_table\", rowCount);\n+\n+        assertQuery(session, \"SELECT MIN(_boolean), MAX(_boolean) FROM test_orc_table\", \"select false, true\");\n+        assertQuery(session, \"SELECT MIN(_tinyint), MAX(_tinyint) FROM test_orc_table\", \"select 1, 10\");\n+        assertQuery(session, \"SELECT MIN(_smallint), MAX(_smallint) FROM test_orc_table\", \"select 2, 20\");\n+        assertQuery(session, \"SELECT MIN(_integer), MAX(_integer) FROM test_orc_table\", \"select 3, 30\");\n+        assertQuery(session, \"SELECT MIN(_bigint), MAX(_bigint) FROM test_orc_table\", \"select 4, 40\");\n+        assertQuery(session, \"SELECT MIN(_real), MAX(_real) FROM test_orc_table\", \"select 1.2, 10.25\");\n+        assertQuery(session, \"SELECT MIN(_double), MAX(_double) FROM test_orc_table\", \"select 2.3, 25.334\");\n+        assertQuery(session, \"SELECT MIN(_shortdecimal), MAX(_shortdecimal) FROM test_orc_table\", \"select 4.5, 465.523\");\n+        assertQuery(session, \"SELECT MIN(_longdecimal), MAX(_longdecimal) FROM test_orc_table\", \"select 55555555555555.32, 88888888555555.91\");\n+        assertQuery(session, \"SELECT MIN(_string), MAX(_string) FROM test_orc_table\", \"select 'abc', 'foo'\");\n+        assertQuery(session, \"SELECT MIN(_varchar), MAX(_varchar) FROM test_orc_table\", \"select 'bar', 'def'\");\n+        assertQuery(session, \"SELECT MIN(_singlechar), MAX(_singlechar) FROM test_orc_table\", \"select 'b', 'g'\");\n+        assertQuery(session, \"SELECT MIN(_char), MAX(_char) FROM test_orc_table\", \"select 'baz', 'hij'\");\n+        assertQuery(session, \"SELECT MIN(_varbinary), MAX(_varbinary) FROM test_orc_table\", \"select X'6b6c6d', X'717578'\");\n+        assertQuery(session, \"SELECT MIN(_date), MAX(_date) FROM test_orc_table\", \"select cast('2020-05-01' as date), cast('2020-06-02' as date)\");\n+        assertQuery(session, \"SELECT MIN(_timestamp), MAX(_timestamp) FROM test_orc_table\", \"select cast('2020-05-01 18:34:23.88' as timestamp), cast('2020-06-04 16:55:40.777' as timestamp)\");\n+\n+        assertUpdate(session, \"DROP TABLE test_orc_table\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2OTMwMQ==", "bodyText": "I'm not sure if I followed...Should we actually remove these tests that are commented out?", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478669301", "createdAt": "2020-08-27T20:13:09Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4774,6 +4774,238 @@ public void testPageFileCompression()\n         }\n     }\n \n+    @Test\n+    public void testPartialAggregatePushdownORC()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_orc_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'orc')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_orc_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.ORC);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_shortdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_longdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_string) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varchar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_singlechar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_char) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varbinary) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_date) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_timestamp) FROM test_orc_table\", rowCount);\n+\n+        assertQuery(session, \"SELECT MIN(_boolean), MAX(_boolean) FROM test_orc_table\", \"select false, true\");\n+        assertQuery(session, \"SELECT MIN(_tinyint), MAX(_tinyint) FROM test_orc_table\", \"select 1, 10\");\n+        assertQuery(session, \"SELECT MIN(_smallint), MAX(_smallint) FROM test_orc_table\", \"select 2, 20\");\n+        assertQuery(session, \"SELECT MIN(_integer), MAX(_integer) FROM test_orc_table\", \"select 3, 30\");\n+        assertQuery(session, \"SELECT MIN(_bigint), MAX(_bigint) FROM test_orc_table\", \"select 4, 40\");\n+        assertQuery(session, \"SELECT MIN(_real), MAX(_real) FROM test_orc_table\", \"select 1.2, 10.25\");\n+        assertQuery(session, \"SELECT MIN(_double), MAX(_double) FROM test_orc_table\", \"select 2.3, 25.334\");\n+        assertQuery(session, \"SELECT MIN(_shortdecimal), MAX(_shortdecimal) FROM test_orc_table\", \"select 4.5, 465.523\");\n+        assertQuery(session, \"SELECT MIN(_longdecimal), MAX(_longdecimal) FROM test_orc_table\", \"select 55555555555555.32, 88888888555555.91\");\n+        assertQuery(session, \"SELECT MIN(_string), MAX(_string) FROM test_orc_table\", \"select 'abc', 'foo'\");\n+        assertQuery(session, \"SELECT MIN(_varchar), MAX(_varchar) FROM test_orc_table\", \"select 'bar', 'def'\");\n+        assertQuery(session, \"SELECT MIN(_singlechar), MAX(_singlechar) FROM test_orc_table\", \"select 'b', 'g'\");\n+        assertQuery(session, \"SELECT MIN(_char), MAX(_char) FROM test_orc_table\", \"select 'baz', 'hij'\");\n+        assertQuery(session, \"SELECT MIN(_varbinary), MAX(_varbinary) FROM test_orc_table\", \"select X'6b6c6d', X'717578'\");\n+        assertQuery(session, \"SELECT MIN(_date), MAX(_date) FROM test_orc_table\", \"select cast('2020-05-01' as date), cast('2020-06-02' as date)\");\n+        assertQuery(session, \"SELECT MIN(_timestamp), MAX(_timestamp) FROM test_orc_table\", \"select cast('2020-05-01 18:34:23.88' as timestamp), cast('2020-06-04 16:55:40.777' as timestamp)\");\n+\n+        assertUpdate(session, \"DROP TABLE test_orc_table\");\n+\n+        assertFalse(getQueryRunner().tableExists(session, \"test_orc_table\"));\n+    }\n+\n+    @Test\n+    public void testPartialAggregatePushdownParquet()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_parquet_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'parquet')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_parquet_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.PARQUET);\n+\n+        assertUpdate(session, \"INSERT INTO test_parquet_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_parquet_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_parquet_table\", rowCount);\n+        // The default Parquet writer does not populate statistics for these datatypes\n+        // though they are populated by hive etl tasks\n+        /*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2OTM2Nw==", "bodyText": "ditto on try-finally", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478669367", "createdAt": "2020-08-27T20:13:17Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4774,6 +4774,238 @@ public void testPageFileCompression()\n         }\n     }\n \n+    @Test\n+    public void testPartialAggregatePushdownORC()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_orc_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'orc')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_orc_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.ORC);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_shortdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_longdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_string) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varchar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_singlechar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_char) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varbinary) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_date) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_timestamp) FROM test_orc_table\", rowCount);\n+\n+        assertQuery(session, \"SELECT MIN(_boolean), MAX(_boolean) FROM test_orc_table\", \"select false, true\");\n+        assertQuery(session, \"SELECT MIN(_tinyint), MAX(_tinyint) FROM test_orc_table\", \"select 1, 10\");\n+        assertQuery(session, \"SELECT MIN(_smallint), MAX(_smallint) FROM test_orc_table\", \"select 2, 20\");\n+        assertQuery(session, \"SELECT MIN(_integer), MAX(_integer) FROM test_orc_table\", \"select 3, 30\");\n+        assertQuery(session, \"SELECT MIN(_bigint), MAX(_bigint) FROM test_orc_table\", \"select 4, 40\");\n+        assertQuery(session, \"SELECT MIN(_real), MAX(_real) FROM test_orc_table\", \"select 1.2, 10.25\");\n+        assertQuery(session, \"SELECT MIN(_double), MAX(_double) FROM test_orc_table\", \"select 2.3, 25.334\");\n+        assertQuery(session, \"SELECT MIN(_shortdecimal), MAX(_shortdecimal) FROM test_orc_table\", \"select 4.5, 465.523\");\n+        assertQuery(session, \"SELECT MIN(_longdecimal), MAX(_longdecimal) FROM test_orc_table\", \"select 55555555555555.32, 88888888555555.91\");\n+        assertQuery(session, \"SELECT MIN(_string), MAX(_string) FROM test_orc_table\", \"select 'abc', 'foo'\");\n+        assertQuery(session, \"SELECT MIN(_varchar), MAX(_varchar) FROM test_orc_table\", \"select 'bar', 'def'\");\n+        assertQuery(session, \"SELECT MIN(_singlechar), MAX(_singlechar) FROM test_orc_table\", \"select 'b', 'g'\");\n+        assertQuery(session, \"SELECT MIN(_char), MAX(_char) FROM test_orc_table\", \"select 'baz', 'hij'\");\n+        assertQuery(session, \"SELECT MIN(_varbinary), MAX(_varbinary) FROM test_orc_table\", \"select X'6b6c6d', X'717578'\");\n+        assertQuery(session, \"SELECT MIN(_date), MAX(_date) FROM test_orc_table\", \"select cast('2020-05-01' as date), cast('2020-06-02' as date)\");\n+        assertQuery(session, \"SELECT MIN(_timestamp), MAX(_timestamp) FROM test_orc_table\", \"select cast('2020-05-01 18:34:23.88' as timestamp), cast('2020-06-04 16:55:40.777' as timestamp)\");\n+\n+        assertUpdate(session, \"DROP TABLE test_orc_table\");\n+\n+        assertFalse(getQueryRunner().tableExists(session, \"test_orc_table\"));\n+    }\n+\n+    @Test\n+    public void testPartialAggregatePushdownParquet()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_parquet_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'parquet')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_parquet_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.PARQUET);\n+\n+        assertUpdate(session, \"INSERT INTO test_parquet_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_parquet_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_parquet_table\", rowCount);\n+        // The default Parquet writer does not populate statistics for these datatypes\n+        // though they are populated by hive etl tasks\n+        /*\n+        assertQuery(session, \"SELECT COUNT(_shortdecimal) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_longdecimal) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_string) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varchar) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_singlechar) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_char) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varbinary) FROM test_parquet_table\", rowCount);\n+         */\n+        assertQuery(session, \"SELECT COUNT(_date) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_timestamp) FROM test_parquet_table\", rowCount);\n+\n+        assertQuery(session, \"SELECT MIN(_boolean), MAX(_boolean) FROM test_parquet_table\", \"select false, true\");\n+        assertQuery(session, \"SELECT MIN(_tinyint), MAX(_tinyint) FROM test_parquet_table\", \"select 1, 10\");\n+        assertQuery(session, \"SELECT MIN(_smallint), MAX(_smallint) FROM test_parquet_table\", \"select 2, 20\");\n+        assertQuery(session, \"SELECT MIN(_integer), MAX(_integer) FROM test_parquet_table\", \"select 3, 30\");\n+        assertQuery(session, \"SELECT MIN(_bigint), MAX(_bigint) FROM test_parquet_table\", \"select 4, 40\");\n+        assertQuery(session, \"SELECT MIN(_real), MAX(_real) FROM test_parquet_table\", \"select 1.2, 10.25\");\n+        assertQuery(session, \"SELECT MIN(_double), MAX(_double) FROM test_parquet_table\", \"select 2.3, 25.334\");\n+        // The default Parquet writer does not populate statistics for these datatypes\n+        // though they are populated by hive etl tasks\n+        /*\n+        assertQuery(session, \"SELECT MIN(_shortdecimal), MAX(_shortdecimal) FROM test_parquet_table\", \"select 4.5, 465.523\");\n+        assertQuery(session, \"SELECT MIN(_longdecimal), MAX(_longdecimal) FROM test_parquet_table\", \"select 55555555555555.32, 88888888555555.91\");\n+        assertQuery(session, \"SELECT MIN(_string), MAX(_string) FROM test_parquet_table\", \"select 'abc', 'foo'\");\n+        assertQuery(session, \"SELECT MIN(_varchar), MAX(_varchar) FROM test_parquet_table\", \"select 'bar', 'def'\");\n+        assertQuery(session, \"SELECT MIN(_singlechar), MAX(_singlechar) FROM test_parquet_table\", \"select 'b', 'g'\");\n+        assertQuery(session, \"SELECT MIN(_char), MAX(_char) FROM test_parquet_table\", \"select 'baz', 'hij'\");\n+        assertQuery(session, \"SELECT MIN(_varbinary), MAX(_varbinary) FROM test_orc_table\", \"select X'6b6c6d', X'717578'\");\n+         */\n+        assertQuery(session, \"SELECT MIN(_date), MAX(_date) FROM test_parquet_table\", \"select cast('2020-05-01' as date), cast('2020-06-02' as date)\");\n+        assertQuery(session, \"SELECT MIN(_timestamp), MAX(_timestamp) FROM test_parquet_table\", \"select cast('2020-05-01 18:34:23.88' as timestamp), cast('2020-06-04 16:55:40.777' as timestamp)\");\n+\n+        assertUpdate(session, \"DROP TABLE test_parquet_table\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed800f1a7409eda550397f6d76b1141764aae662"}, "originalPosition": 231}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "42ee4bfac6a0e72946253b634f9f8898b747be93", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/42ee4bfac6a0e72946253b634f9f8898b747be93", "committedDate": "2020-08-30T23:09:51Z", "message": "code review"}, "afterCommit": {"oid": "9d1bb5e78118b1c8a5c6b5b63ea5df57d87573f7", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/9d1bb5e78118b1c8a5c6b5b63ea5df57d87573f7", "committedDate": "2020-08-31T15:47:08Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9d1bb5e78118b1c8a5c6b5b63ea5df57d87573f7", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/9d1bb5e78118b1c8a5c6b5b63ea5df57d87573f7", "committedDate": "2020-08-31T15:47:08Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "c253c32099e0bacb3bdeb90228ba378de1e4f959", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/c253c32099e0bacb3bdeb90228ba378de1e4f959", "committedDate": "2020-09-01T04:52:39Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c253c32099e0bacb3bdeb90228ba378de1e4f959", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/c253c32099e0bacb3bdeb90228ba378de1e4f959", "committedDate": "2020-09-01T04:52:39Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "f4f9bfc59e9a1da93a03d494191d433ae49a46b1", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/f4f9bfc59e9a1da93a03d494191d433ae49a46b1", "committedDate": "2020-09-01T05:15:57Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f4f9bfc59e9a1da93a03d494191d433ae49a46b1", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/f4f9bfc59e9a1da93a03d494191d433ae49a46b1", "committedDate": "2020-09-01T05:15:57Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "ef26c0bf20ab0ab56b148620b5c956e30927e86f", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/ef26c0bf20ab0ab56b148620b5c956e30927e86f", "committedDate": "2020-09-02T18:39:54Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyMjE2MTEx", "url": "https://github.com/prestodb/presto/pull/14834#pullrequestreview-482216111", "createdAt": "2020-09-03T21:29:26Z", "commit": {"oid": "ef26c0bf20ab0ab56b148620b5c956e30927e86f"}, "state": "APPROVED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QyMToyOToyN1rOHM4HYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QyMjowOTo0NlrOHM5GCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI2NDM1Mw==", "bodyText": "nit: hive.partial_aggregation_pushdown_enabled", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483264353", "createdAt": "2020-09-03T21:29:27Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1452,4 +1455,30 @@ public boolean isParquetDereferencePushdownEnabled()\n     {\n         return this.parquetDereferencePushdownEnabled;\n     }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef26c0bf20ab0ab56b148620b5c956e30927e86f"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI2NDUzNg==", "bodyText": "nit: hive.partial_aggregation_pushdown_for_variable_length_datatypes_enabled", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483264536", "createdAt": "2020-09-03T21:29:51Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1452,4 +1455,30 @@ public boolean isParquetDereferencePushdownEnabled()\n     {\n         return this.parquetDereferencePushdownEnabled;\n     }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown\")\n+    @ConfigDescription(\"enable partial aggregation pushdown\")\n+    public HiveClientConfig setPartialAggregationPushdownEnabled(boolean partialAggregationPushdownEnabled)\n+    {\n+        this.isPartialAggregationPushdownEnabled = partialAggregationPushdownEnabled;\n+        return this;\n+    }\n+\n+    public boolean isPartialAggregationPushdownEnabled()\n+    {\n+        return this.isPartialAggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown_for_variable_length_datatypes\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef26c0bf20ab0ab56b148620b5c956e30927e86f"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI2NjczMg==", "bodyText": "nit: How about making it final and renaming it DUMMY_AGGREGATED_COLUMN_INDEX", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483266732", "createdAt": "2020-09-03T21:34:54Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.common.type.VarcharType.VARCHAR;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownForVariableLengthDatatypesEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    private static int aggregatedColumnIndexDummy = -20;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef26c0bf20ab0ab56b148620b5c956e30927e86f"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3OTE0Mg==", "bodyText": "nit: PARTIAL_AGGREGATION_PUSHDOWN_ENABLED", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483279142", "createdAt": "2020-09-03T22:06:26Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveSessionProperties.java", "diffHunk": "@@ -496,6 +498,16 @@ public HiveSessionProperties(HiveClientConfig hiveClientConfig, OrcFileWriterCon\n                         PARQUET_DEREFERENCE_PUSHDOWN_ENABLED,\n                         \"Is dereference pushdown expression pushdown into Parquet reader enabled?\",\n                         hiveClientConfig.isParquetDereferencePushdownEnabled(),\n+                        false),\n+                booleanProperty(\n+                        ENABLE_PARTIAL_AGGREGATION_PUSHDOWN,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef26c0bf20ab0ab56b148620b5c956e30927e86f"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3OTIxNg==", "bodyText": "nit: PARTIAL_AGGREGATION_PUSHDOWN_FOR_VARIABLE_LENGTH_DATATYPES_ENABLED", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483279216", "createdAt": "2020-09-03T22:06:39Z", "author": {"login": "shixuan-fan"}, "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveSessionProperties.java", "diffHunk": "@@ -496,6 +498,16 @@ public HiveSessionProperties(HiveClientConfig hiveClientConfig, OrcFileWriterCon\n                         PARQUET_DEREFERENCE_PUSHDOWN_ENABLED,\n                         \"Is dereference pushdown expression pushdown into Parquet reader enabled?\",\n                         hiveClientConfig.isParquetDereferencePushdownEnabled(),\n+                        false),\n+                booleanProperty(\n+                        ENABLE_PARTIAL_AGGREGATION_PUSHDOWN,\n+                        \"Is partial aggregation pushdown enabled for Hive file formats\",\n+                        hiveClientConfig.isPartialAggregationPushdownEnabled(),\n+                        false),\n+                booleanProperty(\n+                        ENABLE_PARTIAL_AGGREGATION_PUSHDOWN_FOR_VARIABLE_LENGTH_DATATYPES,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef26c0bf20ab0ab56b148620b5c956e30927e86f"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4MDM5NA==", "bodyText": "nit: Let's extract this and make it a boolean function", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483280394", "createdAt": "2020-09-03T22:09:46Z", "author": {"login": "shixuan-fan"}, "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/sanity/ValidateAggregationsWithDefaultValues.java", "diffHunk": "@@ -103,6 +104,15 @@ public void validate(PlanNode planNode, Session session, Metadata metadata, SqlP\n             if (!node.getStep().equals(FINAL) || !node.hasEmptyGroupingSet()) {\n                 return Optional.empty();\n             }\n+            // TODO - hack to allow partial aggregation pushdown\n+            if (node.getStep().equals(FINAL)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef26c0bf20ab0ab56b148620b5c956e30927e86f"}, "originalPosition": 13}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2a4879dfcb56d8e399f07cd3810a99c843286ffe", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/2a4879dfcb56d8e399f07cd3810a99c843286ffe", "committedDate": "2020-09-03T22:34:20Z", "message": "Merge branch 'master' of github.com:prestodb/presto into partialaggpushdown"}, "afterCommit": {"oid": "35878762491941f4bb2f93a35ca916039fac7c45", "author": {"user": {"login": "shixuan-fan", "name": "Shixuan Fan"}}, "url": "https://github.com/prestodb/presto/commit/35878762491941f4bb2f93a35ca916039fac7c45", "committedDate": "2020-09-04T04:18:22Z", "message": "Make equals() and hashCode() consistent in TableHandle"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "35878762491941f4bb2f93a35ca916039fac7c45", "author": {"user": {"login": "shixuan-fan", "name": "Shixuan Fan"}}, "url": "https://github.com/prestodb/presto/commit/35878762491941f4bb2f93a35ca916039fac7c45", "committedDate": "2020-09-04T04:18:22Z", "message": "Make equals() and hashCode() consistent in TableHandle"}, "afterCommit": {"oid": "275e21f081c7c6bbd486f326f411ada82fb00a6e", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/275e21f081c7c6bbd486f326f411ada82fb00a6e", "committedDate": "2020-09-04T05:15:40Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "275e21f081c7c6bbd486f326f411ada82fb00a6e", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/275e21f081c7c6bbd486f326f411ada82fb00a6e", "committedDate": "2020-09-04T05:15:40Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "5c002ea74487a9772949a47a4c11c4e59c1fa1e6", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/5c002ea74487a9772949a47a4c11c4e59c1fa1e6", "committedDate": "2020-09-04T16:12:52Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5c002ea74487a9772949a47a4c11c4e59c1fa1e6", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/5c002ea74487a9772949a47a4c11c4e59c1fa1e6", "committedDate": "2020-09-04T16:12:52Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "8764c46fb0ff24d8306135ee1c17a033f6978aaa", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/8764c46fb0ff24d8306135ee1c17a033f6978aaa", "committedDate": "2020-09-04T22:34:06Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "693d63d63914a14eb31cabf288b17e04a8d05221", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/693d63d63914a14eb31cabf288b17e04a8d05221", "committedDate": "2020-09-05T18:17:04Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8764c46fb0ff24d8306135ee1c17a033f6978aaa", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/8764c46fb0ff24d8306135ee1c17a033f6978aaa", "committedDate": "2020-09-04T22:34:06Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}, "afterCommit": {"oid": "693d63d63914a14eb31cabf288b17e04a8d05221", "author": {"user": {"login": "ClarenceThreepwood", "name": "Vivek"}}, "url": "https://github.com/prestodb/presto/commit/693d63d63914a14eb31cabf288b17e04a8d05221", "committedDate": "2020-09-05T18:17:04Z", "message": "Partial Aggregation Pushdown for ORC/Parquet"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1259, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}