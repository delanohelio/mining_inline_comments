{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc1MTMwMDI0", "number": 14099, "title": "Implement row base exchange in Presto on Spark", "bodyText": "== NO RELEASE NOTE ==", "createdAt": "2020-02-13T22:59:48Z", "url": "https://github.com/prestodb/presto/pull/14099", "merged": true, "mergeCommit": {"oid": "6eb0293532a3151eb4818efdfec8c4b264a7a538"}, "closed": true, "closedAt": "2020-02-25T21:48:14Z", "author": {"login": "arhimondr"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcFwsNTAFqTM2MDg2ODU2OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcH5Qu2gFqTM2NDQ3MjM3NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwODY4NTY4", "url": "https://github.com/prestodb/presto/pull/14099#pullrequestreview-360868568", "createdAt": "2020-02-19T06:32:24Z", "commit": {"oid": "435878e8d9dee686a3b53d573aef2663db3fb5b5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNjozMjoyNFrOFrcdtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNjozMjoyNFrOFrcdtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA5OTQ0NQ==", "bodyText": "unrelated change? -- since the original RLE block is also a valid representation for all nulls block?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381099445", "createdAt": "2020-02-19T06:32:24Z", "author": {"login": "wenleix"}, "path": "presto-main/src/test/java/com/facebook/presto/block/BlockAssertions.java", "diffHunk": "@@ -115,7 +115,11 @@ public static void assertBlockEquals(Type type, Block actual, Block expected)\n \n     public static Block createAllNullsBlock(Type type, int positionCount)\n     {\n-        return new RunLengthEncodedBlock(type.createBlockBuilder(null, 1).appendNull().build(), positionCount);\n+        BlockBuilder blockBuilder = type.createBlockBuilder(null, 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "435878e8d9dee686a3b53d573aef2663db3fb5b5"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwODc1NjA3", "url": "https://github.com/prestodb/presto/pull/14099#pullrequestreview-360875607", "createdAt": "2020-02-19T06:53:34Z", "commit": {"oid": "3dae179722b363137ef8997d4c5fe4477e9d982c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNjo1MzozNFrOFrc0DQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNjo1MzozNFrOFrc0DQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEwNTE2NQ==", "bodyText": "So this OutputPartitioning is only required by PartitionedOutputOperatorFactory right? (and later PrestoSparkOutputFactory)? Maybe check argument in other OutputFactory that this shouldn't present", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381105165", "createdAt": "2020-02-19T06:53:34Z", "author": {"login": "wenleix"}, "path": "presto-main/src/main/java/com/facebook/presto/operator/OutputFactory.java", "diffHunk": "@@ -17,11 +17,19 @@\n import com.facebook.presto.spi.Page;\n import com.facebook.presto.spi.plan.PlanNodeId;\n import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n \n import java.util.List;\n+import java.util.Optional;\n import java.util.function.Function;\n \n public interface OutputFactory\n {\n-    OperatorFactory createOutputOperator(int operatorId, PlanNodeId planNodeId, List<Type> types, Function<Page, Page> pagePreprocessor, PagesSerdeFactory serdeFactory);\n+    OperatorFactory createOutputOperator(\n+            int operatorId,\n+            PlanNodeId planNodeId,\n+            List<Type> types,\n+            Function<Page, Page> pagePreprocessor,\n+            Optional<OutputPartitioning> outputPartitioning,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3dae179722b363137ef8997d4c5fe4477e9d982c"}, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwODc2NzY3", "url": "https://github.com/prestodb/presto/pull/14099#pullrequestreview-360876767", "createdAt": "2020-02-19T06:56:58Z", "commit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxNTE2NTA0", "url": "https://github.com/prestodb/presto/pull/14099#pullrequestreview-361516504", "createdAt": "2020-02-19T23:34:03Z", "commit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQyMzozNDowNFrOFr7j6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNTozODozOFrOFsFpRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYwODkzNw==", "bodyText": "When outputPartitioning is not present, in PrestoSparkOutputFactory  it means it's SINGLE_PARTITION, but it's not necessary the case for other OutputFactory right? For example, in", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381608937", "createdAt": "2020-02-19T23:34:04Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYyOTQ0MQ==", "bodyText": "what does replicateNullsAndAny mean? In PartitionedOutputOperator, the variable name is replicatesAnyRow", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381629441", "createdAt": "2020-02-20T00:42:08Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2NzA4NA==", "bodyText": "So PrestoSparkRowBuffer#get is a blocked call. Is there any reason for that -- I am asking this since the general convention in Presto seems to be using ListenableFuture<PrestoSparkRow> for such cases?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381767084", "createdAt": "2020-02-20T05:24:04Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;\n+\n+    public PrestoSparkRowBuffer(OutputBufferMemoryManager memoryManager)\n+    {\n+        this.memoryManager = requireNonNull(memoryManager, \"memoryManager is null\");\n+    }\n+\n+    public ListenableFuture<?> isFull()\n+    {\n+        return memoryManager.getBufferBlockedFuture();\n+    }\n+\n+    public void enqueue(PrestoSparkRow row)\n+    {\n+        requireNonNull(row, \"row is null\");\n+        synchronized (monitor) {\n+            buffer.add(row);\n+            monitor.notify();\n+        }\n+        memoryManager.updateMemoryUsage(row.getRetainedSize());\n+    }\n+\n+    public void setNoMoreRows()\n+    {\n+        memoryManager.setNoBlockOnFull();\n+        synchronized (monitor) {\n+            finished = true;\n+            monitor.notifyAll();\n+        }\n+    }\n+\n+    public boolean hasRowsBuffered()\n+    {\n+        synchronized (monitor) {\n+            return !buffer.isEmpty();\n+        }\n+    }\n+\n+    public PrestoSparkRow get()\n+            throws InterruptedException\n+    {\n+        PrestoSparkRow row;\n+        synchronized (monitor) {\n+            while (!finished && buffer.isEmpty()) {\n+                monitor.wait();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2ODM1NQ==", "bodyText": "I guess you intend to avoid create a new DynamicSliceOutput each time so you try to get the underlying byte array directly \ud83d\ude03 . I understand it cannot be done for now since you cannot reset DynamicSliceOutput\nThat being said, we might want to consider add something like reset into SliceOutput?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381768355", "createdAt": "2020-02-20T05:26:42Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;\n+        private final OptionalInt nullChannel;\n+\n+        public PrestoSparkOutputOperatorFactory(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                PrestoSparkRowBuffer rowBuffer,\n+                Function<Page, Page> pagePreprocessor,\n+                PartitionFunction partitionFunction,\n+                List<Integer> partitionChannels,\n+                List<Optional<Block>> partitionConstants,\n+                boolean replicateNullsAndAny,\n+                OptionalInt nullChannel)\n+        {\n+            this.operatorId = operatorId;\n+            this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+            this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+            this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+            this.partitionChannels = requireNonNull(partitionChannels, \"partitionChannels is null\");\n+            this.partitionConstants = requireNonNull(partitionConstants, \"partitionConstants is null\");\n+            this.replicateNullsAndAny = replicateNullsAndAny;\n+            this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+        }\n+\n+        @Override\n+        public Operator createOperator(DriverContext driverContext)\n+        {\n+            OperatorContext operatorContext = driverContext.addOperatorContext(operatorId, planNodeId, PrestoSparkOutputOperator.class.getSimpleName());\n+            return new PrestoSparkOutputOperator(\n+                    operatorContext,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+\n+        @Override\n+        public void noMoreOperators()\n+        {\n+        }\n+\n+        @Override\n+        public OperatorFactory duplicate()\n+        {\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+    }\n+\n+    private final OperatorContext operatorContext;\n+    private final PrestoSparkRowBuffer rowBuffer;\n+    private final Function<Page, Page> pagePreprocessor;\n+    private final PartitionFunction partitionFunction;\n+    private final List<Integer> partitionChannels;\n+    private final List<Optional<Block>> partitionConstants;\n+    private final boolean replicateNullsAndAny;\n+    private final OptionalInt nullChannel;\n+\n+    private boolean finished;\n+    private boolean hasAnyRowBeenReplicated;\n+\n+    public PrestoSparkOutputOperator(\n+            OperatorContext operatorContext,\n+            PrestoSparkRowBuffer rowBuffer,\n+            Function<Page, Page> pagePreprocessor,\n+            PartitionFunction partitionFunction,\n+            List<Integer> partitionChannels,\n+            List<Optional<Block>> partitionConstants,\n+            boolean replicateNullsAndAny,\n+            OptionalInt nullChannel)\n+    {\n+        this.operatorContext = requireNonNull(operatorContext, \"operatorContext is null\");\n+        this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+        this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+        this.partitionChannels = ImmutableList.copyOf(requireNonNull(partitionChannels, \"partitionChannels is null\"));\n+        this.partitionConstants = ImmutableList.copyOf(requireNonNull(partitionConstants, \"partitionConstants is null\"));\n+        this.replicateNullsAndAny = replicateNullsAndAny;\n+        this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+    }\n+\n+    @Override\n+    public OperatorContext getOperatorContext()\n+    {\n+        return operatorContext;\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> isBlocked()\n+    {\n+        return rowBuffer.isFull();\n+    }\n+\n+    @Override\n+    public boolean needsInput()\n+    {\n+        return !finished && isBlocked().isDone();\n+    }\n+\n+    @Override\n+    public void addInput(Page page)\n+    {\n+        page = pagePreprocessor.apply(page);\n+        int positionCount = page.getPositionCount();\n+        int channelCount = page.getChannelCount();\n+        int averageRowSizeInBytes = min(toIntExact(page.getLogicalSizeInBytes() / positionCount), 10);\n+        Page partitionFunctionArguments = getPartitionFunctionArguments(page);\n+        for (int position = 0; position < positionCount; position++) {\n+            SliceOutput output = new DynamicSliceOutput(averageRowSizeInBytes * 2);\n+            for (int channel = 0; channel < channelCount; channel++) {\n+                Block block = page.getBlock(channel);\n+                block.writePositionTo(position, output);\n+            }\n+\n+            boolean shouldReplicate = (replicateNullsAndAny && !hasAnyRowBeenReplicated) ||\n+                    nullChannel.isPresent() && page.getBlock(nullChannel.getAsInt()).isNull(position);\n+            if (shouldReplicate) {\n+                for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n+                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), output.getUnderlyingSlice().byteArray()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 247}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTU1Mg==", "bodyText": "is this enough -- do we want to make sure rowBuffer is empty?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381769552", "createdAt": "2020-02-20T05:29:01Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;\n+        private final OptionalInt nullChannel;\n+\n+        public PrestoSparkOutputOperatorFactory(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                PrestoSparkRowBuffer rowBuffer,\n+                Function<Page, Page> pagePreprocessor,\n+                PartitionFunction partitionFunction,\n+                List<Integer> partitionChannels,\n+                List<Optional<Block>> partitionConstants,\n+                boolean replicateNullsAndAny,\n+                OptionalInt nullChannel)\n+        {\n+            this.operatorId = operatorId;\n+            this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+            this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+            this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+            this.partitionChannels = requireNonNull(partitionChannels, \"partitionChannels is null\");\n+            this.partitionConstants = requireNonNull(partitionConstants, \"partitionConstants is null\");\n+            this.replicateNullsAndAny = replicateNullsAndAny;\n+            this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+        }\n+\n+        @Override\n+        public Operator createOperator(DriverContext driverContext)\n+        {\n+            OperatorContext operatorContext = driverContext.addOperatorContext(operatorId, planNodeId, PrestoSparkOutputOperator.class.getSimpleName());\n+            return new PrestoSparkOutputOperator(\n+                    operatorContext,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+\n+        @Override\n+        public void noMoreOperators()\n+        {\n+        }\n+\n+        @Override\n+        public OperatorFactory duplicate()\n+        {\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+    }\n+\n+    private final OperatorContext operatorContext;\n+    private final PrestoSparkRowBuffer rowBuffer;\n+    private final Function<Page, Page> pagePreprocessor;\n+    private final PartitionFunction partitionFunction;\n+    private final List<Integer> partitionChannels;\n+    private final List<Optional<Block>> partitionConstants;\n+    private final boolean replicateNullsAndAny;\n+    private final OptionalInt nullChannel;\n+\n+    private boolean finished;\n+    private boolean hasAnyRowBeenReplicated;\n+\n+    public PrestoSparkOutputOperator(\n+            OperatorContext operatorContext,\n+            PrestoSparkRowBuffer rowBuffer,\n+            Function<Page, Page> pagePreprocessor,\n+            PartitionFunction partitionFunction,\n+            List<Integer> partitionChannels,\n+            List<Optional<Block>> partitionConstants,\n+            boolean replicateNullsAndAny,\n+            OptionalInt nullChannel)\n+    {\n+        this.operatorContext = requireNonNull(operatorContext, \"operatorContext is null\");\n+        this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+        this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+        this.partitionChannels = ImmutableList.copyOf(requireNonNull(partitionChannels, \"partitionChannels is null\"));\n+        this.partitionConstants = ImmutableList.copyOf(requireNonNull(partitionConstants, \"partitionConstants is null\"));\n+        this.replicateNullsAndAny = replicateNullsAndAny;\n+        this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+    }\n+\n+    @Override\n+    public OperatorContext getOperatorContext()\n+    {\n+        return operatorContext;\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> isBlocked()\n+    {\n+        return rowBuffer.isFull();\n+    }\n+\n+    @Override\n+    public boolean needsInput()\n+    {\n+        return !finished && isBlocked().isDone();\n+    }\n+\n+    @Override\n+    public void addInput(Page page)\n+    {\n+        page = pagePreprocessor.apply(page);\n+        int positionCount = page.getPositionCount();\n+        int channelCount = page.getChannelCount();\n+        int averageRowSizeInBytes = min(toIntExact(page.getLogicalSizeInBytes() / positionCount), 10);\n+        Page partitionFunctionArguments = getPartitionFunctionArguments(page);\n+        for (int position = 0; position < positionCount; position++) {\n+            SliceOutput output = new DynamicSliceOutput(averageRowSizeInBytes * 2);\n+            for (int channel = 0; channel < channelCount; channel++) {\n+                Block block = page.getBlock(channel);\n+                block.writePositionTo(position, output);\n+            }\n+\n+            boolean shouldReplicate = (replicateNullsAndAny && !hasAnyRowBeenReplicated) ||\n+                    nullChannel.isPresent() && page.getBlock(nullChannel.getAsInt()).isNull(position);\n+            if (shouldReplicate) {\n+                for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n+                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), output.getUnderlyingSlice().byteArray()));\n+                }\n+                hasAnyRowBeenReplicated = true;\n+            }\n+            else {\n+                int partition = getPartition(partitionFunctionArguments, position);\n+                rowBuffer.enqueue(new PrestoSparkRow(partition, output.size(), output.getUnderlyingSlice().byteArray()));\n+            }\n+        }\n+    }\n+\n+    private int getPartition(Page partitionFunctionArgs, int position)\n+    {\n+        return partitionFunction.getPartition(partitionFunctionArgs, position);\n+    }\n+\n+    private Page getPartitionFunctionArguments(Page page)\n+    {\n+        Block[] blocks = new Block[partitionChannels.size()];\n+        for (int i = 0; i < blocks.length; i++) {\n+            Optional<Block> partitionConstant = partitionConstants.get(i);\n+            if (partitionConstant.isPresent()) {\n+                blocks[i] = new RunLengthEncodedBlock(partitionConstant.get(), page.getPositionCount());\n+            }\n+            else {\n+                blocks[i] = page.getBlock(partitionChannels.get(i));\n+            }\n+        }\n+        return new Page(page.getPositionCount(), blocks);\n+    }\n+\n+    @Override\n+    public Page getOutput()\n+    {\n+        return null;\n+    }\n+\n+    @Override\n+    public void finish()\n+    {\n+        finished = true;\n+    }\n+\n+    @Override\n+    public boolean isFinished()\n+    {\n+        return finished && isBlocked().isDone();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTkyMw==", "bodyText": "As a future work, I guess you want to use Spark's MutableRow? :) . cc @sameeragarwal", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381769923", "createdAt": "2020-02-20T05:29:49Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -74,18 +81,29 @@ public Page getOutput()\n             return null;\n         }\n \n-        SerializedPage serializedPage = null;\n+        PageBuilder pageBuilder = new PageBuilder(types);\n         synchronized (iterator) {\n-            if (iterator.hasNext()) {\n-                serializedPage = iterator.next();\n+            while (iterator.hasNext() && !pageBuilder.isFull()) {\n+                PrestoSparkRow row = iterator.next();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MDQ1Nw==", "bodyText": "looks like this did nothing for BasicSliceInput ?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381770457", "createdAt": "2020-02-20T05:30:57Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -74,18 +81,29 @@ public Page getOutput()\n             return null;\n         }\n \n-        SerializedPage serializedPage = null;\n+        PageBuilder pageBuilder = new PageBuilder(types);\n         synchronized (iterator) {\n-            if (iterator.hasNext()) {\n-                serializedPage = iterator.next();\n+            while (iterator.hasNext() && !pageBuilder.isFull()) {\n+                PrestoSparkRow row = iterator.next();\n+                SliceInput sliceInput = new BasicSliceInput(wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                pageBuilder.declarePosition();\n+                for (int channel = 0; channel < types.size(); channel++) {\n+                    BlockBuilder blockBuilder = pageBuilder.getBlockBuilder(channel);\n+                    blockBuilder.readPositionFrom(sliceInput);\n+                }\n+                sliceInput.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MDc5Nw==", "bodyText": "nit: types is null", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381770797", "createdAt": "2020-02-20T05:31:41Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -123,17 +141,17 @@ public void noMoreSplits()\n     {\n         private final int operatorId;\n         private final PlanNodeId planNodeId;\n-        private final Iterator<SerializedPage> iterator;\n-        private final PagesSerde serde;\n+        private final Iterator<PrestoSparkRow> iterator;\n+        private final List<Type> types;\n \n         private boolean closed;\n \n-        public SparkRemoteSourceOperatorFactory(int operatorId, PlanNodeId planNodeId, Iterator<SerializedPage> iterator, PagesSerde serde)\n+        public SparkRemoteSourceOperatorFactory(int operatorId, PlanNodeId planNodeId, Iterator<PrestoSparkRow> iterator, List<Type> types)\n         {\n             this.operatorId = operatorId;\n             this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n             this.iterator = requireNonNull(iterator, \"iterator is null\");\n-            this.serde = requireNonNull(serde, \"serde is null\");\n+            this.types = ImmutableList.copyOf(requireNonNull(types, \"serde is null\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MjcxMA==", "bodyText": "I am wondering if we should have a utility function to convert a list of PrestoSparkRow into a list of Blocks? -- we can leave this as TODO .", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381772710", "createdAt": "2020-02-20T05:35:43Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -270,11 +258,20 @@ private PrestoSparkQueryExecution(\n             queryCompletedEvent(Optional.empty());\n \n             ConnectorSession connectorSession = session.toConnectorSession();\n-            return resultRdd.stream()\n-                    .map(Tuple2::_2)\n-                    .map(this::deserializePage)\n-                    .flatMap(page -> getPageValues(connectorSession, page, rootFragment.getTypes()).stream())\n-                    .collect(toList());\n+            List<Type> types = rootFragment.getTypes();\n+            ImmutableList.Builder<List<Object>> result = ImmutableList.builder();\n+            for (Tuple2<Integer, PrestoSparkRow> tuple : resultRdd) {\n+                PrestoSparkRow row = tuple._2;\n+                SliceInput sliceInput = new BasicSliceInput(Slices.wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                ImmutableList.Builder<Object> columns = ImmutableList.builder();\n+                for (Type type : types) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MzQ2MA==", "bodyText": "Why not using ClassLayout.parseClass as we did for other Presto class? -- I am asking this is just adding these bytes together doesn't necessarily sum up to the instance size ,  e.g. there are Java object padding size, etc.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381773460", "createdAt": "2020-02-20T05:37:14Z", "author": {"login": "wenleix"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3NDE1MA==", "bodyText": "Similarly, we usually use SizeOf.sizeOf(bytes)", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381774150", "createdAt": "2020-02-20T05:38:38Z", "author": {"login": "wenleix"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */\n+            + Integer.BYTES /* partition */\n+            + Integer.BYTES /* length */\n+            + Long.BYTES /* bytes pointer */\n+            + Long.BYTES * 2 /* bytes headers */\n+            + Integer.BYTES /* bytes length */;\n+\n+    private final int partition;\n+    private final int length;\n     private final byte[] bytes;\n \n-    public SerializedPrestoSparkPage(byte[] bytes)\n+    public PrestoSparkRow(int partition, int length, byte[] bytes)\n     {\n+        this.partition = partition;\n+        this.length = length;\n         this.bytes = requireNonNull(bytes, \"bytes is null\");\n     }\n \n+    public int getPartition()\n+    {\n+        return partition;\n+    }\n+\n+    public int getLength()\n+    {\n+        return length;\n+    }\n+\n     public byte[] getBytes()\n     {\n         return bytes;\n     }\n+\n+    public long getRetainedSize()\n+    {\n+        return INSTANCE_SIZE + bytes.length;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 44}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/15dc6614cb36f515819e831cbfbfbc8fef635adf", "committedDate": "2020-02-13T22:53:29Z", "message": "Implement row base exchange in Presto on Spark"}, "afterCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/b05ed21ead31462462bc33a85d25a267aaea8137", "committedDate": "2020-02-20T19:09:56Z", "message": "Implement row base exchange in Presto on Spark"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYzMDY2Mjc1", "url": "https://github.com/prestodb/presto/pull/14099#pullrequestreview-363066275", "createdAt": "2020-02-23T05:15:13Z", "commit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNToxNzowOVrOFtOV2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwNTozNjo1NFrOFtWDqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTIwOA==", "bodyText": "I don't think this needs to be volatile", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382965208", "createdAt": "2020-02-23T05:17:09Z", "author": {"login": "tdcmeehan"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY2MA==", "bodyText": "Could we use an ArrayBlockingDeque and remove the synchronization in this class?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382965660", "createdAt": "2020-02-23T05:26:38Z", "author": {"login": "tdcmeehan"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY5Mw==", "bodyText": "Should we clear the buffer as well?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382965693", "createdAt": "2020-02-23T05:27:36Z", "author": {"login": "tdcmeehan"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;\n+\n+    public PrestoSparkRowBuffer(OutputBufferMemoryManager memoryManager)\n+    {\n+        this.memoryManager = requireNonNull(memoryManager, \"memoryManager is null\");\n+    }\n+\n+    public ListenableFuture<?> isFull()\n+    {\n+        return memoryManager.getBufferBlockedFuture();\n+    }\n+\n+    public void enqueue(PrestoSparkRow row)\n+    {\n+        requireNonNull(row, \"row is null\");\n+        synchronized (monitor) {\n+            buffer.add(row);\n+            monitor.notify();\n+        }\n+        memoryManager.updateMemoryUsage(row.getRetainedSize());\n+    }\n+\n+    public void setNoMoreRows()\n+    {\n+        memoryManager.setNoBlockOnFull();\n+        synchronized (monitor) {\n+            finished = true;\n+            monitor.notifyAll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTYyNw==", "bodyText": "Have you considered adding something like an overload to getObjectValue that takes in a sliceInput, to avoid having to create the block builder per cell?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383091627", "createdAt": "2020-02-24T05:36:54Z", "author": {"login": "tdcmeehan"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -270,11 +258,20 @@ private PrestoSparkQueryExecution(\n             queryCompletedEvent(Optional.empty());\n \n             ConnectorSession connectorSession = session.toConnectorSession();\n-            return resultRdd.stream()\n-                    .map(Tuple2::_2)\n-                    .map(this::deserializePage)\n-                    .flatMap(page -> getPageValues(connectorSession, page, rootFragment.getTypes()).stream())\n-                    .collect(toList());\n+            List<Type> types = rootFragment.getTypes();\n+            ImmutableList.Builder<List<Object>> result = ImmutableList.builder();\n+            for (Tuple2<Integer, PrestoSparkRow> tuple : resultRdd) {\n+                PrestoSparkRow row = tuple._2;\n+                SliceInput sliceInput = new BasicSliceInput(Slices.wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                ImmutableList.Builder<Object> columns = ImmutableList.builder();\n+                for (Type type : types) {\n+                    BlockBuilder blockBuilder = type.createBlockBuilder(null, 1);\n+                    blockBuilder.deserializePosition(sliceInput);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 166}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYzODc2MDk1", "url": "https://github.com/prestodb/presto/pull/14099#pullrequestreview-363876095", "createdAt": "2020-02-25T05:18:47Z", "commit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwNToxODo0N1rOFt48tQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwNToxODo0N1rOFt48tQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzY2MzI4NQ==", "bodyText": "bytes headers and bytes length should probably go into sizeOfByteArray?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383663285", "createdAt": "2020-02-25T05:18:47Z", "author": {"login": "wenleix"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */\n+            + Integer.BYTES /* partition */\n+            + Integer.BYTES /* length */\n+            + Long.BYTES /* bytes pointer */\n+            + Long.BYTES * 2 /* bytes headers */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYzODc2NjM2", "url": "https://github.com/prestodb/presto/pull/14099#pullrequestreview-363876636", "createdAt": "2020-02-25T05:20:51Z", "commit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/b05ed21ead31462462bc33a85d25a267aaea8137", "committedDate": "2020-02-20T19:09:56Z", "message": "Implement row base exchange in Presto on Spark"}, "afterCommit": {"oid": "a0708316d18af0d3d6b510a65454c28133929d98", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/a0708316d18af0d3d6b510a65454c28133929d98", "committedDate": "2020-02-25T14:35:55Z", "message": "Implement row base exchange in Presto on Spark"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a0708316d18af0d3d6b510a65454c28133929d98", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/a0708316d18af0d3d6b510a65454c28133929d98", "committedDate": "2020-02-25T14:35:55Z", "message": "Implement row base exchange in Presto on Spark"}, "afterCommit": {"oid": "9ea95d9c20975d3a83f6d2ef6a8337c7232604fb", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/9ea95d9c20975d3a83f6d2ef6a8337c7232604fb", "committedDate": "2020-02-25T19:08:38Z", "message": "Implement row base exchange in Presto on Spark"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "224ec928d5372f5abf29ba07475ee5b4d28a73e8", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/224ec928d5372f5abf29ba07475ee5b4d28a73e8", "committedDate": "2020-02-25T19:15:54Z", "message": "Create normal block with all null positions in createAllNullsBlock\n\nIt is somehow not intuitive that the createAllNullsBlock creates an\nRLE block. If the RLE block of a null value is needed - it feels like\nthere should be an explicit method that does that."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "57ba1ad6e3069510b0f7d1bd6d754cfb5d760f59", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/57ba1ad6e3069510b0f7d1bd6d754cfb5d760f59", "committedDate": "2020-02-25T19:15:55Z", "message": "Implement serialize/deserializePosition in Block/BlockBuilder\n\nThese methods will allow to serialize blocks row by row"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c6e991fbfd94c115bc0bdafb020c85643ca62eb2", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/c6e991fbfd94c115bc0bdafb020c85643ca62eb2", "committedDate": "2020-02-25T19:15:56Z", "message": "Refactor LocalExecutionPlanner\n\nAdd additional \"plan\" method that takes a OutputFactory as an input.\n\nIt is different from the existing \"plan\" method (that also takes OutputFactory).\nThe existing version does not create partitioning function, as it is only intended to\nuse by the LocalQueryRunner that doesn't have to partition the data between stages.\nThe new version creates a partitioning function based on the PartitioningScheme and passes\nit as a parameter of the OutputFactory.\n\nThis allows to override OuputOperator behavior without duplicating the code that\ncreates the partitioning function."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d82cdfbd295b9b627a45be6d4c94934a01b81de9", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/d82cdfbd295b9b627a45be6d4c94934a01b81de9", "committedDate": "2020-02-25T19:15:57Z", "message": "Refactor RemoteSourceFactory\n\nPass list of types as a parameter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2d5c4037d512680b1592b7c94f232448bffe4a4", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/b2d5c4037d512680b1592b7c94f232448bffe4a4", "committedDate": "2020-02-25T19:15:58Z", "message": "Implement row base exchange in Presto on Spark"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9ea95d9c20975d3a83f6d2ef6a8337c7232604fb", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/9ea95d9c20975d3a83f6d2ef6a8337c7232604fb", "committedDate": "2020-02-25T19:08:38Z", "message": "Implement row base exchange in Presto on Spark"}, "afterCommit": {"oid": "b2d5c4037d512680b1592b7c94f232448bffe4a4", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/b2d5c4037d512680b1592b7c94f232448bffe4a4", "committedDate": "2020-02-25T19:15:58Z", "message": "Implement row base exchange in Presto on Spark"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY0NDcyMzc1", "url": "https://github.com/prestodb/presto/pull/14099#pullrequestreview-364472375", "createdAt": "2020-02-25T21:46:25Z", "commit": {"oid": "b2d5c4037d512680b1592b7c94f232448bffe4a4"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2201, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}