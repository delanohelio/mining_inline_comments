{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk2MDI1MjI1", "number": 15258, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMzo1MDo1MFrOEpqUXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMzo1Mzo0MFrOEpqWIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTIwNDEyOnYy", "diffSide": "RIGHT", "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMzo1MDo1MFrOHbd-6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxODoxMjoxMVrOHb3ACw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDg0Mw==", "bodyText": "could it be: An Example deployment to query data in S3?", "url": "https://github.com/prestodb/presto/pull/15258#discussion_r498564843", "createdAt": "2020-10-01T23:50:50Z", "author": {"login": "zhenxiao"}, "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "diffHunk": "@@ -271,6 +276,87 @@ After launching, you can find the log files in ``var/log``:\n   This is the HTTP request log which contains every HTTP request\n   received by the server. It is automatically rotated and compressed.\n \n+An Example Deployment on Laptop", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08719837214bb5f209b4d7e0141b1cf2b2a04853"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk3NDczMQ==", "bodyText": "done", "url": "https://github.com/prestodb/presto/pull/15258#discussion_r498974731", "createdAt": "2020-10-02T18:12:11Z", "author": {"login": "apc999"}, "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "diffHunk": "@@ -271,6 +276,87 @@ After launching, you can find the log files in ``var/log``:\n   This is the HTTP request log which contains every HTTP request\n   received by the server. It is automatically rotated and compressed.\n \n+An Example Deployment on Laptop", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDg0Mw=="}, "originalCommit": {"oid": "08719837214bb5f209b4d7e0141b1cf2b2a04853"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTIwNjMzOnYy", "diffSide": "RIGHT", "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMzo1MjoxMFrOHbeAKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxODoxMjoxOFrOHb3ALw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NTE2Mw==", "bodyText": "shall we omit version?", "url": "https://github.com/prestodb/presto/pull/15258#discussion_r498565163", "createdAt": "2020-10-01T23:52:10Z", "author": {"login": "zhenxiao"}, "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "diffHunk": "@@ -271,6 +276,87 @@ After launching, you can find the log files in ``var/log``:\n   This is the HTTP request log which contains every HTTP request\n   received by the server. It is automatically rotated and compressed.\n \n+An Example Deployment on Laptop\n+-------------------------------\n+\n+This section shows how to run Presto connecting to Hive MetaStore on a single laptop to query data in an S3 bucket.\n+\n+Configure Hive MetaStore\n+^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Download and extract the binary tarball of Hive.\n+For example, download `apache-hive-2.3.7-bin.tar.gz <https://downloads.apache.org/hive/hive-2.3.7/apache-hive-2.3.7-bin.tar.gz>`_ .", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08719837214bb5f209b4d7e0141b1cf2b2a04853"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk3NDc2Nw==", "bodyText": "done", "url": "https://github.com/prestodb/presto/pull/15258#discussion_r498974767", "createdAt": "2020-10-02T18:12:18Z", "author": {"login": "apc999"}, "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "diffHunk": "@@ -271,6 +276,87 @@ After launching, you can find the log files in ``var/log``:\n   This is the HTTP request log which contains every HTTP request\n   received by the server. It is automatically rotated and compressed.\n \n+An Example Deployment on Laptop\n+-------------------------------\n+\n+This section shows how to run Presto connecting to Hive MetaStore on a single laptop to query data in an S3 bucket.\n+\n+Configure Hive MetaStore\n+^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Download and extract the binary tarball of Hive.\n+For example, download `apache-hive-2.3.7-bin.tar.gz <https://downloads.apache.org/hive/hive-2.3.7/apache-hive-2.3.7-bin.tar.gz>`_ .", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NTE2Mw=="}, "originalCommit": {"oid": "08719837214bb5f209b4d7e0141b1cf2b2a04853"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTIwNzMwOnYy", "diffSide": "RIGHT", "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMzo1Mjo0N1rOHbeAwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxODoxMjoyMlrOHb3AVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NTMxMw==", "bodyText": "do we need to document untar commands?", "url": "https://github.com/prestodb/presto/pull/15258#discussion_r498565313", "createdAt": "2020-10-01T23:52:47Z", "author": {"login": "zhenxiao"}, "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "diffHunk": "@@ -271,6 +276,87 @@ After launching, you can find the log files in ``var/log``:\n   This is the HTTP request log which contains every HTTP request\n   received by the server. It is automatically rotated and compressed.\n \n+An Example Deployment on Laptop\n+-------------------------------\n+\n+This section shows how to run Presto connecting to Hive MetaStore on a single laptop to query data in an S3 bucket.\n+\n+Configure Hive MetaStore\n+^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Download and extract the binary tarball of Hive.\n+For example, download `apache-hive-2.3.7-bin.tar.gz <https://downloads.apache.org/hive/hive-2.3.7/apache-hive-2.3.7-bin.tar.gz>`_ .\n+\n+.. code-block:: console", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08719837214bb5f209b4d7e0141b1cf2b2a04853"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk3NDgwNQ==", "bodyText": "removed", "url": "https://github.com/prestodb/presto/pull/15258#discussion_r498974805", "createdAt": "2020-10-02T18:12:22Z", "author": {"login": "apc999"}, "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "diffHunk": "@@ -271,6 +276,87 @@ After launching, you can find the log files in ``var/log``:\n   This is the HTTP request log which contains every HTTP request\n   received by the server. It is automatically rotated and compressed.\n \n+An Example Deployment on Laptop\n+-------------------------------\n+\n+This section shows how to run Presto connecting to Hive MetaStore on a single laptop to query data in an S3 bucket.\n+\n+Configure Hive MetaStore\n+^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Download and extract the binary tarball of Hive.\n+For example, download `apache-hive-2.3.7-bin.tar.gz <https://downloads.apache.org/hive/hive-2.3.7/apache-hive-2.3.7-bin.tar.gz>`_ .\n+\n+.. code-block:: console", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NTMxMw=="}, "originalCommit": {"oid": "08719837214bb5f209b4d7e0141b1cf2b2a04853"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMTIwODY3OnYy", "diffSide": "RIGHT", "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMzo1Mzo0MFrOHbeBpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxODoxNTo1OVrOHb3KhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NTU0MQ==", "bodyText": "omit jar versions?\nare these paths static and reliable?", "url": "https://github.com/prestodb/presto/pull/15258#discussion_r498565541", "createdAt": "2020-10-01T23:53:40Z", "author": {"login": "zhenxiao"}, "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "diffHunk": "@@ -271,6 +276,87 @@ After launching, you can find the log files in ``var/log``:\n   This is the HTTP request log which contains every HTTP request\n   received by the server. It is automatically rotated and compressed.\n \n+An Example Deployment on Laptop\n+-------------------------------\n+\n+This section shows how to run Presto connecting to Hive MetaStore on a single laptop to query data in an S3 bucket.\n+\n+Configure Hive MetaStore\n+^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Download and extract the binary tarball of Hive.\n+For example, download `apache-hive-2.3.7-bin.tar.gz <https://downloads.apache.org/hive/hive-2.3.7/apache-hive-2.3.7-bin.tar.gz>`_ .\n+\n+.. code-block:: console\n+\n+    $ tar -zxf apache-hive-2.3.7-bin.tar.gz\n+    $ cd apache-hive-2.3.7-bin\n+\n+You only need to launch Hive Metastore to serve Presto catalog information such as table schema and partition location.\n+If it is the first time to launch the Hive Metastore, prepare corresponding configuration files and environment, also initialize a new Metastore:\n+\n+.. code-block:: console\n+\n+    $ export HIVE_HOME=`pwd`\n+    $ cp conf/hive-default.xml.template conf/hive-site.xml\n+    $ mkdir -p hcatalog/var/log/\n+    # only required for the first time\n+    $ bin/schematool -dbType derby -initSchema\n+\n+If you want to access AWS S3, append the following lines in ``conf/hive-env.sh``.\n+Hive needs the corresponding jars to access files with ``s3a://`` addresses, and AWS credentials as well to access an S3 bucket (even it is public).\n+If you do not have a Hadoop installation which include above jars, download them from `maven central repository <https://repo1.maven.org/>`_.\n+\n+.. code-block:: console\n+\n+    $ export HIVE_AUX_JARS_PATH=${HADOOP_HOME}/share/hadoop/tools/lib/aws-java-sdk-core-1.10.6.jar:${HADOOP_HOME}/share/hadoop/tools/lib/aws-java-sdk-s3-1.10.6.jar:${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-aws-2.8.4.jar", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08719837214bb5f209b4d7e0141b1cf2b2a04853"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk3NzQxMg==", "bodyText": "updated", "url": "https://github.com/prestodb/presto/pull/15258#discussion_r498977412", "createdAt": "2020-10-02T18:15:59Z", "author": {"login": "apc999"}, "path": "presto-docs/src/main/sphinx/installation/deployment.rst", "diffHunk": "@@ -271,6 +276,87 @@ After launching, you can find the log files in ``var/log``:\n   This is the HTTP request log which contains every HTTP request\n   received by the server. It is automatically rotated and compressed.\n \n+An Example Deployment on Laptop\n+-------------------------------\n+\n+This section shows how to run Presto connecting to Hive MetaStore on a single laptop to query data in an S3 bucket.\n+\n+Configure Hive MetaStore\n+^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Download and extract the binary tarball of Hive.\n+For example, download `apache-hive-2.3.7-bin.tar.gz <https://downloads.apache.org/hive/hive-2.3.7/apache-hive-2.3.7-bin.tar.gz>`_ .\n+\n+.. code-block:: console\n+\n+    $ tar -zxf apache-hive-2.3.7-bin.tar.gz\n+    $ cd apache-hive-2.3.7-bin\n+\n+You only need to launch Hive Metastore to serve Presto catalog information such as table schema and partition location.\n+If it is the first time to launch the Hive Metastore, prepare corresponding configuration files and environment, also initialize a new Metastore:\n+\n+.. code-block:: console\n+\n+    $ export HIVE_HOME=`pwd`\n+    $ cp conf/hive-default.xml.template conf/hive-site.xml\n+    $ mkdir -p hcatalog/var/log/\n+    # only required for the first time\n+    $ bin/schematool -dbType derby -initSchema\n+\n+If you want to access AWS S3, append the following lines in ``conf/hive-env.sh``.\n+Hive needs the corresponding jars to access files with ``s3a://`` addresses, and AWS credentials as well to access an S3 bucket (even it is public).\n+If you do not have a Hadoop installation which include above jars, download them from `maven central repository <https://repo1.maven.org/>`_.\n+\n+.. code-block:: console\n+\n+    $ export HIVE_AUX_JARS_PATH=${HADOOP_HOME}/share/hadoop/tools/lib/aws-java-sdk-core-1.10.6.jar:${HADOOP_HOME}/share/hadoop/tools/lib/aws-java-sdk-s3-1.10.6.jar:${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-aws-2.8.4.jar", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NTU0MQ=="}, "originalCommit": {"oid": "08719837214bb5f209b4d7e0141b1cf2b2a04853"}, "originalPosition": 49}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3467, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}