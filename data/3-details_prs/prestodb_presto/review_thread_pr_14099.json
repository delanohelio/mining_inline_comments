{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc1MTMwMDI0", "number": 14099, "reviewThreads": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNjozMjoyNFrODg9B7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwNToxODo0N1rODikZjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1ODgwOTQyOnYy", "diffSide": "RIGHT", "path": "presto-main/src/test/java/com/facebook/presto/block/BlockAssertions.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNjozMjoyNFrOFrcdtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQxNjo0NjozNVrOFsbAtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA5OTQ0NQ==", "bodyText": "unrelated change? -- since the original RLE block is also a valid representation for all nulls block?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381099445", "createdAt": "2020-02-19T06:32:24Z", "author": {"login": "wenleix"}, "path": "presto-main/src/test/java/com/facebook/presto/block/BlockAssertions.java", "diffHunk": "@@ -115,7 +115,11 @@ public static void assertBlockEquals(Type type, Block actual, Block expected)\n \n     public static Block createAllNullsBlock(Type type, int positionCount)\n     {\n-        return new RunLengthEncodedBlock(type.createBlockBuilder(null, 1).appendNull().build(), positionCount);\n+        BlockBuilder blockBuilder = type.createBlockBuilder(null, 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "435878e8d9dee686a3b53d573aef2663db3fb5b5"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjExNzg2Mw==", "bodyText": "It just feels a little contrintuitive. I would expect the createAllNullsBlock to create a native block for a given type when all positions are nulls. If the intent is to create a RLE block with a null value - there should be a separate method that does that.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382117863", "createdAt": "2020-02-20T16:36:31Z", "author": {"login": "arhimondr"}, "path": "presto-main/src/test/java/com/facebook/presto/block/BlockAssertions.java", "diffHunk": "@@ -115,7 +115,11 @@ public static void assertBlockEquals(Type type, Block actual, Block expected)\n \n     public static Block createAllNullsBlock(Type type, int positionCount)\n     {\n-        return new RunLengthEncodedBlock(type.createBlockBuilder(null, 1).appendNull().build(), positionCount);\n+        BlockBuilder blockBuilder = type.createBlockBuilder(null, 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA5OTQ0NQ=="}, "originalCommit": {"oid": "435878e8d9dee686a3b53d573aef2663db3fb5b5"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjEyNDIxNA==", "bodyText": "Let me extract it into a separate commit", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382124214", "createdAt": "2020-02-20T16:46:35Z", "author": {"login": "arhimondr"}, "path": "presto-main/src/test/java/com/facebook/presto/block/BlockAssertions.java", "diffHunk": "@@ -115,7 +115,11 @@ public static void assertBlockEquals(Type type, Block actual, Block expected)\n \n     public static Block createAllNullsBlock(Type type, int positionCount)\n     {\n-        return new RunLengthEncodedBlock(type.createBlockBuilder(null, 1).appendNull().build(), positionCount);\n+        BlockBuilder blockBuilder = type.createBlockBuilder(null, 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA5OTQ0NQ=="}, "originalCommit": {"oid": "435878e8d9dee686a3b53d573aef2663db3fb5b5"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1ODg0NzU4OnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/com/facebook/presto/operator/OutputFactory.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNjo1MzozNFrOFrc0DQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQyMjoyNzoyNlrOFtyLOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEwNTE2NQ==", "bodyText": "So this OutputPartitioning is only required by PartitionedOutputOperatorFactory right? (and later PrestoSparkOutputFactory)? Maybe check argument in other OutputFactory that this shouldn't present", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381105165", "createdAt": "2020-02-19T06:53:34Z", "author": {"login": "wenleix"}, "path": "presto-main/src/main/java/com/facebook/presto/operator/OutputFactory.java", "diffHunk": "@@ -17,11 +17,19 @@\n import com.facebook.presto.spi.Page;\n import com.facebook.presto.spi.plan.PlanNodeId;\n import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n \n import java.util.List;\n+import java.util.Optional;\n import java.util.function.Function;\n \n public interface OutputFactory\n {\n-    OperatorFactory createOutputOperator(int operatorId, PlanNodeId planNodeId, List<Type> types, Function<Page, Page> pagePreprocessor, PagesSerdeFactory serdeFactory);\n+    OperatorFactory createOutputOperator(\n+            int operatorId,\n+            PlanNodeId planNodeId,\n+            List<Type> types,\n+            Function<Page, Page> pagePreprocessor,\n+            Optional<OutputPartitioning> outputPartitioning,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3dae179722b363137ef8997d4c5fe4477e9d982c"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjEzMDgzNQ==", "bodyText": "Added a check in the TaskOutputFactory. Didn't add for others, as the others are only used in tests.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382130835", "createdAt": "2020-02-20T16:57:49Z", "author": {"login": "arhimondr"}, "path": "presto-main/src/main/java/com/facebook/presto/operator/OutputFactory.java", "diffHunk": "@@ -17,11 +17,19 @@\n import com.facebook.presto.spi.Page;\n import com.facebook.presto.spi.plan.PlanNodeId;\n import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n \n import java.util.List;\n+import java.util.Optional;\n import java.util.function.Function;\n \n public interface OutputFactory\n {\n-    OperatorFactory createOutputOperator(int operatorId, PlanNodeId planNodeId, List<Type> types, Function<Page, Page> pagePreprocessor, PagesSerdeFactory serdeFactory);\n+    OperatorFactory createOutputOperator(\n+            int operatorId,\n+            PlanNodeId planNodeId,\n+            List<Type> types,\n+            Function<Page, Page> pagePreprocessor,\n+            Optional<OutputPartitioning> outputPartitioning,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEwNTE2NQ=="}, "originalCommit": {"oid": "3dae179722b363137ef8997d4c5fe4477e9d982c"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU1MjMxMw==", "bodyText": "Might still be useful to explicitly add the tests (it's more for convenient for readers of the code :)  )", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383552313", "createdAt": "2020-02-24T22:27:26Z", "author": {"login": "wenleix"}, "path": "presto-main/src/main/java/com/facebook/presto/operator/OutputFactory.java", "diffHunk": "@@ -17,11 +17,19 @@\n import com.facebook.presto.spi.Page;\n import com.facebook.presto.spi.plan.PlanNodeId;\n import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n \n import java.util.List;\n+import java.util.Optional;\n import java.util.function.Function;\n \n public interface OutputFactory\n {\n-    OperatorFactory createOutputOperator(int operatorId, PlanNodeId planNodeId, List<Type> types, Function<Page, Page> pagePreprocessor, PagesSerdeFactory serdeFactory);\n+    OperatorFactory createOutputOperator(\n+            int operatorId,\n+            PlanNodeId planNodeId,\n+            List<Type> types,\n+            Function<Page, Page> pagePreprocessor,\n+            Optional<OutputPartitioning> outputPartitioning,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEwNTE2NQ=="}, "originalCommit": {"oid": "3dae179722b363137ef8997d4c5fe4477e9d982c"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MjAzMjY4OnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQyMzozNDowNFrOFr7j6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQyMzo1NToyMVrOFt0HIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYwODkzNw==", "bodyText": "When outputPartitioning is not present, in PrestoSparkOutputFactory  it means it's SINGLE_PARTITION, but it's not necessary the case for other OutputFactory right? For example, in", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381608937", "createdAt": "2020-02-19T23:34:04Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MzIyMA==", "bodyText": "For example, in\n\nGithub must've saved not the final version. Could you please elaborate?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382143220", "createdAt": "2020-02-20T17:19:51Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYwODkzNw=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU4NDAzMg==", "bodyText": "@arhimondr : For example, in TaskOutputOperatorFactory ,  the output partitioning can be any of the FIXED_BROADCAST_DISTRIBUTION, FIXED_ARBITRARY_DISTRIBUTION, SCALED_WRITER_DISTRIBUTION, SINGLE_DISTRIBUTION, COORDINATOR_DISTRIBUTION: \n  \n    \n      presto/presto-main/src/main/java/com/facebook/presto/sql/planner/LocalExecutionPlanner.java\n    \n    \n        Lines 381 to 395\n      in\n      2fb54ed\n    \n    \n    \n    \n\n        \n          \n           if (partitioningScheme.getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION) || \n        \n\n        \n          \n                   partitioningScheme.getPartitioning().getHandle().equals(FIXED_ARBITRARY_DISTRIBUTION) || \n        \n\n        \n          \n                   partitioningScheme.getPartitioning().getHandle().equals(SCALED_WRITER_DISTRIBUTION) || \n        \n\n        \n          \n                   partitioningScheme.getPartitioning().getHandle().equals(SINGLE_DISTRIBUTION) || \n        \n\n        \n          \n                   partitioningScheme.getPartitioning().getHandle().equals(COORDINATOR_DISTRIBUTION)) { \n        \n\n        \n          \n               return plan( \n        \n\n        \n          \n                       taskContext, \n        \n\n        \n          \n                       stageExecutionDescriptor, \n        \n\n        \n          \n                       plan, \n        \n\n        \n          \n                       outputLayout, \n        \n\n        \n          \n                       partitionedSourceOrder, \n        \n\n        \n          \n                       new TaskOutputFactory(outputBuffer), \n        \n\n        \n          \n                       remoteSourceFactory, \n        \n\n        \n          \n                       tableWriteInfo); \n        \n\n        \n          \n           } \n        \n    \n  \n\n\nUpdate: with the check argument that output partitioning must be absent, it might be OK... just note the absence of output partitioning seems to have different semantic for TaskOutputOperatorFactory vs. PrestoSparkOutputFactory", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383584032", "createdAt": "2020-02-24T23:55:21Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYwODkzNw=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MjE2MzU1OnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwMDo0MjowOFrOFr80AQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQxNzoxMjo1N1rOFsb73w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYyOTQ0MQ==", "bodyText": "what does replicateNullsAndAny mean? In PartitionedOutputOperator, the variable name is replicatesAnyRow", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381629441", "createdAt": "2020-02-20T00:42:08Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjEzOTM1OQ==", "bodyText": "what does replicateNullsAndAny mean?\n\nIt is needed for the SemiJoin. It tels the partitioner to copy null rows to every partition and also make sure that if the input is not empty - a row is replicated to every partition (so the partitions are not empty). It is needed to preserve correct null vs false semantics of the SemiJoin.\nI think the replicatesAnyRow is missleading. Whoever was extending this behaviour to the replicateNullsAndAny probably just forgot to do the rename in the PartitioningOperator.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382139359", "createdAt": "2020-02-20T17:12:57Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYyOTQ0MQ=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MzI0MzIxOnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNToyNDowNFrOFsFNrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQxNzoxNDo1OVrOFscAOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2NzA4NA==", "bodyText": "So PrestoSparkRowBuffer#get is a blocked call. Is there any reason for that -- I am asking this since the general convention in Presto seems to be using ListenableFuture<PrestoSparkRow> for such cases?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381767084", "createdAt": "2020-02-20T05:24:04Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;\n+\n+    public PrestoSparkRowBuffer(OutputBufferMemoryManager memoryManager)\n+    {\n+        this.memoryManager = requireNonNull(memoryManager, \"memoryManager is null\");\n+    }\n+\n+    public ListenableFuture<?> isFull()\n+    {\n+        return memoryManager.getBufferBlockedFuture();\n+    }\n+\n+    public void enqueue(PrestoSparkRow row)\n+    {\n+        requireNonNull(row, \"row is null\");\n+        synchronized (monitor) {\n+            buffer.add(row);\n+            monitor.notify();\n+        }\n+        memoryManager.updateMemoryUsage(row.getRetainedSize());\n+    }\n+\n+    public void setNoMoreRows()\n+    {\n+        memoryManager.setNoBlockOnFull();\n+        synchronized (monitor) {\n+            finished = true;\n+            monitor.notifyAll();\n+        }\n+    }\n+\n+    public boolean hasRowsBuffered()\n+    {\n+        synchronized (monitor) {\n+            return !buffer.isEmpty();\n+        }\n+    }\n+\n+    public PrestoSparkRow get()\n+            throws InterruptedException\n+    {\n+        PrestoSparkRow row;\n+        synchronized (monitor) {\n+            while (!finished && buffer.isEmpty()) {\n+                monitor.wait();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MDQ3Mw==", "bodyText": "The Spark iterator is blocking anyway. It is mostly for implementation simplicity. Otherwise we would always wait on the Future#get() unconditionally in the SparkIterator.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382140473", "createdAt": "2020-02-20T17:14:59Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;\n+\n+    public PrestoSparkRowBuffer(OutputBufferMemoryManager memoryManager)\n+    {\n+        this.memoryManager = requireNonNull(memoryManager, \"memoryManager is null\");\n+    }\n+\n+    public ListenableFuture<?> isFull()\n+    {\n+        return memoryManager.getBufferBlockedFuture();\n+    }\n+\n+    public void enqueue(PrestoSparkRow row)\n+    {\n+        requireNonNull(row, \"row is null\");\n+        synchronized (monitor) {\n+            buffer.add(row);\n+            monitor.notify();\n+        }\n+        memoryManager.updateMemoryUsage(row.getRetainedSize());\n+    }\n+\n+    public void setNoMoreRows()\n+    {\n+        memoryManager.setNoBlockOnFull();\n+        synchronized (monitor) {\n+            finished = true;\n+            monitor.notifyAll();\n+        }\n+    }\n+\n+    public boolean hasRowsBuffered()\n+    {\n+        synchronized (monitor) {\n+            return !buffer.isEmpty();\n+        }\n+    }\n+\n+    public PrestoSparkRow get()\n+            throws InterruptedException\n+    {\n+        PrestoSparkRow row;\n+        synchronized (monitor) {\n+            while (!finished && buffer.isEmpty()) {\n+                monitor.wait();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2NzA4NA=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MzI1MjcxOnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNToyNjo0MlrOFsFSow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQxNzoxNjowN1rOFscCkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2ODM1NQ==", "bodyText": "I guess you intend to avoid create a new DynamicSliceOutput each time so you try to get the underlying byte array directly \ud83d\ude03 . I understand it cannot be done for now since you cannot reset DynamicSliceOutput\nThat being said, we might want to consider add something like reset into SliceOutput?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381768355", "createdAt": "2020-02-20T05:26:42Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;\n+        private final OptionalInt nullChannel;\n+\n+        public PrestoSparkOutputOperatorFactory(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                PrestoSparkRowBuffer rowBuffer,\n+                Function<Page, Page> pagePreprocessor,\n+                PartitionFunction partitionFunction,\n+                List<Integer> partitionChannels,\n+                List<Optional<Block>> partitionConstants,\n+                boolean replicateNullsAndAny,\n+                OptionalInt nullChannel)\n+        {\n+            this.operatorId = operatorId;\n+            this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+            this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+            this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+            this.partitionChannels = requireNonNull(partitionChannels, \"partitionChannels is null\");\n+            this.partitionConstants = requireNonNull(partitionConstants, \"partitionConstants is null\");\n+            this.replicateNullsAndAny = replicateNullsAndAny;\n+            this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+        }\n+\n+        @Override\n+        public Operator createOperator(DriverContext driverContext)\n+        {\n+            OperatorContext operatorContext = driverContext.addOperatorContext(operatorId, planNodeId, PrestoSparkOutputOperator.class.getSimpleName());\n+            return new PrestoSparkOutputOperator(\n+                    operatorContext,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+\n+        @Override\n+        public void noMoreOperators()\n+        {\n+        }\n+\n+        @Override\n+        public OperatorFactory duplicate()\n+        {\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+    }\n+\n+    private final OperatorContext operatorContext;\n+    private final PrestoSparkRowBuffer rowBuffer;\n+    private final Function<Page, Page> pagePreprocessor;\n+    private final PartitionFunction partitionFunction;\n+    private final List<Integer> partitionChannels;\n+    private final List<Optional<Block>> partitionConstants;\n+    private final boolean replicateNullsAndAny;\n+    private final OptionalInt nullChannel;\n+\n+    private boolean finished;\n+    private boolean hasAnyRowBeenReplicated;\n+\n+    public PrestoSparkOutputOperator(\n+            OperatorContext operatorContext,\n+            PrestoSparkRowBuffer rowBuffer,\n+            Function<Page, Page> pagePreprocessor,\n+            PartitionFunction partitionFunction,\n+            List<Integer> partitionChannels,\n+            List<Optional<Block>> partitionConstants,\n+            boolean replicateNullsAndAny,\n+            OptionalInt nullChannel)\n+    {\n+        this.operatorContext = requireNonNull(operatorContext, \"operatorContext is null\");\n+        this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+        this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+        this.partitionChannels = ImmutableList.copyOf(requireNonNull(partitionChannels, \"partitionChannels is null\"));\n+        this.partitionConstants = ImmutableList.copyOf(requireNonNull(partitionConstants, \"partitionConstants is null\"));\n+        this.replicateNullsAndAny = replicateNullsAndAny;\n+        this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+    }\n+\n+    @Override\n+    public OperatorContext getOperatorContext()\n+    {\n+        return operatorContext;\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> isBlocked()\n+    {\n+        return rowBuffer.isFull();\n+    }\n+\n+    @Override\n+    public boolean needsInput()\n+    {\n+        return !finished && isBlocked().isDone();\n+    }\n+\n+    @Override\n+    public void addInput(Page page)\n+    {\n+        page = pagePreprocessor.apply(page);\n+        int positionCount = page.getPositionCount();\n+        int channelCount = page.getChannelCount();\n+        int averageRowSizeInBytes = min(toIntExact(page.getLogicalSizeInBytes() / positionCount), 10);\n+        Page partitionFunctionArguments = getPartitionFunctionArguments(page);\n+        for (int position = 0; position < positionCount; position++) {\n+            SliceOutput output = new DynamicSliceOutput(averageRowSizeInBytes * 2);\n+            for (int channel = 0; channel < channelCount; channel++) {\n+                Block block = page.getBlock(channel);\n+                block.writePositionTo(position, output);\n+            }\n+\n+            boolean shouldReplicate = (replicateNullsAndAny && !hasAnyRowBeenReplicated) ||\n+                    nullChannel.isPresent() && page.getBlock(nullChannel.getAsInt()).isNull(position);\n+            if (shouldReplicate) {\n+                for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n+                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), output.getUnderlyingSlice().byteArray()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 247}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MTA3Mg==", "bodyText": "This should be done as part of the buffer recycling effort. As SliceOutput has to acquire a free buffer from a pool before you can reset it.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382141072", "createdAt": "2020-02-20T17:16:07Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;\n+        private final OptionalInt nullChannel;\n+\n+        public PrestoSparkOutputOperatorFactory(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                PrestoSparkRowBuffer rowBuffer,\n+                Function<Page, Page> pagePreprocessor,\n+                PartitionFunction partitionFunction,\n+                List<Integer> partitionChannels,\n+                List<Optional<Block>> partitionConstants,\n+                boolean replicateNullsAndAny,\n+                OptionalInt nullChannel)\n+        {\n+            this.operatorId = operatorId;\n+            this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+            this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+            this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+            this.partitionChannels = requireNonNull(partitionChannels, \"partitionChannels is null\");\n+            this.partitionConstants = requireNonNull(partitionConstants, \"partitionConstants is null\");\n+            this.replicateNullsAndAny = replicateNullsAndAny;\n+            this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+        }\n+\n+        @Override\n+        public Operator createOperator(DriverContext driverContext)\n+        {\n+            OperatorContext operatorContext = driverContext.addOperatorContext(operatorId, planNodeId, PrestoSparkOutputOperator.class.getSimpleName());\n+            return new PrestoSparkOutputOperator(\n+                    operatorContext,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+\n+        @Override\n+        public void noMoreOperators()\n+        {\n+        }\n+\n+        @Override\n+        public OperatorFactory duplicate()\n+        {\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+    }\n+\n+    private final OperatorContext operatorContext;\n+    private final PrestoSparkRowBuffer rowBuffer;\n+    private final Function<Page, Page> pagePreprocessor;\n+    private final PartitionFunction partitionFunction;\n+    private final List<Integer> partitionChannels;\n+    private final List<Optional<Block>> partitionConstants;\n+    private final boolean replicateNullsAndAny;\n+    private final OptionalInt nullChannel;\n+\n+    private boolean finished;\n+    private boolean hasAnyRowBeenReplicated;\n+\n+    public PrestoSparkOutputOperator(\n+            OperatorContext operatorContext,\n+            PrestoSparkRowBuffer rowBuffer,\n+            Function<Page, Page> pagePreprocessor,\n+            PartitionFunction partitionFunction,\n+            List<Integer> partitionChannels,\n+            List<Optional<Block>> partitionConstants,\n+            boolean replicateNullsAndAny,\n+            OptionalInt nullChannel)\n+    {\n+        this.operatorContext = requireNonNull(operatorContext, \"operatorContext is null\");\n+        this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+        this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+        this.partitionChannels = ImmutableList.copyOf(requireNonNull(partitionChannels, \"partitionChannels is null\"));\n+        this.partitionConstants = ImmutableList.copyOf(requireNonNull(partitionConstants, \"partitionConstants is null\"));\n+        this.replicateNullsAndAny = replicateNullsAndAny;\n+        this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+    }\n+\n+    @Override\n+    public OperatorContext getOperatorContext()\n+    {\n+        return operatorContext;\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> isBlocked()\n+    {\n+        return rowBuffer.isFull();\n+    }\n+\n+    @Override\n+    public boolean needsInput()\n+    {\n+        return !finished && isBlocked().isDone();\n+    }\n+\n+    @Override\n+    public void addInput(Page page)\n+    {\n+        page = pagePreprocessor.apply(page);\n+        int positionCount = page.getPositionCount();\n+        int channelCount = page.getChannelCount();\n+        int averageRowSizeInBytes = min(toIntExact(page.getLogicalSizeInBytes() / positionCount), 10);\n+        Page partitionFunctionArguments = getPartitionFunctionArguments(page);\n+        for (int position = 0; position < positionCount; position++) {\n+            SliceOutput output = new DynamicSliceOutput(averageRowSizeInBytes * 2);\n+            for (int channel = 0; channel < channelCount; channel++) {\n+                Block block = page.getBlock(channel);\n+                block.writePositionTo(position, output);\n+            }\n+\n+            boolean shouldReplicate = (replicateNullsAndAny && !hasAnyRowBeenReplicated) ||\n+                    nullChannel.isPresent() && page.getBlock(nullChannel.getAsInt()).isNull(position);\n+            if (shouldReplicate) {\n+                for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n+                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), output.getUnderlyingSlice().byteArray()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2ODM1NQ=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 247}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MzI2MjQ2OnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNToyOTowMVrOFsFXUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQxNzoyMTozMlrOFscOsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTU1Mg==", "bodyText": "is this enough -- do we want to make sure rowBuffer is empty?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381769552", "createdAt": "2020-02-20T05:29:01Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;\n+        private final OptionalInt nullChannel;\n+\n+        public PrestoSparkOutputOperatorFactory(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                PrestoSparkRowBuffer rowBuffer,\n+                Function<Page, Page> pagePreprocessor,\n+                PartitionFunction partitionFunction,\n+                List<Integer> partitionChannels,\n+                List<Optional<Block>> partitionConstants,\n+                boolean replicateNullsAndAny,\n+                OptionalInt nullChannel)\n+        {\n+            this.operatorId = operatorId;\n+            this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+            this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+            this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+            this.partitionChannels = requireNonNull(partitionChannels, \"partitionChannels is null\");\n+            this.partitionConstants = requireNonNull(partitionConstants, \"partitionConstants is null\");\n+            this.replicateNullsAndAny = replicateNullsAndAny;\n+            this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+        }\n+\n+        @Override\n+        public Operator createOperator(DriverContext driverContext)\n+        {\n+            OperatorContext operatorContext = driverContext.addOperatorContext(operatorId, planNodeId, PrestoSparkOutputOperator.class.getSimpleName());\n+            return new PrestoSparkOutputOperator(\n+                    operatorContext,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+\n+        @Override\n+        public void noMoreOperators()\n+        {\n+        }\n+\n+        @Override\n+        public OperatorFactory duplicate()\n+        {\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+    }\n+\n+    private final OperatorContext operatorContext;\n+    private final PrestoSparkRowBuffer rowBuffer;\n+    private final Function<Page, Page> pagePreprocessor;\n+    private final PartitionFunction partitionFunction;\n+    private final List<Integer> partitionChannels;\n+    private final List<Optional<Block>> partitionConstants;\n+    private final boolean replicateNullsAndAny;\n+    private final OptionalInt nullChannel;\n+\n+    private boolean finished;\n+    private boolean hasAnyRowBeenReplicated;\n+\n+    public PrestoSparkOutputOperator(\n+            OperatorContext operatorContext,\n+            PrestoSparkRowBuffer rowBuffer,\n+            Function<Page, Page> pagePreprocessor,\n+            PartitionFunction partitionFunction,\n+            List<Integer> partitionChannels,\n+            List<Optional<Block>> partitionConstants,\n+            boolean replicateNullsAndAny,\n+            OptionalInt nullChannel)\n+    {\n+        this.operatorContext = requireNonNull(operatorContext, \"operatorContext is null\");\n+        this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+        this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+        this.partitionChannels = ImmutableList.copyOf(requireNonNull(partitionChannels, \"partitionChannels is null\"));\n+        this.partitionConstants = ImmutableList.copyOf(requireNonNull(partitionConstants, \"partitionConstants is null\"));\n+        this.replicateNullsAndAny = replicateNullsAndAny;\n+        this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+    }\n+\n+    @Override\n+    public OperatorContext getOperatorContext()\n+    {\n+        return operatorContext;\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> isBlocked()\n+    {\n+        return rowBuffer.isFull();\n+    }\n+\n+    @Override\n+    public boolean needsInput()\n+    {\n+        return !finished && isBlocked().isDone();\n+    }\n+\n+    @Override\n+    public void addInput(Page page)\n+    {\n+        page = pagePreprocessor.apply(page);\n+        int positionCount = page.getPositionCount();\n+        int channelCount = page.getChannelCount();\n+        int averageRowSizeInBytes = min(toIntExact(page.getLogicalSizeInBytes() / positionCount), 10);\n+        Page partitionFunctionArguments = getPartitionFunctionArguments(page);\n+        for (int position = 0; position < positionCount; position++) {\n+            SliceOutput output = new DynamicSliceOutput(averageRowSizeInBytes * 2);\n+            for (int channel = 0; channel < channelCount; channel++) {\n+                Block block = page.getBlock(channel);\n+                block.writePositionTo(position, output);\n+            }\n+\n+            boolean shouldReplicate = (replicateNullsAndAny && !hasAnyRowBeenReplicated) ||\n+                    nullChannel.isPresent() && page.getBlock(nullChannel.getAsInt()).isNull(position);\n+            if (shouldReplicate) {\n+                for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n+                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), output.getUnderlyingSlice().byteArray()));\n+                }\n+                hasAnyRowBeenReplicated = true;\n+            }\n+            else {\n+                int partition = getPartition(partitionFunctionArguments, position);\n+                rowBuffer.enqueue(new PrestoSparkRow(partition, output.size(), output.getUnderlyingSlice().byteArray()));\n+            }\n+        }\n+    }\n+\n+    private int getPartition(Page partitionFunctionArgs, int position)\n+    {\n+        return partitionFunction.getPartition(partitionFunctionArgs, position);\n+    }\n+\n+    private Page getPartitionFunctionArguments(Page page)\n+    {\n+        Block[] blocks = new Block[partitionChannels.size()];\n+        for (int i = 0; i < blocks.length; i++) {\n+            Optional<Block> partitionConstant = partitionConstants.get(i);\n+            if (partitionConstant.isPresent()) {\n+                blocks[i] = new RunLengthEncodedBlock(partitionConstant.get(), page.getPositionCount());\n+            }\n+            else {\n+                blocks[i] = page.getBlock(partitionChannels.get(i));\n+            }\n+        }\n+        return new Page(page.getPositionCount(), blocks);\n+    }\n+\n+    @Override\n+    public Page getOutput()\n+    {\n+        return null;\n+    }\n+\n+    @Override\n+    public void finish()\n+    {\n+        finished = true;\n+    }\n+\n+    @Override\n+    public boolean isFinished()\n+    {\n+        return finished && isBlocked().isDone();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0NDE3Ng==", "bodyText": "It looks like the TaskOutputFactory is not waiting for the buffer to be drained. I followed the same approach here.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382144176", "createdAt": "2020-02-20T17:21:32Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;\n+        private final OptionalInt nullChannel;\n+\n+        public PrestoSparkOutputOperatorFactory(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                PrestoSparkRowBuffer rowBuffer,\n+                Function<Page, Page> pagePreprocessor,\n+                PartitionFunction partitionFunction,\n+                List<Integer> partitionChannels,\n+                List<Optional<Block>> partitionConstants,\n+                boolean replicateNullsAndAny,\n+                OptionalInt nullChannel)\n+        {\n+            this.operatorId = operatorId;\n+            this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+            this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+            this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+            this.partitionChannels = requireNonNull(partitionChannels, \"partitionChannels is null\");\n+            this.partitionConstants = requireNonNull(partitionConstants, \"partitionConstants is null\");\n+            this.replicateNullsAndAny = replicateNullsAndAny;\n+            this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+        }\n+\n+        @Override\n+        public Operator createOperator(DriverContext driverContext)\n+        {\n+            OperatorContext operatorContext = driverContext.addOperatorContext(operatorId, planNodeId, PrestoSparkOutputOperator.class.getSimpleName());\n+            return new PrestoSparkOutputOperator(\n+                    operatorContext,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+\n+        @Override\n+        public void noMoreOperators()\n+        {\n+        }\n+\n+        @Override\n+        public OperatorFactory duplicate()\n+        {\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+    }\n+\n+    private final OperatorContext operatorContext;\n+    private final PrestoSparkRowBuffer rowBuffer;\n+    private final Function<Page, Page> pagePreprocessor;\n+    private final PartitionFunction partitionFunction;\n+    private final List<Integer> partitionChannels;\n+    private final List<Optional<Block>> partitionConstants;\n+    private final boolean replicateNullsAndAny;\n+    private final OptionalInt nullChannel;\n+\n+    private boolean finished;\n+    private boolean hasAnyRowBeenReplicated;\n+\n+    public PrestoSparkOutputOperator(\n+            OperatorContext operatorContext,\n+            PrestoSparkRowBuffer rowBuffer,\n+            Function<Page, Page> pagePreprocessor,\n+            PartitionFunction partitionFunction,\n+            List<Integer> partitionChannels,\n+            List<Optional<Block>> partitionConstants,\n+            boolean replicateNullsAndAny,\n+            OptionalInt nullChannel)\n+    {\n+        this.operatorContext = requireNonNull(operatorContext, \"operatorContext is null\");\n+        this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+        this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+        this.partitionChannels = ImmutableList.copyOf(requireNonNull(partitionChannels, \"partitionChannels is null\"));\n+        this.partitionConstants = ImmutableList.copyOf(requireNonNull(partitionConstants, \"partitionConstants is null\"));\n+        this.replicateNullsAndAny = replicateNullsAndAny;\n+        this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+    }\n+\n+    @Override\n+    public OperatorContext getOperatorContext()\n+    {\n+        return operatorContext;\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> isBlocked()\n+    {\n+        return rowBuffer.isFull();\n+    }\n+\n+    @Override\n+    public boolean needsInput()\n+    {\n+        return !finished && isBlocked().isDone();\n+    }\n+\n+    @Override\n+    public void addInput(Page page)\n+    {\n+        page = pagePreprocessor.apply(page);\n+        int positionCount = page.getPositionCount();\n+        int channelCount = page.getChannelCount();\n+        int averageRowSizeInBytes = min(toIntExact(page.getLogicalSizeInBytes() / positionCount), 10);\n+        Page partitionFunctionArguments = getPartitionFunctionArguments(page);\n+        for (int position = 0; position < positionCount; position++) {\n+            SliceOutput output = new DynamicSliceOutput(averageRowSizeInBytes * 2);\n+            for (int channel = 0; channel < channelCount; channel++) {\n+                Block block = page.getBlock(channel);\n+                block.writePositionTo(position, output);\n+            }\n+\n+            boolean shouldReplicate = (replicateNullsAndAny && !hasAnyRowBeenReplicated) ||\n+                    nullChannel.isPresent() && page.getBlock(nullChannel.getAsInt()).isNull(position);\n+            if (shouldReplicate) {\n+                for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n+                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), output.getUnderlyingSlice().byteArray()));\n+                }\n+                hasAnyRowBeenReplicated = true;\n+            }\n+            else {\n+                int partition = getPartition(partitionFunctionArguments, position);\n+                rowBuffer.enqueue(new PrestoSparkRow(partition, output.size(), output.getUnderlyingSlice().byteArray()));\n+            }\n+        }\n+    }\n+\n+    private int getPartition(Page partitionFunctionArgs, int position)\n+    {\n+        return partitionFunction.getPartition(partitionFunctionArgs, position);\n+    }\n+\n+    private Page getPartitionFunctionArguments(Page page)\n+    {\n+        Block[] blocks = new Block[partitionChannels.size()];\n+        for (int i = 0; i < blocks.length; i++) {\n+            Optional<Block> partitionConstant = partitionConstants.get(i);\n+            if (partitionConstant.isPresent()) {\n+                blocks[i] = new RunLengthEncodedBlock(partitionConstant.get(), page.getPositionCount());\n+            }\n+            else {\n+                blocks[i] = page.getBlock(partitionChannels.get(i));\n+            }\n+        }\n+        return new Page(page.getPositionCount(), blocks);\n+    }\n+\n+    @Override\n+    public Page getOutput()\n+    {\n+        return null;\n+    }\n+\n+    @Override\n+    public void finish()\n+    {\n+        finished = true;\n+    }\n+\n+    @Override\n+    public boolean isFinished()\n+    {\n+        return finished && isBlocked().isDone();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTU1Mg=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 293}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MzI2NTUxOnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNToyOTo0OVrOFsFYww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQxNzoxNjo1OFrOFscEiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTkyMw==", "bodyText": "As a future work, I guess you want to use Spark's MutableRow? :) . cc @sameeragarwal", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381769923", "createdAt": "2020-02-20T05:29:49Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -74,18 +81,29 @@ public Page getOutput()\n             return null;\n         }\n \n-        SerializedPage serializedPage = null;\n+        PageBuilder pageBuilder = new PageBuilder(types);\n         synchronized (iterator) {\n-            if (iterator.hasNext()) {\n-                serializedPage = iterator.next();\n+            while (iterator.hasNext() && !pageBuilder.isFull()) {\n+                PrestoSparkRow row = iterator.next();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MTU3Ng==", "bodyText": "Actually I'm not sure if we want to integrate with Spark's types at this point.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382141576", "createdAt": "2020-02-20T17:16:58Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -74,18 +81,29 @@ public Page getOutput()\n             return null;\n         }\n \n-        SerializedPage serializedPage = null;\n+        PageBuilder pageBuilder = new PageBuilder(types);\n         synchronized (iterator) {\n-            if (iterator.hasNext()) {\n-                serializedPage = iterator.next();\n+            while (iterator.hasNext() && !pageBuilder.isFull()) {\n+                PrestoSparkRow row = iterator.next();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTkyMw=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MzI2OTM2OnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNTozMDo1N1rOFsFa2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQxNzoxNzoxMFrOFscFCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MDQ1Nw==", "bodyText": "looks like this did nothing for BasicSliceInput ?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381770457", "createdAt": "2020-02-20T05:30:57Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -74,18 +81,29 @@ public Page getOutput()\n             return null;\n         }\n \n-        SerializedPage serializedPage = null;\n+        PageBuilder pageBuilder = new PageBuilder(types);\n         synchronized (iterator) {\n-            if (iterator.hasNext()) {\n-                serializedPage = iterator.next();\n+            while (iterator.hasNext() && !pageBuilder.isFull()) {\n+                PrestoSparkRow row = iterator.next();\n+                SliceInput sliceInput = new BasicSliceInput(wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                pageBuilder.declarePosition();\n+                for (int channel = 0; channel < types.size(); channel++) {\n+                    BlockBuilder blockBuilder = pageBuilder.getBlockBuilder(channel);\n+                    blockBuilder.readPositionFrom(sliceInput);\n+                }\n+                sliceInput.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MTcwNQ==", "bodyText": "Just in case =)", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382141705", "createdAt": "2020-02-20T17:17:10Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -74,18 +81,29 @@ public Page getOutput()\n             return null;\n         }\n \n-        SerializedPage serializedPage = null;\n+        PageBuilder pageBuilder = new PageBuilder(types);\n         synchronized (iterator) {\n-            if (iterator.hasNext()) {\n-                serializedPage = iterator.next();\n+            while (iterator.hasNext() && !pageBuilder.isFull()) {\n+                PrestoSparkRow row = iterator.next();\n+                SliceInput sliceInput = new BasicSliceInput(wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                pageBuilder.declarePosition();\n+                for (int channel = 0; channel < types.size(); channel++) {\n+                    BlockBuilder blockBuilder = pageBuilder.getBlockBuilder(channel);\n+                    blockBuilder.readPositionFrom(sliceInput);\n+                }\n+                sliceInput.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MDQ1Nw=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MzI3MTc0OnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNTozMTo0MVrOFsFcLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNTozMTo0MVrOFsFcLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MDc5Nw==", "bodyText": "nit: types is null", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381770797", "createdAt": "2020-02-20T05:31:41Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -123,17 +141,17 @@ public void noMoreSplits()\n     {\n         private final int operatorId;\n         private final PlanNodeId planNodeId;\n-        private final Iterator<SerializedPage> iterator;\n-        private final PagesSerde serde;\n+        private final Iterator<PrestoSparkRow> iterator;\n+        private final List<Type> types;\n \n         private boolean closed;\n \n-        public SparkRemoteSourceOperatorFactory(int operatorId, PlanNodeId planNodeId, Iterator<SerializedPage> iterator, PagesSerde serde)\n+        public SparkRemoteSourceOperatorFactory(int operatorId, PlanNodeId planNodeId, Iterator<PrestoSparkRow> iterator, List<Type> types)\n         {\n             this.operatorId = operatorId;\n             this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n             this.iterator = requireNonNull(iterator, \"iterator is null\");\n-            this.serde = requireNonNull(serde, \"serde is null\");\n+            this.types = ImmutableList.copyOf(requireNonNull(types, \"serde is null\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MzI4NzU2OnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNTozNTo0M1rOFsFjpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNDoyNDowNFrOFuH90Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MjcxMA==", "bodyText": "I am wondering if we should have a utility function to convert a list of PrestoSparkRow into a list of Blocks? -- we can leave this as TODO .", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381772710", "createdAt": "2020-02-20T05:35:43Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -270,11 +258,20 @@ private PrestoSparkQueryExecution(\n             queryCompletedEvent(Optional.empty());\n \n             ConnectorSession connectorSession = session.toConnectorSession();\n-            return resultRdd.stream()\n-                    .map(Tuple2::_2)\n-                    .map(this::deserializePage)\n-                    .flatMap(page -> getPageValues(connectorSession, page, rootFragment.getTypes()).stream())\n-                    .collect(toList());\n+            List<Type> types = rootFragment.getTypes();\n+            ImmutableList.Builder<List<Object>> result = ImmutableList.builder();\n+            for (Tuple2<Integer, PrestoSparkRow> tuple : resultRdd) {\n+                PrestoSparkRow row = tuple._2;\n+                SliceInput sliceInput = new BasicSliceInput(Slices.wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                ImmutableList.Builder<Object> columns = ImmutableList.builder();\n+                for (Type type : types) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzkwOTMyOQ==", "bodyText": "Currently this is a single place where it is done. Let's keep it here for now.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383909329", "createdAt": "2020-02-25T14:24:04Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -270,11 +258,20 @@ private PrestoSparkQueryExecution(\n             queryCompletedEvent(Optional.empty());\n \n             ConnectorSession connectorSession = session.toConnectorSession();\n-            return resultRdd.stream()\n-                    .map(Tuple2::_2)\n-                    .map(this::deserializePage)\n-                    .flatMap(page -> getPageValues(connectorSession, page, rootFragment.getTypes()).stream())\n-                    .collect(toList());\n+            List<Type> types = rootFragment.getTypes();\n+            ImmutableList.Builder<List<Object>> result = ImmutableList.builder();\n+            for (Tuple2<Integer, PrestoSparkRow> tuple : resultRdd) {\n+                PrestoSparkRow row = tuple._2;\n+                SliceInput sliceInput = new BasicSliceInput(Slices.wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                ImmutableList.Builder<Object> columns = ImmutableList.builder();\n+                for (Type type : types) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MjcxMA=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MzI5MzEzOnYy", "diffSide": "RIGHT", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNTozNzoxNFrOFsFmlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwNToyMDowOVrOFt4-Ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MzQ2MA==", "bodyText": "Why not using ClassLayout.parseClass as we did for other Presto class? -- I am asking this is just adding these bytes together doesn't necessarily sum up to the instance size ,  e.g. there are Java object padding size, etc.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381773460", "createdAt": "2020-02-20T05:37:14Z", "author": {"login": "wenleix"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MjI1NQ==", "bodyText": "The Jol library is not in the Spark's classpath, and I don't want to add one to avoid potential clashes.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382142255", "createdAt": "2020-02-20T17:18:09Z", "author": {"login": "arhimondr"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MzQ2MA=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzY2MzYxOA==", "bodyText": "@arhimondr : Sounds reasonable, just add a comment explain why this is the case.\nAlso, looks like JOL and your calculation returns different results? (You seems to over-estimate): https://gist.github.com/wenleix/faae51ac5fe3c0f688d8520c7c0d3105\nInstance Size from JOL: 24\nInstance Size from Andrii: 32", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383663618", "createdAt": "2020-02-25T05:20:09Z", "author": {"login": "wenleix"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MzQ2MA=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM2MzI5NzY5OnYy", "diffSide": "RIGHT", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMFQwNTozODozOFrOFsFpRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQyMzo1OTozM1rOFt0Mjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3NDE1MA==", "bodyText": "Similarly, we usually use SizeOf.sizeOf(bytes)", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381774150", "createdAt": "2020-02-20T05:38:38Z", "author": {"login": "wenleix"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */\n+            + Integer.BYTES /* partition */\n+            + Integer.BYTES /* length */\n+            + Long.BYTES /* bytes pointer */\n+            + Long.BYTES * 2 /* bytes headers */\n+            + Integer.BYTES /* bytes length */;\n+\n+    private final int partition;\n+    private final int length;\n     private final byte[] bytes;\n \n-    public SerializedPrestoSparkPage(byte[] bytes)\n+    public PrestoSparkRow(int partition, int length, byte[] bytes)\n     {\n+        this.partition = partition;\n+        this.length = length;\n         this.bytes = requireNonNull(bytes, \"bytes is null\");\n     }\n \n+    public int getPartition()\n+    {\n+        return partition;\n+    }\n+\n+    public int getLength()\n+    {\n+        return length;\n+    }\n+\n     public byte[] getBytes()\n     {\n         return bytes;\n     }\n+\n+    public long getRetainedSize()\n+    {\n+        return INSTANCE_SIZE + bytes.length;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MjU4Mg==", "bodyText": "SizeOf is in Slice library. I don't want to add it to avoid potential clashes.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382142582", "createdAt": "2020-02-20T17:18:43Z", "author": {"login": "arhimondr"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */\n+            + Integer.BYTES /* partition */\n+            + Integer.BYTES /* length */\n+            + Long.BYTES /* bytes pointer */\n+            + Long.BYTES * 2 /* bytes headers */\n+            + Integer.BYTES /* bytes length */;\n+\n+    private final int partition;\n+    private final int length;\n     private final byte[] bytes;\n \n-    public SerializedPrestoSparkPage(byte[] bytes)\n+    public PrestoSparkRow(int partition, int length, byte[] bytes)\n     {\n+        this.partition = partition;\n+        this.length = length;\n         this.bytes = requireNonNull(bytes, \"bytes is null\");\n     }\n \n+    public int getPartition()\n+    {\n+        return partition;\n+    }\n+\n+    public int getLength()\n+    {\n+        return length;\n+    }\n+\n     public byte[] getBytes()\n     {\n         return bytes;\n     }\n+\n+    public long getRetainedSize()\n+    {\n+        return INSTANCE_SIZE + bytes.length;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3NDE1MA=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU4NTQyMg==", "bodyText": "In this case, should we just copy sizeOfByteArray implementation? i.e. something like\n    public long getRetainedSize()\n    {\n        return INSTANCE_SIZE + sizeOfByteArray(bytes.length);\n    }\n\n    // Copied from SizeOf#sizeOfByteArray in Slice library\n    private static long sizeOfByteArray(int length)\n    {\n        return ARRAY_BYTE_BASE_OFFSET + (((long) ARRAY_BYTE_INDEX_SCALE) * length);\n    }", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383585422", "createdAt": "2020-02-24T23:59:33Z", "author": {"login": "wenleix"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */\n+            + Integer.BYTES /* partition */\n+            + Integer.BYTES /* length */\n+            + Long.BYTES /* bytes pointer */\n+            + Long.BYTES * 2 /* bytes headers */\n+            + Integer.BYTES /* bytes length */;\n+\n+    private final int partition;\n+    private final int length;\n     private final byte[] bytes;\n \n-    public SerializedPrestoSparkPage(byte[] bytes)\n+    public PrestoSparkRow(int partition, int length, byte[] bytes)\n     {\n+        this.partition = partition;\n+        this.length = length;\n         this.bytes = requireNonNull(bytes, \"bytes is null\");\n     }\n \n+    public int getPartition()\n+    {\n+        return partition;\n+    }\n+\n+    public int getLength()\n+    {\n+        return length;\n+    }\n+\n     public byte[] getBytes()\n     {\n         return bytes;\n     }\n+\n+    public long getRetainedSize()\n+    {\n+        return INSTANCE_SIZE + bytes.length;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3NDE1MA=="}, "originalCommit": {"oid": "15dc6614cb36f515819e831cbfbfbc8fef635adf"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MTA4NjE1OnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNToxNzowOVrOFtOV2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQyMjoyODo0NlrOFtyNVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTIwOA==", "bodyText": "I don't think this needs to be volatile", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382965208", "createdAt": "2020-02-23T05:17:09Z", "author": {"login": "tdcmeehan"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0MjkwMQ==", "bodyText": "Yes. Since the variable is guarded by lock the volatile modifier is not needed, as the synchronized block guarantees the ordering. However it is generally a good practice to keep the volatile modifier as it doesn't introduce any performance regressions while allowing to use the variable directly without synchronization where compare-and-set semantics are not needed.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383342901", "createdAt": "2020-02-24T15:44:21Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTIwOA=="}, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU1MTA4MA==", "bodyText": "I think for boolean/byte/integer, JMM grantees it's an atomic update: https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.7 .\n@arhimondr : Are you more worried about the \"Happens Before\" memory model ? (See references in #8772 (comment))  . In that case adding volatile guarantees sequentially consistent  memory model :)", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383551080", "createdAt": "2020-02-24T22:24:40Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTIwOA=="}, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU1Mjg1Mg==", "bodyText": "Since this variable is never accessed outside the lock it doesn't have to be volatile as synchronization enforces the memory ordering. It can be safely removed. I added it just in case somebody accidental uses it outside the lock (e.g.: simple atomic read). However now I'm not sure how much of sense does it make. Let me simply remove it to avoid confusion.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383552852", "createdAt": "2020-02-24T22:28:46Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTIwOA=="}, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MTA5MDAyOnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNToyNjozOFrOFtOXnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQyMjoyNjozNlrOFtyJ1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY2MA==", "bodyText": "Could we use an ArrayBlockingDeque and remove the synchronization in this class?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382965660", "createdAt": "2020-02-23T05:26:38Z", "author": {"login": "tdcmeehan"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0MzQ3NA==", "bodyText": "ArrayBlockingDeque blocks based on the number of elements. We want to block based on the memory utilization instead.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383343474", "createdAt": "2020-02-24T15:45:13Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY2MA=="}, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU1MTk1Ng==", "bodyText": "Discussed offline, a linked blocking queue would work but we'd suffer pointer indirection costs.  There's high performance unbounded array blocking queues out there but not worth the additional dependency.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383551956", "createdAt": "2020-02-24T22:26:36Z", "author": {"login": "tdcmeehan"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY2MA=="}, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MTA5MDMwOnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNToyNzozNlrOFtOXvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTo0NjozNFrOFtle4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY5Mw==", "bodyText": "Should we clear the buffer as well?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382965693", "createdAt": "2020-02-23T05:27:36Z", "author": {"login": "tdcmeehan"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;\n+\n+    public PrestoSparkRowBuffer(OutputBufferMemoryManager memoryManager)\n+    {\n+        this.memoryManager = requireNonNull(memoryManager, \"memoryManager is null\");\n+    }\n+\n+    public ListenableFuture<?> isFull()\n+    {\n+        return memoryManager.getBufferBlockedFuture();\n+    }\n+\n+    public void enqueue(PrestoSparkRow row)\n+    {\n+        requireNonNull(row, \"row is null\");\n+        synchronized (monitor) {\n+            buffer.add(row);\n+            monitor.notify();\n+        }\n+        memoryManager.updateMemoryUsage(row.getRetainedSize());\n+    }\n+\n+    public void setNoMoreRows()\n+    {\n+        memoryManager.setNoBlockOnFull();\n+        synchronized (monitor) {\n+            finished = true;\n+            monitor.notifyAll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0NDM1NA==", "bodyText": "No. Buffered rows has to be consumed by the consumer.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383344354", "createdAt": "2020-02-24T15:46:34Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;\n+\n+    public PrestoSparkRowBuffer(OutputBufferMemoryManager memoryManager)\n+    {\n+        this.memoryManager = requireNonNull(memoryManager, \"memoryManager is null\");\n+    }\n+\n+    public ListenableFuture<?> isFull()\n+    {\n+        return memoryManager.getBufferBlockedFuture();\n+    }\n+\n+    public void enqueue(PrestoSparkRow row)\n+    {\n+        requireNonNull(row, \"row is null\");\n+        synchronized (monitor) {\n+            buffer.add(row);\n+            monitor.notify();\n+        }\n+        memoryManager.updateMemoryUsage(row.getRetainedSize());\n+    }\n+\n+    public void setNoMoreRows()\n+    {\n+        memoryManager.setNoBlockOnFull();\n+        synchronized (monitor) {\n+            finished = true;\n+            monitor.notifyAll();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY5Mw=="}, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MjA0MjYzOnYy", "diffSide": "RIGHT", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwNTozNjo1NFrOFtWDqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxNTo0Nzo0MFrOFtlhiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTYyNw==", "bodyText": "Have you considered adding something like an overload to getObjectValue that takes in a sliceInput, to avoid having to create the block builder per cell?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383091627", "createdAt": "2020-02-24T05:36:54Z", "author": {"login": "tdcmeehan"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -270,11 +258,20 @@ private PrestoSparkQueryExecution(\n             queryCompletedEvent(Optional.empty());\n \n             ConnectorSession connectorSession = session.toConnectorSession();\n-            return resultRdd.stream()\n-                    .map(Tuple2::_2)\n-                    .map(this::deserializePage)\n-                    .flatMap(page -> getPageValues(connectorSession, page, rootFragment.getTypes()).stream())\n-                    .collect(toList());\n+            List<Type> types = rootFragment.getTypes();\n+            ImmutableList.Builder<List<Object>> result = ImmutableList.builder();\n+            for (Tuple2<Integer, PrestoSparkRow> tuple : resultRdd) {\n+                PrestoSparkRow row = tuple._2;\n+                SliceInput sliceInput = new BasicSliceInput(Slices.wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                ImmutableList.Builder<Object> columns = ImmutableList.builder();\n+                for (Type type : types) {\n+                    BlockBuilder blockBuilder = type.createBlockBuilder(null, 1);\n+                    blockBuilder.deserializePosition(sliceInput);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0NTAzMw==", "bodyText": "This is only used to produce the final output to the client, which is not expected to be large.", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383345033", "createdAt": "2020-02-24T15:47:40Z", "author": {"login": "arhimondr"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -270,11 +258,20 @@ private PrestoSparkQueryExecution(\n             queryCompletedEvent(Optional.empty());\n \n             ConnectorSession connectorSession = session.toConnectorSession();\n-            return resultRdd.stream()\n-                    .map(Tuple2::_2)\n-                    .map(this::deserializePage)\n-                    .flatMap(page -> getPageValues(connectorSession, page, rootFragment.getTypes()).stream())\n-                    .collect(toList());\n+            List<Type> types = rootFragment.getTypes();\n+            ImmutableList.Builder<List<Object>> result = ImmutableList.builder();\n+            for (Tuple2<Integer, PrestoSparkRow> tuple : resultRdd) {\n+                PrestoSparkRow row = tuple._2;\n+                SliceInput sliceInput = new BasicSliceInput(Slices.wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                ImmutableList.Builder<Object> columns = ImmutableList.builder();\n+                for (Type type : types) {\n+                    BlockBuilder blockBuilder = type.createBlockBuilder(null, 1);\n+                    blockBuilder.deserializePosition(sliceInput);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTYyNw=="}, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 166}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NTc0NTQwOnYy", "diffSide": "RIGHT", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwNToxODo0N1rOFt48tQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQxNDoyNToxNFrOFuIAoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzY2MzI4NQ==", "bodyText": "bytes headers and bytes length should probably go into sizeOfByteArray?", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383663285", "createdAt": "2020-02-25T05:18:47Z", "author": {"login": "wenleix"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */\n+            + Integer.BYTES /* partition */\n+            + Integer.BYTES /* length */\n+            + Long.BYTES /* bytes pointer */\n+            + Long.BYTES * 2 /* bytes headers */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzkxMDA0OA==", "bodyText": "sizeOfByteArray is in the Slice library. It is not available here =\\", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383910048", "createdAt": "2020-02-25T14:25:14Z", "author": {"login": "arhimondr"}, "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */\n+            + Integer.BYTES /* partition */\n+            + Integer.BYTES /* length */\n+            + Long.BYTES /* bytes pointer */\n+            + Long.BYTES * 2 /* bytes headers */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzY2MzI4NQ=="}, "originalCommit": {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137"}, "originalPosition": 12}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3006, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}