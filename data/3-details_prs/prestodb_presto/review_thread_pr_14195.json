{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgzMTI1MDgy", "number": 14195, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QxOToxNzo1N1rODkyE-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QxOToxNzo1N1rODkyE-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5ODk1ODAxOnYy", "diffSide": "RIGHT", "path": "presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QxOToxNzo1N1rOFxTH0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QyMTozODoxNFrOFxXcxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzIzNzg0Mg==", "bodyText": "Curious why issue get raised by recoverable grouped execution? :)", "url": "https://github.com/prestodb/presto/pull/14195#discussion_r387237842", "createdAt": "2020-03-03T19:17:57Z", "author": {"login": "wenleix"}, "path": "presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java", "diffHunk": "@@ -880,7 +876,15 @@ private void failTask(Throwable cause)\n             log.debug(cause, \"Remote task %s failed with %s\", taskStatus.getSelf(), cause);\n         }\n \n-        abort(failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause))));\n+        TaskStatus failedTaskStatus = failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause)));\n+        // Transition task to failed state without waiting for the final task info returned by the abort request.\n+        // The abort request is very likely not to succeed, leaving the task and the stage in the limbo state for", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e3dec392d146925c4de9be0bbe47bed45020a22"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzIzOTE2Ng==", "bodyText": "I see. Because failed task doesn't fail the whole query. Now if we don't update the task info , the failed task might stuck in RUNNING state :)\nStill , the task should eventually fail once all the abort retries finished right -- rather than stuck in RUNNING forever? cc @shixuan-fan", "url": "https://github.com/prestodb/presto/pull/14195#discussion_r387239166", "createdAt": "2020-03-03T19:20:32Z", "author": {"login": "wenleix"}, "path": "presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java", "diffHunk": "@@ -880,7 +876,15 @@ private void failTask(Throwable cause)\n             log.debug(cause, \"Remote task %s failed with %s\", taskStatus.getSelf(), cause);\n         }\n \n-        abort(failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause))));\n+        TaskStatus failedTaskStatus = failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause)));\n+        // Transition task to failed state without waiting for the final task info returned by the abort request.\n+        // The abort request is very likely not to succeed, leaving the task and the stage in the limbo state for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzIzNzg0Mg=="}, "originalCommit": {"oid": "5e3dec392d146925c4de9be0bbe47bed45020a22"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzI0NTg1Mg==", "bodyText": "Before the recoverable grouped execution the behaviour was \"all or nothing\". As long as any task fails - the entire query fails. And if the query is failed - the client doesn't wait for the final task info: \n  \n    \n      presto/presto-main/src/main/java/com/facebook/presto/server/protocol/Query.java\n    \n    \n         Line 474\n      in\n      8d5d5e6\n    \n    \n    \n    \n\n        \n          \n           if (!queryInfo.isFinalQueryInfo() && !queryInfo.getState().equals(QueryState.FAILED) \n        \n    \n  \n\n.\nIn case of recoverable execution the task failure doesn't necessarily mean query failure. If a task fails the lifespan is rescheduled to a different task.\nHowever, even if all lifespans are done, the query cannot transition to FINISHED before every task receives the final task info. Since the node is (most likely) down the task will never get the final task info before timeout (10 minutes) (\n  \n    \n      presto/presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java\n    \n    \n         Line 864\n      in\n      5e3dec3\n    \n    \n    \n    \n\n        \n          \n           updateTaskInfo(getTaskInfo().withTaskStatus(getTaskStatus())); \n        \n    \n  \n\n) effectively preventing the query from transitioning to FINISHED state.\nAs a solution @shixuan-fan added a shortcut that used to transition a failed task right away to failed state, setting the final task info to \"failed\". Generally it makes perfect sense, as there's no reason to wait for 10 minutes for something that is know to be failed.\nHowever, the same method is used for abort. Abort is called when the query is finished, but some tasks are still running. Sometimes it is a legit behaviour (e.g.: SCAN -> LIMIT where LIMIT can terminate the query prematurely), and sometimes it is just racy (e.g.: query finishes before the coordinator receives the final task info for a task from a worker). Although it might be less important to receive correct task statistics for the first case (since it is inherently racy), for the second case it is pretty important. Otherwise stats could be very inconsistent.", "url": "https://github.com/prestodb/presto/pull/14195#discussion_r387245852", "createdAt": "2020-03-03T19:32:51Z", "author": {"login": "arhimondr"}, "path": "presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java", "diffHunk": "@@ -880,7 +876,15 @@ private void failTask(Throwable cause)\n             log.debug(cause, \"Remote task %s failed with %s\", taskStatus.getSelf(), cause);\n         }\n \n-        abort(failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause))));\n+        TaskStatus failedTaskStatus = failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause)));\n+        // Transition task to failed state without waiting for the final task info returned by the abort request.\n+        // The abort request is very likely not to succeed, leaving the task and the stage in the limbo state for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzIzNzg0Mg=="}, "originalCommit": {"oid": "5e3dec392d146925c4de9be0bbe47bed45020a22"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzI0NjQ1OA==", "bodyText": "Still , the task should eventually fail once all the abort retries finished right -- rather than stuck in RUNNING forever?\n\nYes. But current timeout is 10 minutes. Having your query stuck for 10 minutes is generally not desirable.", "url": "https://github.com/prestodb/presto/pull/14195#discussion_r387246458", "createdAt": "2020-03-03T19:34:00Z", "author": {"login": "arhimondr"}, "path": "presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java", "diffHunk": "@@ -880,7 +876,15 @@ private void failTask(Throwable cause)\n             log.debug(cause, \"Remote task %s failed with %s\", taskStatus.getSelf(), cause);\n         }\n \n-        abort(failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause))));\n+        TaskStatus failedTaskStatus = failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause)));\n+        // Transition task to failed state without waiting for the final task info returned by the abort request.\n+        // The abort request is very likely not to succeed, leaving the task and the stage in the limbo state for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzIzNzg0Mg=="}, "originalCommit": {"oid": "5e3dec392d146925c4de9be0bbe47bed45020a22"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzI5NjM4Mg==", "bodyText": "Does this also address the issue where sometimes there are no stats available for the failure stage of a query?", "url": "https://github.com/prestodb/presto/pull/14195#discussion_r387296382", "createdAt": "2020-03-03T21:12:29Z", "author": {"login": "rschlussel"}, "path": "presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java", "diffHunk": "@@ -880,7 +876,15 @@ private void failTask(Throwable cause)\n             log.debug(cause, \"Remote task %s failed with %s\", taskStatus.getSelf(), cause);\n         }\n \n-        abort(failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause))));\n+        TaskStatus failedTaskStatus = failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause)));\n+        // Transition task to failed state without waiting for the final task info returned by the abort request.\n+        // The abort request is very likely not to succeed, leaving the task and the stage in the limbo state for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzIzNzg0Mg=="}, "originalCommit": {"oid": "5e3dec392d146925c4de9be0bbe47bed45020a22"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzMwODc0Mw==", "bodyText": "@rschlussel I'm not sure. It is likely to be unrelated though.", "url": "https://github.com/prestodb/presto/pull/14195#discussion_r387308743", "createdAt": "2020-03-03T21:38:14Z", "author": {"login": "arhimondr"}, "path": "presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java", "diffHunk": "@@ -880,7 +876,15 @@ private void failTask(Throwable cause)\n             log.debug(cause, \"Remote task %s failed with %s\", taskStatus.getSelf(), cause);\n         }\n \n-        abort(failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause))));\n+        TaskStatus failedTaskStatus = failWith(getTaskStatus(), FAILED, ImmutableList.of(toFailure(cause)));\n+        // Transition task to failed state without waiting for the final task info returned by the abort request.\n+        // The abort request is very likely not to succeed, leaving the task and the stage in the limbo state for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzIzNzg0Mg=="}, "originalCommit": {"oid": "5e3dec392d146925c4de9be0bbe47bed45020a22"}, "originalPosition": 18}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2839, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}