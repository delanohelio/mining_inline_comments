{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3Njc2Mjky", "number": 14522, "title": "Integrate Presto on Spark with the TaskExecutor", "bodyText": "== NO RELEASE NOTE ==", "createdAt": "2020-05-14T00:05:52Z", "url": "https://github.com/prestodb/presto/pull/14522", "merged": true, "mergeCommit": {"oid": "9ce5647c07a8d0f96d1c0aad5f94adbd64b26f48"}, "closed": true, "closedAt": "2020-06-02T15:33:38Z", "author": {"login": "arhimondr"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcipibOgBqjMzNDk2MDg0MTQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcnPNbHAFqTQyMjM4NzUzOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a95c9e6e22e019cb3a6f21da2258f41c3120f944", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/a95c9e6e22e019cb3a6f21da2258f41c3120f944", "committedDate": "2020-05-13T23:52:56Z", "message": "Decrease lock contention in PrestoSparkRowBuffer"}, "afterCommit": {"oid": "300486947eda67b73ecc3c6bee9a50ec9d22dafb", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/300486947eda67b73ecc3c6bee9a50ec9d22dafb", "committedDate": "2020-05-19T00:24:37Z", "message": "Disable force single node output for Presto on Spark"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3d42abf24c89da3ddbfa5f7caa68d380b9c4a5e2", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/3d42abf24c89da3ddbfa5f7caa68d380b9c4a5e2", "committedDate": "2020-05-20T03:08:31Z", "message": "Reduce spark integration tests memory footprint"}, "afterCommit": {"oid": "c157581bd4797cd8267a5535be970234d917e9a2", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/c157581bd4797cd8267a5535be970234d917e9a2", "committedDate": "2020-05-22T19:49:01Z", "message": "Decrease lock contention in PrestoSparkRowBuffer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5ODE0MDg5", "url": "https://github.com/prestodb/presto/pull/14522#pullrequestreview-419814089", "createdAt": "2020-05-28T06:35:54Z", "commit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQwNjozNTo1NFrOGbndTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQwNjozNTo1NFrOGbndTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMTIxNA==", "bodyText": "FWIW, before grouped execution is introduced in 4e55aad, they are called partitionedDriverRunnerFactories and unpartitionedDriverRunnerFactories :) . We can also call them tableScanDriverRunnerFactories vs. exchangeDriverRunenrFactories? :)", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r431611214", "createdAt": "2020-05-28T06:35:54Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "originalPosition": 91}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5ODE2NzY2", "url": "https://github.com/prestodb/presto/pull/14522#pullrequestreview-419816766", "createdAt": "2020-05-28T06:41:16Z", "commit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQwNjo0MToxN1rOGbnlSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQwNjo0MToxN1rOGbnlSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMzI1Ng==", "bodyText": "I am thinking if it makes sense to write imperative for-loop here? -- My general preference is when Stream API is used in such a complicated way, it's actually more difficult to understand than old good for-loop.\nBut it's just a personal taste.", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r431613256", "createdAt": "2020-05-28T06:41:17Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();\n+\n+    public PrestoSparkTaskExecution(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor,\n+            SplitMonitor splitMonitor,\n+            Executor notificationExecutor)\n+    {\n+        this.taskStateMachine = requireNonNull(taskStateMachine, \"taskStateMachine is null\");\n+        this.taskId = taskStateMachine.getTaskId();\n+        this.taskContext = requireNonNull(taskContext, \"taskContext is null\");\n+\n+        this.taskExecutor = requireNonNull(taskExecutor, \"driverExecutor is null\");\n+        this.notificationExecutor = requireNonNull(notificationExecutor, \"notificationExecutor is null\");\n+\n+        this.splitMonitor = requireNonNull(splitMonitor, \"splitMonitor is null\");\n+\n+        // index driver factories\n+        schedulingOrder = localExecutionPlan.getTableScanSourceOrder();\n+        Set<PlanNodeId> tableScanSources = ImmutableSet.copyOf(schedulingOrder);\n+        ImmutableMap.Builder<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle = ImmutableMap.builder();\n+        ImmutableList.Builder<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle = ImmutableList.builder();\n+        for (DriverFactory driverFactory : localExecutionPlan.getDriverFactories()) {\n+            Optional<PlanNodeId> sourceId = driverFactory.getSourceId();\n+            if (sourceId.isPresent() && tableScanSources.contains(sourceId.get())) {\n+                driverRunnerFactoriesWithSplitLifeCycle.put(sourceId.get(), new DriverSplitRunnerFactory(driverFactory, true));\n+            }\n+            else {\n+                checkArgument(\n+                        driverFactory.getPipelineExecutionStrategy() == UNGROUPED_EXECUTION,\n+                        \"unexpected pipeline execution strategy: %s\",\n+                        driverFactory.getPipelineExecutionStrategy());\n+                driverRunnerFactoriesWithTaskLifeCycle.add(new DriverSplitRunnerFactory(driverFactory, false));\n+            }\n+        }\n+        this.driverRunnerFactoriesWithSplitLifeCycle = driverRunnerFactoriesWithSplitLifeCycle.build();\n+        this.driverRunnerFactoriesWithTaskLifeCycle = driverRunnerFactoriesWithTaskLifeCycle.build();\n+\n+        checkArgument(this.driverRunnerFactoriesWithSplitLifeCycle.keySet().equals(tableScanSources),\n+                \"Fragment is partitioned, but not all partitioned drivers were found\");\n+\n+        taskHandle = createTaskHandle(taskStateMachine, taskContext, localExecutionPlan, taskExecutor);\n+    }\n+\n+    // this is a separate method to ensure that the `this` reference is not leaked during construction\n+    private static TaskHandle createTaskHandle(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor)\n+    {\n+        TaskHandle taskHandle = taskExecutor.addTask(\n+                taskStateMachine.getTaskId(),\n+                () -> 0,\n+                getInitialSplitsPerNode(taskContext.getSession()),\n+                getSplitConcurrencyAdjustmentInterval(taskContext.getSession()),\n+                getMaxDriversPerTask(taskContext.getSession()));\n+        taskStateMachine.addStateChangeListener(state -> {\n+            if (state.isDone()) {\n+                taskExecutor.removeTask(taskHandle);\n+                for (DriverFactory factory : localExecutionPlan.getDriverFactories()) {\n+                    factory.noMoreDrivers();\n+                }\n+            }\n+        });\n+        return taskHandle;\n+    }\n+\n+    public void start(List<TaskSource> sources)\n+    {\n+        requireNonNull(sources, \"sources is null\");\n+\n+        scheduleDriversForTaskLifeCycle();\n+        scheduleDriversForSplitLifeCycle(sources);\n+        checkTaskCompletion();\n+    }\n+\n+    private void scheduleDriversForTaskLifeCycle()\n+    {\n+        List<DriverSplitRunner> runners = new ArrayList<>();\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            for (int i = 0; i < driverRunnerFactory.getDriverInstances().orElse(1); i++) {\n+                runners.add(driverRunnerFactory.createDriverRunner(null));\n+            }\n+        }\n+        enqueueDriverSplitRunner(true, runners);\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            driverRunnerFactory.noMoreDriverRunner();\n+            verify(driverRunnerFactory.isNoMoreDriverRunner());\n+        }\n+    }\n+\n+    private synchronized void scheduleDriversForSplitLifeCycle(List<TaskSource> sources)\n+    {\n+        checkArgument(sources.stream().allMatch(TaskSource::isNoMoreSplits), \"All task sources are expected to be final\");\n+\n+        Map<PlanNodeId, List<ScheduledSplit>> splits = sources.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "originalPosition": 192}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5ODE3NjQ3", "url": "https://github.com/prestodb/presto/pull/14522#pullrequestreview-419817647", "createdAt": "2020-05-28T06:42:57Z", "commit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQwNjo0Mjo1N1rOGbnn3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQwNjo0Mjo1N1rOGbnn3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMzkxNw==", "bodyText": "Are you forking the current SqlTaskExecution (and remove grouped execution related stuff), or you are forking the old SqlTaskExecution (i.e. before commit 4e55aad) . In my opinion the code is much easier to follow with the old SqlTaskExecution", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r431613917", "createdAt": "2020-05-28T06:42:57Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNjc0MDc4", "url": "https://github.com/prestodb/presto/pull/14522#pullrequestreview-420674078", "createdAt": "2020-05-29T06:05:50Z", "commit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwNjowNTo1MFrOGcP3LQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwNjowNTo1MFrOGcP3LQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3MzE5Nw==", "bodyText": "Maybe add some guard to make sure start will only be called once? :)", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r432273197", "createdAt": "2020-05-29T06:05:50Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();\n+\n+    public PrestoSparkTaskExecution(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor,\n+            SplitMonitor splitMonitor,\n+            Executor notificationExecutor)\n+    {\n+        this.taskStateMachine = requireNonNull(taskStateMachine, \"taskStateMachine is null\");\n+        this.taskId = taskStateMachine.getTaskId();\n+        this.taskContext = requireNonNull(taskContext, \"taskContext is null\");\n+\n+        this.taskExecutor = requireNonNull(taskExecutor, \"driverExecutor is null\");\n+        this.notificationExecutor = requireNonNull(notificationExecutor, \"notificationExecutor is null\");\n+\n+        this.splitMonitor = requireNonNull(splitMonitor, \"splitMonitor is null\");\n+\n+        // index driver factories\n+        schedulingOrder = localExecutionPlan.getTableScanSourceOrder();\n+        Set<PlanNodeId> tableScanSources = ImmutableSet.copyOf(schedulingOrder);\n+        ImmutableMap.Builder<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle = ImmutableMap.builder();\n+        ImmutableList.Builder<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle = ImmutableList.builder();\n+        for (DriverFactory driverFactory : localExecutionPlan.getDriverFactories()) {\n+            Optional<PlanNodeId> sourceId = driverFactory.getSourceId();\n+            if (sourceId.isPresent() && tableScanSources.contains(sourceId.get())) {\n+                driverRunnerFactoriesWithSplitLifeCycle.put(sourceId.get(), new DriverSplitRunnerFactory(driverFactory, true));\n+            }\n+            else {\n+                checkArgument(\n+                        driverFactory.getPipelineExecutionStrategy() == UNGROUPED_EXECUTION,\n+                        \"unexpected pipeline execution strategy: %s\",\n+                        driverFactory.getPipelineExecutionStrategy());\n+                driverRunnerFactoriesWithTaskLifeCycle.add(new DriverSplitRunnerFactory(driverFactory, false));\n+            }\n+        }\n+        this.driverRunnerFactoriesWithSplitLifeCycle = driverRunnerFactoriesWithSplitLifeCycle.build();\n+        this.driverRunnerFactoriesWithTaskLifeCycle = driverRunnerFactoriesWithTaskLifeCycle.build();\n+\n+        checkArgument(this.driverRunnerFactoriesWithSplitLifeCycle.keySet().equals(tableScanSources),\n+                \"Fragment is partitioned, but not all partitioned drivers were found\");\n+\n+        taskHandle = createTaskHandle(taskStateMachine, taskContext, localExecutionPlan, taskExecutor);\n+    }\n+\n+    // this is a separate method to ensure that the `this` reference is not leaked during construction\n+    private static TaskHandle createTaskHandle(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor)\n+    {\n+        TaskHandle taskHandle = taskExecutor.addTask(\n+                taskStateMachine.getTaskId(),\n+                () -> 0,\n+                getInitialSplitsPerNode(taskContext.getSession()),\n+                getSplitConcurrencyAdjustmentInterval(taskContext.getSession()),\n+                getMaxDriversPerTask(taskContext.getSession()));\n+        taskStateMachine.addStateChangeListener(state -> {\n+            if (state.isDone()) {\n+                taskExecutor.removeTask(taskHandle);\n+                for (DriverFactory factory : localExecutionPlan.getDriverFactories()) {\n+                    factory.noMoreDrivers();\n+                }\n+            }\n+        });\n+        return taskHandle;\n+    }\n+\n+    public void start(List<TaskSource> sources)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "originalPosition": 164}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNjgwMjk0", "url": "https://github.com/prestodb/presto/pull/14522#pullrequestreview-420680294", "createdAt": "2020-05-29T06:21:50Z", "commit": {"oid": "c157581bd4797cd8267a5535be970234d917e9a2"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwNjoyMTo1MFrOGcQJzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwNjoyOTo1NlrOGcQUtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3Nzk2Ng==", "bodyText": "Does this has to be a ImutableList.Builder? -- or a normal ArrayList would be good?\nAlso maybe consider to use previous list size to initialize new array list capacity -- although shouldn't be a big issue.", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r432277966", "createdAt": "2020-05-29T06:21:50Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -245,15 +258,29 @@ public void addInput(Page page)\n             byte[] rowBytes = output.size() == 0 ? new byte[0] : output.getUnderlyingSlice().byteArray();\n             if (shouldReplicate) {\n                 for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n-                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), rowBytes));\n+                    appendRow(new PrestoSparkRow(i, output.size(), rowBytes));\n                 }\n                 hasAnyRowBeenReplicated = true;\n             }\n             else {\n                 int partition = getPartition(partitionFunctionArguments, position);\n-                rowBuffer.enqueue(new PrestoSparkRow(partition, output.size(), rowBytes));\n+                appendRow(new PrestoSparkRow(partition, output.size(), rowBytes));\n             }\n         }\n+        updateMemoryContext();\n+    }\n+\n+    private void appendRow(PrestoSparkRow row)\n+    {\n+        long rowSize = row.getRetainedSize();\n+        if (currentBatchSize + rowSize > BATCH_SIZE) {\n+            flush();\n+        }\n+        if (currentBatch == null) {\n+            currentBatch = ImmutableList.builderWithExpectedSize(EXPECTED_ROWS_COUNT_PER_BATCH);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c157581bd4797cd8267a5535be970234d917e9a2"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3OTYwOA==", "bodyText": "Is this only get called twice ? (once enqueue and once get)? Note in theory we can always reduce the retain size computation to be once (by wrapping it with something like PrestoSparkRowBatch. But if it's just computed twice I think it's OK to keep it as is.", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r432279608", "createdAt": "2020-05-29T06:26:36Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -63,21 +65,34 @@ public void setNoMoreRows()\n         }\n     }\n \n-    public PrestoSparkRow get()\n+    public List<PrestoSparkRow> get()\n             throws InterruptedException\n     {\n-        PrestoSparkRow row = null;\n+        List<PrestoSparkRow> rows = null;\n         synchronized (monitor) {\n             while (buffer.isEmpty() && !finished) {\n                 monitor.wait();\n             }\n             if (!buffer.isEmpty()) {\n-                row = buffer.poll();\n+                rows = buffer.poll();\n             }\n-            if (row != null) {\n-                memoryManager.updateMemoryUsage(-row.getRetainedSize());\n+            if (rows != null) {\n+                memoryManager.updateMemoryUsage(-getRetainedSize(rows));\n             }\n         }\n-        return row;\n+        return rows;\n+    }\n+\n+    /**\n+     * Does not use iterators / streams for efficiency\n+     */\n+    @SuppressWarnings(\"ForLoopReplaceableByForEach\")\n+    private static long getRetainedSize(List<PrestoSparkRow> rows)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c157581bd4797cd8267a5535be970234d917e9a2"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI4MDc1OA==", "bodyText": "Note the memory doesn't really get cleaned before this batch get fully consumed by PrestoSparkTaskExecutor#getNextRow. So we could under-count 1 batch of rows. Is this acceptable?", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r432280758", "createdAt": "2020-05-29T06:29:56Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -63,21 +65,34 @@ public void setNoMoreRows()\n         }\n     }\n \n-    public PrestoSparkRow get()\n+    public List<PrestoSparkRow> get()\n             throws InterruptedException\n     {\n-        PrestoSparkRow row = null;\n+        List<PrestoSparkRow> rows = null;\n         synchronized (monitor) {\n             while (buffer.isEmpty() && !finished) {\n                 monitor.wait();\n             }\n             if (!buffer.isEmpty()) {\n-                row = buffer.poll();\n+                rows = buffer.poll();\n             }\n-            if (row != null) {\n-                memoryManager.updateMemoryUsage(-row.getRetainedSize());\n+            if (rows != null) {\n+                memoryManager.updateMemoryUsage(-getRetainedSize(rows));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c157581bd4797cd8267a5535be970234d917e9a2"}, "originalPosition": 58}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxNjA3NDI0", "url": "https://github.com/prestodb/presto/pull/14522#pullrequestreview-421607424", "createdAt": "2020-06-01T05:53:12Z", "commit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQwNTo1MzoxMlrOGc_eZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQwNjowNTozOFrOGc_rBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA1MzI4NA==", "bodyText": "I think the comment in SqlTaskExecution is probably useful?\n    /**\n     * Number of drivers that have been sent to the TaskExecutor that have not finished.\n     */", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433053284", "createdAt": "2020-06-01T05:53:12Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA1NjEyMg==", "bodyText": "Curious: why need to track closed in DriverSplitRunnerFactory?", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433056122", "createdAt": "2020-06-01T06:04:12Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();\n+\n+    public PrestoSparkTaskExecution(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor,\n+            SplitMonitor splitMonitor,\n+            Executor notificationExecutor)\n+    {\n+        this.taskStateMachine = requireNonNull(taskStateMachine, \"taskStateMachine is null\");\n+        this.taskId = taskStateMachine.getTaskId();\n+        this.taskContext = requireNonNull(taskContext, \"taskContext is null\");\n+\n+        this.taskExecutor = requireNonNull(taskExecutor, \"driverExecutor is null\");\n+        this.notificationExecutor = requireNonNull(notificationExecutor, \"notificationExecutor is null\");\n+\n+        this.splitMonitor = requireNonNull(splitMonitor, \"splitMonitor is null\");\n+\n+        // index driver factories\n+        schedulingOrder = localExecutionPlan.getTableScanSourceOrder();\n+        Set<PlanNodeId> tableScanSources = ImmutableSet.copyOf(schedulingOrder);\n+        ImmutableMap.Builder<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle = ImmutableMap.builder();\n+        ImmutableList.Builder<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle = ImmutableList.builder();\n+        for (DriverFactory driverFactory : localExecutionPlan.getDriverFactories()) {\n+            Optional<PlanNodeId> sourceId = driverFactory.getSourceId();\n+            if (sourceId.isPresent() && tableScanSources.contains(sourceId.get())) {\n+                driverRunnerFactoriesWithSplitLifeCycle.put(sourceId.get(), new DriverSplitRunnerFactory(driverFactory, true));\n+            }\n+            else {\n+                checkArgument(\n+                        driverFactory.getPipelineExecutionStrategy() == UNGROUPED_EXECUTION,\n+                        \"unexpected pipeline execution strategy: %s\",\n+                        driverFactory.getPipelineExecutionStrategy());\n+                driverRunnerFactoriesWithTaskLifeCycle.add(new DriverSplitRunnerFactory(driverFactory, false));\n+            }\n+        }\n+        this.driverRunnerFactoriesWithSplitLifeCycle = driverRunnerFactoriesWithSplitLifeCycle.build();\n+        this.driverRunnerFactoriesWithTaskLifeCycle = driverRunnerFactoriesWithTaskLifeCycle.build();\n+\n+        checkArgument(this.driverRunnerFactoriesWithSplitLifeCycle.keySet().equals(tableScanSources),\n+                \"Fragment is partitioned, but not all partitioned drivers were found\");\n+\n+        taskHandle = createTaskHandle(taskStateMachine, taskContext, localExecutionPlan, taskExecutor);\n+    }\n+\n+    // this is a separate method to ensure that the `this` reference is not leaked during construction\n+    private static TaskHandle createTaskHandle(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor)\n+    {\n+        TaskHandle taskHandle = taskExecutor.addTask(\n+                taskStateMachine.getTaskId(),\n+                () -> 0,\n+                getInitialSplitsPerNode(taskContext.getSession()),\n+                getSplitConcurrencyAdjustmentInterval(taskContext.getSession()),\n+                getMaxDriversPerTask(taskContext.getSession()));\n+        taskStateMachine.addStateChangeListener(state -> {\n+            if (state.isDone()) {\n+                taskExecutor.removeTask(taskHandle);\n+                for (DriverFactory factory : localExecutionPlan.getDriverFactories()) {\n+                    factory.noMoreDrivers();\n+                }\n+            }\n+        });\n+        return taskHandle;\n+    }\n+\n+    public void start(List<TaskSource> sources)\n+    {\n+        requireNonNull(sources, \"sources is null\");\n+\n+        scheduleDriversForTaskLifeCycle();\n+        scheduleDriversForSplitLifeCycle(sources);\n+        checkTaskCompletion();\n+    }\n+\n+    private void scheduleDriversForTaskLifeCycle()\n+    {\n+        List<DriverSplitRunner> runners = new ArrayList<>();\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            for (int i = 0; i < driverRunnerFactory.getDriverInstances().orElse(1); i++) {\n+                runners.add(driverRunnerFactory.createDriverRunner(null));\n+            }\n+        }\n+        enqueueDriverSplitRunner(true, runners);\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            driverRunnerFactory.noMoreDriverRunner();\n+            verify(driverRunnerFactory.isNoMoreDriverRunner());\n+        }\n+    }\n+\n+    private synchronized void scheduleDriversForSplitLifeCycle(List<TaskSource> sources)\n+    {\n+        checkArgument(sources.stream().allMatch(TaskSource::isNoMoreSplits), \"All task sources are expected to be final\");\n+\n+        Map<PlanNodeId, List<ScheduledSplit>> splits = sources.stream()\n+                .collect(groupingBy(\n+                        TaskSource::getPlanNodeId,\n+                        collectingAndThen(\n+                                mapping(TaskSource::getSplits, toImmutableList()),\n+                                s -> s.stream().flatMap(Set::stream).collect(toImmutableList()))));\n+\n+        for (PlanNodeId planNodeId : schedulingOrder) {\n+            DriverSplitRunnerFactory driverSplitRunnerFactory = driverRunnerFactoriesWithSplitLifeCycle.get(planNodeId);\n+            List<ScheduledSplit> planNodeSplits = splits.getOrDefault(planNodeId, ImmutableList.of());\n+            scheduleTableScanSource(driverSplitRunnerFactory, planNodeSplits);\n+        }\n+    }\n+\n+    private synchronized void scheduleTableScanSource(DriverSplitRunnerFactory factory, List<ScheduledSplit> splits)\n+    {\n+        factory.splitsAdded(splits.size());\n+\n+        // Enqueue driver runners with split lifecycle for this plan node and driver life cycle combination.\n+        ImmutableList.Builder<DriverSplitRunner> runners = ImmutableList.builder();\n+        for (ScheduledSplit scheduledSplit : splits) {\n+            // create a new driver for the split\n+            runners.add(factory.createDriverRunner(scheduledSplit));\n+        }\n+        enqueueDriverSplitRunner(false, runners.build());\n+\n+        factory.noMoreDriverRunner();\n+    }\n+\n+    private synchronized void enqueueDriverSplitRunner(boolean forceRunSplit, List<DriverSplitRunner> runners)\n+    {\n+        // schedule driver to be executed\n+        List<ListenableFuture<?>> finishedFutures = taskExecutor.enqueueSplits(taskHandle, forceRunSplit, runners);\n+        checkState(finishedFutures.size() == runners.size(), \"Expected %s futures but got %s\", runners.size(), finishedFutures.size());\n+\n+        // when driver completes, update state and fire events\n+        for (int i = 0; i < finishedFutures.size(); i++) {\n+            ListenableFuture<?> finishedFuture = finishedFutures.get(i);\n+            final DriverSplitRunner splitRunner = runners.get(i);\n+\n+            // record new driver\n+            remainingDrivers.incrementAndGet();\n+\n+            Futures.addCallback(finishedFuture, new FutureCallback<Object>()\n+            {\n+                @Override\n+                public void onSuccess(Object result)\n+                {\n+                    try (SetThreadName ignored = new SetThreadName(\"Task-%s\", taskId)) {\n+                        // record driver is finished\n+                        remainingDrivers.decrementAndGet();\n+\n+                        checkTaskCompletion();\n+\n+                        splitMonitor.splitCompletedEvent(taskId, getDriverStats());\n+                    }\n+                }\n+\n+                @Override\n+                public void onFailure(Throwable cause)\n+                {\n+                    try (SetThreadName ignored = new SetThreadName(\"Task-%s\", taskId)) {\n+                        taskStateMachine.failed(cause);\n+\n+                        // record driver is finished\n+                        remainingDrivers.decrementAndGet();\n+\n+                        // fire failed event with cause\n+                        splitMonitor.splitFailedEvent(taskId, getDriverStats(), cause);\n+                    }\n+                }\n+\n+                private DriverStats getDriverStats()\n+                {\n+                    DriverContext driverContext = splitRunner.getDriverContext();\n+                    DriverStats driverStats;\n+                    if (driverContext != null) {\n+                        driverStats = driverContext.getDriverStats();\n+                    }\n+                    else {\n+                        // split runner did not start successfully\n+                        driverStats = new DriverStats();\n+                    }\n+\n+                    return driverStats;\n+                }\n+            }, notificationExecutor);\n+        }\n+    }\n+\n+    private synchronized void checkTaskCompletion()\n+    {\n+        if (taskStateMachine.getState().isDone()) {\n+            return;\n+        }\n+\n+        // are there more partition splits expected?\n+        for (DriverSplitRunnerFactory driverSplitRunnerFactory : driverRunnerFactoriesWithSplitLifeCycle.values()) {\n+            if (!driverSplitRunnerFactory.isNoMoreDriverRunner()) {\n+                return;\n+            }\n+        }\n+        // do we still have running tasks?\n+        if (remainingDrivers.get() != 0) {\n+            return;\n+        }\n+\n+        // Cool! All done!\n+        taskStateMachine.finished();\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+        return toStringHelper(this)\n+                .add(\"taskId\", taskId)\n+                .add(\"remainingDrivers\", remainingDrivers.get())\n+                .toString();\n+    }\n+\n+    private class DriverSplitRunnerFactory\n+    {\n+        private final DriverFactory driverFactory;\n+        private final PipelineContext pipelineContext;\n+\n+        private final AtomicInteger pendingCreation = new AtomicInteger();\n+        private final AtomicBoolean noMoreDriverRunner = new AtomicBoolean();\n+        private boolean closed;\n+\n+        private DriverSplitRunnerFactory(DriverFactory driverFactory, boolean partitioned)\n+        {\n+            this.driverFactory = requireNonNull(driverFactory, \"driverFactory is null\");\n+            this.pipelineContext = taskContext.addPipelineContext(driverFactory.getPipelineId(), driverFactory.isInputDriver(), driverFactory.isOutputDriver(), partitioned);\n+        }\n+\n+        public DriverSplitRunner createDriverRunner(@Nullable ScheduledSplit partitionedSplit)\n+        {\n+            checkState(!noMoreDriverRunner.get(), \"Cannot create driver for pipeline: %s\", pipelineContext.getPipelineId());\n+            pendingCreation.incrementAndGet();\n+            // create driver context immediately so the driver existence is recorded in the stats\n+            // the number of drivers is used to balance work across nodes\n+            DriverContext driverContext = pipelineContext.addDriverContext(Lifespan.taskWide());\n+            return new DriverSplitRunner(this, driverContext, partitionedSplit);\n+        }\n+\n+        public Driver createDriver(DriverContext driverContext, @Nullable ScheduledSplit partitionedSplit)\n+        {\n+            Driver driver = driverFactory.createDriver(driverContext);\n+\n+            if (partitionedSplit != null) {\n+                // TableScanOperator requires partitioned split to be added before the first call to process\n+                driver.updateSource(new TaskSource(partitionedSplit.getPlanNodeId(), ImmutableSet.of(partitionedSplit), true));\n+            }\n+\n+            verify(pendingCreation.get() > 0, \"pendingCreation is expected to be greater than zero\");\n+            pendingCreation.decrementAndGet();\n+\n+            closeDriverFactoryIfFullyCreated();\n+\n+            return driver;\n+        }\n+\n+        public void noMoreDriverRunner()\n+        {\n+            if (noMoreDriverRunner.get()) {\n+                return;\n+            }\n+            noMoreDriverRunner.set(true);\n+            closeDriverFactoryIfFullyCreated();\n+        }\n+\n+        public boolean isNoMoreDriverRunner()\n+        {\n+            return noMoreDriverRunner.get();\n+        }\n+\n+        public void closeDriverFactoryIfFullyCreated()\n+        {\n+            if (closed) {\n+                return;\n+            }\n+            if (isNoMoreDriverRunner() && pendingCreation.get() == 0) {\n+                driverFactory.noMoreDrivers(Lifespan.taskWide());\n+                driverFactory.noMoreDrivers();\n+                closed = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "originalPosition": 376}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA1NjUxOQ==", "bodyText": "nit: Why this method and createDriver has to be public? :)", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433056519", "createdAt": "2020-06-01T06:05:38Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();\n+\n+    public PrestoSparkTaskExecution(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor,\n+            SplitMonitor splitMonitor,\n+            Executor notificationExecutor)\n+    {\n+        this.taskStateMachine = requireNonNull(taskStateMachine, \"taskStateMachine is null\");\n+        this.taskId = taskStateMachine.getTaskId();\n+        this.taskContext = requireNonNull(taskContext, \"taskContext is null\");\n+\n+        this.taskExecutor = requireNonNull(taskExecutor, \"driverExecutor is null\");\n+        this.notificationExecutor = requireNonNull(notificationExecutor, \"notificationExecutor is null\");\n+\n+        this.splitMonitor = requireNonNull(splitMonitor, \"splitMonitor is null\");\n+\n+        // index driver factories\n+        schedulingOrder = localExecutionPlan.getTableScanSourceOrder();\n+        Set<PlanNodeId> tableScanSources = ImmutableSet.copyOf(schedulingOrder);\n+        ImmutableMap.Builder<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle = ImmutableMap.builder();\n+        ImmutableList.Builder<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle = ImmutableList.builder();\n+        for (DriverFactory driverFactory : localExecutionPlan.getDriverFactories()) {\n+            Optional<PlanNodeId> sourceId = driverFactory.getSourceId();\n+            if (sourceId.isPresent() && tableScanSources.contains(sourceId.get())) {\n+                driverRunnerFactoriesWithSplitLifeCycle.put(sourceId.get(), new DriverSplitRunnerFactory(driverFactory, true));\n+            }\n+            else {\n+                checkArgument(\n+                        driverFactory.getPipelineExecutionStrategy() == UNGROUPED_EXECUTION,\n+                        \"unexpected pipeline execution strategy: %s\",\n+                        driverFactory.getPipelineExecutionStrategy());\n+                driverRunnerFactoriesWithTaskLifeCycle.add(new DriverSplitRunnerFactory(driverFactory, false));\n+            }\n+        }\n+        this.driverRunnerFactoriesWithSplitLifeCycle = driverRunnerFactoriesWithSplitLifeCycle.build();\n+        this.driverRunnerFactoriesWithTaskLifeCycle = driverRunnerFactoriesWithTaskLifeCycle.build();\n+\n+        checkArgument(this.driverRunnerFactoriesWithSplitLifeCycle.keySet().equals(tableScanSources),\n+                \"Fragment is partitioned, but not all partitioned drivers were found\");\n+\n+        taskHandle = createTaskHandle(taskStateMachine, taskContext, localExecutionPlan, taskExecutor);\n+    }\n+\n+    // this is a separate method to ensure that the `this` reference is not leaked during construction\n+    private static TaskHandle createTaskHandle(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor)\n+    {\n+        TaskHandle taskHandle = taskExecutor.addTask(\n+                taskStateMachine.getTaskId(),\n+                () -> 0,\n+                getInitialSplitsPerNode(taskContext.getSession()),\n+                getSplitConcurrencyAdjustmentInterval(taskContext.getSession()),\n+                getMaxDriversPerTask(taskContext.getSession()));\n+        taskStateMachine.addStateChangeListener(state -> {\n+            if (state.isDone()) {\n+                taskExecutor.removeTask(taskHandle);\n+                for (DriverFactory factory : localExecutionPlan.getDriverFactories()) {\n+                    factory.noMoreDrivers();\n+                }\n+            }\n+        });\n+        return taskHandle;\n+    }\n+\n+    public void start(List<TaskSource> sources)\n+    {\n+        requireNonNull(sources, \"sources is null\");\n+\n+        scheduleDriversForTaskLifeCycle();\n+        scheduleDriversForSplitLifeCycle(sources);\n+        checkTaskCompletion();\n+    }\n+\n+    private void scheduleDriversForTaskLifeCycle()\n+    {\n+        List<DriverSplitRunner> runners = new ArrayList<>();\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            for (int i = 0; i < driverRunnerFactory.getDriverInstances().orElse(1); i++) {\n+                runners.add(driverRunnerFactory.createDriverRunner(null));\n+            }\n+        }\n+        enqueueDriverSplitRunner(true, runners);\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            driverRunnerFactory.noMoreDriverRunner();\n+            verify(driverRunnerFactory.isNoMoreDriverRunner());\n+        }\n+    }\n+\n+    private synchronized void scheduleDriversForSplitLifeCycle(List<TaskSource> sources)\n+    {\n+        checkArgument(sources.stream().allMatch(TaskSource::isNoMoreSplits), \"All task sources are expected to be final\");\n+\n+        Map<PlanNodeId, List<ScheduledSplit>> splits = sources.stream()\n+                .collect(groupingBy(\n+                        TaskSource::getPlanNodeId,\n+                        collectingAndThen(\n+                                mapping(TaskSource::getSplits, toImmutableList()),\n+                                s -> s.stream().flatMap(Set::stream).collect(toImmutableList()))));\n+\n+        for (PlanNodeId planNodeId : schedulingOrder) {\n+            DriverSplitRunnerFactory driverSplitRunnerFactory = driverRunnerFactoriesWithSplitLifeCycle.get(planNodeId);\n+            List<ScheduledSplit> planNodeSplits = splits.getOrDefault(planNodeId, ImmutableList.of());\n+            scheduleTableScanSource(driverSplitRunnerFactory, planNodeSplits);\n+        }\n+    }\n+\n+    private synchronized void scheduleTableScanSource(DriverSplitRunnerFactory factory, List<ScheduledSplit> splits)\n+    {\n+        factory.splitsAdded(splits.size());\n+\n+        // Enqueue driver runners with split lifecycle for this plan node and driver life cycle combination.\n+        ImmutableList.Builder<DriverSplitRunner> runners = ImmutableList.builder();\n+        for (ScheduledSplit scheduledSplit : splits) {\n+            // create a new driver for the split\n+            runners.add(factory.createDriverRunner(scheduledSplit));\n+        }\n+        enqueueDriverSplitRunner(false, runners.build());\n+\n+        factory.noMoreDriverRunner();\n+    }\n+\n+    private synchronized void enqueueDriverSplitRunner(boolean forceRunSplit, List<DriverSplitRunner> runners)\n+    {\n+        // schedule driver to be executed\n+        List<ListenableFuture<?>> finishedFutures = taskExecutor.enqueueSplits(taskHandle, forceRunSplit, runners);\n+        checkState(finishedFutures.size() == runners.size(), \"Expected %s futures but got %s\", runners.size(), finishedFutures.size());\n+\n+        // when driver completes, update state and fire events\n+        for (int i = 0; i < finishedFutures.size(); i++) {\n+            ListenableFuture<?> finishedFuture = finishedFutures.get(i);\n+            final DriverSplitRunner splitRunner = runners.get(i);\n+\n+            // record new driver\n+            remainingDrivers.incrementAndGet();\n+\n+            Futures.addCallback(finishedFuture, new FutureCallback<Object>()\n+            {\n+                @Override\n+                public void onSuccess(Object result)\n+                {\n+                    try (SetThreadName ignored = new SetThreadName(\"Task-%s\", taskId)) {\n+                        // record driver is finished\n+                        remainingDrivers.decrementAndGet();\n+\n+                        checkTaskCompletion();\n+\n+                        splitMonitor.splitCompletedEvent(taskId, getDriverStats());\n+                    }\n+                }\n+\n+                @Override\n+                public void onFailure(Throwable cause)\n+                {\n+                    try (SetThreadName ignored = new SetThreadName(\"Task-%s\", taskId)) {\n+                        taskStateMachine.failed(cause);\n+\n+                        // record driver is finished\n+                        remainingDrivers.decrementAndGet();\n+\n+                        // fire failed event with cause\n+                        splitMonitor.splitFailedEvent(taskId, getDriverStats(), cause);\n+                    }\n+                }\n+\n+                private DriverStats getDriverStats()\n+                {\n+                    DriverContext driverContext = splitRunner.getDriverContext();\n+                    DriverStats driverStats;\n+                    if (driverContext != null) {\n+                        driverStats = driverContext.getDriverStats();\n+                    }\n+                    else {\n+                        // split runner did not start successfully\n+                        driverStats = new DriverStats();\n+                    }\n+\n+                    return driverStats;\n+                }\n+            }, notificationExecutor);\n+        }\n+    }\n+\n+    private synchronized void checkTaskCompletion()\n+    {\n+        if (taskStateMachine.getState().isDone()) {\n+            return;\n+        }\n+\n+        // are there more partition splits expected?\n+        for (DriverSplitRunnerFactory driverSplitRunnerFactory : driverRunnerFactoriesWithSplitLifeCycle.values()) {\n+            if (!driverSplitRunnerFactory.isNoMoreDriverRunner()) {\n+                return;\n+            }\n+        }\n+        // do we still have running tasks?\n+        if (remainingDrivers.get() != 0) {\n+            return;\n+        }\n+\n+        // Cool! All done!\n+        taskStateMachine.finished();\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+        return toStringHelper(this)\n+                .add(\"taskId\", taskId)\n+                .add(\"remainingDrivers\", remainingDrivers.get())\n+                .toString();\n+    }\n+\n+    private class DriverSplitRunnerFactory\n+    {\n+        private final DriverFactory driverFactory;\n+        private final PipelineContext pipelineContext;\n+\n+        private final AtomicInteger pendingCreation = new AtomicInteger();\n+        private final AtomicBoolean noMoreDriverRunner = new AtomicBoolean();\n+        private boolean closed;\n+\n+        private DriverSplitRunnerFactory(DriverFactory driverFactory, boolean partitioned)\n+        {\n+            this.driverFactory = requireNonNull(driverFactory, \"driverFactory is null\");\n+            this.pipelineContext = taskContext.addPipelineContext(driverFactory.getPipelineId(), driverFactory.isInputDriver(), driverFactory.isOutputDriver(), partitioned);\n+        }\n+\n+        public DriverSplitRunner createDriverRunner(@Nullable ScheduledSplit partitionedSplit)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a26ba8d7d1ff28510647043d2372676f97ce8bdf"}, "originalPosition": 327}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9ebfee096752c9ebee7d347320ff58870345a20", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/a9ebfee096752c9ebee7d347320ff58870345a20", "committedDate": "2020-06-01T16:19:02Z", "message": "Implement presto like threading model for Presto on Spark"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b890917767e9c069de83082aa3d2c083a1fe4f0", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/4b890917767e9c069de83082aa3d2c083a1fe4f0", "committedDate": "2020-06-01T16:19:02Z", "message": "Decrease lock contention in PrestoSparkRowBuffer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c157581bd4797cd8267a5535be970234d917e9a2", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/c157581bd4797cd8267a5535be970234d917e9a2", "committedDate": "2020-05-22T19:49:01Z", "message": "Decrease lock contention in PrestoSparkRowBuffer"}, "afterCommit": {"oid": "4b890917767e9c069de83082aa3d2c083a1fe4f0", "author": {"user": {"login": "arhimondr", "name": "Andrii Rosa"}}, "url": "https://github.com/prestodb/presto/commit/4b890917767e9c069de83082aa3d2c083a1fe4f0", "committedDate": "2020-06-01T16:19:02Z", "message": "Decrease lock contention in PrestoSparkRowBuffer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyMzg3NTM4", "url": "https://github.com/prestodb/presto/pull/14522#pullrequestreview-422387538", "createdAt": "2020-06-02T06:51:15Z", "commit": {"oid": "4b890917767e9c069de83082aa3d2c083a1fe4f0"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQwNjo1MToxNlrOGdkTXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQwNjo1MToxNlrOGdkTXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY1NjY3MA==", "bodyText": "nit: Any reason why defer the creation of ImmutableList.Builder to appendRow? Because I would personally eagerly create the new ImmutableList.Builder here.", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433656670", "createdAt": "2020-06-02T06:51:16Z", "author": {"login": "wenleix"}, "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -285,9 +313,38 @@ public Page getOutput()\n     @Override\n     public void finish()\n     {\n+        flush();\n+        updateMemoryContext();\n         finished = true;\n     }\n \n+    private void flush()\n+    {\n+        if (currentBatchSize > 0) {\n+            verify(currentBatch != null);\n+            // Uses currentBatch internally. Must be called before currentBatch is set to null.\n+            int rowsListRetainedSize = getCurrentBatchRetainedBytes();\n+            List<PrestoSparkRow> rowsList = currentBatch.build();\n+            BufferedRows bufferedRows = new BufferedRows(rowsList, rowsListRetainedSize);\n+            rowBuffer.enqueue(bufferedRows);\n+            currentBatch = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b890917767e9c069de83082aa3d2c083a1fe4f0"}, "originalPosition": 126}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1634, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}