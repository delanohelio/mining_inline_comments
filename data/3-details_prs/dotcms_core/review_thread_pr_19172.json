{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc0MTgwNzM1", "number": 19172, "reviewThreads": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQyMzozODo1N1rOEczmFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo1MFrOEefwMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NjQwOTE2OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/CleanUpFieldReferencesJob.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQyMzozODo1N1rOHHju4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQyMzo0OTozMVrOHHksQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY4NzUyMw==", "bodyText": "@fabrizzio-dotCMS did you leave your test sleep in here?", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r477687523", "createdAt": "2020-08-26T23:38:57Z", "author": {"login": "wezell"}, "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/CleanUpFieldReferencesJob.java", "diffHunk": "@@ -101,34 +113,26 @@ public void run(JobExecutionContext jobContext) throws JobExecutionException {\n             Logger.error(CleanUpFieldReferencesJob.class,\n                     \"Error cleaning up field references. Field velocity var: \" + field.variable(), e);\n         }\n+*/\n+\n+        try {\n+            Thread.sleep(25000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fe9b9a00fbc9f36bec2f09591285841fba29a23"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzcwMzIzMw==", "bodyText": "it's a draft I forgot to set that back to normal. yeah, that was to simulate a long-running task. I still need to visit the other jobs. I'll do that. as soon as I finish an internal QA business that I have pending.  Don't worry final version won't have that sleep thing.", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r477703233", "createdAt": "2020-08-26T23:49:31Z", "author": {"login": "fabrizzio-dotCMS"}, "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/CleanUpFieldReferencesJob.java", "diffHunk": "@@ -101,34 +113,26 @@ public void run(JobExecutionContext jobContext) throws JobExecutionException {\n             Logger.error(CleanUpFieldReferencesJob.class,\n                     \"Error cleaning up field references. Field velocity var: \" + field.variable(), e);\n         }\n+*/\n+\n+        try {\n+            Thread.sleep(25000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY4NzUyMw=="}, "originalCommit": {"oid": "8fe9b9a00fbc9f36bec2f09591285841fba29a23"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTEwODMxOnYy", "diffSide": "RIGHT", "path": "dotCMS/src/main/java/com/dotmarketing/quartz/DotStatefulJob.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwNTo1Nzo0MVrOHIAXvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxNzowNzowOVrOHKBK0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODE1NjczMg==", "bodyText": "Optional.ofNullable(dataMap)???", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r478156732", "createdAt": "2020-08-27T05:57:41Z", "author": {"login": "jdotcms"}, "path": "dotCMS/src/main/java/com/dotmarketing/quartz/DotStatefulJob.java", "diffHunk": "@@ -1,7 +1,151 @@\n package com.dotmarketing.quartz;\n \n+import com.dotmarketing.util.Logger;\n+import io.vavr.control.Try;\n+import java.io.Serializable;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Calendar;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.UUID;\n+import org.quartz.JobDetail;\n+import org.quartz.SchedulerException;\n+import org.quartz.SimpleTrigger;\n import org.quartz.StatefulJob;\n \n public abstract class DotStatefulJob extends DotJob implements StatefulJob {\n \n+     static final String TRIGGER_JOB_DETAIL = \"trigger_job_detail\";\n+\n+    /**\n+     * This is meant simplify the generation of a Job-name\n+     * if we have a stateful class and we want it to behave as one single job allowed to run at the time\n+     * Meaning no parallel instances. The key resides in the name. Quartz guarantees such behavior based on the name.\n+     * We can still have two instances of a Stateful job if they're scheduled under a different name.\n+     * @param jobClass\n+     * @return\n+     */\n+    static String getJobName(final Class<? extends StatefulJob> jobClass) {\n+        return jobClass.getSimpleName();\n+    }\n+\n+    /**\n+     * This is meant simplify the generation of a Job-Group name which also needs to be unique.\n+     * The Key that makes a job unique is the value pair (job-name,job-group)\n+     * @param jobClass\n+     * @return\n+     */\n+    static String getJobGroupName(final Class<? extends StatefulJob> jobClass) {\n+        return getJobName(jobClass) + \"_Group\";\n+    }\n+\n+    /**\n+     * Description is only informative.\n+     * @param jobClass\n+     * @return\n+     */\n+    static String getJobDescription(final Class<? extends StatefulJob> jobClass) {\n+        return getJobName(jobClass) + \" instance.\";\n+    }\n+\n+    /**\n+     * Trigger names must be unique. A duplicate entry with the same name created in a later date would imply an execution re-schedule rescheduling.\n+     * Again here the key is a composite of (trigger-name,trigger-group)\n+     * @param jobClass\n+     * @return\n+     */\n+    static String nextTriggerName(final Class<? extends StatefulJob> jobClass) {\n+        final String randomID = UUID.randomUUID().toString();\n+        return jobClass.getSimpleName() + \"_Trigger_\" + randomID;\n+    }\n+\n+    /**\n+     * Group must be unique to provide meaning to the triggers\n+     * @param jobClass\n+     * @return\n+     */\n+    static String getTriggerGroupName(final Class<? extends StatefulJob> jobClass) {\n+        return jobClass.getSimpleName() + \"_Trigger_Group\";\n+    }\n+\n+    /**\n+     * This will get you the map that stores all the data written into the job detail organized by trigger name.\n+     * @param jobName\n+     * @param groupName\n+     * @return\n+     */\n+    private static Optional<Map<String, Object>> getTriggerJobDetail(final String jobName,\n+            final String groupName) {\n+        final JobDetail jobDetail = Try\n+                .of(() -> QuartzUtils.getSequentialScheduler().getJobDetail(jobName, groupName))\n+                .getOrNull();\n+        if (null == jobDetail) {\n+            return Optional.empty();\n+        }\n+        @SuppressWarnings(\"unchecked\") final Map<String, Object> dataMap = (Map<String, Object>) jobDetail\n+                .getJobDataMap()\n+                .get(TRIGGER_JOB_DETAIL);\n+        if (null == dataMap) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fe9b9a00fbc9f36bec2f09591285841fba29a23"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI2Njk2MQ==", "bodyText": "I like it better this way empty or not", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480266961", "createdAt": "2020-08-31T17:07:09Z", "author": {"login": "fabrizzio-dotCMS"}, "path": "dotCMS/src/main/java/com/dotmarketing/quartz/DotStatefulJob.java", "diffHunk": "@@ -1,7 +1,151 @@\n package com.dotmarketing.quartz;\n \n+import com.dotmarketing.util.Logger;\n+import io.vavr.control.Try;\n+import java.io.Serializable;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Calendar;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.UUID;\n+import org.quartz.JobDetail;\n+import org.quartz.SchedulerException;\n+import org.quartz.SimpleTrigger;\n import org.quartz.StatefulJob;\n \n public abstract class DotStatefulJob extends DotJob implements StatefulJob {\n \n+     static final String TRIGGER_JOB_DETAIL = \"trigger_job_detail\";\n+\n+    /**\n+     * This is meant simplify the generation of a Job-name\n+     * if we have a stateful class and we want it to behave as one single job allowed to run at the time\n+     * Meaning no parallel instances. The key resides in the name. Quartz guarantees such behavior based on the name.\n+     * We can still have two instances of a Stateful job if they're scheduled under a different name.\n+     * @param jobClass\n+     * @return\n+     */\n+    static String getJobName(final Class<? extends StatefulJob> jobClass) {\n+        return jobClass.getSimpleName();\n+    }\n+\n+    /**\n+     * This is meant simplify the generation of a Job-Group name which also needs to be unique.\n+     * The Key that makes a job unique is the value pair (job-name,job-group)\n+     * @param jobClass\n+     * @return\n+     */\n+    static String getJobGroupName(final Class<? extends StatefulJob> jobClass) {\n+        return getJobName(jobClass) + \"_Group\";\n+    }\n+\n+    /**\n+     * Description is only informative.\n+     * @param jobClass\n+     * @return\n+     */\n+    static String getJobDescription(final Class<? extends StatefulJob> jobClass) {\n+        return getJobName(jobClass) + \" instance.\";\n+    }\n+\n+    /**\n+     * Trigger names must be unique. A duplicate entry with the same name created in a later date would imply an execution re-schedule rescheduling.\n+     * Again here the key is a composite of (trigger-name,trigger-group)\n+     * @param jobClass\n+     * @return\n+     */\n+    static String nextTriggerName(final Class<? extends StatefulJob> jobClass) {\n+        final String randomID = UUID.randomUUID().toString();\n+        return jobClass.getSimpleName() + \"_Trigger_\" + randomID;\n+    }\n+\n+    /**\n+     * Group must be unique to provide meaning to the triggers\n+     * @param jobClass\n+     * @return\n+     */\n+    static String getTriggerGroupName(final Class<? extends StatefulJob> jobClass) {\n+        return jobClass.getSimpleName() + \"_Trigger_Group\";\n+    }\n+\n+    /**\n+     * This will get you the map that stores all the data written into the job detail organized by trigger name.\n+     * @param jobName\n+     * @param groupName\n+     * @return\n+     */\n+    private static Optional<Map<String, Object>> getTriggerJobDetail(final String jobName,\n+            final String groupName) {\n+        final JobDetail jobDetail = Try\n+                .of(() -> QuartzUtils.getSequentialScheduler().getJobDetail(jobName, groupName))\n+                .getOrNull();\n+        if (null == jobDetail) {\n+            return Optional.empty();\n+        }\n+        @SuppressWarnings(\"unchecked\") final Map<String, Object> dataMap = (Map<String, Object>) jobDetail\n+                .getJobDataMap()\n+                .get(TRIGGER_JOB_DETAIL);\n+        if (null == dataMap) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODE1NjczMg=="}, "originalCommit": {"oid": "8fe9b9a00fbc9f36bec2f09591285841fba29a23"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTAxOnYy", "diffSide": "RIGHT", "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/DeleteUserJob.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0MFrOHKLdzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0MFrOHKLdzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTY2Mw==", "bodyText": "Codacy found an issue: Avoid unused imports such as 'org.quartz.JobDataMap'", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435663", "createdAt": "2020-08-31T22:29:40Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/DeleteUserJob.java", "diffHunk": "@@ -9,22 +11,26 @@\n import com.dotmarketing.exception.DotHibernateException;\n import com.dotmarketing.exception.DotRuntimeException;\n import com.dotmarketing.exception.DotSecurityException;\n-import com.dotmarketing.quartz.QuartzUtils;\n+import com.dotmarketing.quartz.DotStatefulJob;\n import com.dotmarketing.util.AdminLogger;\n import com.dotmarketing.util.Logger;\n+import com.google.common.collect.ImmutableMap;\n import com.liferay.portal.language.LanguageUtil;\n import com.liferay.portal.model.User;\n-\n-import org.quartz.*;\n-\n+import java.io.Serializable;\n import java.text.MessageFormat;\n-import java.util.Date;\n-import java.util.UUID;\n+import java.text.ParseException;\n+import java.util.Map;\n+import org.quartz.JobDataMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTA4OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0MVrOHKLd3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0MVrOHKLd3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTY3OA==", "bodyText": "Codacy found an issue: Avoid variables with short names like to", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435678", "createdAt": "2020-08-31T22:29:41Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+package com.dotmarketing.quartz;\n+\n+import static com.dotmarketing.quartz.QuartzUtils.getSequentialScheduler;\n+import static java.util.Objects.requireNonNull;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.dotcms.IntegrationTestBase;\n+import com.dotcms.util.IntegrationTestInitService;\n+import com.dotmarketing.util.Logger;\n+import com.google.common.collect.ImmutableMap;\n+import java.text.ParseException;\n+import java.time.LocalTime;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.quartz.JobDetail;\n+import org.quartz.JobExecutionContext;\n+import org.quartz.Scheduler;\n+import org.quartz.SchedulerException;\n+\n+public class DotStatefulJobTest extends IntegrationTestBase {\n+\n+    @BeforeClass\n+    public static void prepare() throws Exception {\n+        // Setting web app environment\n+        IntegrationTestInitService.getInstance().init();\n+        getSequentialScheduler().start();\n+    }\n+\n+    /**\n+     * clean up precaution\n+     * @throws SchedulerException\n+     */\n+    private void removeAnyExistingJob() throws SchedulerException {\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        final String jobGroupName = DotStatefulJob.getJobGroupName(MyStatefulJob.class);\n+        QuartzUtils.removeJob(jobName, jobGroupName);\n+    }\n+\n+    /**\n+     * Given scenario: We prep to trigger a bunch of tasks that must be executed sequentially (one at the time) never in parallel.\n+     * Expected Results: first all triggered tasks must be executed and completed. second their time mark must revel that none of theme overlapped.\n+     *\n+     * @throws SchedulerException\n+     * @throws ParseException\n+     * @throws ClassNotFoundException\n+     * @throws InterruptedException\n+     */\n+    @Test\n+    public void Test_Launch_Stateful_Jobs_Verify_They_Dont_Overlap_In_Time()\n+            throws SchedulerException, ParseException, ClassNotFoundException, InterruptedException {\n+\n+        //in order to avoid conflicts clean any reference that could have been left.\n+        removeAnyExistingJob();\n+\n+        //Now enqueue a few jos .. They will sleep randomly to simulate work.\n+        for (int i = 1; i <= MyStatefulJob.MAX_THREADS; i++) {\n+            MyStatefulJob.fireJob(ImmutableMap.of(\"index\", i));\n+            //Now verify the detail has been added for the present trigger we're introducing\n+            final Optional<Map<String, Object>> triggerJobDetail = DotStatefulJob\n+                    .getTriggerJobDetail(MyStatefulJob.class);\n+            assertNotNull(triggerJobDetail);\n+            assertTrue(triggerJobDetail.isPresent());\n+            final Map<String, Object> detail = triggerJobDetail.get();\n+            assertNotNull(detail);\n+            //The size of the detail should have grown as we insert new triggers.\n+            assertEquals(detail.size(), i);\n+        }\n+\n+        //Verify at least 1 job has been launched.\n+        final Optional<JobExecutionContext> jobExecutionContext = getJobExecutionContext();\n+        assertTrue(jobExecutionContext.isPresent());\n+\n+        //Now lets wait for the all the threads to complete.\n+        MyStatefulJob.countDownLatch.await();\n+\n+        //Now lets revise the execution times. Since they were supposed to run sequentially the should never overlap.\n+        final HashSet<MyStatefulJob> myStatefulJobs = new HashSet<>(MyStatefulJob.finishedJobs);\n+        final Iterator<MyStatefulJob> iterator = myStatefulJobs.iterator();\n+        while(iterator.hasNext()){\n+            final MyStatefulJob myStatefulJob = iterator.next();\n+            iterator.forEachRemaining(job -> {\n+                //They should never overlap.\n+                assertFalse(myStatefulJob.getTimeRange().overlaps(job.getTimeRange()));\n+            });\n+        }\n+    }\n+\n+    /**\n+     * This gets you the execution context for the given job-name.\n+     * @return\n+     */\n+    private Optional<JobExecutionContext> getJobExecutionContext(){\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        try {\n+            final Scheduler sequentialScheduler = getSequentialScheduler();\n+            @SuppressWarnings(\"unchecked\")\n+            final List<JobExecutionContext> executingJobs = sequentialScheduler.getCurrentlyExecutingJobs();\n+            return executingJobs.stream().filter(jobExecutionContext -> {\n+                final JobDetail jobDetail = jobExecutionContext.getJobDetail();\n+                return jobDetail != null && jobName.equals(jobDetail.getName());\n+            }).findFirst();\n+        } catch (Exception e) {\n+            Logger.error(DotStatefulJobTest.class, \"Error retrieving execution context. \" , e);\n+        }\n+        return Optional.empty();\n+    }\n+\n+    /**\n+     * additional struct to follow execution time lapse.\n+     */\n+    public static class LocalTimeRange {\n+\n+        private final LocalTime from;\n+        private final LocalTime to;\n+\n+        LocalTimeRange(final LocalTime from, final LocalTime to) {\n+            requireNonNull(from, \"from must not be null\");\n+            requireNonNull(to, \"to must not be null\");\n+            this.from = from;\n+            this.to = to;\n+        }\n+\n+        boolean overlaps(final LocalTimeRange other) {\n+            requireNonNull(other, \"other must not be null\");\n+            return isBetween(other.from, this.from, this.to)\n+                    || isBetween(other.to, this.from, this.to)\n+                    || isBetween(this.from, other.from, other.to)\n+                    || isBetween(this.to, other.from, other.to);\n+        }\n+\n+        private static boolean isBetween(final LocalTime time, final LocalTime from, final LocalTime to) {\n+            if (from.isBefore(to)) { // same day\n+                return from.isBefore(time) && time.isBefore(to);\n+            } else { // spans to the next day.\n+                return from.isBefore(time) || time.isBefore(to);\n+            }\n+        }\n+\n+        public static LocalTimeRange of(final LocalTime from, final LocalTime to){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTE1OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0MlrOHKLd6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0MlrOHKLd6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTY4OA==", "bodyText": "Codacy found an issue: Avoid variables with short names like to", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435688", "createdAt": "2020-08-31T22:29:42Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+package com.dotmarketing.quartz;\n+\n+import static com.dotmarketing.quartz.QuartzUtils.getSequentialScheduler;\n+import static java.util.Objects.requireNonNull;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.dotcms.IntegrationTestBase;\n+import com.dotcms.util.IntegrationTestInitService;\n+import com.dotmarketing.util.Logger;\n+import com.google.common.collect.ImmutableMap;\n+import java.text.ParseException;\n+import java.time.LocalTime;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.quartz.JobDetail;\n+import org.quartz.JobExecutionContext;\n+import org.quartz.Scheduler;\n+import org.quartz.SchedulerException;\n+\n+public class DotStatefulJobTest extends IntegrationTestBase {\n+\n+    @BeforeClass\n+    public static void prepare() throws Exception {\n+        // Setting web app environment\n+        IntegrationTestInitService.getInstance().init();\n+        getSequentialScheduler().start();\n+    }\n+\n+    /**\n+     * clean up precaution\n+     * @throws SchedulerException\n+     */\n+    private void removeAnyExistingJob() throws SchedulerException {\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        final String jobGroupName = DotStatefulJob.getJobGroupName(MyStatefulJob.class);\n+        QuartzUtils.removeJob(jobName, jobGroupName);\n+    }\n+\n+    /**\n+     * Given scenario: We prep to trigger a bunch of tasks that must be executed sequentially (one at the time) never in parallel.\n+     * Expected Results: first all triggered tasks must be executed and completed. second their time mark must revel that none of theme overlapped.\n+     *\n+     * @throws SchedulerException\n+     * @throws ParseException\n+     * @throws ClassNotFoundException\n+     * @throws InterruptedException\n+     */\n+    @Test\n+    public void Test_Launch_Stateful_Jobs_Verify_They_Dont_Overlap_In_Time()\n+            throws SchedulerException, ParseException, ClassNotFoundException, InterruptedException {\n+\n+        //in order to avoid conflicts clean any reference that could have been left.\n+        removeAnyExistingJob();\n+\n+        //Now enqueue a few jos .. They will sleep randomly to simulate work.\n+        for (int i = 1; i <= MyStatefulJob.MAX_THREADS; i++) {\n+            MyStatefulJob.fireJob(ImmutableMap.of(\"index\", i));\n+            //Now verify the detail has been added for the present trigger we're introducing\n+            final Optional<Map<String, Object>> triggerJobDetail = DotStatefulJob\n+                    .getTriggerJobDetail(MyStatefulJob.class);\n+            assertNotNull(triggerJobDetail);\n+            assertTrue(triggerJobDetail.isPresent());\n+            final Map<String, Object> detail = triggerJobDetail.get();\n+            assertNotNull(detail);\n+            //The size of the detail should have grown as we insert new triggers.\n+            assertEquals(detail.size(), i);\n+        }\n+\n+        //Verify at least 1 job has been launched.\n+        final Optional<JobExecutionContext> jobExecutionContext = getJobExecutionContext();\n+        assertTrue(jobExecutionContext.isPresent());\n+\n+        //Now lets wait for the all the threads to complete.\n+        MyStatefulJob.countDownLatch.await();\n+\n+        //Now lets revise the execution times. Since they were supposed to run sequentially the should never overlap.\n+        final HashSet<MyStatefulJob> myStatefulJobs = new HashSet<>(MyStatefulJob.finishedJobs);\n+        final Iterator<MyStatefulJob> iterator = myStatefulJobs.iterator();\n+        while(iterator.hasNext()){\n+            final MyStatefulJob myStatefulJob = iterator.next();\n+            iterator.forEachRemaining(job -> {\n+                //They should never overlap.\n+                assertFalse(myStatefulJob.getTimeRange().overlaps(job.getTimeRange()));\n+            });\n+        }\n+    }\n+\n+    /**\n+     * This gets you the execution context for the given job-name.\n+     * @return\n+     */\n+    private Optional<JobExecutionContext> getJobExecutionContext(){\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        try {\n+            final Scheduler sequentialScheduler = getSequentialScheduler();\n+            @SuppressWarnings(\"unchecked\")\n+            final List<JobExecutionContext> executingJobs = sequentialScheduler.getCurrentlyExecutingJobs();\n+            return executingJobs.stream().filter(jobExecutionContext -> {\n+                final JobDetail jobDetail = jobExecutionContext.getJobDetail();\n+                return jobDetail != null && jobName.equals(jobDetail.getName());\n+            }).findFirst();\n+        } catch (Exception e) {\n+            Logger.error(DotStatefulJobTest.class, \"Error retrieving execution context. \" , e);\n+        }\n+        return Optional.empty();\n+    }\n+\n+    /**\n+     * additional struct to follow execution time lapse.\n+     */\n+    public static class LocalTimeRange {\n+\n+        private final LocalTime from;\n+        private final LocalTime to;\n+\n+        LocalTimeRange(final LocalTime from, final LocalTime to) {\n+            requireNonNull(from, \"from must not be null\");\n+            requireNonNull(to, \"to must not be null\");\n+            this.from = from;\n+            this.to = to;\n+        }\n+\n+        boolean overlaps(final LocalTimeRange other) {\n+            requireNonNull(other, \"other must not be null\");\n+            return isBetween(other.from, this.from, this.to)\n+                    || isBetween(other.to, this.from, this.to)\n+                    || isBetween(this.from, other.from, other.to)\n+                    || isBetween(this.to, other.from, other.to);\n+        }\n+\n+        private static boolean isBetween(final LocalTime time, final LocalTime from, final LocalTime to) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTIxOnYy", "diffSide": "RIGHT", "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/CascadePermissionsJob.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0M1rOHKLd8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0M1rOHKLd8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTY5Nw==", "bodyText": "Codacy found an issue: Avoid catching generic exceptions such as NullPointerException, RuntimeException, Exception in try-catch block", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435697", "createdAt": "2020-08-31T22:29:43Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/CascadePermissionsJob.java", "diffHunk": "@@ -86,34 +80,21 @@ public CascadePermissionsJob() {\n \t}\r\n     \r\n \tpublic static void triggerJobImmediately (Permissionable perm, Role role) {\r\n-\t\tString randomID = UUID.randomUUID().toString();\r\n-\t\tString userId = null;\r\n-\t\tJobDataMap dataMap = new JobDataMap();\r\n-\t\t\r\n-\t\tdataMap.put(\"permissionableId\", perm.getPermissionId());\r\n-\t\tdataMap.put(\"roleId\", role.getId());\r\n-\r\n-\t\t//TODO: For a major release, remove this logic and get userId as parameter\r\n-\t\tif (UtilMethods.isSet(HttpServletRequestThreadLocal.INSTANCE.getRequest())) {\r\n-\t\t\tuserId = WebAPILocator.getUserWebAPI()\r\n-\t\t\t\t\t.getLoggedInUser(HttpServletRequestThreadLocal.INSTANCE.getRequest())\r\n-\t\t\t\t\t.getUserId();\r\n-\t\t}\r\n-\t\tdataMap.put(\"userId\", userId);\r\n-\r\n-\t\tJobDetail jd = new JobDetail(\"CascadePermissionsJob-\" + randomID, \"cascade_permissions_jobs\", CascadePermissionsJob.class);\r\n-\t\tjd.setJobDataMap(dataMap);\r\n-\t\tjd.setDurability(false);\r\n-\t\tjd.setVolatility(false);\r\n-\t\tjd.setRequestsRecovery(true);\r\n-\t\t\r\n-\t\tlong startTime = System.currentTimeMillis();\r\n-\t\tSimpleTrigger trigger = new SimpleTrigger(\"permissionsCascadeTrigger-\"+randomID, \"cascade_permissions_triggers\",  new Date(startTime));\r\n-\t\t\r\n \t\ttry {\r\n-\t\t\tScheduler sched = QuartzUtils.getSequentialScheduler();\r\n-\t\t\tsched.scheduleJob(jd, trigger);\r\n-\t\t} catch (SchedulerException e) {\r\n+\t\t\tString userId = null;\r\n+\t\t\tif (UtilMethods.isSet(HttpServletRequestThreadLocal.INSTANCE.getRequest())) {\r\n+\t\t\t\tuserId = WebAPILocator.getUserWebAPI()\r\n+\t\t\t\t\t\t.getLoggedInUser(HttpServletRequestThreadLocal.INSTANCE.getRequest())\r\n+\t\t\t\t\t\t.getUserId();\r\n+\t\t\t}\r\n+\t\t\tfinal ImmutableMap<String, Serializable> nextExecutionData = ImmutableMap\r\n+\t\t\t\t\t.of(\"permissionableId\", perm.getPermissionId(),\r\n+\t\t\t\t\t\t\t\"roleId\", role.getId(),\r\n+\t\t\t\t\t\t\t\"userId\", userId\r\n+\t\t\t\t\t);\r\n+\r\n+\t\t\tDotStatefulJob.enqueueTrigger(nextExecutionData, CascadePermissionsJob.class);\r\n+\t\t} catch (Exception e) {\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTI2OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/ResetPermissionsJob.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0NFrOHKLd_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0NFrOHKLd_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTcxMA==", "bodyText": "Codacy found an issue: Avoid catching generic exceptions such as NullPointerException, RuntimeException, Exception in try-catch block", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435710", "createdAt": "2020-08-31T22:29:44Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/ResetPermissionsJob.java", "diffHunk": "@@ -70,35 +74,23 @@ public ResetPermissionsJob() {\n      *        Page, etc.\r\n      */\r\n \tpublic static void triggerJobImmediately (final Permissionable perm) {\r\n-\t\tfinal String randomID = UUID.randomUUID().toString();\r\n-\t\tfinal JobDataMap dataMap = new JobDataMap();\r\n-\r\n \t\tString userId = null;\r\n-\t\t\r\n-\t\tdataMap.put(\"permissionableId\", perm.getPermissionId());\r\n \r\n \t\t//TODO: For a major release, remove this logic and get userId as parameter\r\n \t\tif (UtilMethods.isSet(HttpServletRequestThreadLocal.INSTANCE.getRequest())) {\r\n \t\t\tuserId = WebAPILocator.getUserWebAPI()\r\n \t\t\t\t\t.getLoggedInUser(HttpServletRequestThreadLocal.INSTANCE.getRequest())\r\n \t\t\t\t\t.getUserId();\r\n \t\t}\r\n-\t\tdataMap.put(\"userId\", userId);\r\n-\r\n-\t\tfinal JobDetail jd = new JobDetail(\"ResetPermissionsJob-\" + randomID, \"dotcms_jobs\", ResetPermissionsJob.class);\r\n-\t\tjd.setJobDataMap(dataMap);\r\n-\t\tjd.setDurability(false);\r\n-\t\tjd.setVolatility(false);\r\n-\t\tjd.setRequestsRecovery(true);\r\n-\t\t\r\n-\t\tfinal long startTime = System.currentTimeMillis();\r\n-\t\tfinal SimpleTrigger trigger = new SimpleTrigger(\"permissionsResetTrigger-\"+randomID, \"dotcms_triggers\",  new Date(startTime));\r\n+\t\tfinal Map<String, Serializable> nextExecutionData = ImmutableMap\r\n+\t\t\t\t.of(\r\n+\t\t\t\t\t\t\"permissionableId\", perm.getPermissionId(),\r\n+\t\t\t\t\t\t\"userId\", userId);\r\n \t\t\r\n \t\ttry {\r\n+\t\t\tDotStatefulJob.enqueueTrigger(nextExecutionData, ResetPermissionsJob.class);\r\n \r\n-\t\t\tfinal Scheduler sched = QuartzUtils.getSequentialScheduler();\r\n-\t\t\tsched.scheduleJob(jd, trigger);\r\n-\t\t} catch (SchedulerException e) {\r\n+\t\t} catch (Exception e) {\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTM1OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0NVrOHKLeCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0NVrOHKLeCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTcyMQ==", "bodyText": "Codacy found an issue: Avoid variables with short names like to", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435721", "createdAt": "2020-08-31T22:29:45Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+package com.dotmarketing.quartz;\n+\n+import static com.dotmarketing.quartz.QuartzUtils.getSequentialScheduler;\n+import static java.util.Objects.requireNonNull;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.dotcms.IntegrationTestBase;\n+import com.dotcms.util.IntegrationTestInitService;\n+import com.dotmarketing.util.Logger;\n+import com.google.common.collect.ImmutableMap;\n+import java.text.ParseException;\n+import java.time.LocalTime;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.quartz.JobDetail;\n+import org.quartz.JobExecutionContext;\n+import org.quartz.Scheduler;\n+import org.quartz.SchedulerException;\n+\n+public class DotStatefulJobTest extends IntegrationTestBase {\n+\n+    @BeforeClass\n+    public static void prepare() throws Exception {\n+        // Setting web app environment\n+        IntegrationTestInitService.getInstance().init();\n+        getSequentialScheduler().start();\n+    }\n+\n+    /**\n+     * clean up precaution\n+     * @throws SchedulerException\n+     */\n+    private void removeAnyExistingJob() throws SchedulerException {\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        final String jobGroupName = DotStatefulJob.getJobGroupName(MyStatefulJob.class);\n+        QuartzUtils.removeJob(jobName, jobGroupName);\n+    }\n+\n+    /**\n+     * Given scenario: We prep to trigger a bunch of tasks that must be executed sequentially (one at the time) never in parallel.\n+     * Expected Results: first all triggered tasks must be executed and completed. second their time mark must revel that none of theme overlapped.\n+     *\n+     * @throws SchedulerException\n+     * @throws ParseException\n+     * @throws ClassNotFoundException\n+     * @throws InterruptedException\n+     */\n+    @Test\n+    public void Test_Launch_Stateful_Jobs_Verify_They_Dont_Overlap_In_Time()\n+            throws SchedulerException, ParseException, ClassNotFoundException, InterruptedException {\n+\n+        //in order to avoid conflicts clean any reference that could have been left.\n+        removeAnyExistingJob();\n+\n+        //Now enqueue a few jos .. They will sleep randomly to simulate work.\n+        for (int i = 1; i <= MyStatefulJob.MAX_THREADS; i++) {\n+            MyStatefulJob.fireJob(ImmutableMap.of(\"index\", i));\n+            //Now verify the detail has been added for the present trigger we're introducing\n+            final Optional<Map<String, Object>> triggerJobDetail = DotStatefulJob\n+                    .getTriggerJobDetail(MyStatefulJob.class);\n+            assertNotNull(triggerJobDetail);\n+            assertTrue(triggerJobDetail.isPresent());\n+            final Map<String, Object> detail = triggerJobDetail.get();\n+            assertNotNull(detail);\n+            //The size of the detail should have grown as we insert new triggers.\n+            assertEquals(detail.size(), i);\n+        }\n+\n+        //Verify at least 1 job has been launched.\n+        final Optional<JobExecutionContext> jobExecutionContext = getJobExecutionContext();\n+        assertTrue(jobExecutionContext.isPresent());\n+\n+        //Now lets wait for the all the threads to complete.\n+        MyStatefulJob.countDownLatch.await();\n+\n+        //Now lets revise the execution times. Since they were supposed to run sequentially the should never overlap.\n+        final HashSet<MyStatefulJob> myStatefulJobs = new HashSet<>(MyStatefulJob.finishedJobs);\n+        final Iterator<MyStatefulJob> iterator = myStatefulJobs.iterator();\n+        while(iterator.hasNext()){\n+            final MyStatefulJob myStatefulJob = iterator.next();\n+            iterator.forEachRemaining(job -> {\n+                //They should never overlap.\n+                assertFalse(myStatefulJob.getTimeRange().overlaps(job.getTimeRange()));\n+            });\n+        }\n+    }\n+\n+    /**\n+     * This gets you the execution context for the given job-name.\n+     * @return\n+     */\n+    private Optional<JobExecutionContext> getJobExecutionContext(){\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        try {\n+            final Scheduler sequentialScheduler = getSequentialScheduler();\n+            @SuppressWarnings(\"unchecked\")\n+            final List<JobExecutionContext> executingJobs = sequentialScheduler.getCurrentlyExecutingJobs();\n+            return executingJobs.stream().filter(jobExecutionContext -> {\n+                final JobDetail jobDetail = jobExecutionContext.getJobDetail();\n+                return jobDetail != null && jobName.equals(jobDetail.getName());\n+            }).findFirst();\n+        } catch (Exception e) {\n+            Logger.error(DotStatefulJobTest.class, \"Error retrieving execution context. \" , e);\n+        }\n+        return Optional.empty();\n+    }\n+\n+    /**\n+     * additional struct to follow execution time lapse.\n+     */\n+    public static class LocalTimeRange {\n+\n+        private final LocalTime from;\n+        private final LocalTime to;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTQ0OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0NlrOHKLeFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0NlrOHKLeFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTczMw==", "bodyText": "Codacy found an issue: Avoid catching generic exceptions such as NullPointerException, RuntimeException, Exception in try-catch block", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435733", "createdAt": "2020-08-31T22:29:46Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+package com.dotmarketing.quartz;\n+\n+import static com.dotmarketing.quartz.QuartzUtils.getSequentialScheduler;\n+import static java.util.Objects.requireNonNull;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.dotcms.IntegrationTestBase;\n+import com.dotcms.util.IntegrationTestInitService;\n+import com.dotmarketing.util.Logger;\n+import com.google.common.collect.ImmutableMap;\n+import java.text.ParseException;\n+import java.time.LocalTime;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.quartz.JobDetail;\n+import org.quartz.JobExecutionContext;\n+import org.quartz.Scheduler;\n+import org.quartz.SchedulerException;\n+\n+public class DotStatefulJobTest extends IntegrationTestBase {\n+\n+    @BeforeClass\n+    public static void prepare() throws Exception {\n+        // Setting web app environment\n+        IntegrationTestInitService.getInstance().init();\n+        getSequentialScheduler().start();\n+    }\n+\n+    /**\n+     * clean up precaution\n+     * @throws SchedulerException\n+     */\n+    private void removeAnyExistingJob() throws SchedulerException {\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        final String jobGroupName = DotStatefulJob.getJobGroupName(MyStatefulJob.class);\n+        QuartzUtils.removeJob(jobName, jobGroupName);\n+    }\n+\n+    /**\n+     * Given scenario: We prep to trigger a bunch of tasks that must be executed sequentially (one at the time) never in parallel.\n+     * Expected Results: first all triggered tasks must be executed and completed. second their time mark must revel that none of theme overlapped.\n+     *\n+     * @throws SchedulerException\n+     * @throws ParseException\n+     * @throws ClassNotFoundException\n+     * @throws InterruptedException\n+     */\n+    @Test\n+    public void Test_Launch_Stateful_Jobs_Verify_They_Dont_Overlap_In_Time()\n+            throws SchedulerException, ParseException, ClassNotFoundException, InterruptedException {\n+\n+        //in order to avoid conflicts clean any reference that could have been left.\n+        removeAnyExistingJob();\n+\n+        //Now enqueue a few jos .. They will sleep randomly to simulate work.\n+        for (int i = 1; i <= MyStatefulJob.MAX_THREADS; i++) {\n+            MyStatefulJob.fireJob(ImmutableMap.of(\"index\", i));\n+            //Now verify the detail has been added for the present trigger we're introducing\n+            final Optional<Map<String, Object>> triggerJobDetail = DotStatefulJob\n+                    .getTriggerJobDetail(MyStatefulJob.class);\n+            assertNotNull(triggerJobDetail);\n+            assertTrue(triggerJobDetail.isPresent());\n+            final Map<String, Object> detail = triggerJobDetail.get();\n+            assertNotNull(detail);\n+            //The size of the detail should have grown as we insert new triggers.\n+            assertEquals(detail.size(), i);\n+        }\n+\n+        //Verify at least 1 job has been launched.\n+        final Optional<JobExecutionContext> jobExecutionContext = getJobExecutionContext();\n+        assertTrue(jobExecutionContext.isPresent());\n+\n+        //Now lets wait for the all the threads to complete.\n+        MyStatefulJob.countDownLatch.await();\n+\n+        //Now lets revise the execution times. Since they were supposed to run sequentially the should never overlap.\n+        final HashSet<MyStatefulJob> myStatefulJobs = new HashSet<>(MyStatefulJob.finishedJobs);\n+        final Iterator<MyStatefulJob> iterator = myStatefulJobs.iterator();\n+        while(iterator.hasNext()){\n+            final MyStatefulJob myStatefulJob = iterator.next();\n+            iterator.forEachRemaining(job -> {\n+                //They should never overlap.\n+                assertFalse(myStatefulJob.getTimeRange().overlaps(job.getTimeRange()));\n+            });\n+        }\n+    }\n+\n+    /**\n+     * This gets you the execution context for the given job-name.\n+     * @return\n+     */\n+    private Optional<JobExecutionContext> getJobExecutionContext(){\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        try {\n+            final Scheduler sequentialScheduler = getSequentialScheduler();\n+            @SuppressWarnings(\"unchecked\")\n+            final List<JobExecutionContext> executingJobs = sequentialScheduler.getCurrentlyExecutingJobs();\n+            return executingJobs.stream().filter(jobExecutionContext -> {\n+                final JobDetail jobDetail = jobExecutionContext.getJobDetail();\n+                return jobDetail != null && jobName.equals(jobDetail.getName());\n+            }).findFirst();\n+        } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTQ5OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0N1rOHKLeHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0N1rOHKLeHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTc0Mg==", "bodyText": "Codacy found an issue: A method/constructor should not explicitly throw java.lang.Exception", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435742", "createdAt": "2020-08-31T22:29:47Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+package com.dotmarketing.quartz;\n+\n+import static com.dotmarketing.quartz.QuartzUtils.getSequentialScheduler;\n+import static java.util.Objects.requireNonNull;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.dotcms.IntegrationTestBase;\n+import com.dotcms.util.IntegrationTestInitService;\n+import com.dotmarketing.util.Logger;\n+import com.google.common.collect.ImmutableMap;\n+import java.text.ParseException;\n+import java.time.LocalTime;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.quartz.JobDetail;\n+import org.quartz.JobExecutionContext;\n+import org.quartz.Scheduler;\n+import org.quartz.SchedulerException;\n+\n+public class DotStatefulJobTest extends IntegrationTestBase {\n+\n+    @BeforeClass\n+    public static void prepare() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTU3OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0OFrOHKLeKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0OFrOHKLeKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTc1NA==", "bodyText": "Codacy found an issue: Avoid using short method names", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435754", "createdAt": "2020-08-31T22:29:48Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+package com.dotmarketing.quartz;\n+\n+import static com.dotmarketing.quartz.QuartzUtils.getSequentialScheduler;\n+import static java.util.Objects.requireNonNull;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.dotcms.IntegrationTestBase;\n+import com.dotcms.util.IntegrationTestInitService;\n+import com.dotmarketing.util.Logger;\n+import com.google.common.collect.ImmutableMap;\n+import java.text.ParseException;\n+import java.time.LocalTime;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.quartz.JobDetail;\n+import org.quartz.JobExecutionContext;\n+import org.quartz.Scheduler;\n+import org.quartz.SchedulerException;\n+\n+public class DotStatefulJobTest extends IntegrationTestBase {\n+\n+    @BeforeClass\n+    public static void prepare() throws Exception {\n+        // Setting web app environment\n+        IntegrationTestInitService.getInstance().init();\n+        getSequentialScheduler().start();\n+    }\n+\n+    /**\n+     * clean up precaution\n+     * @throws SchedulerException\n+     */\n+    private void removeAnyExistingJob() throws SchedulerException {\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        final String jobGroupName = DotStatefulJob.getJobGroupName(MyStatefulJob.class);\n+        QuartzUtils.removeJob(jobName, jobGroupName);\n+    }\n+\n+    /**\n+     * Given scenario: We prep to trigger a bunch of tasks that must be executed sequentially (one at the time) never in parallel.\n+     * Expected Results: first all triggered tasks must be executed and completed. second their time mark must revel that none of theme overlapped.\n+     *\n+     * @throws SchedulerException\n+     * @throws ParseException\n+     * @throws ClassNotFoundException\n+     * @throws InterruptedException\n+     */\n+    @Test\n+    public void Test_Launch_Stateful_Jobs_Verify_They_Dont_Overlap_In_Time()\n+            throws SchedulerException, ParseException, ClassNotFoundException, InterruptedException {\n+\n+        //in order to avoid conflicts clean any reference that could have been left.\n+        removeAnyExistingJob();\n+\n+        //Now enqueue a few jos .. They will sleep randomly to simulate work.\n+        for (int i = 1; i <= MyStatefulJob.MAX_THREADS; i++) {\n+            MyStatefulJob.fireJob(ImmutableMap.of(\"index\", i));\n+            //Now verify the detail has been added for the present trigger we're introducing\n+            final Optional<Map<String, Object>> triggerJobDetail = DotStatefulJob\n+                    .getTriggerJobDetail(MyStatefulJob.class);\n+            assertNotNull(triggerJobDetail);\n+            assertTrue(triggerJobDetail.isPresent());\n+            final Map<String, Object> detail = triggerJobDetail.get();\n+            assertNotNull(detail);\n+            //The size of the detail should have grown as we insert new triggers.\n+            assertEquals(detail.size(), i);\n+        }\n+\n+        //Verify at least 1 job has been launched.\n+        final Optional<JobExecutionContext> jobExecutionContext = getJobExecutionContext();\n+        assertTrue(jobExecutionContext.isPresent());\n+\n+        //Now lets wait for the all the threads to complete.\n+        MyStatefulJob.countDownLatch.await();\n+\n+        //Now lets revise the execution times. Since they were supposed to run sequentially the should never overlap.\n+        final HashSet<MyStatefulJob> myStatefulJobs = new HashSet<>(MyStatefulJob.finishedJobs);\n+        final Iterator<MyStatefulJob> iterator = myStatefulJobs.iterator();\n+        while(iterator.hasNext()){\n+            final MyStatefulJob myStatefulJob = iterator.next();\n+            iterator.forEachRemaining(job -> {\n+                //They should never overlap.\n+                assertFalse(myStatefulJob.getTimeRange().overlaps(job.getTimeRange()));\n+            });\n+        }\n+    }\n+\n+    /**\n+     * This gets you the execution context for the given job-name.\n+     * @return\n+     */\n+    private Optional<JobExecutionContext> getJobExecutionContext(){\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        try {\n+            final Scheduler sequentialScheduler = getSequentialScheduler();\n+            @SuppressWarnings(\"unchecked\")\n+            final List<JobExecutionContext> executingJobs = sequentialScheduler.getCurrentlyExecutingJobs();\n+            return executingJobs.stream().filter(jobExecutionContext -> {\n+                final JobDetail jobDetail = jobExecutionContext.getJobDetail();\n+                return jobDetail != null && jobName.equals(jobDetail.getName());\n+            }).findFirst();\n+        } catch (Exception e) {\n+            Logger.error(DotStatefulJobTest.class, \"Error retrieving execution context. \" , e);\n+        }\n+        return Optional.empty();\n+    }\n+\n+    /**\n+     * additional struct to follow execution time lapse.\n+     */\n+    public static class LocalTimeRange {\n+\n+        private final LocalTime from;\n+        private final LocalTime to;\n+\n+        LocalTimeRange(final LocalTime from, final LocalTime to) {\n+            requireNonNull(from, \"from must not be null\");\n+            requireNonNull(to, \"to must not be null\");\n+            this.from = from;\n+            this.to = to;\n+        }\n+\n+        boolean overlaps(final LocalTimeRange other) {\n+            requireNonNull(other, \"other must not be null\");\n+            return isBetween(other.from, this.from, this.to)\n+                    || isBetween(other.to, this.from, this.to)\n+                    || isBetween(this.from, other.from, other.to)\n+                    || isBetween(this.to, other.from, other.to);\n+        }\n+\n+        private static boolean isBetween(final LocalTime time, final LocalTime from, final LocalTime to) {\n+            if (from.isBefore(to)) { // same day\n+                return from.isBefore(time) && time.isBefore(to);\n+            } else { // spans to the next day.\n+                return from.isBefore(time) || time.isBefore(to);\n+            }\n+        }\n+\n+        public static LocalTimeRange of(final LocalTime from, final LocalTime to){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTY3OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0OVrOHKLeNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo0OVrOHKLeNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTc2Nw==", "bodyText": "Codacy found an issue: Avoid variables with short names like to", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435767", "createdAt": "2020-08-31T22:29:49Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/integration-test/java/com/dotmarketing/quartz/DotStatefulJobTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+package com.dotmarketing.quartz;\n+\n+import static com.dotmarketing.quartz.QuartzUtils.getSequentialScheduler;\n+import static java.util.Objects.requireNonNull;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.dotcms.IntegrationTestBase;\n+import com.dotcms.util.IntegrationTestInitService;\n+import com.dotmarketing.util.Logger;\n+import com.google.common.collect.ImmutableMap;\n+import java.text.ParseException;\n+import java.time.LocalTime;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.quartz.JobDetail;\n+import org.quartz.JobExecutionContext;\n+import org.quartz.Scheduler;\n+import org.quartz.SchedulerException;\n+\n+public class DotStatefulJobTest extends IntegrationTestBase {\n+\n+    @BeforeClass\n+    public static void prepare() throws Exception {\n+        // Setting web app environment\n+        IntegrationTestInitService.getInstance().init();\n+        getSequentialScheduler().start();\n+    }\n+\n+    /**\n+     * clean up precaution\n+     * @throws SchedulerException\n+     */\n+    private void removeAnyExistingJob() throws SchedulerException {\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        final String jobGroupName = DotStatefulJob.getJobGroupName(MyStatefulJob.class);\n+        QuartzUtils.removeJob(jobName, jobGroupName);\n+    }\n+\n+    /**\n+     * Given scenario: We prep to trigger a bunch of tasks that must be executed sequentially (one at the time) never in parallel.\n+     * Expected Results: first all triggered tasks must be executed and completed. second their time mark must revel that none of theme overlapped.\n+     *\n+     * @throws SchedulerException\n+     * @throws ParseException\n+     * @throws ClassNotFoundException\n+     * @throws InterruptedException\n+     */\n+    @Test\n+    public void Test_Launch_Stateful_Jobs_Verify_They_Dont_Overlap_In_Time()\n+            throws SchedulerException, ParseException, ClassNotFoundException, InterruptedException {\n+\n+        //in order to avoid conflicts clean any reference that could have been left.\n+        removeAnyExistingJob();\n+\n+        //Now enqueue a few jos .. They will sleep randomly to simulate work.\n+        for (int i = 1; i <= MyStatefulJob.MAX_THREADS; i++) {\n+            MyStatefulJob.fireJob(ImmutableMap.of(\"index\", i));\n+            //Now verify the detail has been added for the present trigger we're introducing\n+            final Optional<Map<String, Object>> triggerJobDetail = DotStatefulJob\n+                    .getTriggerJobDetail(MyStatefulJob.class);\n+            assertNotNull(triggerJobDetail);\n+            assertTrue(triggerJobDetail.isPresent());\n+            final Map<String, Object> detail = triggerJobDetail.get();\n+            assertNotNull(detail);\n+            //The size of the detail should have grown as we insert new triggers.\n+            assertEquals(detail.size(), i);\n+        }\n+\n+        //Verify at least 1 job has been launched.\n+        final Optional<JobExecutionContext> jobExecutionContext = getJobExecutionContext();\n+        assertTrue(jobExecutionContext.isPresent());\n+\n+        //Now lets wait for the all the threads to complete.\n+        MyStatefulJob.countDownLatch.await();\n+\n+        //Now lets revise the execution times. Since they were supposed to run sequentially the should never overlap.\n+        final HashSet<MyStatefulJob> myStatefulJobs = new HashSet<>(MyStatefulJob.finishedJobs);\n+        final Iterator<MyStatefulJob> iterator = myStatefulJobs.iterator();\n+        while(iterator.hasNext()){\n+            final MyStatefulJob myStatefulJob = iterator.next();\n+            iterator.forEachRemaining(job -> {\n+                //They should never overlap.\n+                assertFalse(myStatefulJob.getTimeRange().overlaps(job.getTimeRange()));\n+            });\n+        }\n+    }\n+\n+    /**\n+     * This gets you the execution context for the given job-name.\n+     * @return\n+     */\n+    private Optional<JobExecutionContext> getJobExecutionContext(){\n+        final String jobName = DotStatefulJob.getJobName(MyStatefulJob.class);\n+        try {\n+            final Scheduler sequentialScheduler = getSequentialScheduler();\n+            @SuppressWarnings(\"unchecked\")\n+            final List<JobExecutionContext> executingJobs = sequentialScheduler.getCurrentlyExecutingJobs();\n+            return executingJobs.stream().filter(jobExecutionContext -> {\n+                final JobDetail jobDetail = jobExecutionContext.getJobDetail();\n+                return jobDetail != null && jobName.equals(jobDetail.getName());\n+            }).findFirst();\n+        } catch (Exception e) {\n+            Logger.error(DotStatefulJobTest.class, \"Error retrieving execution context. \" , e);\n+        }\n+        return Optional.empty();\n+    }\n+\n+    /**\n+     * additional struct to follow execution time lapse.\n+     */\n+    public static class LocalTimeRange {\n+\n+        private final LocalTime from;\n+        private final LocalTime to;\n+\n+        LocalTimeRange(final LocalTime from, final LocalTime to) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDEyOTc5OnYy", "diffSide": "RIGHT", "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/DeleteUserJob.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo1MFrOHKLeRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMjoyOTo1MFrOHKLeRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQzNTc4Mg==", "bodyText": "Codacy found an issue: A catch statement should never catch throwable since it includes errors.", "url": "https://github.com/dotCMS/core/pull/19172#discussion_r480435782", "createdAt": "2020-08-31T22:29:50Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/main/java/com/dotmarketing/quartz/job/DeleteUserJob.java", "diffHunk": "@@ -34,47 +40,41 @@ public DeleteUserJob() {\n         notfAPI = APILocator.getNotificationAPI();\n     }\n \n-    public static void triggerDeleteUserJob(User userToDelete, User replacementUser, User user,\n-                                            boolean respectFrontEndRoles) {\n-        JobDataMap dataMap = new JobDataMap();\n-        dataMap.put(\"userToDelete\", userToDelete);\n-        dataMap.put(\"replacementUser\", replacementUser);\n-        dataMap.put(\"user\", user);\n-        dataMap.put(\"respectFrontEndRoles\", respectFrontEndRoles);\n+    public static void triggerDeleteUserJob(final User userToDelete, final User replacementUser, final User user,\n+                                           final boolean respectFrontEndRoles) {\n \n-        String randomID = UUID.randomUUID().toString();\n+        final Map<String, Serializable> nextExecutionData = ImmutableMap\n+                .of(\"userToDelete\", userToDelete,\n+                        \"replacementUser\", replacementUser,\n+                        \"user\", user,\n+                        \"respectFrontEndRoles\", respectFrontEndRoles);\n \n-        JobDetail jd = new JobDetail(\"DeleteUserJob-\" + randomID, \"delete_user_jobs\", DeleteUserJob.class);\n-        jd.setJobDataMap(dataMap);\n-        jd.setDurability(false);\n-        jd.setVolatility(false);\n-        jd.setRequestsRecovery(true);\n-\n-        long startTime = System.currentTimeMillis();\n-        SimpleTrigger trigger = new SimpleTrigger(\"deleteUserTrigger-\" + randomID, \"delete_user_triggers\",\n-            new Date(startTime));\n \n         try {\n-            Scheduler sched = QuartzUtils.getSequentialScheduler();\n-            UserAPI userAPI = APILocator.getUserAPI();\n-            NotificationAPI notAPI = APILocator.getNotificationAPI();\n+            final UserAPI userAPI = APILocator.getUserAPI();\n+            final NotificationAPI notAPI = APILocator.getNotificationAPI();\n \n-            String deleteInProgress = MessageFormat.format(LanguageUtil.get(user,\n+            final String deleteInProgress = MessageFormat.format(LanguageUtil.get(user,\n                 \"com.dotmarketing.business.UserAPI.delete.inProgress\"),\n                 userToDelete.getUserId() + \"/\" + userToDelete.getFullName());\n \n-            synchronized (userToDelete.getUserId().intern()) {\n-                User freshUser = userAPI.loadUserById(userToDelete.getUserId());\n-                if(! freshUser.isDeleteInProgress()) {\n+            final IdentifierStripedLock lockManager = DotConcurrentFactory.getInstance().getIdentifierStripedLock();\n+            lockManager.tryLock(userToDelete.getUserId(), () -> {\n+                final User freshUser = userAPI.loadUserById(userToDelete.getUserId());\n+                if (!freshUser.isDeleteInProgress()) {\n                     userAPI.markToDelete(userToDelete);\n-                    sched.scheduleJob(jd, trigger);\n+                    try {\n+                        DotStatefulJob.enqueueTrigger(nextExecutionData, DeleteUserJob.class);\n+                    }catch (ParseException | SchedulerException | ClassNotFoundException e){\n+                        Logger.error(DeleteUserJob.class, \"Error scheduling DeleteUserJob\", e);\n+                        throw new DotRuntimeException(\"Error scheduling DeleteUserJob\", e);\n+                    }\n                 } else {\n                     notAPI.info(deleteInProgress, user.getUserId());\n                 }\n-            }\n+            });\n \n-\n-        } catch (SchedulerException e) {\n+        } catch (Throwable e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db4892f2221d8a4eb1be5d45f4c3f813782ad0ef"}, "originalPosition": 108}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1834, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}