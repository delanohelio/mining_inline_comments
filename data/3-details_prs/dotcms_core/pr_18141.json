{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg5MzA2OTg0", "number": 18141, "title": "Issue 17976 fixes", "bodyText": "This comes to solve problems when creating bundles for non-default languages.\nThe problem was in DotParse resolving contentletVersionInfo\nAdditionally to that. Other problems related to concurrency were solved by refactoring and the structure of the large method of the job converting it into smaller synchronizable pieces.\nAnd last but not least I solved an additional problem that surfaced while testing simultaneous running jobs where the alias names would eventually get lost. The alias name assigned to the old index name wasn't getting returned by the site search API.", "createdAt": "2020-03-16T15:16:45Z", "url": "https://github.com/dotCMS/core/pull/18141", "merged": true, "mergeCommit": {"oid": "4b17b698d1c034c0b5b719f106e3530d198a6ad1"}, "closed": true, "closedAt": "2020-03-19T16:45:03Z", "author": {"login": "fabrizzio-dotCMS"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcNRNoDAH2gAyMzg5MzA2OTg0OmIzNDM4YzQyYzZiOWQwNWVmYTQ4ZTE5ZWY5YTllMmVlNTRjOGFlMDg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcPOugigFqTM3NzkwMjc4MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "b3438c42c6b9d05efa48e19ef9a9e2ee54c8ae08", "author": {"user": {"login": "fabrizzio-dotCMS", "name": "Fabrizzio Araya"}}, "url": "https://github.com/dotCMS/core/commit/b3438c42c6b9d05efa48e19ef9a9e2ee54c8ae08", "committedDate": "2020-03-13T14:30:22Z", "message": "#17976"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "79914fcafa2fb297ae568ee60a33a11b774c1f8a", "author": {"user": {"login": "fabrizzio-dotCMS", "name": "Fabrizzio Araya"}}, "url": "https://github.com/dotCMS/core/commit/79914fcafa2fb297ae568ee60a33a11b774c1f8a", "committedDate": "2020-03-13T18:18:23Z", "message": "#17976 fix indexing non-default lang"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "150d16af52443a6a91d95b279480d042ff66db67", "author": {"user": {"login": "fabrizzio-dotCMS", "name": "Fabrizzio Araya"}}, "url": "https://github.com/dotCMS/core/commit/150d16af52443a6a91d95b279480d042ff66db67", "committedDate": "2020-03-16T14:38:08Z", "message": "#17976 adding concurrency  support."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d", "author": {"user": {"login": "fabrizzio-dotCMS", "name": "Fabrizzio Araya"}}, "url": "https://github.com/dotCMS/core/commit/665016576f43724d2aa070ab028f588ca153dc4d", "committedDate": "2020-03-16T14:55:31Z", "message": "#17976 logger clean up"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1MzI1MDU0", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-375325054", "createdAt": "2020-03-16T15:26:42Z", "commit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNToyNjo0MlrOF25btw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNToyNjo0MlrOF25btw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzEwODQwNw==", "bodyText": "rename to bundlerStatus", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393108407", "createdAt": "2020-03-16T15:26:42Z", "author": {"login": "jdotcms"}, "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -129,182 +134,213 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n \n         HibernateUtil.startTransaction();\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n-\n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n-        }\n-\n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n-\n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n-\n-        final User userToRun = userAPI.getSystemUser();\n-\n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n-\n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n+        final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+        synchronized (preparedJobContext.lockKey()) {\n+            for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                publisherAPI.publish(config, status);\n             }\n         }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n-\n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n-                }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n-\n-        final List<String> languageToIndex = Arrays.asList((String[])dataMap.get(LANG_TO_INDEX));\n-        final ListIterator<String> listIterator = languageToIndex.listIterator();\n-        while (listIterator.hasNext()) {\n-            final String lang = listIterator.next();\n-            final SiteSearchConfig config = new SiteSearchConfig();\n-            config.setJobId(jobId);\n-            config.setLanguage(Long.parseLong(lang));\n-            config.setJobName(jobName);\n-            config.setHosts(hosts);\n-            config.setNewIndexName(newIndexName);\n-            config.setIndexName(indexName);\n-            config.setId(bundleId);\n-            config.setStartDate(startDate);\n-            config.setEndDate(endDate);\n-            config.setIncremental(incremental);\n-            config.setUser(userToRun);\n-\n-            if(include) {\n-                config.setIncludePatterns(paths);\n-            } else {\n-                config.setExcludePatterns(paths);\n-            }\n \n-            //We should always replace the index when performing on non-incremental mode.\n-            //That means we drop the old one and re-use the alias.\n-            //But we only activate the new index when the old one was the default.\n-            //Or there wasn't any previous index.\n-            //it must be done on the last round of our loop.\n-            final boolean switchIndex = !incremental && !listIterator.hasNext();\n-            config.setSwitchIndexWhenDone(switchIndex);\n-            publisherAPI.publish(config, status);\n-        }\n+        try {\n \n-        int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n-        for (final BundlerStatus bs : status.getBundlerStatuses()) {\n-            if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n-                filesCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n-                urlmapCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(HTMLPageAsContentBundler.class.getName())) {\n-                pagesCount += bs.getTotal();\n-            }\n-        }\n+                int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                for (final BundlerStatus bs : status.getBundlerStatuses()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "originalPosition": 188}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1MzMwOTMx", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-375330931", "createdAt": "2020-03-16T15:33:04Z", "commit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNTozMzowNFrOF25tnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNTozMzowNFrOF25tnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExMjk4OQ==", "bodyText": "Is a synchronization block enough? At the end of the day, the SiteSearchJob in quartz should be a Stateful job.  A Stateful job can only be run one at a time in a whole cluster. This is an important distinction as for most of our Quartz Jobs we do not want them to be run simultaneously in a clustered environment by different servers.", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393112989", "createdAt": "2020-03-16T15:33:04Z", "author": {"login": "wezell"}, "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -52,6 +55,8 @@\n \n public class SiteSearchJobImpl {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1MzMxNTIx", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-375331521", "createdAt": "2020-03-16T15:33:44Z", "commit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNTozMzo0NFrOF25vlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNTozMzo0NFrOF25vlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExMzQ5Mw==", "bodyText": "this could be handle in a method such as\nindexHosts = ConversionUtils.toArrayString (dataMap.get(INDEX_HOST));", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393113493", "createdAt": "2020-03-16T15:33:44Z", "author": {"login": "jdotcms"}, "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -129,182 +134,213 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n \n         HibernateUtil.startTransaction();\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n-\n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n-        }\n-\n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n-\n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n-\n-        final User userToRun = userAPI.getSystemUser();\n-\n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n-\n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n+        final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+        synchronized (preparedJobContext.lockKey()) {\n+            for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                publisherAPI.publish(config, status);\n             }\n         }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n-\n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n-                }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n-\n-        final List<String> languageToIndex = Arrays.asList((String[])dataMap.get(LANG_TO_INDEX));\n-        final ListIterator<String> listIterator = languageToIndex.listIterator();\n-        while (listIterator.hasNext()) {\n-            final String lang = listIterator.next();\n-            final SiteSearchConfig config = new SiteSearchConfig();\n-            config.setJobId(jobId);\n-            config.setLanguage(Long.parseLong(lang));\n-            config.setJobName(jobName);\n-            config.setHosts(hosts);\n-            config.setNewIndexName(newIndexName);\n-            config.setIndexName(indexName);\n-            config.setId(bundleId);\n-            config.setStartDate(startDate);\n-            config.setEndDate(endDate);\n-            config.setIncremental(incremental);\n-            config.setUser(userToRun);\n-\n-            if(include) {\n-                config.setIncludePatterns(paths);\n-            } else {\n-                config.setExcludePatterns(paths);\n-            }\n \n-            //We should always replace the index when performing on non-incremental mode.\n-            //That means we drop the old one and re-use the alias.\n-            //But we only activate the new index when the old one was the default.\n-            //Or there wasn't any previous index.\n-            //it must be done on the last round of our loop.\n-            final boolean switchIndex = !incremental && !listIterator.hasNext();\n-            config.setSwitchIndexWhenDone(switchIndex);\n-            publisherAPI.publish(config, status);\n-        }\n+        try {\n \n-        int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n-        for (final BundlerStatus bs : status.getBundlerStatuses()) {\n-            if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n-                filesCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n-                urlmapCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(HTMLPageAsContentBundler.class.getName())) {\n-                pagesCount += bs.getTotal();\n-            }\n-        }\n+                int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                for (final BundlerStatus bs : status.getBundlerStatuses()) {\n+                    if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n+                        filesCount += bs.getTotal();\n+                    } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n+                        urlmapCount += bs.getTotal();\n+                    } else if (bs.getBundlerClass()\n+                            .equals(HTMLPageAsContentBundler.class.getName())) {\n+                        pagesCount += bs.getTotal();\n+                    }\n+                }\n \n-        try {\n-            final SiteSearchAudit audit = new SiteSearchAudit();\n-            audit.setPagesCount(pagesCount);\n-            audit.setFilesCount(filesCount);\n-            audit.setUrlmapsCount(urlmapCount);\n-            audit.setAllHosts(indexAll);\n-            audit.setFireDate(jobContext.getFireTime());\n-            audit.setHostList(UtilMethods.join(indexHosts,\",\",true));\n-            audit.setIncremental(incremental);\n-            audit.setStartDate(startDate);\n-            audit.setEndDate(endDate);\n-            audit.setIndexName( UtilMethods.isSet(newIndexName) ? newIndexName :  indexName );\n-            audit.setJobId(jobId);\n-            audit.setJobName(dataMap.getString(QUARTZ_JOB_NAME));\n-            audit.setLangList(UtilMethods.join(languageToIndex,\",\"));\n-            audit.setPath(paths.size() > 0 ? UtilMethods.join(paths,\",\") : \"/*\");\n-            audit.setPathInclude(include);\n-            siteSearchAuditAPI.save(audit);\n-        }\n-        catch(DotDataException ex) {\n-            Logger.error(this, \"can't save audit data\",ex);\n-        }\n-        finally {\n+                final SiteSearchAudit audit = new SiteSearchAudit();\n+                audit.setPagesCount(pagesCount);\n+                audit.setFilesCount(filesCount);\n+                audit.setUrlmapsCount(urlmapCount);\n+                audit.setAllHosts(preparedJobContext.isIndexAll());\n+                audit.setFireDate(jobContext.getFireTime());\n+                audit.setHostList(preparedJobContext.getJoinedHosts());\n+                audit.setIncremental(preparedJobContext.isIncremental());\n+                audit.setStartDate(preparedJobContext.getStartDate());\n+                audit.setEndDate(preparedJobContext.getEndDate());\n+                audit.setIndexName(\n+                        UtilMethods.isSet(preparedJobContext.getNewIndexName()) ? preparedJobContext\n+                                .getNewIndexName() : preparedJobContext.getIndexName());\n+                audit.setJobId(preparedJobContext.getJobId());\n+                audit.setJobName(preparedJobContext.getJobName());\n+                audit.setLangList(preparedJobContext.getLangList());\n+                audit.setPath(preparedJobContext.getPaths());\n+                audit.setPathInclude(preparedJobContext.isPathInclude());\n+                siteSearchAuditAPI.save(audit);\n+\n+\n+        } catch (DotDataException ex) {\n+            Logger.error(this, \"can't save audit data\", ex);\n+        } finally {\n             HibernateUtil.closeSession();\n         }\n-\n         date = DateUtil.getCurrentDate();\n         ActivityLogger.logInfo(getClass(), \"Job Finished\", \"User: \" +userAPI.getSystemUser().getUserId()+ \"; Date: \" + date + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME  );\n         AdminLogger.log(getClass(), \"Job Finished\", \"User: \" +userAPI.getSystemUser().getUserId()+ \"; Date: \" + date + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME );\n     }\n \n+     private synchronized PreparedJobContext prepareJob(final JobExecutionContext jobContext)\n+             throws DotDataException, IOException, DotSecurityException {\n+\n+         final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+         String jobId = (String) dataMap.get(JOB_ID);\n+         if (jobId == null) {\n+             jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+         }\n+\n+         final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n+         final String[] indexHosts;\n+         final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "originalPosition": 265}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1MzMyNzkx", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-375332791", "createdAt": "2020-03-16T15:35:04Z", "commit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNTozNTowNFrOF25zAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNTozNTowNFrOF25zAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExNDM3MA==", "bodyText": "rename to pathToken or so", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393114370", "createdAt": "2020-03-16T15:35:04Z", "author": {"login": "jdotcms"}, "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -129,182 +134,213 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n \n         HibernateUtil.startTransaction();\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n-\n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n-        }\n-\n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n-\n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n-\n-        final User userToRun = userAPI.getSystemUser();\n-\n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n-\n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n+        final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+        synchronized (preparedJobContext.lockKey()) {\n+            for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                publisherAPI.publish(config, status);\n             }\n         }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n-\n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n-                }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n-\n-        final List<String> languageToIndex = Arrays.asList((String[])dataMap.get(LANG_TO_INDEX));\n-        final ListIterator<String> listIterator = languageToIndex.listIterator();\n-        while (listIterator.hasNext()) {\n-            final String lang = listIterator.next();\n-            final SiteSearchConfig config = new SiteSearchConfig();\n-            config.setJobId(jobId);\n-            config.setLanguage(Long.parseLong(lang));\n-            config.setJobName(jobName);\n-            config.setHosts(hosts);\n-            config.setNewIndexName(newIndexName);\n-            config.setIndexName(indexName);\n-            config.setId(bundleId);\n-            config.setStartDate(startDate);\n-            config.setEndDate(endDate);\n-            config.setIncremental(incremental);\n-            config.setUser(userToRun);\n-\n-            if(include) {\n-                config.setIncludePatterns(paths);\n-            } else {\n-                config.setExcludePatterns(paths);\n-            }\n \n-            //We should always replace the index when performing on non-incremental mode.\n-            //That means we drop the old one and re-use the alias.\n-            //But we only activate the new index when the old one was the default.\n-            //Or there wasn't any previous index.\n-            //it must be done on the last round of our loop.\n-            final boolean switchIndex = !incremental && !listIterator.hasNext();\n-            config.setSwitchIndexWhenDone(switchIndex);\n-            publisherAPI.publish(config, status);\n-        }\n+        try {\n \n-        int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n-        for (final BundlerStatus bs : status.getBundlerStatuses()) {\n-            if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n-                filesCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n-                urlmapCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(HTMLPageAsContentBundler.class.getName())) {\n-                pagesCount += bs.getTotal();\n-            }\n-        }\n+                int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                for (final BundlerStatus bs : status.getBundlerStatuses()) {\n+                    if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n+                        filesCount += bs.getTotal();\n+                    } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n+                        urlmapCount += bs.getTotal();\n+                    } else if (bs.getBundlerClass()\n+                            .equals(HTMLPageAsContentBundler.class.getName())) {\n+                        pagesCount += bs.getTotal();\n+                    }\n+                }\n \n-        try {\n-            final SiteSearchAudit audit = new SiteSearchAudit();\n-            audit.setPagesCount(pagesCount);\n-            audit.setFilesCount(filesCount);\n-            audit.setUrlmapsCount(urlmapCount);\n-            audit.setAllHosts(indexAll);\n-            audit.setFireDate(jobContext.getFireTime());\n-            audit.setHostList(UtilMethods.join(indexHosts,\",\",true));\n-            audit.setIncremental(incremental);\n-            audit.setStartDate(startDate);\n-            audit.setEndDate(endDate);\n-            audit.setIndexName( UtilMethods.isSet(newIndexName) ? newIndexName :  indexName );\n-            audit.setJobId(jobId);\n-            audit.setJobName(dataMap.getString(QUARTZ_JOB_NAME));\n-            audit.setLangList(UtilMethods.join(languageToIndex,\",\"));\n-            audit.setPath(paths.size() > 0 ? UtilMethods.join(paths,\",\") : \"/*\");\n-            audit.setPathInclude(include);\n-            siteSearchAuditAPI.save(audit);\n-        }\n-        catch(DotDataException ex) {\n-            Logger.error(this, \"can't save audit data\",ex);\n-        }\n-        finally {\n+                final SiteSearchAudit audit = new SiteSearchAudit();\n+                audit.setPagesCount(pagesCount);\n+                audit.setFilesCount(filesCount);\n+                audit.setUrlmapsCount(urlmapCount);\n+                audit.setAllHosts(preparedJobContext.isIndexAll());\n+                audit.setFireDate(jobContext.getFireTime());\n+                audit.setHostList(preparedJobContext.getJoinedHosts());\n+                audit.setIncremental(preparedJobContext.isIncremental());\n+                audit.setStartDate(preparedJobContext.getStartDate());\n+                audit.setEndDate(preparedJobContext.getEndDate());\n+                audit.setIndexName(\n+                        UtilMethods.isSet(preparedJobContext.getNewIndexName()) ? preparedJobContext\n+                                .getNewIndexName() : preparedJobContext.getIndexName());\n+                audit.setJobId(preparedJobContext.getJobId());\n+                audit.setJobName(preparedJobContext.getJobName());\n+                audit.setLangList(preparedJobContext.getLangList());\n+                audit.setPath(preparedJobContext.getPaths());\n+                audit.setPathInclude(preparedJobContext.isPathInclude());\n+                siteSearchAuditAPI.save(audit);\n+\n+\n+        } catch (DotDataException ex) {\n+            Logger.error(this, \"can't save audit data\", ex);\n+        } finally {\n             HibernateUtil.closeSession();\n         }\n-\n         date = DateUtil.getCurrentDate();\n         ActivityLogger.logInfo(getClass(), \"Job Finished\", \"User: \" +userAPI.getSystemUser().getUserId()+ \"; Date: \" + date + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME  );\n         AdminLogger.log(getClass(), \"Job Finished\", \"User: \" +userAPI.getSystemUser().getUserId()+ \"; Date: \" + date + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME );\n     }\n \n+     private synchronized PreparedJobContext prepareJob(final JobExecutionContext jobContext)\n+             throws DotDataException, IOException, DotSecurityException {\n+\n+         final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+         String jobId = (String) dataMap.get(JOB_ID);\n+         if (jobId == null) {\n+             jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+         }\n+\n+         final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n+         final String[] indexHosts;\n+         final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n+         if (obj instanceof String) {\n+             indexHosts = new String[]{(String) obj};\n+         } else {\n+             indexHosts = (String[]) obj;\n+         }\n+\n+         final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n+\n+         final User userToRun = userAPI.getSystemUser();\n+\n+         final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n+                 .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n+\n+         String path = dataMap.getString(PATHS);\n+         final List<String> paths = new ArrayList<>();\n+         if (path != null) {\n+             path = path.replace(',', '\\r');\n+             path = path.replace('\\n', '\\r');\n+             for (String x : path.split(\"\\r\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "originalPosition": 284}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1MzQwOTgw", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-375340980", "createdAt": "2020-03-16T15:44:01Z", "commit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNTo0NDowMVrOF26MFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNTo0NDowMVrOF26MFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzEyMDc5MQ==", "bodyText": "perfect candidate for a builder", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393120791", "createdAt": "2020-03-16T15:44:01Z", "author": {"login": "jdotcms"}, "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -371,4 +407,106 @@ public boolean isEmpty() {\n         }\n     }\n \n+    static class PreparedJobContext{\n+\n+        private final String indexName;\n+        private final String newIndexName;\n+        private final boolean indexAll;\n+        private final String joinedHosts;\n+        private final boolean incremental;\n+        private final Date startDate;\n+        private final Date endDate;\n+        private final String jobId;\n+        private final String jobName;\n+        private final String langList;\n+        private final String paths;\n+        private final boolean pathInclude;\n+        private final List<SiteSearchConfig> configs;\n+\n+        PreparedJobContext(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "665016576f43724d2aa070ab028f588ca153dc4d"}, "originalPosition": 433}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dbee0449e006af7075299e43b7c094e383f6690d", "author": {"user": {"login": "fabrizzio-dotCMS", "name": "Fabrizzio Araya"}}, "url": "https://github.com/dotCMS/core/commit/dbee0449e006af7075299e43b7c094e383f6690d", "committedDate": "2020-03-16T15:44:14Z", "message": "#17976  feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de21d996220f7296d06472749c355b116fff2693", "author": {"user": {"login": "fabrizzio-dotCMS", "name": "Fabrizzio Araya"}}, "url": "https://github.com/dotCMS/core/commit/de21d996220f7296d06472749c355b116fff2693", "committedDate": "2020-03-18T17:25:09Z", "message": "#17976 save point"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934", "author": {"user": {"login": "fabrizzio-dotCMS", "name": "Fabrizzio Araya"}}, "url": "https://github.com/dotCMS/core/commit/c24d0bc153ba91945ce03e93354009e02d5fb934", "committedDate": "2020-03-18T22:18:41Z", "message": "#17976 new unique site-search index name generation strategy"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3Mjc5MTEz", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-377279113", "createdAt": "2020-03-18T22:26:29Z", "commit": {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQyMjoyNjoyOVrOF4ZBbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQyMjoyNjoyOVrOF4ZBbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY3NDU0MQ==", "bodyText": "Issue found: Substitute calls to size() == 0 (or size() != 0, size() > 0, size() < 1) with calls to isEmpty()", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r394674541", "createdAt": "2020-03-18T22:26:29Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -128,186 +141,246 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n                         + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n \n         HibernateUtil.startTransaction();\n+        try {\n+            final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+            synchronized (preparedJobContext.lockKey()) {\n+                for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                    publisherAPI.publish(config, status);\n+                }\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+                try {\n \n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+                    int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                    for (final BundlerStatus bundlerStatus : status.getBundlerStatuses()) {\n+                        if (bundlerStatus.getBundlerClass()\n+                                .equals(FileAssetBundler.class.getName())) {\n+                            filesCount += bundlerStatus.getTotal();\n+                        } else if (bundlerStatus.getBundlerClass()\n+                                .equals(URLMapBundler.class.getName())) {\n+                            urlmapCount += bundlerStatus.getTotal();\n+                        } else if (bundlerStatus.getBundlerClass()\n+                                .equals(HTMLPageAsContentBundler.class.getName())) {\n+                            pagesCount += bundlerStatus.getTotal();\n+                        }\n+                    }\n+\n+                    final SiteSearchAudit audit = new SiteSearchAudit();\n+                    audit.setPagesCount(pagesCount);\n+                    audit.setFilesCount(filesCount);\n+                    audit.setUrlmapsCount(urlmapCount);\n+                    audit.setAllHosts(preparedJobContext.isIndexAll());\n+                    audit.setFireDate(jobContext.getFireTime());\n+                    audit.setHostList(preparedJobContext.getJoinedHosts());\n+                    audit.setIncremental(preparedJobContext.isIncremental());\n+                    audit.setStartDate(preparedJobContext.getStartDate());\n+                    audit.setEndDate(preparedJobContext.getEndDate());\n+                    audit.setIndexName(\n+                            UtilMethods.isSet(preparedJobContext.getNewIndexName())\n+                                    ? preparedJobContext\n+                                    .getNewIndexName() : preparedJobContext.getIndexName());\n+                    audit.setJobId(preparedJobContext.getJobId());\n+                    audit.setJobName(preparedJobContext.getJobName());\n+                    audit.setLangList(preparedJobContext.getLangList());\n+                    audit.setPath(preparedJobContext.getPaths());\n+                    audit.setPathInclude(preparedJobContext.isPathInclude());\n+                    siteSearchAuditAPI.save(audit);\n+\n+                } catch (DotDataException ex) {\n+                    Logger.error(this, \"can't save audit data\", ex);\n+                }\n+            }\n+        } finally {\n+            HibernateUtil.closeSession();\n         }\n+        date = DateUtil.getCurrentDate();\n+        ActivityLogger.logInfo(getClass(), \"Job Finished\",\n+                \"User: \" + userAPI.getSystemUser().getUserId() + \"; Date: \" + date\n+                        + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n+        AdminLogger.log(getClass(), \"Job Finished\",\n+                \"User: \" + userAPI.getSystemUser().getUserId() + \"; Date: \" + date\n+                        + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n+    }\n \n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n+    private PreparedJobContext prepareJob(final JobExecutionContext jobContext)\n+            throws DotDataException, IOException, DotSecurityException {\n+        synchronized (SiteSearchJobImpl.class) {\n+            final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+            String jobId = (String) dataMap.get(JOB_ID);\n+            if (jobId == null) {\n+                jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+            }\n \n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n+            final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n+            final String[] indexHosts;\n+            final Object obj =\n+                    (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n+            if (obj instanceof String) {\n+                indexHosts = new String[]{(String) obj};\n+            } else {\n+                indexHosts = (String[]) obj;\n+            }\n \n-        final User userToRun = userAPI.getSystemUser();\n+            final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n \n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n+            final User userToRun = userAPI.getSystemUser();\n \n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n-            }\n-        }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n+            final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n+                    .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n \n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n+            String path = dataMap.getString(PATHS);\n+            final List<String> paths = new ArrayList<>();\n+            if (path != null) {\n+                path = path.replace(',', '\\r');\n+                path = path.replace('\\n', '\\r');\n+                for (String x : path.split(\"\\r\")) {\n+                    if (UtilMethods.isSet(x)) {\n+                        paths.add(x);\n+                    }\n                 }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n+            }\n+            final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n+            // Run now jobs can not get the incremental treatment.\n+            final String indexAlias = dataMap.getString(INDEX_ALIAS);\n+            final IndexMetaData indexMetaData = getIndexMetaData(indexAlias);\n+            final String newIndexName;\n+            final String indexName;\n+\n+            final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n+            final Date startDate, endDate;\n+            final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n+                    : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n+\n+            final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData\n+                    .isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n+            //We can only run incrementally if all the above pre-requisites are met.\n+            if (incremental) {\n+                //Incremental mode is useful only if there's already an index previously built.\n+                //Incremental mode also implies that we have to have a date range to work on.\n+                //So if we have an empty index or we lack of audit data we can not run incrementally.\n+                //Even if the user wants to.\n+                newIndexName = null;\n+                endDate = jobContext.getFireTime();\n+                startDate = recentAudits.get(0).getFireDate();\n+                //For incremental jobs, we write the bundle to the same folder every time.\n+                bundleId = StringUtils.camelCaseLower(jobName);\n+                //We'll be working directly into the final index.\n+                indexName = indexMetaData.getIndexName();\n+            } else {\n+                //Set null explicitly just in case\n+                startDate = endDate = null;\n+                // For non-incremental jobs. We create a new folder using a date stamp.\n+                // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n+                // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n+                // So they will still be available in the next round.\n+                bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n+                        // Otherwise it is safe to create a unique  folder name.\n+                        uniqueFolderName();\n+                // We use a new index name only on non-incremental\n+                newIndexName = newIndexName();\n+                final String newAlias =\n+                        indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null;\n+                siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n+                // This is the old index we will swap from.\n+                // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n+                indexName = indexMetaData.getIndexName();\n+            }\n \n-        final List<String> languageToIndex = Arrays.asList((String[])dataMap.get(LANG_TO_INDEX));\n-        final ListIterator<String> listIterator = languageToIndex.listIterator();\n-        while (listIterator.hasNext()) {\n-            final String lang = listIterator.next();\n-            final SiteSearchConfig config = new SiteSearchConfig();\n-            config.setJobId(jobId);\n-            config.setLanguage(Long.parseLong(lang));\n-            config.setJobName(jobName);\n-            config.setHosts(hosts);\n-            config.setNewIndexName(newIndexName);\n-            config.setIndexName(indexName);\n-            config.setId(bundleId);\n-            config.setStartDate(startDate);\n-            config.setEndDate(endDate);\n-            config.setIncremental(incremental);\n-            config.setUser(userToRun);\n-\n-            if(include) {\n-                config.setIncludePatterns(paths);\n+            Logger.info(SiteSearchJobImpl.class, () -> String\n+                    .format(\"Incremental mode [%s]. current index is `%s`. new index is `%s`. alias is `%s`  bundle id is `%s` \",\n+                            BooleanUtils.toStringYesNo(incremental), indexName,\n+                            UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n+                            indexAlias,\n+                            bundleId)\n+            );\n+\n+            final List<Host> hosts;\n+            if (indexAll) {\n+                hosts = hostAPI.findAll(userToRun, true);\n             } else {\n-                config.setExcludePatterns(paths);\n+                hosts = Stream.of(indexHosts).map(h -> {\n+                    try {\n+                        return hostAPI.find(h, userToRun, true);\n+                    } catch (DotDataException | DotSecurityException e) {\n+                        Logger.error(SiteSearchJobImpl.class, e);\n+                    }\n+                    return null;\n+                }).filter(Objects::nonNull).collect(Collectors.toList());\n             }\n \n-            //We should always replace the index when performing on non-incremental mode.\n-            //That means we drop the old one and re-use the alias.\n-            //But we only activate the new index when the old one was the default.\n-            //Or there wasn't any previous index.\n-            //it must be done on the last round of our loop.\n-            final boolean switchIndex = !incremental && !listIterator.hasNext();\n-            config.setSwitchIndexWhenDone(switchIndex);\n-            publisherAPI.publish(config, status);\n-        }\n+            final Builder<SiteSearchConfig> builder = ImmutableList.builder();\n+\n+            final List<String> languageToIndex = Arrays\n+                    .asList((String[]) dataMap.get(LANG_TO_INDEX));\n+            final ListIterator<String> listIterator = languageToIndex.listIterator();\n+            while (listIterator.hasNext()) {\n+                final String lang = listIterator.next();\n+                final SiteSearchConfig config = new SiteSearchConfig();\n+                config.setJobId(jobId);\n+                config.setLanguage(Long.parseLong(lang));\n+                config.setJobName(jobName);\n+                config.setHosts(hosts);\n+                config.setNewIndexName(newIndexName);\n+                config.setIndexName(indexName);\n+                config.setIndexAlias(indexAlias);\n+                config.setId(bundleId);\n+                config.setStartDate(startDate);\n+                config.setEndDate(endDate);\n+                config.setIncremental(incremental);\n+                config.setUser(userToRun);\n+\n+                if (include) {\n+                    config.setIncludePatterns(paths);\n+                } else {\n+                    config.setExcludePatterns(paths);\n+                }\n \n-        int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n-        for (final BundlerStatus bs : status.getBundlerStatuses()) {\n-            if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n-                filesCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n-                urlmapCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(HTMLPageAsContentBundler.class.getName())) {\n-                pagesCount += bs.getTotal();\n+                //We should always replace the index when performing on non-incremental mode.\n+                //That means we drop the old one and re-use the alias.\n+                //But we only activate the new index when the old one was the default.\n+                //Or there wasn't any previous index.\n+                //it must be done on the last round of our loop.\n+                final boolean switchIndex = !incremental && !listIterator.hasNext();\n+                config.setSwitchIndexWhenDone(switchIndex);\n+                builder.add(config);\n             }\n+            final String joinedHosts = UtilMethods.join(indexHosts, \",\", true);\n+            final String langList = UtilMethods.join(languageToIndex, \",\");\n+            final String pathsAsString = paths.size() > 0 ? UtilMethods.join(paths, \",\") : \"/*\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934"}, "originalPosition": 371}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3Mjc5MTQy", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-377279142", "createdAt": "2020-03-18T22:26:30Z", "commit": {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQyMjoyNjozMFrOF4ZBcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQyMjoyNjozMFrOF4ZBcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY3NDU0NQ==", "bodyText": "Issue found: Useless parentheses.", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r394674545", "createdAt": "2020-03-18T22:26:30Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -128,186 +141,246 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n                         + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n \n         HibernateUtil.startTransaction();\n+        try {\n+            final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+            synchronized (preparedJobContext.lockKey()) {\n+                for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                    publisherAPI.publish(config, status);\n+                }\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+                try {\n \n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+                    int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                    for (final BundlerStatus bundlerStatus : status.getBundlerStatuses()) {\n+                        if (bundlerStatus.getBundlerClass()\n+                                .equals(FileAssetBundler.class.getName())) {\n+                            filesCount += bundlerStatus.getTotal();\n+                        } else if (bundlerStatus.getBundlerClass()\n+                                .equals(URLMapBundler.class.getName())) {\n+                            urlmapCount += bundlerStatus.getTotal();\n+                        } else if (bundlerStatus.getBundlerClass()\n+                                .equals(HTMLPageAsContentBundler.class.getName())) {\n+                            pagesCount += bundlerStatus.getTotal();\n+                        }\n+                    }\n+\n+                    final SiteSearchAudit audit = new SiteSearchAudit();\n+                    audit.setPagesCount(pagesCount);\n+                    audit.setFilesCount(filesCount);\n+                    audit.setUrlmapsCount(urlmapCount);\n+                    audit.setAllHosts(preparedJobContext.isIndexAll());\n+                    audit.setFireDate(jobContext.getFireTime());\n+                    audit.setHostList(preparedJobContext.getJoinedHosts());\n+                    audit.setIncremental(preparedJobContext.isIncremental());\n+                    audit.setStartDate(preparedJobContext.getStartDate());\n+                    audit.setEndDate(preparedJobContext.getEndDate());\n+                    audit.setIndexName(\n+                            UtilMethods.isSet(preparedJobContext.getNewIndexName())\n+                                    ? preparedJobContext\n+                                    .getNewIndexName() : preparedJobContext.getIndexName());\n+                    audit.setJobId(preparedJobContext.getJobId());\n+                    audit.setJobName(preparedJobContext.getJobName());\n+                    audit.setLangList(preparedJobContext.getLangList());\n+                    audit.setPath(preparedJobContext.getPaths());\n+                    audit.setPathInclude(preparedJobContext.isPathInclude());\n+                    siteSearchAuditAPI.save(audit);\n+\n+                } catch (DotDataException ex) {\n+                    Logger.error(this, \"can't save audit data\", ex);\n+                }\n+            }\n+        } finally {\n+            HibernateUtil.closeSession();\n         }\n+        date = DateUtil.getCurrentDate();\n+        ActivityLogger.logInfo(getClass(), \"Job Finished\",\n+                \"User: \" + userAPI.getSystemUser().getUserId() + \"; Date: \" + date\n+                        + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n+        AdminLogger.log(getClass(), \"Job Finished\",\n+                \"User: \" + userAPI.getSystemUser().getUserId() + \"; Date: \" + date\n+                        + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n+    }\n \n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n+    private PreparedJobContext prepareJob(final JobExecutionContext jobContext)\n+            throws DotDataException, IOException, DotSecurityException {\n+        synchronized (SiteSearchJobImpl.class) {\n+            final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+            String jobId = (String) dataMap.get(JOB_ID);\n+            if (jobId == null) {\n+                jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+            }\n \n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n+            final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n+            final String[] indexHosts;\n+            final Object obj =\n+                    (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n+            if (obj instanceof String) {\n+                indexHosts = new String[]{(String) obj};\n+            } else {\n+                indexHosts = (String[]) obj;\n+            }\n \n-        final User userToRun = userAPI.getSystemUser();\n+            final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n \n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n+            final User userToRun = userAPI.getSystemUser();\n \n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n-            }\n-        }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n+            final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n+                    .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n \n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n+            String path = dataMap.getString(PATHS);\n+            final List<String> paths = new ArrayList<>();\n+            if (path != null) {\n+                path = path.replace(',', '\\r');\n+                path = path.replace('\\n', '\\r');\n+                for (String x : path.split(\"\\r\")) {\n+                    if (UtilMethods.isSet(x)) {\n+                        paths.add(x);\n+                    }\n                 }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n+            }\n+            final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n+            // Run now jobs can not get the incremental treatment.\n+            final String indexAlias = dataMap.getString(INDEX_ALIAS);\n+            final IndexMetaData indexMetaData = getIndexMetaData(indexAlias);\n+            final String newIndexName;\n+            final String indexName;\n+\n+            final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n+            final Date startDate, endDate;\n+            final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n+                    : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n+\n+            final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934"}, "originalPosition": 239}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3Mjc5MTc2", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-377279176", "createdAt": "2020-03-18T22:26:31Z", "commit": {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQyMjoyNjozMVrOF4ZBeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQyMjoyNjozMVrOF4ZBeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY3NDU1Mg==", "bodyText": "Issue found: Useless parentheses.", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r394674552", "createdAt": "2020-03-18T22:26:31Z", "author": {"login": "dev-dotcms"}, "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -371,4 +444,106 @@ public boolean isEmpty() {\n         }\n     }\n \n+    static class PreparedJobContext{\n+\n+        private final String indexName;\n+        private final String newIndexName;\n+        private final boolean indexAll;\n+        private final String joinedHosts;\n+        private final boolean incremental;\n+        private final Date startDate;\n+        private final Date endDate;\n+        private final String jobId;\n+        private final String jobName;\n+        private final String langList;\n+        private final String paths;\n+        private final boolean pathInclude;\n+        private final List<SiteSearchConfig> configs;\n+\n+        PreparedJobContext(\n+                final String indexName,\n+                final String newIndexName,\n+                final boolean indexAll,\n+                final String joinedHosts,\n+                final boolean incremental,\n+                final Date startDate,\n+                final Date endDate,\n+                final String jobId,\n+                final String jobName,\n+                final String langList,\n+                final String paths,\n+                final boolean pathInclude,\n+                final List<SiteSearchConfig> configs) {\n+            this.indexName = indexName;\n+            this.newIndexName = newIndexName;\n+            this.indexAll = indexAll;\n+            this.joinedHosts = joinedHosts;\n+            this.incremental = incremental;\n+            this.startDate = startDate;\n+            this.endDate = endDate;\n+            this.jobId = jobId;\n+            this.jobName = jobName;\n+            this.langList = langList;\n+            this.configs = configs;\n+            this.pathInclude = pathInclude;\n+            this.paths = paths;\n+        }\n+\n+        String getIndexName() {\n+            return indexName;\n+        }\n+\n+        List<SiteSearchConfig> getConfigs() {\n+            return configs;\n+        }\n+\n+        String getNewIndexName() {\n+            return newIndexName;\n+        }\n+\n+        boolean isIndexAll() {\n+            return indexAll;\n+        }\n+\n+        String getJoinedHosts() {\n+            return joinedHosts;\n+        }\n+\n+        boolean isIncremental() {\n+            return incremental;\n+        }\n+\n+        Date getStartDate() {\n+            return startDate;\n+        }\n+\n+        Date getEndDate() {\n+            return endDate;\n+        }\n+\n+        String getJobId() {\n+            return jobId;\n+        }\n+\n+        String getJobName() {\n+            return jobName;\n+        }\n+\n+        String getLangList() {\n+            return langList;\n+        }\n+\n+        public String getPaths() {\n+            return paths;\n+        }\n+\n+        boolean isPathInclude() {\n+            return pathInclude;\n+        }\n+\n+        String lockKey(){\n+           return ( UtilMethods.isSet(indexName) ? indexName  : newIndexName );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934"}, "originalPosition": 546}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3Mjg1MzEy", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-377285312", "createdAt": "2020-03-18T22:37:08Z", "commit": {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3OTAyNzgx", "url": "https://github.com/dotCMS/core/pull/18141#pullrequestreview-377902781", "createdAt": "2020-03-19T16:44:25Z", "commit": {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1189, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}