{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMzNzMwODE0", "number": 1581, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTowMjo1OVrOEFF3QA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwODowNzo0MlrOEF1BBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzc0NDAwOnYy", "diffSide": "RIGHT", "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/FrameSequence.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTowMjo1OVrOGjHYdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTowNDoyNVrOGjHbxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQ3NDI5NA==", "bodyText": "I can't really figure out how length can become -1", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r439474294", "createdAt": "2020-06-12T15:02:59Z", "author": {"login": "bantonsson"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/FrameSequence.java", "diffHunk": "@@ -58,14 +61,16 @@ public FrameSequence(\n   }\n \n   public int length() {\n-    if (isEmpty()) {\n-      return 0;\n-    }\n-    if (isLeaf()) {\n-      return frameCpIndexes.length;\n+    if (length == -1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad8e34e5575184cf49b84bed02d109329320ebc"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQ3NTE0MQ==", "bodyText": "Right. Messed up rebase ...\nlength is supposed to be initialized to -1", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r439475141", "createdAt": "2020-06-12T15:04:25Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/FrameSequence.java", "diffHunk": "@@ -58,14 +61,16 @@ public FrameSequence(\n   }\n \n   public int length() {\n-    if (isEmpty()) {\n-      return 0;\n-    }\n-    if (isLeaf()) {\n-      return frameCpIndexes.length;\n+    if (length == -1) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQ3NDI5NA=="}, "originalCommit": {"oid": "8ad8e34e5575184cf49b84bed02d109329320ebc"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzkxMDI1OnYy", "diffSide": "RIGHT", "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/AbstractLEB128Writer.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTo1MTo1OVrOGjJCKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxNDo0MDowOFrOGj1Nbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwMTM1NQ==", "bodyText": "We've been caching these in various ways (constants in a poor man's constant pool, variables in an LRU cache) could you take something like a Function<String, byte[]> which intercepts this?\nI was a bit surprised that C2 isn't smart enough to eliminate these, even with compact strings.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r439501355", "createdAt": "2020-06-12T15:51:59Z", "author": {"login": "richardstartin"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/AbstractLEB128Writer.java", "diffHunk": "@@ -0,0 +1,223 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.charset.StandardCharsets;\n+\n+abstract class AbstractLEB128Writer implements LEB128Writer {\n+  @Override\n+  public final LEB128Writer writeChar(char data) {\n+    writeChar(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeChar(long offset, char data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeShort(short data) {\n+    writeShort(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeShort(long offset, short data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeInt(int data) {\n+    writeInt(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeInt(long offset, int data) {\n+    return writeLong(offset, data & 0x00000000ffffffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeLong(long data) {\n+    writeLong(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeLong(long offset, long data) {\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) (data & 0xff));\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    return writeByte(offset, (byte) (data >> 7));\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeFloat(float data) {\n+    writeFloat(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeDouble(double data) {\n+    writeDouble(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBoolean(boolean data) {\n+    writeBoolean(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeBoolean(long offset, boolean data) {\n+    return writeByte(offset, data ? (byte) 1 : (byte) 0);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeByte(byte data) {\n+    writeByte(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBytes(byte... data) {\n+    writeBytes(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeUTF(String data) {\n+    writeUTF(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeUTF(long offset, String data) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA0MjE1OQ==", "bodyText": "You mean we are having LRU cache of UTF8 byte array representation of string instances?\nIs it a global cache? Would it be able to handle the extra amount of strings coming from sampled stack traces?\nMaybe having an overloaded writeUTF(long offset, byte[] stringData) could work? And if the caller can get the byte array eg. from the cache it would call this method instead?", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440042159", "createdAt": "2020-06-15T09:20:33Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/AbstractLEB128Writer.java", "diffHunk": "@@ -0,0 +1,223 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.charset.StandardCharsets;\n+\n+abstract class AbstractLEB128Writer implements LEB128Writer {\n+  @Override\n+  public final LEB128Writer writeChar(char data) {\n+    writeChar(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeChar(long offset, char data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeShort(short data) {\n+    writeShort(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeShort(long offset, short data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeInt(int data) {\n+    writeInt(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeInt(long offset, int data) {\n+    return writeLong(offset, data & 0x00000000ffffffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeLong(long data) {\n+    writeLong(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeLong(long offset, long data) {\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) (data & 0xff));\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    return writeByte(offset, (byte) (data >> 7));\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeFloat(float data) {\n+    writeFloat(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeDouble(double data) {\n+    writeDouble(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBoolean(boolean data) {\n+    writeBoolean(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeBoolean(long offset, boolean data) {\n+    return writeByte(offset, data ? (byte) 1 : (byte) 0);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeByte(byte data) {\n+    writeByte(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBytes(byte... data) {\n+    writeBytes(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeUTF(String data) {\n+    writeUTF(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeUTF(long offset, String data) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwMTM1NQ=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA1NTcxMg==", "bodyText": "So the cache instance is local to the MsgpackFormatWriter since it's mostly for short tags, and I'm not sure of the overlap with what you are writing, but the class is here datadog.trace.core.util.LRUCache.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440055712", "createdAt": "2020-06-15T09:43:42Z", "author": {"login": "bantonsson"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/AbstractLEB128Writer.java", "diffHunk": "@@ -0,0 +1,223 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.charset.StandardCharsets;\n+\n+abstract class AbstractLEB128Writer implements LEB128Writer {\n+  @Override\n+  public final LEB128Writer writeChar(char data) {\n+    writeChar(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeChar(long offset, char data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeShort(short data) {\n+    writeShort(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeShort(long offset, short data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeInt(int data) {\n+    writeInt(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeInt(long offset, int data) {\n+    return writeLong(offset, data & 0x00000000ffffffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeLong(long data) {\n+    writeLong(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeLong(long offset, long data) {\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) (data & 0xff));\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    return writeByte(offset, (byte) (data >> 7));\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeFloat(float data) {\n+    writeFloat(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeDouble(double data) {\n+    writeDouble(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBoolean(boolean data) {\n+    writeBoolean(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeBoolean(long offset, boolean data) {\n+    return writeByte(offset, data ? (byte) 1 : (byte) 0);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeByte(byte data) {\n+    writeByte(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBytes(byte... data) {\n+    writeBytes(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeUTF(String data) {\n+    writeUTF(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeUTF(long offset, String data) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwMTM1NQ=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDIyNTEzNA==", "bodyText": "Well, I have added support for accepting a byte array of an UTF8 encoded string. It will be up to the user to decide when it is appropriate to get the data from the LRU cache.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440225134", "createdAt": "2020-06-15T14:40:08Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/AbstractLEB128Writer.java", "diffHunk": "@@ -0,0 +1,223 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.charset.StandardCharsets;\n+\n+abstract class AbstractLEB128Writer implements LEB128Writer {\n+  @Override\n+  public final LEB128Writer writeChar(char data) {\n+    writeChar(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeChar(long offset, char data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeShort(short data) {\n+    writeShort(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeShort(long offset, short data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeInt(int data) {\n+    writeInt(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeInt(long offset, int data) {\n+    return writeLong(offset, data & 0x00000000ffffffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeLong(long data) {\n+    writeLong(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeLong(long offset, long data) {\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) (data & 0xff));\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    return writeByte(offset, (byte) (data >> 7));\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeFloat(float data) {\n+    writeFloat(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeDouble(double data) {\n+    writeDouble(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBoolean(boolean data) {\n+    writeBoolean(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeBoolean(long offset, boolean data) {\n+    return writeByte(offset, data ? (byte) 1 : (byte) 0);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeByte(byte data) {\n+    writeByte(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBytes(byte... data) {\n+    writeBytes(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeUTF(String data) {\n+    writeUTF(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeUTF(long offset, String data) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwMTM1NQ=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 131}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzkxMTEzOnYy", "diffSide": "RIGHT", "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/AbstractLEB128Writer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTo1MjoxN1rOGjJCxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTo1MjoxN1rOGjJCxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwMTUwOA==", "bodyText": "ditto", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r439501508", "createdAt": "2020-06-12T15:52:17Z", "author": {"login": "richardstartin"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/AbstractLEB128Writer.java", "diffHunk": "@@ -0,0 +1,223 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.charset.StandardCharsets;\n+\n+abstract class AbstractLEB128Writer implements LEB128Writer {\n+  @Override\n+  public final LEB128Writer writeChar(char data) {\n+    writeChar(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeChar(long offset, char data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeShort(short data) {\n+    writeShort(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeShort(long offset, short data) {\n+    return writeLong(offset, data & 0x000000000000ffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeInt(int data) {\n+    writeInt(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeInt(long offset, int data) {\n+    return writeLong(offset, data & 0x00000000ffffffffL);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeLong(long data) {\n+    writeLong(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeLong(long offset, long data) {\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) (data & 0xff));\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    data >>= 7;\n+    if ((data & LEB128Writer.COMPRESSED_INT_MASK) == 0) {\n+      return writeByte(offset, (byte) data);\n+    }\n+    offset = writeByte(offset, (byte) (data | LEB128Writer.EXT_BIT));\n+    return writeByte(offset, (byte) (data >> 7));\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeFloat(float data) {\n+    writeFloat(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeDouble(double data) {\n+    writeDouble(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBoolean(boolean data) {\n+    writeBoolean(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeBoolean(long offset, boolean data) {\n+    return writeByte(offset, data ? (byte) 1 : (byte) 0);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeByte(byte data) {\n+    writeByte(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeBytes(byte... data) {\n+    writeBytes(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeUTF(String data) {\n+    writeUTF(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeUTF(long offset, String data) {\n+    byte[] bytes = data.getBytes(StandardCharsets.UTF_8);\n+    long pos = writeInt(offset, bytes.length);\n+    return writeBytes(pos, bytes);\n+  }\n+\n+  @Override\n+  public final LEB128Writer writeCompactUTF(String data) {\n+    writeCompactUTF(position(), data);\n+    return this;\n+  }\n+\n+  @Override\n+  public final long writeCompactUTF(long offset, String data) {\n+    if (data == null) {\n+      return writeByte(offset, (byte) 0); // special NULL encoding\n+    }\n+    if (data.isEmpty()) {\n+      return writeByte(offset, (byte) 1); // special empty string encoding\n+    }\n+    long pos = writeByte(offset, (byte) 3); // UTF-8 string\n+    byte[] out = data.getBytes(StandardCharsets.UTF_8);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzkxNTk1OnYy", "diffSide": "RIGHT", "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteArrayWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTo1Mzo1MVrOGjJGBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQwODo0NzowNFrOGjo0yA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwMjM0MQ==", "bodyText": "I really think that using a byte[] instead of a ByteBuffer on JDK11 will leave a lot on the table when writing wide integer types (there's no difference if you benchmark on JDK8).", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r439502341", "createdAt": "2020-06-12T15:53:51Z", "author": {"login": "richardstartin"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteArrayWriter.java", "diffHunk": "@@ -1,167 +1,34 @@\n package com.datadog.mlt.io;\n \n-import java.nio.charset.StandardCharsets;\n import java.util.Arrays;\n \n /** Byte-array writer with default support for LEB128 encoded integer types */\n-final class LEB128ByteArrayWriter {\n-  private static final int EXT_BIT = 0x80;\n-  private static final long COMPRESSED_INT_MASK = -EXT_BIT;\n+final class LEB128ByteArrayWriter extends AbstractLEB128Writer {\n   private byte[] array;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAyMjIxNg==", "bodyText": "This is just a fall-back implementation and I expect it to get removed once we are happy with the ByteBuffer based one.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440022216", "createdAt": "2020-06-15T08:47:04Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteArrayWriter.java", "diffHunk": "@@ -1,167 +1,34 @@\n package com.datadog.mlt.io;\n \n-import java.nio.charset.StandardCharsets;\n import java.util.Arrays;\n \n /** Byte-array writer with default support for LEB128 encoded integer types */\n-final class LEB128ByteArrayWriter {\n-  private static final int EXT_BIT = 0x80;\n-  private static final long COMPRESSED_INT_MASK = -EXT_BIT;\n+final class LEB128ByteArrayWriter extends AbstractLEB128Writer {\n   private byte[] array;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwMjM0MQ=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzkyMDk3OnYy", "diffSide": "RIGHT", "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteBufferWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTo1NToyMFrOGjJJNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTo1NToyMFrOGjJJNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwMzE1Ng==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r439503156", "createdAt": "2020-06-12T15:55:20Z", "author": {"login": "richardstartin"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteBufferWriter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.ByteBuffer;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+final class LEB128ByteBufferWriter extends AbstractLEB128Writer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzkyNjQ4OnYy", "diffSide": "RIGHT", "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteBufferWriter.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTo1Njo1M1rOGjJMqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxNjowMjozN1rOGj4w7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDA0MA==", "bodyText": "Have you tried using on heap buffers? This is slow, so should probably be pooled if you need direct memory, and makes the copy slower too.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r439504040", "createdAt": "2020-06-12T15:56:53Z", "author": {"login": "richardstartin"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteBufferWriter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.ByteBuffer;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+final class LEB128ByteBufferWriter extends AbstractLEB128Writer {\n+  private ByteBuffer buffer;\n+\n+  LEB128ByteBufferWriter(int initialCapacity) {\n+    this.buffer = ByteBuffer.allocateDirect(initialCapacity);\n+  }\n+\n+  @Override\n+  public void reset() {\n+    buffer.clear();\n+  }\n+\n+  @Override\n+  public long writeFloat(long offset, float data) {\n+    ensureCapacity((int) offset, 4);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putFloat(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeDouble(long offset, double data) {\n+    ensureCapacity((int) offset, 8);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putDouble(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeByte(long offset, byte data) {\n+    ensureCapacity((int) offset, 1);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.put(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeBytes(long offset, byte... data) {\n+    ensureCapacity((int) offset, data.length);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.put(data, 0, data.length);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeShortRaw(long offset, short data) {\n+    ensureCapacity((int) offset, 2);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putShort(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeIntRaw(long offset, int data) {\n+    ensureCapacity((int) offset, 4);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putInt(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeLongRaw(long offset, long data) {\n+    ensureCapacity((int) offset, 8);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putLong(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public byte[] toByteArray() {\n+    buffer.flip();\n+    byte[] data = new byte[buffer.remaining()];\n+    buffer.get(data, 0, data.length);\n+    return data;\n+  }\n+\n+  @Override\n+  public int position() {\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public int capacity() {\n+    return buffer.capacity();\n+  }\n+\n+  private void ensureCapacity(int offset, int dataLength) {\n+    if (offset + dataLength > buffer.capacity()) {\n+      int newCapacity = buffer.capacity() * 2;\n+      log.warn(\n+          \"{} capacity ({} bytes) exceeded. Reallocating internal buffer with new capacity {} bytes\",\n+          this.getClass().getName(),\n+          buffer.capacity(),\n+          newCapacity);\n+      ByteBuffer newBuffer = ByteBuffer.allocateDirect(newCapacity);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAzODQ4NQ==", "bodyText": "The ByteBuffer instance is cached at the writer instance level - eg. it can be reused many times.\nMaybe on-heap buffers would be good enough? Since the data is never shared with native code it should not make any difference (except of increasing the heap reqs)", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440038485", "createdAt": "2020-06-15T09:14:22Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteBufferWriter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.ByteBuffer;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+final class LEB128ByteBufferWriter extends AbstractLEB128Writer {\n+  private ByteBuffer buffer;\n+\n+  LEB128ByteBufferWriter(int initialCapacity) {\n+    this.buffer = ByteBuffer.allocateDirect(initialCapacity);\n+  }\n+\n+  @Override\n+  public void reset() {\n+    buffer.clear();\n+  }\n+\n+  @Override\n+  public long writeFloat(long offset, float data) {\n+    ensureCapacity((int) offset, 4);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putFloat(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeDouble(long offset, double data) {\n+    ensureCapacity((int) offset, 8);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putDouble(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeByte(long offset, byte data) {\n+    ensureCapacity((int) offset, 1);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.put(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeBytes(long offset, byte... data) {\n+    ensureCapacity((int) offset, data.length);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.put(data, 0, data.length);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeShortRaw(long offset, short data) {\n+    ensureCapacity((int) offset, 2);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putShort(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeIntRaw(long offset, int data) {\n+    ensureCapacity((int) offset, 4);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putInt(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeLongRaw(long offset, long data) {\n+    ensureCapacity((int) offset, 8);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putLong(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public byte[] toByteArray() {\n+    buffer.flip();\n+    byte[] data = new byte[buffer.remaining()];\n+    buffer.get(data, 0, data.length);\n+    return data;\n+  }\n+\n+  @Override\n+  public int position() {\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public int capacity() {\n+    return buffer.capacity();\n+  }\n+\n+  private void ensureCapacity(int offset, int dataLength) {\n+    if (offset + dataLength > buffer.capacity()) {\n+      int newCapacity = buffer.capacity() * 2;\n+      log.warn(\n+          \"{} capacity ({} bytes) exceeded. Reallocating internal buffer with new capacity {} bytes\",\n+          this.getClass().getName(),\n+          buffer.capacity(),\n+          newCapacity);\n+      ByteBuffer newBuffer = ByteBuffer.allocateDirect(newCapacity);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDA0MA=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDIxOTc1NQ==", "bodyText": "I have factored out the code allocating the buffer so we can play with both modes.\nIn my naive local 'benchmarks' the only effect I can reliably see is more allocations happening for the on-heap buffers (of course). The allocations/deallocations are infrequent enough not to have any visible effect ...", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440219755", "createdAt": "2020-06-15T14:32:44Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteBufferWriter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.ByteBuffer;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+final class LEB128ByteBufferWriter extends AbstractLEB128Writer {\n+  private ByteBuffer buffer;\n+\n+  LEB128ByteBufferWriter(int initialCapacity) {\n+    this.buffer = ByteBuffer.allocateDirect(initialCapacity);\n+  }\n+\n+  @Override\n+  public void reset() {\n+    buffer.clear();\n+  }\n+\n+  @Override\n+  public long writeFloat(long offset, float data) {\n+    ensureCapacity((int) offset, 4);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putFloat(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeDouble(long offset, double data) {\n+    ensureCapacity((int) offset, 8);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putDouble(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeByte(long offset, byte data) {\n+    ensureCapacity((int) offset, 1);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.put(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeBytes(long offset, byte... data) {\n+    ensureCapacity((int) offset, data.length);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.put(data, 0, data.length);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeShortRaw(long offset, short data) {\n+    ensureCapacity((int) offset, 2);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putShort(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeIntRaw(long offset, int data) {\n+    ensureCapacity((int) offset, 4);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putInt(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeLongRaw(long offset, long data) {\n+    ensureCapacity((int) offset, 8);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putLong(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public byte[] toByteArray() {\n+    buffer.flip();\n+    byte[] data = new byte[buffer.remaining()];\n+    buffer.get(data, 0, data.length);\n+    return data;\n+  }\n+\n+  @Override\n+  public int position() {\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public int capacity() {\n+    return buffer.capacity();\n+  }\n+\n+  private void ensureCapacity(int offset, int dataLength) {\n+    if (offset + dataLength > buffer.capacity()) {\n+      int newCapacity = buffer.capacity() * 2;\n+      log.warn(\n+          \"{} capacity ({} bytes) exceeded. Reallocating internal buffer with new capacity {} bytes\",\n+          this.getClass().getName(),\n+          buffer.capacity(),\n+          newCapacity);\n+      ByteBuffer newBuffer = ByteBuffer.allocateDirect(newCapacity);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDA0MA=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDI4MzM3Mw==", "bodyText": "looks good", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440283373", "createdAt": "2020-06-15T16:02:37Z", "author": {"login": "richardstartin"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128ByteBufferWriter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+package com.datadog.mlt.io;\n+\n+import java.nio.ByteBuffer;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+final class LEB128ByteBufferWriter extends AbstractLEB128Writer {\n+  private ByteBuffer buffer;\n+\n+  LEB128ByteBufferWriter(int initialCapacity) {\n+    this.buffer = ByteBuffer.allocateDirect(initialCapacity);\n+  }\n+\n+  @Override\n+  public void reset() {\n+    buffer.clear();\n+  }\n+\n+  @Override\n+  public long writeFloat(long offset, float data) {\n+    ensureCapacity((int) offset, 4);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putFloat(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeDouble(long offset, double data) {\n+    ensureCapacity((int) offset, 8);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putDouble(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeByte(long offset, byte data) {\n+    ensureCapacity((int) offset, 1);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.put(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeBytes(long offset, byte... data) {\n+    ensureCapacity((int) offset, data.length);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.put(data, 0, data.length);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeShortRaw(long offset, short data) {\n+    ensureCapacity((int) offset, 2);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putShort(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeIntRaw(long offset, int data) {\n+    ensureCapacity((int) offset, 4);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putInt(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public long writeLongRaw(long offset, long data) {\n+    ensureCapacity((int) offset, 8);\n+    int originalPosition = buffer.position();\n+    buffer.position((int) offset);\n+    buffer.putLong(data);\n+    if (originalPosition > buffer.position()) {\n+      buffer.position(originalPosition);\n+    }\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public byte[] toByteArray() {\n+    buffer.flip();\n+    byte[] data = new byte[buffer.remaining()];\n+    buffer.get(data, 0, data.length);\n+    return data;\n+  }\n+\n+  @Override\n+  public int position() {\n+    return buffer.position();\n+  }\n+\n+  @Override\n+  public int capacity() {\n+    return buffer.capacity();\n+  }\n+\n+  private void ensureCapacity(int offset, int dataLength) {\n+    if (offset + dataLength > buffer.capacity()) {\n+      int newCapacity = buffer.capacity() * 2;\n+      log.warn(\n+          \"{} capacity ({} bytes) exceeded. Reallocating internal buffer with new capacity {} bytes\",\n+          this.getClass().getName(),\n+          buffer.capacity(),\n+          newCapacity);\n+      ByteBuffer newBuffer = ByteBuffer.allocateDirect(newCapacity);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDA0MA=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 129}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNzkzMDYzOnYy", "diffSide": "RIGHT", "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/MLTWriter.java", "isResolved": false, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNTo1ODoxNFrOGjJPQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxODowNDoxNlrOGj9A6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDcwNg==", "bodyText": "Have you considered not releasing a new byte[] and taking a Consumer<byte[] which must synchronously consume the data?", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r439504706", "createdAt": "2020-06-12T15:58:14Z", "author": {"login": "richardstartin"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/MLTWriter.java", "diffHunk": "@@ -4,38 +4,29 @@\n import it.unimi.dsi.fastutil.ints.IntSet;\n import java.nio.charset.StandardCharsets;\n import java.util.function.IntConsumer;\n-import java.util.stream.Stream;\n-import lombok.Generated;\n \n /** The MLT binary format writer */\n public final class MLTWriter {\n+  private static final int CHUNK_WRITER_CAPACITY = 512 * 1024; // initial 512kB for chunk writer\n+  private static final int FRAME_STACK_WRITER_CAPACITY =\n+      256 * 1024; // initial 256kB for frame stack writer\n+  private final LEB128Writer chunkWriter = LEB128Writer.getInstance(CHUNK_WRITER_CAPACITY);\n+  private final LEB128Writer frameStackDataWriter =\n+      LEB128Writer.getInstance(FRAME_STACK_WRITER_CAPACITY);\n   /**\n    * Write a single chunk to its binary format\n    *\n    * @param chunk the chunk\n    * @return chunk in its MLT binary format\n    */\n   public byte[] writeChunk(IMLTChunk chunk) {\n-    LEB128ByteArrayWriter writer =\n-        new LEB128ByteArrayWriter(16384); // conservatively pre-allocate 16k byte array\n-    writeChunk(chunk, writer);\n-    return writer.toByteArray();\n+    writeChunk(chunk, chunkWriter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAyNDEwMA==", "bodyText": "Would this help? The byte[] instance would still be escaping the writeChunk(chunk) method, right?", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440024100", "createdAt": "2020-06-15T08:50:18Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/MLTWriter.java", "diffHunk": "@@ -4,38 +4,29 @@\n import it.unimi.dsi.fastutil.ints.IntSet;\n import java.nio.charset.StandardCharsets;\n import java.util.function.IntConsumer;\n-import java.util.stream.Stream;\n-import lombok.Generated;\n \n /** The MLT binary format writer */\n public final class MLTWriter {\n+  private static final int CHUNK_WRITER_CAPACITY = 512 * 1024; // initial 512kB for chunk writer\n+  private static final int FRAME_STACK_WRITER_CAPACITY =\n+      256 * 1024; // initial 256kB for frame stack writer\n+  private final LEB128Writer chunkWriter = LEB128Writer.getInstance(CHUNK_WRITER_CAPACITY);\n+  private final LEB128Writer frameStackDataWriter =\n+      LEB128Writer.getInstance(FRAME_STACK_WRITER_CAPACITY);\n   /**\n    * Write a single chunk to its binary format\n    *\n    * @param chunk the chunk\n    * @return chunk in its MLT binary format\n    */\n   public byte[] writeChunk(IMLTChunk chunk) {\n-    LEB128ByteArrayWriter writer =\n-        new LEB128ByteArrayWriter(16384); // conservatively pre-allocate 16k byte array\n-    writeChunk(chunk, writer);\n-    return writer.toByteArray();\n+    writeChunk(chunk, chunkWriter);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDcwNg=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAzNTE5NA==", "bodyText": "I think the idea was to change the signature to be public void writeChunk(IMLTChunk chunk, Consumer consumer) and just hand out the underlying byte[], and the length of the written bytes instead of a copy of the byte[].", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440035194", "createdAt": "2020-06-15T09:08:44Z", "author": {"login": "bantonsson"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/MLTWriter.java", "diffHunk": "@@ -4,38 +4,29 @@\n import it.unimi.dsi.fastutil.ints.IntSet;\n import java.nio.charset.StandardCharsets;\n import java.util.function.IntConsumer;\n-import java.util.stream.Stream;\n-import lombok.Generated;\n \n /** The MLT binary format writer */\n public final class MLTWriter {\n+  private static final int CHUNK_WRITER_CAPACITY = 512 * 1024; // initial 512kB for chunk writer\n+  private static final int FRAME_STACK_WRITER_CAPACITY =\n+      256 * 1024; // initial 256kB for frame stack writer\n+  private final LEB128Writer chunkWriter = LEB128Writer.getInstance(CHUNK_WRITER_CAPACITY);\n+  private final LEB128Writer frameStackDataWriter =\n+      LEB128Writer.getInstance(FRAME_STACK_WRITER_CAPACITY);\n   /**\n    * Write a single chunk to its binary format\n    *\n    * @param chunk the chunk\n    * @return chunk in its MLT binary format\n    */\n   public byte[] writeChunk(IMLTChunk chunk) {\n-    LEB128ByteArrayWriter writer =\n-        new LEB128ByteArrayWriter(16384); // conservatively pre-allocate 16k byte array\n-    writeChunk(chunk, writer);\n-    return writer.toByteArray();\n+    writeChunk(chunk, chunkWriter);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDcwNg=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA0MzIxOQ==", "bodyText": "IC. Yes, that's a good idea.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440043219", "createdAt": "2020-06-15T09:22:09Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/MLTWriter.java", "diffHunk": "@@ -4,38 +4,29 @@\n import it.unimi.dsi.fastutil.ints.IntSet;\n import java.nio.charset.StandardCharsets;\n import java.util.function.IntConsumer;\n-import java.util.stream.Stream;\n-import lombok.Generated;\n \n /** The MLT binary format writer */\n public final class MLTWriter {\n+  private static final int CHUNK_WRITER_CAPACITY = 512 * 1024; // initial 512kB for chunk writer\n+  private static final int FRAME_STACK_WRITER_CAPACITY =\n+      256 * 1024; // initial 256kB for frame stack writer\n+  private final LEB128Writer chunkWriter = LEB128Writer.getInstance(CHUNK_WRITER_CAPACITY);\n+  private final LEB128Writer frameStackDataWriter =\n+      LEB128Writer.getInstance(FRAME_STACK_WRITER_CAPACITY);\n   /**\n    * Write a single chunk to its binary format\n    *\n    * @param chunk the chunk\n    * @return chunk in its MLT binary format\n    */\n   public byte[] writeChunk(IMLTChunk chunk) {\n-    LEB128ByteArrayWriter writer =\n-        new LEB128ByteArrayWriter(16384); // conservatively pre-allocate 16k byte array\n-    writeChunk(chunk, writer);\n-    return writer.toByteArray();\n+    writeChunk(chunk, chunkWriter);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDcwNg=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDExNjIwMw==", "bodyText": "Well ... this assumes an on-heap buffer since direct buffers have no underlying array.\nSo I will change also the buffer allocation from direct to on-heap.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440116203", "createdAt": "2020-06-15T11:42:35Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/MLTWriter.java", "diffHunk": "@@ -4,38 +4,29 @@\n import it.unimi.dsi.fastutil.ints.IntSet;\n import java.nio.charset.StandardCharsets;\n import java.util.function.IntConsumer;\n-import java.util.stream.Stream;\n-import lombok.Generated;\n \n /** The MLT binary format writer */\n public final class MLTWriter {\n+  private static final int CHUNK_WRITER_CAPACITY = 512 * 1024; // initial 512kB for chunk writer\n+  private static final int FRAME_STACK_WRITER_CAPACITY =\n+      256 * 1024; // initial 256kB for frame stack writer\n+  private final LEB128Writer chunkWriter = LEB128Writer.getInstance(CHUNK_WRITER_CAPACITY);\n+  private final LEB128Writer frameStackDataWriter =\n+      LEB128Writer.getInstance(FRAME_STACK_WRITER_CAPACITY);\n   /**\n    * Write a single chunk to its binary format\n    *\n    * @param chunk the chunk\n    * @return chunk in its MLT binary format\n    */\n   public byte[] writeChunk(IMLTChunk chunk) {\n-    LEB128ByteArrayWriter writer =\n-        new LEB128ByteArrayWriter(16384); // conservatively pre-allocate 16k byte array\n-    writeChunk(chunk, writer);\n-    return writer.toByteArray();\n+    writeChunk(chunk, chunkWriter);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDcwNg=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDIxNzY3MA==", "bodyText": "Ok, I have added support for exporting the writer data via a callback which will get passed in a ByteBuffer instance. Not sure if this will help anything at the end since we will need to materialize the byte array at the end before base64 encoding it anyway - unless we can not use Java 8 Base64 class which can accept directly ByteBuffer.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440217670", "createdAt": "2020-06-15T14:29:57Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/MLTWriter.java", "diffHunk": "@@ -4,38 +4,29 @@\n import it.unimi.dsi.fastutil.ints.IntSet;\n import java.nio.charset.StandardCharsets;\n import java.util.function.IntConsumer;\n-import java.util.stream.Stream;\n-import lombok.Generated;\n \n /** The MLT binary format writer */\n public final class MLTWriter {\n+  private static final int CHUNK_WRITER_CAPACITY = 512 * 1024; // initial 512kB for chunk writer\n+  private static final int FRAME_STACK_WRITER_CAPACITY =\n+      256 * 1024; // initial 256kB for frame stack writer\n+  private final LEB128Writer chunkWriter = LEB128Writer.getInstance(CHUNK_WRITER_CAPACITY);\n+  private final LEB128Writer frameStackDataWriter =\n+      LEB128Writer.getInstance(FRAME_STACK_WRITER_CAPACITY);\n   /**\n    * Write a single chunk to its binary format\n    *\n    * @param chunk the chunk\n    * @return chunk in its MLT binary format\n    */\n   public byte[] writeChunk(IMLTChunk chunk) {\n-    LEB128ByteArrayWriter writer =\n-        new LEB128ByteArrayWriter(16384); // conservatively pre-allocate 16k byte array\n-    writeChunk(chunk, writer);\n-    return writer.toByteArray();\n+    writeChunk(chunk, chunkWriter);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDcwNg=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDI4NTI0OA==", "bodyText": "Yes that's why I said it must be synchronous. I.e. the contract is: the consumer gets access to your data until they return, which can avoid a copy. If they need the data after returning and don't copy it, that's their problem. If the consumer were outside the scope of this codebase, it would be unacceptable, but we can police it with review, and it should avoid allocating lots of arrays. I am inclined to lean away from direct memory.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440285248", "createdAt": "2020-06-15T16:05:39Z", "author": {"login": "richardstartin"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/MLTWriter.java", "diffHunk": "@@ -4,38 +4,29 @@\n import it.unimi.dsi.fastutil.ints.IntSet;\n import java.nio.charset.StandardCharsets;\n import java.util.function.IntConsumer;\n-import java.util.stream.Stream;\n-import lombok.Generated;\n \n /** The MLT binary format writer */\n public final class MLTWriter {\n+  private static final int CHUNK_WRITER_CAPACITY = 512 * 1024; // initial 512kB for chunk writer\n+  private static final int FRAME_STACK_WRITER_CAPACITY =\n+      256 * 1024; // initial 256kB for frame stack writer\n+  private final LEB128Writer chunkWriter = LEB128Writer.getInstance(CHUNK_WRITER_CAPACITY);\n+  private final LEB128Writer frameStackDataWriter =\n+      LEB128Writer.getInstance(FRAME_STACK_WRITER_CAPACITY);\n   /**\n    * Write a single chunk to its binary format\n    *\n    * @param chunk the chunk\n    * @return chunk in its MLT binary format\n    */\n   public byte[] writeChunk(IMLTChunk chunk) {\n-    LEB128ByteArrayWriter writer =\n-        new LEB128ByteArrayWriter(16384); // conservatively pre-allocate 16k byte array\n-    writeChunk(chunk, writer);\n-    return writer.toByteArray();\n+    writeChunk(chunk, chunkWriter);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDcwNg=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDM1MzAwMQ==", "bodyText": "\ud83d\udc4d\nSupport is there - now we only have to make sure the clients will do the right thing.", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440353001", "createdAt": "2020-06-15T18:04:16Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/MLTWriter.java", "diffHunk": "@@ -4,38 +4,29 @@\n import it.unimi.dsi.fastutil.ints.IntSet;\n import java.nio.charset.StandardCharsets;\n import java.util.function.IntConsumer;\n-import java.util.stream.Stream;\n-import lombok.Generated;\n \n /** The MLT binary format writer */\n public final class MLTWriter {\n+  private static final int CHUNK_WRITER_CAPACITY = 512 * 1024; // initial 512kB for chunk writer\n+  private static final int FRAME_STACK_WRITER_CAPACITY =\n+      256 * 1024; // initial 256kB for frame stack writer\n+  private final LEB128Writer chunkWriter = LEB128Writer.getInstance(CHUNK_WRITER_CAPACITY);\n+  private final LEB128Writer frameStackDataWriter =\n+      LEB128Writer.getInstance(FRAME_STACK_WRITER_CAPACITY);\n   /**\n    * Write a single chunk to its binary format\n    *\n    * @param chunk the chunk\n    * @return chunk in its MLT binary format\n    */\n   public byte[] writeChunk(IMLTChunk chunk) {\n-    LEB128ByteArrayWriter writer =\n-        new LEB128ByteArrayWriter(16384); // conservatively pre-allocate 16k byte array\n-    writeChunk(chunk, writer);\n-    return writer.toByteArray();\n+    writeChunk(chunk, chunkWriter);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUwNDcwNg=="}, "originalCommit": {"oid": "1f30019655279f3c5e37498ede5d7a68fa7be6c0"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NTQ2OTQ4OnYy", "diffSide": "RIGHT", "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128Writer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwODowNzo0MlrOGkQAlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwODoxMzoyNlrOGkQNdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDY2NDIxMg==", "bodyText": "So this is the way to work around the final requirement for the lambda. It makes everything so much more readable \ud83d\ude09", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440664212", "createdAt": "2020-06-16T08:07:42Z", "author": {"login": "bantonsson"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128Writer.java", "diffHunk": "@@ -269,7 +314,34 @@ static LEB128Writer getInstance(int initialCapacity) {\n    *\n    * @return byte array containing the written data\n    */\n-  byte[] toByteArray();\n+  default byte[] export() {\n+    final byte[][] dataRef = new byte[1][];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b7aad513231cf8cab0b8ad34e398500e0d8253f"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDY2NzUxMA==", "bodyText": "Yeah. You can choose your poison - either unnecessary AtomicReference or this abomination :(", "url": "https://github.com/DataDog/dd-trace-java/pull/1581#discussion_r440667510", "createdAt": "2020-06-16T08:13:26Z", "author": {"login": "jbachorik"}, "path": "utils/mlt-support/src/main/java/com/datadog/mlt/io/LEB128Writer.java", "diffHunk": "@@ -269,7 +314,34 @@ static LEB128Writer getInstance(int initialCapacity) {\n    *\n    * @return byte array containing the written data\n    */\n-  byte[] toByteArray();\n+  default byte[] export() {\n+    final byte[][] dataRef = new byte[1][];", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDY2NDIxMg=="}, "originalCommit": {"oid": "0b7aad513231cf8cab0b8ad34e398500e0d8253f"}, "originalPosition": 112}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 58, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}