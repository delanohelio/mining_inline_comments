{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3MjY2MDU2", "number": 1454, "reviewThreads": {"totalCount": 28, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxMzozNzowOFrOD8EcWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNjozMDoyOVrOD9eCPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MzEzOTQ3OnYy", "diffSide": "LEFT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/AbstractDisruptor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxMzozNzowOFrOGUx95g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxMzozNzowOFrOGUx95g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDQ0MzM2Ng==", "bodyText": "Yes, I'm in agreement with removing this.  Even prior to this change, I was little concerned that it was creating some unnecessary complexity.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r424443366", "createdAt": "2020-05-13T13:37:08Z", "author": {"login": "dougqh"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/AbstractDisruptor.java", "diffHunk": "@@ -1,96 +0,0 @@\n-package datadog.trace.common.writer.ddagent;\n-\n-import com.lmax.disruptor.EventHandler;\n-import com.lmax.disruptor.SleepingWaitStrategy;\n-import com.lmax.disruptor.dsl.Disruptor;\n-import com.lmax.disruptor.dsl.ProducerType;\n-import datadog.common.exec.DaemonThreadFactory;\n-import java.io.Closeable;\n-import java.util.concurrent.CountDownLatch;\n-import java.util.concurrent.TimeUnit;\n-import lombok.extern.slf4j.Slf4j;\n-\n-@Slf4j\n-abstract class AbstractDisruptor<T> implements Closeable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21cf41bfa85f5e807c696972dd41e702ff0a865b"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0NzMzMzk0OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMzowNjoyM1rOGVbUQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMzoxOTo0OFrOGVb3Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEyMDgzMw==", "bodyText": "This spams the logs quite a bit \ud83d\ude09", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425120833", "createdAt": "2020-05-14T13:06:23Z", "author": {"login": "bantonsson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -75,83 +73,81 @@ public void addResponseListener(final DDAgentResponseListener listener) {\n     }\n   }\n \n-  Response sendSerializedTraces(\n-      final int representativeCount,\n-      final int traceCount,\n-      final int sizeInBytes,\n-      final List<TraceBuffer> traces) {\n+  Response sendSerializedTraces(final TraceBuffer traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n+              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")\n+              .put(new MsgPackRequestBody(traces))\n               .build();\n-\n       try (final okhttp3.Response response = httpClient.newCall(request).execute()) {\n         if (response.code() != 200) {\n           if (log.isDebugEnabled()) {\n             log.debug(\n                 \"Error while sending {} of {} traces to the DD agent. Status: {}, Response: {}, Body: {}\",\n-                traces.size(),\n-                representativeCount,\n+                traces.traceCount(),\n+                traces.representativeCount(),\n                 response.code(),\n                 response.message(),\n                 response.body().string());\n           } else if (nextAllowedLogTime < System.currentTimeMillis()) {\n             nextAllowedLogTime = System.currentTimeMillis() + MILLISECONDS_BETWEEN_ERROR_LOG;\n             log.warn(\n                 \"Error while sending {} of {} traces to the DD agent. Status: {} {} (going silent for {} minutes)\",\n-                traces.size(),\n-                representativeCount,\n+                traces.traceCount(),\n+                traces.representativeCount(),\n                 response.code(),\n                 response.message(),\n                 TimeUnit.MILLISECONDS.toMinutes(MILLISECONDS_BETWEEN_ERROR_LOG));\n           }\n           return Response.failed(response.code());\n         }\n-\n-        log.debug(\n-            \"Successfully sent {} of {} traces to the DD agent.\",\n-            traces.size(),\n-            representativeCount);\n-\n+        if (log.isDebugEnabled()) {\n+          log.debug(\n+              \"Successfully sent {} of {} traces to the DD agent.\",\n+              traces.traceCount(),\n+              traces.representativeCount());\n+        }\n         final String responseString = response.body().string().trim();\n         try {\n           if (!\"\".equals(responseString) && !\"OK\".equalsIgnoreCase(responseString)) {\n             final Map<String, Map<String, Number>> parsedResponse =\n                 RESPONSE_ADAPTER.fromJson(responseString);\n             final String endpoint = tracesUrl.toString();\n-\n             for (final DDAgentResponseListener listener : responseListeners) {\n               listener.onResponse(endpoint, parsedResponse);\n             }\n           }\n           return Response.success(response.code());\n         } catch (final IOException e) {\n           log.debug(\"Failed to parse DD agent response: \" + responseString, e);\n-\n           return Response.success(response.code(), e);\n         }\n       }\n     } catch (final IOException e) {\n       if (log.isDebugEnabled()) {\n         log.debug(\n             \"Error while sending \"\n-                + traces.size()\n+                + traces.traceCount()\n                 + \" of \"\n-                + representativeCount\n+                + traces.representativeCount()\n+                + \" (size=\"\n+                + (traces.sizeInBytes() / 1024)\n+                + \"KB)\"\n                 + \" traces to the DD agent.\",\n             e);\n-      } else if (nextAllowedLogTime < System.currentTimeMillis()) {\n+      } else { // if (nextAllowedLogTime < System.currentTimeMillis()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1051e41a075afdce72325392773d697fd95a44de"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEyOTc4Mw==", "bodyText": "Good catch, that was for debugging purposes.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425129783", "createdAt": "2020-05-14T13:19:48Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -75,83 +73,81 @@ public void addResponseListener(final DDAgentResponseListener listener) {\n     }\n   }\n \n-  Response sendSerializedTraces(\n-      final int representativeCount,\n-      final int traceCount,\n-      final int sizeInBytes,\n-      final List<TraceBuffer> traces) {\n+  Response sendSerializedTraces(final TraceBuffer traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n+              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")\n+              .put(new MsgPackRequestBody(traces))\n               .build();\n-\n       try (final okhttp3.Response response = httpClient.newCall(request).execute()) {\n         if (response.code() != 200) {\n           if (log.isDebugEnabled()) {\n             log.debug(\n                 \"Error while sending {} of {} traces to the DD agent. Status: {}, Response: {}, Body: {}\",\n-                traces.size(),\n-                representativeCount,\n+                traces.traceCount(),\n+                traces.representativeCount(),\n                 response.code(),\n                 response.message(),\n                 response.body().string());\n           } else if (nextAllowedLogTime < System.currentTimeMillis()) {\n             nextAllowedLogTime = System.currentTimeMillis() + MILLISECONDS_BETWEEN_ERROR_LOG;\n             log.warn(\n                 \"Error while sending {} of {} traces to the DD agent. Status: {} {} (going silent for {} minutes)\",\n-                traces.size(),\n-                representativeCount,\n+                traces.traceCount(),\n+                traces.representativeCount(),\n                 response.code(),\n                 response.message(),\n                 TimeUnit.MILLISECONDS.toMinutes(MILLISECONDS_BETWEEN_ERROR_LOG));\n           }\n           return Response.failed(response.code());\n         }\n-\n-        log.debug(\n-            \"Successfully sent {} of {} traces to the DD agent.\",\n-            traces.size(),\n-            representativeCount);\n-\n+        if (log.isDebugEnabled()) {\n+          log.debug(\n+              \"Successfully sent {} of {} traces to the DD agent.\",\n+              traces.traceCount(),\n+              traces.representativeCount());\n+        }\n         final String responseString = response.body().string().trim();\n         try {\n           if (!\"\".equals(responseString) && !\"OK\".equalsIgnoreCase(responseString)) {\n             final Map<String, Map<String, Number>> parsedResponse =\n                 RESPONSE_ADAPTER.fromJson(responseString);\n             final String endpoint = tracesUrl.toString();\n-\n             for (final DDAgentResponseListener listener : responseListeners) {\n               listener.onResponse(endpoint, parsedResponse);\n             }\n           }\n           return Response.success(response.code());\n         } catch (final IOException e) {\n           log.debug(\"Failed to parse DD agent response: \" + responseString, e);\n-\n           return Response.success(response.code(), e);\n         }\n       }\n     } catch (final IOException e) {\n       if (log.isDebugEnabled()) {\n         log.debug(\n             \"Error while sending \"\n-                + traces.size()\n+                + traces.traceCount()\n                 + \" of \"\n-                + representativeCount\n+                + traces.representativeCount()\n+                + \" (size=\"\n+                + (traces.sizeInBytes() / 1024)\n+                + \"KB)\"\n                 + \" traces to the DD agent.\",\n             e);\n-      } else if (nextAllowedLogTime < System.currentTimeMillis()) {\n+      } else { // if (nextAllowedLogTime < System.currentTimeMillis()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEyMDgzMw=="}, "originalCommit": {"oid": "1051e41a075afdce72325392773d697fd95a44de"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MTc0NzY0OnYy", "diffSide": "RIGHT", "path": ".palantir/revapi.yml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNDoxNzo0OFrOGWGy8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxODowNTo1MFrOGWO2Sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTgzMzIwMw==", "bodyText": "I have never used Palantir, so I'll ignore this part for now. Would be good with a quick walkthrough.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425833203", "createdAt": "2020-05-15T14:17:48Z", "author": {"login": "bantonsson"}, "path": ".palantir/revapi.yml", "diffHunk": "@@ -134,8 +133,35 @@ acceptedBreaks:\n     - code: \"java.class.removed\"\n       old: \"interface datadog.opentracing.scopemanager.ScopeContext\"\n       justification: \"Non-api class moved to core\"\n-    # End: Classes moved to core\n-    # Begin: LogHandler method changes\n+    - code: \"java.field.removed\"\n+      old: \"field datadog.opentracing.DDTracer.TRACE_ID_MAX\"\n+      justification: \"Internal field\"\n+    - code: \"java.field.removed\"\n+      old: \"field datadog.opentracing.DDTracer.TRACE_ID_MIN\"\n+      justification: \"Internal field\"\n+    - code: \"java.method.exception.checkedAdded\"\n+      old: \"method void datadog.opentracing.DDTracer::finalize()\"\n+      new: \"method void java.lang.Object::finalize() throws java.lang.Throwable @\\\n+        \\ datadog.opentracing.DDTracer\"\n+      justification: \"finalize only needed on CoreTracer\"\n+    - code: \"java.method.movedToSuperClass\"\n+      old: \"method void datadog.opentracing.DDTracer::finalize()\"\n+      new: \"method void java.lang.Object::finalize() throws java.lang.Throwable @\\\n+        \\ datadog.opentracing.DDTracer\"\n+      justification: \"finalize only needed on CoreTracer\"\n+    - code: \"java.method.numberOfParametersChanged\"\n+      old: \"method void datadog.opentracing.DDTracer.DDSpanBuilder::<init>(java.lang.String,\\\n+        \\ io.opentracing.ScopeManager)\"\n+      new: \"method void datadog.opentracing.DDTracer.DDSpanBuilder::<init>(java.lang.String)\"\n+      justification: \"ScopeManager should always be the DDTracer's scopemanager\"\n+    - code: \"java.method.parameterTypeChanged\"\n+      old: \"parameter datadog.opentracing.DDTracer.DDTracerBuilder datadog.opentracing.DDTracer.DDTracerBuilder::extractor(===datadog.opentracing.propagation.HttpCodec.Extractor===)\"\n+      new: \"parameter datadog.opentracing.DDTracer.DDTracerBuilder datadog.opentracing.DDTracer.DDTracerBuilder::extractor(===datadog.trace.core.propagation.HttpCodec.Extractor===)\"\n+      justification: \"HttpCodec package and interface changed\"\n+    - code: \"java.method.parameterTypeChanged\"\n+      old: \"parameter datadog.opentracing.DDTracer.DDTracerBuilder datadog.opentracing.DDTracer.DDTracerBuilder::injector(===datadog.opentracing.propagation.HttpCodec.Injector===)\"\n+      new: \"parameter datadog.opentracing.DDTracer.DDTracerBuilder datadog.opentracing.DDTracer.DDTracerBuilder::injector(===datadog.trace.core.propagation.HttpCodec.Injector===)\"\n+      justification: \"HttpCodec package and interface changed\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk2NTEzMA==", "bodyText": "#1465 should prevent noise like this", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425965130", "createdAt": "2020-05-15T18:05:50Z", "author": {"login": "richardstartin"}, "path": ".palantir/revapi.yml", "diffHunk": "@@ -134,8 +133,35 @@ acceptedBreaks:\n     - code: \"java.class.removed\"\n       old: \"interface datadog.opentracing.scopemanager.ScopeContext\"\n       justification: \"Non-api class moved to core\"\n-    # End: Classes moved to core\n-    # Begin: LogHandler method changes\n+    - code: \"java.field.removed\"\n+      old: \"field datadog.opentracing.DDTracer.TRACE_ID_MAX\"\n+      justification: \"Internal field\"\n+    - code: \"java.field.removed\"\n+      old: \"field datadog.opentracing.DDTracer.TRACE_ID_MIN\"\n+      justification: \"Internal field\"\n+    - code: \"java.method.exception.checkedAdded\"\n+      old: \"method void datadog.opentracing.DDTracer::finalize()\"\n+      new: \"method void java.lang.Object::finalize() throws java.lang.Throwable @\\\n+        \\ datadog.opentracing.DDTracer\"\n+      justification: \"finalize only needed on CoreTracer\"\n+    - code: \"java.method.movedToSuperClass\"\n+      old: \"method void datadog.opentracing.DDTracer::finalize()\"\n+      new: \"method void java.lang.Object::finalize() throws java.lang.Throwable @\\\n+        \\ datadog.opentracing.DDTracer\"\n+      justification: \"finalize only needed on CoreTracer\"\n+    - code: \"java.method.numberOfParametersChanged\"\n+      old: \"method void datadog.opentracing.DDTracer.DDSpanBuilder::<init>(java.lang.String,\\\n+        \\ io.opentracing.ScopeManager)\"\n+      new: \"method void datadog.opentracing.DDTracer.DDSpanBuilder::<init>(java.lang.String)\"\n+      justification: \"ScopeManager should always be the DDTracer's scopemanager\"\n+    - code: \"java.method.parameterTypeChanged\"\n+      old: \"parameter datadog.opentracing.DDTracer.DDTracerBuilder datadog.opentracing.DDTracer.DDTracerBuilder::extractor(===datadog.opentracing.propagation.HttpCodec.Extractor===)\"\n+      new: \"parameter datadog.opentracing.DDTracer.DDTracerBuilder datadog.opentracing.DDTracer.DDTracerBuilder::extractor(===datadog.trace.core.propagation.HttpCodec.Extractor===)\"\n+      justification: \"HttpCodec package and interface changed\"\n+    - code: \"java.method.parameterTypeChanged\"\n+      old: \"parameter datadog.opentracing.DDTracer.DDTracerBuilder datadog.opentracing.DDTracer.DDTracerBuilder::injector(===datadog.opentracing.propagation.HttpCodec.Injector===)\"\n+      new: \"parameter datadog.opentracing.DDTracer.DDTracerBuilder datadog.opentracing.DDTracer.DDTracerBuilder::injector(===datadog.trace.core.propagation.HttpCodec.Injector===)\"\n+      justification: \"HttpCodec package and interface changed\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTgzMzIwMw=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MTg0MjI2OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNDo0MTowMVrOGWHuYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjo0MDozNlrOGWMLew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                          .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")\n          \n          \n            \n                          .addHeader(X_DATADOG_TRACE_COUNT, Integer.toString(traces.representativeCount()))", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425848417", "createdAt": "2020-05-15T14:41:01Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -75,83 +73,81 @@ public void addResponseListener(final DDAgentResponseListener listener) {\n     }\n   }\n \n-  Response sendSerializedTraces(\n-      final int representativeCount,\n-      final int traceCount,\n-      final int sizeInBytes,\n-      final List<TraceBuffer> traces) {\n+  Response sendSerializedTraces(final TraceBuffer traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n+              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTAwMg==", "bodyText": "in fact I made the change to reduce the number of characters so it all fits on one line", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425905002", "createdAt": "2020-05-15T16:12:12Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -75,83 +73,81 @@ public void addResponseListener(final DDAgentResponseListener listener) {\n     }\n   }\n \n-  Response sendSerializedTraces(\n-      final int representativeCount,\n-      final int traceCount,\n-      final int sizeInBytes,\n-      final List<TraceBuffer> traces) {\n+  Response sendSerializedTraces(final TraceBuffer traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n+              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMzYzNg==", "bodyText": ":)\nYeah, but that will instantiate StringBuilder to do the concatenation :/\nMaybe this time readability will have to be sacrificed.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425913636", "createdAt": "2020-05-15T16:27:26Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -75,83 +73,81 @@ public void addResponseListener(final DDAgentResponseListener listener) {\n     }\n   }\n \n-  Response sendSerializedTraces(\n-      final int representativeCount,\n-      final int traceCount,\n-      final int sizeInBytes,\n-      final List<TraceBuffer> traces) {\n+  Response sendSerializedTraces(final TraceBuffer traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n+              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxODg1Mw==", "bodyText": "Depends on the JDK version.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425918853", "createdAt": "2020-05-15T16:35:53Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -75,83 +73,81 @@ public void addResponseListener(final DDAgentResponseListener listener) {\n     }\n   }\n \n-  Response sendSerializedTraces(\n-      final int representativeCount,\n-      final int traceCount,\n-      final int sizeInBytes,\n-      final List<TraceBuffer> traces) {\n+  Response sendSerializedTraces(final TraceBuffer traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n+              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyMTQwMw==", "bodyText": "True. But since we are targeting JDK 7 as the lowest common denominator we need to consider that.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425921403", "createdAt": "2020-05-15T16:40:36Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -75,83 +73,81 @@ public void addResponseListener(final DDAgentResponseListener listener) {\n     }\n   }\n \n-  Response sendSerializedTraces(\n-      final int representativeCount,\n-      final int traceCount,\n-      final int sizeInBytes,\n-      final List<TraceBuffer> traces) {\n+  Response sendSerializedTraces(final TraceBuffer traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n+              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MTg5ODUzOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNDo1NTowOFrOGWITJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNDo1NTowOFrOGWITJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg1NzgyOA==", "bodyText": "These could perhaps be package private?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425857828", "createdAt": "2020-05-15T14:55:08Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java", "diffHunk": "@@ -0,0 +1,126 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.BlockingWaitStrategy;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+/**\n+ * Disruptor that takes serialized traces and dispatches them to the DD agent\n+ *\n+ * <p>publishing to the buffer will block if the buffer is full.\n+ */\n+@Slf4j\n+public class DispatchingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<TraceBuffer> disruptor;\n+\n+  public DispatchingDisruptor(\n+      int disruptorSize,\n+      EventFactory<TraceBuffer> eventFactory,\n+      DDAgentApi api,\n+      Monitor monitor,\n+      DDAgentWriter writer) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            eventFactory,\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_WRITER,\n+            ProducerType.SINGLE,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(new TraceDispatchingHandler(api, monitor, writer));\n+  }\n+\n+  public void start() {\n+    disruptor.start();\n+  }\n+\n+  @Override\n+  public void close() {\n+    disruptor.halt();\n+  }\n+\n+  public long beginTransaction() {\n+    return disruptor.getRingBuffer().next();\n+  }\n+\n+  public TraceBuffer getTraceBuffer(long sequence) {\n+    return disruptor.getRingBuffer().get(sequence);\n+  }\n+\n+  public void commit(long sequence) {\n+    disruptor.getRingBuffer().publish(sequence);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MTkxNDkwOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNDo1OTowNVrOGWIduw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNTozNTo0OFrOGWJ4zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2MDUzOQ==", "bodyText": "From looking at the code it seems that we are running this on every HeartBeat which is every 100 ms. I'm not sure what this does or accomplishes. I would need to get a walk-through of the code.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425860539", "createdAt": "2020-05-15T14:59:05Z", "author": {"login": "bantonsson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,227 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        try {\n+          if (event.force\n+              || (representativeCount > 0 && serializer.shouldFlush())\n+              || event.flushLatch != null) {\n+            commitTransaction(event.flushLatch);\n+            beginTransaction();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3NjM1OA==", "bodyText": "I'm trying to keep semantic equivalence with the old code, which had a heartbeat to ensure timely flushing of traces in applications which don't generate traces very quickly.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425876358", "createdAt": "2020-05-15T15:23:35Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,227 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        try {\n+          if (event.force\n+              || (representativeCount > 0 && serializer.shouldFlush())\n+              || event.flushLatch != null) {\n+            commitTransaction(event.flushLatch);\n+            beginTransaction();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2MDUzOQ=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4Mzg1NQ==", "bodyText": "So I'm probably confused by the code, but I can't see that the heartbeat did anything in the old code, since both data and flushLatch are null it just skips right through.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425883855", "createdAt": "2020-05-15T15:35:48Z", "author": {"login": "bantonsson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,227 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        try {\n+          if (event.force\n+              || (representativeCount > 0 && serializer.shouldFlush())\n+              || event.flushLatch != null) {\n+            commitTransaction(event.flushLatch);\n+            beginTransaction();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2MDUzOQ=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MTkyMjI1OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNTowMDo0NlrOGWIiWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNTowMDo0NlrOGWIiWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2MTcyMw==", "bodyText": "Wouldn't it be useful to have also the stacktrace?\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    log.debug(\"Failed to send traces to the API: {}\", e.getMessage());\n          \n          \n            \n                    log.debug(\"Failed to send traces to the API: {}\", e.getMessage(), e);", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425861723", "createdAt": "2020-05-15T15:00:46Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java", "diffHunk": "@@ -0,0 +1,126 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.BlockingWaitStrategy;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+/**\n+ * Disruptor that takes serialized traces and dispatches them to the DD agent\n+ *\n+ * <p>publishing to the buffer will block if the buffer is full.\n+ */\n+@Slf4j\n+public class DispatchingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<TraceBuffer> disruptor;\n+\n+  public DispatchingDisruptor(\n+      int disruptorSize,\n+      EventFactory<TraceBuffer> eventFactory,\n+      DDAgentApi api,\n+      Monitor monitor,\n+      DDAgentWriter writer) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            eventFactory,\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_WRITER,\n+            ProducerType.SINGLE,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(new TraceDispatchingHandler(api, monitor, writer));\n+  }\n+\n+  public void start() {\n+    disruptor.start();\n+  }\n+\n+  @Override\n+  public void close() {\n+    disruptor.halt();\n+  }\n+\n+  public long beginTransaction() {\n+    return disruptor.getRingBuffer().next();\n+  }\n+\n+  public TraceBuffer getTraceBuffer(long sequence) {\n+    return disruptor.getRingBuffer().get(sequence);\n+  }\n+\n+  public void commit(long sequence) {\n+    disruptor.getRingBuffer().publish(sequence);\n+  }\n+\n+  // Intentionally not thread safe.\n+  private static class TraceDispatchingHandler implements EventHandler<TraceBuffer> {\n+\n+    private final DDAgentApi api;\n+    private final Monitor monitor;\n+    private final DDAgentWriter writer;\n+\n+    private TraceDispatchingHandler(\n+        final DDAgentApi api, final Monitor monitor, final DDAgentWriter writer) {\n+      this.api = api;\n+      this.monitor = monitor;\n+      this.writer = writer;\n+    }\n+\n+    @Override\n+    public void onEvent(final TraceBuffer event, final long sequence, final boolean endOfBatch) {\n+      sendData(event);\n+    }\n+\n+    private void sendData(TraceBuffer traces) {\n+      if (log.isDebugEnabled()) {\n+        log.debug(\n+            \"receive id={}, rc={}, tc={}\",\n+            traces.id(),\n+            traces.representativeCount(),\n+            traces.traceCount());\n+      }\n+      try {\n+        if (traces.traceCount() > 0) {\n+          final DDAgentApi.Response response = api.sendSerializedTraces(traces);\n+          if (response.success()) {\n+            if (log.isDebugEnabled()) {\n+              log.debug(\n+                  \"Successfully sent {} traces {} to the API\", traces.traceCount(), traces.id());\n+            }\n+            monitor.onSend(writer, traces.representativeCount(), traces.sizeInBytes(), response);\n+          } else {\n+            if (log.isDebugEnabled()) {\n+              log.debug(\n+                  \"Failed to send {} traces (representing {}) of size {} bytes to the API\",\n+                  traces.traceCount(),\n+                  traces.representativeCount(),\n+                  traces.sizeInBytes());\n+            }\n+            monitor.onFailedSend(\n+                writer, traces.representativeCount(), traces.sizeInBytes(), response);\n+          }\n+        } else if (log.isDebugEnabled()) {\n+          log.debug(\"buffer {} was empty\", traces.id());\n+        }\n+      } catch (final Throwable e) {\n+        log.debug(\"Failed to send traces to the API: {}\", e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MTk0NjgyOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DisruptorUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNTowNzowOFrOGWIyEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNTowNzowOFrOGWIyEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2NTc0NQ==", "bodyText": "Nit: Could be final?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425865745", "createdAt": "2020-05-15T15:07:08Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DisruptorUtils.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.WaitStrategy;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import java.util.concurrent.ThreadFactory;\n+\n+public class DisruptorUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MTk4MzY1OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNToxNjoxOVrOGWJJOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNToxNjoxOVrOGWJJOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3MTY3NA==", "bodyText": "Can you add a comment here explaining why both clear() and flush() must be called?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425871674", "createdAt": "2020-05-15T15:16:19Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +44,192 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean shouldFlush() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjAyMzYwOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNToyNTo0NVrOGWJhWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNlQxNzo0MjoyNlrOGWbnVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3Nzg0OQ==", "bodyText": "Can this be combined with a call to headerSize()?\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  if (traceCount < (1 << 4)) {\n          \n          \n            \n                    ByteBuffer buffer = ByteBuffer.allocate(1);\n          \n          \n            \n                    buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n          \n          \n            \n                    channel.write(buffer);\n          \n          \n            \n                  } else if (traceCount < (1 << 16)) {\n          \n          \n            \n                    ByteBuffer buffer = ByteBuffer.allocate(3);\n          \n          \n            \n                    buffer.put(0, ARRAY16);\n          \n          \n            \n                    buffer.putShort(1, (short) traceCount);\n          \n          \n            \n                    channel.write(buffer);\n          \n          \n            \n                  } else {\n          \n          \n            \n                    ByteBuffer buffer = ByteBuffer.allocate(5);\n          \n          \n            \n                    buffer.put(0, ARRAY32);\n          \n          \n            \n                    buffer.putInt(1, traceCount);\n          \n          \n            \n                    channel.write(buffer);\n          \n          \n            \n                  }\n          \n          \n            \n                  int headerSize = headerSize();\n          \n          \n            \n                  ByteBuffer buffer = ByteBuffer.allocate(headerSize);\n          \n          \n            \n                  switch (headerSize) {\n          \n          \n            \n                  if (traceCount < (1 << 4)) {\n          \n          \n            \n                    case 1:\n          \n          \n            \n                      buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n          \n          \n            \n                      break;\n          \n          \n            \n                    case 3:\n          \n          \n            \n                      buffer.put(0, ARRAY16);\n          \n          \n            \n                      buffer.putShort(1, (short) traceCount);\n          \n          \n            \n                      break;\n          \n          \n            \n                    case 5:\n          \n          \n            \n                      buffer.put(0, ARRAY32);\n          \n          \n            \n                      buffer.putInt(1, traceCount);\n          \n          \n            \n                      break;\n          \n          \n            \n                    default:\n          \n          \n            \n                      throw new IOException(\"Unsupported header size {}\", headerSize);\n          \n          \n            \n                  }\n          \n          \n            \n                  channel.write(buffer);", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425877849", "createdAt": "2020-05-15T15:25:45Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +44,192 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean shouldFlush() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);\n   }\n \n-  private int traceBufferSize() {\n-    // round up to next KB, assumes for now that there will be one trace per buffer\n-    return ((lastTracesPerBuffer * traceSizeSum / TRACE_HISTORY_SIZE) + 1023) / 1024;\n+  private int avgTraceSize() {\n+    return traceSizeSum / TRACE_HISTORY_SIZE;\n   }\n \n-  public static class MsgPackTraceBuffer implements TraceBuffer {\n+  static class MsgPackTraceBuffer implements TraceBuffer {\n+\n+    private static final AtomicInteger BUFFER_ID = new AtomicInteger(0);\n \n-    private ArrayBufferOutput buffer;\n+    private final ArrayBufferOutput buffer;\n+    final int id;\n     private int length;\n     private int traceCount;\n+    private int representativeCount;\n+    private CountDownLatch flushLatch;\n+\n+    public MsgPackTraceBuffer(ArrayBufferOutput buffer) {\n+      this.buffer = buffer;\n+      this.id = BUFFER_ID.getAndIncrement();\n+    }\n \n     @Override\n     public void writeTo(WritableByteChannel channel) throws IOException {\n+      writeHeader(channel);\n       int remaining = length;\n       for (MessageBuffer messageBuffer : buffer.toBufferList()) {\n         int size = messageBuffer.size();\n-        ByteBuffer buffer =\n-            size > remaining\n-                ? messageBuffer.sliceAsByteBuffer(0, remaining)\n-                : messageBuffer.sliceAsByteBuffer();\n+        ByteBuffer buffer = messageBuffer.sliceAsByteBuffer(0, Math.min(size, remaining));\n         while (buffer.hasRemaining()) {\n-          channel.write(buffer);\n+          remaining -= channel.write(buffer);\n         }\n-        remaining -= size;\n       }\n       assert remaining == 0;\n     }\n \n+    private void writeHeader(WritableByteChannel channel) throws IOException {\n+      // inlines behaviour from MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(1);\n+        buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n+        channel.write(buffer);\n+      } else if (traceCount < (1 << 16)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(3);\n+        buffer.put(0, ARRAY16);\n+        buffer.putShort(1, (short) traceCount);\n+        channel.write(buffer);\n+      } else {\n+        ByteBuffer buffer = ByteBuffer.allocate(5);\n+        buffer.put(0, ARRAY32);\n+        buffer.putInt(1, traceCount);\n+        channel.write(buffer);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkzNjgwNg==", "bodyText": "I'm not sure this is more succinct, whereas it's already inlining some logic from message pack so divergence here may not be the primary concern. I will think about it.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425936806", "createdAt": "2020-05-15T17:09:51Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +44,192 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean shouldFlush() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);\n   }\n \n-  private int traceBufferSize() {\n-    // round up to next KB, assumes for now that there will be one trace per buffer\n-    return ((lastTracesPerBuffer * traceSizeSum / TRACE_HISTORY_SIZE) + 1023) / 1024;\n+  private int avgTraceSize() {\n+    return traceSizeSum / TRACE_HISTORY_SIZE;\n   }\n \n-  public static class MsgPackTraceBuffer implements TraceBuffer {\n+  static class MsgPackTraceBuffer implements TraceBuffer {\n+\n+    private static final AtomicInteger BUFFER_ID = new AtomicInteger(0);\n \n-    private ArrayBufferOutput buffer;\n+    private final ArrayBufferOutput buffer;\n+    final int id;\n     private int length;\n     private int traceCount;\n+    private int representativeCount;\n+    private CountDownLatch flushLatch;\n+\n+    public MsgPackTraceBuffer(ArrayBufferOutput buffer) {\n+      this.buffer = buffer;\n+      this.id = BUFFER_ID.getAndIncrement();\n+    }\n \n     @Override\n     public void writeTo(WritableByteChannel channel) throws IOException {\n+      writeHeader(channel);\n       int remaining = length;\n       for (MessageBuffer messageBuffer : buffer.toBufferList()) {\n         int size = messageBuffer.size();\n-        ByteBuffer buffer =\n-            size > remaining\n-                ? messageBuffer.sliceAsByteBuffer(0, remaining)\n-                : messageBuffer.sliceAsByteBuffer();\n+        ByteBuffer buffer = messageBuffer.sliceAsByteBuffer(0, Math.min(size, remaining));\n         while (buffer.hasRemaining()) {\n-          channel.write(buffer);\n+          remaining -= channel.write(buffer);\n         }\n-        remaining -= size;\n       }\n       assert remaining == 0;\n     }\n \n+    private void writeHeader(WritableByteChannel channel) throws IOException {\n+      // inlines behaviour from MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(1);\n+        buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n+        channel.write(buffer);\n+      } else if (traceCount < (1 << 16)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(3);\n+        buffer.put(0, ARRAY16);\n+        buffer.putShort(1, (short) traceCount);\n+        channel.write(buffer);\n+      } else {\n+        ByteBuffer buffer = ByteBuffer.allocate(5);\n+        buffer.put(0, ARRAY32);\n+        buffer.putInt(1, traceCount);\n+        channel.write(buffer);\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3Nzg0OQ=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjE3NDI5Mw==", "bodyText": "ok", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426174293", "createdAt": "2020-05-16T17:42:26Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +44,192 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean shouldFlush() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);\n   }\n \n-  private int traceBufferSize() {\n-    // round up to next KB, assumes for now that there will be one trace per buffer\n-    return ((lastTracesPerBuffer * traceSizeSum / TRACE_HISTORY_SIZE) + 1023) / 1024;\n+  private int avgTraceSize() {\n+    return traceSizeSum / TRACE_HISTORY_SIZE;\n   }\n \n-  public static class MsgPackTraceBuffer implements TraceBuffer {\n+  static class MsgPackTraceBuffer implements TraceBuffer {\n+\n+    private static final AtomicInteger BUFFER_ID = new AtomicInteger(0);\n \n-    private ArrayBufferOutput buffer;\n+    private final ArrayBufferOutput buffer;\n+    final int id;\n     private int length;\n     private int traceCount;\n+    private int representativeCount;\n+    private CountDownLatch flushLatch;\n+\n+    public MsgPackTraceBuffer(ArrayBufferOutput buffer) {\n+      this.buffer = buffer;\n+      this.id = BUFFER_ID.getAndIncrement();\n+    }\n \n     @Override\n     public void writeTo(WritableByteChannel channel) throws IOException {\n+      writeHeader(channel);\n       int remaining = length;\n       for (MessageBuffer messageBuffer : buffer.toBufferList()) {\n         int size = messageBuffer.size();\n-        ByteBuffer buffer =\n-            size > remaining\n-                ? messageBuffer.sliceAsByteBuffer(0, remaining)\n-                : messageBuffer.sliceAsByteBuffer();\n+        ByteBuffer buffer = messageBuffer.sliceAsByteBuffer(0, Math.min(size, remaining));\n         while (buffer.hasRemaining()) {\n-          channel.write(buffer);\n+          remaining -= channel.write(buffer);\n         }\n-        remaining -= size;\n       }\n       assert remaining == 0;\n     }\n \n+    private void writeHeader(WritableByteChannel channel) throws IOException {\n+      // inlines behaviour from MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(1);\n+        buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n+        channel.write(buffer);\n+      } else if (traceCount < (1 << 16)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(3);\n+        buffer.put(0, ARRAY16);\n+        buffer.putShort(1, (short) traceCount);\n+        channel.write(buffer);\n+      } else {\n+        ByteBuffer buffer = ByteBuffer.allocate(5);\n+        buffer.put(0, ARRAY32);\n+        buffer.putInt(1, traceCount);\n+        channel.write(buffer);\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3Nzg0OQ=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 206}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjAzNjgxOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNToyOToxNVrOGWJpqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNjowODo0OVrOGWLD2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3OTk3OA==", "bodyText": "Would it be possible to change this to accept a Runnable or a custom Callback interface instead?\nWould be nice if CountdownLatch choice is not imposed on the API caller.\nAlso, can this method be called concurrently with onDispatched()?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425879978", "createdAt": "2020-05-15T15:29:15Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +44,192 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean shouldFlush() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);\n   }\n \n-  private int traceBufferSize() {\n-    // round up to next KB, assumes for now that there will be one trace per buffer\n-    return ((lastTracesPerBuffer * traceSizeSum / TRACE_HISTORY_SIZE) + 1023) / 1024;\n+  private int avgTraceSize() {\n+    return traceSizeSum / TRACE_HISTORY_SIZE;\n   }\n \n-  public static class MsgPackTraceBuffer implements TraceBuffer {\n+  static class MsgPackTraceBuffer implements TraceBuffer {\n+\n+    private static final AtomicInteger BUFFER_ID = new AtomicInteger(0);\n \n-    private ArrayBufferOutput buffer;\n+    private final ArrayBufferOutput buffer;\n+    final int id;\n     private int length;\n     private int traceCount;\n+    private int representativeCount;\n+    private CountDownLatch flushLatch;\n+\n+    public MsgPackTraceBuffer(ArrayBufferOutput buffer) {\n+      this.buffer = buffer;\n+      this.id = BUFFER_ID.getAndIncrement();\n+    }\n \n     @Override\n     public void writeTo(WritableByteChannel channel) throws IOException {\n+      writeHeader(channel);\n       int remaining = length;\n       for (MessageBuffer messageBuffer : buffer.toBufferList()) {\n         int size = messageBuffer.size();\n-        ByteBuffer buffer =\n-            size > remaining\n-                ? messageBuffer.sliceAsByteBuffer(0, remaining)\n-                : messageBuffer.sliceAsByteBuffer();\n+        ByteBuffer buffer = messageBuffer.sliceAsByteBuffer(0, Math.min(size, remaining));\n         while (buffer.hasRemaining()) {\n-          channel.write(buffer);\n+          remaining -= channel.write(buffer);\n         }\n-        remaining -= size;\n       }\n       assert remaining == 0;\n     }\n \n+    private void writeHeader(WritableByteChannel channel) throws IOException {\n+      // inlines behaviour from MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(1);\n+        buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n+        channel.write(buffer);\n+      } else if (traceCount < (1 << 16)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(3);\n+        buffer.put(0, ARRAY16);\n+        buffer.putShort(1, (short) traceCount);\n+        channel.write(buffer);\n+      } else {\n+        ByteBuffer buffer = ByteBuffer.allocate(5);\n+        buffer.put(0, ARRAY32);\n+        buffer.putInt(1, traceCount);\n+        channel.write(buffer);\n+      }\n+    }\n+\n     @Override\n     public int sizeInBytes() {\n       return length;\n     }\n \n+    @Override\n+    public int headerSize() {\n+      // Need to allocate additional to handle MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        return 1;\n+      } else if (traceCount < (1 << 16)) {\n+        return 3;\n+      } else {\n+        return 5;\n+      }\n+    }\n+\n     @Override\n     public int traceCount() {\n       return traceCount;\n     }\n+\n+    @Override\n+    public int representativeCount() {\n+      return representativeCount;\n+    }\n+\n+    @Override\n+    public void setRepresentativeCount(int representativeCount) {\n+      this.representativeCount = representativeCount;\n+    }\n+\n+    @Override\n+    public int id() {\n+      return id;\n+    }\n+\n+    @Override\n+    public void setLatch(CountDownLatch latch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 247}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzA2Ng==", "bodyText": "yes I agree, runnable is more general.\nno, it can't, but we're relying on the disruptor to coordinate that.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425903066", "createdAt": "2020-05-15T16:08:49Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +44,192 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean shouldFlush() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);\n   }\n \n-  private int traceBufferSize() {\n-    // round up to next KB, assumes for now that there will be one trace per buffer\n-    return ((lastTracesPerBuffer * traceSizeSum / TRACE_HISTORY_SIZE) + 1023) / 1024;\n+  private int avgTraceSize() {\n+    return traceSizeSum / TRACE_HISTORY_SIZE;\n   }\n \n-  public static class MsgPackTraceBuffer implements TraceBuffer {\n+  static class MsgPackTraceBuffer implements TraceBuffer {\n+\n+    private static final AtomicInteger BUFFER_ID = new AtomicInteger(0);\n \n-    private ArrayBufferOutput buffer;\n+    private final ArrayBufferOutput buffer;\n+    final int id;\n     private int length;\n     private int traceCount;\n+    private int representativeCount;\n+    private CountDownLatch flushLatch;\n+\n+    public MsgPackTraceBuffer(ArrayBufferOutput buffer) {\n+      this.buffer = buffer;\n+      this.id = BUFFER_ID.getAndIncrement();\n+    }\n \n     @Override\n     public void writeTo(WritableByteChannel channel) throws IOException {\n+      writeHeader(channel);\n       int remaining = length;\n       for (MessageBuffer messageBuffer : buffer.toBufferList()) {\n         int size = messageBuffer.size();\n-        ByteBuffer buffer =\n-            size > remaining\n-                ? messageBuffer.sliceAsByteBuffer(0, remaining)\n-                : messageBuffer.sliceAsByteBuffer();\n+        ByteBuffer buffer = messageBuffer.sliceAsByteBuffer(0, Math.min(size, remaining));\n         while (buffer.hasRemaining()) {\n-          channel.write(buffer);\n+          remaining -= channel.write(buffer);\n         }\n-        remaining -= size;\n       }\n       assert remaining == 0;\n     }\n \n+    private void writeHeader(WritableByteChannel channel) throws IOException {\n+      // inlines behaviour from MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(1);\n+        buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n+        channel.write(buffer);\n+      } else if (traceCount < (1 << 16)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(3);\n+        buffer.put(0, ARRAY16);\n+        buffer.putShort(1, (short) traceCount);\n+        channel.write(buffer);\n+      } else {\n+        ByteBuffer buffer = ByteBuffer.allocate(5);\n+        buffer.put(0, ARRAY32);\n+        buffer.putInt(1, traceCount);\n+        channel.write(buffer);\n+      }\n+    }\n+\n     @Override\n     public int sizeInBytes() {\n       return length;\n     }\n \n+    @Override\n+    public int headerSize() {\n+      // Need to allocate additional to handle MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        return 1;\n+      } else if (traceCount < (1 << 16)) {\n+        return 3;\n+      } else {\n+        return 5;\n+      }\n+    }\n+\n     @Override\n     public int traceCount() {\n       return traceCount;\n     }\n+\n+    @Override\n+    public int representativeCount() {\n+      return representativeCount;\n+    }\n+\n+    @Override\n+    public void setRepresentativeCount(int representativeCount) {\n+      this.representativeCount = representativeCount;\n+    }\n+\n+    @Override\n+    public int id() {\n+      return id;\n+    }\n+\n+    @Override\n+    public void setLatch(CountDownLatch latch) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3OTk3OA=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 247}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjA0MzUxOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/StatefulSerializer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNTozMTowMlrOGWJt4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNzoxNzowM1rOGWNV9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4MTA1Ng==", "bodyText": "If I get this right if shouldFlush() returns true the caller should get the buffer contents and reset the buffer. The name then does not sound right - perhaps shouldReset or isCapacityExceeded()? Or something even better fitting the method purpose?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425881056", "createdAt": "2020-05-15T15:31:02Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/StatefulSerializer.java", "diffHunk": "@@ -10,17 +10,32 @@\n    * Serialises the trace into a trace buffer.\n    *\n    * @param trace a list of spans making up a trace\n+   * @return how many bytes were serialized\n    * @throws IOException\n    */\n-  void serialize(List<DDSpan> trace) throws IOException;\n+  int serialize(List<DDSpan> trace) throws IOException;\n+\n+  void dropBuffer() throws IOException;\n \n   /**\n-   * Returns a buffer containing all traces written since the last call to this method. The buffer\n-   * belongs to the caller and should no longer be referenced by the serializer after being\n-   * released.\n+   * returns a newly allocated buffer\n    *\n-   * @return the buffer into which traces have been serialized.\n-   * @throws IOException\n+   * @return a new buffer\n+   */\n+  TraceBuffer newBuffer();\n+\n+  /**\n+   * Returns true if the current buffer is near or exceeding capacity. This is advice to claim the\n+   * buffer and reset.\n+   *\n+   * @return true if the buffer should be reset", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk0MDQ2OA==", "bodyText": "I've changed the name, but it's not an easy method to name. How do you feel about shouldGetTheBufferNowOrTheNextTraceMayCauseAnAllocationOrThatMayAlreadyHaveHappenedButItWasMostlyUnavoidable? I went with isAtCapacity, but that doesn't describe the semantics of the only implementation.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425940468", "createdAt": "2020-05-15T17:17:03Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/StatefulSerializer.java", "diffHunk": "@@ -10,17 +10,32 @@\n    * Serialises the trace into a trace buffer.\n    *\n    * @param trace a list of spans making up a trace\n+   * @return how many bytes were serialized\n    * @throws IOException\n    */\n-  void serialize(List<DDSpan> trace) throws IOException;\n+  int serialize(List<DDSpan> trace) throws IOException;\n+\n+  void dropBuffer() throws IOException;\n \n   /**\n-   * Returns a buffer containing all traces written since the last call to this method. The buffer\n-   * belongs to the caller and should no longer be referenced by the serializer after being\n-   * released.\n+   * returns a newly allocated buffer\n    *\n-   * @return the buffer into which traces have been serialized.\n-   * @throws IOException\n+   * @return a new buffer\n+   */\n+  TraceBuffer newBuffer();\n+\n+  /**\n+   * Returns true if the current buffer is near or exceeding capacity. This is advice to claim the\n+   * buffer and reset.\n+   *\n+   * @return true if the buffer should be reset", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4MTA1Ng=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjA3ODk0OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNTo0MTowMVrOGWKE1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNTo0MTowMVrOGWKE1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4NjkzMg==", "bodyText": "Probably the nested try is not necessary here.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425886932", "createdAt": "2020-05-15T15:41:01Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,227 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 182}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjA5MzYwOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/core/serialization/FormatWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNTo0NTowN1rOGWKOLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxNzo0MjowNFrOGWOG7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4OTMyNw==", "bodyText": "Is this change related to the disruptor changes?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425889327", "createdAt": "2020-05-15T15:45:07Z", "author": {"login": "jbachorik"}, "path": "dd-trace-core/src/main/java/datadog/trace/core/serialization/FormatWriter.java", "diffHunk": "@@ -85,7 +85,7 @@ public void writeStringMap(\n     writeKey(key, destination);\n     writeMapHeader(value.size(), destination);\n     for (final Map.Entry<String, String> entry : value.entrySet()) {\n-      writeString(entry.getKey(), entry.getValue(), destination);\n+      writeTag(entry.getKey(), entry.getValue(), destination);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk1MzAwNA==", "bodyText": "True, but this caused a small regression when changed with the last change to this area of the code (perhaps shouldn't have been changed then) so just undoing it now.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425953004", "createdAt": "2020-05-15T17:42:04Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/core/serialization/FormatWriter.java", "diffHunk": "@@ -85,7 +85,7 @@ public void writeStringMap(\n     writeKey(key, destination);\n     writeMapHeader(value.size(), destination);\n     for (final Map.Entry<String, String> entry : value.entrySet()) {\n-      writeString(entry.getKey(), entry.getValue(), destination);\n+      writeTag(entry.getKey(), entry.getValue(), destination);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4OTMyNw=="}, "originalCommit": {"oid": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjY2OTM3OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxODo0Mzo1MFrOGWP_DA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxMDowOTo0OVrOGWwfRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4Mzc1Ng==", "bodyText": "Do we want to wait for flushing at all?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425983756", "createdAt": "2020-05-15T18:43:50Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjUxNjI5Mw==", "bodyText": "Only DDAgentWriter calls this method, but does a flush with a timeout before doing so. So it shouldn't matter in practice, but this class isn't taking responsibility for flushing data. All that's done before halting the disruptor is we make sure no more heartbeats are sent. This may need some more thought, but I'm working on the principle that losing some traces at shutdown is preferable to delaying shutdown.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426516293", "createdAt": "2020-05-18T10:09:49Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4Mzc1Ng=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjY5NjMwOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxODo1Mjo0NFrOGWQQDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNDozMTowNlrOGW52UQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODExMA==", "bodyText": "Something that seems to have been changed, and maybe it was intentional, but in the previous version, if there was enough flushing due to size, then the heartbeat would never actually trigger a flush.  the timeout for the flush delay was reset every flush.  With the current design, it seems you could send a bunch of large payloads, but then occasionally you'll see a smaller one.\nAn additional reason to keep a \"time since last flush\" timestamp and not just since the last heartbeat flush is I think that would make an interesting health metric to report... (how frequent are we actually flushing).", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425988110", "createdAt": "2020-05-15T18:52:44Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ4ODA2OA==", "bodyText": "I agree, this was moved over at the end and probably needs more thought.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426488068", "createdAt": "2020-05-18T09:23:43Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODExMA=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjU0MTM1OA==", "bodyText": "I have attempted to address this. Please let me know what you think.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426541358", "createdAt": "2020-05-18T10:56:57Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODExMA=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY2OTY0OQ==", "bodyText": "Looks better. Thanks!", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426669649", "createdAt": "2020-05-18T14:31:06Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODExMA=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjcwMDU5OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxODo1NDoxOFrOGWQTBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNDoyODoyN1rOGW5uzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODg3MA==", "bodyText": "Why not keep all units in nano?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425988870", "createdAt": "2020-05-15T18:54:18Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {\n+          long now = millisecondTime();\n+          if (now >= nextFlushMillis) {\n+            commitTransaction();\n+            beginTransaction();\n+            scheduleNextTimeFlush(now);\n           }\n         }\n-\n-        if (event.flushLatch != null) {\n-          if (batchWritingDisruptor.running) {\n-            // propagate the flush.\n-            batchWritingDisruptor.flush(event.representativeCount, event.flushLatch);\n-          }\n-          if (!batchWritingDisruptor.running) { // check again to protect against race condition.\n-            // got shutdown early somehow?\n-            event.flushLatch.countDown();\n-          }\n+        if (event.data != null) {\n+          serialize(event.data, event.representativeCount);\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n         }\n+        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n     }\n+\n+    private void serialize(List<DDSpan> trace, int representativeCount) throws IOException {\n+      // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+      this.representativeCount += representativeCount;\n+      trace = processor.onTraceComplete(trace);\n+      int sizeInBytes = serializer.serialize(trace);\n+      monitor.onSerialize(writer, trace, sizeInBytes);\n+    }\n+\n+    private void commitTransaction() throws IOException {\n+      commitTransaction(null);\n+    }\n+\n+    private void commitTransaction(final CountDownLatch flushLatch) throws IOException {\n+      serializer.dropBuffer();\n+      TraceBuffer buffer = dispatchingDisruptor.getTraceBuffer(publicationTxn);\n+      if (null != flushLatch) {\n+        buffer.setDispatchRunnable(\n+            new Runnable() {\n+              @Override\n+              public void run() {\n+                flushLatch.countDown();\n+              }\n+            });\n+      }\n+      buffer.setRepresentativeCount(representativeCount);\n+      if (log.isDebugEnabled()) {\n+        log.debug(\n+            \"publish id={}, rc={}, tc={}\",\n+            buffer.id(),\n+            buffer.representativeCount(),\n+            buffer.traceCount());\n+      }\n+      dispatchingDisruptor.commit(publicationTxn);\n+    }\n+\n+    private void beginTransaction() {\n+      this.publicationTxn = dispatchingDisruptor.beginTransaction();\n+      this.representativeCount = 0;\n+      serializer.reset(dispatchingDisruptor.getTraceBuffer(publicationTxn));\n+    }\n+\n+    private void scheduleNextTimeFlush(long now) {\n+      nextFlushMillis = now + flushIntervalMillis;\n+    }\n+\n+    private long millisecondTime() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ4ODIyMw==", "bodyText": "arithmetic overflow", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426488223", "createdAt": "2020-05-18T09:23:57Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {\n+          long now = millisecondTime();\n+          if (now >= nextFlushMillis) {\n+            commitTransaction();\n+            beginTransaction();\n+            scheduleNextTimeFlush(now);\n           }\n         }\n-\n-        if (event.flushLatch != null) {\n-          if (batchWritingDisruptor.running) {\n-            // propagate the flush.\n-            batchWritingDisruptor.flush(event.representativeCount, event.flushLatch);\n-          }\n-          if (!batchWritingDisruptor.running) { // check again to protect against race condition.\n-            // got shutdown early somehow?\n-            event.flushLatch.countDown();\n-          }\n+        if (event.data != null) {\n+          serialize(event.data, event.representativeCount);\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n         }\n+        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n     }\n+\n+    private void serialize(List<DDSpan> trace, int representativeCount) throws IOException {\n+      // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+      this.representativeCount += representativeCount;\n+      trace = processor.onTraceComplete(trace);\n+      int sizeInBytes = serializer.serialize(trace);\n+      monitor.onSerialize(writer, trace, sizeInBytes);\n+    }\n+\n+    private void commitTransaction() throws IOException {\n+      commitTransaction(null);\n+    }\n+\n+    private void commitTransaction(final CountDownLatch flushLatch) throws IOException {\n+      serializer.dropBuffer();\n+      TraceBuffer buffer = dispatchingDisruptor.getTraceBuffer(publicationTxn);\n+      if (null != flushLatch) {\n+        buffer.setDispatchRunnable(\n+            new Runnable() {\n+              @Override\n+              public void run() {\n+                flushLatch.countDown();\n+              }\n+            });\n+      }\n+      buffer.setRepresentativeCount(representativeCount);\n+      if (log.isDebugEnabled()) {\n+        log.debug(\n+            \"publish id={}, rc={}, tc={}\",\n+            buffer.id(),\n+            buffer.representativeCount(),\n+            buffer.traceCount());\n+      }\n+      dispatchingDisruptor.commit(publicationTxn);\n+    }\n+\n+    private void beginTransaction() {\n+      this.publicationTxn = dispatchingDisruptor.beginTransaction();\n+      this.representativeCount = 0;\n+      serializer.reset(dispatchingDisruptor.getTraceBuffer(publicationTxn));\n+    }\n+\n+    private void scheduleNextTimeFlush(long now) {\n+      nextFlushMillis = now + flushIntervalMillis;\n+    }\n+\n+    private long millisecondTime() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODg3MA=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY2NzcyNA==", "bodyText": "consider adding a comment with this rationalization.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426667724", "createdAt": "2020-05-18T14:28:27Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {\n+          long now = millisecondTime();\n+          if (now >= nextFlushMillis) {\n+            commitTransaction();\n+            beginTransaction();\n+            scheduleNextTimeFlush(now);\n           }\n         }\n-\n-        if (event.flushLatch != null) {\n-          if (batchWritingDisruptor.running) {\n-            // propagate the flush.\n-            batchWritingDisruptor.flush(event.representativeCount, event.flushLatch);\n-          }\n-          if (!batchWritingDisruptor.running) { // check again to protect against race condition.\n-            // got shutdown early somehow?\n-            event.flushLatch.countDown();\n-          }\n+        if (event.data != null) {\n+          serialize(event.data, event.representativeCount);\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n         }\n+        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n     }\n+\n+    private void serialize(List<DDSpan> trace, int representativeCount) throws IOException {\n+      // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+      this.representativeCount += representativeCount;\n+      trace = processor.onTraceComplete(trace);\n+      int sizeInBytes = serializer.serialize(trace);\n+      monitor.onSerialize(writer, trace, sizeInBytes);\n+    }\n+\n+    private void commitTransaction() throws IOException {\n+      commitTransaction(null);\n+    }\n+\n+    private void commitTransaction(final CountDownLatch flushLatch) throws IOException {\n+      serializer.dropBuffer();\n+      TraceBuffer buffer = dispatchingDisruptor.getTraceBuffer(publicationTxn);\n+      if (null != flushLatch) {\n+        buffer.setDispatchRunnable(\n+            new Runnable() {\n+              @Override\n+              public void run() {\n+                flushLatch.countDown();\n+              }\n+            });\n+      }\n+      buffer.setRepresentativeCount(representativeCount);\n+      if (log.isDebugEnabled()) {\n+        log.debug(\n+            \"publish id={}, rc={}, tc={}\",\n+            buffer.id(),\n+            buffer.representativeCount(),\n+            buffer.traceCount());\n+      }\n+      dispatchingDisruptor.commit(publicationTxn);\n+    }\n+\n+    private void beginTransaction() {\n+      this.publicationTxn = dispatchingDisruptor.beginTransaction();\n+      this.representativeCount = 0;\n+      serializer.reset(dispatchingDisruptor.getTraceBuffer(publicationTxn));\n+    }\n+\n+    private void scheduleNextTimeFlush(long now) {\n+      nextFlushMillis = now + flushIntervalMillis;\n+    }\n+\n+    private long millisecondTime() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODg3MA=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 263}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1MjcwNjgzOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxODo1NjoxNVrOGWQW5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxMDo1NjozMlrOGWyAUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4OTg2MQ==", "bodyText": "I generally prefer to let TimeUnit do my conversions to avoid silly arithmetic errors.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425989861", "createdAt": "2020-05-15T18:56:15Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {\n+          long now = millisecondTime();\n+          if (now >= nextFlushMillis) {\n+            commitTransaction();\n+            beginTransaction();\n+            scheduleNextTimeFlush(now);\n           }\n         }\n-\n-        if (event.flushLatch != null) {\n-          if (batchWritingDisruptor.running) {\n-            // propagate the flush.\n-            batchWritingDisruptor.flush(event.representativeCount, event.flushLatch);\n-          }\n-          if (!batchWritingDisruptor.running) { // check again to protect against race condition.\n-            // got shutdown early somehow?\n-            event.flushLatch.countDown();\n-          }\n+        if (event.data != null) {\n+          serialize(event.data, event.representativeCount);\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n         }\n+        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n     }\n+\n+    private void serialize(List<DDSpan> trace, int representativeCount) throws IOException {\n+      // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+      this.representativeCount += representativeCount;\n+      trace = processor.onTraceComplete(trace);\n+      int sizeInBytes = serializer.serialize(trace);\n+      monitor.onSerialize(writer, trace, sizeInBytes);\n+    }\n+\n+    private void commitTransaction() throws IOException {\n+      commitTransaction(null);\n+    }\n+\n+    private void commitTransaction(final CountDownLatch flushLatch) throws IOException {\n+      serializer.dropBuffer();\n+      TraceBuffer buffer = dispatchingDisruptor.getTraceBuffer(publicationTxn);\n+      if (null != flushLatch) {\n+        buffer.setDispatchRunnable(\n+            new Runnable() {\n+              @Override\n+              public void run() {\n+                flushLatch.countDown();\n+              }\n+            });\n+      }\n+      buffer.setRepresentativeCount(representativeCount);\n+      if (log.isDebugEnabled()) {\n+        log.debug(\n+            \"publish id={}, rc={}, tc={}\",\n+            buffer.id(),\n+            buffer.representativeCount(),\n+            buffer.traceCount());\n+      }\n+      dispatchingDisruptor.commit(publicationTxn);\n+    }\n+\n+    private void beginTransaction() {\n+      this.publicationTxn = dispatchingDisruptor.beginTransaction();\n+      this.representativeCount = 0;\n+      serializer.reset(dispatchingDisruptor.getTraceBuffer(publicationTxn));\n+    }\n+\n+    private void scheduleNextTimeFlush(long now) {\n+      nextFlushMillis = now + flushIntervalMillis;\n+    }\n+\n+    private long millisecondTime() {\n+      // important: nanoTime is monotonic, currentTimeMillis is not\n+      return System.nanoTime() / 1_000_000L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 265}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjU0MTEzNw==", "bodyText": "Done.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426541137", "createdAt": "2020-05-18T10:56:32Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {\n+          long now = millisecondTime();\n+          if (now >= nextFlushMillis) {\n+            commitTransaction();\n+            beginTransaction();\n+            scheduleNextTimeFlush(now);\n           }\n         }\n-\n-        if (event.flushLatch != null) {\n-          if (batchWritingDisruptor.running) {\n-            // propagate the flush.\n-            batchWritingDisruptor.flush(event.representativeCount, event.flushLatch);\n-          }\n-          if (!batchWritingDisruptor.running) { // check again to protect against race condition.\n-            // got shutdown early somehow?\n-            event.flushLatch.countDown();\n-          }\n+        if (event.data != null) {\n+          serialize(event.data, event.representativeCount);\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n         }\n+        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n     }\n+\n+    private void serialize(List<DDSpan> trace, int representativeCount) throws IOException {\n+      // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+      this.representativeCount += representativeCount;\n+      trace = processor.onTraceComplete(trace);\n+      int sizeInBytes = serializer.serialize(trace);\n+      monitor.onSerialize(writer, trace, sizeInBytes);\n+    }\n+\n+    private void commitTransaction() throws IOException {\n+      commitTransaction(null);\n+    }\n+\n+    private void commitTransaction(final CountDownLatch flushLatch) throws IOException {\n+      serializer.dropBuffer();\n+      TraceBuffer buffer = dispatchingDisruptor.getTraceBuffer(publicationTxn);\n+      if (null != flushLatch) {\n+        buffer.setDispatchRunnable(\n+            new Runnable() {\n+              @Override\n+              public void run() {\n+                flushLatch.countDown();\n+              }\n+            });\n+      }\n+      buffer.setRepresentativeCount(representativeCount);\n+      if (log.isDebugEnabled()) {\n+        log.debug(\n+            \"publish id={}, rc={}, tc={}\",\n+            buffer.id(),\n+            buffer.representativeCount(),\n+            buffer.traceCount());\n+      }\n+      dispatchingDisruptor.commit(publicationTxn);\n+    }\n+\n+    private void beginTransaction() {\n+      this.publicationTxn = dispatchingDisruptor.beginTransaction();\n+      this.representativeCount = 0;\n+      serializer.reset(dispatchingDisruptor.getTraceBuffer(publicationTxn));\n+    }\n+\n+    private void scheduleNextTimeFlush(long now) {\n+      nextFlushMillis = now + flushIntervalMillis;\n+    }\n+\n+    private long millisecondTime() {\n+      // important: nanoTime is monotonic, currentTimeMillis is not\n+      return System.nanoTime() / 1_000_000L;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4OTg2MQ=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 265}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1Mjc0OTk5OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxOTowOToxOFrOGWQyWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxOTowOToxOFrOGWQyWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk5Njg4OA==", "bodyText": "beginTransaction() is always called after commitTransaction.  Perhaps the begin should be implicit (called inside commit)?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425996888", "createdAt": "2020-05-15T19:09:18Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 186}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1Mjc1ODkzOnYy", "diffSide": "LEFT", "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxOToxMjoyMlrOGWQ3zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwOToyNzo0OFrOGWu7Ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk5ODI4Ng==", "bodyText": "Why don't we have a test for this case anymore?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425998286", "createdAt": "2020-05-15T19:12:22Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "diffHunk": "@@ -113,58 +121,13 @@ class DDAgentWriterTest extends DDSpecification {\n     traceCount = 100 // Shouldn't trigger payload, but bigger than the disruptor size.\n   }\n \n-  def \"test flush by size\"() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5MDY1OA==", "bodyText": "I'm not sure this test case was testing what was being done but how. Flushing by size is now handled by the pre-allocated buffer overflowing resulting in publication onto the ring buffer in the trace processor thread. I think \"test default buffer size\" tests this.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426490658", "createdAt": "2020-05-18T09:27:48Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "diffHunk": "@@ -113,58 +121,13 @@ class DDAgentWriterTest extends DDSpecification {\n     traceCount = 100 // Shouldn't trigger payload, but bigger than the disruptor size.\n   }\n \n-  def \"test flush by size\"() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk5ODI4Ng=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1Mjc2NTc0OnYy", "diffSide": "LEFT", "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxOToxNDo1NlrOGWQ7_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNDoxOTo1NFrOGW5W4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk5OTM1OQ==", "bodyText": "Did you remove this to avoid the non-determinisim, or is the comment no longer relevant?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425999359", "createdAt": "2020-05-15T19:14:56Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "diffHunk": "@@ -539,11 +505,6 @@ class DDAgentWriterTest extends DDSpecification {\n     }\n \n     then:\n-    // If the in-flight request times out (we don't currently retry),\n-    // then a new batch will begin processing and many of traces will\n-    // be accepted and batched into a new failing request.\n-    // In that case, the reject number will be low.\n-    numFailedPublish.get() - priorNumFailed >= expectedRejects * 0.80", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 258}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5NzQyNg==", "bodyText": "It just wasn't really clear why this condition would survive a refactoring. Batching is now independent of sending, so if the in-flight request times out, we lose that batch of traces, but can/should simply retry. The next batch, if ready, stays on the ring buffer until any retries are done. If the ring buffer fills up, the processor blocks trying to publish, so can't drain the application-facing ring buffer. The number of dropped traces on the application threads will increase while any backlog caused by a failure sending to the agent. Effectively this is back-pressure propagating from the agent to the processor, without blocking the application.\nI think the actual retry should be done in another PR.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426497426", "createdAt": "2020-05-18T09:38:57Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "diffHunk": "@@ -539,11 +505,6 @@ class DDAgentWriterTest extends DDSpecification {\n     }\n \n     then:\n-    // If the in-flight request times out (we don't currently retry),\n-    // then a new batch will begin processing and many of traces will\n-    // be accepted and batched into a new failing request.\n-    // In that case, the reject number will be low.\n-    numFailedPublish.get() - priorNumFailed >= expectedRejects * 0.80", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk5OTM1OQ=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 258}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY2MTYwMw==", "bodyText": "yeah, I agree the test doesn't make sense if we are retrying.  I was just confused because we don't have retries yet.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426661603", "createdAt": "2020-05-18T14:19:54Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "diffHunk": "@@ -539,11 +505,6 @@ class DDAgentWriterTest extends DDSpecification {\n     }\n \n     then:\n-    // If the in-flight request times out (we don't currently retry),\n-    // then a new batch will begin processing and many of traces will\n-    // be accepted and batched into a new failing request.\n-    // In that case, the reject number will be low.\n-    numFailedPublish.get() - priorNumFailed >= expectedRejects * 0.80", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk5OTM1OQ=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 258}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1Mjc3MTE2OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxOToxNjo0NVrOGWQ_Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxMDo1ODoyNVrOGWyEKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAwMDIxNQ==", "bodyText": "How does this test flush by time?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426000215", "createdAt": "2020-05-15T19:16:45Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "diffHunk": "@@ -113,58 +121,13 @@ class DDAgentWriterTest extends DDSpecification {\n     traceCount = 100 // Shouldn't trigger payload, but bigger than the disruptor size.\n   }\n \n-  def \"test flush by size\"() {\n-    setup:\n-    def writer = DDAgentWriter.builder()\n-      .agentApi(api)\n-      .traceBufferSize(DISRUPTOR_BUFFER_SIZE)\n-      .serializer(serializer)\n-      .flushFrequencySeconds(-1).build()\n-    writer.start()\n-\n-    when:\n-    (1..6).each {\n-      writer.write(trace)\n-    }\n-    // Wait for 2 flushes of 3 by size\n-    phaser.awaitAdvanceInterruptibly(phaser.arrive())\n-    phaser.awaitAdvanceInterruptibly(phaser.arriveAndDeregister())\n-\n-    then:\n-    6 * serializer.serialize(_) >> { trace -> callRealMethod() }\n-    6 * serializer.getBuffer() >> { trace -> callRealMethod() }\n-    2 * api.sendSerializedTraces(3, 3, _, { it.size() == 3 }) >> {\n-      phaser.arrive()\n-      return DDAgentApi.Response.success(200)\n-    }\n-\n-    when:\n-    (1..2).each {\n-      writer.write(trace)\n-    }\n-    // Flush the remaining 2\n-    writer.flush()\n-\n-    then:\n-    2 * serializer.serialize(_) >> { trace -> callRealMethod() }\n-    2 * serializer.getBuffer() >> { trace -> callRealMethod() }\n-    1 * api.sendSerializedTraces(2, 2, _, { it.size() == 2 }) >> DDAgentApi.Response.success(200)\n-    0 * _\n-\n-    cleanup:\n-    writer.close()\n-\n-    where:\n-    span = newSpanOf(0, \"fixed-thread-name\")\n-    trace = (0..10000).collect { span }\n-  }\n-\n   def \"test flush by time\"() {\n     setup:\n     def writer = DDAgentWriter.builder()\n       .agentApi(api)\n       .monitor(monitor)\n       .serializer(serializer)\n+      .flushFrequencySeconds(-1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5ODA0Nw==", "bodyText": "Good question, this was to enable the heartbeat. I mentioned elsewhere that heartbeating needs more thought after the refactor and you're right to challenge this - will be updating the PR so this makes more sense.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426498047", "createdAt": "2020-05-18T09:39:56Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "diffHunk": "@@ -113,58 +121,13 @@ class DDAgentWriterTest extends DDSpecification {\n     traceCount = 100 // Shouldn't trigger payload, but bigger than the disruptor size.\n   }\n \n-  def \"test flush by size\"() {\n-    setup:\n-    def writer = DDAgentWriter.builder()\n-      .agentApi(api)\n-      .traceBufferSize(DISRUPTOR_BUFFER_SIZE)\n-      .serializer(serializer)\n-      .flushFrequencySeconds(-1).build()\n-    writer.start()\n-\n-    when:\n-    (1..6).each {\n-      writer.write(trace)\n-    }\n-    // Wait for 2 flushes of 3 by size\n-    phaser.awaitAdvanceInterruptibly(phaser.arrive())\n-    phaser.awaitAdvanceInterruptibly(phaser.arriveAndDeregister())\n-\n-    then:\n-    6 * serializer.serialize(_) >> { trace -> callRealMethod() }\n-    6 * serializer.getBuffer() >> { trace -> callRealMethod() }\n-    2 * api.sendSerializedTraces(3, 3, _, { it.size() == 3 }) >> {\n-      phaser.arrive()\n-      return DDAgentApi.Response.success(200)\n-    }\n-\n-    when:\n-    (1..2).each {\n-      writer.write(trace)\n-    }\n-    // Flush the remaining 2\n-    writer.flush()\n-\n-    then:\n-    2 * serializer.serialize(_) >> { trace -> callRealMethod() }\n-    2 * serializer.getBuffer() >> { trace -> callRealMethod() }\n-    1 * api.sendSerializedTraces(2, 2, _, { it.size() == 2 }) >> DDAgentApi.Response.success(200)\n-    0 * _\n-\n-    cleanup:\n-    writer.close()\n-\n-    where:\n-    span = newSpanOf(0, \"fixed-thread-name\")\n-    trace = (0..10000).collect { span }\n-  }\n-\n   def \"test flush by time\"() {\n     setup:\n     def writer = DDAgentWriter.builder()\n       .agentApi(api)\n       .monitor(monitor)\n       .serializer(serializer)\n+      .flushFrequencySeconds(-1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAwMDIxNQ=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjU0MjEyMQ==", "bodyText": "I have addressed this now, because not enough data is published to fill the buffer, the flush will not occur until a heart beat is received and a second has elapsed.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426542121", "createdAt": "2020-05-18T10:58:25Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/test/groovy/datadog/trace/api/writer/DDAgentWriterTest.groovy", "diffHunk": "@@ -113,58 +121,13 @@ class DDAgentWriterTest extends DDSpecification {\n     traceCount = 100 // Shouldn't trigger payload, but bigger than the disruptor size.\n   }\n \n-  def \"test flush by size\"() {\n-    setup:\n-    def writer = DDAgentWriter.builder()\n-      .agentApi(api)\n-      .traceBufferSize(DISRUPTOR_BUFFER_SIZE)\n-      .serializer(serializer)\n-      .flushFrequencySeconds(-1).build()\n-    writer.start()\n-\n-    when:\n-    (1..6).each {\n-      writer.write(trace)\n-    }\n-    // Wait for 2 flushes of 3 by size\n-    phaser.awaitAdvanceInterruptibly(phaser.arrive())\n-    phaser.awaitAdvanceInterruptibly(phaser.arriveAndDeregister())\n-\n-    then:\n-    6 * serializer.serialize(_) >> { trace -> callRealMethod() }\n-    6 * serializer.getBuffer() >> { trace -> callRealMethod() }\n-    2 * api.sendSerializedTraces(3, 3, _, { it.size() == 3 }) >> {\n-      phaser.arrive()\n-      return DDAgentApi.Response.success(200)\n-    }\n-\n-    when:\n-    (1..2).each {\n-      writer.write(trace)\n-    }\n-    // Flush the remaining 2\n-    writer.flush()\n-\n-    then:\n-    2 * serializer.serialize(_) >> { trace -> callRealMethod() }\n-    2 * serializer.getBuffer() >> { trace -> callRealMethod() }\n-    1 * api.sendSerializedTraces(2, 2, _, { it.size() == 2 }) >> DDAgentApi.Response.success(200)\n-    0 * _\n-\n-    cleanup:\n-    writer.close()\n-\n-    where:\n-    span = newSpanOf(0, \"fixed-thread-name\")\n-    trace = (0..10000).collect { span }\n-  }\n-\n   def \"test flush by time\"() {\n     setup:\n     def writer = DDAgentWriter.builder()\n       .agentApi(api)\n       .monitor(monitor)\n       .serializer(serializer)\n+      .flushFrequencySeconds(-1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAwMDIxNQ=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1Mjc5OTIxOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQxOToyNzowNVrOGWRRLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwOTo0MjoxMVrOGWvdZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAwNDc4Mg==", "bodyText": "Can you add a comment somewhere explaining how this estimation method works?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426004782", "createdAt": "2020-05-15T19:27:05Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +43,193 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean isAtCapacity() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    // reset the packer's position to zero\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5ODgyMg==", "bodyText": "Sure, but it's just a moving average of trace size, using a ring buffer to store history, with constant update/calculation time.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426498822", "createdAt": "2020-05-18T09:41:09Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +43,193 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean isAtCapacity() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    // reset the packer's position to zero\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAwNDc4Mg=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5OTQzMQ==", "bodyText": "To simplify the calculation, the ring buffer is filled with an estimate at the start, but once 16 traces have been seen, it's a real moving average of trace sizes.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426499431", "createdAt": "2020-05-18T09:42:11Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +43,193 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean isAtCapacity() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    // reset the packer's position to zero\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAwNDc4Mg=="}, "originalCommit": {"oid": "336bec7e307043d5abfe428d69b48c4f1cba1ce3"}, "originalPosition": 142}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NzQ0MzYwOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNTowMTo0NlrOGW7M5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNjo1MzozOFrOGW_uag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY5MTgxNQ==", "bodyText": "I wonder if we should limit this to 4 instead... 8 fully serialized buffers seems like a significant backlog.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426691815", "createdAt": "2020-05-18T15:01:46Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -34,12 +37,14 @@\n public class DDAgentWriter implements Writer {\n \n   private static final int DISRUPTOR_BUFFER_SIZE = 1024;\n+  private static final int OUTSTANDING_REQUESTS = 8;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc2NTkzMA==", "bodyText": "I agree. Decreases RSS too.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426765930", "createdAt": "2020-05-18T16:53:38Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -34,12 +37,14 @@\n public class DDAgentWriter implements Writer {\n \n   private static final int DISRUPTOR_BUFFER_SIZE = 1024;\n+  private static final int OUTSTANDING_REQUESTS = 8;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY5MTgxNQ=="}, "originalCommit": {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NzQ1MjQ2OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNTowMzo1M1rOGW7SuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNTowMzo1M1rOGW7SuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY5MzMwNA==", "bodyText": "Do we want to check the closed state at all in here?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426693304", "createdAt": "2020-05-18T15:03:53Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -166,20 +183,21 @@ public DDAgentApi getApi() {\n \n   @Override\n   public void start() {\n-    batchWritingDisruptor.start();\n+    dispatchingDisruptor.start();\n     traceProcessingDisruptor.start();\n     monitor.onStart(this);\n   }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178"}, "originalPosition": 148}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NzQ4OTk0OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNToxMjo0MlrOGW7rqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNToxMjo0MlrOGW7rqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY5OTY4OQ==", "bodyText": "Would it be better to shift the heartbeat logic into the constructor instead of exposing as a parameter?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426699689", "createdAt": "2020-05-18T15:12:42Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,234 @@\n package datadog.trace.common.writer.ddagent;\n \n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator<>();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1Nzc4MzA4OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNjoyMTowMVrOGW-iyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNjo1MzowN1rOGW_tPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc0NjU2OQ==", "bodyText": "Should this be called in the constructor instead?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426746569", "createdAt": "2020-05-18T16:21:01Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,234 @@\n package datadog.trace.common.writer.ddagent;\n \n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator<>();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc2NTYzMA==", "bodyText": "no, I'm not 100% sure but I don't think it's safe to.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426765630", "createdAt": "2020-05-18T16:53:07Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,234 @@\n package datadog.trace.common.writer.ddagent;\n \n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator<>();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc0NjU2OQ=="}, "originalCommit": {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178"}, "originalPosition": 165}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NzgxODIzOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNjozMDoyOVrOGW-5vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNjo1Njo1NlrOGW_1ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc1MjQ0Nw==", "bodyText": "Should this class be made generic instead to ensure the proper argument type?", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426752447", "createdAt": "2020-05-18T16:30:29Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +43,205 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n-  private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int[] traceSizeHistory = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n-  private int traceSizeSum;\n+  private int runningTraceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizeHistory, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.runningTraceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean isAtCapacity() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc2NzgxMQ==", "bodyText": "I would like to, but it ripples out a long way, and I don't want to make the change now. At the back of my mind is keeping message pack abstracted to some extent. It would be nice to easily swap out for another codec but keep the same mechanisms in place, and not hardcode to StatefulSerializer<MsgPack> or similar in DDAgentWriter. I will add a comment that this can be made generic.", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426767811", "createdAt": "2020-05-18T16:56:56Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +43,205 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n-  private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int[] traceSizeHistory = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n-  private int traceSizeSum;\n+  private int runningTraceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizeHistory, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.runningTraceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean isAtCapacity() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc1MjQ0Nw=="}, "originalCommit": {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178"}, "originalPosition": 114}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 317, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}