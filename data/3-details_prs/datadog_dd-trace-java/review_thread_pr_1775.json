{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY4MTcxMzYz", "number": 1775, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo0MTowOFrOEYnGpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxMjozNTo0NlrOEZBuWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQxOTU3OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo0MTowOFrOHBCvLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo0MTowOFrOHBCvLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NTQ2OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * traces are published in batches to the Datadog Agent}.\n          \n          \n            \n             * traces are published in batches to the Datadog Agent.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r470855469", "createdAt": "2020-08-14T20:41:08Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,239 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MessagePassingQueue;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0eaa82613a6bfd4b2a1697ca9e57c7b3cf3127e5"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQyNzcyOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo0NDo1MlrOHBC0Og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxNDowNTo1MlrOHBLMEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1Njc2Mg==", "bodyText": "If you don't restrict publishing to just heartbeats, then it doesn't matter if this is successfully added to the queue.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r470856762", "createdAt": "2020-08-14T20:44:52Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,239 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MessagePassingQueue;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.\n+ *\n+ * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n+ * the buffer is full. This is to avoid impacting an application thread.\n+ */\n+@Slf4j\n+public class TraceProcessingWorker implements AutoCloseable {\n+\n+  // empty list used to signal heartbeat, which means we could spuriously flush\n+  // if an empty list were published upstream, but care is taken in PendingTrace\n+  // and CoreTracer not to do this.\n+  private static final List<List<DDSpan>> HEARTBEAT = new ArrayList<>(0);\n+\n+  private final MpscCompoundQueue<Object> primaryQueue;\n+  private final TraceSerializingHandler serializingHandler;\n+  private final Thread serializerThread;\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this(capacity, monitor, dispatcher, new TraceProcessor(), flushInterval, timeUnit, heartbeat);\n+  }\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final TraceProcessor processor,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.doHeartbeat = heartbeat;\n+    this.primaryQueue =\n+        new MpscCompoundQueue<>(Math.max(capacity, 8), Runtime.getRuntime().availableProcessors());\n+    this.serializingHandler =\n+        new TraceSerializingHandler(\n+            primaryQueue, monitor, processor, flushInterval, timeUnit, dispatcher);\n+    this.serializerThread = DaemonThreadFactory.TRACE_PROCESSOR.newThread(serializingHandler);\n+  }\n+\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 1000, 1000, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    this.serializerThread.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    FlushEvent flush = new FlushEvent(latch);\n+    boolean offered;\n+    do {\n+      offered = primaryQueue.offer(flush);\n+    } while (!offered);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    serializerThread.interrupt();\n+  }\n+\n+  public boolean publish(final List<DDSpan> data) {\n+    return primaryQueue.offer(data);\n+  }\n+\n+  void heartbeat() {\n+    // if we don't insist on publishing a heartbeat, they might get starved out\n+    // if traces are very small, it might take quite a long time to fill the buffer,\n+    // without regular heartbeats\n+    boolean success;\n+    do {\n+      success = primaryQueue.offer(HEARTBEAT);\n+    } while (!success);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0eaa82613a6bfd4b2a1697ca9e57c7b3cf3127e5"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDk5MzkzNw==", "bodyText": "This avoids computing a timestamp once per message in the consumer thread.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r470993937", "createdAt": "2020-08-15T14:05:52Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,239 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MessagePassingQueue;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.\n+ *\n+ * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n+ * the buffer is full. This is to avoid impacting an application thread.\n+ */\n+@Slf4j\n+public class TraceProcessingWorker implements AutoCloseable {\n+\n+  // empty list used to signal heartbeat, which means we could spuriously flush\n+  // if an empty list were published upstream, but care is taken in PendingTrace\n+  // and CoreTracer not to do this.\n+  private static final List<List<DDSpan>> HEARTBEAT = new ArrayList<>(0);\n+\n+  private final MpscCompoundQueue<Object> primaryQueue;\n+  private final TraceSerializingHandler serializingHandler;\n+  private final Thread serializerThread;\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this(capacity, monitor, dispatcher, new TraceProcessor(), flushInterval, timeUnit, heartbeat);\n+  }\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final TraceProcessor processor,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.doHeartbeat = heartbeat;\n+    this.primaryQueue =\n+        new MpscCompoundQueue<>(Math.max(capacity, 8), Runtime.getRuntime().availableProcessors());\n+    this.serializingHandler =\n+        new TraceSerializingHandler(\n+            primaryQueue, monitor, processor, flushInterval, timeUnit, dispatcher);\n+    this.serializerThread = DaemonThreadFactory.TRACE_PROCESSOR.newThread(serializingHandler);\n+  }\n+\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 1000, 1000, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    this.serializerThread.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    FlushEvent flush = new FlushEvent(latch);\n+    boolean offered;\n+    do {\n+      offered = primaryQueue.offer(flush);\n+    } while (!offered);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    serializerThread.interrupt();\n+  }\n+\n+  public boolean publish(final List<DDSpan> data) {\n+    return primaryQueue.offer(data);\n+  }\n+\n+  void heartbeat() {\n+    // if we don't insist on publishing a heartbeat, they might get starved out\n+    // if traces are very small, it might take quite a long time to fill the buffer,\n+    // without regular heartbeats\n+    boolean success;\n+    do {\n+      success = primaryQueue.offer(HEARTBEAT);\n+    } while (!success);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1Njc2Mg=="}, "originalCommit": {"oid": "0eaa82613a6bfd4b2a1697ca9e57c7b3cf3127e5"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQ0MjkyOnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo1MTowNlrOHBC9aA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxMzozNjoxMlrOHBpCZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1OTExMg==", "bodyText": "If you remove this, then it doesn't matter if heartbeats are successfully added to the queue.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r470859112", "createdAt": "2020-08-14T20:51:06Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,239 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MessagePassingQueue;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.\n+ *\n+ * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n+ * the buffer is full. This is to avoid impacting an application thread.\n+ */\n+@Slf4j\n+public class TraceProcessingWorker implements AutoCloseable {\n+\n+  // empty list used to signal heartbeat, which means we could spuriously flush\n+  // if an empty list were published upstream, but care is taken in PendingTrace\n+  // and CoreTracer not to do this.\n+  private static final List<List<DDSpan>> HEARTBEAT = new ArrayList<>(0);\n+\n+  private final MpscCompoundQueue<Object> primaryQueue;\n+  private final TraceSerializingHandler serializingHandler;\n+  private final Thread serializerThread;\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this(capacity, monitor, dispatcher, new TraceProcessor(), flushInterval, timeUnit, heartbeat);\n+  }\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final TraceProcessor processor,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.doHeartbeat = heartbeat;\n+    this.primaryQueue =\n+        new MpscCompoundQueue<>(Math.max(capacity, 8), Runtime.getRuntime().availableProcessors());\n+    this.serializingHandler =\n+        new TraceSerializingHandler(\n+            primaryQueue, monitor, processor, flushInterval, timeUnit, dispatcher);\n+    this.serializerThread = DaemonThreadFactory.TRACE_PROCESSOR.newThread(serializingHandler);\n+  }\n+\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 1000, 1000, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    this.serializerThread.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    FlushEvent flush = new FlushEvent(latch);\n+    boolean offered;\n+    do {\n+      offered = primaryQueue.offer(flush);\n+    } while (!offered);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    serializerThread.interrupt();\n+  }\n+\n+  public boolean publish(final List<DDSpan> data) {\n+    return primaryQueue.offer(data);\n+  }\n+\n+  void heartbeat() {\n+    // if we don't insist on publishing a heartbeat, they might get starved out\n+    // if traces are very small, it might take quite a long time to fill the buffer,\n+    // without regular heartbeats\n+    boolean success;\n+    do {\n+      success = primaryQueue.offer(HEARTBEAT);\n+    } while (!success);\n+  }\n+\n+  public int getCapacity() {\n+    return primaryQueue.capacity();\n+  }\n+\n+  public long getRemainingCapacity() {\n+    return primaryQueue.capacity() - primaryQueue.size();\n+  }\n+\n+  public static class TraceSerializingHandler\n+      implements Runnable, MessagePassingQueue.Consumer<Object> {\n+\n+    private final MpscCompoundQueue<Object> primaryQueue;\n+    private final TraceProcessor processor;\n+    private final Monitor monitor;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+    private final PayloadDispatcher payloadDispatcher;\n+    private long nextFlushMillis;\n+\n+    public TraceSerializingHandler(\n+        final MpscCompoundQueue<Object> primaryQueue,\n+        final Monitor monitor,\n+        final TraceProcessor traceProcessor,\n+        final long flushInterval,\n+        final TimeUnit timeUnit,\n+        final PayloadDispatcher payloadDispatcher) {\n+      this.primaryQueue = primaryQueue;\n+      this.monitor = monitor;\n+      this.processor = traceProcessor;\n+      this.doTimeFlush = flushInterval > 0;\n+      this.payloadDispatcher = payloadDispatcher;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Override\n+    public void accept(Object event) {\n+      // publish an incomplete batch if\n+      // 1. we get a heartbeat, and it's time to send (early heartbeats will be ignored)\n+      // 2. a synchronous flush command is received (at shutdown)\n+      try {\n+        if (event instanceof List) {\n+          List<DDSpan> trace = (List<DDSpan>) event;\n+          if (trace.isEmpty()) { // a heartbeat", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52073b0fa4243eec9f967549a7edb567211d7e11"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDk5MzkxMA==", "bodyText": "There's more than one factor to consider here. If we don't do this, we take a timestamp for each message, just to check if it's been roughly one second since we last flushed. Timestamps aren't free: expect 25ns per call, and, depending on the deployment, can cost even 10x more. It's worth considering if forcing heartbeats into the queue could starve traces, but that could only happen if it took more than one second to process each trace.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r470993910", "createdAt": "2020-08-15T14:05:25Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,239 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MessagePassingQueue;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.\n+ *\n+ * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n+ * the buffer is full. This is to avoid impacting an application thread.\n+ */\n+@Slf4j\n+public class TraceProcessingWorker implements AutoCloseable {\n+\n+  // empty list used to signal heartbeat, which means we could spuriously flush\n+  // if an empty list were published upstream, but care is taken in PendingTrace\n+  // and CoreTracer not to do this.\n+  private static final List<List<DDSpan>> HEARTBEAT = new ArrayList<>(0);\n+\n+  private final MpscCompoundQueue<Object> primaryQueue;\n+  private final TraceSerializingHandler serializingHandler;\n+  private final Thread serializerThread;\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this(capacity, monitor, dispatcher, new TraceProcessor(), flushInterval, timeUnit, heartbeat);\n+  }\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final TraceProcessor processor,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.doHeartbeat = heartbeat;\n+    this.primaryQueue =\n+        new MpscCompoundQueue<>(Math.max(capacity, 8), Runtime.getRuntime().availableProcessors());\n+    this.serializingHandler =\n+        new TraceSerializingHandler(\n+            primaryQueue, monitor, processor, flushInterval, timeUnit, dispatcher);\n+    this.serializerThread = DaemonThreadFactory.TRACE_PROCESSOR.newThread(serializingHandler);\n+  }\n+\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 1000, 1000, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    this.serializerThread.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    FlushEvent flush = new FlushEvent(latch);\n+    boolean offered;\n+    do {\n+      offered = primaryQueue.offer(flush);\n+    } while (!offered);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    serializerThread.interrupt();\n+  }\n+\n+  public boolean publish(final List<DDSpan> data) {\n+    return primaryQueue.offer(data);\n+  }\n+\n+  void heartbeat() {\n+    // if we don't insist on publishing a heartbeat, they might get starved out\n+    // if traces are very small, it might take quite a long time to fill the buffer,\n+    // without regular heartbeats\n+    boolean success;\n+    do {\n+      success = primaryQueue.offer(HEARTBEAT);\n+    } while (!success);\n+  }\n+\n+  public int getCapacity() {\n+    return primaryQueue.capacity();\n+  }\n+\n+  public long getRemainingCapacity() {\n+    return primaryQueue.capacity() - primaryQueue.size();\n+  }\n+\n+  public static class TraceSerializingHandler\n+      implements Runnable, MessagePassingQueue.Consumer<Object> {\n+\n+    private final MpscCompoundQueue<Object> primaryQueue;\n+    private final TraceProcessor processor;\n+    private final Monitor monitor;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+    private final PayloadDispatcher payloadDispatcher;\n+    private long nextFlushMillis;\n+\n+    public TraceSerializingHandler(\n+        final MpscCompoundQueue<Object> primaryQueue,\n+        final Monitor monitor,\n+        final TraceProcessor traceProcessor,\n+        final long flushInterval,\n+        final TimeUnit timeUnit,\n+        final PayloadDispatcher payloadDispatcher) {\n+      this.primaryQueue = primaryQueue;\n+      this.monitor = monitor;\n+      this.processor = traceProcessor;\n+      this.doTimeFlush = flushInterval > 0;\n+      this.payloadDispatcher = payloadDispatcher;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Override\n+    public void accept(Object event) {\n+      // publish an incomplete batch if\n+      // 1. we get a heartbeat, and it's time to send (early heartbeats will be ignored)\n+      // 2. a synchronous flush command is received (at shutdown)\n+      try {\n+        if (event instanceof List) {\n+          List<DDSpan> trace = (List<DDSpan>) event;\n+          if (trace.isEmpty()) { // a heartbeat", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1OTExMg=="}, "originalCommit": {"oid": "52073b0fa4243eec9f967549a7edb567211d7e11"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ4Mjk4Mg==", "bodyText": "Ok, I understand now why you made that call.  If you think this is the right tradeoff to make, I support your decision.  To me it seems pretty inconsequential given all the other processing we're doing on this thread, but I guess it adds up.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r471482982", "createdAt": "2020-08-17T13:36:12Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,239 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MessagePassingQueue;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.\n+ *\n+ * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n+ * the buffer is full. This is to avoid impacting an application thread.\n+ */\n+@Slf4j\n+public class TraceProcessingWorker implements AutoCloseable {\n+\n+  // empty list used to signal heartbeat, which means we could spuriously flush\n+  // if an empty list were published upstream, but care is taken in PendingTrace\n+  // and CoreTracer not to do this.\n+  private static final List<List<DDSpan>> HEARTBEAT = new ArrayList<>(0);\n+\n+  private final MpscCompoundQueue<Object> primaryQueue;\n+  private final TraceSerializingHandler serializingHandler;\n+  private final Thread serializerThread;\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this(capacity, monitor, dispatcher, new TraceProcessor(), flushInterval, timeUnit, heartbeat);\n+  }\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final TraceProcessor processor,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.doHeartbeat = heartbeat;\n+    this.primaryQueue =\n+        new MpscCompoundQueue<>(Math.max(capacity, 8), Runtime.getRuntime().availableProcessors());\n+    this.serializingHandler =\n+        new TraceSerializingHandler(\n+            primaryQueue, monitor, processor, flushInterval, timeUnit, dispatcher);\n+    this.serializerThread = DaemonThreadFactory.TRACE_PROCESSOR.newThread(serializingHandler);\n+  }\n+\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 1000, 1000, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    this.serializerThread.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    FlushEvent flush = new FlushEvent(latch);\n+    boolean offered;\n+    do {\n+      offered = primaryQueue.offer(flush);\n+    } while (!offered);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    serializerThread.interrupt();\n+  }\n+\n+  public boolean publish(final List<DDSpan> data) {\n+    return primaryQueue.offer(data);\n+  }\n+\n+  void heartbeat() {\n+    // if we don't insist on publishing a heartbeat, they might get starved out\n+    // if traces are very small, it might take quite a long time to fill the buffer,\n+    // without regular heartbeats\n+    boolean success;\n+    do {\n+      success = primaryQueue.offer(HEARTBEAT);\n+    } while (!success);\n+  }\n+\n+  public int getCapacity() {\n+    return primaryQueue.capacity();\n+  }\n+\n+  public long getRemainingCapacity() {\n+    return primaryQueue.capacity() - primaryQueue.size();\n+  }\n+\n+  public static class TraceSerializingHandler\n+      implements Runnable, MessagePassingQueue.Consumer<Object> {\n+\n+    private final MpscCompoundQueue<Object> primaryQueue;\n+    private final TraceProcessor processor;\n+    private final Monitor monitor;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+    private final PayloadDispatcher payloadDispatcher;\n+    private long nextFlushMillis;\n+\n+    public TraceSerializingHandler(\n+        final MpscCompoundQueue<Object> primaryQueue,\n+        final Monitor monitor,\n+        final TraceProcessor traceProcessor,\n+        final long flushInterval,\n+        final TimeUnit timeUnit,\n+        final PayloadDispatcher payloadDispatcher) {\n+      this.primaryQueue = primaryQueue;\n+      this.monitor = monitor;\n+      this.processor = traceProcessor;\n+      this.doTimeFlush = flushInterval > 0;\n+      this.payloadDispatcher = payloadDispatcher;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Override\n+    public void accept(Object event) {\n+      // publish an incomplete batch if\n+      // 1. we get a heartbeat, and it's time to send (early heartbeats will be ignored)\n+      // 2. a synchronous flush command is received (at shutdown)\n+      try {\n+        if (event instanceof List) {\n+          List<DDSpan> trace = (List<DDSpan>) event;\n+          if (trace.isEmpty()) { // a heartbeat", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1OTExMg=="}, "originalCommit": {"oid": "52073b0fa4243eec9f967549a7edb567211d7e11"}, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQ1MTc0OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo1NDozM1rOHBDCmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxMzo1ODoxOVrOHBLJjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2MDQ0MQ==", "bodyText": "Any risk of an object that isn't these two types being added to the queue?\nIf so it looks like it'll just be ignored, so I guess it doesn't matter.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r470860441", "createdAt": "2020-08-14T20:54:33Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,239 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MessagePassingQueue;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.\n+ *\n+ * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n+ * the buffer is full. This is to avoid impacting an application thread.\n+ */\n+@Slf4j\n+public class TraceProcessingWorker implements AutoCloseable {\n+\n+  // empty list used to signal heartbeat, which means we could spuriously flush\n+  // if an empty list were published upstream, but care is taken in PendingTrace\n+  // and CoreTracer not to do this.\n+  private static final List<List<DDSpan>> HEARTBEAT = new ArrayList<>(0);\n+\n+  private final MpscCompoundQueue<Object> primaryQueue;\n+  private final TraceSerializingHandler serializingHandler;\n+  private final Thread serializerThread;\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this(capacity, monitor, dispatcher, new TraceProcessor(), flushInterval, timeUnit, heartbeat);\n+  }\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final TraceProcessor processor,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.doHeartbeat = heartbeat;\n+    this.primaryQueue =\n+        new MpscCompoundQueue<>(Math.max(capacity, 8), Runtime.getRuntime().availableProcessors());\n+    this.serializingHandler =\n+        new TraceSerializingHandler(\n+            primaryQueue, monitor, processor, flushInterval, timeUnit, dispatcher);\n+    this.serializerThread = DaemonThreadFactory.TRACE_PROCESSOR.newThread(serializingHandler);\n+  }\n+\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 1000, 1000, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    this.serializerThread.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    FlushEvent flush = new FlushEvent(latch);\n+    boolean offered;\n+    do {\n+      offered = primaryQueue.offer(flush);\n+    } while (!offered);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    serializerThread.interrupt();\n+  }\n+\n+  public boolean publish(final List<DDSpan> data) {\n+    return primaryQueue.offer(data);\n+  }\n+\n+  void heartbeat() {\n+    // if we don't insist on publishing a heartbeat, they might get starved out\n+    // if traces are very small, it might take quite a long time to fill the buffer,\n+    // without regular heartbeats\n+    boolean success;\n+    do {\n+      success = primaryQueue.offer(HEARTBEAT);\n+    } while (!success);\n+  }\n+\n+  public int getCapacity() {\n+    return primaryQueue.capacity();\n+  }\n+\n+  public long getRemainingCapacity() {\n+    return primaryQueue.capacity() - primaryQueue.size();\n+  }\n+\n+  public static class TraceSerializingHandler\n+      implements Runnable, MessagePassingQueue.Consumer<Object> {\n+\n+    private final MpscCompoundQueue<Object> primaryQueue;\n+    private final TraceProcessor processor;\n+    private final Monitor monitor;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+    private final PayloadDispatcher payloadDispatcher;\n+    private long nextFlushMillis;\n+\n+    public TraceSerializingHandler(\n+        final MpscCompoundQueue<Object> primaryQueue,\n+        final Monitor monitor,\n+        final TraceProcessor traceProcessor,\n+        final long flushInterval,\n+        final TimeUnit timeUnit,\n+        final PayloadDispatcher payloadDispatcher) {\n+      this.primaryQueue = primaryQueue;\n+      this.monitor = monitor;\n+      this.processor = traceProcessor;\n+      this.doTimeFlush = flushInterval > 0;\n+      this.payloadDispatcher = payloadDispatcher;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Override\n+    public void accept(Object event) {\n+      // publish an incomplete batch if\n+      // 1. we get a heartbeat, and it's time to send (early heartbeats will be ignored)\n+      // 2. a synchronous flush command is received (at shutdown)\n+      try {\n+        if (event instanceof List) {\n+          List<DDSpan> trace = (List<DDSpan>) event;\n+          if (trace.isEmpty()) { // a heartbeat\n+            if (doTimeFlush && millisecondTime() > nextFlushMillis) {\n+              payloadDispatcher.flush();\n+              scheduleNextTimeFlush();\n+            }\n+          } else {\n+            // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+            payloadDispatcher.addTrace(processor.onTraceComplete(trace));\n+          }\n+        } else if (event instanceof FlushEvent) {\n+          payloadDispatcher.flush();\n+          ((FlushEvent) event).sync();\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b71e52786c042b2486ce0b2552f57da78705e03"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDk5MzI5Mw==", "bodyText": "In a perfect world Java would have sum types and we'd be able to use types like List<DDSpan> | FlushEvent without materialising a wrapper, but we can't, and I don't want to allocate a wrapper per trace. I think it's important that this is properly encapsulated, that we don't let arbitrary types to published into the queue from outside of TraceProcessingWorker.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r470993293", "createdAt": "2020-08-15T13:58:19Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,239 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MessagePassingQueue;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.\n+ *\n+ * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n+ * the buffer is full. This is to avoid impacting an application thread.\n+ */\n+@Slf4j\n+public class TraceProcessingWorker implements AutoCloseable {\n+\n+  // empty list used to signal heartbeat, which means we could spuriously flush\n+  // if an empty list were published upstream, but care is taken in PendingTrace\n+  // and CoreTracer not to do this.\n+  private static final List<List<DDSpan>> HEARTBEAT = new ArrayList<>(0);\n+\n+  private final MpscCompoundQueue<Object> primaryQueue;\n+  private final TraceSerializingHandler serializingHandler;\n+  private final Thread serializerThread;\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this(capacity, monitor, dispatcher, new TraceProcessor(), flushInterval, timeUnit, heartbeat);\n+  }\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final TraceProcessor processor,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.doHeartbeat = heartbeat;\n+    this.primaryQueue =\n+        new MpscCompoundQueue<>(Math.max(capacity, 8), Runtime.getRuntime().availableProcessors());\n+    this.serializingHandler =\n+        new TraceSerializingHandler(\n+            primaryQueue, monitor, processor, flushInterval, timeUnit, dispatcher);\n+    this.serializerThread = DaemonThreadFactory.TRACE_PROCESSOR.newThread(serializingHandler);\n+  }\n+\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 1000, 1000, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    this.serializerThread.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    FlushEvent flush = new FlushEvent(latch);\n+    boolean offered;\n+    do {\n+      offered = primaryQueue.offer(flush);\n+    } while (!offered);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    serializerThread.interrupt();\n+  }\n+\n+  public boolean publish(final List<DDSpan> data) {\n+    return primaryQueue.offer(data);\n+  }\n+\n+  void heartbeat() {\n+    // if we don't insist on publishing a heartbeat, they might get starved out\n+    // if traces are very small, it might take quite a long time to fill the buffer,\n+    // without regular heartbeats\n+    boolean success;\n+    do {\n+      success = primaryQueue.offer(HEARTBEAT);\n+    } while (!success);\n+  }\n+\n+  public int getCapacity() {\n+    return primaryQueue.capacity();\n+  }\n+\n+  public long getRemainingCapacity() {\n+    return primaryQueue.capacity() - primaryQueue.size();\n+  }\n+\n+  public static class TraceSerializingHandler\n+      implements Runnable, MessagePassingQueue.Consumer<Object> {\n+\n+    private final MpscCompoundQueue<Object> primaryQueue;\n+    private final TraceProcessor processor;\n+    private final Monitor monitor;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+    private final PayloadDispatcher payloadDispatcher;\n+    private long nextFlushMillis;\n+\n+    public TraceSerializingHandler(\n+        final MpscCompoundQueue<Object> primaryQueue,\n+        final Monitor monitor,\n+        final TraceProcessor traceProcessor,\n+        final long flushInterval,\n+        final TimeUnit timeUnit,\n+        final PayloadDispatcher payloadDispatcher) {\n+      this.primaryQueue = primaryQueue;\n+      this.monitor = monitor;\n+      this.processor = traceProcessor;\n+      this.doTimeFlush = flushInterval > 0;\n+      this.payloadDispatcher = payloadDispatcher;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Override\n+    public void accept(Object event) {\n+      // publish an incomplete batch if\n+      // 1. we get a heartbeat, and it's time to send (early heartbeats will be ignored)\n+      // 2. a synchronous flush command is received (at shutdown)\n+      try {\n+        if (event instanceof List) {\n+          List<DDSpan> trace = (List<DDSpan>) event;\n+          if (trace.isEmpty()) { // a heartbeat\n+            if (doTimeFlush && millisecondTime() > nextFlushMillis) {\n+              payloadDispatcher.flush();\n+              scheduleNextTimeFlush();\n+            }\n+          } else {\n+            // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+            payloadDispatcher.addTrace(processor.onTraceComplete(trace));\n+          }\n+        } else if (event instanceof FlushEvent) {\n+          payloadDispatcher.flush();\n+          ((FlushEvent) event).sync();\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2MDQ0MQ=="}, "originalCommit": {"oid": "5b71e52786c042b2486ce0b2552f57da78705e03"}, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQ2NDQ1OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/dd-trace-core.gradle", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo1OToxNFrOHBDJ6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxMzozODoyMVrOHBpHag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2MjMxNQ==", "bodyText": "How much bigger is this?", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r470862315", "createdAt": "2020-08-14T20:59:14Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/dd-trace-core.gradle", "diffHunk": "@@ -38,7 +38,8 @@ dependencies {\n   compile deps.okhttp\n   compile group: 'com.squareup.moshi', name: 'moshi', version: '1.9.2'\n   compile group: 'com.github.jnr', name: 'jnr-unixsocket', version: \"${versions.jnr_unixsocket}\"\n-  compile group: 'com.lmax', name: 'disruptor', version: '3.4.2'\n+  compile group: 'org.jctools', name: 'jctools-core', version: '3.1.0'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b71e52786c042b2486ce0b2552f57da78705e03"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDk4OTcxNg==", "bodyText": "316KB, whereas disruptor is 81KB. For comparison, we shed 116KB when we dropped msgpack-core, and guava is, er, 2.7MB. JCTools contains lots of other quality data structures which we can probably leverage to eliminate other dependencies.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r470989716", "createdAt": "2020-08-15T13:48:37Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/dd-trace-core.gradle", "diffHunk": "@@ -38,7 +38,8 @@ dependencies {\n   compile deps.okhttp\n   compile group: 'com.squareup.moshi', name: 'moshi', version: '1.9.2'\n   compile group: 'com.github.jnr', name: 'jnr-unixsocket', version: \"${versions.jnr_unixsocket}\"\n-  compile group: 'com.lmax', name: 'disruptor', version: '3.4.2'\n+  compile group: 'org.jctools', name: 'jctools-core', version: '3.1.0'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2MjMxNQ=="}, "originalCommit": {"oid": "5b71e52786c042b2486ce0b2552f57da78705e03"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ4MDEyNQ==", "bodyText": "I'm not concerned... just wanted to make sure it wasn't as big as guava.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r471480125", "createdAt": "2020-08-17T13:31:26Z", "author": {"login": "tylerbenson"}, "path": "dd-trace-core/dd-trace-core.gradle", "diffHunk": "@@ -38,7 +38,8 @@ dependencies {\n   compile deps.okhttp\n   compile group: 'com.squareup.moshi', name: 'moshi', version: '1.9.2'\n   compile group: 'com.github.jnr', name: 'jnr-unixsocket', version: \"${versions.jnr_unixsocket}\"\n-  compile group: 'com.lmax', name: 'disruptor', version: '3.4.2'\n+  compile group: 'org.jctools', name: 'jctools-core', version: '3.1.0'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2MjMxNQ=="}, "originalCommit": {"oid": "5b71e52786c042b2486ce0b2552f57da78705e03"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ4NDI2Ng==", "bodyText": "Not \"as big as guava\" is a pretty low bar to aim for \ud83d\ude06", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r471484266", "createdAt": "2020-08-17T13:38:21Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/dd-trace-core.gradle", "diffHunk": "@@ -38,7 +38,8 @@ dependencies {\n   compile deps.okhttp\n   compile group: 'com.squareup.moshi', name: 'moshi', version: '1.9.2'\n   compile group: 'com.github.jnr', name: 'jnr-unixsocket', version: \"${versions.jnr_unixsocket}\"\n-  compile group: 'com.lmax', name: 'disruptor', version: '3.4.2'\n+  compile group: 'org.jctools', name: 'jctools-core', version: '3.1.0'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2MjMxNQ=="}, "originalCommit": {"oid": "5b71e52786c042b2486ce0b2552f57da78705e03"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0Njc4MTA0OnYy", "diffSide": "RIGHT", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxMjozNTo0NlrOHBm5jQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxMzoxNjo0MlrOHBoTMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ0Nzk0OQ==", "bodyText": "So System.nanoTime() is a relative time, and the value can be negative (there is no guarantee that the value starts at 0). How does NANOSECONDS.toMillis deal with that? Also, the comparison needs to be done relative to a start time since the counter could potentially wrap in the middle of an interval.", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r471447949", "createdAt": "2020-08-17T12:35:46Z", "author": {"login": "bantonsson"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,241 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static datadog.trace.core.util.ThreadUtil.onSpinWait;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.\n+ *\n+ * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n+ * the buffer is full. This is to avoid impacting an application thread.\n+ */\n+@Slf4j\n+public class TraceProcessingWorker implements AutoCloseable {\n+\n+  // empty list used to signal heartbeat, which means we could spuriously flush\n+  // if an empty list were published upstream, but care is taken in PendingTrace\n+  // and CoreTracer not to do this.\n+  private static final List<List<DDSpan>> HEARTBEAT = new ArrayList<>(0);\n+\n+  private final MpscCompoundQueue<Object> primaryQueue;\n+  private final TraceSerializingHandler serializingHandler;\n+  private final Thread serializerThread;\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this(capacity, monitor, dispatcher, new TraceProcessor(), flushInterval, timeUnit, heartbeat);\n+  }\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final TraceProcessor processor,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.doHeartbeat = heartbeat;\n+    int parallelism = Runtime.getRuntime().availableProcessors();\n+    this.primaryQueue = new MpscCompoundQueue<>(Math.max(capacity, parallelism), parallelism);\n+    this.serializingHandler =\n+        new TraceSerializingHandler(\n+            primaryQueue, monitor, processor, flushInterval, timeUnit, dispatcher);\n+    this.serializerThread = DaemonThreadFactory.TRACE_PROCESSOR.newThread(serializingHandler);\n+  }\n+\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 1000, 1000, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    this.serializerThread.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    FlushEvent flush = new FlushEvent(latch);\n+    boolean offered;\n+    do {\n+      offered = primaryQueue.offer(flush);\n+    } while (!offered);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    serializerThread.interrupt();\n+  }\n+\n+  public boolean publish(final List<DDSpan> data) {\n+    return primaryQueue.offer(data);\n+  }\n+\n+  void heartbeat() {\n+    // if we don't insist on publishing a heartbeat, they might get starved out\n+    // if traces are very small, it might take quite a long time to fill the buffer,\n+    // without regular heartbeats\n+    boolean success;\n+    do {\n+      success = primaryQueue.offer(HEARTBEAT);\n+    } while (!success);\n+  }\n+\n+  public int getCapacity() {\n+    return primaryQueue.capacity();\n+  }\n+\n+  public long getRemainingCapacity() {\n+    return primaryQueue.capacity() - primaryQueue.size();\n+  }\n+\n+  public static class TraceSerializingHandler implements Runnable {\n+\n+    private final MpscCompoundQueue<Object> primaryQueue;\n+    private final TraceProcessor processor;\n+    private final Monitor monitor;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+    private final PayloadDispatcher payloadDispatcher;\n+    private long nextFlushMillis;\n+\n+    public TraceSerializingHandler(\n+        final MpscCompoundQueue<Object> primaryQueue,\n+        final Monitor monitor,\n+        final TraceProcessor traceProcessor,\n+        final long flushInterval,\n+        final TimeUnit timeUnit,\n+        final PayloadDispatcher payloadDispatcher) {\n+      this.primaryQueue = primaryQueue;\n+      this.monitor = monitor;\n+      this.processor = traceProcessor;\n+      this.doTimeFlush = flushInterval > 0;\n+      this.payloadDispatcher = payloadDispatcher;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    public void onEvent(Object event) {\n+      // publish an incomplete batch if\n+      // 1. we get a heartbeat, and it's time to send (early heartbeats will be ignored)\n+      // 2. a synchronous flush command is received (at shutdown)\n+      try {\n+        if (event instanceof List) {\n+          List<DDSpan> trace = (List<DDSpan>) event;\n+          if (trace.isEmpty()) { // a heartbeat\n+            if (doTimeFlush && millisecondTime() > nextFlushMillis) {\n+              payloadDispatcher.flush();\n+              scheduleNextTimeFlush();\n+            }\n+          } else {\n+            // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+            payloadDispatcher.addTrace(processor.onTraceComplete(trace));\n+          }\n+        } else if (event instanceof FlushEvent) {\n+          payloadDispatcher.flush();\n+          ((FlushEvent) event).sync();\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n+        }\n+        List<DDSpan> data = event instanceof List ? (List<DDSpan>) event : null;\n+        monitor.onFailedSerialize(data, e);\n+      }\n+    }\n+\n+    private void scheduleNextTimeFlush() {\n+      if (doTimeFlush) {\n+        nextFlushMillis = millisecondTime() + flushIntervalMillis;\n+      }\n+    }\n+\n+    private long millisecondTime() {\n+      // important: nanoTime is monotonic, currentTimeMillis is not\n+      return NANOSECONDS.toMillis(System.nanoTime());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19cd528c20b9ed905ac9af72206863206e4dd083"}, "originalPosition": 193}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ3MDg5Nw==", "bodyText": "This is old code but please take a look at the latest commit and let me know if it addresses your concerns", "url": "https://github.com/DataDog/dd-trace-java/pull/1775#discussion_r471470897", "createdAt": "2020-08-17T13:16:42Z", "author": {"login": "richardstartin"}, "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingWorker.java", "diffHunk": "@@ -0,0 +1,241 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import static datadog.trace.core.util.ThreadUtil.onSpinWait;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import datadog.common.exec.CommonTaskExecutor;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.core.DDSpan;\n+import datadog.trace.core.monitor.Monitor;\n+import datadog.trace.core.processor.TraceProcessor;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MpscCompoundQueue;\n+\n+/**\n+ * Worker which applies rules to traces and serializes the results. Upon completion, the serialized\n+ * traces are published in batches to the Datadog Agent}.\n+ *\n+ * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n+ * the buffer is full. This is to avoid impacting an application thread.\n+ */\n+@Slf4j\n+public class TraceProcessingWorker implements AutoCloseable {\n+\n+  // empty list used to signal heartbeat, which means we could spuriously flush\n+  // if an empty list were published upstream, but care is taken in PendingTrace\n+  // and CoreTracer not to do this.\n+  private static final List<List<DDSpan>> HEARTBEAT = new ArrayList<>(0);\n+\n+  private final MpscCompoundQueue<Object> primaryQueue;\n+  private final TraceSerializingHandler serializingHandler;\n+  private final Thread serializerThread;\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this(capacity, monitor, dispatcher, new TraceProcessor(), flushInterval, timeUnit, heartbeat);\n+  }\n+\n+  public TraceProcessingWorker(\n+      final int capacity,\n+      final Monitor monitor,\n+      final PayloadDispatcher dispatcher,\n+      final TraceProcessor processor,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.doHeartbeat = heartbeat;\n+    int parallelism = Runtime.getRuntime().availableProcessors();\n+    this.primaryQueue = new MpscCompoundQueue<>(Math.max(capacity, parallelism), parallelism);\n+    this.serializingHandler =\n+        new TraceSerializingHandler(\n+            primaryQueue, monitor, processor, flushInterval, timeUnit, dispatcher);\n+    this.serializerThread = DaemonThreadFactory.TRACE_PROCESSOR.newThread(serializingHandler);\n+  }\n+\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 1000, 1000, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    this.serializerThread.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    FlushEvent flush = new FlushEvent(latch);\n+    boolean offered;\n+    do {\n+      offered = primaryQueue.offer(flush);\n+    } while (!offered);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    serializerThread.interrupt();\n+  }\n+\n+  public boolean publish(final List<DDSpan> data) {\n+    return primaryQueue.offer(data);\n+  }\n+\n+  void heartbeat() {\n+    // if we don't insist on publishing a heartbeat, they might get starved out\n+    // if traces are very small, it might take quite a long time to fill the buffer,\n+    // without regular heartbeats\n+    boolean success;\n+    do {\n+      success = primaryQueue.offer(HEARTBEAT);\n+    } while (!success);\n+  }\n+\n+  public int getCapacity() {\n+    return primaryQueue.capacity();\n+  }\n+\n+  public long getRemainingCapacity() {\n+    return primaryQueue.capacity() - primaryQueue.size();\n+  }\n+\n+  public static class TraceSerializingHandler implements Runnable {\n+\n+    private final MpscCompoundQueue<Object> primaryQueue;\n+    private final TraceProcessor processor;\n+    private final Monitor monitor;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+    private final PayloadDispatcher payloadDispatcher;\n+    private long nextFlushMillis;\n+\n+    public TraceSerializingHandler(\n+        final MpscCompoundQueue<Object> primaryQueue,\n+        final Monitor monitor,\n+        final TraceProcessor traceProcessor,\n+        final long flushInterval,\n+        final TimeUnit timeUnit,\n+        final PayloadDispatcher payloadDispatcher) {\n+      this.primaryQueue = primaryQueue;\n+      this.monitor = monitor;\n+      this.processor = traceProcessor;\n+      this.doTimeFlush = flushInterval > 0;\n+      this.payloadDispatcher = payloadDispatcher;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    public void onEvent(Object event) {\n+      // publish an incomplete batch if\n+      // 1. we get a heartbeat, and it's time to send (early heartbeats will be ignored)\n+      // 2. a synchronous flush command is received (at shutdown)\n+      try {\n+        if (event instanceof List) {\n+          List<DDSpan> trace = (List<DDSpan>) event;\n+          if (trace.isEmpty()) { // a heartbeat\n+            if (doTimeFlush && millisecondTime() > nextFlushMillis) {\n+              payloadDispatcher.flush();\n+              scheduleNextTimeFlush();\n+            }\n+          } else {\n+            // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+            payloadDispatcher.addTrace(processor.onTraceComplete(trace));\n+          }\n+        } else if (event instanceof FlushEvent) {\n+          payloadDispatcher.flush();\n+          ((FlushEvent) event).sync();\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n+        }\n+        List<DDSpan> data = event instanceof List ? (List<DDSpan>) event : null;\n+        monitor.onFailedSerialize(data, e);\n+      }\n+    }\n+\n+    private void scheduleNextTimeFlush() {\n+      if (doTimeFlush) {\n+        nextFlushMillis = millisecondTime() + flushIntervalMillis;\n+      }\n+    }\n+\n+    private long millisecondTime() {\n+      // important: nanoTime is monotonic, currentTimeMillis is not\n+      return NANOSECONDS.toMillis(System.nanoTime());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ0Nzk0OQ=="}, "originalCommit": {"oid": "19cd528c20b9ed905ac9af72206863206e4dd083"}, "originalPosition": 193}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 28, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}