{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIyNDE2Nzc1", "number": 2303, "title": "Add Kafka based downstream client", "bodyText": "Replaces #2216.\n\nI have not tested it yet with the Quarkus based adapters.\nOnly tested manually, integration tests are still missing.\nI have added new Spring Conditions to enable a clean control of the selection between AMQP and Kafka. @sophokles73, now I have seen that you have taken steps in AbstractAdapterConfig to move away from Spring Boot. What is your strategy there? Do you want to remove the bean creation by Spring Boot entirely?", "createdAt": "2020-11-17T13:38:04Z", "url": "https://github.com/eclipse/hono/pull/2303", "merged": true, "mergeCommit": {"oid": "d42d616f8e962041d237b106d375064cd4c1fe19"}, "closed": true, "closedAt": "2020-12-17T17:15:54Z", "author": {"login": "b-abel"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABddbY_FAFqTUzMjQ2Nzk3OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdnGy9BAFqTU1NDgxNDYyNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyNDY3OTc4", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-532467978", "createdAt": "2020-11-17T15:15:05Z", "commit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxNToxNTowNVrOH05w7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxNTozNTowMlrOH07KUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzNDQxMw==", "bodyText": "why do we need to keep this at Java 1.8 level?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525234413", "createdAt": "2020-11-17T15:15:05Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/pom.xml", "diffHunk": "@@ -0,0 +1,143 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+    Copyright (c) 2020 Contributors to the Eclipse Foundation\n+\n+    See the NOTICE file(s) distributed with this work for additional\n+    information regarding copyright ownership.\n+\n+    This program and the accompanying materials are made available under the\n+    terms of the Eclipse Public License 2.0 which is available at\n+    http://www.eclipse.org/legal/epl-2.0\n+\n+    SPDX-License-Identifier: EPL-2.0\n+ -->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <groupId>org.eclipse.hono</groupId>\n+        <artifactId>hono-clients-parent</artifactId>\n+        <version>1.5.0-SNAPSHOT</version>\n+    </parent>\n+    <artifactId>hono-client-kafka-common</artifactId>\n+\n+    <name>Hono Client Kafka Common</name>\n+    <description>Classes required for implementing Kafka based Hono clients</description>\n+\n+    <properties>\n+        <maven.compiler.source>1.8</maven.compiler.source>\n+        <maven.compiler.target>1.8</maven.compiler.target>\n+    </properties>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzODgxMQ==", "bodyText": "this seems to be the most often used method, isn't it? Given that this class is immutable, we should probably create the string representation once during construction instead of concatenating the strings over and over again ...", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525238811", "createdAt": "2020-11-17T15:20:29Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/HonoTopic.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.Objects;\n+\n+import org.eclipse.hono.util.CommandConstants;\n+import org.eclipse.hono.util.EventConstants;\n+import org.eclipse.hono.util.TelemetryConstants;\n+\n+/**\n+ * Identifier for Hono's topics. The Kafka topic string is obtained by {@link #toString()}.\n+ */\n+public final class HonoTopic {\n+\n+    private static final String SEPARATOR = \".\";\n+    private static final String NAMESPACE = \"hono\" + SEPARATOR;\n+\n+    private final Type type;\n+    private final String tenantId;\n+\n+    /**\n+     * Creates a new topic from the given topic type and tenant ID.\n+     *\n+     * @param type The type of the topic.\n+     * @param tenantId The ID of the tenant that the topic belongs to.\n+     * @throws NullPointerException if any of the parameters is {@code null}.\n+     */\n+    public HonoTopic(final Type type, final String tenantId) {\n+        Objects.requireNonNull(type);\n+        Objects.requireNonNull(tenantId);\n+\n+        this.type = type;\n+        this.tenantId = tenantId;\n+    }\n+\n+    /**\n+     * Creates a topic instance from the string representation.\n+     *\n+     * @param topicString The string to create a topic from.\n+     * @return The topic or {@code null} if the string does not contain a valid Hono topic.\n+     */\n+    public static HonoTopic fromString(final String topicString) {\n+        if (topicString.startsWith(Type.TELEMETRY.prefix)) {\n+            return new HonoTopic(Type.TELEMETRY, topicString.substring(Type.TELEMETRY.prefix.length()));\n+        } else if (topicString.startsWith(Type.EVENT.prefix)) {\n+            return new HonoTopic(Type.EVENT, topicString.substring(Type.EVENT.prefix.length()));\n+        } else if (topicString.startsWith(Type.COMMAND.prefix)) {\n+            return new HonoTopic(Type.COMMAND, topicString.substring(Type.COMMAND.prefix.length()));\n+        } else if (topicString.startsWith(Type.COMMAND_RESPONSE.prefix)) {\n+            return new HonoTopic(Type.COMMAND_RESPONSE, topicString.substring(Type.COMMAND_RESPONSE.prefix.length()));\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Gets the type of the topic.\n+     *\n+     * @return The type.\n+     */\n+    public Type getType() {\n+        return type;\n+    }\n+\n+    /**\n+     * Gets the tenant ID of the topic.\n+     *\n+     * @return The tenant ID.\n+     */\n+    public String getTenantId() {\n+        return tenantId;\n+    }\n+\n+    /**\n+     * Returns the string representation of the topic as used by the Kafka client.\n+     *\n+     * @return The topic as a string.\n+     */\n+    @Override\n+    public String toString() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzOTgwNA==", "bodyText": "do we really need this in the main source tree or can this go into the test folder?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525239804", "createdAt": "2020-11-17T15:21:42Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/test/FakeProducer.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.test;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0MDA4OA==", "bodyText": "test folder?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525240088", "createdAt": "2020-11-17T15:22:03Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/test/TestHelper.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.test;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0MzA5Mw==", "bodyText": "IMHO these values should be logged to a span but should not be set as tags ... I doubt that you will filter/search spans based on these values, will you?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525243093", "createdAt": "2020-11-17T15:25:01Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/KafkaTracingHelper.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import java.util.Objects;\n+\n+import org.eclipse.hono.kafka.client.HonoTopic;\n+import org.eclipse.hono.tracing.TracingHelper;\n+\n+import io.opentracing.Span;\n+import io.opentracing.SpanContext;\n+import io.opentracing.Tracer;\n+import io.opentracing.noop.NoopSpanContext;\n+import io.opentracing.propagation.Format;\n+import io.opentracing.tag.IntTag;\n+import io.opentracing.tag.Tags;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.kafka.client.producer.KafkaProducerRecord;\n+import io.vertx.kafka.client.producer.RecordMetadata;\n+\n+/**\n+ * A helper class providing Kafka-specific utility methods for interacting with the OpenTracing API.\n+ *\n+ */\n+// TODO align with Kafka tracing support in Vert.x 4.0\n+public final class KafkaTracingHelper {\n+\n+    /**\n+     * An OpenTracing tag that contains the offset of a Kafka record.\n+     */\n+    public static final LongTag TAG_OFFSET = new LongTag(\"offset\");\n+\n+    /**\n+     * An OpenTracing tag that contains the partition of a Kafka record.\n+     */\n+    public static final IntTag TAG_PARTITION = new IntTag(\"partition\");\n+\n+    /**\n+     * An OpenTracing tag that contains the timestamp of a Kafka record.\n+     */\n+    public static final LongTag TAG_TIMESTAMP = new LongTag(\"timestamp\");\n+\n+    private KafkaTracingHelper() {\n+        // prevent instantiation\n+    }\n+\n+    /**\n+     * Creates a new <em>OpenTracing</em> span to trace producing messages to Kafka.\n+     * <p>\n+     * The returned span will already contain the following tags:\n+     * <ul>\n+     * <li>{@link Tags#COMPONENT} - set to <em>hono-client-kafka</em></li>\n+     * <li>{@link Tags#MESSAGE_BUS_DESTINATION} - set to {@code To_<topic>}</li>\n+     * <li>{@link Tags#SPAN_KIND} - set to {@link Tags#SPAN_KIND_PRODUCER}</li>\n+     * <li>{@link Tags#PEER_SERVICE} - set to <em>kafka</em></li>\n+     * </ul>\n+     *\n+     * @param tracer The Tracer to use.\n+     * @param topic The topic from which the operation name is derived.\n+     * @param referenceType The type of reference towards the span context.\n+     * @param parent The span context to set as parent and to derive the sampling priority from (may be null).\n+     * @return The new span.\n+     * @throws NullPointerException if tracer or topic is {@code null}.\n+     */\n+    public static Span newProducerSpan(final Tracer tracer, final HonoTopic topic, final String referenceType,\n+            final SpanContext parent) {\n+        Objects.requireNonNull(tracer);\n+        Objects.requireNonNull(topic);\n+        Objects.requireNonNull(referenceType);\n+\n+        return TracingHelper.buildSpan(tracer, parent, \"To_\" + topic.toString(), referenceType)\n+                .ignoreActiveSpan()\n+                .withTag(Tags.COMPONENT.getKey(), \"hono-client-kafka\")\n+                .withTag(Tags.SPAN_KIND.getKey(), Tags.SPAN_KIND_PRODUCER)\n+                .withTag(Tags.MESSAGE_BUS_DESTINATION.getKey(), topic.toString())\n+                .withTag(Tags.PEER_SERVICE.getKey(), \"kafka\")\n+                .start();\n+    }\n+\n+    /**\n+     * Sets tags from record metadata.\n+     * <p>\n+     * It sets the following tags:\n+     * <ul>\n+     * <li>{@link #TAG_OFFSET}</li>\n+     * <li>{@link #TAG_PARTITION}</li>\n+     * <li>{@link #TAG_TIMESTAMP}</li>\n+     * </ul>\n+     * <p>\n+     * <em>It does not set the topic, as this is expected to be already already set.</em>\n+     *\n+     * @param span The span to set the tags on.\n+     * @param recordMetadata The record metadata.\n+     */\n+    public static void setRecordMetadataTags(final Span span, final RecordMetadata recordMetadata) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0NDQ0Mw==", "bodyText": "this doesn't seem to be kafka specific, is it?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525244443", "createdAt": "2020-11-17T15:25:54Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/LongTag.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import io.opentracing.Span;\n+import io.opentracing.tag.AbstractTag;\n+\n+/**\n+ * An OpenTracing tag type for {@code long} values.\n+ */\n+public class LongTag extends AbstractTag<Long> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI1NTE3OQ==", "bodyText": "can we keep the AMQP related beans together?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525255179", "createdAt": "2020-11-17T15:32:51Z", "author": {"login": "sophokles73"}, "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -248,11 +281,24 @@ protected ClientConfigProperties getDownstreamSenderFactoryConfigDefaults() {\n      */\n     @Qualifier(Constants.QUALIFIER_MESSAGING)\n     @Bean\n+    @ConditionalOnAmqpMessaging\n     @Scope(\"prototype\")\n     public HonoConnection downstreamConnection() {\n         return HonoConnection.newConnection(vertx(), downstreamSenderFactoryConfig());\n     }\n \n+    /**\n+     * Exposes a factory for creating producers for sending downstream messages via the Kafka cluster.\n+     *\n+     * @return The factory.\n+     */\n+    @Bean\n+    @Scope(\"prototype\")\n+    @ConditionalOnKafkaMessaging\n+    public CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory() {\n+        return CachingKafkaProducerFactory.sharedProducerFactory(vertx());\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI1NzI5OA==", "bodyText": "IMHO we do not need the conditional annotations because we only instantiate the beans directly by invoking the methods explicitly ...", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525257298", "createdAt": "2020-11-17T15:35:02Z", "author": {"login": "sophokles73"}, "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -266,13 +312,30 @@ public HonoConnection downstreamConnection() {\n      */\n     @Qualifier(TelemetryConstants.TELEMETRY_ENDPOINT)\n     @Bean\n+    @ConditionalOnAmqpMessaging", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 119}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "17f642c741041ad2d56309dbc947296c88cc15f4", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/17f642c741041ad2d56309dbc947296c88cc15f4", "committedDate": "2020-11-18T11:59:13Z", "message": "[#8] Move bean creation of AMQP related beans together.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}, "afterCommit": {"oid": "c59af806cf4ace9108aa356c0a1793bd046040dd", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/c59af806cf4ace9108aa356c0a1793bd046040dd", "committedDate": "2020-11-23T09:03:16Z", "message": "[#8] Add KafkaConsumerConfigProperties.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM2NDIxMjg5", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-536421289", "createdAt": "2020-11-23T12:20:22Z", "commit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMjoyMDoyMlrOH4LFdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMjo0MjoyNlrOH4Lzvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2MzkyNA==", "bodyText": "If we want to be able to create fake producers then I guess we should have a KafkaProducerFactory interface which can be mocked for test cases ...", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528663924", "createdAt": "2020-11-23T12:20:22Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/CachingKafkaProducerFactory.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import org.apache.kafka.common.errors.AuthorizationException;\n+import org.apache.kafka.common.errors.OutOfOrderSequenceException;\n+import org.apache.kafka.common.errors.ProducerFencedException;\n+import org.apache.kafka.common.errors.UnsupportedForMessageFormatException;\n+import org.apache.kafka.common.errors.UnsupportedVersionException;\n+import org.eclipse.hono.kafka.client.test.FakeProducer;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+import io.vertx.core.Vertx;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+\n+/**\n+ * A factory for creating Kafka producers.\n+ * <p>\n+ * This implementation provides no synchronization and should not be used by multiple threads.\n+ * <p>\n+ * Created producers are being cached.\n+ * <p>\n+ * Producers are closed and removed from the cache if they throw a {@link #isFatalError(Throwable) fatal exception}. A\n+ * following invocation of {@link #getOrCreateProducer(String, Map)} will then return a new instance.\n+ *\n+ * @param <K> The type for the record key serialization.\n+ * @param <V> The type for the record value serialization.\n+ */\n+public class CachingKafkaProducerFactory<K, V> {\n+\n+    private final Map<String, KafkaProducer<K, V>> activeProducers = new HashMap<>();\n+    private final BiFunction<String, Map<String, String>, KafkaProducer<K, V>> producerInstanceSupplier;\n+\n+    /**\n+     * Creates a new producer factory.\n+     *\n+     * @param producerInstanceSupplier The function that provides new producer instances.\n+     */\n+    private CachingKafkaProducerFactory(\n+            final BiFunction<String, Map<String, String>, KafkaProducer<K, V>> producerInstanceSupplier) {\n+        this.producerInstanceSupplier = producerInstanceSupplier;\n+    }\n+\n+    /**\n+     * Creates an instance of the factory which produces {@link KafkaProducer#createShared(Vertx, String, Map) shared\n+     * producers}.\n+     * <p>\n+     * Config must always be the same for the same key in {@link #getOrCreateProducer(String, Map)}.\n+     *\n+     * @param vertx The Vert.x instance to use.\n+     * @param <K> The type for the record key serialization.\n+     * @param <V> The type for the record value serialization.\n+     * @return An instance of the factory.\n+     */\n+    public static <K, V> CachingKafkaProducerFactory<K, V> sharedProducerFactory(final Vertx vertx) {\n+        return new CachingKafkaProducerFactory<>((name, config) -> KafkaProducer.createShared(vertx, name, config));\n+    }\n+\n+    /**\n+     * Creates an instance of the factory which produces {@link FakeProducer}s.\n+     * <p>\n+     * This is intended for tests only.\n+     *\n+     * @param <K> The type for the record key serialization.\n+     * @param <V> The type for the record value serialization.\n+     * @return An instance of the factory.\n+     */\n+    public static <K, V> CachingKafkaProducerFactory<K, V> testProducerFactory() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NjQzNQ==", "bodyText": "FMPOV this method should never return null ...", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528666435", "createdAt": "2020-11-23T12:25:07Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/KafkaConsumerConfigProperties.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Configuration properties for Kafka consumers.\n+ * <p>\n+ * This class is intended to be as agnostic to the provided properties as possible in order to be forward-compatible\n+ * with changes in new versions of the Kafka client. It only sets a couple of properties that are important for Hono to\n+ * provide the expected quality of service.\n+ *\n+ * @see <a href=\"https://kafka.apache.org/documentation/#consumerconfigs\">Kafka Consumer Configs</a>\n+ * @see <a href=\"https://www.eclipse.org/hono/docs/api/kafka\">Documentation of Hono's Kafka-based APIs</a>\n+ */\n+// TODO check link to Hono documentation after the API specs are on master\n+public class KafkaConsumerConfigProperties {\n+\n+    private final Logger log = LoggerFactory.getLogger(KafkaConsumerConfigProperties.class);\n+\n+    private Map<String, String> consumerConfig;\n+    private String clientId;\n+\n+    /**\n+     * Sets the Kafka consumer config properties to be used.\n+     *\n+     * @param consumerConfig The config properties.\n+     * @throws NullPointerException if the config is {@code null}.\n+     */\n+    public void setConsumerConfig(final Map<String, String> consumerConfig) {\n+        this.consumerConfig = Objects.requireNonNull(consumerConfig);\n+    }\n+\n+    /**\n+     * Sets the client ID that is passed to the Kafka server to allow application specific server-side request logging.\n+     * <p>\n+     * If the config set in {@link #setConsumerConfig(Map)} already contains a value for key {@code client.id}, that one\n+     * will be used and the parameter here will be ignored.\n+     *\n+     * @param clientId The client ID to set.\n+     * @throws NullPointerException if the client ID is {@code null}.\n+     */\n+    public final void setClientId(final String clientId) {\n+        this.clientId = Objects.requireNonNull(clientId);\n+    }\n+\n+    /**\n+     * Gets the Kafka consumer configuration to which additional properties were applied. The following properties are\n+     * set here to the given configuration:\n+     * <ul>\n+     * <li>{@code key.deserializer=org.apache.kafka.common.serialization.StringDeserializer}: defines how message keys\n+     * are deserialized</li>\n+     * <li>{@code value.deserializer=io.vertx.kafka.client.serialization.BufferDeserializer}: defines how message values\n+     * are deserialized</li>\n+     * <li>{@code client.id} if the property is not already present in the configuration and a value has been set with\n+     * {@link #setClientId(String)}, this value will be taken</li>\n+     * </ul>\n+     *\n+     * @return a copy of the consumer configuration with the applied properties or {@code null} if no consumer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NjYxNA==", "bodyText": "same here", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528666614", "createdAt": "2020-11-23T12:25:28Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/KafkaProducerConfigProperties.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Configuration properties for Kafka producers.\n+ * <p>\n+ * This class is intended to be as agnostic to the provided properties as possible in order to be forward-compatible\n+ * with changes in new versions of the Kafka client. It only sets a couple of properties that are important for Hono to\n+ * provide the expected quality of service.\n+ *\n+ * @see <a href=\"https://kafka.apache.org/documentation/#producerconfigs\">Kafka Producer Configs</a>\n+ * @see <a href=\"https://www.eclipse.org/hono/docs/api/kafka\">Documentation of Hono's Kafka-based APIs</a>\n+ */\n+// TODO check link to Hono documentation after the API specs are on master\n+public class KafkaProducerConfigProperties {\n+\n+    private final Logger log = LoggerFactory.getLogger(KafkaProducerConfigProperties.class);\n+\n+    private Map<String, String> producerConfig;\n+    private String clientId;\n+\n+    /**\n+     * Sets the Kafka producer config properties to be used.\n+     *\n+     * @param producerConfig The config properties.\n+     * @throws NullPointerException if the config is {@code null}.\n+     */\n+    public void setProducerConfig(final Map<String, String> producerConfig) {\n+        this.producerConfig = Objects.requireNonNull(producerConfig);\n+    }\n+\n+    /**\n+     * Sets the client ID that is passed to the Kafka server to allow application specific server-side request logging.\n+     * <p>\n+     * If the config set in {@link #setProducerConfig(Map)} already contains a value for key {@code client.id}, that one\n+     * will be used and the parameter here will be ignored.\n+     *\n+     * @param clientId The client ID to set.\n+     * @throws NullPointerException if the client ID is {@code null}.\n+     */\n+    public final void setClientId(final String clientId) {\n+        this.clientId = Objects.requireNonNull(clientId);\n+    }\n+\n+    /**\n+     * Gets the Kafka producer configuration to which additional properties were applied. The following properties are\n+     * set here to the given configuration:\n+     * <ul>\n+     * <li>{@code enable.idempotence=true}: enables idempotent producer behavior</li>\n+     * <li>{@code key.serializer=org.apache.kafka.common.serialization.StringSerializer}: defines how message keys are\n+     * serialized</li>\n+     * <li>{@code value.serializer=io.vertx.kafka.client.serialization.BufferSerializer}: defines how message values are\n+     * serialized</li>\n+     *\n+     * <li>{@code client.id} if the property is not already present in the configuration and a value has been set with\n+     * {@link #setClientId(String)}, this value will be taken</li>\n+     * </ul>\n+     *\n+     * @return a copy of the producer configuration with the applied properties or {@code null} if no producer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NzcwMA==", "bodyText": "IMHO this should use KafkaHeader.header(key, value) instead ...", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528667700", "createdAt": "2020-11-23T12:27:31Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/KafkaHeaderInjectAdapter.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map.Entry;\n+\n+import io.opentracing.propagation.TextMap;\n+import io.vertx.kafka.client.producer.KafkaHeader;\n+import io.vertx.kafka.client.producer.impl.KafkaHeaderImpl;\n+\n+/**\n+ * An adapter for injecting properties as a new {@link KafkaHeader} to a list of Vert.x Kafka producer headers.\n+ *\n+ */\n+public class KafkaHeaderInjectAdapter implements TextMap {\n+\n+    private final List<KafkaHeader> headers;\n+\n+    /**\n+     * Creates an adapter for a list of {@link KafkaHeader} objects.\n+     *\n+     * @param headers The list of {@link KafkaHeader} objects.\n+     */\n+    public KafkaHeaderInjectAdapter(final List<KafkaHeader> headers) {\n+        this.headers = headers;\n+    }\n+\n+    @Override\n+    public Iterator<Entry<String, String>> iterator() {\n+        throw new UnsupportedOperationException();\n+    }\n+\n+    @Override\n+    public void put(final String key, final String value) {\n+        headers.add(new KafkaHeaderImpl(key, value));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NzgwNA==", "bodyText": "final ?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528667804", "createdAt": "2020-11-23T12:27:45Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/KafkaHeaderInjectAdapter.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map.Entry;\n+\n+import io.opentracing.propagation.TextMap;\n+import io.vertx.kafka.client.producer.KafkaHeader;\n+import io.vertx.kafka.client.producer.impl.KafkaHeaderImpl;\n+\n+/**\n+ * An adapter for injecting properties as a new {@link KafkaHeader} to a list of Vert.x Kafka producer headers.\n+ *\n+ */\n+public class KafkaHeaderInjectAdapter implements TextMap {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2ODQyMw==", "bodyText": "Is this class required by other modules than the adapter-kafka module?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528668423", "createdAt": "2020-11-23T12:29:02Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/test/FakeProducer.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.test;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzOTgwNA=="}, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3MzkwMw==", "bodyText": "can you also add the environment variable names?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528673903", "createdAt": "2020-11-23T12:39:09Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/admin-guide/hono-kafka-client-configuration.md", "diffHunk": "@@ -0,0 +1,43 @@\n++++\n+title = \"Hono Kafka Client Configuration\"\n+weight = 342\n++++\n+\n+Protocol adapters can be configured to use Kafka for the messaging. The Kafka client used there can be configured with \n+command line options.\n+\n+## Producer Configuration Properties\n+\n+The `org.eclipse.hono.kafka.client.CachingKafkaProducerFactory` factory can be used to create Kafka producers for Hono's Kafka based APIs. \n+The producers created by the factory are configured with instances of the class `org.eclipse.hono.kafka.client.KafkaProducerConfigProperties`\n+which can be used to programmatically configure a producer. \n+\n+The configuration needs to be provided in the form `hono.kafka.producerConfig.${property}`, where `${property}` is any of the \n+Kafka client's [producer properties](https://kafka.apache.org/documentation/#producerconfigs). \n+The provided configuration is passed directly to the Kafka producer without Hono parsing or validating it.\n+The following table shows which properties _are_ changed by Hono.\n+\n+| Kafka Producer Config Property | Mandatory Value | Description |\n+| :----------------------------- | :-------------- | :-----------|\n+| `--hono.kafka.producerConfig.key.serializer` | `org.apache.kafka.common.serialization.StringSerializer` | The record keys in Hono are always strings. Any other specified value is ignored. |\n+| `--hono.kafka.producerConfig.value.serializer` | `io.vertx.kafka.client.serialization.BufferSerializer` | The record values in Hono are always byte arrays.  Any other specified value is ignored. |\n+| `--hono.kafka.producerConfig.enable.idempotence` | `true` | The Hono Kafka client uses only idempotent producers.  Any other specified value is ignored. |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3NTc3NQ==", "bodyText": "does this work (i.e. doesn't throw a runtime exception) if no hono.kafka properties are set at all?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528675775", "createdAt": "2020-11-23T12:42:26Z", "author": {"login": "sophokles73"}, "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -134,14 +141,24 @@ protected void setCollaborators(\n             adapter.setCommandConsumerFactory(commandConsumerFactory(adapterProperties, samplerFactory, commandRouterClient));\n         }\n \n+        final KafkaProducerConfigProperties kafkaProducerConfig = kafkaProducerConfig();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyNTI3NDI5", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-532527429", "createdAt": "2020-11-17T16:03:30Z", "commit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxNjowMzozMVrOH08lzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwODozMjoyNFrOH4xSOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI4MDcxOA==", "bodyText": "How about final EncodeException e?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525280718", "createdAt": "2020-11-17T16:03:31Z", "author": {"login": "kaniyan"}, "path": "clients/adapter-kafka/src/main/java/org/eclipse/hono/adapter/client/telemetry/kafka/AbstractKafkaBasedDownstreamSender.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.adapter.client.telemetry.kafka;\n+\n+import java.net.HttpURLConnection;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+import org.eclipse.hono.client.ServerErrorException;\n+import org.eclipse.hono.kafka.client.CachingKafkaProducerFactory;\n+import org.eclipse.hono.kafka.client.HonoTopic;\n+import org.eclipse.hono.kafka.client.tracing.KafkaTracingHelper;\n+import org.eclipse.hono.tracing.TracingHelper;\n+import org.eclipse.hono.util.Lifecycle;\n+import org.eclipse.hono.util.MessageHelper;\n+import org.eclipse.hono.util.QoS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import io.opentracing.References;\n+import io.opentracing.Span;\n+import io.opentracing.SpanContext;\n+import io.opentracing.Tracer;\n+import io.opentracing.tag.Tags;\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.EncodeException;\n+import io.vertx.core.json.Json;\n+import io.vertx.kafka.client.producer.KafkaHeader;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+import io.vertx.kafka.client.producer.KafkaProducerRecord;\n+import io.vertx.kafka.client.producer.RecordMetadata;\n+import io.vertx.kafka.client.producer.impl.KafkaHeaderImpl;\n+\n+/**\n+ * A client for publishing messages to a Kafka cluster.\n+ */\n+public abstract class AbstractKafkaBasedDownstreamSender implements Lifecycle {\n+\n+    /**\n+     * A logger to be shared with subclasses.\n+     */\n+    protected final Logger log = LoggerFactory.getLogger(getClass());\n+\n+    private final CachingKafkaProducerFactory<String, Buffer> producerFactory;\n+    private final String producerName;\n+    private final Map<String, String> config;\n+    private final Tracer tracer;\n+\n+    /**\n+     * Creates a new Kafka-based telemetry sender.\n+     *\n+     * @param producerFactory The factory to use for creating Kafka producers.\n+     * @param producerName The producer name to use.\n+     * @param config The Kafka producer configuration properties to use.\n+     * @param tracer The OpenTracing tracer.\n+     * @throws NullPointerException if any of the parameters are {@code null}.\n+     */\n+\n+    public AbstractKafkaBasedDownstreamSender(final CachingKafkaProducerFactory<String, Buffer> producerFactory,\n+            final String producerName, final Map<String, String> config, final Tracer tracer) {\n+\n+        Objects.requireNonNull(producerFactory);\n+        Objects.requireNonNull(producerName);\n+        Objects.requireNonNull(config);\n+        Objects.requireNonNull(tracer);\n+\n+        this.config = config;\n+        this.producerName = producerName;\n+        this.tracer = tracer;\n+        this.producerFactory = producerFactory;\n+    }\n+\n+    /**\n+     * Sends a message downstream.\n+     *\n+     * @param topic The topic to send the message to.\n+     * @param tenantId The ID of the tenant that the device belongs to.\n+     * @param deviceId The ID of the device that the data originates from.\n+     * @param qos The delivery semantics to use for sending the data.\n+     * @param contentType The content type of the data.\n+     * @param payload The data to send.\n+     * @param properties Additional meta data that should be included in the downstream message.\n+     * @param context The currently active OpenTracing span (may be {@code null}). An implementation should use this as\n+     *            the parent for any span it creates for tracing the execution of this operation.\n+     * @return A future indicating the outcome of the operation.\n+     *         <p>\n+     *         The future will be succeeded if the message has been sent downstream.\n+     *         <p>\n+     *         The future will be failed with a {@link org.eclipse.hono.client.ServerErrorException} if the data could\n+     *         not be sent. The error code contained in the exception indicates the cause of the failure.\n+     * @throws NullPointerException if topic, tenant ID, device ID, qos or contentType are {@code null}.\n+     */\n+    protected Future<Void> send(final HonoTopic topic, final String tenantId, final String deviceId, final QoS qos,\n+            final String contentType, final Buffer payload, final Map<String, Object> properties,\n+            final SpanContext context) {\n+\n+        Objects.requireNonNull(topic);\n+        Objects.requireNonNull(tenantId);\n+        Objects.requireNonNull(deviceId);\n+        Objects.requireNonNull(qos);\n+        Objects.requireNonNull(contentType);\n+\n+        log.trace(\"sending to Kafka [topic: {}, tenantId: {}, deviceId: {}, qos: {}, contentType: {}, properties: {}]\",\n+                topic, tenantId, deviceId, qos, contentType, properties);\n+        final Span span = startSpan(topic, tenantId, deviceId, qos, contentType, context);\n+\n+        final KafkaProducerRecord<String, Buffer> record = KafkaProducerRecord.create(topic.toString(), deviceId,\n+                payload);\n+        record.addHeaders(createHeaders(properties, deviceId, qos, contentType, span));\n+\n+        KafkaTracingHelper.injectSpanContext(tracer, record, span.context());\n+        logProducerRecord(span, record);\n+\n+        final Promise<RecordMetadata> promise = Promise.promise();\n+        getOrCreateProducer().send(record, promise);\n+\n+        final Future<Void> producerFuture = promise.future()\n+                .recover(t -> {\n+                    logError(span, topic, tenantId, deviceId, qos, t);\n+                    span.finish();\n+                    return Future.failedFuture(new ServerErrorException(getErrorCode(t), t));\n+                })\n+                .map(recordMetadata -> {\n+                    logRecordMetadata(span, deviceId, recordMetadata);\n+                    span.finish();\n+                    return null;\n+                });\n+\n+        return qos.equals(QoS.AT_MOST_ONCE) ? Future.succeededFuture() : producerFuture;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * Starts the producer.\n+     */\n+    @Override\n+    public Future<Void> start() {\n+        getOrCreateProducer();\n+        return Future.succeededFuture();\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * Stops the producer.\n+     */\n+    @Override\n+    public Future<Void> stop() {\n+        return producerFactory.removeProducer(producerName);\n+    }\n+\n+    private KafkaProducer<String, Buffer> getOrCreateProducer() {\n+        return producerFactory.getOrCreateProducer(producerName, config);\n+    }\n+\n+    private List<KafkaHeader> createHeaders(final Map<String, Object> properties, final String deviceId,\n+            final QoS qos, final String contentType, final Span span) {\n+\n+        // ensure that we have a modifiable map\n+        final Map<String, Object> headerProperties = new HashMap<>();\n+        if (properties != null) {\n+            headerProperties.putAll(properties);\n+        }\n+\n+        setStandardProperties(headerProperties, deviceId, qos, contentType);\n+\n+        return encodePropertiesAsKafkaHeaders(headerProperties, span);\n+    }\n+\n+    private void setStandardProperties(final Map<String, Object> headerProperties, final String deviceId,\n+            final QoS qos, final String contentType) {\n+\n+        // ensure that the standard properties are set correctly\n+        headerProperties.put(MessageHelper.SYS_PROPERTY_CONTENT_TYPE, contentType);\n+        headerProperties.put(MessageHelper.APP_PROPERTY_DEVICE_ID, deviceId);\n+        headerProperties.put(MessageHelper.APP_PROPERTY_QOS, qos.ordinal());\n+\n+        if (headerProperties.containsKey(MessageHelper.APP_PROPERTY_DEVICE_TTD)\n+                && !headerProperties.containsKey(MessageHelper.SYS_PROPERTY_CREATION_TIME)) {\n+            // TODO set this as creation time in the KafkaRecord?\n+\n+            // must match http://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-types-v1.0-os.html#type-timestamp\n+            // as defined in https://www.eclipse.org/hono/docs/api/telemetry/#forward-telemetry-data\n+            final long timestamp = Instant.now().toEpochMilli();\n+            headerProperties.put(MessageHelper.SYS_PROPERTY_CREATION_TIME, timestamp);\n+        }\n+    }\n+\n+    private List<KafkaHeader> encodePropertiesAsKafkaHeaders(final Map<String, Object> properties, final Span span) {\n+        final List<KafkaHeader> headers = new ArrayList<>();\n+        properties.forEach((k, v) -> {\n+            try {\n+                final Buffer headerValue = (v instanceof String)\n+                        ? Buffer.buffer((String) v)\n+                        : Buffer.buffer(Json.encode(v));\n+\n+                headers.add(new KafkaHeaderImpl(k, headerValue));\n+            } catch (EncodeException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI4ODA5MQ==", "bodyText": "AFAIK CachingClientFactory is quite generic and I think it can also accommodate Kafka clients and in this case KafkaProducer? Then we could reuse the code and IMHO having a uniform style throughout, makes the code easier to understand. I am just curious to know if there are any reasons to have a new  CachingKafkaProducerFactory.", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529288091", "createdAt": "2020-11-24T08:29:45Z", "author": {"login": "kaniyan"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/CachingKafkaProducerFactory.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import org.apache.kafka.common.errors.AuthorizationException;\n+import org.apache.kafka.common.errors.OutOfOrderSequenceException;\n+import org.apache.kafka.common.errors.ProducerFencedException;\n+import org.apache.kafka.common.errors.UnsupportedForMessageFormatException;\n+import org.apache.kafka.common.errors.UnsupportedVersionException;\n+import org.eclipse.hono.kafka.client.test.FakeProducer;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+import io.vertx.core.Vertx;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+\n+/**\n+ * A factory for creating Kafka producers.\n+ * <p>\n+ * This implementation provides no synchronization and should not be used by multiple threads.\n+ * <p>\n+ * Created producers are being cached.\n+ * <p>\n+ * Producers are closed and removed from the cache if they throw a {@link #isFatalError(Throwable) fatal exception}. A\n+ * following invocation of {@link #getOrCreateProducer(String, Map)} will then return a new instance.\n+ *\n+ * @param <K> The type for the record key serialization.\n+ * @param <V> The type for the record value serialization.\n+ */\n+public class CachingKafkaProducerFactory<K, V> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI4OTc4Nw==", "bodyText": "How about final Exception e?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529289787", "createdAt": "2020-11-24T08:32:24Z", "author": {"login": "kaniyan"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/test/FakeProducer.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.test;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import org.apache.kafka.clients.producer.MockProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.kafka.client.common.PartitionInfo;\n+import io.vertx.kafka.client.common.impl.Helper;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+import io.vertx.kafka.client.producer.KafkaProducerRecord;\n+import io.vertx.kafka.client.producer.KafkaWriteStream;\n+import io.vertx.kafka.client.producer.RecordMetadata;\n+\n+/**\n+ * This is a fake Kafka producer. It provides the Vert.x abstraction for the {@link MockProducer} of Kafka's client.\n+ * <p>\n+ * This does not support every Vert.x <em>stream</em> related operation.\n+ * <p>\n+ * <b>Usage Example:</b>\n+ * <pre>\n+ * {@code\n+ *     final FakeProducer<String, String> fakeProducer = new FakeProducer<>();\n+ *\n+ *     final Handler<AsyncResult<RecordMetadata>> resultHandler = asyncResult -> {\n+ *         if (asyncResult.succeeded()) {\n+ *             System.out.println(\"Record produced successfully to topic: \" + asyncResult.result().getTopic());\n+ *         } else {\n+ *             System.out.println(\"Sending record failed: \" + asyncResult.cause().getMessage());\n+ *         }\n+ *     };\n+ *\n+ *     // send two records\n+ *     fakeProducer.send(new KafkaProducerRecordImpl<>(\"my-topic\", \"first message\"), resultHandler);\n+ *     fakeProducer.send(new KafkaProducerRecordImpl<>(\"my-topic\", \"second message\"), resultHandler);\n+ *\n+ *     final MockProducer<String, String> mockProducer = fakeProducer.getMockProducer();\n+ *\n+ *     // completes the result handler of the first record successfully\n+ *     mockProducer.completeNext();\n+ *     // fails the result handler of the second record\n+ *     mockProducer.errorNext(new KafkaException(\"something went wrong\"));\n+ *\n+ *     // inspect the sent records\n+ *     final ProducerRecord<String, String> firstRecord = mockProducer.history().get(0);\n+ *     System.out.println(firstRecord);\n+ *\n+ *     final ProducerRecord<String, String> secondRecord = mockProducer.history().get(1);\n+ *     System.out.println(secondRecord);\n+ *\n+ *     // clean the history...\n+ *     mockProducer.clear();\n+ *     // ... or close it if you are done\n+ *     mockProducer.close();\n+ * }\n+ * </pre>\n+ *\n+ * @param <K> The type for the record key serialization.\n+ * @param <V> The type for the record value serialization.\n+ */\n+public class FakeProducer<K, V> implements KafkaProducer<K, V> {\n+\n+    private final MockProducer<K, V> producer;\n+    private Handler<Throwable> exceptionHandler;\n+\n+    /**\n+     * Creates a fake producer with a new instance of {@link MockProducer#MockProducer()}.\n+     */\n+    public FakeProducer() {\n+        producer = new MockProducer<>();\n+    }\n+\n+    /**\n+     * Creates a fake producer with the given mock producer instance.\n+     *\n+     * @param producer The mock producer to be used.\n+     */\n+    public FakeProducer(final MockProducer<K, V> producer) {\n+        this.producer = producer;\n+    }\n+\n+    /**\n+     * Gets the underlying {@link MockProducer}.\n+     *\n+     * @return the mock producer.\n+     */\n+    public MockProducer<K, V> getMockProducer() {\n+        return producer;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> exceptionHandler(final Handler<Throwable> handler) {\n+        this.exceptionHandler = handler;\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> write(final KafkaProducerRecord<K, V> kafkaProducerRecord) {\n+        write(kafkaProducerRecord, null);\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * This implementation simply returns {@code this}.\n+     */\n+    @Override\n+    public KafkaProducer<K, V> setWriteQueueMaxSize(final int i) {\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * This implementation always returns {@code false}.\n+     */\n+    @Override\n+    public boolean writeQueueFull() {\n+        return false;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * This implementation simply returns {@code this}.\n+     */\n+    @Override\n+    public KafkaProducer<K, V> drainHandler(final Handler<Void> handler) {\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> write(final KafkaProducerRecord<K, V> data, final Handler<AsyncResult<Void>> handler) {\n+        Handler<AsyncResult<RecordMetadata>> mdHandler = null;\n+        if (handler != null) {\n+            mdHandler = ar -> handler.handle(ar.mapEmpty());\n+        }\n+        send(data, mdHandler);\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void end() {\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void end(final Handler<AsyncResult<Void>> handler) {\n+        if (handler != null) {\n+            handler.handle(Future.succeededFuture());\n+        }\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> send(final KafkaProducerRecord<K, V> record) {\n+        send(record, null);\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> send(final KafkaProducerRecord<K, V> record,\n+            final Handler<AsyncResult<RecordMetadata>> handler) {\n+\n+        try {\n+            producer.send(record.record(), (metadata, err) -> {\n+                if (err != null) {\n+                    if (exceptionHandler != null) {\n+                        exceptionHandler.handle(err);\n+                    }\n+                    if (handler != null) {\n+                        handler.handle(Future.failedFuture(err));\n+                    }\n+                } else if (handler != null) {\n+                    handler.handle(Future.succeededFuture(Helper.from(metadata)));\n+                }\n+            });\n+        } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 216}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3MzI1Mjgx", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-537325281", "createdAt": "2020-11-24T10:00:16Z", "commit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMDowMDoxNlrOH43FIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMDowMDoxNlrOH43FIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NDczNw==", "bodyText": "I added #2326. This simplifies this part to the following, by leveraging conditional bean creation:\n// look up client via bean factory in order to take advantage of conditional bean instantiation based\n// on config properties\nadapter.setEventSender(context.getBean(EventSender.class));\nadapter.setTelemetrySender(context.getBean(TelemetrySender.class));\nAdditionally, I can then change the class KafkaProducerConfig to no longer return null.\n@sophokles73 WDYT?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529384737", "createdAt": "2020-11-24T10:00:16Z", "author": {"login": "b-abel"}, "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -134,14 +141,24 @@ protected void setCollaborators(\n             adapter.setCommandConsumerFactory(commandConsumerFactory(adapterProperties, samplerFactory, commandRouterClient));\n         }\n \n+        final KafkaProducerConfigProperties kafkaProducerConfig = kafkaProducerConfig();\n+        if (kafkaProducerConfig.getProducerConfig() == null) {\n+            // look up via bean factory is not possible because EventSender and TelemetrySender are implemented by\n+            // ProtonBasedDownstreamSender\n+            adapter.setEventSender(downstreamEventSender(samplerFactory, adapterProperties));\n+            adapter.setTelemetrySender(downstreamTelemetrySender(samplerFactory, adapterProperties));\n+        } else {\n+            final CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory = kafkaProducerFactory();\n+            adapter.setEventSender(downstreamEventKafkaSender(kafkaProducerFactory, kafkaProducerConfig));\n+            adapter.setTelemetrySender(downstreamTelemetryKafkaSender(kafkaProducerFactory, kafkaProducerConfig));\n+        }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3NDQyMTA2", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-537442106", "createdAt": "2020-11-24T12:28:00Z", "commit": {"oid": "a0dfdbf7c15ef661fb553e1acb2ea4272b417ea5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjoyODowMVrOH4-llA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjoyODowMVrOH4-llA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUwNzczMg==", "bodyText": "both the event sender  and the telemetry sender seem to use the same configuration, or am I mistaken? If that is the case, what advantage does it have to create two separate senders? is there a reason why they shouldn't use the same KafkaProducer instance (and the same connection to the Kafka cluster)?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529507732", "createdAt": "2020-11-24T12:28:01Z", "author": {"login": "sophokles73"}, "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -297,13 +332,58 @@ public TelemetrySender downstreamTelemetrySender(\n      */\n     @Qualifier(EventConstants.EVENT_ENDPOINT)\n     @Bean\n+    @ConditionalOnAmqpMessaging\n     @Scope(\"prototype\")\n     public EventSender downstreamEventSender(\n             final SendMessageSampler.Factory samplerFactory,\n             final ProtocolAdapterProperties adapterConfig) {\n         return new ProtonBasedDownstreamSender(downstreamConnection(), samplerFactory, adapterConfig);\n     }\n \n+    /**\n+     * Exposes a factory for creating producers for sending downstream messages via the Kafka cluster.\n+     *\n+     * @return The factory.\n+     */\n+    @Bean\n+    @Scope(\"prototype\")\n+    @ConditionalOnKafkaMessaging\n+    public CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory() {\n+        return CachingKafkaProducerFactory.sharedProducerFactory(vertx());\n+    }\n+\n+    /**\n+     * Exposes a client for sending telemetry messages via <em>Kafka</em> as a Spring bean.\n+     *\n+     * @return The client.\n+     * @param kafkaProducerFactory The producer factory to use.\n+     * @param kafkaProducerConfig The producer configuration to use.\n+     */\n+    @Bean\n+    @ConditionalOnKafkaMessaging\n+    @Scope(\"prototype\")\n+    public TelemetrySender downstreamTelemetryKafkaSender(\n+            final CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory,\n+            final KafkaProducerConfigProperties kafkaProducerConfig) {\n+        return new KafkaBasedTelemetrySender(kafkaProducerFactory, kafkaProducerConfig, getTracer());\n+    }\n+\n+    /**\n+     * Exposes a client for sending events via <em>Kafka</em> as a Spring bean.\n+     *\n+     * @return The client.\n+     * @param kafkaProducerFactory The producer factory to use.\n+     * @param kafkaProducerConfig The producer configuration to use.\n+     */\n+    @Bean\n+    @ConditionalOnKafkaMessaging\n+    @Scope(\"prototype\")\n+    public EventSender downstreamEventKafkaSender(\n+            final CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory,\n+            final KafkaProducerConfigProperties kafkaProducerConfig) {\n+        return new KafkaBasedEventSender(kafkaProducerFactory, kafkaProducerConfig, getTracer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0dfdbf7c15ef661fb553e1acb2ea4272b417ea5"}, "originalPosition": 155}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzNjgyNjcw", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-543682670", "createdAt": "2020-12-03T07:51:28Z", "commit": {"oid": "c33956dc6e7dcbb4ceae0313a2726e18fd9b5509"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwNzo1MToyOFrOH-EV0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwNzo1OTo1OFrOH-FQEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg0NDg4MQ==", "bodyText": "IMHO it would be helpful if the description would explain who needs to invoke this method and why?\nIn particular, it seems that you do not want to let clients invoke the KafkaProducer.close() method.\nDo all the producers need to be closed when shutting down the system? Should this factory take care of that?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r534844881", "createdAt": "2020-12-03T07:51:28Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/KafkaProducerFactory.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.Map;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Vertx;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+\n+/**\n+ * A factory for creating Kafka producers.\n+ *\n+ * @param <K> The type for the record key serialization.\n+ * @param <V> The type for the record value serialization.\n+ */\n+public interface KafkaProducerFactory<K, V> {\n+\n+    /**\n+     * Creates a new factory which produces {@link KafkaProducer#createShared(Vertx, String, Map) shared producers}.\n+     * Shared producers\n+     * can safely be shared between verticle instances.\n+     * <p>\n+     * Config must always be the same for the same key in {@link #getOrCreateProducer(String, Map)}.\n+     *\n+     * @param vertx The Vert.x instance to use.\n+     * @param <K> The type for the record key serialization.\n+     * @param <V> The type for the record value serialization.\n+     * @return An instance of the factory.\n+     */\n+    static <K, V> KafkaProducerFactory<K, V> sharedProducerFactory(final Vertx vertx) {\n+        return new CachingKafkaProducerFactory<>((name, config) -> KafkaProducer.createShared(vertx, name, config));\n+    }\n+\n+    /**\n+     * Gets a producer for sending data to Kafka.\n+     * <p>\n+     * The producer returned may be either newly created or it may be an existing producer for the given producer name.\n+     * The config parameter might be ignored if an existing producer is returned.\n+     *\n+     * @param producerName The name to identify the producer.\n+     * @param config The Kafka configuration with which the producer is to be created.\n+     * @return an existing or new producer.\n+     */\n+    KafkaProducer<K, V> getOrCreateProducer(String producerName, Map<String, String> config);\n+\n+    /**\n+     * Closes the producer with the given producer name if it exists.\n+     *\n+     * @param producerName The name of the producer to remove.\n+     * @return A future that is completed when the close operation completed or a succeeded future if no producer\n+     *         existed with the given name.\n+     */\n+    Future<Void> closeProducer(String producerName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c33956dc6e7dcbb4ceae0313a2726e18fd9b5509"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg1MDMxMw==", "bodyText": "this seems to be kind of the Hono standard producer supplier, isn't it? I wonder if every client needs to create this again and again or if we can use this as the default supplier in CachingKafkaProducerFactory instead ...", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r534850313", "createdAt": "2020-12-03T07:54:33Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/test/java/org/eclipse/hono/kafka/client/CachingKafkaProducerFactoryTest.java", "diffHunk": "@@ -49,7 +59,25 @@\n \n     @BeforeEach\n     void setUp() {\n-        factory = CachingKafkaProducerFactory.testProducerFactory();\n+\n+        final Vertx vertxMock = mock(Vertx.class);\n+        final Context context = VertxMockSupport.mockContext(vertxMock);\n+        when(vertxMock.getOrCreateContext()).thenReturn(context);\n+\n+        doAnswer(invocation -> {\n+            final Promise<RecordMetadata> result = Promise.promise();\n+            final Handler<Future<RecordMetadata>> blockingCode = invocation.getArgument(0);\n+            blockingCode.handle(result.future());\n+            return null;\n+        }).when(context).executeBlocking(VertxMockSupport.anyHandler(), any());\n+\n+        final BiFunction<String, Map<String, String>, KafkaProducer<String, Buffer>> instanceSupplier = (n, c) -> {\n+            final MockProducer<String, Buffer> mockProducer = new MockProducer<>(true, new StringSerializer(),\n+                    new BufferSerializer());\n+            return KafkaProducer.create(vertxMock, mockProducer);\n+        };", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c33956dc6e7dcbb4ceae0313a2726e18fd9b5509"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg1OTc5NQ==", "bodyText": "This should return a KafkaProducerFactory shouldn't it?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r534859795", "createdAt": "2020-12-03T07:59:58Z", "author": {"login": "sophokles73"}, "path": "clients/adapter-kafka/src/test/java/org/eclipse/hono/adapter/client/telemetry/kafka/TestHelper.java", "diffHunk": "@@ -30,41 +48,65 @@ private TestHelper() {\n     }\n \n     /**\n-     * Gets the {@link MockProducer} for the given producer name from a factory.\n+     * Returns a new {@link org.eclipse.hono.client.impl.CachingClientFactory} for the given native {@link Producer}.\n+     * <p>\n+     * All producers returned by this factory will use the given native producer instance wrapped in a\n+     * {@link KafkaProducer}.\n      *\n-     * @param producerFactory The factory containing the {@link FakeProducer}.\n-     * @param producerName The name under which the fake producer is cached in the factory.\n-     * @param <K> The type for the record key serialization.\n-     * @param <V> The type for the record value serialization.\n-     * @return The mock producer.\n-     *\n-     * @throws NoSuchElementException if the given factory does not contain the expected producer (e.g. when the\n-     *             producer got closed after a fatal error).\n-     * @throws ClassCastException if the provided producer implementation is not an instance of {@link FakeProducer}.\n+     * @param producer The (mock) producer to be wrapped.\n+     * @return The producer factory.\n      */\n-    public static <K, V> MockProducer<K, V> getUnderlyingMockProducer(\n-            final CachingKafkaProducerFactory<K, V> producerFactory, final String producerName) {\n+    public static CachingKafkaProducerFactory<String, Buffer> newProducerFactory(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c33956dc6e7dcbb4ceae0313a2726e18fd9b5509"}, "originalPosition": 58}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUxMTM3NzA5", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-551137709", "createdAt": "2020-12-14T08:30:34Z", "commit": {"oid": "1d19342dc5ca057b77116006326a28caeb33d239"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwODozMDozNFrOIFFBWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwODozODoyMVrOIFFT1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE5NjA1Ng==", "bodyText": "I guess the headers param is mandatory and should therefore be checked for null?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r542196056", "createdAt": "2020-12-14T08:30:34Z", "author": {"login": "sophokles73"}, "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/KafkaHeaderInjectAdapter.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map.Entry;\n+\n+import io.opentracing.propagation.TextMap;\n+import io.vertx.kafka.client.producer.KafkaHeader;\n+\n+/**\n+ * An adapter for injecting properties as a new {@link KafkaHeader} to a list of Vert.x Kafka producer headers.\n+ *\n+ */\n+public final class KafkaHeaderInjectAdapter implements TextMap {\n+\n+    private final List<KafkaHeader> headers;\n+\n+    /**\n+     * Creates an adapter for a list of {@link KafkaHeader} objects.\n+     *\n+     * @param headers The list of {@link KafkaHeader} objects.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d19342dc5ca057b77116006326a28caeb33d239"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE5Nzg4Mg==", "bodyText": "IMHO we should better add a KafkaProducerConfigProperties.isConfigured() method in order to decouple the test from the inner structure of the properties object. WDYT?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r542197882", "createdAt": "2020-12-14T08:33:38Z", "author": {"login": "sophokles73"}, "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -134,14 +139,26 @@ protected void setCollaborators(\n             adapter.setCommandConsumerFactory(commandConsumerFactory(adapterProperties, samplerFactory, commandRouterClient));\n         }\n \n+        final KafkaProducerConfigProperties kafkaProducerConfig = kafkaProducerConfig();\n+        if (kafkaProducerConfig.getProducerConfig().isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d19342dc5ca057b77116006326a28caeb33d239"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjIwMDQzMg==", "bodyText": "why do we make this configurable if we only accept org.apache.kafka.common.serialization.StringSerializer anyway?\nApart from that I am not sure if the name of the command line option will result in the desired outcome of putting key key.serializer to the Map. Have you tested if Spring Boot maps this as you expected?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r542200432", "createdAt": "2020-12-14T08:37:41Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/admin-guide/hono-kafka-client-configuration.md", "diffHunk": "@@ -0,0 +1,49 @@\n++++\n+title = \"Hono Kafka Client Configuration\"\n+weight = 342\n++++\n+\n+Protocol adapters can be configured to use Kafka for the messaging. The Kafka client used there can be configured with \n+environment variables and/or command line options.\n+\n+{{% note title=\"Tech preview\" %}}\n+The support of Kafka as a messaging system is currently a preview and not yet ready for production. \n+The implementation as well as it's APIs may change with the next version. \n+{{% /note %}}\n+\n+## Producer Configuration Properties\n+\n+The `org.eclipse.hono.kafka.client.CachingKafkaProducerFactory` factory can be used to create Kafka producers for Hono's Kafka based APIs. \n+The producers created by the factory are configured with instances of the class `org.eclipse.hono.kafka.client.KafkaProducerConfigProperties`\n+which can be used to programmatically configure a producer. \n+\n+The configuration needs to be provided in the form `HONO_KAFKA_PRODUCERCONFIG_${PROPERTY}` as an environment variable or\n+as a command line option in the form `hono.kafka.producerConfig.${property}`, where `${PROPERTY}` respectively \n+`${property}` is any of the Kafka client's [producer properties](https://kafka.apache.org/documentation/#producerconfigs). \n+The provided configuration is passed directly to the Kafka producer without Hono parsing or validating it.\n+The following table shows which properties _are_ changed by Hono.\n+\n+| Environment Variable<br>Command Line Option | Mandatory Value | Description |\n+| :------------------------------------------ | :-------------- | :---------- |\n+| `HONO_KAFKA_PRODUCERCONFIG_KEY_SERIALIZER`<br>`--hono.kafka.producerConfig.key.serializer` | `org.apache.kafka.common.serialization.StringSerializer` | The record keys in Hono are always strings. Any other specified value is ignored. |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d19342dc5ca057b77116006326a28caeb33d239"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjIwMDYyOA==", "bodyText": "same here", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r542200628", "createdAt": "2020-12-14T08:38:05Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/admin-guide/hono-kafka-client-configuration.md", "diffHunk": "@@ -0,0 +1,49 @@\n++++\n+title = \"Hono Kafka Client Configuration\"\n+weight = 342\n++++\n+\n+Protocol adapters can be configured to use Kafka for the messaging. The Kafka client used there can be configured with \n+environment variables and/or command line options.\n+\n+{{% note title=\"Tech preview\" %}}\n+The support of Kafka as a messaging system is currently a preview and not yet ready for production. \n+The implementation as well as it's APIs may change with the next version. \n+{{% /note %}}\n+\n+## Producer Configuration Properties\n+\n+The `org.eclipse.hono.kafka.client.CachingKafkaProducerFactory` factory can be used to create Kafka producers for Hono's Kafka based APIs. \n+The producers created by the factory are configured with instances of the class `org.eclipse.hono.kafka.client.KafkaProducerConfigProperties`\n+which can be used to programmatically configure a producer. \n+\n+The configuration needs to be provided in the form `HONO_KAFKA_PRODUCERCONFIG_${PROPERTY}` as an environment variable or\n+as a command line option in the form `hono.kafka.producerConfig.${property}`, where `${PROPERTY}` respectively \n+`${property}` is any of the Kafka client's [producer properties](https://kafka.apache.org/documentation/#producerconfigs). \n+The provided configuration is passed directly to the Kafka producer without Hono parsing or validating it.\n+The following table shows which properties _are_ changed by Hono.\n+\n+| Environment Variable<br>Command Line Option | Mandatory Value | Description |\n+| :------------------------------------------ | :-------------- | :---------- |\n+| `HONO_KAFKA_PRODUCERCONFIG_KEY_SERIALIZER`<br>`--hono.kafka.producerConfig.key.serializer` | `org.apache.kafka.common.serialization.StringSerializer` | The record keys in Hono are always strings. Any other specified value is ignored. |\n+| `HONO_KAFKA_PRODUCERCONFIG_VALUE_SERIALIZER`<br>`--hono.kafka.producerConfig.value.serializer` | `io.vertx.kafka.client.serialization.BufferSerializer` | The record values in Hono are always byte arrays.  Any other specified value is ignored. |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d19342dc5ca057b77116006326a28caeb33d239"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjIwMDc5MA==", "bodyText": "and here", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r542200790", "createdAt": "2020-12-14T08:38:21Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/admin-guide/hono-kafka-client-configuration.md", "diffHunk": "@@ -0,0 +1,49 @@\n++++\n+title = \"Hono Kafka Client Configuration\"\n+weight = 342\n++++\n+\n+Protocol adapters can be configured to use Kafka for the messaging. The Kafka client used there can be configured with \n+environment variables and/or command line options.\n+\n+{{% note title=\"Tech preview\" %}}\n+The support of Kafka as a messaging system is currently a preview and not yet ready for production. \n+The implementation as well as it's APIs may change with the next version. \n+{{% /note %}}\n+\n+## Producer Configuration Properties\n+\n+The `org.eclipse.hono.kafka.client.CachingKafkaProducerFactory` factory can be used to create Kafka producers for Hono's Kafka based APIs. \n+The producers created by the factory are configured with instances of the class `org.eclipse.hono.kafka.client.KafkaProducerConfigProperties`\n+which can be used to programmatically configure a producer. \n+\n+The configuration needs to be provided in the form `HONO_KAFKA_PRODUCERCONFIG_${PROPERTY}` as an environment variable or\n+as a command line option in the form `hono.kafka.producerConfig.${property}`, where `${PROPERTY}` respectively \n+`${property}` is any of the Kafka client's [producer properties](https://kafka.apache.org/documentation/#producerconfigs). \n+The provided configuration is passed directly to the Kafka producer without Hono parsing or validating it.\n+The following table shows which properties _are_ changed by Hono.\n+\n+| Environment Variable<br>Command Line Option | Mandatory Value | Description |\n+| :------------------------------------------ | :-------------- | :---------- |\n+| `HONO_KAFKA_PRODUCERCONFIG_KEY_SERIALIZER`<br>`--hono.kafka.producerConfig.key.serializer` | `org.apache.kafka.common.serialization.StringSerializer` | The record keys in Hono are always strings. Any other specified value is ignored. |\n+| `HONO_KAFKA_PRODUCERCONFIG_VALUE_SERIALIZER`<br>`--hono.kafka.producerConfig.value.serializer` | `io.vertx.kafka.client.serialization.BufferSerializer` | The record values in Hono are always byte arrays.  Any other specified value is ignored. |\n+| `HONO_KAFKA_PRODUCERCONFIG_ENABLE_IDEMPOTENCE`<br>`--hono.kafka.producerConfig.enable.idempotence` | `true` | The Hono Kafka client uses only idempotent producers.  Any other specified value is ignored. |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d19342dc5ca057b77116006326a28caeb33d239"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0NDQzMTU0", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-554443154", "createdAt": "2020-12-17T09:55:59Z", "commit": {"oid": "503a37d795895ac01342e95b422341274d6ca79e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwOTo1NTo1OVrOIHticg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwOTo1NTo1OVrOIHticg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDk1NzA0Mg==", "bodyText": "Missing null check for the adapterConfig.", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r544957042", "createdAt": "2020-12-17T09:55:59Z", "author": {"login": "kaniyan"}, "path": "clients/adapter-kafka/src/main/java/org/eclipse/hono/adapter/client/telemetry/kafka/AbstractKafkaBasedDownstreamSender.java", "diffHunk": "@@ -72,22 +74,25 @@\n      * @param producerFactory The factory to use for creating Kafka producers.\n      * @param producerName The producer name to use.\n      * @param config The Kafka producer configuration properties to use.\n+     * @param adapterConfig The protocol adapter's configuration properties.\n      * @param tracer The OpenTracing tracer.\n      * @throws NullPointerException if any of the parameters are {@code null}.\n      */\n \n     public AbstractKafkaBasedDownstreamSender(final KafkaProducerFactory<String, Buffer> producerFactory,\n-            final String producerName, final Map<String, String> config, final Tracer tracer) {\n+            final String producerName, final Map<String, String> config, final ProtocolAdapterProperties adapterConfig,\n+            final Tracer tracer) {\n \n         Objects.requireNonNull(producerFactory);\n         Objects.requireNonNull(producerName);\n         Objects.requireNonNull(config);\n         Objects.requireNonNull(tracer);\n \n-        this.config = config;\n+        this.producerFactory = producerFactory;\n         this.producerName = producerName;\n+        this.config = config;\n+        this.adapterConfig = adapterConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "503a37d795895ac01342e95b422341274d6ca79e"}, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0NjcwNDk3", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-554670497", "createdAt": "2020-12-17T14:44:56Z", "commit": {"oid": "f1e425692cff85d36a6ee5df3801feb0ae3d0739"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxNDo0NDo1NlrOIH48TA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxNDo0NDo1NlrOIH48TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE0Mzg4NA==", "bodyText": "out of curiosity: which component uses/requires this dependency?", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r545143884", "createdAt": "2020-12-17T14:44:56Z", "author": {"login": "sophokles73"}, "path": "adapters/pom.xml", "diffHunk": "@@ -82,6 +82,10 @@\n       <groupId>io.opentracing</groupId>\n       <artifactId>opentracing-noop</artifactId>\n     </dependency>\n+    <dependency>\n+      <groupId>org.wildfly.security</groupId>\n+      <artifactId>wildfly-elytron-password-impl</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1e425692cff85d36a6ee5df3801feb0ae3d0739"}, "originalPosition": 6}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f1e425692cff85d36a6ee5df3801feb0ae3d0739", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/f1e425692cff85d36a6ee5df3801feb0ae3d0739", "committedDate": "2020-12-17T10:08:31Z", "message": "[#8] Add a null check.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}, "afterCommit": {"oid": "286d04671fc5ced239831cbec32bc1c15d77bf23", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/286d04671fc5ced239831cbec32bc1c15d77bf23", "committedDate": "2020-12-17T14:30:31Z", "message": "[#8] Update Hono version in hono kafka client and release notes.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "590952720f42998b5ae9d692230611225404d766", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/590952720f42998b5ae9d692230611225404d766", "committedDate": "2020-12-17T16:37:18Z", "message": "[#8] Add a Kafka based client for downstream messages.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "286d04671fc5ced239831cbec32bc1c15d77bf23", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/286d04671fc5ced239831cbec32bc1c15d77bf23", "committedDate": "2020-12-17T14:30:31Z", "message": "[#8] Update Hono version in hono kafka client and release notes.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}, "afterCommit": {"oid": "590952720f42998b5ae9d692230611225404d766", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/590952720f42998b5ae9d692230611225404d766", "committedDate": "2020-12-17T16:37:18Z", "message": "[#8] Add a Kafka based client for downstream messages.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0ODE0NjI2", "url": "https://github.com/eclipse/hono/pull/2303#pullrequestreview-554814626", "createdAt": "2020-12-17T17:15:22Z", "commit": {"oid": "590952720f42998b5ae9d692230611225404d766"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 444, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}