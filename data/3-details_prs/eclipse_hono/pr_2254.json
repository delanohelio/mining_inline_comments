{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA0ODA0MDM0", "number": 2254, "title": "[#8] Add specifications for the Kafka-based Telemetry API and Event API.", "bodyText": "Proposal for Kafka-based Telemetry and Events APIs. Required by [#8 ].\nHint:\nbuild and preview API specifications with:\n# from Hono's base directory\ncd site/documentation\nhugo server -v\n\nThen open http://localhost:1313/hono/docs/api/telemetry/#telemetry-api-for-kafka and http://localhost:1313/hono/docs/api/event/#event-api-for-kafka in browser.", "createdAt": "2020-10-16T12:24:56Z", "url": "https://github.com/eclipse/hono/pull/2254", "merged": true, "mergeCommit": {"oid": "02e82f610b9cb49c405bb76651909c8b74d78644"}, "closed": true, "closedAt": "2021-01-05T08:14:47Z", "author": {"login": "b-abel"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdT_g6hAFqTUxMTQ4NzI0NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdtGa7MAFqTU2MTU4NTQ4OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTExNDg3MjQ1", "url": "https://github.com/eclipse/hono/pull/2254#pullrequestreview-511487245", "createdAt": "2020-10-19T07:41:47Z", "commit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQwNzo0MTo0OFrOHkBgJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xOVQwODowMDo1N1rOHkCNrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA==", "bodyText": "is there a particular problem with sticking to using / as the path segment delimiter?", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507535398", "createdAt": "2020-10-19T07:41:48Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTg5Nw==", "bodyText": "is broker a common term for referring to Kafka?", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507535897", "createdAt": "2020-10-19T07:42:35Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzOTUyNg==", "bodyText": "Maybe we can refer to the Telemetry API for a description of the mentioned params ...", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507539526", "createdAt": "2020-10-19T07:48:31Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send event messages has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST set *acks* to `all`. Either MUST *enable.idempotence* be set to `true` OR *max.in.flight.requests.per.connection* MUST be set to `1`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MDE3NQ==", "bodyText": "is the exception being thrown after the client has re-tried to send the event to Kafka?", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507540175", "createdAt": "2020-10-19T07:49:36Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send event messages has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST set *acks* to `all`. Either MUST *enable.idempotence* be set to `true` OR *max.in.flight.requests.per.connection* MUST be set to `1`.\n+\n+\n+The recommended Kafka producer properties for *Event* messages are: `enable.idempotence=true`, `acks=all`, `max.in.flight.requests.per.connection=5`, leaving *retries* unset (which defaults to `Integer.MAX`), and setting *delivery.timeout.ms* to a reasonable value (supported from Kafka version 1.0.0 on). \n+\n+The following sequence diagram illustrates the flow of messages involved in the *MQTT Adapter* producing an event to the Kafka cluster.\n+\n+{{< figure src=\"produce_kafka.svg\" title=\"Produce event flow\" >}}\n+\n+1. *Device* `4711` publishes an event using MQTT QoS 1.\n+   1. *MQTT Adapter* produces an event message to *Kafka Cluster*.\n+   1. *Kafka cluster* acknowledges reception of the message.\n+   1. *MQTT Adapter* acknowledges the reception of the message to the *Device*.\n+\n+When the Kafka producer receives an exception when sending an event message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but MUST indicate the failed transfer to the device if the transport protocol provides means to do so.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MjA4Ng==", "bodyText": "is committing a message the common term for advancing the message pointer in the Kafka world?", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507542086", "createdAt": "2020-10-19T07:52:47Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send event messages has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST set *acks* to `all`. Either MUST *enable.idempotence* be set to `true` OR *max.in.flight.requests.per.connection* MUST be set to `1`.\n+\n+\n+The recommended Kafka producer properties for *Event* messages are: `enable.idempotence=true`, `acks=all`, `max.in.flight.requests.per.connection=5`, leaving *retries* unset (which defaults to `Integer.MAX`), and setting *delivery.timeout.ms* to a reasonable value (supported from Kafka version 1.0.0 on). \n+\n+The following sequence diagram illustrates the flow of messages involved in the *MQTT Adapter* producing an event to the Kafka cluster.\n+\n+{{< figure src=\"produce_kafka.svg\" title=\"Produce event flow\" >}}\n+\n+1. *Device* `4711` publishes an event using MQTT QoS 1.\n+   1. *MQTT Adapter* produces an event message to *Kafka Cluster*.\n+   1. *Kafka cluster* acknowledges reception of the message.\n+   1. *MQTT Adapter* acknowledges the reception of the message to the *Device*.\n+\n+When the Kafka producer receives an exception when sending an event message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but MUST indicate the failed transfer to the device if the transport protocol provides means to do so.\n+\n+**Message Format**\n+\n+See [Telemetry API]({{< relref \"/api/telemetry#produce-telemetry-data\" >}}) for the definition of the message format.\n+\n+### Northbound Operations\n+\n+The following operation can be used by *Business Applications* to receive event messages from Kafka.\n+\n+#### Consume Events\n+\n+Hono delivers messages containing events reported by a particular device in the same order that they have been received in (using the [Produce Event]({{< relref \"#produce-event\" >}}) operation).\n+*Business Applications* consume messages from the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` represents the ID of the tenant the client wants to retrieve event messages for.\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to read from the topic.\n+1. The client subscribes to the topic with a Kafka consumer. \n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST NOT commit messages until it has successfully completed consuming them.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MjY2Ng==", "bodyText": "I guess none at all. We cannot prevent people form doing what they want to do. We can only point out consequences of not following the behavior we propose in this context.", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507542666", "createdAt": "2020-10-19T07:53:41Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send event messages has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST set *acks* to `all`. Either MUST *enable.idempotence* be set to `true` OR *max.in.flight.requests.per.connection* MUST be set to `1`.\n+\n+\n+The recommended Kafka producer properties for *Event* messages are: `enable.idempotence=true`, `acks=all`, `max.in.flight.requests.per.connection=5`, leaving *retries* unset (which defaults to `Integer.MAX`), and setting *delivery.timeout.ms* to a reasonable value (supported from Kafka version 1.0.0 on). \n+\n+The following sequence diagram illustrates the flow of messages involved in the *MQTT Adapter* producing an event to the Kafka cluster.\n+\n+{{< figure src=\"produce_kafka.svg\" title=\"Produce event flow\" >}}\n+\n+1. *Device* `4711` publishes an event using MQTT QoS 1.\n+   1. *MQTT Adapter* produces an event message to *Kafka Cluster*.\n+   1. *Kafka cluster* acknowledges reception of the message.\n+   1. *MQTT Adapter* acknowledges the reception of the message to the *Device*.\n+\n+When the Kafka producer receives an exception when sending an event message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but MUST indicate the failed transfer to the device if the transport protocol provides means to do so.\n+\n+**Message Format**\n+\n+See [Telemetry API]({{< relref \"/api/telemetry#produce-telemetry-data\" >}}) for the definition of the message format.\n+\n+### Northbound Operations\n+\n+The following operation can be used by *Business Applications* to receive event messages from Kafka.\n+\n+#### Consume Events\n+\n+Hono delivers messages containing events reported by a particular device in the same order that they have been received in (using the [Produce Event]({{< relref \"#produce-event\" >}}) operation).\n+*Business Applications* consume messages from the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` represents the ID of the tenant the client wants to retrieve event messages for.\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to read from the topic.\n+1. The client subscribes to the topic with a Kafka consumer. \n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST NOT commit messages until it has successfully completed consuming them.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_How many assumptions about the behaviour of the consumers should hono make?_**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0Mzg4MA==", "bodyText": "absolutely \ud83d\udc4d", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507543880", "createdAt": "2020-10-19T07:55:45Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/telemetry/index.md", "diffHunk": "@@ -118,3 +121,134 @@ The *Business Application* can only consume telemetry messages that have been up\n **Message Format**\n \n The format of the messages containing the telemetry data is the same as for the [Forward Telemetry Data operation]({{< relref \"#forward-telemetry-data\" >}}).\n+\n+\n+## Telemetry API for Kafka\n+\n+Hono can alternatively be configured to publish telemetry data to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Telemetry API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send telemetry data received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Telemetry Data\n+\n+The protocol adapter writes messages to the tenant-specific topic `telemetry-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload telemetry data for.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a section with some basic explanations? E.g. like this:_**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0NTIyNA==", "bodyText": "IMHO that is a good idea", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507545224", "createdAt": "2020-10-19T07:57:55Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/telemetry/index.md", "diffHunk": "@@ -118,3 +121,134 @@ The *Business Application* can only consume telemetry messages that have been up\n **Message Format**\n \n The format of the messages containing the telemetry data is the same as for the [Forward Telemetry Data operation]({{< relref \"#forward-telemetry-data\" >}}).\n+\n+\n+## Telemetry API for Kafka\n+\n+Hono can alternatively be configured to publish telemetry data to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Telemetry API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send telemetry data received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Telemetry Data\n+\n+The protocol adapter writes messages to the tenant-specific topic `telemetry-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload telemetry data for.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a section with some basic explanations? E.g. like this:_**\n+\n+**On Acknowledgements, Retries and Message Ordering**\n+\n+The adapter indicates its preferred message delivery mode by means of the Kafka producer config properties *acks*, *retries*, and *max.in.flight.requests.per.connection*.\n+Setting *acks* to `0` effectively disables retries.\n+Setting *acks* to `1` requests only the partition leader to acknowledge the message. If the leader goes down before the followers finished replication, then the message will be lost.\n+Setting *acks* to `all` (or equivalent `-1`) requests the leader to wait for the acknowledgements from all in-sync replicas before sending the acknowledgement back to the client. \n+This guarantees that the message will not be lost as long as at least one in-sync replica remains alive.\n+\n+If *retries* are enabled and *max.in.flight.requests.per.connection* is set to a value greater than `1`, the order of the messages is no longer guaranteed by Kafka. \n+The only exception is the *idempotent* producer, which can handle *max.in.flight.requests.per.connection* to be up to `5` with retries enabled while still maintaining the message order (since Kafka version 1.0.0).\n+\n+{{% /note %}}\n+\n+**Preconditions**\n+\n+1. Either the topic `telemetry-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send telemetry data has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+It is up to the discretion of the protocol adapter whether it wants to use *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics.\n+To achieve *AT LEAST ONCE* delivery semantics the protocol adapter MUST request acknowledgements from *all* in-sync-replicas in the Kafka cluster.\n+For *AT MOST ONCE* delivery semantics the protocol adapter acknowledges the message to the device without waiting for any acknowledgements from the Kafka cluster.\n+If *retries* is greater than zero, *max.in.flight.requests.per.connection* MUST be set to `1`, except if *enable.idempotence* is set to `true`.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a table similar to the one in the AMQP Telemetry API? It could look like this:_**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0NzA1Mg==", "bodyText": "which device ID is that? The authenticated device's or the device's that the data originates from?", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507547052", "createdAt": "2020-10-19T08:00:57Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/telemetry/index.md", "diffHunk": "@@ -118,3 +121,134 @@ The *Business Application* can only consume telemetry messages that have been up\n **Message Format**\n \n The format of the messages containing the telemetry data is the same as for the [Forward Telemetry Data operation]({{< relref \"#forward-telemetry-data\" >}}).\n+\n+\n+## Telemetry API for Kafka\n+\n+Hono can alternatively be configured to publish telemetry data to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Telemetry API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send telemetry data received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Telemetry Data\n+\n+The protocol adapter writes messages to the tenant-specific topic `telemetry-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload telemetry data for.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a section with some basic explanations? E.g. like this:_**\n+\n+**On Acknowledgements, Retries and Message Ordering**\n+\n+The adapter indicates its preferred message delivery mode by means of the Kafka producer config properties *acks*, *retries*, and *max.in.flight.requests.per.connection*.\n+Setting *acks* to `0` effectively disables retries.\n+Setting *acks* to `1` requests only the partition leader to acknowledge the message. If the leader goes down before the followers finished replication, then the message will be lost.\n+Setting *acks* to `all` (or equivalent `-1`) requests the leader to wait for the acknowledgements from all in-sync replicas before sending the acknowledgement back to the client. \n+This guarantees that the message will not be lost as long as at least one in-sync replica remains alive.\n+\n+If *retries* are enabled and *max.in.flight.requests.per.connection* is set to a value greater than `1`, the order of the messages is no longer guaranteed by Kafka. \n+The only exception is the *idempotent* producer, which can handle *max.in.flight.requests.per.connection* to be up to `5` with retries enabled while still maintaining the message order (since Kafka version 1.0.0).\n+\n+{{% /note %}}\n+\n+**Preconditions**\n+\n+1. Either the topic `telemetry-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send telemetry data has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+It is up to the discretion of the protocol adapter whether it wants to use *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics.\n+To achieve *AT LEAST ONCE* delivery semantics the protocol adapter MUST request acknowledgements from *all* in-sync-replicas in the Kafka cluster.\n+For *AT MOST ONCE* delivery semantics the protocol adapter acknowledges the message to the device without waiting for any acknowledgements from the Kafka cluster.\n+If *retries* is greater than zero, *max.in.flight.requests.per.connection* MUST be set to `1`, except if *enable.idempotence* is set to `true`.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a table similar to the one in the AMQP Telemetry API? It could look like this:_**\n+\n+| acks  | retries   |  max.in.flight.requests.per.connection    | enable.idempotence    | Delivery semantics |\n+| :---: | :-----:   | :-------------------------------------:   | :-------------------: | :----------------- |\n+| 0     | 0  | >0 | `false` | Setting *acks* to `0` allows for adapters to implement *AT MOST ONCE* delivery semantics only. This is the fastest mode of delivery but has the drawback of potential loss of messages without notice. |\n+| 1     | 0  | >0 | `false` | Setting *acks* to `1` allows for adapters to implement *AT MOST ONCE* delivery semantics only. If the leader goes down before the followers finished replication, then the message will be lost. | \n+| 1     | >0 | 1  | `false` | Setting *acks* to `1` allows for adapters to implement *AT MOST ONCE* delivery semantics only. When retries are enabled, *max.in.flight.requests.per.connection* MUST be set to `1`. | \n+| all   | 0  | >0 | `false` | Setting *acks* to `all` allows for adapters to implement both *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics, depending on whether the adapter waits for and considers the acknowledgement it receives from the Kafka cluster or not. Disabling retries might cause messages to fail in case of high load or transient transmission failures. |\n+| all   | >0 | 1  | `false` | Setting *acks* to `all` allows for adapters to implement both *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics, depending on whether the adapter waits for and considers the acknowledgement it receives from the Kafka cluster or not. When retries are enabled, *max.in.flight.requests.per.connection* MUST be set to `1`. |\n+| all   | >0 | <6 | `true`  | Setting *acks* to `all` allows for adapters to implement both *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics, depending on whether the adapter waits for and considers the acknowledgement it receives from the Kafka cluster or not. |\n+\n+All other combinations are not supported by Hono.\n+{{% /note %}}\n+\n+The recommended Kafka producer properties for *AT LEAST ONCE* delivery are: `enable.idempotence=true`, `acks=all`, `max.in.flight.requests.per.connection=5`, leaving *retries* unset, and setting *delivery.timeout.ms* to a reasonable value (supported from Kafka version 1.0.0 on). \n+\n+The following sequence diagram illustrates the flow of messages involved in the *HTTP Adapter* producing a telemetry data message to the Kafka cluster implementing *AT MOST ONCE* delivery semantics.\n+\n+{{< figure src=\"produce_kafka_qos0.svg\" title=\"Produce telemetry data flow (AT MOST ONCE)\" >}}\n+\n+1. *Device* `4711` PUTs telemetry data to the *HTTP Adapter*\n+   1. *HTTP Adapter* produces telemetry data to *Kafka Cluster*.\n+   1. *HTTP Adapter* acknowledges the reception of the data to the *Device*.\n+\n+The following sequence diagram illustrates the flow of messages involved in the *HTTP Adapter* producing a telemetry data message to the Kafka cluster implementing *AT LEAST ONCE* delivery semantics.\n+\n+{{< figure src=\"produce_kafka_qos1.svg\" title=\"Produce telemetry data flow (AT LEAST ONCE)\" >}}\n+\n+1. *Device* `4711` PUTs telemetry data to the *HTTP Adapter*, indicating *QoS Level* 1.\n+   1. *HTTP Adapter* produces telemetry data to *Kafka Cluster*.\n+   1. *Kafka Cluster* acknowledges reception of the message.\n+   1. *HTTP Adapter* acknowledges the reception of the data to the *Device*.\n+\n+When the Kafka producer receives an exception when sending a telemetry message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but SHOULD indicate the failed transfer to the device if the transport protocol provides means to do so.\n+\n+**Message Format**\n+\n+A Kafka message (also called record) consists of a key, a value, a timestamp, and headers.\n+The key of the message MUST be the device ID.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 96}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIwNzE1NjMz", "url": "https://github.com/eclipse/hono/pull/2254#pullrequestreview-520715633", "createdAt": "2020-10-30T14:22:17Z", "commit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNDoyMjoxN1rOHrRRbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNDoyMjoxN1rOHrRRbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEzMzgwNQ==", "bodyText": "How about using either here? I think when you say both, then it means both AT LEAST ONCE and AT MOST ONCE.\nmaybe it is worth to distinguish how this implements AT LEAST ONCE or AT MOST ONCE delivery semantics. Do you mean that it implements AT LEAST ONCE when there is at least one alive in-sync replica that commits the message? And it implements AT MOST ONCE when no in-sync replica is alive, in which case the message will be lost?", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515133805", "createdAt": "2020-10-30T14:22:17Z", "author": {"login": "Alfusainey"}, "path": "site/documentation/content/api/telemetry/index.md", "diffHunk": "@@ -118,3 +121,134 @@ The *Business Application* can only consume telemetry messages that have been up\n **Message Format**\n \n The format of the messages containing the telemetry data is the same as for the [Forward Telemetry Data operation]({{< relref \"#forward-telemetry-data\" >}}).\n+\n+\n+## Telemetry API for Kafka\n+\n+Hono can alternatively be configured to publish telemetry data to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Telemetry API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send telemetry data received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Telemetry Data\n+\n+The protocol adapter writes messages to the tenant-specific topic `telemetry-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload telemetry data for.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a section with some basic explanations? E.g. like this:_**\n+\n+**On Acknowledgements, Retries and Message Ordering**\n+\n+The adapter indicates its preferred message delivery mode by means of the Kafka producer config properties *acks*, *retries*, and *max.in.flight.requests.per.connection*.\n+Setting *acks* to `0` effectively disables retries.\n+Setting *acks* to `1` requests only the partition leader to acknowledge the message. If the leader goes down before the followers finished replication, then the message will be lost.\n+Setting *acks* to `all` (or equivalent `-1`) requests the leader to wait for the acknowledgements from all in-sync replicas before sending the acknowledgement back to the client. \n+This guarantees that the message will not be lost as long as at least one in-sync replica remains alive.\n+\n+If *retries* are enabled and *max.in.flight.requests.per.connection* is set to a value greater than `1`, the order of the messages is no longer guaranteed by Kafka. \n+The only exception is the *idempotent* producer, which can handle *max.in.flight.requests.per.connection* to be up to `5` with retries enabled while still maintaining the message order (since Kafka version 1.0.0).\n+\n+{{% /note %}}\n+\n+**Preconditions**\n+\n+1. Either the topic `telemetry-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send telemetry data has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+It is up to the discretion of the protocol adapter whether it wants to use *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics.\n+To achieve *AT LEAST ONCE* delivery semantics the protocol adapter MUST request acknowledgements from *all* in-sync-replicas in the Kafka cluster.\n+For *AT MOST ONCE* delivery semantics the protocol adapter acknowledges the message to the device without waiting for any acknowledgements from the Kafka cluster.\n+If *retries* is greater than zero, *max.in.flight.requests.per.connection* MUST be set to `1`, except if *enable.idempotence* is set to `true`.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a table similar to the one in the AMQP Telemetry API? It could look like this:_**\n+\n+| acks  | retries   |  max.in.flight.requests.per.connection    | enable.idempotence    | Delivery semantics |\n+| :---: | :-----:   | :-------------------------------------:   | :-------------------: | :----------------- |\n+| 0     | 0  | >0 | `false` | Setting *acks* to `0` allows for adapters to implement *AT MOST ONCE* delivery semantics only. This is the fastest mode of delivery but has the drawback of potential loss of messages without notice. |\n+| 1     | 0  | >0 | `false` | Setting *acks* to `1` allows for adapters to implement *AT MOST ONCE* delivery semantics only. If the leader goes down before the followers finished replication, then the message will be lost. | \n+| 1     | >0 | 1  | `false` | Setting *acks* to `1` allows for adapters to implement *AT MOST ONCE* delivery semantics only. When retries are enabled, *max.in.flight.requests.per.connection* MUST be set to `1`. | \n+| all   | 0  | >0 | `false` | Setting *acks* to `all` allows for adapters to implement both *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics, depending on whether the adapter waits for and considers the acknowledgement it receives from the Kafka cluster or not. Disabling retries might cause messages to fail in case of high load or transient transmission failures. |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf"}, "originalPosition": 65}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4ODEyMTIx", "url": "https://github.com/eclipse/hono/pull/2254#pullrequestreview-528812121", "createdAt": "2020-11-12T07:35:15Z", "commit": {"oid": "0e102dd5b22ab4204cbc1481d526864d9963cd82"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNzozNToxNVrOHxtsrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNzozNToxNVrOHxtsrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg5MDk4OQ==", "bodyText": "it might be helpful to also explain the reason for this requirement.", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r521890989", "createdAt": "2020-11-12T07:35:15Z", "author": {"login": "sophokles73"}, "path": "site/documentation/content/api/kafka/telemetry-kafka/index.md", "diffHunk": "@@ -141,6 +144,13 @@ The following sequence diagram illustrates the flow of messages involved in the\n \n When a Kafka producer raises an exception while sending a telemetry message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but SHOULD indicate the failed transfer to the device if the transport protocol provides means to do so.\n \n+**Use *AT LEAST ONCE* and *AT MOST ONCE* in a Protocol Adapter**\n+\n+If a protocol adapter should support both delivery semantics, a single producer MUST be used and it MUST be configured \n+for *AT LEAST ONCE*. It may not wait for acknowledgements of *AT MOST ONCE* messages. \n+\n+A protocol adapter MUST NOT use two producers sending telemetry data for the same device.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e102dd5b22ab4204cbc1481d526864d9963cd82"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e67730e7d68d614f70a632ed8096705230d72d9", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/1e67730e7d68d614f70a632ed8096705230d72d9", "committedDate": "2021-01-04T11:16:01Z", "message": "[#8] Add specifications for the Kafka-based Telemetry API and Event API.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d5a39606bd04ac3af5159bd429232fce0f9c6d1", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/5d5a39606bd04ac3af5159bd429232fce0f9c6d1", "committedDate": "2021-01-04T11:16:01Z", "message": "[#8] Add preview notice to Kafka API documentation.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfe5a6f2ecfa02e7c95621b33d555b8cfa880507", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/cfe5a6f2ecfa02e7c95621b33d555b8cfa880507", "committedDate": "2021-01-04T11:16:01Z", "message": "[#8] Add Kafka APIs to release notes.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb1e1753edc80e8988bf10787a4bf2d964ae91c1", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/bb1e1753edc80e8988bf10787a4bf2d964ae91c1", "committedDate": "2021-01-04T11:47:43Z", "message": "[#8] Do not use a sub-menu for Kafka-based API specifications.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fca4a56ee4347cd2047e988dd021fa34feb7a02a", "author": {"user": {"login": "sophokles73", "name": "Kai Hudalla"}}, "url": "https://github.com/eclipse/hono/commit/fca4a56ee4347cd2047e988dd021fa34feb7a02a", "committedDate": "2020-12-22T08:01:36Z", "message": "Merge branch 'master' into PR/kafka_api_spec"}, "afterCommit": {"oid": "bb1e1753edc80e8988bf10787a4bf2d964ae91c1", "author": {"user": {"login": "b-abel", "name": "Abel B\u00fcchner-Mihaljevi\u0107"}}, "url": "https://github.com/eclipse/hono/commit/bb1e1753edc80e8988bf10787a4bf2d964ae91c1", "committedDate": "2021-01-04T11:47:43Z", "message": "[#8] Do not use a sub-menu for Kafka-based API specifications.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxMDQ3NTAy", "url": "https://github.com/eclipse/hono/pull/2254#pullrequestreview-561047502", "createdAt": "2021-01-04T13:57:34Z", "commit": {"oid": "bb1e1753edc80e8988bf10787a4bf2d964ae91c1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxNTg1NDg4", "url": "https://github.com/eclipse/hono/pull/2254#pullrequestreview-561585488", "createdAt": "2021-01-05T08:12:40Z", "commit": {"oid": "bb1e1753edc80e8988bf10787a4bf2d964ae91c1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 399, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}