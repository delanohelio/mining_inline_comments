{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkxOTI5OTg4", "number": 1436, "title": "[HUDI-711] Refactor exporter main logic", "bodyText": "break main method into multiple readable methods\nfix bug of passing wrong file list\navoid deleting output path when exists\nthrow exception to early abort on multiple cases\nuse JavaSparkContext instead of SparkSession\n\nVerify this pull request\nThis pull request is already covered by existing tests, such as (please describe tests).\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-03-21T23:27:38Z", "url": "https://github.com/apache/hudi/pull/1436", "merged": true, "mergeCommit": {"oid": "bc82e2be6cf080ab99092758368e91f509a2004c"}, "closed": true, "closedAt": "2020-03-25T10:02:25Z", "author": {"login": "xushiyan"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcP9tmpAH2gAyMzkxOTI5OTg4OmI0OTY5ODMzYjYyYzA2MDA0OWY0NThlNmY0MGQ2MmY3YzBjY2U0MGM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcREi7dAFqTM4MTAwMTg3Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "b4969833b62c060049f458e6f40d62f7c0cce40c", "author": {"user": {"login": "xushiyan", "name": "Raymond Xu"}}, "url": "https://github.com/apache/hudi/commit/b4969833b62c060049f458e6f40d62f7c0cce40c", "committedDate": "2020-03-21T23:28:58Z", "message": "Refactor exporter main logic\n\n* break main method into multiple readable methods\n* fix bug of passing wrong file list\n* avoid deleting output path when exists\n* throw exception to early abort on multiple cases"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "b4969833b62c060049f458e6f40d62f7c0cce40c", "author": {"user": {"login": "xushiyan", "name": "Raymond Xu"}}, "url": "https://github.com/apache/hudi/commit/b4969833b62c060049f458e6f40d62f7c0cce40c", "committedDate": "2020-03-21T23:28:58Z", "message": "Refactor exporter main logic\n\n* break main method into multiple readable methods\n* fix bug of passing wrong file list\n* avoid deleting output path when exists\n* throw exception to early abort on multiple cases"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4OTYwMDEx", "url": "https://github.com/apache/hudi/pull/1436#pullrequestreview-378960011", "createdAt": "2020-03-21T23:34:50Z", "commit": {"oid": "b4969833b62c060049f458e6f40d62f7c0cce40c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQyMzozNDo1MFrOF5sTKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQyMzozNDo1MFrOF5sTKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjAzODk1Mw==", "bodyText": "We don't want to accidentally delete output directory.", "url": "https://github.com/apache/hudi/pull/1436#discussion_r396038953", "createdAt": "2020-03-21T23:34:50Z", "author": {"login": "xushiyan"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java", "diffHunk": "@@ -160,37 +174,36 @@ private void exportAsNonHudi(SparkSession spark, Config cfg, List<String> dataFi\n         ? defaultPartitioner\n         : ReflectionUtils.loadClass(cfg.outputPartitioner);\n \n-    Dataset<Row> sourceDataset = spark.read().parquet(JavaConversions.asScalaIterator(dataFiles.iterator()).toSeq());\n+    final JavaSparkContext jsc = new JavaSparkContext(spark.sparkContext());\n+    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n+    Iterator<String> exportingFilePaths = jsc\n+        .parallelize(partitions, partitions.size())\n+        .flatMap(partition -> fsView\n+            .getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp)\n+            .map(HoodieBaseFile::getPath).iterator())\n+        .toLocalIterator();\n+\n+    Dataset<Row> sourceDataset = spark.read().parquet(JavaConversions.asScalaIterator(exportingFilePaths).toSeq());\n     partitioner.partition(sourceDataset)\n         .format(cfg.outputFormat)\n         .mode(SaveMode.Overwrite)\n         .save(cfg.targetOutputPath);\n   }\n \n-  private void copySnapshot(JavaSparkContext jsc,\n-      FileSystem fs,\n-      Config cfg,\n-      List<String> partitions,\n-      List<String> dataFiles,\n-      String latestCommitTimestamp,\n-      SerializableConfiguration serConf) throws IOException {\n-    // Make sure the output directory is empty\n-    Path outputPath = new Path(cfg.targetOutputPath);\n-    if (fs.exists(outputPath)) {\n-      LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n-      fs.delete(new Path(cfg.targetOutputPath), true);\n-    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4969833b62c060049f458e6f40d62f7c0cce40c"}, "originalPosition": 147}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4OTYwMTY1", "url": "https://github.com/apache/hudi/pull/1436#pullrequestreview-378960165", "createdAt": "2020-03-21T23:38:04Z", "commit": {"oid": "b4969833b62c060049f458e6f40d62f7c0cce40c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQyMzozODowNFrOF5sUAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMVQyMzozODowNFrOF5sUAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjAzOTE2OQ==", "bodyText": "Fix dataFiles by scanning the current partition.", "url": "https://github.com/apache/hudi/pull/1436#discussion_r396039169", "createdAt": "2020-03-21T23:38:04Z", "author": {"login": "xushiyan"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/HoodieSnapshotExporter.java", "diffHunk": "@@ -160,37 +174,36 @@ private void exportAsNonHudi(SparkSession spark, Config cfg, List<String> dataFi\n         ? defaultPartitioner\n         : ReflectionUtils.loadClass(cfg.outputPartitioner);\n \n-    Dataset<Row> sourceDataset = spark.read().parquet(JavaConversions.asScalaIterator(dataFiles.iterator()).toSeq());\n+    final JavaSparkContext jsc = new JavaSparkContext(spark.sparkContext());\n+    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n+    Iterator<String> exportingFilePaths = jsc\n+        .parallelize(partitions, partitions.size())\n+        .flatMap(partition -> fsView\n+            .getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp)\n+            .map(HoodieBaseFile::getPath).iterator())\n+        .toLocalIterator();\n+\n+    Dataset<Row> sourceDataset = spark.read().parquet(JavaConversions.asScalaIterator(exportingFilePaths).toSeq());\n     partitioner.partition(sourceDataset)\n         .format(cfg.outputFormat)\n         .mode(SaveMode.Overwrite)\n         .save(cfg.targetOutputPath);\n   }\n \n-  private void copySnapshot(JavaSparkContext jsc,\n-      FileSystem fs,\n-      Config cfg,\n-      List<String> partitions,\n-      List<String> dataFiles,\n-      String latestCommitTimestamp,\n-      SerializableConfiguration serConf) throws IOException {\n-    // Make sure the output directory is empty\n-    Path outputPath = new Path(cfg.targetOutputPath);\n-    if (fs.exists(outputPath)) {\n-      LOG.warn(String.format(\"The output path %s targetBasePath already exists, deleting\", outputPath));\n-      fs.delete(new Path(cfg.targetOutputPath), true);\n-    }\n-\n+  private void exportAsHudi(JavaSparkContext jsc, Config cfg, List<String> partitions, String latestCommitTimestamp) throws IOException {\n+    final BaseFileOnlyView fsView = getBaseFileOnlyView(jsc, cfg);\n+    final SerializableConfiguration serConf = new SerializableConfiguration(jsc.hadoopConfiguration());\n     jsc.parallelize(partitions, partitions.size()).flatMap(partition -> {\n       // Only take latest version files <= latestCommit.\n-      FileSystem fs1 = FSUtils.getFs(cfg.sourceBasePath, serConf.newCopy());\n       List<Tuple2<String, String>> filePaths = new ArrayList<>();\n-      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile)));\n+      Stream<HoodieBaseFile> dataFiles = fsView.getLatestBaseFilesBeforeOrOn(partition, latestCommitTimestamp);\n+      dataFiles.forEach(hoodieDataFile -> filePaths.add(new Tuple2<>(partition, hoodieDataFile.getPath())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4969833b62c060049f458e6f40d62f7c0cce40c"}, "originalPosition": 158}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "45b3ef61135f65629ebc4dba2664dd669de81dd6", "author": {"user": {"login": "xushiyan", "name": "Raymond Xu"}}, "url": "https://github.com/apache/hudi/commit/45b3ef61135f65629ebc4dba2664dd669de81dd6", "committedDate": "2020-03-22T01:09:39Z", "message": "add more testcases"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "45b3ef61135f65629ebc4dba2664dd669de81dd6", "author": {"user": {"login": "xushiyan", "name": "Raymond Xu"}}, "url": "https://github.com/apache/hudi/commit/45b3ef61135f65629ebc4dba2664dd669de81dd6", "committedDate": "2020-03-22T01:09:39Z", "message": "add more testcases"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0", "author": {"user": {"login": "xushiyan", "name": "Raymond Xu"}}, "url": "https://github.com/apache/hudi/commit/5bb9e0b111b3d46f6186082c1c8e55571053f8c0", "committedDate": "2020-03-22T15:55:01Z", "message": "Use JavaSparkContext instead of SparkSession"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwODMyMzE0", "url": "https://github.com/apache/hudi/pull/1436#pullrequestreview-380832314", "createdAt": "2020-03-25T03:08:03Z", "commit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzowODowM1rOF7Kp2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzowODowM1rOF7Kp2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU4NDg1Nw==", "bodyText": "use fail assert?", "url": "https://github.com/apache/hudi/pull/1436#discussion_r397584857", "createdAt": "2020-03-25T03:08:03Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieSnapshotExporter.java", "diffHunk": "@@ -159,18 +161,85 @@ public void testExportAsHudi() throws IOException {\n       assertTrue(dfs.exists(new Path(partition + \"/.hoodie_partition_metadata\")));\n       assertTrue(dfs.exists(new Path(targetPath + \"/_SUCCESS\")));\n     }\n+  }\n+\n+  public static class TestHoodieSnapshotExporterForEarlyAbort extends ExporterTestHarness {\n+\n+    private HoodieSnapshotExporter.Config cfg;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+      super.setUp();\n+      cfg = new Config();\n+      cfg.sourceBasePath = sourcePath;\n+      cfg.targetOutputPath = targetPath;\n+      cfg.outputFormat = OutputFormatValidator.HUDI;\n+    }\n \n     @Test\n-    public void testExportEmptyDataset() throws IOException {\n+    public void testExportWhenTargetPathExists() throws IOException {\n+      // make target output path present\n+      dfs.mkdirs(new Path(targetPath));\n+\n+      // export\n+      Throwable t = null;\n+      try {\n+        new HoodieSnapshotExporter().export(jsc, cfg);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0"}, "originalPosition": 76}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwODMyMzkz", "url": "https://github.com/apache/hudi/pull/1436#pullrequestreview-380832393", "createdAt": "2020-03-25T03:08:23Z", "commit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzowODoyM1rOF7KqHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzowODoyM1rOF7KqHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU4NDkyNg==", "bodyText": "would move to catch block?", "url": "https://github.com/apache/hudi/pull/1436#discussion_r397584926", "createdAt": "2020-03-25T03:08:23Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieSnapshotExporter.java", "diffHunk": "@@ -159,18 +161,85 @@ public void testExportAsHudi() throws IOException {\n       assertTrue(dfs.exists(new Path(partition + \"/.hoodie_partition_metadata\")));\n       assertTrue(dfs.exists(new Path(targetPath + \"/_SUCCESS\")));\n     }\n+  }\n+\n+  public static class TestHoodieSnapshotExporterForEarlyAbort extends ExporterTestHarness {\n+\n+    private HoodieSnapshotExporter.Config cfg;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+      super.setUp();\n+      cfg = new Config();\n+      cfg.sourceBasePath = sourcePath;\n+      cfg.targetOutputPath = targetPath;\n+      cfg.outputFormat = OutputFormatValidator.HUDI;\n+    }\n \n     @Test\n-    public void testExportEmptyDataset() throws IOException {\n+    public void testExportWhenTargetPathExists() throws IOException {\n+      // make target output path present\n+      dfs.mkdirs(new Path(targetPath));\n+\n+      // export\n+      Throwable t = null;\n+      try {\n+        new HoodieSnapshotExporter().export(jsc, cfg);\n+      } catch (Exception e) {\n+        t = e;\n+      } finally {\n+        assertNotNull(t);\n+        assertTrue(t instanceof HoodieSnapshotExporterException);\n+        assertEquals(\"The target output path already exists.\", t.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0"}, "originalPosition": 82}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwODMyNTA4", "url": "https://github.com/apache/hudi/pull/1436#pullrequestreview-380832508", "createdAt": "2020-03-25T03:08:46Z", "commit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzowODo0NlrOF7Kqkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzowODo0NlrOF7Kqkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU4NTA0Mg==", "bodyText": "ditto", "url": "https://github.com/apache/hudi/pull/1436#discussion_r397585042", "createdAt": "2020-03-25T03:08:46Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieSnapshotExporter.java", "diffHunk": "@@ -159,18 +161,85 @@ public void testExportAsHudi() throws IOException {\n       assertTrue(dfs.exists(new Path(partition + \"/.hoodie_partition_metadata\")));\n       assertTrue(dfs.exists(new Path(targetPath + \"/_SUCCESS\")));\n     }\n+  }\n+\n+  public static class TestHoodieSnapshotExporterForEarlyAbort extends ExporterTestHarness {\n+\n+    private HoodieSnapshotExporter.Config cfg;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+      super.setUp();\n+      cfg = new Config();\n+      cfg.sourceBasePath = sourcePath;\n+      cfg.targetOutputPath = targetPath;\n+      cfg.outputFormat = OutputFormatValidator.HUDI;\n+    }\n \n     @Test\n-    public void testExportEmptyDataset() throws IOException {\n+    public void testExportWhenTargetPathExists() throws IOException {\n+      // make target output path present\n+      dfs.mkdirs(new Path(targetPath));\n+\n+      // export\n+      Throwable t = null;\n+      try {\n+        new HoodieSnapshotExporter().export(jsc, cfg);\n+      } catch (Exception e) {\n+        t = e;\n+      } finally {\n+        assertNotNull(t);\n+        assertTrue(t instanceof HoodieSnapshotExporterException);\n+        assertEquals(\"The target output path already exists.\", t.getMessage());\n+      }\n+    }\n+\n+    @Test\n+    public void testExportDatasetWithNoCommit() throws IOException {\n+      // delete commit files\n+      List<Path> commitFiles = Arrays.stream(dfs.listStatus(new Path(sourcePath + \"/.hoodie\")))\n+          .map(FileStatus::getPath)\n+          .filter(filePath -> filePath.getName().endsWith(\".commit\"))\n+          .collect(Collectors.toList());\n+      for (Path p : commitFiles) {\n+        dfs.delete(p, false);\n+      }\n+\n+      // export\n+      Throwable t = null;\n+      try {\n+        new HoodieSnapshotExporter().export(jsc, cfg);\n+      } catch (Exception e) {\n+        t = e;\n+      } finally {\n+        assertNotNull(t);\n+        assertTrue(t instanceof HoodieSnapshotExporterException);\n+        assertEquals(\"No commits present. Nothing to snapshot.\", t.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0"}, "originalPosition": 106}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwODMyNTk0", "url": "https://github.com/apache/hudi/pull/1436#pullrequestreview-380832594", "createdAt": "2020-03-25T03:09:02Z", "commit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzowOTowMlrOF7Kq5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQwMzowOTowMlrOF7Kq5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU4NTEyNg==", "bodyText": "ditto", "url": "https://github.com/apache/hudi/pull/1436#discussion_r397585126", "createdAt": "2020-03-25T03:09:02Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieSnapshotExporter.java", "diffHunk": "@@ -159,18 +161,85 @@ public void testExportAsHudi() throws IOException {\n       assertTrue(dfs.exists(new Path(partition + \"/.hoodie_partition_metadata\")));\n       assertTrue(dfs.exists(new Path(targetPath + \"/_SUCCESS\")));\n     }\n+  }\n+\n+  public static class TestHoodieSnapshotExporterForEarlyAbort extends ExporterTestHarness {\n+\n+    private HoodieSnapshotExporter.Config cfg;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+      super.setUp();\n+      cfg = new Config();\n+      cfg.sourceBasePath = sourcePath;\n+      cfg.targetOutputPath = targetPath;\n+      cfg.outputFormat = OutputFormatValidator.HUDI;\n+    }\n \n     @Test\n-    public void testExportEmptyDataset() throws IOException {\n+    public void testExportWhenTargetPathExists() throws IOException {\n+      // make target output path present\n+      dfs.mkdirs(new Path(targetPath));\n+\n+      // export\n+      Throwable t = null;\n+      try {\n+        new HoodieSnapshotExporter().export(jsc, cfg);\n+      } catch (Exception e) {\n+        t = e;\n+      } finally {\n+        assertNotNull(t);\n+        assertTrue(t instanceof HoodieSnapshotExporterException);\n+        assertEquals(\"The target output path already exists.\", t.getMessage());\n+      }\n+    }\n+\n+    @Test\n+    public void testExportDatasetWithNoCommit() throws IOException {\n+      // delete commit files\n+      List<Path> commitFiles = Arrays.stream(dfs.listStatus(new Path(sourcePath + \"/.hoodie\")))\n+          .map(FileStatus::getPath)\n+          .filter(filePath -> filePath.getName().endsWith(\".commit\"))\n+          .collect(Collectors.toList());\n+      for (Path p : commitFiles) {\n+        dfs.delete(p, false);\n+      }\n+\n+      // export\n+      Throwable t = null;\n+      try {\n+        new HoodieSnapshotExporter().export(jsc, cfg);\n+      } catch (Exception e) {\n+        t = e;\n+      } finally {\n+        assertNotNull(t);\n+        assertTrue(t instanceof HoodieSnapshotExporterException);\n+        assertEquals(\"No commits present. Nothing to snapshot.\", t.getMessage());\n+      }\n+\n+      // Check results\n+      assertFalse(dfs.exists(new Path(targetPath)));\n+    }\n+\n+    @Test\n+    public void testExportDatasetWithNoPartition() throws IOException {\n       // delete all source data\n       dfs.delete(new Path(sourcePath + \"/\" + PARTITION_PATH), true);\n \n       // export\n-      new HoodieSnapshotExporter().export(SparkSession.builder().config(jsc.getConf()).getOrCreate(), cfg);\n+      Throwable t = null;\n+      try {\n+        new HoodieSnapshotExporter().export(jsc, cfg);\n+      } catch (Exception e) {\n+        t = e;\n+      } finally {\n+        assertNotNull(t);\n+        assertTrue(t instanceof HoodieSnapshotExporterException);\n+        assertEquals(\"The source dataset has 0 partition to snapshot.\", t.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0"}, "originalPosition": 128}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwODMzMzcx", "url": "https://github.com/apache/hudi/pull/1436#pullrequestreview-380833371", "createdAt": "2020-03-25T03:11:52Z", "commit": {"oid": "5bb9e0b111b3d46f6186082c1c8e55571053f8c0"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6bb034656370b3360082de5f8e19e2ce52eeb49a", "author": {"user": {"login": "xushiyan", "name": "Raymond Xu"}}, "url": "https://github.com/apache/hudi/commit/6bb034656370b3360082de5f8e19e2ce52eeb49a", "committedDate": "2020-03-25T03:53:04Z", "message": "improve unit test for expected exceptions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxMDAxODc3", "url": "https://github.com/apache/hudi/pull/1436#pullrequestreview-381001877", "createdAt": "2020-03-25T10:00:35Z", "commit": {"oid": "6bb034656370b3360082de5f8e19e2ce52eeb49a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3227, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}