{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM3OTkzNzY0", "number": 1756, "reviewThreads": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyMDozMlrOEILSVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwMzo0MzowNlrOEP78Bw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDA4OTgxOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/test/java/org/apache/hudi/table/action/rollback/TestCopyOnWriteRollbackActionExecutor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyMDozMlrOGn-1Rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyMDozMlrOGn-1Rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3NzA5NA==", "bodyText": "cc @xushiyan I feel just making these two commits or this template code in some TestHelper.. will clean up code by a lot..", "url": "https://github.com/apache/hudi/pull/1756#discussion_r444577094", "createdAt": "2020-06-24T00:20:32Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/test/java/org/apache/hudi/table/action/rollback/TestCopyOnWriteRollbackActionExecutor.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.rollback;\n+\n+import org.apache.hudi.common.model.FileSlice;\n+import org.apache.hudi.common.model.HoodieFileGroup;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.client.HoodieWriteClient;\n+import org.apache.hudi.client.WriteStatus;\n+import org.apache.hudi.common.HoodieRollbackStat;\n+import org.apache.hudi.common.testutils.HoodieTestUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieIndexConfig;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.index.HoodieIndex;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.testutils.HoodieClientTestBase;\n+import org.apache.hudi.testutils.HoodieTestDataGenerator;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_SECOND_PARTITION_PATH;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+public class TestCopyOnWriteRollbackActionExecutor extends HoodieClientTestBase {\n+  @BeforeEach\n+  public void setUp() throws Exception {\n+    initPath();\n+    initSparkContexts();\n+    //just generate tow partitions\n+    dataGen = new HoodieTestDataGenerator(new String[]{DEFAULT_FIRST_PARTITION_PATH, DEFAULT_SECOND_PARTITION_PATH});\n+    initFileSystem();\n+    initMetaClient();\n+  }\n+\n+  @AfterEach\n+  public void tearDown() throws Exception {\n+    cleanupResources();\n+  }\n+\n+  @Test\n+  public void testCopyOnWriteRollbackActionExecutorForFileListingAsGenerateFile() throws IOException {\n+    // Let's create some commit files and parquet files\n+    String commitTime1 = \"001\";\n+    String commitTime2 = \"002\";\n+    new File(basePath + \"/.hoodie\").mkdirs();\n+    HoodieTestDataGenerator.writePartitionMetadata(fs, new String[]{\"2015/03/16\", \"2015/03/17\", \"2016/03/15\"},\n+        basePath);\n+    HoodieTestUtils.createCommitFiles(basePath, commitTime1, commitTime2);\n+\n+    // Make commit1\n+    String file11 = HoodieTestUtils.createDataFile(basePath, \"2015/03/16\", commitTime1, \"id11\");\n+    HoodieTestUtils.createNewLogFile(fs, basePath, \"2015/03/16\",\n+        commitTime1, \"id11\", Option.of(3));\n+    String file12 = HoodieTestUtils.createDataFile(basePath, \"2015/03/17\", commitTime1, \"id12\");\n+\n+    // Make commit2\n+    String file21 = HoodieTestUtils.createDataFile(basePath, \"2015/03/16\", commitTime2, \"id21\");\n+    String file22 = HoodieTestUtils.createDataFile(basePath, \"2015/03/17\", commitTime2, \"id22\");\n+    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath)\n+        .withIndexConfig(HoodieIndexConfig.newBuilder().withIndexType(HoodieIndex.IndexType.INMEMORY).build()).build();\n+    HoodieTable table = this.getHoodieTable(metaClient, config);\n+    HoodieInstant needRollBackInstant = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, \"002\");\n+\n+    // execute CopyOnWriteRollbackActionExecutor with filelisting mode\n+    CopyOnWriteRollbackActionExecutor copyOnWriteRollbackActionExecutor = new CopyOnWriteRollbackActionExecutor(jsc, config, table, \"003\", needRollBackInstant, true);\n+    assertFalse(copyOnWriteRollbackActionExecutor.getRollbackStrategy() instanceof MarkerBasedRollbackStrategy);\n+    List<HoodieRollbackStat> hoodieRollbackStats = copyOnWriteRollbackActionExecutor.executeRollback();\n+\n+    // assert hoodieRollbackStats\n+    assertEquals(hoodieRollbackStats.size(), 3);\n+    hoodieRollbackStats.forEach(stat -> {\n+      if (stat.getPartitionPath().equals(\"2015/03/16\")) {\n+        assertEquals(1, stat.getSuccessDeleteFiles().size());\n+        assertEquals(0, stat.getFailedDeleteFiles().size());\n+        assertEquals(null, stat.getCommandBlocksCount());\n+        assertEquals(\"file:\" + HoodieTestUtils.getDataFilePath(basePath, \"2015/03/16\", commitTime2, file21),\n+            stat.getSuccessDeleteFiles().get(0));\n+      } else if (stat.getPartitionPath().equals(\"2015/03/17\")) {\n+        assertEquals(1, stat.getSuccessDeleteFiles().size());\n+        assertEquals(0, stat.getFailedDeleteFiles().size());\n+        assertEquals(null, stat.getCommandBlocksCount());\n+        assertEquals(\"file:\" + HoodieTestUtils.getDataFilePath(basePath, \"2015/03/17\", commitTime2, file22),\n+            stat.getSuccessDeleteFiles().get(0));\n+      } else if (stat.getPartitionPath().equals(\"2015/03/17\")) {\n+        assertEquals(0, stat.getSuccessDeleteFiles().size());\n+        assertEquals(0, stat.getFailedDeleteFiles().size());\n+        assertEquals(null, stat.getCommandBlocksCount());\n+      }\n+    });\n+\n+    assertTrue(HoodieTestUtils.doesCommitExist(basePath, \"001\"));\n+    assertTrue(HoodieTestUtils.doesInflightExist(basePath, \"001\"));\n+    assertFalse(HoodieTestUtils.doesCommitExist(basePath, \"002\"));\n+    assertFalse(HoodieTestUtils.doesInflightExist(basePath, \"002\"));\n+    assertTrue(HoodieTestUtils.doesDataFileExist(basePath, \"2015/03/16\", commitTime1, file11)\n+        && HoodieTestUtils.doesDataFileExist(basePath, \"2015/03/17\", commitTime1, file12));\n+    assertFalse(HoodieTestUtils.doesDataFileExist(basePath, \"2015/03/16\", commitTime2, file21)\n+        || HoodieTestUtils.doesDataFileExist(basePath, \"2015/03/17\", commitTime2, file22));\n+  }\n+\n+  private void twoUpsertCommitDataRollBack(boolean isUsingMarkers) throws IOException {\n+    //1. prepare data\n+    HoodieWriteConfig cfg = getConfigBuilder().withRollbackUsingMarkers(isUsingMarkers).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e55ce7cd424bf33aa0eb2420449c34a19ecfa891"}, "originalPosition": 133}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMzI3NDA2OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/client/HoodieWriteClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNFQwMDowMzoxMlrOGs41bQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMTozODozMlrOGtGjLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTcyMTcwOQ==", "bodyText": "I am wondering if we should do this always.. having this logic be rollback dependent can become hard to reason with in the long run", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449721709", "createdAt": "2020-07-04T00:03:12Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/client/HoodieWriteClient.java", "diffHunk": "@@ -332,9 +333,11 @@ public static SparkConf registerClasses(SparkConf conf) {\n   }\n \n   @Override\n-  protected void postCommit(HoodieCommitMetadata metadata, String instantTime,\n-      Option<Map<String, String>> extraMetadata) {\n+  protected void postCommit(HoodieTable<?> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n+      if (!config.getRollBackUsingMarkers()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk0NjQxMw==", "bodyText": "i  also think  it not so good. i think can do not delete markerfiles here.Can delete the unuseful   markerfile in pre-commit. when clean delete the old markerfiles", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449946413", "createdAt": "2020-07-06T01:38:32Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/main/java/org/apache/hudi/client/HoodieWriteClient.java", "diffHunk": "@@ -332,9 +333,11 @@ public static SparkConf registerClasses(SparkConf conf) {\n   }\n \n   @Override\n-  protected void postCommit(HoodieCommitMetadata metadata, String instantTime,\n-      Option<Map<String, String>> extraMetadata) {\n+  protected void postCommit(HoodieTable<?> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n+      if (!config.getRollBackUsingMarkers()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTcyMTcwOQ=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMzI3NDk3OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNFQwMDowNDo1NlrOGs413g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMTozOToxMFrOGtGjpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTcyMTgyMg==", "bodyText": "Reflecting on this, probably good to rename MarkerType to IOType..", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449721822", "createdAt": "2020-07-04T00:04:56Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -278,6 +286,11 @@ public WriteStatus getWriteStatus() {\n     return writeStatus;\n   }\n \n+  @Override\n+  public MarkerFiles.MarkerType getIOType() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk0NjUzMg==", "bodyText": "to IOType will be better", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449946532", "createdAt": "2020-07-06T01:39:10Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -278,6 +286,11 @@ public WriteStatus getWriteStatus() {\n     return writeStatus;\n   }\n \n+  @Override\n+  public MarkerFiles.MarkerType getIOType() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTcyMTgyMg=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMzgxNzYxOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieMergeHandle.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNFQxNjozNDo1OVrOGs8zxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMTo0MzozN1rOGtGm3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTc4NjgyMw==", "bodyText": "probably need to ensure we are getting the base file format extension from the hoodieTable instance?", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449786823", "createdAt": "2020-07-04T16:34:59Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieMergeHandle.java", "diffHunk": "@@ -113,8 +109,9 @@ private void init(String fileId, String partitionPath, HoodieBaseFile dataFileTo\n       partitionMetadata.trySave(getPartitionId());\n \n       oldFilePath = new Path(config.getBasePath() + \"/\" + partitionPath + \"/\" + latestValidFilePath);\n+      String newFileName = FSUtils.makeDataFileName(instantTime, writeToken, fileId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk0NzM1OA==", "bodyText": "yes, it will be more common use. HUDI will support more base format", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449947358", "createdAt": "2020-07-06T01:43:37Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieMergeHandle.java", "diffHunk": "@@ -113,8 +109,9 @@ private void init(String fileId, String partitionPath, HoodieBaseFile dataFileTo\n       partitionMetadata.trySave(getPartitionId());\n \n       oldFilePath = new Path(config.getBasePath() + \"/\" + partitionPath + \"/\" + latestValidFilePath);\n+      String newFileName = FSUtils.makeDataFileName(instantTime, writeToken, fileId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTc4NjgyMw=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMzgyMDAxOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieWriteHandle.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNFQxNjozODoxMFrOGs805g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwNjoxODoxN1rOGtwg0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTc4NzExMA==", "bodyText": "nit: we can just name this create()", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449787110", "createdAt": "2020-07-04T16:38:10Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieWriteHandle.java", "diffHunk": "@@ -97,28 +98,9 @@ public Path makeNewPath(String partitionPath) {\n    *\n    * @param partitionPath Partition path\n    */\n-  protected void createMarkerFile(String partitionPath) {\n-    Path markerPath = makeNewMarkerPath(partitionPath);\n-    try {\n-      LOG.info(\"Creating Marker Path=\" + markerPath);\n-      fs.create(markerPath, false).close();\n-    } catch (IOException e) {\n-      throw new HoodieException(\"Failed to create marker file \" + markerPath, e);\n-    }\n-  }\n-\n-  /**\n-   * THe marker path will be <base-path>/.hoodie/.temp/<instant_ts>/2019/04/25/filename.\n-   */\n-  private Path makeNewMarkerPath(String partitionPath) {\n-    Path markerRootPath = new Path(hoodieTable.getMetaClient().getMarkerFolderPath(instantTime));\n-    Path path = FSUtils.getPartitionPath(markerRootPath, partitionPath);\n-    try {\n-      fs.mkdirs(path); // create a new partition as needed.\n-    } catch (IOException e) {\n-      throw new HoodieIOException(\"Failed to make dir \" + path, e);\n-    }\n-    return new Path(path.toString(), FSUtils.makeMarkerFile(instantTime, writeToken, fileId));\n+  protected void createMarkerFile(String partitionPath, String dataFileName) {\n+    MarkerFiles markerFiles = new MarkerFiles(hoodieTable, instantTime);\n+    markerFiles.createMarkerFile(partitionPath, dataFileName, getIOType());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDYzMzkzNg==", "bodyText": "nit: we can just name this create()\n\nyes ,i will be better", "url": "https://github.com/apache/hudi/pull/1756#discussion_r450633936", "createdAt": "2020-07-07T06:18:17Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieWriteHandle.java", "diffHunk": "@@ -97,28 +98,9 @@ public Path makeNewPath(String partitionPath) {\n    *\n    * @param partitionPath Partition path\n    */\n-  protected void createMarkerFile(String partitionPath) {\n-    Path markerPath = makeNewMarkerPath(partitionPath);\n-    try {\n-      LOG.info(\"Creating Marker Path=\" + markerPath);\n-      fs.create(markerPath, false).close();\n-    } catch (IOException e) {\n-      throw new HoodieException(\"Failed to create marker file \" + markerPath, e);\n-    }\n-  }\n-\n-  /**\n-   * THe marker path will be <base-path>/.hoodie/.temp/<instant_ts>/2019/04/25/filename.\n-   */\n-  private Path makeNewMarkerPath(String partitionPath) {\n-    Path markerRootPath = new Path(hoodieTable.getMetaClient().getMarkerFolderPath(instantTime));\n-    Path path = FSUtils.getPartitionPath(markerRootPath, partitionPath);\n-    try {\n-      fs.mkdirs(path); // create a new partition as needed.\n-    } catch (IOException e) {\n-      throw new HoodieIOException(\"Failed to make dir \" + path, e);\n-    }\n-    return new Path(path.toString(), FSUtils.makeMarkerFile(instantTime, writeToken, fileId));\n+  protected void createMarkerFile(String partitionPath, String dataFileName) {\n+    MarkerFiles markerFiles = new MarkerFiles(hoodieTable, instantTime);\n+    markerFiles.createMarkerFile(partitionPath, dataFileName, getIOType());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTc4NzExMA=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTAzNTU2OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/ListingBasedRollbackHelper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMDozMDozNVrOGtF-Pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMTo0NjozNlrOGtGpEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzNjk1OA==", "bodyText": "these could be replaced with base format from the table object?", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449936958", "createdAt": "2020-07-06T00:30:35Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/ListingBasedRollbackHelper.java", "diffHunk": "@@ -54,29 +53,28 @@\n /**\n  * Performs Rollback of Hoodie Tables.\n  */\n-public class RollbackHelper implements Serializable {\n+public class ListingBasedRollbackHelper implements Serializable {\n \n-  private static final Logger LOG = LogManager.getLogger(RollbackHelper.class);\n+  private static final Logger LOG = LogManager.getLogger(ListingBasedRollbackHelper.class);\n \n   private final HoodieTableMetaClient metaClient;\n   private final HoodieWriteConfig config;\n \n-  public RollbackHelper(HoodieTableMetaClient metaClient, HoodieWriteConfig config) {\n+  public ListingBasedRollbackHelper(HoodieTableMetaClient metaClient, HoodieWriteConfig config) {\n     this.metaClient = metaClient;\n     this.config = config;\n   }\n \n   /**\n    * Performs all rollback actions that we have collected in parallel.\n    */\n-  public List<HoodieRollbackStat> performRollback(JavaSparkContext jsc, HoodieInstant instantToRollback, List<RollbackRequest> rollbackRequests) {\n+  public List<HoodieRollbackStat> performRollback(JavaSparkContext jsc, HoodieInstant instantToRollback, List<ListingBasedRollbackRequest> rollbackRequests) {\n \n-    String basefileExtension = metaClient.getTableConfig().getBaseFileFormat().getFileExtension();\n     SerializablePathFilter filter = (path) -> {\n-      if (path.toString().contains(basefileExtension)) {\n+      if (path.toString().endsWith(HoodieFileFormat.PARQUET.getFileExtension())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk0NzkyMg==", "bodyText": "to be format from the table object will better", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449947922", "createdAt": "2020-07-06T01:46:36Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/ListingBasedRollbackHelper.java", "diffHunk": "@@ -54,29 +53,28 @@\n /**\n  * Performs Rollback of Hoodie Tables.\n  */\n-public class RollbackHelper implements Serializable {\n+public class ListingBasedRollbackHelper implements Serializable {\n \n-  private static final Logger LOG = LogManager.getLogger(RollbackHelper.class);\n+  private static final Logger LOG = LogManager.getLogger(ListingBasedRollbackHelper.class);\n \n   private final HoodieTableMetaClient metaClient;\n   private final HoodieWriteConfig config;\n \n-  public RollbackHelper(HoodieTableMetaClient metaClient, HoodieWriteConfig config) {\n+  public ListingBasedRollbackHelper(HoodieTableMetaClient metaClient, HoodieWriteConfig config) {\n     this.metaClient = metaClient;\n     this.config = config;\n   }\n \n   /**\n    * Performs all rollback actions that we have collected in parallel.\n    */\n-  public List<HoodieRollbackStat> performRollback(JavaSparkContext jsc, HoodieInstant instantToRollback, List<RollbackRequest> rollbackRequests) {\n+  public List<HoodieRollbackStat> performRollback(JavaSparkContext jsc, HoodieInstant instantToRollback, List<ListingBasedRollbackRequest> rollbackRequests) {\n \n-    String basefileExtension = metaClient.getTableConfig().getBaseFileFormat().getFileExtension();\n     SerializablePathFilter filter = (path) -> {\n-      if (path.toString().contains(basefileExtension)) {\n+      if (path.toString().endsWith(HoodieFileFormat.PARQUET.getFileExtension())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzNjk1OA=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTAzNzU0OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/MarkerBasedRollbackStrategy.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMDozMjoyNVrOGtF_Og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMDozMjoyNVrOGtF_Og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzNzIxMA==", "bodyText": "nit:extra line", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449937210", "createdAt": "2020-07-06T00:32:25Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/MarkerBasedRollbackStrategy.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.rollback;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.HoodieRollbackStat;\n+import org.apache.hudi.common.fs.FSUtils;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.table.log.HoodieLogFormat;\n+import org.apache.hudi.common.table.log.block.HoodieCommandBlock;\n+import org.apache.hudi.common.table.log.block.HoodieLogBlock;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.exception.HoodieRollbackException;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.table.MarkerFiles;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import scala.Tuple2;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Performs rollback using marker files generated during the write..\n+ */\n+public class MarkerBasedRollbackStrategy implements BaseRollbackActionExecutor.RollbackStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(MarkerBasedRollbackStrategy.class);\n+\n+  private final HoodieTable<?> table;\n+\n+  private final transient JavaSparkContext jsc;\n+\n+  private final HoodieWriteConfig config;\n+\n+  private final String basePath;\n+\n+  private final String instantTime;\n+\n+  public MarkerBasedRollbackStrategy(HoodieTable<?> table, JavaSparkContext jsc, HoodieWriteConfig config, String instantTime) {\n+    this.table = table;\n+    this.jsc = jsc;\n+    this.basePath = table.getMetaClient().getBasePath();\n+    this.config = config;\n+    this.instantTime = instantTime;\n+  }\n+\n+  private HoodieRollbackStat undoMerge(String mergedBaseFilePath) throws IOException {\n+    LOG.info(\"Rolling back by deleting the merged base file:\" + mergedBaseFilePath);\n+    return deleteBaseFile(mergedBaseFilePath);\n+  }\n+\n+  private HoodieRollbackStat undoCreate(String createdBaseFilePath) throws IOException {\n+    LOG.info(\"Rolling back by deleting the created base file:\" + createdBaseFilePath);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTA0MTU1OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/test/java/org/apache/hudi/client/TestTableSchemaEvolution.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMDozNzowNlrOGtGBWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwNjoyNjowNlrOGtwr4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzNzc1Mw==", "bodyText": "these combinations added on Schema evolution test is a bit hard to understand. like why would be testing modes for rollbacks in a schema evolution test? any particular reason?", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449937753", "createdAt": "2020-07-06T00:37:06Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/test/java/org/apache/hudi/client/TestTableSchemaEvolution.java", "diffHunk": "@@ -408,6 +416,16 @@ public void testCopyOnWriteTable() throws Exception {\n     checkReadRecords(\"000\", 2 * numRecords);\n   }\n \n+  @Test\n+  public void testCopyOnWriteTableUsingFileListRollBack() throws Exception {\n+    testCopyOnWriteTable(false);\n+  }\n+\n+  @Test\n+  public void testCopyOnWriteTableUsingMarkersRollBack() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDYzNjc2OA==", "bodyText": "yes ,i will remove it", "url": "https://github.com/apache/hudi/pull/1756#discussion_r450636768", "createdAt": "2020-07-07T06:26:06Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/test/java/org/apache/hudi/client/TestTableSchemaEvolution.java", "diffHunk": "@@ -408,6 +416,16 @@ public void testCopyOnWriteTable() throws Exception {\n     checkReadRecords(\"000\", 2 * numRecords);\n   }\n \n+  @Test\n+  public void testCopyOnWriteTableUsingFileListRollBack() throws Exception {\n+    testCopyOnWriteTable(false);\n+  }\n+\n+  @Test\n+  public void testCopyOnWriteTableUsingMarkersRollBack() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzNzc1Mw=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTA0MjU5OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/test/java/org/apache/hudi/index/TestHoodieIndex.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMDozODoyN1rOGtGB5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMTo0Njo0M1rOGtGpJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzNzg5NQ==", "bodyText": "Similar here.. this test probably does not need to test these two modes? for e.g: what additional testing are we getting over the test schema evolution test by doing this?", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449937895", "createdAt": "2020-07-06T00:38:27Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/test/java/org/apache/hudi/index/TestHoodieIndex.java", "diffHunk": "@@ -328,6 +330,18 @@ public void testSimpleTagLocationAndUpdateWithRollback(IndexType indexType) thro\n     assert (javaRDD.filter(record -> record.getCurrentLocation() != null).collect().size() == 0);\n   }\n \n+  @ParameterizedTest\n+  @EnumSource(value = IndexType.class, names = {\"BLOOM\", \"GLOBAL_BLOOM\", \"SIMPLE\", \"GLOBAL_SIMPLE\"})", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk0Nzk0MQ==", "bodyText": "ok", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449947941", "createdAt": "2020-07-06T01:46:43Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/test/java/org/apache/hudi/index/TestHoodieIndex.java", "diffHunk": "@@ -328,6 +330,18 @@ public void testSimpleTagLocationAndUpdateWithRollback(IndexType indexType) thro\n     assert (javaRDD.filter(record -> record.getCurrentLocation() != null).collect().size() == 0);\n   }\n \n+  @ParameterizedTest\n+  @EnumSource(value = IndexType.class, names = {\"BLOOM\", \"GLOBAL_BLOOM\", \"SIMPLE\", \"GLOBAL_SIMPLE\"})", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzNzg5NQ=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTA0Mjg1OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/test/java/org/apache/hudi/table/TestCleaner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMDozODo1OVrOGtGCEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMTo0Njo1MVrOGtGpRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzNzkzNw==", "bodyText": "same comment here..", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449937937", "createdAt": "2020-07-06T00:38:59Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/test/java/org/apache/hudi/table/TestCleaner.java", "diffHunk": "@@ -904,6 +901,19 @@ public void testCleanMarkerDataFilesOnRollback() throws IOException {\n     assertEquals(0, getTotalTempFiles(), \"All temp files are deleted.\");\n   }\n \n+  /**\n+   * Test Cleaning functionality of table.rollback() API.\n+   */\n+  @Test\n+  public void testCleanMarkerDataFilesOnRollbackUsingFileList() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk0Nzk3Mg==", "bodyText": "ok", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449947972", "createdAt": "2020-07-06T01:46:51Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/test/java/org/apache/hudi/table/TestCleaner.java", "diffHunk": "@@ -904,6 +901,19 @@ public void testCleanMarkerDataFilesOnRollback() throws IOException {\n     assertEquals(0, getTotalTempFiles(), \"All temp files are deleted.\");\n   }\n \n+  /**\n+   * Test Cleaning functionality of table.rollback() API.\n+   */\n+  @Test\n+  public void testCleanMarkerDataFilesOnRollbackUsingFileList() throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzNzkzNw=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTA0MzQ5OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/test/java/org/apache/hudi/table/TestHoodieMergeOnReadTable.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMDozOTozNVrOGtGCYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMTo0NzozMlrOGtGpsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzODAxNg==", "bodyText": "these may be worth adding in both modes..", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449938016", "createdAt": "2020-07-06T00:39:35Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/test/java/org/apache/hudi/table/TestHoodieMergeOnReadTable.java", "diffHunk": "@@ -445,10 +442,20 @@ public void testCOWToMORConvertedTableRollback(HoodieFileFormat baseFileFormat)\n \n   @ParameterizedTest\n   @MethodSource(\"argumentsProvider\")\n-  public void testRollbackWithDeltaAndCompactionCommit(HoodieFileFormat baseFileFormat) throws Exception {\n+  public void testCOWToMORConvertedTableRollbackUsingFileList(HoodieFileFormat baseFileFormat) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk0ODA4Mg==", "bodyText": "ok", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449948082", "createdAt": "2020-07-06T01:47:32Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/test/java/org/apache/hudi/table/TestHoodieMergeOnReadTable.java", "diffHunk": "@@ -445,10 +442,20 @@ public void testCOWToMORConvertedTableRollback(HoodieFileFormat baseFileFormat)\n \n   @ParameterizedTest\n   @MethodSource(\"argumentsProvider\")\n-  public void testRollbackWithDeltaAndCompactionCommit(HoodieFileFormat baseFileFormat) throws Exception {\n+  public void testCOWToMORConvertedTableRollbackUsingFileList(HoodieFileFormat baseFileFormat) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzODAxNg=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTA0NTE5OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/test/java/org/apache/hudi/table/action/rollback/TestCopyOnWriteRollbackActionExecutor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMDo0MToxMVrOGtGDLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMTo1MDoyOVrOGtGrjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzODIyMg==", "bodyText": "typo:two", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449938222", "createdAt": "2020-07-06T00:41:11Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/test/java/org/apache/hudi/table/action/rollback/TestCopyOnWriteRollbackActionExecutor.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.rollback;\n+\n+import org.apache.hudi.common.model.FileSlice;\n+import org.apache.hudi.common.model.HoodieFileGroup;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.client.HoodieWriteClient;\n+import org.apache.hudi.client.WriteStatus;\n+import org.apache.hudi.common.HoodieRollbackStat;\n+import org.apache.hudi.common.testutils.HoodieTestUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieIndexConfig;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.index.HoodieIndex;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.testutils.HoodieClientTestBase;\n+import org.apache.hudi.testutils.HoodieTestDataGenerator;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_SECOND_PARTITION_PATH;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+public class TestCopyOnWriteRollbackActionExecutor extends HoodieClientTestBase {\n+  @BeforeEach\n+  public void setUp() throws Exception {\n+    initPath();\n+    initSparkContexts();\n+    //just generate tow partitions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk0ODU1Nw==", "bodyText": "ok", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449948557", "createdAt": "2020-07-06T01:50:29Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/test/java/org/apache/hudi/table/action/rollback/TestCopyOnWriteRollbackActionExecutor.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.rollback;\n+\n+import org.apache.hudi.common.model.FileSlice;\n+import org.apache.hudi.common.model.HoodieFileGroup;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.client.HoodieWriteClient;\n+import org.apache.hudi.client.WriteStatus;\n+import org.apache.hudi.common.HoodieRollbackStat;\n+import org.apache.hudi.common.testutils.HoodieTestUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieIndexConfig;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.index.HoodieIndex;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.testutils.HoodieClientTestBase;\n+import org.apache.hudi.testutils.HoodieTestDataGenerator;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_SECOND_PARTITION_PATH;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+public class TestCopyOnWriteRollbackActionExecutor extends HoodieClientTestBase {\n+  @BeforeEach\n+  public void setUp() throws Exception {\n+    initPath();\n+    initSparkContexts();\n+    //just generate tow partitions", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzODIyMg=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTA0NzMzOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/test/java/org/apache/hudi/table/action/rollback/TestMergeOnReadRollbackActionExecutor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMDo0Mzo0MlrOGtGEUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMTo0ODo1OVrOGtGqjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzODUxMw==", "bodyText": "anyway to share code with the COW test?", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449938513", "createdAt": "2020-07-06T00:43:42Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/test/java/org/apache/hudi/table/action/rollback/TestMergeOnReadRollbackActionExecutor.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.rollback;\n+\n+import org.apache.hudi.client.HoodieWriteClient;\n+import org.apache.hudi.client.WriteStatus;\n+import org.apache.hudi.common.HoodieRollbackStat;\n+\n+import org.apache.hudi.common.model.FileSlice;\n+import org.apache.hudi.common.model.HoodieFileGroup;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.model.HoodieTableType;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.testutils.HoodieClientTestBase;\n+import org.apache.hudi.testutils.HoodieTestDataGenerator;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_SECOND_PARTITION_PATH;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+public class TestMergeOnReadRollbackActionExecutor extends HoodieClientTestBase {\n+  @Override\n+  protected HoodieTableType getTableType() {\n+    return HoodieTableType.MERGE_ON_READ;\n+  }\n+\n+  @BeforeEach\n+  public void setUp() throws Exception {\n+    initPath();\n+    initSparkContexts();\n+    //just generate tow partitions\n+    dataGen = new HoodieTestDataGenerator(new String[]{DEFAULT_FIRST_PARTITION_PATH, DEFAULT_SECOND_PARTITION_PATH});\n+    initFileSystem();\n+    initMetaClient();\n+  }\n+\n+  @AfterEach\n+  public void tearDown() throws Exception {\n+    cleanupResources();\n+  }\n+\n+  private void twoUpsertCommitDataRollBack(boolean isUsingMarkers) throws IOException, InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk0ODMwMg==", "bodyText": "yes  make sense", "url": "https://github.com/apache/hudi/pull/1756#discussion_r449948302", "createdAt": "2020-07-06T01:48:59Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/test/java/org/apache/hudi/table/action/rollback/TestMergeOnReadRollbackActionExecutor.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.rollback;\n+\n+import org.apache.hudi.client.HoodieWriteClient;\n+import org.apache.hudi.client.WriteStatus;\n+import org.apache.hudi.common.HoodieRollbackStat;\n+\n+import org.apache.hudi.common.model.FileSlice;\n+import org.apache.hudi.common.model.HoodieFileGroup;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.model.HoodieTableType;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.testutils.HoodieClientTestBase;\n+import org.apache.hudi.testutils.HoodieTestDataGenerator;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+import static org.apache.hudi.testutils.HoodieTestDataGenerator.DEFAULT_SECOND_PARTITION_PATH;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+public class TestMergeOnReadRollbackActionExecutor extends HoodieClientTestBase {\n+  @Override\n+  protected HoodieTableType getTableType() {\n+    return HoodieTableType.MERGE_ON_READ;\n+  }\n+\n+  @BeforeEach\n+  public void setUp() throws Exception {\n+    initPath();\n+    initSparkContexts();\n+    //just generate tow partitions\n+    dataGen = new HoodieTestDataGenerator(new String[]{DEFAULT_FIRST_PARTITION_PATH, DEFAULT_SECOND_PARTITION_PATH});\n+    initFileSystem();\n+    initMetaClient();\n+  }\n+\n+  @AfterEach\n+  public void tearDown() throws Exception {\n+    cleanupResources();\n+  }\n+\n+  private void twoUpsertCommitDataRollBack(boolean isUsingMarkers) throws IOException, InterruptedException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTkzODUxMw=="}, "originalCommit": {"oid": "9f57d75d73b81a31d7ece46a9134fcf26886dc31"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzOTc2MDA3OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/ListingBasedRollbackHelper.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxOTowOTowMFrOGyMEXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwMjo0MToxM1rOGyYCIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI3OTcwOQ==", "bodyText": "@lw309637554 any reason for changing this to PARQUET? (or was that me?)", "url": "https://github.com/apache/hudi/pull/1756#discussion_r455279709", "createdAt": "2020-07-15T19:09:00Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/ListingBasedRollbackHelper.java", "diffHunk": "@@ -182,12 +162,12 @@ private HoodieRollbackStat mergeRollbackStat(HoodieRollbackStat stat1, HoodieRol\n    * Common method used for cleaning out parquet files under a partition path during rollback of a set of commits.\n    */\n   private Map<FileStatus, Boolean> deleteCleanedFiles(HoodieTableMetaClient metaClient, HoodieWriteConfig config,\n-      Map<FileStatus, Boolean> results, String commit, String partitionPath) throws IOException {\n+                                                      String commit, String partitionPath) throws IOException {\n+    final Map<FileStatus, Boolean> results = new HashMap<>();\n     LOG.info(\"Cleaning path \" + partitionPath);\n     FileSystem fs = metaClient.getFs();\n-    String basefileExtension = metaClient.getTableConfig().getBaseFileFormat().getFileExtension();\n     PathFilter filter = (path) -> {\n-      if (path.toString().contains(basefileExtension)) {\n+      if (path.toString().contains(HoodieFileFormat.PARQUET.getFileExtension())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ3NDQyMQ==", "bodyText": "Get it. it is because master merge  do not handle well. Let me fix it", "url": "https://github.com/apache/hudi/pull/1756#discussion_r455474421", "createdAt": "2020-07-16T02:35:59Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/ListingBasedRollbackHelper.java", "diffHunk": "@@ -182,12 +162,12 @@ private HoodieRollbackStat mergeRollbackStat(HoodieRollbackStat stat1, HoodieRol\n    * Common method used for cleaning out parquet files under a partition path during rollback of a set of commits.\n    */\n   private Map<FileStatus, Boolean> deleteCleanedFiles(HoodieTableMetaClient metaClient, HoodieWriteConfig config,\n-      Map<FileStatus, Boolean> results, String commit, String partitionPath) throws IOException {\n+                                                      String commit, String partitionPath) throws IOException {\n+    final Map<FileStatus, Boolean> results = new HashMap<>();\n     LOG.info(\"Cleaning path \" + partitionPath);\n     FileSystem fs = metaClient.getFs();\n-    String basefileExtension = metaClient.getTableConfig().getBaseFileFormat().getFileExtension();\n     PathFilter filter = (path) -> {\n-      if (path.toString().contains(basefileExtension)) {\n+      if (path.toString().contains(HoodieFileFormat.PARQUET.getFileExtension())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI3OTcwOQ=="}, "originalCommit": null, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ3NTc0NQ==", "bodyText": "done", "url": "https://github.com/apache/hudi/pull/1756#discussion_r455475745", "createdAt": "2020-07-16T02:41:13Z", "author": {"login": "lw309637554"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/ListingBasedRollbackHelper.java", "diffHunk": "@@ -182,12 +162,12 @@ private HoodieRollbackStat mergeRollbackStat(HoodieRollbackStat stat1, HoodieRol\n    * Common method used for cleaning out parquet files under a partition path during rollback of a set of commits.\n    */\n   private Map<FileStatus, Boolean> deleteCleanedFiles(HoodieTableMetaClient metaClient, HoodieWriteConfig config,\n-      Map<FileStatus, Boolean> results, String commit, String partitionPath) throws IOException {\n+                                                      String commit, String partitionPath) throws IOException {\n+    final Map<FileStatus, Boolean> results = new HashMap<>();\n     LOG.info(\"Cleaning path \" + partitionPath);\n     FileSystem fs = metaClient.getFs();\n-    String basefileExtension = metaClient.getTableConfig().getBaseFileFormat().getFileExtension();\n     PathFilter filter = (path) -> {\n-      if (path.toString().contains(basefileExtension)) {\n+      if (path.toString().contains(HoodieFileFormat.PARQUET.getFileExtension())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI3OTcwOQ=="}, "originalCommit": null, "originalPosition": 160}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTA2MzkyOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/client/HoodieWriteClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMjo1NDozMVrOGzy-TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwMzowMjozN1rOGz1Wpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NTcwOQ==", "bodyText": "this PR will change behavior for marker dir deletion, with or without marker based rollback turned on.", "url": "https://github.com/apache/hudi/pull/1756#discussion_r456965709", "createdAt": "2020-07-19T22:54:31Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/client/HoodieWriteClient.java", "diffHunk": "@@ -332,9 +333,12 @@ public static SparkConf registerClasses(SparkConf conf) {\n   }\n \n   @Override\n-  protected void postCommit(HoodieCommitMetadata metadata, String instantTime,\n-      Option<Map<String, String>> extraMetadata) {\n+  protected void postCommit(HoodieTable<?> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n+\n+      // Delete the marker directory for the instant.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzAwNDcxMQ==", "bodyText": "Ack.", "url": "https://github.com/apache/hudi/pull/1756#discussion_r457004711", "createdAt": "2020-07-20T03:02:37Z", "author": {"login": "bvaradar"}, "path": "hudi-client/src/main/java/org/apache/hudi/client/HoodieWriteClient.java", "diffHunk": "@@ -332,9 +333,12 @@ public static SparkConf registerClasses(SparkConf conf) {\n   }\n \n   @Override\n-  protected void postCommit(HoodieCommitMetadata metadata, String instantTime,\n-      Option<Map<String, String>> extraMetadata) {\n+  protected void postCommit(HoodieTable<?> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n+\n+      // Delete the marker directory for the instant.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NTcwOQ=="}, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTA2NDg4OnYy", "diffSide": "LEFT", "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieWriteHandle.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMjo1NTozMVrOGzy-xA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMjo1NTozMVrOGzy-xA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NTgyOA==", "bodyText": "all of this stuff is now encapsulatd into a  MarkerFiles class", "url": "https://github.com/apache/hudi/pull/1756#discussion_r456965828", "createdAt": "2020-07-19T22:55:31Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieWriteHandle.java", "diffHunk": "@@ -97,28 +98,9 @@ public Path makeNewPath(String partitionPath) {\n    *\n    * @param partitionPath Partition path\n    */\n-  protected void createMarkerFile(String partitionPath) {\n-    Path markerPath = makeNewMarkerPath(partitionPath);\n-    try {\n-      LOG.info(\"Creating Marker Path=\" + markerPath);\n-      fs.create(markerPath, false).close();\n-    } catch (IOException e) {\n-      throw new HoodieException(\"Failed to create marker file \" + markerPath, e);\n-    }\n-  }\n-\n-  /**\n-   * THe marker path will be <base-path>/.hoodie/.temp/<instant_ts>/2019/04/25/filename.\n-   */\n-  private Path makeNewMarkerPath(String partitionPath) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTA2NTgzOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/HoodieTable.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMjo1Njo0M1rOGzy_Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwMzozMzoxOFrOGz2DPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NTkzOQ==", "bodyText": "quick skim of changes here would be nice.", "url": "https://github.com/apache/hudi/pull/1756#discussion_r456965939", "createdAt": "2020-07-19T22:56:43Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/HoodieTable.java", "diffHunk": "@@ -410,72 +412,54 @@ public void deleteMarkerDir(String instantTs) {\n    * @param consistencyCheckEnabled Consistency Check Enabled\n    * @throws HoodieIOException\n    */\n-  protected void cleanFailedWrites(JavaSparkContext jsc, String instantTs, List<HoodieWriteStat> stats,\n-      boolean consistencyCheckEnabled) throws HoodieIOException {\n+  protected void reconcileAgainstMarkers(JavaSparkContext jsc,\n+                                         String instantTs,\n+                                         List<HoodieWriteStat> stats,\n+                                         boolean consistencyCheckEnabled) throws HoodieIOException {\n     try {\n       // Reconcile marker and data files with WriteStats so that partially written data-files due to failed\n       // (but succeeded on retry) tasks are removed.\n       String basePath = getMetaClient().getBasePath();\n-      FileSystem fs = getMetaClient().getFs();\n-      Path markerDir = new Path(metaClient.getMarkerFolderPath(instantTs));\n+      MarkerFiles markers = new MarkerFiles(this, instantTs);\n \n-      if (!fs.exists(markerDir)) {\n-        // Happens when all writes are appends\n+      if (!markers.doesMarkerDirExist()) {\n+        // can happen if it was an empty write say.\n         return;\n       }\n \n-      final String baseFileExtension = getBaseFileFormat().getFileExtension();\n-      List<String> invalidDataPaths = FSUtils.getAllDataFilesForMarkers(fs, basePath, instantTs, markerDir.toString(),\n-          baseFileExtension);\n-      List<String> validDataPaths = stats.stream().map(w -> String.format(\"%s/%s\", basePath, w.getPath()))\n-          .filter(p -> p.endsWith(baseFileExtension)).collect(Collectors.toList());\n+      // we are not including log appends here, since they are already fail-safe.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzAxNjEyNA==", "bodyText": "This looks good to me.", "url": "https://github.com/apache/hudi/pull/1756#discussion_r457016124", "createdAt": "2020-07-20T03:33:18Z", "author": {"login": "bvaradar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/HoodieTable.java", "diffHunk": "@@ -410,72 +412,54 @@ public void deleteMarkerDir(String instantTs) {\n    * @param consistencyCheckEnabled Consistency Check Enabled\n    * @throws HoodieIOException\n    */\n-  protected void cleanFailedWrites(JavaSparkContext jsc, String instantTs, List<HoodieWriteStat> stats,\n-      boolean consistencyCheckEnabled) throws HoodieIOException {\n+  protected void reconcileAgainstMarkers(JavaSparkContext jsc,\n+                                         String instantTs,\n+                                         List<HoodieWriteStat> stats,\n+                                         boolean consistencyCheckEnabled) throws HoodieIOException {\n     try {\n       // Reconcile marker and data files with WriteStats so that partially written data-files due to failed\n       // (but succeeded on retry) tasks are removed.\n       String basePath = getMetaClient().getBasePath();\n-      FileSystem fs = getMetaClient().getFs();\n-      Path markerDir = new Path(metaClient.getMarkerFolderPath(instantTs));\n+      MarkerFiles markers = new MarkerFiles(this, instantTs);\n \n-      if (!fs.exists(markerDir)) {\n-        // Happens when all writes are appends\n+      if (!markers.doesMarkerDirExist()) {\n+        // can happen if it was an empty write say.\n         return;\n       }\n \n-      final String baseFileExtension = getBaseFileFormat().getFileExtension();\n-      List<String> invalidDataPaths = FSUtils.getAllDataFilesForMarkers(fs, basePath, instantTs, markerDir.toString(),\n-          baseFileExtension);\n-      List<String> validDataPaths = stats.stream().map(w -> String.format(\"%s/%s\", basePath, w.getPath()))\n-          .filter(p -> p.endsWith(baseFileExtension)).collect(Collectors.toList());\n+      // we are not including log appends here, since they are already fail-safe.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NTkzOQ=="}, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTA2NjcxOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/HoodieTimelineArchiveLog.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMjo1Nzo0N1rOGzy_ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwMzozNToxN1rOGz2GCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NjA0Ng==", "bodyText": "during archival. either the commit instant or the corresponding rollback.. any left over marker dir will be deleted. or the archival will fail. there is a test added for this.", "url": "https://github.com/apache/hudi/pull/1756#discussion_r456966046", "createdAt": "2020-07-19T22:57:47Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/HoodieTimelineArchiveLog.java", "diffHunk": "@@ -264,6 +275,7 @@ public void archive(List<HoodieInstant> instants) throws HoodieCommitException {\n       List<IndexedRecord> records = new ArrayList<>();\n       for (HoodieInstant hoodieInstant : instants) {\n         try {\n+          deleteAnyLeftOverMarkerFiles(hoodieInstant);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzAxNjg0Mg==", "bodyText": "Ack", "url": "https://github.com/apache/hudi/pull/1756#discussion_r457016842", "createdAt": "2020-07-20T03:35:17Z", "author": {"login": "bvaradar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/HoodieTimelineArchiveLog.java", "diffHunk": "@@ -264,6 +275,7 @@ public void archive(List<HoodieInstant> instants) throws HoodieCommitException {\n       List<IndexedRecord> records = new ArrayList<>();\n       for (HoodieInstant hoodieInstant : instants) {\n         try {\n+          deleteAnyLeftOverMarkerFiles(hoodieInstant);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NjA0Ng=="}, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 158}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTA2NzEyOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/MarkerFiles.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMjo1ODozMFrOGzy_2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMjo1ODozMFrOGzy_2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NjEwNA==", "bodyText": "@umehrot2 we can now add the parallelization changes here. for deletion of marker files.", "url": "https://github.com/apache/hudi/pull/1756#discussion_r456966104", "createdAt": "2020-07-19T22:58:30Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/MarkerFiles.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.fs.FSUtils;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.io.IOType;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Operates on marker files for a given write action (commit, delta commit, compaction).\n+ */\n+public class MarkerFiles {\n+\n+  private static final Logger LOG = LogManager.getLogger(MarkerFiles.class);\n+\n+  public static String stripMarkerSuffix(String path) {\n+    return path.substring(0, path.indexOf(HoodieTableMetaClient.MARKER_EXTN));\n+  }\n+\n+  private final String instantTime;\n+  private final FileSystem fs;\n+  private final Path markerDirPath;\n+  private final String basePath;\n+\n+  public MarkerFiles(FileSystem fs, String basePath, String markerFolderPath, String instantTime) {\n+    this.instantTime = instantTime;\n+    this.fs = fs;\n+    this.markerDirPath = new Path(markerFolderPath);\n+    this.basePath = basePath;\n+  }\n+\n+  public MarkerFiles(HoodieTable<?> table, String instantTime) {\n+    this(table.getMetaClient().getFs(),\n+        table.getMetaClient().getBasePath(),\n+        table.getMetaClient().getMarkerFolderPath(instantTime),\n+        instantTime);\n+  }\n+\n+  public void quietDeleteMarkerDir() {\n+    try {\n+      deleteMarkerDir();\n+    } catch (HoodieIOException ioe) {\n+      LOG.warn(\"Error deleting marker directory for instant \" + instantTime, ioe);\n+    }\n+  }\n+\n+  /**\n+   * Delete Marker directory corresponding to an instant.\n+   */\n+  public boolean deleteMarkerDir() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTA2ODQ3OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/MarkerBasedRollbackStrategy.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMzowMDoxMFrOGzzAgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMzowMDoxMFrOGzzAgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NjI3NQ==", "bodyText": "this is resilient already to attempting to delete an non-existent file.. marker file may not imply the data file is thre.", "url": "https://github.com/apache/hudi/pull/1756#discussion_r456966275", "createdAt": "2020-07-19T23:00:10Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/MarkerBasedRollbackStrategy.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.rollback;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.HoodieRollbackStat;\n+import org.apache.hudi.common.fs.FSUtils;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.table.log.HoodieLogFormat;\n+import org.apache.hudi.common.table.log.block.HoodieCommandBlock;\n+import org.apache.hudi.common.table.log.block.HoodieLogBlock;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.exception.HoodieRollbackException;\n+import org.apache.hudi.io.IOType;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.table.MarkerFiles;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import scala.Tuple2;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Performs rollback using marker files generated during the write..\n+ */\n+public class MarkerBasedRollbackStrategy implements BaseRollbackActionExecutor.RollbackStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(MarkerBasedRollbackStrategy.class);\n+\n+  private final HoodieTable<?> table;\n+\n+  private final transient JavaSparkContext jsc;\n+\n+  private final HoodieWriteConfig config;\n+\n+  private final String basePath;\n+\n+  private final String instantTime;\n+\n+  public MarkerBasedRollbackStrategy(HoodieTable<?> table, JavaSparkContext jsc, HoodieWriteConfig config, String instantTime) {\n+    this.table = table;\n+    this.jsc = jsc;\n+    this.basePath = table.getMetaClient().getBasePath();\n+    this.config = config;\n+    this.instantTime = instantTime;\n+  }\n+\n+  private HoodieRollbackStat undoMerge(String mergedBaseFilePath) throws IOException {\n+    LOG.info(\"Rolling back by deleting the merged base file:\" + mergedBaseFilePath);\n+    return deleteBaseFile(mergedBaseFilePath);\n+  }\n+\n+  private HoodieRollbackStat undoCreate(String createdBaseFilePath) throws IOException {\n+    LOG.info(\"Rolling back by deleting the created base file:\" + createdBaseFilePath);\n+    return deleteBaseFile(createdBaseFilePath);\n+  }\n+\n+  private HoodieRollbackStat deleteBaseFile(String baseFilePath) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTA2ODk2OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/MarkerBasedRollbackStrategy.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMzowMDo0NlrOGzzAvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOVQyMzowMDo0NlrOGzzAvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk2NjMzMg==", "bodyText": "checked that the log scanner can deal with spurious rollback blocks.. i.e rollbacks logged without any data blocks for that instant", "url": "https://github.com/apache/hudi/pull/1756#discussion_r456966332", "createdAt": "2020-07-19T23:00:46Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/rollback/MarkerBasedRollbackStrategy.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.rollback;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.HoodieRollbackStat;\n+import org.apache.hudi.common.fs.FSUtils;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.table.log.HoodieLogFormat;\n+import org.apache.hudi.common.table.log.block.HoodieCommandBlock;\n+import org.apache.hudi.common.table.log.block.HoodieLogBlock;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.exception.HoodieRollbackException;\n+import org.apache.hudi.io.IOType;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.table.MarkerFiles;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import scala.Tuple2;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Performs rollback using marker files generated during the write..\n+ */\n+public class MarkerBasedRollbackStrategy implements BaseRollbackActionExecutor.RollbackStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(MarkerBasedRollbackStrategy.class);\n+\n+  private final HoodieTable<?> table;\n+\n+  private final transient JavaSparkContext jsc;\n+\n+  private final HoodieWriteConfig config;\n+\n+  private final String basePath;\n+\n+  private final String instantTime;\n+\n+  public MarkerBasedRollbackStrategy(HoodieTable<?> table, JavaSparkContext jsc, HoodieWriteConfig config, String instantTime) {\n+    this.table = table;\n+    this.jsc = jsc;\n+    this.basePath = table.getMetaClient().getBasePath();\n+    this.config = config;\n+    this.instantTime = instantTime;\n+  }\n+\n+  private HoodieRollbackStat undoMerge(String mergedBaseFilePath) throws IOException {\n+    LOG.info(\"Rolling back by deleting the merged base file:\" + mergedBaseFilePath);\n+    return deleteBaseFile(mergedBaseFilePath);\n+  }\n+\n+  private HoodieRollbackStat undoCreate(String createdBaseFilePath) throws IOException {\n+    LOG.info(\"Rolling back by deleting the created base file:\" + createdBaseFilePath);\n+    return deleteBaseFile(createdBaseFilePath);\n+  }\n+\n+  private HoodieRollbackStat deleteBaseFile(String baseFilePath) throws IOException {\n+    Path fullDeletePath = new Path(basePath, baseFilePath);\n+    String partitionPath = FSUtils.getRelativePartitionPath(new Path(basePath), fullDeletePath.getParent());\n+    boolean isDeleted = table.getMetaClient().getFs().delete(fullDeletePath);\n+    return HoodieRollbackStat.newBuilder()\n+        .withPartitionPath(partitionPath)\n+        .withDeletedFileResult(baseFilePath, isDeleted)\n+        .build();\n+  }\n+\n+  private HoodieRollbackStat undoAppend(String appendBaseFilePath, HoodieInstant instantToRollback) throws IOException, InterruptedException {\n+    Path baseFilePathForAppend = new Path(basePath, appendBaseFilePath);\n+    String fileId = FSUtils.getFileIdFromFilePath(baseFilePathForAppend);\n+    String baseCommitTime = FSUtils.getCommitTime(baseFilePathForAppend.getName());\n+    String partitionPath = FSUtils.getRelativePartitionPath(new Path(basePath), new Path(basePath, appendBaseFilePath).getParent());\n+\n+    HoodieLogFormat.Writer writer = null;\n+    try {\n+      Path partitionFullPath = FSUtils.getPartitionPath(basePath, partitionPath);\n+\n+      if (!table.getMetaClient().getFs().exists(partitionFullPath)) {\n+        return HoodieRollbackStat.newBuilder()\n+            .withPartitionPath(partitionPath)\n+            .build();\n+      }\n+      writer = HoodieLogFormat.newWriterBuilder()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c4de4af17603e879e4bfdfc05846bdabecc6fa"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTM2NjAwOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwMzowOTowNFrOGz1f2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwMzowOTowNFrOGz1f2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzAwNzA2NA==", "bodyText": "Is this needed since we already.have shouldRollbackUsingMarkers() ?", "url": "https://github.com/apache/hudi/pull/1756#discussion_r457007064", "createdAt": "2020-07-20T03:09:04Z", "author": {"login": "bvaradar"}, "path": "hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -632,6 +638,10 @@ public FileSystemViewStorageConfig getClientSpecifiedViewStorageConfig() {\n     return clientSpecifiedViewStorageConfig;\n   }\n \n+  public boolean getRollBackUsingMarkers() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37c1febc23c88d27fccb42f7afc3acc6a4ee3d21"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTQ2MTE5OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/MarkerFiles.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwMzo0MzowNlrOGz2Q8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxOTo0Nzo1MVrOG0c1zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzAxOTYzNQ==", "bodyText": "This is fine (backwards compatible) as we are not currently writing marker files for appends. right ?", "url": "https://github.com/apache/hudi/pull/1756#discussion_r457019635", "createdAt": "2020-07-20T03:43:06Z", "author": {"login": "bvaradar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/MarkerFiles.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.fs.FSUtils;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.io.IOType;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Operates on marker files for a given write action (commit, delta commit, compaction).\n+ */\n+public class MarkerFiles {\n+\n+  private static final Logger LOG = LogManager.getLogger(MarkerFiles.class);\n+\n+  public static String stripMarkerSuffix(String path) {\n+    return path.substring(0, path.indexOf(HoodieTableMetaClient.MARKER_EXTN));\n+  }\n+\n+  private final String instantTime;\n+  private final FileSystem fs;\n+  private final Path markerDirPath;\n+  private final String basePath;\n+\n+  public MarkerFiles(FileSystem fs, String basePath, String markerFolderPath, String instantTime) {\n+    this.instantTime = instantTime;\n+    this.fs = fs;\n+    this.markerDirPath = new Path(markerFolderPath);\n+    this.basePath = basePath;\n+  }\n+\n+  public MarkerFiles(HoodieTable<?> table, String instantTime) {\n+    this(table.getMetaClient().getFs(),\n+        table.getMetaClient().getBasePath(),\n+        table.getMetaClient().getMarkerFolderPath(instantTime),\n+        instantTime);\n+  }\n+\n+  public void quietDeleteMarkerDir() {\n+    try {\n+      deleteMarkerDir();\n+    } catch (HoodieIOException ioe) {\n+      LOG.warn(\"Error deleting marker directory for instant \" + instantTime, ioe);\n+    }\n+  }\n+\n+  /**\n+   * Delete Marker directory corresponding to an instant.\n+   */\n+  public boolean deleteMarkerDir() {\n+    try {\n+      boolean result = fs.delete(markerDirPath, true);\n+      if (result) {\n+        LOG.info(\"Removing marker directory at \" + markerDirPath);\n+      } else {\n+        LOG.info(\"No marker directory to delete at \" + markerDirPath);\n+      }\n+      return result;\n+    } catch (IOException ioe) {\n+      throw new HoodieIOException(ioe.getMessage(), ioe);\n+    }\n+  }\n+\n+  public boolean doesMarkerDirExist() throws IOException {\n+    return fs.exists(markerDirPath);\n+  }\n+\n+  public List<String> createdAndMergedDataPaths() throws IOException {\n+    List<String> dataFiles = new LinkedList<>();\n+    FSUtils.processFiles(fs, markerDirPath.toString(), (status) -> {\n+      String pathStr = status.getPath().toString();\n+      if (pathStr.contains(HoodieTableMetaClient.MARKER_EXTN) && !pathStr.endsWith(IOType.APPEND.name())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37c1febc23c88d27fccb42f7afc3acc6a4ee3d21"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1MTY2Mw==", "bodyText": "yes. we will be performing an upgrade anyway to 0.6.0., which will list the inflight instant at the time of upgrade and then subsequently, write compatible, corresponding marker files", "url": "https://github.com/apache/hudi/pull/1756#discussion_r457651663", "createdAt": "2020-07-20T19:47:51Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/MarkerFiles.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.fs.FSUtils;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.io.IOType;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Operates on marker files for a given write action (commit, delta commit, compaction).\n+ */\n+public class MarkerFiles {\n+\n+  private static final Logger LOG = LogManager.getLogger(MarkerFiles.class);\n+\n+  public static String stripMarkerSuffix(String path) {\n+    return path.substring(0, path.indexOf(HoodieTableMetaClient.MARKER_EXTN));\n+  }\n+\n+  private final String instantTime;\n+  private final FileSystem fs;\n+  private final Path markerDirPath;\n+  private final String basePath;\n+\n+  public MarkerFiles(FileSystem fs, String basePath, String markerFolderPath, String instantTime) {\n+    this.instantTime = instantTime;\n+    this.fs = fs;\n+    this.markerDirPath = new Path(markerFolderPath);\n+    this.basePath = basePath;\n+  }\n+\n+  public MarkerFiles(HoodieTable<?> table, String instantTime) {\n+    this(table.getMetaClient().getFs(),\n+        table.getMetaClient().getBasePath(),\n+        table.getMetaClient().getMarkerFolderPath(instantTime),\n+        instantTime);\n+  }\n+\n+  public void quietDeleteMarkerDir() {\n+    try {\n+      deleteMarkerDir();\n+    } catch (HoodieIOException ioe) {\n+      LOG.warn(\"Error deleting marker directory for instant \" + instantTime, ioe);\n+    }\n+  }\n+\n+  /**\n+   * Delete Marker directory corresponding to an instant.\n+   */\n+  public boolean deleteMarkerDir() {\n+    try {\n+      boolean result = fs.delete(markerDirPath, true);\n+      if (result) {\n+        LOG.info(\"Removing marker directory at \" + markerDirPath);\n+      } else {\n+        LOG.info(\"No marker directory to delete at \" + markerDirPath);\n+      }\n+      return result;\n+    } catch (IOException ioe) {\n+      throw new HoodieIOException(ioe.getMessage(), ioe);\n+    }\n+  }\n+\n+  public boolean doesMarkerDirExist() throws IOException {\n+    return fs.exists(markerDirPath);\n+  }\n+\n+  public List<String> createdAndMergedDataPaths() throws IOException {\n+    List<String> dataFiles = new LinkedList<>();\n+    FSUtils.processFiles(fs, markerDirPath.toString(), (status) -> {\n+      String pathStr = status.getPath().toString();\n+      if (pathStr.contains(HoodieTableMetaClient.MARKER_EXTN) && !pathStr.endsWith(IOType.APPEND.name())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzAxOTYzNQ=="}, "originalCommit": {"oid": "37c1febc23c88d27fccb42f7afc3acc6a4ee3d21"}, "originalPosition": 100}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4506, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}