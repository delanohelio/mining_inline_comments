{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA2ODgzNDM4", "number": 2190, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNVQwMDozOToxM1rOExm2fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNVQwMDozOToxM1rOExm2fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNDUyMjIzOnYy", "diffSide": "RIGHT", "path": "hudi-hadoop-mr/src/main/java/org/apache/hudi/hadoop/realtime/RealtimeCompactedRecordReader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNVQwMDozOToxM1rOHn1Ubw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNVQwMDozOToxM1rOHn1Ubw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTUzMDA5NQ==", "bodyText": "I think we can structure this as a if block without need for the else? since the if above anyway returns out.", "url": "https://github.com/apache/hudi/pull/2190#discussion_r511530095", "createdAt": "2020-10-25T00:39:13Z", "author": {"login": "vinothchandar"}, "path": "hudi-hadoop-mr/src/main/java/org/apache/hudi/hadoop/realtime/RealtimeCompactedRecordReader.java", "diffHunk": "@@ -85,53 +85,55 @@ public boolean next(NullWritable aVoid, ArrayWritable arrayWritable) throws IOEx\n       // if the result is false, then there are no more records\n       return false;\n     } else {\n-      // TODO(VC): Right now, we assume all records in log, have a matching base record. (which\n-      // would be true until we have a way to index logs too)\n-      // return from delta records map if we have some match.\n-      String key = arrayWritable.get()[HoodieInputFormatUtils.HOODIE_RECORD_KEY_COL_POS].toString();\n-      if (deltaRecordMap.containsKey(key)) {\n-        // TODO(NA): Invoke preCombine here by converting arrayWritable to Avro. This is required since the\n-        // deltaRecord may not be a full record and needs values of columns from the parquet\n-        Option<GenericRecord> rec;\n-        if (usesCustomPayload) {\n-          rec = deltaRecordMap.get(key).getData().getInsertValue(getWriterSchema());\n-        } else {\n-          rec = deltaRecordMap.get(key).getData().getInsertValue(getReaderSchema());\n-        }\n-        if (!rec.isPresent()) {\n-          // If the record is not present, this is a delete record using an empty payload so skip this base record\n-          // and move to the next record\n-          return next(aVoid, arrayWritable);\n-        }\n-        GenericRecord recordToReturn = rec.get();\n-        if (usesCustomPayload) {\n-          // If using a custom payload, return only the projection fields. The readerSchema is a schema derived from\n-          // the writerSchema with only the projection fields\n-          recordToReturn = HoodieAvroUtils.rewriteRecordWithOnlyNewSchemaFields(rec.get(), getReaderSchema());\n-        }\n-        // we assume, a later safe record in the log, is newer than what we have in the map &\n-        // replace it. Since we want to return an arrayWritable which is the same length as the elements in the latest\n-        // schema, we use writerSchema to create the arrayWritable from the latest generic record\n-        ArrayWritable aWritable = (ArrayWritable) HoodieRealtimeRecordReaderUtils.avroToArrayWritable(recordToReturn, getHiveSchema());\n-        Writable[] replaceValue = aWritable.get();\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(String.format(\"key %s, base values: %s, log values: %s\", key, HoodieRealtimeRecordReaderUtils.arrayWritableToString(arrayWritable),\n-              HoodieRealtimeRecordReaderUtils.arrayWritableToString(aWritable)));\n-        }\n-        Writable[] originalValue = arrayWritable.get();\n-        try {\n-          // Sometime originalValue.length > replaceValue.length.\n-          // This can happen when hive query is looking for pseudo parquet columns like BLOCK_OFFSET_INSIDE_FILE\n-          System.arraycopy(replaceValue, 0, originalValue, 0,\n-              Math.min(originalValue.length, replaceValue.length));\n-          arrayWritable.set(originalValue);\n-        } catch (RuntimeException re) {\n-          LOG.error(\"Got exception when doing array copy\", re);\n-          LOG.error(\"Base record :\" + HoodieRealtimeRecordReaderUtils.arrayWritableToString(arrayWritable));\n-          LOG.error(\"Log record :\" + HoodieRealtimeRecordReaderUtils.arrayWritableToString(aWritable));\n-          String errMsg = \"Base-record :\" + HoodieRealtimeRecordReaderUtils.arrayWritableToString(arrayWritable)\n-              + \" ,Log-record :\" + HoodieRealtimeRecordReaderUtils.arrayWritableToString(aWritable) + \" ,Error :\" + re.getMessage();\n-          throw new RuntimeException(errMsg, re);\n+      if (!deltaRecordMap.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5942ceea24442cc7964de848b2bdf74de18883f0"}, "originalPosition": 51}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4109, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}