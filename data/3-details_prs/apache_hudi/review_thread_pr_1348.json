{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc4NTQyOTk5", "number": 1348, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNTo0NjozOVrODiIB7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNTo1NDo0MVrODiIDKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MTA5NzQzOnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNTo0NjozOVrOFtObQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwMDozMzoyNlrOFtT3AQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NjU5NA==", "bodyText": "can we move the \"\" default to DataSourceOptions, to keep it consistent with how the other options are defined", "url": "https://github.com/apache/hudi/pull/1348#discussion_r382966594", "createdAt": "2020-02-23T05:46:39Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -84,7 +85,7 @@ class IncrementalRelation(val sqlContext: SQLContext,\n \n   val filters = {\n     if (optParams.contains(DataSourceReadOptions.PUSH_DOWN_INCR_FILTERS_OPT_KEY)) {\n-      val filterStr = optParams.get(DataSourceReadOptions.PUSH_DOWN_INCR_FILTERS_OPT_KEY).getOrElse(\"\")\n+      val filterStr = optParams.getOrElse(DataSourceReadOptions.PUSH_DOWN_INCR_FILTERS_OPT_KEY, \"\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA1NTYxNw==", "bodyText": "Good point, will do", "url": "https://github.com/apache/hudi/pull/1348#discussion_r383055617", "createdAt": "2020-02-24T00:33:26Z", "author": {"login": "garyli1019"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -84,7 +85,7 @@ class IncrementalRelation(val sqlContext: SQLContext,\n \n   val filters = {\n     if (optParams.contains(DataSourceReadOptions.PUSH_DOWN_INCR_FILTERS_OPT_KEY)) {\n-      val filterStr = optParams.get(DataSourceReadOptions.PUSH_DOWN_INCR_FILTERS_OPT_KEY).getOrElse(\"\")\n+      val filterStr = optParams.getOrElse(DataSourceReadOptions.PUSH_DOWN_INCR_FILTERS_OPT_KEY, \"\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NjU5NA=="}, "originalCommit": null, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MTA5ODAxOnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNTo0ODoyNlrOFtObiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNTo0ODoyNlrOFtObiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NjY2NA==", "bodyText": "here we will compare with the default variable constant.", "url": "https://github.com/apache/hudi/pull/1348#discussion_r382966664", "createdAt": "2020-02-23T05:48:26Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -100,17 +101,22 @@ class IncrementalRelation(val sqlContext: SQLContext,\n         .get, classOf[HoodieCommitMetadata])\n       fileIdToFullPath ++= metadata.getFileIdAndFullPaths(basePath).toMap\n     }\n+    val pathGlobPattern = optParams.getOrElse(DataSourceReadOptions.INCR_PATH_GLOB_OPT_KEY, \"\")\n+    val filteredFullPath = if(!pathGlobPattern.equals(\"\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MTA5ODM0OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNTo0OToyNFrOFtObsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNTo0OToyNFrOFtObsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NjcwNQ==", "bodyText": "please enclose within braces for readability.", "url": "https://github.com/apache/hudi/pull/1348#discussion_r382966705", "createdAt": "2020-02-23T05:49:24Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -100,17 +101,22 @@ class IncrementalRelation(val sqlContext: SQLContext,\n         .get, classOf[HoodieCommitMetadata])\n       fileIdToFullPath ++= metadata.getFileIdAndFullPaths(basePath).toMap\n     }\n+    val pathGlobPattern = optParams.getOrElse(DataSourceReadOptions.INCR_PATH_GLOB_OPT_KEY, \"\")\n+    val filteredFullPath = if(!pathGlobPattern.equals(\"\")) {\n+      val globMatcher = new GlobPattern(\"*\" + pathGlobPattern)\n+      fileIdToFullPath.filter(p => globMatcher.matches(p._2))\n+    } else fileIdToFullPath", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MTA5OTYwOnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNTo1MjozN1rOFtOcRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwMDozMjo1MVrOFtT2yA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2Njg1Mg==", "bodyText": "should we leave the * to the user? i.e let the user pass in * if needed? or is that needed for the matching...\nI am not familiar with this class per se..\nAlso http://hadoop.apache.org/docs/r2.8.0/api/allclasses-noframe.html does not seem to have GlobPattern is this class still around.. Was a bit confused by that..", "url": "https://github.com/apache/hudi/pull/1348#discussion_r382966852", "createdAt": "2020-02-23T05:52:37Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -100,17 +101,22 @@ class IncrementalRelation(val sqlContext: SQLContext,\n         .get, classOf[HoodieCommitMetadata])\n       fileIdToFullPath ++= metadata.getFileIdAndFullPaths(basePath).toMap\n     }\n+    val pathGlobPattern = optParams.getOrElse(DataSourceReadOptions.INCR_PATH_GLOB_OPT_KEY, \"\")\n+    val filteredFullPath = if(!pathGlobPattern.equals(\"\")) {\n+      val globMatcher = new GlobPattern(\"*\" + pathGlobPattern)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA1NTU2MA==", "bodyText": "the path here is a full HDFS path so we need * here to match with the prefix.  The benefit if we include * here is that the user will have a consistent interface. When loading the full table, they will do .load(basePath + \"/2016/*/*/*\") and in incremental pulling the String the user defined will be the same. If we leave the * to the user I think it might cause some confusion there and the users need to read this part of the code themselves to fully understand how things work here.\nYea I couldn't find any documents as well. The GlobFilter in the API list is using GlobPattern inside https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/GlobFilter.java#L67 and the class is still around https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/GlobPattern.java", "url": "https://github.com/apache/hudi/pull/1348#discussion_r383055560", "createdAt": "2020-02-24T00:32:51Z", "author": {"login": "garyli1019"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -100,17 +101,22 @@ class IncrementalRelation(val sqlContext: SQLContext,\n         .get, classOf[HoodieCommitMetadata])\n       fileIdToFullPath ++= metadata.getFileIdAndFullPaths(basePath).toMap\n     }\n+    val pathGlobPattern = optParams.getOrElse(DataSourceReadOptions.INCR_PATH_GLOB_OPT_KEY, \"\")\n+    val filteredFullPath = if(!pathGlobPattern.equals(\"\")) {\n+      val globMatcher = new GlobPattern(\"*\" + pathGlobPattern)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2Njg1Mg=="}, "originalCommit": null, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3MTEwMDU5OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/test/scala/TestDataSource.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yM1QwNTo1NDo0MVrOFtOctw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwMDozNzoxMVrOFtT4Vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2Njk2Nw==", "bodyText": "is the leading / necessary?  could we make it (if not already) such that the matchong works with or without it..", "url": "https://github.com/apache/hudi/pull/1348#discussion_r382966967", "createdAt": "2020-02-23T05:54:41Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/test/scala/TestDataSource.scala", "diffHunk": "@@ -135,6 +136,14 @@ class TestDataSource extends AssertionsForJUnit {\n     countsPerCommit = hoodieIncViewDF2.groupBy(\"_hoodie_commit_time\").count().collect();\n     assertEquals(1, countsPerCommit.length)\n     assertEquals(commitInstantTime2, countsPerCommit(0).get(0))\n+\n+    // pull the latest commit within certain partitions\n+    val hoodieIncViewDF3 = spark.read.format(\"org.apache.hudi\")\n+      .option(DataSourceReadOptions.QUERY_TYPE_OPT_KEY, DataSourceReadOptions.QUERY_TYPE_INCREMENTAL_OPT_VAL)\n+      .option(DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY, commitInstantTime1)\n+      .option(DataSourceReadOptions.INCR_PATH_GLOB_OPT_KEY, \"/2016/*/*/*\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA1NTk1OQ==", "bodyText": "Since we add * in front of it so it will still work without /. Here is just trying to be consistent with loading the full table.", "url": "https://github.com/apache/hudi/pull/1348#discussion_r383055959", "createdAt": "2020-02-24T00:37:11Z", "author": {"login": "garyli1019"}, "path": "hudi-spark/src/test/scala/TestDataSource.scala", "diffHunk": "@@ -135,6 +136,14 @@ class TestDataSource extends AssertionsForJUnit {\n     countsPerCommit = hoodieIncViewDF2.groupBy(\"_hoodie_commit_time\").count().collect();\n     assertEquals(1, countsPerCommit.length)\n     assertEquals(commitInstantTime2, countsPerCommit(0).get(0))\n+\n+    // pull the latest commit within certain partitions\n+    val hoodieIncViewDF3 = spark.read.format(\"org.apache.hudi\")\n+      .option(DataSourceReadOptions.QUERY_TYPE_OPT_KEY, DataSourceReadOptions.QUERY_TYPE_INCREMENTAL_OPT_VAL)\n+      .option(DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY, commitInstantTime1)\n+      .option(DataSourceReadOptions.INCR_PATH_GLOB_OPT_KEY, \"/2016/*/*/*\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2Njk2Nw=="}, "originalCommit": null, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4853, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}