{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDkyNDMwMDE0", "number": 2111, "title": "[HUDI-1234] Insert new records to data files without merging for \"Insert\" operation. ", "bodyText": "What is the purpose of the pull request\nWhen Insert operation is chosen, it could be no-op in trying to merge w/ existing data file. So, this patch introduces HoodieConcatHandle which will just append/concat new incoming data to existing data for a given data file w/o performing any merge(combineAndUpdate) as such. Its users responsibility to ensure there are no duplicate if the config is enabled with Insert operation.\nBrief change log\n\nAdded HoodieConcatHandle to concat/append incoming records to existing records for a given data file w/o performing any merge for Insert operation.\nAdded a new config hoodie.merge.allow.duplicate.inserts to guard this new behavior.\n\nVerify this pull request\n\nAdded tests to TestHoodieClientOnCopyOnWriteStorage(testInsertsWithHoodieConcatHandle and testInsertsPreppedWithHoodieConcatHandle) to verify new behavior\n\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-09-24T13:00:50Z", "url": "https://github.com/apache/hudi/pull/2111", "merged": true, "mergeCommit": {"oid": "2ee1c3fb0cb9740dc6d924f5e6e638aec19ed9b3"}, "closed": true, "closedAt": "2021-01-27T18:09:52Z", "author": {"login": "SteNicholas"}, "timelineItems": {"totalCount": 48, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdMURGFAFqTQ5NjM0MzY5MA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdyBjE6ABqjQyMjg0NzI3Mzg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MzQzNjkw", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-496343690", "createdAt": "2020-09-25T11:41:06Z", "commit": {"oid": "7313074623a295060fdba16d3b33f4701cce71b8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMTo0MTowNlrOHYAKZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMTo0MTowNlrOHYAKZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDkzMDUzMg==", "bodyText": "WriteOperationType should be Serializable?", "url": "https://github.com/apache/hudi/pull/2111#discussion_r494930532", "createdAt": "2020-09-25T11:41:06Z", "author": {"login": "leesf"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/WorkloadProfile.java", "diffHunk": "@@ -54,13 +55,23 @@\n    */\n   private final WorkloadStat globalStat;\n \n+  /**\n+   * Write operation type.\n+   */\n+  private WriteOperationType operationType;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7313074623a295060fdba16d3b33f4701cce71b8"}, "originalPosition": 15}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "42d9c3a2f1cce771ba7c77b74f70279a71a6e2df", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/42d9c3a2f1cce771ba7c77b74f70279a71a6e2df", "committedDate": "2020-10-01T05:14:40Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "0a9518660ebed9d38c5bba0cfbf8db38760974d4", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/0a9518660ebed9d38c5bba0cfbf8db38760974d4", "committedDate": "2020-10-02T05:28:01Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f1a73f5b8cf982c9876570946b695e958cf524b8", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/f1a73f5b8cf982c9876570946b695e958cf524b8", "committedDate": "2020-10-02T06:12:00Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "2703684438f9aeeeaf28c68d0241cc00b98339e6", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/2703684438f9aeeeaf28c68d0241cc00b98339e6", "committedDate": "2020-10-02T06:20:45Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2703684438f9aeeeaf28c68d0241cc00b98339e6", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/2703684438f9aeeeaf28c68d0241cc00b98339e6", "committedDate": "2020-10-02T06:20:45Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "ce8a23b2c7402158c3a35ec978465edaefa15cb6", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/ce8a23b2c7402158c3a35ec978465edaefa15cb6", "committedDate": "2020-10-02T10:42:32Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ce8a23b2c7402158c3a35ec978465edaefa15cb6", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/ce8a23b2c7402158c3a35ec978465edaefa15cb6", "committedDate": "2020-10-02T10:42:32Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "7c770ec23c11fccd7298a3e8c9e187297b74f749", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/7c770ec23c11fccd7298a3e8c9e187297b74f749", "committedDate": "2020-10-02T11:41:04Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7c770ec23c11fccd7298a3e8c9e187297b74f749", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/7c770ec23c11fccd7298a3e8c9e187297b74f749", "committedDate": "2020-10-02T11:41:04Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "b60451d881e17b64cd5a7db084377b79c4a47d84", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/b60451d881e17b64cd5a7db084377b79c4a47d84", "committedDate": "2020-10-02T12:44:11Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "90e6462fe571d86aef899cb326000f38b0f4bbf2", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/90e6462fe571d86aef899cb326000f38b0f4bbf2", "committedDate": "2020-10-02T13:27:45Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "3872213002b615be0cacaa2c6221b60e066f4934", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/3872213002b615be0cacaa2c6221b60e066f4934", "committedDate": "2020-10-02T14:08:17Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3872213002b615be0cacaa2c6221b60e066f4934", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/3872213002b615be0cacaa2c6221b60e066f4934", "committedDate": "2020-10-02T14:08:17Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/3ce6e021080921c9e01e819b577ab307e7cfee85", "committedDate": "2020-10-02T14:51:33Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzAxNDU1", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504701455", "createdAt": "2020-10-08T11:53:10Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMTo1MzoxMFrOHea4Zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMTo1MzoxMFrOHea4Zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY1OTc1MQ==", "bodyText": "The method called addUpdateBucket, but the BucketType would be INSERT, it is not very suitable, would we move the logic outside of the method?", "url": "https://github.com/apache/hudi/pull/2111#discussion_r501659751", "createdAt": "2020-10-08T11:53:10Z", "author": {"login": "leesf"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/commit/UpsertPartitioner.java", "diffHunk": "@@ -112,16 +115,17 @@ private void assignUpdates(WorkloadProfile profile) {\n     for (Map.Entry<String, WorkloadStat> partitionStat : partitionStatEntries) {\n       for (Map.Entry<String, Pair<String, Long>> updateLocEntry :\n           partitionStat.getValue().getUpdateLocationToCount().entrySet()) {\n-        addUpdateBucket(partitionStat.getKey(), updateLocEntry.getKey());\n+        addUpdateBucket(partitionStat.getKey(), updateLocEntry.getKey(), profile.getOperationType());\n       }\n     }\n   }\n \n-  private int addUpdateBucket(String partitionPath, String fileIdHint) {\n+  private int addUpdateBucket(String partitionPath, String fileIdHint, WriteOperationType operationType) {\n     int bucket = totalBuckets;\n     updateLocationToBucket.put(fileIdHint, bucket);\n     BucketInfo bucketInfo = new BucketInfo();\n-    bucketInfo.bucketType = BucketType.UPDATE;\n+    bucketInfo.bucketType = operationType == null || isChangingRecords(operationType)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzAzMzc3", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504703377", "createdAt": "2020-10-08T11:55:50Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMTo1NTo1MFrOHea-Ww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMTo1NTo1MFrOHea-Ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY2MTI3NQ==", "bodyText": "must remove these asserts?", "url": "https://github.com/apache/hudi/pull/2111#discussion_r501661275", "createdAt": "2020-10-08T11:55:50Z", "author": {"login": "leesf"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/client/TestHoodieClientOnCopyOnWriteStorage.java", "diffHunk": "@@ -743,47 +743,37 @@ public void testSmallInsertHandlingForUpserts() throws Exception {\n    */\n   @Test\n   public void testSmallInsertHandlingForInserts() throws Exception {\n-\n     final String testPartitionPath = \"2016/09/26\";\n     final int insertSplitLimit = 100;\n     // setup the small file handling params\n     HoodieWriteConfig config = getSmallInsertWriteConfig(insertSplitLimit); // hold upto 200 records max\n     dataGen = new HoodieTestDataGenerator(new String[] {testPartitionPath});\n     SparkRDDWriteClient client = getHoodieWriteClient(config, false);\n \n-    // Inserts => will write file1\n     String commitTime1 = \"001\";\n     client.startCommitWithTime(commitTime1);\n     List<HoodieRecord> inserts1 = dataGen.generateInserts(commitTime1, insertSplitLimit); // this writes ~500kb\n     Set<String> keys1 = recordsToRecordKeySet(inserts1);\n     JavaRDD<HoodieRecord> insertRecordsRDD1 = jsc.parallelize(inserts1, 1);\n     List<WriteStatus> statuses = client.insert(insertRecordsRDD1, commitTime1).collect();\n-\n     assertNoWriteErrors(statuses);\n-    assertPartitionMetadata(new String[] {testPartitionPath}, fs);\n-\n+    assertPartitionMetadata(new String[]{testPartitionPath}, fs);\n     assertEquals(1, statuses.size(), \"Just 1 file needs to be added.\");\n-    String file1 = statuses.get(0).getFileId();\n     assertEquals(100,\n         readRowKeysFromParquet(hadoopConf, new Path(basePath, statuses.get(0).getStat().getPath()))\n             .size(), \"file should contain 100 records\");\n \n-    // Second, set of Inserts should just expand file1\n     String commitTime2 = \"002\";\n     client.startCommitWithTime(commitTime2);\n     List<HoodieRecord> inserts2 = dataGen.generateInserts(commitTime2, 40);\n     Set<String> keys2 = recordsToRecordKeySet(inserts2);\n     JavaRDD<HoodieRecord> insertRecordsRDD2 = jsc.parallelize(inserts2, 1);\n     statuses = client.insert(insertRecordsRDD2, commitTime2).collect();\n     assertNoWriteErrors(statuses);\n-\n-    assertEquals(1, statuses.size(), \"Just 1 file needs to be updated.\");\n-    assertEquals(file1, statuses.get(0).getFileId(), \"Existing file should be expanded\");\n-    assertEquals(commitTime1, statuses.get(0).getStat().getPrevCommit(), \"Existing file should be expanded\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "originalPosition": 41}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzIwMzAx", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504720301", "createdAt": "2020-10-08T12:18:30Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoxODozMFrOHebyFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoxODozMFrOHebyFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY3NDUxNg==", "bodyText": "100 should be passed via method parameter.", "url": "https://github.com/apache/hudi/pull/2111#discussion_r501674516", "createdAt": "2020-10-08T12:18:30Z", "author": {"login": "leesf"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/action/commit/TestUpsertPartitioner.java", "diffHunk": "@@ -90,14 +88,33 @@ private UpsertPartitioner getUpsertPartitioner(int smallFileSize, int numInserts\n     List<HoodieRecord> records = new ArrayList<>();\n     records.addAll(insertRecords);\n     records.addAll(updateRecords);\n-    WorkloadProfile profile = new WorkloadProfile(buildProfile(jsc.parallelize(records)));\n+    WorkloadProfile profile = new WorkloadProfile(buildProfile(jsc.parallelize(records)), WriteOperationType.UPSERT);\n     UpsertPartitioner partitioner = new UpsertPartitioner(profile, context, table, config);\n     assertEquals(0, partitioner.getPartition(\n         new Tuple2<>(updateRecords.get(0).getKey(), Option.ofNullable(updateRecords.get(0).getCurrentLocation()))),\n         \"Update record should have gone to the 1 update partition\");\n     return partitioner;\n   }\n \n+  private UpsertPartitioner getInsertPartitioner(int smallFileSize, int numInserts, int fileSize, String testPartitionPath,\n+      boolean autoSplitInserts) throws Exception {\n+    HoodieWriteConfig config = makeHoodieClientConfigBuilder()\n+            .withCompactionConfig(HoodieCompactionConfig.newBuilder().compactionSmallFileSize(smallFileSize)\n+                    .insertSplitSize(100).autoTuneInsertSplits(autoSplitInserts).build())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzIxMTY2", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504721166", "createdAt": "2020-10-08T12:19:45Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoxOTo0NVrOHeb0nQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoxOTo0NVrOHeb0nQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY3NTE2NQ==", "bodyText": "it would be better if you would describe how to get 3 expected partitions.", "url": "https://github.com/apache/hudi/pull/2111#discussion_r501675165", "createdAt": "2020-10-08T12:19:45Z", "author": {"login": "leesf"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/action/commit/TestUpsertPartitioner.java", "diffHunk": "@@ -286,8 +303,48 @@ public void testUpsertPartitionerWithSmallInsertHandling() throws Exception {\n         \"Bucket 3 is INSERT\");\n     assertEquals(4, insertBuckets.size(), \"Total of 4 insert buckets\");\n \n-    weights = new Double[] { 0.08, 0.31, 0.31, 0.31};\n-    cumulativeWeights = new Double[] { 0.08, 0.39, 0.69, 1.0};\n+    weights = new Double[] {0.08, 0.31, 0.31, 0.31};\n+    cumulativeWeights = new Double[] {0.08, 0.39, 0.69, 1.0};\n+    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n+  }\n+\n+  @Test\n+  public void testInsertPartitionerWithSmallInsertHandling() throws Exception {\n+    final String testPartitionPath = \"2016/09/26\";\n+    // Inserts  .. Check updates go together & inserts subsplit, after expanding smallest file\n+    UpsertPartitioner partitioner = getInsertPartitioner(1000 * 1024, 400, 800 * 1024, testPartitionPath, false);\n+    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n+\n+    assertEquals(3, partitioner.numPartitions(), \"Should have 3 partitions\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzIxNTc3", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504721577", "createdAt": "2020-10-08T12:20:16Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMDoxNlrOHeb17A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMDoxNlrOHeb17A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY3NTUwMA==", "bodyText": "ditto", "url": "https://github.com/apache/hudi/pull/2111#discussion_r501675500", "createdAt": "2020-10-08T12:20:16Z", "author": {"login": "leesf"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/action/commit/TestUpsertPartitioner.java", "diffHunk": "@@ -286,8 +303,48 @@ public void testUpsertPartitionerWithSmallInsertHandling() throws Exception {\n         \"Bucket 3 is INSERT\");\n     assertEquals(4, insertBuckets.size(), \"Total of 4 insert buckets\");\n \n-    weights = new Double[] { 0.08, 0.31, 0.31, 0.31};\n-    cumulativeWeights = new Double[] { 0.08, 0.39, 0.69, 1.0};\n+    weights = new Double[] {0.08, 0.31, 0.31, 0.31};\n+    cumulativeWeights = new Double[] {0.08, 0.39, 0.69, 1.0};\n+    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n+  }\n+\n+  @Test\n+  public void testInsertPartitionerWithSmallInsertHandling() throws Exception {\n+    final String testPartitionPath = \"2016/09/26\";\n+    // Inserts  .. Check updates go together & inserts subsplit, after expanding smallest file\n+    UpsertPartitioner partitioner = getInsertPartitioner(1000 * 1024, 400, 800 * 1024, testPartitionPath, false);\n+    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n+\n+    assertEquals(3, partitioner.numPartitions(), \"Should have 3 partitions\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(0).bucketType,\n+        \"Bucket 0 is INSERT\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n+        \"Bucket 1 is INSERT\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n+        \"Bucket 2 is INSERT\");\n+    assertEquals(3, insertBuckets.size(), \"Total of 3 insert buckets\");\n+\n+    Double[] weights = {0.5, 0.25, 0.25};\n+    Double[] cumulativeWeights = {0.5, 0.75, 1.0};\n+    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n+\n+    // Now with insert split size auto tuned\n+    partitioner = getInsertPartitioner(1000 * 1024, 2400, 800 * 1024, testPartitionPath, true);\n+    insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n+\n+    assertEquals(4, partitioner.numPartitions(), \"Should have 4 partitions\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "originalPosition": 106}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzIyODkw", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504722890", "createdAt": "2020-10-08T12:21:52Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMTo1MlrOHeb5tA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMTo1MlrOHeb5tA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY3NjQ2OA==", "bodyText": "would you please use foreach assertion instead of listing all buckets?", "url": "https://github.com/apache/hudi/pull/2111#discussion_r501676468", "createdAt": "2020-10-08T12:21:52Z", "author": {"login": "leesf"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/action/commit/TestUpsertPartitioner.java", "diffHunk": "@@ -286,8 +303,48 @@ public void testUpsertPartitionerWithSmallInsertHandling() throws Exception {\n         \"Bucket 3 is INSERT\");\n     assertEquals(4, insertBuckets.size(), \"Total of 4 insert buckets\");\n \n-    weights = new Double[] { 0.08, 0.31, 0.31, 0.31};\n-    cumulativeWeights = new Double[] { 0.08, 0.39, 0.69, 1.0};\n+    weights = new Double[] {0.08, 0.31, 0.31, 0.31};\n+    cumulativeWeights = new Double[] {0.08, 0.39, 0.69, 1.0};\n+    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n+  }\n+\n+  @Test\n+  public void testInsertPartitionerWithSmallInsertHandling() throws Exception {\n+    final String testPartitionPath = \"2016/09/26\";\n+    // Inserts  .. Check updates go together & inserts subsplit, after expanding smallest file\n+    UpsertPartitioner partitioner = getInsertPartitioner(1000 * 1024, 400, 800 * 1024, testPartitionPath, false);\n+    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n+\n+    assertEquals(3, partitioner.numPartitions(), \"Should have 3 partitions\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(0).bucketType,\n+        \"Bucket 0 is INSERT\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n+        \"Bucket 1 is INSERT\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n+        \"Bucket 2 is INSERT\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "originalPosition": 95}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzIzMDcw", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504723070", "createdAt": "2020-10-08T12:22:04Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMjowNFrOHeb6Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMjowNFrOHeb6Ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY3NjU3OA==", "bodyText": "ditto", "url": "https://github.com/apache/hudi/pull/2111#discussion_r501676578", "createdAt": "2020-10-08T12:22:04Z", "author": {"login": "leesf"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/table/action/commit/TestUpsertPartitioner.java", "diffHunk": "@@ -286,8 +303,48 @@ public void testUpsertPartitionerWithSmallInsertHandling() throws Exception {\n         \"Bucket 3 is INSERT\");\n     assertEquals(4, insertBuckets.size(), \"Total of 4 insert buckets\");\n \n-    weights = new Double[] { 0.08, 0.31, 0.31, 0.31};\n-    cumulativeWeights = new Double[] { 0.08, 0.39, 0.69, 1.0};\n+    weights = new Double[] {0.08, 0.31, 0.31, 0.31};\n+    cumulativeWeights = new Double[] {0.08, 0.39, 0.69, 1.0};\n+    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n+  }\n+\n+  @Test\n+  public void testInsertPartitionerWithSmallInsertHandling() throws Exception {\n+    final String testPartitionPath = \"2016/09/26\";\n+    // Inserts  .. Check updates go together & inserts subsplit, after expanding smallest file\n+    UpsertPartitioner partitioner = getInsertPartitioner(1000 * 1024, 400, 800 * 1024, testPartitionPath, false);\n+    List<InsertBucketCumulativeWeightPair> insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n+\n+    assertEquals(3, partitioner.numPartitions(), \"Should have 3 partitions\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(0).bucketType,\n+        \"Bucket 0 is INSERT\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n+        \"Bucket 1 is INSERT\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n+        \"Bucket 2 is INSERT\");\n+    assertEquals(3, insertBuckets.size(), \"Total of 3 insert buckets\");\n+\n+    Double[] weights = {0.5, 0.25, 0.25};\n+    Double[] cumulativeWeights = {0.5, 0.75, 1.0};\n+    assertInsertBuckets(weights, cumulativeWeights, insertBuckets);\n+\n+    // Now with insert split size auto tuned\n+    partitioner = getInsertPartitioner(1000 * 1024, 2400, 800 * 1024, testPartitionPath, true);\n+    insertBuckets = partitioner.getInsertBuckets(testPartitionPath);\n+\n+    assertEquals(4, partitioner.numPartitions(), \"Should have 4 partitions\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(0).bucketType,\n+        \"Bucket 0 is INSERT\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(1).bucketType,\n+        \"Bucket 1 is INSERT\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(2).bucketType,\n+        \"Bucket 2 is INSERT\");\n+    assertEquals(BucketType.INSERT, partitioner.getBucketInfo(3).bucketType,\n+        \"Bucket 3 is INSERT\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "originalPosition": 114}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzIzNzMx", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504723731", "createdAt": "2020-10-08T12:22:49Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMjo0OVrOHeb74g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMjo0OVrOHeb74g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY3NzAyNg==", "bodyText": "would you please explain why change from 200 to 100 ?", "url": "https://github.com/apache/hudi/pull/2111#discussion_r501677026", "createdAt": "2020-10-08T12:22:49Z", "author": {"login": "leesf"}, "path": "hudi-integ-test/src/test/java/org/apache/hudi/integ/command/ITTestHoodieSyncCommand.java", "diffHunk": "@@ -52,7 +52,7 @@ public void testValidateSync() throws Exception {\n         executeCommandStringInDocker(ADHOC_1_CONTAINER, HUDI_CLI_TOOL + \" --cmdfile \" + SYNC_VALIDATE_COMMANDS, true);\n \n     String expected = String.format(\"Count difference now is (count(%s) - count(%s) == %d. Catch up count is %d\",\n-        hiveTableName, hiveTableName2, 100, 200);\n+        hiveTableName, hiveTableName2, 100, 100);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzIzODQx", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504723841", "createdAt": "2020-10-08T12:22:56Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMjo1NlrOHeb8Mg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMjo1NlrOHeb8Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY3NzEwNg==", "bodyText": "ditto", "url": "https://github.com/apache/hudi/pull/2111#discussion_r501677106", "createdAt": "2020-10-08T12:22:56Z", "author": {"login": "leesf"}, "path": "hudi-spark/src/test/scala/org/apache/hudi/functional/TestMORDataSource.scala", "diffHunk": "@@ -211,7 +211,7 @@ class TestMORDataSource extends HoodieClientTestBase {\n     val hudiSnapshotDF5 = spark.read.format(\"org.apache.hudi\")\n       .option(DataSourceReadOptions.QUERY_TYPE_OPT_KEY, DataSourceReadOptions.QUERY_TYPE_SNAPSHOT_OPT_VAL)\n       .load(basePath + \"/*/*/*/*\")\n-    assertEquals(200, hudiSnapshotDF5.count())\n+    assertEquals(300, hudiSnapshotDF5.count())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NzI0MTg1", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-504724185", "createdAt": "2020-10-08T12:23:17Z", "commit": {"oid": "3ce6e021080921c9e01e819b577ab307e7cfee85"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "70a6777d7e24069938b82c6cda33e9e40e5c38c2", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/70a6777d7e24069938b82c6cda33e9e40e5c38c2", "committedDate": "2020-10-15T06:14:49Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "cd244bb28bb6826f09a612f4d75ab081d8cb749a", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/cd244bb28bb6826f09a612f4d75ab081d8cb749a", "committedDate": "2020-10-15T07:39:50Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA5Mzc4MTc4", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-509378178", "createdAt": "2020-10-15T13:28:17Z", "commit": {"oid": "cd244bb28bb6826f09a612f4d75ab081d8cb749a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxMzoyODoxN1rOHiHzRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxMzoyODoxN1rOHiHzRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTU0MTQ0Ng==", "bodyText": "would also merge\nfor (int b = 0; b < insertBuckets; b++) {\n            bucketNumbers.add(totalBuckets);\n            recordsPerBucket.add(totalUnassignedInserts / insertBuckets);\n            BucketInfo bucketInfo = new BucketInfo();\n            bucketInfo.bucketType = BucketType.INSERT;\n            bucketInfo.partitionPath = partitionPath;\n            bucketInfo.fileIdPrefix = FSUtils.createNewFileIdPfx();\n            bucketInfoMap.put(totalBuckets, bucketInfo);\n            totalBuckets++;\n          }\n\nthe logic to the method?", "url": "https://github.com/apache/hudi/pull/2111#discussion_r505541446", "createdAt": "2020-10-15T13:28:17Z", "author": {"login": "leesf"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/commit/UpsertPartitioner.java", "diffHunk": "@@ -129,6 +131,18 @@ private int addUpdateBucket(String partitionPath, String fileIdHint) {\n     return bucket;\n   }\n \n+  private int addInsertBucket(String partitionPath, String fileIdHint) {\n+    int bucket = totalBuckets;\n+    updateLocationToBucket.put(fileIdHint, bucket);\n+    BucketInfo bucketInfo = new BucketInfo();\n+    bucketInfo.bucketType = BucketType.INSERT;\n+    bucketInfo.fileIdPrefix = fileIdHint;\n+    bucketInfo.partitionPath = partitionPath;\n+    bucketInfoMap.put(totalBuckets, bucketInfo);\n+    totalBuckets++;\n+    return bucket;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd244bb28bb6826f09a612f4d75ab081d8cb749a"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA5MzgwMDkw", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-509380090", "createdAt": "2020-10-15T13:30:08Z", "commit": {"oid": "cd244bb28bb6826f09a612f4d75ab081d8cb749a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxMzozMDowOVrOHiH4sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxMzozMDowOVrOHiH4sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTU0MjgzMg==", "bodyText": "maybe we would create a new FileID instead of using exist small file id @bvaradar WDYT?", "url": "https://github.com/apache/hudi/pull/2111#discussion_r505542832", "createdAt": "2020-10-15T13:30:09Z", "author": {"login": "leesf"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/commit/UpsertPartitioner.java", "diffHunk": "@@ -160,11 +174,15 @@ private void assignInserts(WorkloadProfile profile, HoodieEngineContext context)\n           if (recordsToAppend > 0 && totalUnassignedInserts > 0) {\n             // create a new bucket or re-use an existing bucket\n             int bucket;\n-            if (updateLocationToBucket.containsKey(smallFile.location.getFileId())) {\n+            // insert new records regardless of small file when using insert operation\n+            if (isChangingRecords(profile.getOperationType())\n+                    && updateLocationToBucket.containsKey(smallFile.location.getFileId())) {\n               bucket = updateLocationToBucket.get(smallFile.location.getFileId());\n               LOG.info(\"Assigning \" + recordsToAppend + \" inserts to existing update bucket \" + bucket);\n             } else {\n-              bucket = addUpdateBucket(partitionPath, smallFile.location.getFileId());\n+              bucket = profile.getOperationType() == null || isChangingRecords(profile.getOperationType())\n+                      ? addUpdateBucket(partitionPath, smallFile.location.getFileId())\n+                      : addInsertBucket(partitionPath, smallFile.location.getFileId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd244bb28bb6826f09a612f4d75ab081d8cb749a"}, "originalPosition": 42}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1359b033f7fcd9c0c4a3579b38c7fc378bc000dd", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/1359b033f7fcd9c0c4a3579b38c7fc378bc000dd", "committedDate": "2020-10-15T16:29:52Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "f0a56e1337899a4f0ceeec8dc6998f88eb5adcfd", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/f0a56e1337899a4f0ceeec8dc6998f88eb5adcfd", "committedDate": "2020-10-16T06:31:49Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEwMzAzNjQ2", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-510303646", "createdAt": "2020-10-16T09:27:37Z", "commit": {"oid": "f0a56e1337899a4f0ceeec8dc6998f88eb5adcfd"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzMzIxNTMx", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-513321531", "createdAt": "2020-10-21T05:41:34Z", "commit": {"oid": "f0a56e1337899a4f0ceeec8dc6998f88eb5adcfd"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQwNTo0MTozNVrOHlbDFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQwNTo0MTozNVrOHlbDFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTAwMjUxOA==", "bodyText": "would really prefer a non -static import here. makes it easier on the eyes.", "url": "https://github.com/apache/hudi/pull/2111#discussion_r509002518", "createdAt": "2020-10-21T05:41:35Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/commit/UpsertPartitioner.java", "diffHunk": "@@ -54,6 +54,8 @@\n \n import scala.Tuple2;\n \n+import static org.apache.hudi.common.model.WriteOperationType.isChangingRecords;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f0a56e1337899a4f0ceeec8dc6998f88eb5adcfd"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f0a56e1337899a4f0ceeec8dc6998f88eb5adcfd", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/f0a56e1337899a4f0ceeec8dc6998f88eb5adcfd", "committedDate": "2020-10-16T06:31:49Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}, "afterCommit": {"oid": "0081537f85abb1654119bcaef6cb782441e9c600", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/0081537f85abb1654119bcaef6cb782441e9c600", "committedDate": "2021-01-07T04:35:03Z", "message": "Adding a config flag to route inserts to new files ignoring small file handling"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0081537f85abb1654119bcaef6cb782441e9c600", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/0081537f85abb1654119bcaef6cb782441e9c600", "committedDate": "2021-01-07T04:35:03Z", "message": "Adding a config flag to route inserts to new files ignoring small file handling"}, "afterCommit": {"oid": "3ee7854700476cf5185be5c765ec582e4f14955f", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/3ee7854700476cf5185be5c765ec582e4f14955f", "committedDate": "2021-01-07T04:38:31Z", "message": "Adding a config flag to route inserts to new files ignoring small file handling"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzMjA1NTE4", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-563205518", "createdAt": "2021-01-07T04:37:59Z", "commit": {"oid": "0081537f85abb1654119bcaef6cb782441e9c600"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNDozNzo1OVrOIPe1SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNDozNzo1OVrOIPe1SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEwNDcxMg==", "bodyText": "I don't want to add config.isRouteInsertsToNewFiles() to all 3 if else conditions and hence, have added a bigger if else for older and new code path.", "url": "https://github.com/apache/hudi/pull/2111#discussion_r553104712", "createdAt": "2021-01-07T04:37:59Z", "author": {"login": "nsivabalan"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/commit/UpsertPartitioner.java", "diffHunk": "@@ -191,14 +201,29 @@ private void assignInserts(WorkloadProfile profile, HoodieEngineContext context)\n           long recordsToAppend = Math.min((config.getParquetMaxFileSize() - smallFile.sizeBytes) / averageRecordSize,\n               totalUnassignedInserts);\n           if (recordsToAppend > 0 && totalUnassignedInserts > 0) {\n-            // create a new bucket or re-use an existing bucket\n             int bucket;\n-            if (updateLocationToBucket.containsKey(smallFile.location.getFileId())) {\n-              bucket = updateLocationToBucket.get(smallFile.location.getFileId());\n-              LOG.info(\"Assigning \" + recordsToAppend + \" inserts to existing update bucket \" + bucket);\n-            } else {\n-              bucket = addUpdateBucket(partitionPath, smallFile.location.getFileId());\n-              LOG.info(\"Assigning \" + recordsToAppend + \" inserts to new update bucket \" + bucket);\n+            if (config.isRouteInsertsToNewFiles()) {\n+              // if insert operation, route inserts to new files regardless of small file handling.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0081537f85abb1654119bcaef6cb782441e9c600"}, "originalPosition": 37}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3ee7854700476cf5185be5c765ec582e4f14955f", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/3ee7854700476cf5185be5c765ec582e4f14955f", "committedDate": "2021-01-07T04:38:31Z", "message": "Adding a config flag to route inserts to new files ignoring small file handling"}, "afterCommit": {"oid": "dbb835a799e16212c9051571c1a9ee1ef080bcf4", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/dbb835a799e16212c9051571c1a9ee1ef080bcf4", "committedDate": "2021-01-07T13:47:47Z", "message": "Adding a config flag to route inserts to new files ignoring small file handling"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzOTcxNjg1", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-563971685", "createdAt": "2021-01-08T02:55:36Z", "commit": {"oid": "dbb835a799e16212c9051571c1a9ee1ef080bcf4"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQwMjo1NTozN1rOIQD-KA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQwMjo1NTozN1rOIQD-KA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzcxMzE5Mg==", "bodyText": "rename hoodie.merge.allow.duplicate.inserts", "url": "https://github.com/apache/hudi/pull/2111#discussion_r553713192", "createdAt": "2021-01-08T02:55:37Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -133,6 +133,10 @@\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n+  // Routes inserts to new files ignoring small file handling\n+  private static final String ROUTE_INSERTS_TO_NEW_FILES = \"hoodie.route.inserts.to.new.files\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dbb835a799e16212c9051571c1a9ee1ef080bcf4"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY5NDk0MDcz", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-569494073", "createdAt": "2021-01-15T18:17:05Z", "commit": {"oid": "36d316b4406ce344d92d75b856f2d936160f3393"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxODoxNzowNlrOIUnTyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxODoxNzowNlrOIUnTyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODQ4NjQ3Mg==", "bodyText": "@vinothchandar : Have added this new handle and tested that it works as expected. But would like to call out that any new records would just get appended. For instance, if records to be deleted (with \"_hoodie_is_deleted\" set to true) are sent via \"Insert\" operation, this handle will just append and may not recognize the deleted records as we don't do any combineAndUpdate.", "url": "https://github.com/apache/hudi/pull/2111#discussion_r558486472", "createdAt": "2021-01-15T18:17:06Z", "author": {"login": "nsivabalan"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/storage/HoodieConcatHandle.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.io.storage;\n+\n+import org.apache.hudi.client.common.TaskContextSupplier;\n+import org.apache.hudi.common.model.HoodieBaseFile;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieUpsertException;\n+import org.apache.hudi.io.HoodieMergeHandle;\n+import org.apache.hudi.table.HoodieTable;\n+\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.Map;\n+\n+/**\n+ * Handle to concatenate new records to old records w/o any merging. If Operation is set to Inserts, and if {{@link HoodieWriteConfig#isRouteInsertsToNewFiles()}}\n+ * is set, this handle will be used instead of {@link HoodieMergeHandle}\n+ */\n+public class HoodieConcatHandle<T extends HoodieRecordPayload, I, K, O> extends HoodieMergeHandle<T, I, K, O> {\n+\n+  private static final Logger LOG = LogManager.getLogger(HoodieConcatHandle.class);\n+\n+  public HoodieConcatHandle(HoodieWriteConfig config, String instantTime, HoodieTable hoodieTable, Iterator recordItr,\n+      String partitionPath, String fileId, TaskContextSupplier taskContextSupplier) {\n+    super(config, instantTime, hoodieTable, recordItr, partitionPath, fileId, taskContextSupplier);\n+  }\n+\n+  public HoodieConcatHandle(HoodieWriteConfig config, String instantTime, HoodieTable hoodieTable, Map keyToNewRecords, String partitionPath, String fileId,\n+      HoodieBaseFile dataFileToBeMerged, TaskContextSupplier taskContextSupplier) {\n+    super(config, instantTime, hoodieTable, keyToNewRecords, partitionPath, fileId, dataFileToBeMerged, taskContextSupplier);\n+  }\n+\n+  /**\n+   * Write old record as is w/o merging with incoming record.\n+   */\n+  @Override\n+  public void write(GenericRecord oldRecord) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36d316b4406ce344d92d75b856f2d936160f3393"}, "originalPosition": 60}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY5NDk1NDIy", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-569495422", "createdAt": "2021-01-15T18:19:06Z", "commit": {"oid": "36d316b4406ce344d92d75b856f2d936160f3393"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b6a6b4ecdfd64154341c0c0ed6573e50e871d6d0", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/b6a6b4ecdfd64154341c0c0ed6573e50e871d6d0", "committedDate": "2021-01-19T05:36:34Z", "message": "Minor fixes"}, "afterCommit": {"oid": "0b016c69f860f8cdf2bafca24ce5e3f70b84032e", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/0b016c69f860f8cdf2bafca24ce5e3f70b84032e", "committedDate": "2021-01-19T05:47:52Z", "message": "Minor fixes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxMTQ3MDY2", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-571147066", "createdAt": "2021-01-19T11:22:08Z", "commit": {"oid": "0b016c69f860f8cdf2bafca24ce5e3f70b84032e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMToyMjowOFrOIWKG7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMToyMjowOFrOIWKG7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwNTE5Nw==", "bodyText": "IMO, this could be defined as boolean type.", "url": "https://github.com/apache/hudi/pull/2111#discussion_r560105197", "createdAt": "2021-01-19T11:22:08Z", "author": {"login": "SteNicholas"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -133,6 +133,10 @@\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n+  // Concats inserts to data files without merging\n+  private static final String MERGE_ALLOW_DUPLICATE_INSERTS = \"hoodie.merge.allow.duplicate.inserts\";\n+  private static final String DEFAULT_MERGE_ALLOW_DUPLICATE_INSERTS = \"false\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b016c69f860f8cdf2bafca24ce5e3f70b84032e"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxNzYxMjk1", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-571761295", "createdAt": "2021-01-19T23:50:10Z", "commit": {"oid": "0b016c69f860f8cdf2bafca24ce5e3f70b84032e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQyMzo1MDoxMFrOIWm_Pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQyMzo1MDoxMFrOIWm_Pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDU3ODM2Nw==", "bodyText": "allowDuplicateInserts()", "url": "https://github.com/apache/hudi/pull/2111#discussion_r560578367", "createdAt": "2021-01-19T23:50:10Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -330,6 +334,10 @@ public boolean isMergeDataValidationCheckEnabled() {\n     return Boolean.parseBoolean(props.getProperty(MERGE_DATA_VALIDATION_CHECK_ENABLED));\n   }\n \n+  public boolean isMergeAllowDuplicateInserts() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b016c69f860f8cdf2bafca24ce5e3f70b84032e"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxNzYzMTA4", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-571763108", "createdAt": "2021-01-19T23:54:27Z", "commit": {"oid": "0b016c69f860f8cdf2bafca24ce5e3f70b84032e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxODczMTQ0", "url": "https://github.com/apache/hudi/pull/2111#pullrequestreview-571873144", "createdAt": "2021-01-20T05:03:25Z", "commit": {"oid": "0b016c69f860f8cdf2bafca24ce5e3f70b84032e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNTowMzoyNVrOIWtQOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNTowMzoyNVrOIWtQOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY4MTAxNg==", "bodyText": "@vinothchandar : does the config name looks ok? somehow I feel it does not exactly convey the actual intent, but talks about the effect. For instance,\nsomething like \"hoodie.concat.inserts.without.merge.on.insert\" or \"hoodie.concat.records.on.insert\" etc.", "url": "https://github.com/apache/hudi/pull/2111#discussion_r560681016", "createdAt": "2021-01-20T05:03:25Z", "author": {"login": "nsivabalan"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -133,6 +133,10 @@\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n+  // Concats inserts to data files without merging\n+  private static final String MERGE_ALLOW_DUPLICATE_INSERTS = \"hoodie.merge.allow.duplicate.inserts\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b016c69f860f8cdf2bafca24ce5e3f70b84032e"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7d52e77c6cd6972db9e85dabbc2143591b774a1", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/f7d52e77c6cd6972db9e85dabbc2143591b774a1", "committedDate": "2021-01-20T15:00:45Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f742ee0bfdbbbd6bfb6a5e1bb52bfec11f6a753", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/7f742ee0bfdbbbd6bfb6a5e1bb52bfec11f6a753", "committedDate": "2021-01-20T15:01:33Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dde11ef3cbd27bda17c2ce1f680a110bfcf6e5c1", "author": {"user": {"login": "SteNicholas", "name": "SteNicholas"}}, "url": "https://github.com/apache/hudi/commit/dde11ef3cbd27bda17c2ce1f680a110bfcf6e5c1", "committedDate": "2021-01-20T15:01:37Z", "message": "[HUDI-1234] Insert new records regardless of small file when using insert operation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c466a22d69088104c17e30e68a4b8f824d5dfbf5", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/c466a22d69088104c17e30e68a4b8f824d5dfbf5", "committedDate": "2021-01-20T15:02:42Z", "message": "Adding a config flag to route inserts to new files ignoring small file handling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "591e97e2837e0a15709edce85df31b09fa2b1586", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/591e97e2837e0a15709edce85df31b09fa2b1586", "committedDate": "2021-01-20T15:02:46Z", "message": "Adding HoodieConcatHandle to insert records w/o merging with \"Insert\" operation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "39123ef582ab8c8d388d7f3b714188310de68fc1", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/39123ef582ab8c8d388d7f3b714188310de68fc1", "committedDate": "2021-01-20T15:03:12Z", "message": "Reverting some of previous changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "09fcaa1fd9f21c1573e8450b7e28e21acfd05273", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/09fcaa1fd9f21c1573e8450b7e28e21acfd05273", "committedDate": "2021-01-20T15:03:16Z", "message": "Fixing tests in TestHoodieClientOnCopyOnWriteStorage.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c5d84cc5c0472c6d9001502d768ed1f16372296", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/4c5d84cc5c0472c6d9001502d768ed1f16372296", "committedDate": "2021-01-20T15:03:17Z", "message": "Minor fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1eec9b1cdb71e451fef5f19dc4f2d0692e773443", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/1eec9b1cdb71e451fef5f19dc4f2d0692e773443", "committedDate": "2021-01-20T15:03:18Z", "message": "Addressing comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e57413377a57f2861ab783f4df6483c163910ccd", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/e57413377a57f2861ab783f4df6483c163910ccd", "committedDate": "2021-01-20T04:44:18Z", "message": "Addressing comments"}, "afterCommit": {"oid": "23c6ce3f35da17c65465b786845a800856cd1c9f", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/23c6ce3f35da17c65465b786845a800856cd1c9f", "committedDate": "2021-01-20T15:17:11Z", "message": "Fetching and rebasing with master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "287a016ff22b8d555b8a6ea39135003417b93d7c", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/287a016ff22b8d555b8a6ea39135003417b93d7c", "committedDate": "2021-01-20T15:21:24Z", "message": "Fetching and rebasing with master"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "23c6ce3f35da17c65465b786845a800856cd1c9f", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/23c6ce3f35da17c65465b786845a800856cd1c9f", "committedDate": "2021-01-20T15:17:11Z", "message": "Fetching and rebasing with master"}, "afterCommit": {"oid": "287a016ff22b8d555b8a6ea39135003417b93d7c", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/287a016ff22b8d555b8a6ea39135003417b93d7c", "committedDate": "2021-01-20T15:21:24Z", "message": "Fetching and rebasing with master"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4569, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}