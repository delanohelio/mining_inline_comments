{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAwNTY5MzMx", "number": 2157, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQyMDozNjo1MVrOEsUI6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNzoyNjozNVrOEs5q6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0OTAyNzYyOnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/helpers/DFSPathSelector.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQyMDozNjo1MVrOHfiTBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQwODowMTozNlrOHfzS-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjgyOTgzMA==", "bodyText": "let us add java docs here?", "url": "https://github.com/apache/hudi/pull/2157#discussion_r502829830", "createdAt": "2020-10-10T20:36:51Z", "author": {"login": "pratyakshsharma"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/helpers/DFSPathSelector.java", "diffHunk": "@@ -119,4 +103,18 @@ public DFSPathSelector(TypedProperties props, Configuration hadoopConf) {\n       throw new HoodieIOException(\"Unable to read from source from checkpoint: \" + lastCheckpointStr, ioe);\n     }\n   }\n+\n+  private List<FileStatus> listEligibleFiles(FileSystem fs, Path path, long lastCheckpointTime) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14b56db5f68a078baa411fde61237b4fadc482b1"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzEwODM0NA==", "bodyText": "added", "url": "https://github.com/apache/hudi/pull/2157#discussion_r503108344", "createdAt": "2020-10-12T08:01:36Z", "author": {"login": "hotienvu"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/helpers/DFSPathSelector.java", "diffHunk": "@@ -119,4 +103,18 @@ public DFSPathSelector(TypedProperties props, Configuration hadoopConf) {\n       throw new HoodieIOException(\"Unable to read from source from checkpoint: \" + lastCheckpointStr, ioe);\n     }\n   }\n+\n+  private List<FileStatus> listEligibleFiles(FileSystem fs, Path path, long lastCheckpointTime) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjgyOTgzMA=="}, "originalCommit": {"oid": "14b56db5f68a078baa411fde61237b4fadc482b1"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NTE3NjcyOnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/helpers/DFSPathSelector.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNzoyNjozNVrOHgY3vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQwNjoxOTozMFrOHlb24g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzcyMzk2Ng==", "bodyText": "what's the advantage of walking recursively by ourselves, instead of calling fs.listStatus(,true) like before?  (in the interest of keeping PR minimal and changing just the prefix filtering)", "url": "https://github.com/apache/hudi/pull/2157#discussion_r503723966", "createdAt": "2020-10-13T07:26:35Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/helpers/DFSPathSelector.java", "diffHunk": "@@ -119,4 +103,25 @@ public DFSPathSelector(TypedProperties props, Configuration hadoopConf) {\n       throw new HoodieIOException(\"Unable to read from source from checkpoint: \" + lastCheckpointStr, ioe);\n     }\n   }\n+\n+  /**\n+   * List files recursively, filter out illegible files/directories while doing so.\n+   */\n+  private List<FileStatus> listEligibleFiles(FileSystem fs, Path path, long lastCheckpointTime) throws IOException {\n+    // skip files/dirs whose names start with (_, ., etc)\n+    FileStatus[] statuses = fs.listStatus(path, file ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83a2e3ee3c8e969d2f41407f3a6f8d256d960269"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzc3ODAzOA==", "bodyText": "Hi Vinoth, thanks for the feedback. Unfortunately the old listFiles(,true) returns everything so we will have to check all files under the path. Also the logic will be a bit more complicated cos we will have to check for all the sub-dir along the path too e.g. foo/_bar/file.  On the other hand, walking recursively allow us to exit early as soon as the file/directory name doesn't match. This will also allow us to do more directory skipping (based on modification time) in the future.\nUnder the hood, listFiles also call listStatus recursively so performance wise there should be no impact.", "url": "https://github.com/apache/hudi/pull/2157#discussion_r503778038", "createdAt": "2020-10-13T08:50:07Z", "author": {"login": "hotienvu"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/helpers/DFSPathSelector.java", "diffHunk": "@@ -119,4 +103,25 @@ public DFSPathSelector(TypedProperties props, Configuration hadoopConf) {\n       throw new HoodieIOException(\"Unable to read from source from checkpoint: \" + lastCheckpointStr, ioe);\n     }\n   }\n+\n+  /**\n+   * List files recursively, filter out illegible files/directories while doing so.\n+   */\n+  private List<FileStatus> listEligibleFiles(FileSystem fs, Path path, long lastCheckpointTime) throws IOException {\n+    // skip files/dirs whose names start with (_, ., etc)\n+    FileStatus[] statuses = fs.listStatus(path, file ->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzcyMzk2Ng=="}, "originalCommit": {"oid": "83a2e3ee3c8e969d2f41407f3a6f8d256d960269"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTAxNTc3OA==", "bodyText": "makes sense. thanks for the detailed explanation!", "url": "https://github.com/apache/hudi/pull/2157#discussion_r509015778", "createdAt": "2020-10-21T06:19:30Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/helpers/DFSPathSelector.java", "diffHunk": "@@ -119,4 +103,25 @@ public DFSPathSelector(TypedProperties props, Configuration hadoopConf) {\n       throw new HoodieIOException(\"Unable to read from source from checkpoint: \" + lastCheckpointStr, ioe);\n     }\n   }\n+\n+  /**\n+   * List files recursively, filter out illegible files/directories while doing so.\n+   */\n+  private List<FileStatus> listEligibleFiles(FileSystem fs, Path path, long lastCheckpointTime) throws IOException {\n+    // skip files/dirs whose names start with (_, ., etc)\n+    FileStatus[] statuses = fs.listStatus(path, file ->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzcyMzk2Ng=="}, "originalCommit": {"oid": "83a2e3ee3c8e969d2f41407f3a6f8d256d960269"}, "originalPosition": 80}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4334, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}