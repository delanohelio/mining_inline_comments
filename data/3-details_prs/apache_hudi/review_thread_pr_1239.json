{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzOTk5NTI3", "number": 1239, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNjo0NjoxOVrODY_FlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwNDoyNTo1N1rODZBprQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTI2MDM2OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/AbstractDFSSourceTestBase.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNjo0NjoxOVrOFfJzTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNjo1Mjo0N1rOFfJ0Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIxMDc2Ng==", "bodyText": "Based on the latest checkstyle about import, the order of these import statement is not correct.", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368210766", "createdAt": "2020-01-18T06:46:19Z", "author": {"login": "yanghua"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/AbstractDFSSourceTestBase.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.sources;\n+\n+import static org.junit.Assert.assertEquals;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIxMTAxNQ==", "bodyText": "Got it.  will fix it.  Somehow local checkstyle does not prompt any error.", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368211015", "createdAt": "2020-01-18T06:52:47Z", "author": {"login": "yihua"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/AbstractDFSSourceTestBase.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.sources;\n+\n+import static org.junit.Assert.assertEquals;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIxMDc2Ng=="}, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTI2MDUzOnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestJsonDFSSource.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNjo0NjozN1rOFfJzXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNjo0NjozN1rOFfJzXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIxMDc4Mw==", "bodyText": "ditto", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368210783", "createdAt": "2020-01-18T06:46:37Z", "author": {"login": "yanghua"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestJsonDFSSource.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.sources;\n+\n+import java.io.IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTI2MDYzOnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestParquetDFSSource.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNjo0Njo1MFrOFfJzbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwNjo0Njo1MFrOFfJzbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIxMDc5Ng==", "bodyText": "ditto", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368210796", "createdAt": "2020-01-18T06:46:50Z", "author": {"login": "yanghua"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestParquetDFSSource.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.sources;\n+\n+import java.io.IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTY4MDQ1OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/AbstractDFSSourceTestBase.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwNDoyNTo1N1rOFfNGcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQwNTo1Njo0NlrOFfNTRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2NDgxOA==", "bodyText": "Would not get the point of this method, a bit of tricky.", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368264818", "createdAt": "2020-01-19T04:25:57Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/AbstractDFSSourceTestBase.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.sources;\n+\n+import org.apache.hudi.AvroConversionUtils;\n+import org.apache.hudi.common.HoodieTestDataGenerator;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.utilities.UtilitiesTestBase;\n+import org.apache.hudi.utilities.deltastreamer.SourceFormatAdapter;\n+import org.apache.hudi.utilities.schema.FilebasedSchemaProvider;\n+\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * An abstract test base for {@link Source} using DFS as the file system.\n+ */\n+public abstract class AbstractDFSSourceTestBase extends UtilitiesTestBase {\n+\n+  FilebasedSchemaProvider schemaProvider;\n+  String dfsRoot;\n+  String fileSuffix;\n+  int fileCount = 1;\n+  HoodieTestDataGenerator dataGenerator = new HoodieTestDataGenerator();\n+\n+  @BeforeClass\n+  public static void initClass() throws Exception {\n+    UtilitiesTestBase.initClass();\n+  }\n+\n+  @AfterClass\n+  public static void cleanupClass() throws Exception {\n+    UtilitiesTestBase.cleanupClass();\n+  }\n+\n+  @Before\n+  public void setup() throws Exception {\n+    super.setup();\n+    schemaProvider = new FilebasedSchemaProvider(Helpers.setupSchemaOnDFS(), jsc);\n+  }\n+\n+  @After\n+  public void teardown() throws Exception {\n+    super.teardown();\n+  }\n+\n+  /**\n+   * Prepares the specific {@link Source} to test, by passing in necessary configurations.\n+   *\n+   * @return A {@link Source} using DFS as the file system.\n+   */\n+  abstract Source prepareDFSSource();\n+\n+  /**\n+   * Writes test data, i.e., a {@link List} of {@link HoodieRecord}, to a file on DFS.\n+   *\n+   * @param records Test data.\n+   * @param path    The path in {@link Path} of the file to write.\n+   * @throws IOException\n+   */\n+  abstract void writeNewDataToFile(List<HoodieRecord> records, Path path) throws IOException;\n+\n+  /**\n+   * Generates a batch of test data and writes the data to a file.  This can be called multiple times to generate multiple files.\n+   *\n+   * @return The {@link Path} of the file.\n+   * @throws IOException\n+   */\n+  Path generateOneFile() throws IOException {\n+    Path path = new Path(dfsRoot, fileCount + fileSuffix);\n+    switch (fileCount) {\n+      case 1:\n+        writeNewDataToFile(dataGenerator.generateInserts(\"000\", 100), path);\n+        fileCount++;\n+        return path;\n+      case 2:\n+        writeNewDataToFile(dataGenerator.generateInserts(\"001\", 10000), path);\n+        fileCount++;\n+        return path;\n+      default:\n+        return null;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "54032670a865e1498fa266648e3397f8f6908694"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2NjUyNA==", "bodyText": "Each time it's called, the method generates a new file for a batch of data.  Only two batches are considered.  Any suggestions to make it better?", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368266524", "createdAt": "2020-01-19T05:15:00Z", "author": {"login": "yihua"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/AbstractDFSSourceTestBase.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.sources;\n+\n+import org.apache.hudi.AvroConversionUtils;\n+import org.apache.hudi.common.HoodieTestDataGenerator;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.utilities.UtilitiesTestBase;\n+import org.apache.hudi.utilities.deltastreamer.SourceFormatAdapter;\n+import org.apache.hudi.utilities.schema.FilebasedSchemaProvider;\n+\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * An abstract test base for {@link Source} using DFS as the file system.\n+ */\n+public abstract class AbstractDFSSourceTestBase extends UtilitiesTestBase {\n+\n+  FilebasedSchemaProvider schemaProvider;\n+  String dfsRoot;\n+  String fileSuffix;\n+  int fileCount = 1;\n+  HoodieTestDataGenerator dataGenerator = new HoodieTestDataGenerator();\n+\n+  @BeforeClass\n+  public static void initClass() throws Exception {\n+    UtilitiesTestBase.initClass();\n+  }\n+\n+  @AfterClass\n+  public static void cleanupClass() throws Exception {\n+    UtilitiesTestBase.cleanupClass();\n+  }\n+\n+  @Before\n+  public void setup() throws Exception {\n+    super.setup();\n+    schemaProvider = new FilebasedSchemaProvider(Helpers.setupSchemaOnDFS(), jsc);\n+  }\n+\n+  @After\n+  public void teardown() throws Exception {\n+    super.teardown();\n+  }\n+\n+  /**\n+   * Prepares the specific {@link Source} to test, by passing in necessary configurations.\n+   *\n+   * @return A {@link Source} using DFS as the file system.\n+   */\n+  abstract Source prepareDFSSource();\n+\n+  /**\n+   * Writes test data, i.e., a {@link List} of {@link HoodieRecord}, to a file on DFS.\n+   *\n+   * @param records Test data.\n+   * @param path    The path in {@link Path} of the file to write.\n+   * @throws IOException\n+   */\n+  abstract void writeNewDataToFile(List<HoodieRecord> records, Path path) throws IOException;\n+\n+  /**\n+   * Generates a batch of test data and writes the data to a file.  This can be called multiple times to generate multiple files.\n+   *\n+   * @return The {@link Path} of the file.\n+   * @throws IOException\n+   */\n+  Path generateOneFile() throws IOException {\n+    Path path = new Path(dfsRoot, fileCount + fileSuffix);\n+    switch (fileCount) {\n+      case 1:\n+        writeNewDataToFile(dataGenerator.generateInserts(\"000\", 100), path);\n+        fileCount++;\n+        return path;\n+      case 2:\n+        writeNewDataToFile(dataGenerator.generateInserts(\"001\", 10000), path);\n+        fileCount++;\n+        return path;\n+      default:\n+        return null;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2NDgxOA=="}, "originalCommit": {"oid": "54032670a865e1498fa266648e3397f8f6908694"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2ODEwMw==", "bodyText": "In my latest commit, as we discussed, I parameterized this method to take the file name, commit time String and the number of records to generate, to make it easier to understand and use.", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368268103", "createdAt": "2020-01-19T05:56:46Z", "author": {"login": "yihua"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/AbstractDFSSourceTestBase.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.sources;\n+\n+import org.apache.hudi.AvroConversionUtils;\n+import org.apache.hudi.common.HoodieTestDataGenerator;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.utilities.UtilitiesTestBase;\n+import org.apache.hudi.utilities.deltastreamer.SourceFormatAdapter;\n+import org.apache.hudi.utilities.schema.FilebasedSchemaProvider;\n+\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * An abstract test base for {@link Source} using DFS as the file system.\n+ */\n+public abstract class AbstractDFSSourceTestBase extends UtilitiesTestBase {\n+\n+  FilebasedSchemaProvider schemaProvider;\n+  String dfsRoot;\n+  String fileSuffix;\n+  int fileCount = 1;\n+  HoodieTestDataGenerator dataGenerator = new HoodieTestDataGenerator();\n+\n+  @BeforeClass\n+  public static void initClass() throws Exception {\n+    UtilitiesTestBase.initClass();\n+  }\n+\n+  @AfterClass\n+  public static void cleanupClass() throws Exception {\n+    UtilitiesTestBase.cleanupClass();\n+  }\n+\n+  @Before\n+  public void setup() throws Exception {\n+    super.setup();\n+    schemaProvider = new FilebasedSchemaProvider(Helpers.setupSchemaOnDFS(), jsc);\n+  }\n+\n+  @After\n+  public void teardown() throws Exception {\n+    super.teardown();\n+  }\n+\n+  /**\n+   * Prepares the specific {@link Source} to test, by passing in necessary configurations.\n+   *\n+   * @return A {@link Source} using DFS as the file system.\n+   */\n+  abstract Source prepareDFSSource();\n+\n+  /**\n+   * Writes test data, i.e., a {@link List} of {@link HoodieRecord}, to a file on DFS.\n+   *\n+   * @param records Test data.\n+   * @param path    The path in {@link Path} of the file to write.\n+   * @throws IOException\n+   */\n+  abstract void writeNewDataToFile(List<HoodieRecord> records, Path path) throws IOException;\n+\n+  /**\n+   * Generates a batch of test data and writes the data to a file.  This can be called multiple times to generate multiple files.\n+   *\n+   * @return The {@link Path} of the file.\n+   * @throws IOException\n+   */\n+  Path generateOneFile() throws IOException {\n+    Path path = new Path(dfsRoot, fileCount + fileSuffix);\n+    switch (fileCount) {\n+      case 1:\n+        writeNewDataToFile(dataGenerator.generateInserts(\"000\", 100), path);\n+        fileCount++;\n+        return path;\n+      case 2:\n+        writeNewDataToFile(dataGenerator.generateInserts(\"001\", 10000), path);\n+        fileCount++;\n+        return path;\n+      default:\n+        return null;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2NDgxOA=="}, "originalCommit": {"oid": "54032670a865e1498fa266648e3397f8f6908694"}, "originalPosition": 118}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4975, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}