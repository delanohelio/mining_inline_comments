{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc2ODUzMDEy", "number": 1341, "title": "[HUDI-626] Add exportToTable option to CLI", "bodyText": "What is the purpose of the pull request\nCLI shell is very restrictive and it is sometimes hard to filter specific rows. Adding ability to export results of CLI command into temporary table. So CLI users can write HiveQL queries to look for any specific information.\n(This idea has been brought up by multiple folks on the team, thanks everyone for great suggestions)\nBrief change log\n\nAdd 'exportToTableName' cli option for commits command.\nThis creates a temp table in spark session. Users can write HiveQL queries against the table to filter desired row.\nNote, intentionally not using Hoodie format for temp tables (to avoid versioning and any potential bugs in hoodie)\nOnly added this option for commits. But can add it to other commands if general approach looks good.\n\nExample usage:\n->commits show archived --startTs \"20200121224545\" --endTs \"20200224004414\"   --includeExtraMetadata true --exportToTableName satishkotha_debug\nWrote table view: satishkotha_debug\n\ntemp_query --sql \"select Instant, NumInserts, NumWrites from satishkotha_debug where FileId='ed33bd99-466f-4417-bd92-5d914fa58a8f' and Instant > '20200123211217' order by Instant\"\n+--------------+----------+---------+\n|Instant       |NumInserts|NumWrites|\n+--------------+----------+---------+\n|20200123221012|0         |2418     |\n|20200123223835|0         |2418     |\n|20200123231230|0         |2418     |\n|20200123233911|0         |2418     |\n|20200124000848|3         |3        |\n|20200124004403|7         |10       |\n|20200124013616|1         |11       |\n|20200124020556|1         |12       |\n|20200124061752|1         |13       |\n\nVerify this pull request\nOnly changes CLI. can be verified by running CLI commands.\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-02-18T21:48:49Z", "url": "https://github.com/apache/hudi/pull/1341", "merged": true, "mergeCommit": {"oid": "3d3781810c2fd28c85407b04aad08fc2a85174dc"}, "closed": true, "closedAt": "2020-03-06T16:53:24Z", "author": {"login": "satishkotha"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcFpH2RgBqjMwNDg5NjMxMzc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcKNCknABqjMwOTQ2NDM2MTQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwNzQwMTIz", "url": "https://github.com/apache/hudi/pull/1341#pullrequestreview-360740123", "createdAt": "2020-02-18T23:08:38Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMzowODozOFrOFrVy2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMzowOTozMVrOFrVz6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk5MDE3MQ==", "bodyText": "Please desist from using any Guava APIs.", "url": "https://github.com/apache/hudi/pull/1341#discussion_r380990171", "createdAt": "2020-02-18T23:08:38Z", "author": {"login": "smarthi"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/HoodiePrintHelper.java", "diffHunk": "@@ -18,13 +18,16 @@\n \n package org.apache.hudi.cli;\n \n+import com.google.common.base.Strings;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk5MDQ0MA==", "bodyText": "Replace this with StringUtils.isNullOrEmpty() pending PR# 1159", "url": "https://github.com/apache/hudi/pull/1341#discussion_r380990440", "createdAt": "2020-02-18T23:09:31Z", "author": {"login": "smarthi"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/HoodiePrintHelper.java", "diffHunk": "@@ -57,11 +60,38 @@ public static String print(String[] header, String[][] rows) {\n    */\n   public static String print(TableHeader rowHeader, Map<String, Function<Object, String>> fieldNameToConverterMap,\n       String sortByField, boolean isDescending, Integer limit, boolean headerOnly, List<Comparable[]> rows) {\n+    return print(rowHeader, fieldNameToConverterMap, sortByField, isDescending, limit, headerOnly, rows, \"\");\n+  }\n+\n+  /**\n+   * Serialize Table to printable string and also export a temporary view to easily write sql queries.\n+   *\n+   * Ideally, exporting view needs to be outside PrintHelper, but all commands use this. So this is easy\n+   * way to add support for all commands\n+   *\n+   * @param rowHeader Row Header\n+   * @param fieldNameToConverterMap Field Specific Converters\n+   * @param sortByField Sorting field\n+   * @param isDescending Order\n+   * @param limit Limit\n+   * @param headerOnly Headers only\n+   * @param rows List of rows\n+   * @param tempTableName table name to export\n+   * @return Serialized form for printing\n+   */\n+  public static String print(TableHeader rowHeader, Map<String, Function<Object, String>> fieldNameToConverterMap,\n+      String sortByField, boolean isDescending, Integer limit, boolean headerOnly, List<Comparable[]> rows,\n+      String tempTableName) {\n \n     if (headerOnly) {\n       return HoodiePrintHelper.print(rowHeader);\n     }\n \n+    if (!Strings.isNullOrEmpty(tempTableName)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwNzQzODIw", "url": "https://github.com/apache/hudi/pull/1341#pullrequestreview-360743820", "createdAt": "2020-02-18T23:18:01Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMzoxODowMVrOFrV-rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMzoxODowMVrOFrV-rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk5MzE5OA==", "bodyText": "Is this gonna be coupled to Spark? It's best not to add more Spark specific code given that there is work being undertaken to support other engines like flink on Hudi.  Can this be abstracted out to be engine agnostic ?", "url": "https://github.com/apache/hudi/pull/1341#discussion_r380993198", "createdAt": "2020-02-18T23:18:01Z", "author": {"login": "smarthi"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/utils/TempTableUtil.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.utils;\n+\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+public class TempTableUtil {\n+  private static final Logger LOG = LogManager.getLogger(TempTableUtil.class);\n+\n+  private JavaSparkContext jsc;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYwNzQ0MDIy", "url": "https://github.com/apache/hudi/pull/1341#pullrequestreview-360744022", "createdAt": "2020-02-18T23:18:29Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMzoxODoyOVrOFrV_Qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMzoxODoyOVrOFrV_Qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk5MzM0Ng==", "bodyText": "Please use Generic types if possible.", "url": "https://github.com/apache/hudi/pull/1341#discussion_r380993346", "createdAt": "2020-02-18T23:18:29Z", "author": {"login": "smarthi"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/utils/TempTableUtil.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.utils;\n+\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+public class TempTableUtil {\n+  private static final Logger LOG = LogManager.getLogger(TempTableUtil.class);\n+\n+  private JavaSparkContext jsc;\n+  private SQLContext sqlContext;\n+\n+  public TempTableUtil(String appName) {\n+    try {\n+      SparkConf sparkConf = new SparkConf().setAppName(appName)\n+              .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\").setMaster(\"local[8]\");\n+      jsc = new JavaSparkContext(sparkConf);\n+      jsc.setLogLevel(\"ERROR\");\n+\n+      sqlContext = new SQLContext(jsc);\n+    } catch (Throwable ex) {\n+      // log full stack trace and rethrow. Without this its difficult to debug failures, if any\n+      LOG.error(\"unable to initialize spark context \", ex);\n+      throw new HoodieException(ex);\n+    }\n+  }\n+\n+  public void write(String tableName, List<String> headers, List<List<Comparable>> rows) {\n+    try {\n+      if (headers.isEmpty() || rows.isEmpty()) {\n+        return;\n+      }\n+\n+      if (rows.stream().filter(row -> row.size() != headers.size()).count() > 0) {\n+        throw new HoodieException(\"Invalid row, does not match headers \" + headers.size() + \" \" + rows.size());\n+      }\n+\n+      // replace all whitespaces in headers to make it easy to write sql queries\n+      List<String> headersNoSpaces = headers.stream().map(title -> title.replaceAll(\"\\\\s+\",\"\"))\n+              .collect(Collectors.toList());\n+\n+      // generate schema for table\n+      StructType structType = new StructType();\n+      for (int i = 0; i < headersNoSpaces.size(); i++) {\n+        // try guessing data type from column data.\n+        DataType headerDataType = getDataType(rows.get(0).get(i));\n+        structType = structType.add(DataTypes.createStructField(headersNoSpaces.get(i), headerDataType, true));\n+      }\n+      List<Row> records = rows.stream().map(row -> RowFactory.create(row.toArray(new Comparable[row.size()])))\n+              .collect(Collectors.toList());\n+      Dataset<Row> dataset = this.sqlContext.createDataFrame(records, structType);\n+      dataset.createOrReplaceTempView(tableName);\n+      System.out.println(\"Wrote table view: \" + tableName);\n+    } catch (Throwable ex) {\n+      // log full stack trace and rethrow. Without this its difficult to debug failures, if any\n+      LOG.error(\"unable to write \", ex);\n+      throw new HoodieException(ex);\n+    }\n+  }\n+\n+  public void runQuery(String sqlText) {\n+    try {\n+      this.sqlContext.sql(sqlText).show(Integer.MAX_VALUE, false);\n+    } catch (Throwable ex) {\n+      // log full stack trace and rethrow. Without this its difficult to debug failures, if any\n+      LOG.error(\"unable to read \", ex);\n+      throw new HoodieException(ex);\n+    }\n+  }\n+\n+  public void deleteTable(String tableName) {\n+    try {\n+      sqlContext.sql(\"DROP TABLE IF EXISTS \" + tableName);\n+    } catch (Throwable ex) {\n+      // log full stack trace and rethrow. Without this its difficult to debug failures, if any\n+      LOG.error(\"unable to initialize spark context \", ex);\n+      throw new HoodieException(ex);\n+    }\n+  }\n+\n+  private DataType getDataType(Comparable comparable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 111}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYzNzkwMzQ5", "url": "https://github.com/apache/hudi/pull/1341#pullrequestreview-363790349", "createdAt": "2020-02-25T00:10:56Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwMDoxMDo1N1rOFt0aMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQwMDoxMDo1N1rOFt0aMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU4ODkxMg==", "bodyText": "This is not a real hive table. So maybe reword this for clarity. Also, export means something persistent while this is a temporary view.\nName of in-memory view to cache results.", "url": "https://github.com/apache/hudi/pull/1341#discussion_r383588912", "createdAt": "2020-02-25T00:10:57Z", "author": {"login": "prashantwason"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CommitsCommand.java", "diffHunk": "@@ -145,13 +148,16 @@ private String printCommitsWithMetadata(HoodieDefaultTimeline timeline,\n             .addTableHeaderField(\"Total Rollback Blocks\").addTableHeaderField(\"Total Log Records\")\n             .addTableHeaderField(\"Total Updated Records Compacted\").addTableHeaderField(\"Total Write Bytes\");\n \n-    return HoodiePrintHelper.print(header, new HashMap<>(), sortByField, descending, limit, headerOnly, rows);\n+    return HoodiePrintHelper.print(header, new HashMap<>(), sortByField, descending,\n+            limit, headerOnly, rows, tempTableName);\n   }\n \n   @CliCommand(value = \"commits show\", help = \"Show the commits\")\n   public String showCommits(\n       @CliOption(key = {\"includeExtraMetadata\"}, help = \"Include extra metadata\",\n           unspecifiedDefaultValue = \"false\") final boolean includeExtraMetadata,\n+      @CliOption(key = {\"exportToTableName\"}, mandatory = false, help = \"hive table name to export\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYzNzkyMzkz", "url": "https://github.com/apache/hudi/pull/1341#pullrequestreview-363792393", "createdAt": "2020-02-25T00:16:41Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MTc5OTU1", "url": "https://github.com/apache/hudi/pull/1341#pullrequestreview-365179955", "createdAt": "2020-02-26T19:30:14Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxOTozMDoxNFrOFu5FyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxOTozMDoxNFrOFu5FyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDcxNDE4NA==", "bodyText": "Can we provide 2 different API's :\n\ncreateTable\nwriteToTable", "url": "https://github.com/apache/hudi/pull/1341#discussion_r384714184", "createdAt": "2020-02-26T19:30:14Z", "author": {"login": "n3nash"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/utils/TempViewProvider.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.utils;\n+\n+import java.util.List;\n+\n+public interface TempViewProvider {\n+  void write(String tableName, List<String> headers, List<List<Comparable>> rows);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MTgwNjM3", "url": "https://github.com/apache/hudi/pull/1341#pullrequestreview-365180637", "createdAt": "2020-02-26T19:31:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxOTozMToxNlrOFu5H5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxOTozMToxNlrOFu5H5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDcxNDcyNg==", "bodyText": "Just keep a constant :\nString DUMMY_STRING = \"\";\nand then return that constant..", "url": "https://github.com/apache/hudi/pull/1341#discussion_r384714726", "createdAt": "2020-02-26T19:31:16Z", "author": {"login": "n3nash"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/TempViewCommand.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+\n+/**\n+ * CLI command to query/delete temp views.\n+ */\n+@Component\n+public class TempViewCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"temp_query\", help = \"query against created temp view\")\n+  public String query(\n+          @CliOption(key = {\"sql\"}, mandatory = true, help = \"select query to run against view\") final String sql)\n+          throws IOException {\n+\n+    HoodieCLI.getTempViewProvider().runQuery(sql);\n+    return \"\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MTgwNzgw", "url": "https://github.com/apache/hudi/pull/1341#pullrequestreview-365180780", "createdAt": "2020-02-26T19:31:29Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "64c8ef0d269f01541607d4dfc90772141e52a89b", "author": {"user": {"login": "satishkotha", "name": null}}, "url": "https://github.com/apache/hudi/commit/64c8ef0d269f01541607d4dfc90772141e52a89b", "committedDate": "2020-03-04T01:56:20Z", "message": "[CLI] Add export to table"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "64c8ef0d269f01541607d4dfc90772141e52a89b", "author": {"user": {"login": "satishkotha", "name": null}}, "url": "https://github.com/apache/hudi/commit/64c8ef0d269f01541607d4dfc90772141e52a89b", "committedDate": "2020-03-04T01:56:20Z", "message": "[CLI] Add export to table"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3584, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}