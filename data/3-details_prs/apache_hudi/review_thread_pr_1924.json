{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYzNzM1Nzk4", "number": 1924, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwNzo1Njo0NFrOEVtiaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwNzo1Nzo1NlrOEVtkJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMjAxNjQzOnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/bootstrap/BootstrapUtils.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwNzo1Njo0NFrOG8nmFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwNjo0MTowMVrOG9OUVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIxNjQ2OA==", "bodyText": "we had some very similar code for marker dir listing? can we see if we can reuse some code here across them?", "url": "https://github.com/apache/hudi/pull/1924#discussion_r466216468", "createdAt": "2020-08-06T07:56:44Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/bootstrap/BootstrapUtils.java", "diffHunk": "@@ -41,37 +48,87 @@\n    * Returns leaf folders with files under a path.\n    * @param fs  File System\n    * @param basePathStr Base Path to look for leaf folders\n-   * @param filePathFilter  Filters to skip directories/paths\n+   * @param jsc Java spark context\n    * @return list of partition paths with files under them.\n    * @throws IOException\n    */\n   public static List<Pair<String, List<HoodieFileStatus>>> getAllLeafFoldersWithFiles(FileSystem fs, String basePathStr,\n-                                                                                      PathFilter filePathFilter) throws IOException {\n+      JavaSparkContext jsc) throws IOException {\n     final Path basePath = new Path(basePathStr);\n     final Map<Integer, List<String>> levelToPartitions = new HashMap<>();\n     final Map<String, List<HoodieFileStatus>> partitionToFiles = new HashMap<>();\n-    FSUtils.processFiles(fs, basePathStr, (status) -> {\n-      if (status.isFile() && filePathFilter.accept(status.getPath())) {\n-        String relativePath = FSUtils.getRelativePartitionPath(basePath, status.getPath().getParent());\n-        List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n-        if (null == statusList) {\n-          Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n-          List<String> dirs = levelToPartitions.get(level);\n-          if (null == dirs) {\n-            dirs = new ArrayList<>();\n-            levelToPartitions.put(level, dirs);\n+    PathFilter filePathFilter = getFilePathFilter();\n+    PathFilter metaPathFilter = getExcludeMetaPathFilter();\n+\n+    FileStatus[] topLevelStatuses = fs.listStatus(new Path(basePathStr));\n+    List<String> subDirectories = new ArrayList<>();\n+\n+    List<Pair<HoodieFileStatus, Pair<Integer, String>>> result = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc3OTQ0Mw==", "bodyText": "Only the outer structure is a bit similar in terms of first listing and taking action on top level files, and then using spark context to perform the same action on sub-directories in parallel. But the inner logic is different and values being collected are different.\nIf we really want to re-use the common outer logic, it would require exploring extracting out the inner logic into serializable functions that would work fine with spark context as well. So, to not over-complicate this PR I can explore this separately if its okay. I have created a new Jira https://issues.apache.org/jira/browse/HUDI-1158 where I have listed the two optimizations we discussed about w.r.t to parallel listing behavior:\n\nThe parallelization should be at leaf partition directory level and not just at the top directory level\nExtract out common code paths", "url": "https://github.com/apache/hudi/pull/1924#discussion_r466779443", "createdAt": "2020-08-07T02:02:07Z", "author": {"login": "umehrot2"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/bootstrap/BootstrapUtils.java", "diffHunk": "@@ -41,37 +48,87 @@\n    * Returns leaf folders with files under a path.\n    * @param fs  File System\n    * @param basePathStr Base Path to look for leaf folders\n-   * @param filePathFilter  Filters to skip directories/paths\n+   * @param jsc Java spark context\n    * @return list of partition paths with files under them.\n    * @throws IOException\n    */\n   public static List<Pair<String, List<HoodieFileStatus>>> getAllLeafFoldersWithFiles(FileSystem fs, String basePathStr,\n-                                                                                      PathFilter filePathFilter) throws IOException {\n+      JavaSparkContext jsc) throws IOException {\n     final Path basePath = new Path(basePathStr);\n     final Map<Integer, List<String>> levelToPartitions = new HashMap<>();\n     final Map<String, List<HoodieFileStatus>> partitionToFiles = new HashMap<>();\n-    FSUtils.processFiles(fs, basePathStr, (status) -> {\n-      if (status.isFile() && filePathFilter.accept(status.getPath())) {\n-        String relativePath = FSUtils.getRelativePartitionPath(basePath, status.getPath().getParent());\n-        List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n-        if (null == statusList) {\n-          Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n-          List<String> dirs = levelToPartitions.get(level);\n-          if (null == dirs) {\n-            dirs = new ArrayList<>();\n-            levelToPartitions.put(level, dirs);\n+    PathFilter filePathFilter = getFilePathFilter();\n+    PathFilter metaPathFilter = getExcludeMetaPathFilter();\n+\n+    FileStatus[] topLevelStatuses = fs.listStatus(new Path(basePathStr));\n+    List<String> subDirectories = new ArrayList<>();\n+\n+    List<Pair<HoodieFileStatus, Pair<Integer, String>>> result = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIxNjQ2OA=="}, "originalCommit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg1MDkwMw==", "bodyText": "Sounds good . @umehrot2", "url": "https://github.com/apache/hudi/pull/1924#discussion_r466850903", "createdAt": "2020-08-07T06:41:01Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/bootstrap/BootstrapUtils.java", "diffHunk": "@@ -41,37 +48,87 @@\n    * Returns leaf folders with files under a path.\n    * @param fs  File System\n    * @param basePathStr Base Path to look for leaf folders\n-   * @param filePathFilter  Filters to skip directories/paths\n+   * @param jsc Java spark context\n    * @return list of partition paths with files under them.\n    * @throws IOException\n    */\n   public static List<Pair<String, List<HoodieFileStatus>>> getAllLeafFoldersWithFiles(FileSystem fs, String basePathStr,\n-                                                                                      PathFilter filePathFilter) throws IOException {\n+      JavaSparkContext jsc) throws IOException {\n     final Path basePath = new Path(basePathStr);\n     final Map<Integer, List<String>> levelToPartitions = new HashMap<>();\n     final Map<String, List<HoodieFileStatus>> partitionToFiles = new HashMap<>();\n-    FSUtils.processFiles(fs, basePathStr, (status) -> {\n-      if (status.isFile() && filePathFilter.accept(status.getPath())) {\n-        String relativePath = FSUtils.getRelativePartitionPath(basePath, status.getPath().getParent());\n-        List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n-        if (null == statusList) {\n-          Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n-          List<String> dirs = levelToPartitions.get(level);\n-          if (null == dirs) {\n-            dirs = new ArrayList<>();\n-            levelToPartitions.put(level, dirs);\n+    PathFilter filePathFilter = getFilePathFilter();\n+    PathFilter metaPathFilter = getExcludeMetaPathFilter();\n+\n+    FileStatus[] topLevelStatuses = fs.listStatus(new Path(basePathStr));\n+    List<String> subDirectories = new ArrayList<>();\n+\n+    List<Pair<HoodieFileStatus, Pair<Integer, String>>> result = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIxNjQ2OA=="}, "originalCommit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMjAyMDg2OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/bootstrap/BootstrapUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwNzo1Nzo1N1rOG8no0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMTo0MzozNlrOG9JrGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIxNzE2OA==", "bodyText": "can we just use the table's base file format here?", "url": "https://github.com/apache/hudi/pull/1924#discussion_r466217168", "createdAt": "2020-08-06T07:57:57Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/bootstrap/BootstrapUtils.java", "diffHunk": "@@ -41,37 +48,87 @@\n    * Returns leaf folders with files under a path.\n    * @param fs  File System\n    * @param basePathStr Base Path to look for leaf folders\n-   * @param filePathFilter  Filters to skip directories/paths\n+   * @param jsc Java spark context\n    * @return list of partition paths with files under them.\n    * @throws IOException\n    */\n   public static List<Pair<String, List<HoodieFileStatus>>> getAllLeafFoldersWithFiles(FileSystem fs, String basePathStr,\n-                                                                                      PathFilter filePathFilter) throws IOException {\n+      JavaSparkContext jsc) throws IOException {\n     final Path basePath = new Path(basePathStr);\n     final Map<Integer, List<String>> levelToPartitions = new HashMap<>();\n     final Map<String, List<HoodieFileStatus>> partitionToFiles = new HashMap<>();\n-    FSUtils.processFiles(fs, basePathStr, (status) -> {\n-      if (status.isFile() && filePathFilter.accept(status.getPath())) {\n-        String relativePath = FSUtils.getRelativePartitionPath(basePath, status.getPath().getParent());\n-        List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n-        if (null == statusList) {\n-          Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n-          List<String> dirs = levelToPartitions.get(level);\n-          if (null == dirs) {\n-            dirs = new ArrayList<>();\n-            levelToPartitions.put(level, dirs);\n+    PathFilter filePathFilter = getFilePathFilter();\n+    PathFilter metaPathFilter = getExcludeMetaPathFilter();\n+\n+    FileStatus[] topLevelStatuses = fs.listStatus(new Path(basePathStr));\n+    List<String> subDirectories = new ArrayList<>();\n+\n+    List<Pair<HoodieFileStatus, Pair<Integer, String>>> result = new ArrayList<>();\n+\n+    for (FileStatus topLevelStatus: topLevelStatuses) {\n+      if (topLevelStatus.isFile() && filePathFilter.accept(topLevelStatus.getPath())) {\n+        String relativePath = FSUtils.getRelativePartitionPath(basePath, topLevelStatus.getPath().getParent());\n+        Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n+        HoodieFileStatus hoodieFileStatus = FileStatusUtils.fromFileStatus(topLevelStatus);\n+        result.add(Pair.of(hoodieFileStatus, Pair.of(level, relativePath)));\n+      } else if (metaPathFilter.accept(topLevelStatus.getPath())) {\n+        subDirectories.add(topLevelStatus.getPath().toString());\n+      }\n+    }\n+\n+    if (subDirectories.size() > 0) {\n+      result.addAll(jsc.parallelize(subDirectories, subDirectories.size()).flatMap(directory -> {\n+        PathFilter pathFilter = getFilePathFilter();\n+        Path path = new Path(directory);\n+        FileSystem fileSystem = path.getFileSystem(new Configuration());\n+        RemoteIterator<LocatedFileStatus> itr = fileSystem.listFiles(path, true);\n+        List<Pair<HoodieFileStatus, Pair<Integer, String>>> res = new ArrayList<>();\n+        while (itr.hasNext()) {\n+          FileStatus status = itr.next();\n+          if (pathFilter.accept(status.getPath())) {\n+            String relativePath = FSUtils.getRelativePartitionPath(new Path(basePathStr), status.getPath().getParent());\n+            Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n+            HoodieFileStatus hoodieFileStatus = FileStatusUtils.fromFileStatus(status);\n+            res.add(Pair.of(hoodieFileStatus, Pair.of(level, relativePath)));\n           }\n-          dirs.add(relativePath);\n-          statusList = new ArrayList<>();\n-          partitionToFiles.put(relativePath, statusList);\n         }\n-        statusList.add(FileStatusUtils.fromFileStatus(status));\n+        return res.iterator();\n+      }).collect());\n+    }\n+\n+    result.forEach(val -> {\n+      String relativePath = val.getRight().getRight();\n+      List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n+      if (null == statusList) {\n+        Integer level = val.getRight().getLeft();\n+        List<String> dirs = levelToPartitions.get(level);\n+        if (null == dirs) {\n+          dirs = new ArrayList<>();\n+          levelToPartitions.put(level, dirs);\n+        }\n+        dirs.add(relativePath);\n+        statusList = new ArrayList<>();\n+        partitionToFiles.put(relativePath, statusList);\n       }\n-      return true;\n-    }, true);\n+      statusList.add(val.getLeft());\n+    });\n+\n     OptionalInt maxLevelOpt = levelToPartitions.keySet().stream().mapToInt(x -> x).max();\n     int maxLevel = maxLevelOpt.orElse(-1);\n     return maxLevel >= 0 ? levelToPartitions.get(maxLevel).stream()\n-        .map(d -> Pair.of(d, partitionToFiles.get(d))).collect(Collectors.toList()) : new ArrayList<>();\n+            .map(d -> Pair.of(d, partitionToFiles.get(d))).collect(Collectors.toList()) : new ArrayList<>();\n+  }\n+\n+  private static PathFilter getFilePathFilter() {\n+    return (path) -> {\n+      // TODO: Needs to be abstracted out when supporting different formats\n+      // TODO: Remove hoodieFilter\n+      return path.getName().endsWith(HoodieFileFormat.PARQUET.getFileExtension());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc3NDgxMA==", "bodyText": "Done.", "url": "https://github.com/apache/hudi/pull/1924#discussion_r466774810", "createdAt": "2020-08-07T01:43:36Z", "author": {"login": "umehrot2"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/bootstrap/BootstrapUtils.java", "diffHunk": "@@ -41,37 +48,87 @@\n    * Returns leaf folders with files under a path.\n    * @param fs  File System\n    * @param basePathStr Base Path to look for leaf folders\n-   * @param filePathFilter  Filters to skip directories/paths\n+   * @param jsc Java spark context\n    * @return list of partition paths with files under them.\n    * @throws IOException\n    */\n   public static List<Pair<String, List<HoodieFileStatus>>> getAllLeafFoldersWithFiles(FileSystem fs, String basePathStr,\n-                                                                                      PathFilter filePathFilter) throws IOException {\n+      JavaSparkContext jsc) throws IOException {\n     final Path basePath = new Path(basePathStr);\n     final Map<Integer, List<String>> levelToPartitions = new HashMap<>();\n     final Map<String, List<HoodieFileStatus>> partitionToFiles = new HashMap<>();\n-    FSUtils.processFiles(fs, basePathStr, (status) -> {\n-      if (status.isFile() && filePathFilter.accept(status.getPath())) {\n-        String relativePath = FSUtils.getRelativePartitionPath(basePath, status.getPath().getParent());\n-        List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n-        if (null == statusList) {\n-          Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n-          List<String> dirs = levelToPartitions.get(level);\n-          if (null == dirs) {\n-            dirs = new ArrayList<>();\n-            levelToPartitions.put(level, dirs);\n+    PathFilter filePathFilter = getFilePathFilter();\n+    PathFilter metaPathFilter = getExcludeMetaPathFilter();\n+\n+    FileStatus[] topLevelStatuses = fs.listStatus(new Path(basePathStr));\n+    List<String> subDirectories = new ArrayList<>();\n+\n+    List<Pair<HoodieFileStatus, Pair<Integer, String>>> result = new ArrayList<>();\n+\n+    for (FileStatus topLevelStatus: topLevelStatuses) {\n+      if (topLevelStatus.isFile() && filePathFilter.accept(topLevelStatus.getPath())) {\n+        String relativePath = FSUtils.getRelativePartitionPath(basePath, topLevelStatus.getPath().getParent());\n+        Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n+        HoodieFileStatus hoodieFileStatus = FileStatusUtils.fromFileStatus(topLevelStatus);\n+        result.add(Pair.of(hoodieFileStatus, Pair.of(level, relativePath)));\n+      } else if (metaPathFilter.accept(topLevelStatus.getPath())) {\n+        subDirectories.add(topLevelStatus.getPath().toString());\n+      }\n+    }\n+\n+    if (subDirectories.size() > 0) {\n+      result.addAll(jsc.parallelize(subDirectories, subDirectories.size()).flatMap(directory -> {\n+        PathFilter pathFilter = getFilePathFilter();\n+        Path path = new Path(directory);\n+        FileSystem fileSystem = path.getFileSystem(new Configuration());\n+        RemoteIterator<LocatedFileStatus> itr = fileSystem.listFiles(path, true);\n+        List<Pair<HoodieFileStatus, Pair<Integer, String>>> res = new ArrayList<>();\n+        while (itr.hasNext()) {\n+          FileStatus status = itr.next();\n+          if (pathFilter.accept(status.getPath())) {\n+            String relativePath = FSUtils.getRelativePartitionPath(new Path(basePathStr), status.getPath().getParent());\n+            Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n+            HoodieFileStatus hoodieFileStatus = FileStatusUtils.fromFileStatus(status);\n+            res.add(Pair.of(hoodieFileStatus, Pair.of(level, relativePath)));\n           }\n-          dirs.add(relativePath);\n-          statusList = new ArrayList<>();\n-          partitionToFiles.put(relativePath, statusList);\n         }\n-        statusList.add(FileStatusUtils.fromFileStatus(status));\n+        return res.iterator();\n+      }).collect());\n+    }\n+\n+    result.forEach(val -> {\n+      String relativePath = val.getRight().getRight();\n+      List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n+      if (null == statusList) {\n+        Integer level = val.getRight().getLeft();\n+        List<String> dirs = levelToPartitions.get(level);\n+        if (null == dirs) {\n+          dirs = new ArrayList<>();\n+          levelToPartitions.put(level, dirs);\n+        }\n+        dirs.add(relativePath);\n+        statusList = new ArrayList<>();\n+        partitionToFiles.put(relativePath, statusList);\n       }\n-      return true;\n-    }, true);\n+      statusList.add(val.getLeft());\n+    });\n+\n     OptionalInt maxLevelOpt = levelToPartitions.keySet().stream().mapToInt(x -> x).max();\n     int maxLevel = maxLevelOpt.orElse(-1);\n     return maxLevel >= 0 ? levelToPartitions.get(maxLevel).stream()\n-        .map(d -> Pair.of(d, partitionToFiles.get(d))).collect(Collectors.toList()) : new ArrayList<>();\n+            .map(d -> Pair.of(d, partitionToFiles.get(d))).collect(Collectors.toList()) : new ArrayList<>();\n+  }\n+\n+  private static PathFilter getFilePathFilter() {\n+    return (path) -> {\n+      // TODO: Needs to be abstracted out when supporting different formats\n+      // TODO: Remove hoodieFilter\n+      return path.getName().endsWith(HoodieFileFormat.PARQUET.getFileExtension());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIxNzE2OA=="}, "originalCommit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11"}, "originalPosition": 123}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4405, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}