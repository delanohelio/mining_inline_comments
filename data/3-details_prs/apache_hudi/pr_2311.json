{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM0OTgyNjU1", "number": 2311, "title": "[HUDI-115] Adding DefaultHoodieRecordPayload to honor ordering with combineAndGetUpdateValue", "bodyText": "What is the purpose of the pull request\nExisting OverwriteWithLatestAvroPayload always chooses incoming record when combineAndGetUpdateValue is called, but there are chances a record is late arriving and needs to be ignored. Hence adding DefaultHoodieRecordPayload to honor ordering with combineAndGetUpdateValue.\n\nTo achieve this, have introduced new apis in HoodieRecordPayload interface by adding a new arg for Properties for all apis and deprecating existing apis. Default impl is added so that all existing implementations are compatible w/o any changes.\nIntroduced a new config called \"hoodie.payload.ordering.field\" in HoodieWriteClient which is set to the preCombine field value.\nSo, when a user configures payload class as the new class i.e. DefaultHoodieRecordPayload, then combineAndGetUpdateValue will combine based on preCombine field with existing record in storage.\nAdded HoodiePayloadConfig to hold all payload configs going forward.\n\nFirst attempt: #1704\nBrief change log\n\nAdded new apis to HoodieRecordPayload interface by adding Properties as arg to all apis and deprecating existing apis.\nAdding DefaultHoodieRecordPayload to honor ordering with combineAndGetUpdateValue.\nIntroduced a new config called \"hoodie.payload.ordering.field\" in HoodieWriteClient which is set to the preCombine field value.\nAdded HoodiePayloadConfig to hold all payload configs going forward.\n\nVerify this pull request\nThis change added tests and can be verified as follows:\n\nAdded tests tp TestDataSourceDefaults to verify the change.\nAdded TestDefaultHoodieRecordPayload to verify the new payload class\n\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-12-09T07:50:08Z", "url": "https://github.com/apache/hudi/pull/2311", "merged": true, "mergeCommit": {"oid": "33d338f3923862fdff24443a02d8a33a56d92e63"}, "closed": true, "closedAt": "2020-12-20T03:19:43Z", "author": {"login": "nsivabalan"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdkZ9ZkABqjQwODg1NTI1Mzg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdn4m4XAFqTU1NTk4Mjg0Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ef1169e0b0e3c8a7908cafe20c385581e0e7fe8b", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/ef1169e0b0e3c8a7908cafe20c385581e0e7fe8b", "committedDate": "2020-12-09T07:44:08Z", "message": "Adding OverwriteWithLatestAvroPayloadV1 to honor ordering while merging two records"}, "afterCommit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/d637a728505792fdd5ca184877b12a918aeb3314", "committedDate": "2020-12-09T07:52:58Z", "message": "Adding OverwriteWithLatestAvroPayloadV1 to honor ordering while merging two records"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3OTcyOTc4", "url": "https://github.com/apache/hudi/pull/2311#pullrequestreview-547972978", "createdAt": "2020-12-09T09:08:37Z", "commit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQwOTowODozN1rOICJ60g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQwOToyODoyNFrOICKz2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEzMDU3OA==", "bodyText": "should we use a string to save storage? Looks like this will create a map for every record.", "url": "https://github.com/apache/hudi/pull/2311#discussion_r539130578", "createdAt": "2020-12-09T09:08:37Z", "author": {"login": "garyli1019"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n+ * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n+ */\n+public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload\n+    implements HoodieRecordPayload<OverwriteWithLatestAvroPayloadV1> {\n+\n+  private Map<String, String> props;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEzMzI4NA==", "bodyText": "Is there any reason we need a different config from the pre-combine field? IIUC we wanna make the merging logic consistent, so preCombine and combineAndGetUpdateValue should produce the same result?", "url": "https://github.com/apache/hudi/pull/2311#discussion_r539133284", "createdAt": "2020-12-09T09:12:18Z", "author": {"login": "garyli1019"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -121,6 +121,10 @@\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n+  // payload ordering field\n+  private static final String PAYLOAD_ORDERING_FIELD_PROP = \"hoodie.payload.ordering.field\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEzNTgxNQ==", "bodyText": "naming is hard... how about CombineWithLargestOrderingValPayload?", "url": "https://github.com/apache/hudi/pull/2311#discussion_r539135815", "createdAt": "2020-12-09T09:15:52Z", "author": {"login": "garyli1019"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n+ * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n+ */\n+public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTE0NTE3Ng==", "bodyText": "keep this true is more rational for me. From a new user perspective, I don't really understand the difference between preCombine and combineWithLatestValue. It took me a while to figure this out and originally I thought this is a bug. But we need to think about the impact of the existing user.", "url": "https://github.com/apache/hudi/pull/2311#discussion_r539145176", "createdAt": "2020-12-09T09:28:24Z", "author": {"login": "garyli1019"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/DataSourceOptions.scala", "diffHunk": "@@ -205,6 +205,12 @@ object DataSourceWriteOptions {\n   val PRECOMBINE_FIELD_OPT_KEY = \"hoodie.datasource.write.precombine.field\"\n   val DEFAULT_PRECOMBINE_FIELD_OPT_VAL = \"ts\"\n \n+  /**\n+   * Field when set to true, will honor ordering while merging two records. If not, incoming record will overwrite\n+   * record in storage.\n+   */\n+  val HONOR_ORDERING_WHILE_MERGING_OPT_KEY = \"hoodie.datasource.honor.ordering.while.merging\"\n+  val DEFAULT_HONOR_ORDERING_WHILE_MERGING_OPT_VAL = \"false\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5ODg4Mzkx", "url": "https://github.com/apache/hudi/pull/2311#pullrequestreview-549888391", "createdAt": "2020-12-11T08:26:48Z", "commit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQwODoyNjo0OFrOIDuD7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQwODoyODoxNFrOIDuHag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc3MTMwOQ==", "bodyText": "@nsivabalan  won't this break for an existing payloadClass (user defined), that does have this three member constructor?", "url": "https://github.com/apache/hudi/pull/2311#discussion_r540771309", "createdAt": "2020-12-11T08:26:48Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -142,6 +142,20 @@ public static HoodieRecordPayload createPayload(String payloadClass, GenericReco\n     }\n   }\n \n+  /**\n+   * Create a payload class via reflection, passing in an ordering/precombine value.\n+   */\n+  public static HoodieRecordPayload createPayload(String payloadClass, GenericRecord record, Comparable orderingVal,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc3MTczNg==", "bodyText": "I really don't like having these payload specific configs, top level in datasource options.", "url": "https://github.com/apache/hudi/pull/2311#discussion_r540771736", "createdAt": "2020-12-11T08:27:33Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/DataSourceOptions.scala", "diffHunk": "@@ -205,6 +205,12 @@ object DataSourceWriteOptions {\n   val PRECOMBINE_FIELD_OPT_KEY = \"hoodie.datasource.write.precombine.field\"\n   val DEFAULT_PRECOMBINE_FIELD_OPT_VAL = \"ts\"\n \n+  /**\n+   * Field when set to true, will honor ordering while merging two records. If not, incoming record will overwrite\n+   * record in storage.\n+   */\n+  val HONOR_ORDERING_WHILE_MERGING_OPT_KEY = \"hoodie.datasource.honor.ordering.while.merging\"\n+  val DEFAULT_HONOR_ORDERING_WHILE_MERGING_OPT_VAL = \"false\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTE0NTE3Ng=="}, "originalCommit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc3MjIwMg==", "bodyText": "this is more and more overhead for the user to learn one more parameter when using one specific payload", "url": "https://github.com/apache/hudi/pull/2311#discussion_r540772202", "createdAt": "2020-12-11T08:28:14Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala", "diffHunk": "@@ -154,9 +154,16 @@ private[hudi] object HoodieSparkSqlWriter {\n             val hoodieRecord = if (shouldCombine) {\n               val orderingVal = HoodieAvroUtils.getNestedFieldVal(gr, parameters(PRECOMBINE_FIELD_OPT_KEY), false)\n                 .asInstanceOf[Comparable[_]]\n-              DataSourceUtils.createHoodieRecord(gr,\n-                orderingVal, keyGenerator.getKey(gr),\n-                parameters(PAYLOAD_CLASS_OPT_KEY))\n+              val honorOrderingWhileMerging = parameters(HONOR_ORDERING_WHILE_MERGING_OPT_KEY).toBoolean", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d637a728505792fdd5ca184877b12a918aeb3314"}, "originalPosition": 7}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "46e5f721d0651d4477d342a2cc1448700d9d216f", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/46e5f721d0651d4477d342a2cc1448700d9d216f", "committedDate": "2020-12-12T20:15:42Z", "message": "Fixing default payload based on feedback"}, "afterCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/13e1417ae2653aa649598bf539767f7cefef75e9", "committedDate": "2020-12-12T20:42:54Z", "message": "Fixing default payload based on feedback"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyNjAzMzcz", "url": "https://github.com/apache/hudi/pull/2311#pullrequestreview-552603373", "createdAt": "2020-12-15T15:52:31Z", "commit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "state": "COMMENTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQxNTo1NDowMVrOIGSiKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQxNjoxNTowOFrOIGTmMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ2NjAyNg==", "bodyText": "rename: getPayloadConfig()", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543466026", "createdAt": "2020-12-15T15:54:01Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -729,6 +731,10 @@ public FileSystemViewStorageConfig getClientSpecifiedViewStorageConfig() {\n     return clientSpecifiedViewStorageConfig;\n   }\n \n+  public HoodiePayloadConfig getHoodiePayloadConfig() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ2Njc5Ng==", "bodyText": "nit: extra line", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543466796", "createdAt": "2020-12-15T15:54:56Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/BaseAvroPayload.java", "diffHunk": "@@ -29,6 +29,7 @@\n  * Base class for all AVRO record based payloads, that can be ordered based on a field.\n  */\n public abstract class BaseAvroPayload implements Serializable {\n+  ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ2Nzk2NA==", "bodyText": "more descriptive doc?", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543467964", "createdAt": "2020-12-15T15:56:28Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodiePayloadProps.java", "diffHunk": "@@ -0,0 +1,12 @@\n+package org.apache.hudi.common.model;\n+\n+/**\n+ * Since both payload classes and HoodiePayloadConfig needs to access these props, storing it here.\n+ */\n+public class HoodiePayloadProps {\n+\n+  // payload ordering field", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3MDE2MQ==", "bodyText": "mark all deprecated methods with the right ApiMaturityLevel.DEPRECATED?", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543470161", "createdAt": "2020-12-15T15:58:53Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3MjMxMQ==", "bodyText": "this is not just for delta streamer.", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543472311", "createdAt": "2020-12-15T16:01:24Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+/**\n+ * Default payload used for delta streamer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NDE3MQ==", "bodyText": "is this class pretty much a modified version of OverwriteWithLatestAvroPayload?  if so, can we reuse some code by having that extend from this, and override methods as needed?", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543474171", "createdAt": "2020-12-15T16:03:44Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n+ * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ */\n+public class DefaultHoodieRecordPayload extends BaseAvroPayload", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NTQxMA==", "bodyText": "just do the Comparable cast here itself?", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543475410", "createdAt": "2020-12-15T16:05:12Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n+ * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ */\n+public class DefaultHoodieRecordPayload extends BaseAvroPayload\n+    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n+\n+  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n+    super(record, orderingVal);\n+  }\n+\n+  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n+  }\n+\n+  @Override\n+  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n+    // pick the payload with greatest ordering value\n+    if (another.orderingVal.compareTo(orderingVal) > 0) {\n+      return another;\n+    } else {\n+      return this;\n+    }\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> getInsertValue(Schema schema) throws IOException {\n+    if (recordBytes.length == 0) {\n+      return Option.empty();\n+    }\n+    IndexedRecord indexedRecord = bytesToAvro(recordBytes, schema);\n+    if (isDeleteRecord((GenericRecord) indexedRecord)) {\n+      return Option.empty();\n+    } else {\n+      return Option.of(indexedRecord);\n+    }\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException{\n+    return getInsertValue(schema);\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n+    if (recordBytes.length == 0) {\n+      return Option.empty();\n+    }\n+    GenericRecord incomingRecord = bytesToAvro(recordBytes, schema);\n+    /*\n+     * Combining strategy here returns currentValue on disk if incoming record is older.\n+     * The incoming record can be either a delete (sent as an upsert with _hoodie_is_deleted set to true)\n+     * or an insert/update record. In any case, if it is older than the record in disk, the currentValue\n+     * in disk is returned (to be rewritten with new commit time).\n+     *\n+     * NOTE: Deletes sent via EmptyHoodieRecordPayload and/or Delete operation type do not hit this code path\n+     * and need to be dealt with separately.\n+     */\n+    Object persistedOrderingVal = getNestedFieldVal((GenericRecord) currentValue, properties.getProperty(HoodiePayloadProps.PAYLOAD_ORDERING_FIELD_PROP), true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NzI3Nw==", "bodyText": "nts: the check means persistedOrderingVal > incomingOrderingVal i.e we should retain the value on disk", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543477277", "createdAt": "2020-12-15T16:07:28Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n+ * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ */\n+public class DefaultHoodieRecordPayload extends BaseAvroPayload\n+    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n+\n+  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n+    super(record, orderingVal);\n+  }\n+\n+  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n+  }\n+\n+  @Override\n+  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n+    // pick the payload with greatest ordering value\n+    if (another.orderingVal.compareTo(orderingVal) > 0) {\n+      return another;\n+    } else {\n+      return this;\n+    }\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> getInsertValue(Schema schema) throws IOException {\n+    if (recordBytes.length == 0) {\n+      return Option.empty();\n+    }\n+    IndexedRecord indexedRecord = bytesToAvro(recordBytes, schema);\n+    if (isDeleteRecord((GenericRecord) indexedRecord)) {\n+      return Option.empty();\n+    } else {\n+      return Option.of(indexedRecord);\n+    }\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException{\n+    return getInsertValue(schema);\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n+    if (recordBytes.length == 0) {\n+      return Option.empty();\n+    }\n+    GenericRecord incomingRecord = bytesToAvro(recordBytes, schema);\n+    /*\n+     * Combining strategy here returns currentValue on disk if incoming record is older.\n+     * The incoming record can be either a delete (sent as an upsert with _hoodie_is_deleted set to true)\n+     * or an insert/update record. In any case, if it is older than the record in disk, the currentValue\n+     * in disk is returned (to be rewritten with new commit time).\n+     *\n+     * NOTE: Deletes sent via EmptyHoodieRecordPayload and/or Delete operation type do not hit this code path\n+     * and need to be dealt with separately.\n+     */\n+    Object persistedOrderingVal = getNestedFieldVal((GenericRecord) currentValue, properties.getProperty(HoodiePayloadProps.PAYLOAD_ORDERING_FIELD_PROP), true);\n+    Comparable incomingOrderingVal = (Comparable) getNestedFieldVal(incomingRecord, properties.getProperty(HoodiePayloadProps.PAYLOAD_ORDERING_FIELD_PROP), false);\n+\n+    // Null check is needed here to support schema evolution. The record in storage may be from old schema where\n+    // the new ordering column might not be present and hence returns null.\n+    if (persistedOrderingVal != null && ((Comparable) persistedOrderingVal).compareTo(incomingOrderingVal) > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3ODU4NQ==", "bodyText": "please remove \"if combinng turned on ...\" comment. we should ideally refrain from referring to higher level constructs from lower layers.", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543478585", "createdAt": "2020-12-15T16:09:10Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTE2Mw==", "bodyText": "same here", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543479163", "createdAt": "2020-12-15T16:09:51Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTUwNA==", "bodyText": "place 2 on a newline?", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543479504", "createdAt": "2020-12-15T16:10:19Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTY4Mg==", "bodyText": "close the </p>", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543479682", "createdAt": "2020-12-15T16:10:34Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTUwNA=="}, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4MTU0NA==", "bodyText": "I think we should just refer to the other method here in the javadoc, instead of repeating the entire description here again.", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543481544", "createdAt": "2020-12-15T16:12:52Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTUwNA=="}, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4MzI2Mw==", "bodyText": "this line can be bit pithy?", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543483263", "createdAt": "2020-12-15T16:14:53Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n-   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n-   * insert) Return EMPTY to skip writing this record.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n+   *    * on some properties set.\n+   * <p>\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n+   *\n+   * @param currentValue Current value in storage, to merge/combine this payload with\n+   * @param schema Schema used for record\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n+    return combineAndGetUpdateValue(currentValue, schema);\n+  }\n+\n+  /**\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n+   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n+   * @param schema Schema used for record\n+   * @return the {@link IndexedRecord} to be inserted.\n+   */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n-   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n-   * using the metadata in the context of a write success or failure.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n+   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n+   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4MzQ0MA==", "bodyText": "thanks for fixing this", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543483440", "createdAt": "2020-12-15T16:15:08Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n-   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n-   * insert) Return EMPTY to skip writing this record.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n+   *    * on some properties set.\n+   * <p>\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n+   *\n+   * @param currentValue Current value in storage, to merge/combine this payload with\n+   * @param schema Schema used for record\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n+    return combineAndGetUpdateValue(currentValue, schema);\n+  }\n+\n+  /**\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n+   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n+   * @param schema Schema used for record\n+   * @return the {@link IndexedRecord} to be inserted.\n+   */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n-   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n-   * using the metadata in the context of a write success or failure.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n+   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n+   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.\n+   * @param schema Schema used for record\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the {@link IndexedRecord} to be inserted.\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default Option<IndexedRecord> getInsertValue(Schema schema, Properties properties) throws IOException {\n+    return getInsertValue(schema);\n+  }\n+\n+  /**\n+   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to {@code WriteStatus.markSuccess()} and", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9"}, "originalPosition": 102}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/9238696e84b3aeb54a821fd85cdda37e642c8f21", "committedDate": "2020-12-16T06:28:29Z", "message": "Adding OverwriteWithLatestAvroPayloadV1 to honor ordering while merging two records"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f759074310296e064012dc95dcadb622b7a36ce9", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/f759074310296e064012dc95dcadb622b7a36ce9", "committedDate": "2020-12-16T06:29:24Z", "message": "Fixing default payload based on feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f4f529e1a9e045e417151c78e3333de0cd3c274f", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/f4f529e1a9e045e417151c78e3333de0cd3c274f", "committedDate": "2020-12-16T06:29:42Z", "message": "Addressing feedback"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "931b1415e422b38c8163e9b8d7546b1ab57dd93a", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/931b1415e422b38c8163e9b8d7546b1ab57dd93a", "committedDate": "2020-12-16T06:27:55Z", "message": "Addressing feedback"}, "afterCommit": {"oid": "f4f529e1a9e045e417151c78e3333de0cd3c274f", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/f4f529e1a9e045e417151c78e3333de0cd3c274f", "committedDate": "2020-12-16T06:29:42Z", "message": "Addressing feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9327235f3ebc1b40fb76c7162fac7dd5b9f2726", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/d9327235f3ebc1b40fb76c7162fac7dd5b9f2726", "committedDate": "2020-12-18T02:00:40Z", "message": "Fixing build issues"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0a5eb1c04dd906c2d05b8fac6901dd9a28aa7b80", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/0a5eb1c04dd906c2d05b8fac6901dd9a28aa7b80", "committedDate": "2020-12-18T00:31:10Z", "message": "Fixing build issues"}, "afterCommit": {"oid": "d9327235f3ebc1b40fb76c7162fac7dd5b9f2726", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/d9327235f3ebc1b40fb76c7162fac7dd5b9f2726", "committedDate": "2020-12-18T02:00:40Z", "message": "Fixing build issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1OTgyODQ3", "url": "https://github.com/apache/hudi/pull/2311#pullrequestreview-555982847", "createdAt": "2020-12-20T03:17:26Z", "commit": {"oid": "d9327235f3ebc1b40fb76c7162fac7dd5b9f2726"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4419, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}