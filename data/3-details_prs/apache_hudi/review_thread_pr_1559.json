{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4ODA3NjQ1", "number": 1559, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxOTo1MDoxNVrOD3WtQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQyMDoxMToxMlrOD3XJ-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5MzcwMzA0OnYy", "diffSide": "RIGHT", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxOTo1MDoxNVrOGNkUEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwMToyNzozMlrOGNs1ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg3OTYzMw==", "bodyText": "Rename to just getTableAvroSchema ?", "url": "https://github.com/apache/hudi/pull/1559#discussion_r416879633", "createdAt": "2020-04-28T19:50:15Z", "author": {"login": "bvaradar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -145,23 +146,37 @@ public MessageType getDataSchema() throws Exception {\n    * @return Avro schema for this table\n    * @throws Exception\n    */\n-  public Schema getTableSchema() throws Exception {\n-    return convertParquetSchemaToAvro(getDataSchema());\n+  public Schema getTableSchemaInAvroFormat() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAxOTMyMg==", "bodyText": "Done.", "url": "https://github.com/apache/hudi/pull/1559#discussion_r417019322", "createdAt": "2020-04-29T01:27:32Z", "author": {"login": "umehrot2"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -145,23 +146,37 @@ public MessageType getDataSchema() throws Exception {\n    * @return Avro schema for this table\n    * @throws Exception\n    */\n-  public Schema getTableSchema() throws Exception {\n-    return convertParquetSchemaToAvro(getDataSchema());\n+  public Schema getTableSchemaInAvroFormat() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg3OTYzMw=="}, "originalCommit": null, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5MzcyNzg2OnYy", "diffSide": "RIGHT", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxOTo1NzowOFrOGNkjbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwMToyODowOVrOGNs2QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4MzU2Nw==", "bodyText": "You can introduce a getTableAvroSchemaFromDataFile to return in avro format.", "url": "https://github.com/apache/hudi/pull/1559#discussion_r416883567", "createdAt": "2020-04-28T19:57:08Z", "author": {"login": "bvaradar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -145,23 +146,37 @@ public MessageType getDataSchema() throws Exception {\n    * @return Avro schema for this table\n    * @throws Exception\n    */\n-  public Schema getTableSchema() throws Exception {\n-    return convertParquetSchemaToAvro(getDataSchema());\n+  public Schema getTableSchemaInAvroFormat() throws Exception {\n+    Option<Schema> schemaFromCommitMetadata = getTableSchemaFromCommitMetadata();\n+    return schemaFromCommitMetadata.isPresent() ? schemaFromCommitMetadata.get() :\n+           convertParquetSchemaToAvro(getDataSchema());\n+  }\n+\n+  /**\n+   * Gets the schema for a hoodie table in Parquet format.\n+   *\n+   * @return Parquet schema for the table\n+   * @throws Exception\n+   */\n+  public MessageType getTableSchemaInParquetFormat() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAxOTQ1Nw==", "bodyText": "Added.", "url": "https://github.com/apache/hudi/pull/1559#discussion_r417019457", "createdAt": "2020-04-29T01:28:09Z", "author": {"login": "umehrot2"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -145,23 +146,37 @@ public MessageType getDataSchema() throws Exception {\n    * @return Avro schema for this table\n    * @throws Exception\n    */\n-  public Schema getTableSchema() throws Exception {\n-    return convertParquetSchemaToAvro(getDataSchema());\n+  public Schema getTableSchemaInAvroFormat() throws Exception {\n+    Option<Schema> schemaFromCommitMetadata = getTableSchemaFromCommitMetadata();\n+    return schemaFromCommitMetadata.isPresent() ? schemaFromCommitMetadata.get() :\n+           convertParquetSchemaToAvro(getDataSchema());\n+  }\n+\n+  /**\n+   * Gets the schema for a hoodie table in Parquet format.\n+   *\n+   * @return Parquet schema for the table\n+   * @throws Exception\n+   */\n+  public MessageType getTableSchemaInParquetFormat() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4MzU2Nw=="}, "originalCommit": null, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5MzczMTk2OnYy", "diffSide": "RIGHT", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxOTo1ODoxM1rOGNkl8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QyMzoyOTo0MVrOGSTw3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NDIxMQ==", "bodyText": "Please check ParquetUtils class for similar APIs", "url": "https://github.com/apache/hudi/pull/1559#discussion_r416884211", "createdAt": "2020-04-28T19:58:13Z", "author": {"login": "bvaradar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -178,6 +193,17 @@ public Schema convertParquetSchemaToAvro(MessageType parquetSchema) {\n     return avroSchemaConverter.convert(parquetSchema);\n   }\n \n+  /**\n+   * Convert a avro scheme to the parquet format.\n+   *\n+   * @param schema The avro schema to convert\n+   * @return The converted parquet schema\n+   */\n+  public MessageType convertAvroSchemaToParquet(Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAyMDQ1MA==", "bodyText": "There is nothing really that we can re-use from ParquetUtils for the purpose of this PR. The APIs in ParquetUtils class accept a file path from which to read. However, here it first needs to go through the active timeline and find out the file path and then read the schema. The reading from file functions of this class can internally re-use some of the APIs from ParquetUtils but I don't think we should touch it as part of this PR.", "url": "https://github.com/apache/hudi/pull/1559#discussion_r417020450", "createdAt": "2020-04-29T01:32:11Z", "author": {"login": "umehrot2"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -178,6 +193,17 @@ public Schema convertParquetSchemaToAvro(MessageType parquetSchema) {\n     return avroSchemaConverter.convert(parquetSchema);\n   }\n \n+  /**\n+   * Convert a avro scheme to the parquet format.\n+   *\n+   * @param schema The avro schema to convert\n+   * @return The converted parquet schema\n+   */\n+  public MessageType convertAvroSchemaToParquet(Schema schema) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NDIxMQ=="}, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTg1MTM1Ng==", "bodyText": "the current code change is fine.", "url": "https://github.com/apache/hudi/pull/1559#discussion_r421851356", "createdAt": "2020-05-07T23:29:41Z", "author": {"login": "bvaradar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -178,6 +193,17 @@ public Schema convertParquetSchemaToAvro(MessageType parquetSchema) {\n     return avroSchemaConverter.convert(parquetSchema);\n   }\n \n+  /**\n+   * Convert a avro scheme to the parquet format.\n+   *\n+   * @param schema The avro schema to convert\n+   * @return The converted parquet schema\n+   */\n+  public MessageType convertAvroSchemaToParquet(Schema schema) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NDIxMQ=="}, "originalCommit": null, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5Mzc3NjU2OnYy", "diffSide": "RIGHT", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQyMDoxMToxMlrOGNlBkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwMTozMzowMVrOGNs63A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg5MTI4MQ==", "bodyText": "On a related note :  As we are start to rely on avro schema to be present in commit-metadata, we should store avro-schema as first-level entity in commit metadata instead of storing it in extra-metadata map and handle upgrade-downgrade (Added https://jira.apache.org/jira/browse/HUDI-844)", "url": "https://github.com/apache/hudi/pull/1559#discussion_r416891281", "createdAt": "2020-04-28T20:11:12Z", "author": {"login": "bvaradar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -145,23 +146,37 @@ public MessageType getDataSchema() throws Exception {\n    * @return Avro schema for this table\n    * @throws Exception\n    */\n-  public Schema getTableSchema() throws Exception {\n-    return convertParquetSchemaToAvro(getDataSchema());\n+  public Schema getTableSchemaInAvroFormat() throws Exception {\n+    Option<Schema> schemaFromCommitMetadata = getTableSchemaFromCommitMetadata();\n+    return schemaFromCommitMetadata.isPresent() ? schemaFromCommitMetadata.get() :\n+           convertParquetSchemaToAvro(getDataSchema());\n+  }\n+\n+  /**\n+   * Gets the schema for a hoodie table in Parquet format.\n+   *\n+   * @return Parquet schema for the table\n+   * @throws Exception\n+   */\n+  public MessageType getTableSchemaInParquetFormat() throws Exception {\n+    Option<Schema> schemaFromCommitMetadata = getTableSchemaFromCommitMetadata();\n+    return schemaFromCommitMetadata.isPresent() ? convertAvroSchemaToParquet(schemaFromCommitMetadata.get()) :\n+           getDataSchema();\n   }\n \n   /**\n    * Gets the schema for a hoodie table in Avro format from the HoodieCommitMetadata of the last commit.\n    *\n    * @return Avro schema for this table\n-   * @throws Exception\n    */\n-  public Schema getTableSchemaFromCommitMetadata() throws Exception {\n+  private Option<Schema> getTableSchemaFromCommitMetadata() {\n     try {\n       HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants();\n       byte[] data = timeline.getInstantDetails(timeline.lastInstant().get()).get();\n       HoodieCommitMetadata metadata = HoodieCommitMetadata.fromBytes(data, HoodieCommitMetadata.class);\n       String existingSchemaStr = metadata.getMetadata(HoodieCommitMetadata.SCHEMA_KEY);\n-      return new Schema.Parser().parse(existingSchemaStr);\n+      return StringUtils.isNullOrEmpty(existingSchemaStr) ? Option.empty() :", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAyMDYzNg==", "bodyText": "Agreed. This would be a good addition and make it cleaner.", "url": "https://github.com/apache/hudi/pull/1559#discussion_r417020636", "createdAt": "2020-04-29T01:33:01Z", "author": {"login": "umehrot2"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -145,23 +146,37 @@ public MessageType getDataSchema() throws Exception {\n    * @return Avro schema for this table\n    * @throws Exception\n    */\n-  public Schema getTableSchema() throws Exception {\n-    return convertParquetSchemaToAvro(getDataSchema());\n+  public Schema getTableSchemaInAvroFormat() throws Exception {\n+    Option<Schema> schemaFromCommitMetadata = getTableSchemaFromCommitMetadata();\n+    return schemaFromCommitMetadata.isPresent() ? schemaFromCommitMetadata.get() :\n+           convertParquetSchemaToAvro(getDataSchema());\n+  }\n+\n+  /**\n+   * Gets the schema for a hoodie table in Parquet format.\n+   *\n+   * @return Parquet schema for the table\n+   * @throws Exception\n+   */\n+  public MessageType getTableSchemaInParquetFormat() throws Exception {\n+    Option<Schema> schemaFromCommitMetadata = getTableSchemaFromCommitMetadata();\n+    return schemaFromCommitMetadata.isPresent() ? convertAvroSchemaToParquet(schemaFromCommitMetadata.get()) :\n+           getDataSchema();\n   }\n \n   /**\n    * Gets the schema for a hoodie table in Avro format from the HoodieCommitMetadata of the last commit.\n    *\n    * @return Avro schema for this table\n-   * @throws Exception\n    */\n-  public Schema getTableSchemaFromCommitMetadata() throws Exception {\n+  private Option<Schema> getTableSchemaFromCommitMetadata() {\n     try {\n       HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants();\n       byte[] data = timeline.getInstantDetails(timeline.lastInstant().get()).get();\n       HoodieCommitMetadata metadata = HoodieCommitMetadata.fromBytes(data, HoodieCommitMetadata.class);\n       String existingSchemaStr = metadata.getMetadata(HoodieCommitMetadata.SCHEMA_KEY);\n-      return new Schema.Parser().parse(existingSchemaStr);\n+      return StringUtils.isNullOrEmpty(existingSchemaStr) ? Option.empty() :", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg5MTI4MQ=="}, "originalCommit": null, "originalPosition": 46}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4589, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}