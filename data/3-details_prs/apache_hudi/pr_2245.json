{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE5MTc3MzAz", "number": 2245, "title": "Adding Hudi indexing mechanisms blog", "bodyText": "What is the purpose of the pull request\nAdding Hudi indexing mechanisms blog\nBrief change log\n\nAdding Hudi indexing mechanisms blog\n\nVerify this pull request\nWIP PR. Will have to verify blog rendering once outline is agreed\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-11-11T12:49:19Z", "url": "https://github.com/apache/hudi/pull/2245", "merged": true, "mergeCommit": {"oid": "19b1b058cb8ba4e51cf3c0ab87ce48f185359d91"}, "closed": true, "closedAt": "2020-12-19T09:05:14Z", "author": {"login": "nsivabalan"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdcyT3aABqjM5OTc1Mjg3NDM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdno5sVAH2gAyNTE5MTc3MzAzOmM2MDZlNWU0OTFmYWJlMDhmNmE3M2ZlYWEzOTRmYTJhNDFiYTA3MmM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "89a0ef9d2bfee64f26c82b2c880a2c9a4a949977", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/89a0ef9d2bfee64f26c82b2c880a2c9a4a949977", "committedDate": "2020-11-11T12:46:13Z", "message": "Adding Hudi indexing mechanisms blog"}, "afterCommit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e", "committedDate": "2020-11-15T15:37:58Z", "message": "Adding Hudi indexing mechanisms blog"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwODY1NTc2", "url": "https://github.com/apache/hudi/pull/2245#pullrequestreview-530865576", "createdAt": "2020-11-16T01:23:39Z", "commit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQwMToyMzozOVrOHzlUyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQwMjoxNjozNVrOHzl9Ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzg1MDk1NQ==", "bodyText": "more motivation on why this is important from use-case perspective. for e.g upstream database may be updated in random ways and the downstream hudi table needs to absorb them well.", "url": "https://github.com/apache/hudi/pull/2245#discussion_r523850955", "createdAt": "2020-11-16T01:23:39Z", "author": {"login": "vinothchandar"}, "path": "docs/_posts/2020-11-11-hudi-indexing-mechanisms.mb", "diffHunk": "@@ -0,0 +1,93 @@\n+---\n+title: \"Apache Hudi Indexing mechanisms\"\n+excerpt: \"Detailing different indexing mechanisms in Hudi and when to use each of them\"\n+author: sivabalan\n+category: blog\n+---\n+\n+\n+## 1. Introduction\n+Hoodie employs index to find and update the location of incoming records during write operations. Hoodie index is a very critical piece in Hoodie as it gives record level lookup support to Hudi for efficient write operations. This blog talks about different indices and when to use which one. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzg1MDk5MQ==", "bodyText": "Apache Hudi please. everywhere :)", "url": "https://github.com/apache/hudi/pull/2245#discussion_r523850991", "createdAt": "2020-11-16T01:23:50Z", "author": {"login": "vinothchandar"}, "path": "docs/_posts/2020-11-11-hudi-indexing-mechanisms.mb", "diffHunk": "@@ -0,0 +1,93 @@\n+---\n+title: \"Apache Hudi Indexing mechanisms\"\n+excerpt: \"Detailing different indexing mechanisms in Hudi and when to use each of them\"\n+author: sivabalan\n+category: blog\n+---\n+\n+\n+## 1. Introduction\n+Hoodie employs index to find and update the location of incoming records during write operations. Hoodie index is a very critical piece in Hoodie as it gives record level lookup support to Hudi for efficient write operations. This blog talks about different indices and when to use which one. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzg2MDQwMw==", "bodyText": "this is not worth mentioning. its just s test impl", "url": "https://github.com/apache/hudi/pull/2245#discussion_r523860403", "createdAt": "2020-11-16T02:12:54Z", "author": {"login": "vinothchandar"}, "path": "docs/_posts/2020-11-11-hudi-indexing-mechanisms.mb", "diffHunk": "@@ -0,0 +1,93 @@\n+---\n+title: \"Apache Hudi Indexing mechanisms\"\n+excerpt: \"Detailing different indexing mechanisms in Hudi and when to use each of them\"\n+author: sivabalan\n+category: blog\n+---\n+\n+\n+## 1. Introduction\n+Hoodie employs index to find and update the location of incoming records during write operations. Hoodie index is a very critical piece in Hoodie as it gives record level lookup support to Hudi for efficient write operations. This blog talks about different indices and when to use which one. \n+\n+Hoodie dataset can be of two types in general, partitioned and non-partitioned. So, most index has two implementations one for partitioned dataset and another for non-partitioned called as global index. \n+\n+These are the types of index supported by Hoodie as of now. \n+\n+- InMemory", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzg2MDU0MQ==", "bodyText": "its also pluggable. we should mention that", "url": "https://github.com/apache/hudi/pull/2245#discussion_r523860541", "createdAt": "2020-11-16T02:13:41Z", "author": {"login": "vinothchandar"}, "path": "docs/_posts/2020-11-11-hudi-indexing-mechanisms.mb", "diffHunk": "@@ -0,0 +1,93 @@\n+---\n+title: \"Apache Hudi Indexing mechanisms\"\n+excerpt: \"Detailing different indexing mechanisms in Hudi and when to use each of them\"\n+author: sivabalan\n+category: blog\n+---\n+\n+\n+## 1. Introduction\n+Hoodie employs index to find and update the location of incoming records during write operations. Hoodie index is a very critical piece in Hoodie as it gives record level lookup support to Hudi for efficient write operations. This blog talks about different indices and when to use which one. \n+\n+Hoodie dataset can be of two types in general, partitioned and non-partitioned. So, most index has two implementations one for partitioned dataset and another for non-partitioned called as global index. \n+\n+These are the types of index supported by Hoodie as of now. \n+\n+- InMemory\n+- Bloom\n+- Simple\n+- Hbase ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzg2MTI2Nw==", "bodyText": "this is more like steps.", "url": "https://github.com/apache/hudi/pull/2245#discussion_r523861267", "createdAt": "2020-11-16T02:16:35Z", "author": {"login": "vinothchandar"}, "path": "docs/_posts/2020-11-11-hudi-indexing-mechanisms.mb", "diffHunk": "@@ -0,0 +1,93 @@\n+---\n+title: \"Apache Hudi Indexing mechanisms\"\n+excerpt: \"Detailing different indexing mechanisms in Hudi and when to use each of them\"\n+author: sivabalan\n+category: blog\n+---\n+\n+\n+## 1. Introduction\n+Hoodie employs index to find and update the location of incoming records during write operations. Hoodie index is a very critical piece in Hoodie as it gives record level lookup support to Hudi for efficient write operations. This blog talks about different indices and when to use which one. \n+\n+Hoodie dataset can be of two types in general, partitioned and non-partitioned. So, most index has two implementations one for partitioned dataset and another for non-partitioned called as global index. \n+\n+These are the types of index supported by Hoodie as of now. \n+\n+- InMemory\n+- Bloom\n+- Simple\n+- Hbase \n+\n+You could use \u201choodie.index.type\u201d to choose any of these indices. \n+\n+### 1.1 Motivation\n+Different workloads have different access patterns. Hudi supports different indexing schemes to cater to the needs of different workloads. So depending on one\u2019s use-case, indexing schema can be chosen. \n+\n+For eg: \u2026\u2026. \n+To Be filled\n+\n+Let's take a brief look at each of these indices.\n+\n+## 2. InMemory\n+Stores an in memory hashmap of records to location mapping. Intended to be used for local testing. \n+\n+## 3. Bloom\n+Leverages bloom index stored with data files to find the location for the incoming records. This is the most commonly used Index in Hudi and is the default one. On a high level, this does a range pruning followed by bloom look up. So, if the record keys are laid out such that it follows some type of ordering like timestamps, then this will essentially cut down a lot of files to be looked up as bloom would have filtered out most of the files. But Range pruning is optional depending on your use-case. If your write batch is such that the records have no ordering in them (e.g uuid), but the pattern is such that mostly the recent partitions are updated with a long tail of updates/deletes to the older partitions, then still bloom index will be faster. But better to turn off range pruning as it just incurs the cost of checking w/o much benefit. \n+\n+For instance, consider a list of file slices in a partition\n+\n+F1 : key_t0 to key_t10000\n+F2 : key_t10001 to key_t20000\n+F3 : key_t20001 to key_t30000\n+F4 : key_t30001 to key_t40000\n+F5 : key_t40001 to key_t50000\n+\n+So, when looking up records ranging from key_t25000 to key_t28000, bloom will filter every file slice except F3 with range pruning. \n+\n+Here is a high level pseudocode used for this bloom:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM2MDM1NzQ0", "url": "https://github.com/apache/hudi/pull/2245#pullrequestreview-536035744", "createdAt": "2020-11-22T07:28:00Z", "commit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQwNzoyODowMFrOH30kuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQwNzoyODowMFrOH30kuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODI5NTA5Nw==", "bodyText": "Should we use HoodieIndex instead of SparkHoodieIndex?", "url": "https://github.com/apache/hudi/pull/2245#discussion_r528295097", "createdAt": "2020-11-22T07:28:00Z", "author": {"login": "garyli1019"}, "path": "docs/_posts/2020-11-11-hudi-indexing-mechanisms.mb", "diffHunk": "@@ -0,0 +1,93 @@\n+---\n+title: \"Apache Hudi Indexing mechanisms\"\n+excerpt: \"Detailing different indexing mechanisms in Hudi and when to use each of them\"\n+author: sivabalan\n+category: blog\n+---\n+\n+\n+## 1. Introduction\n+Hoodie employs index to find and update the location of incoming records during write operations. Hoodie index is a very critical piece in Hoodie as it gives record level lookup support to Hudi for efficient write operations. This blog talks about different indices and when to use which one. \n+\n+Hoodie dataset can be of two types in general, partitioned and non-partitioned. So, most index has two implementations one for partitioned dataset and another for non-partitioned called as global index. \n+\n+These are the types of index supported by Hoodie as of now. \n+\n+- InMemory\n+- Bloom\n+- Simple\n+- Hbase \n+\n+You could use \u201choodie.index.type\u201d to choose any of these indices. \n+\n+### 1.1 Motivation\n+Different workloads have different access patterns. Hudi supports different indexing schemes to cater to the needs of different workloads. So depending on one\u2019s use-case, indexing schema can be chosen. \n+\n+For eg: \u2026\u2026. \n+To Be filled\n+\n+Let's take a brief look at each of these indices.\n+\n+## 2. InMemory\n+Stores an in memory hashmap of records to location mapping. Intended to be used for local testing. \n+\n+## 3. Bloom\n+Leverages bloom index stored with data files to find the location for the incoming records. This is the most commonly used Index in Hudi and is the default one. On a high level, this does a range pruning followed by bloom look up. So, if the record keys are laid out such that it follows some type of ordering like timestamps, then this will essentially cut down a lot of files to be looked up as bloom would have filtered out most of the files. But Range pruning is optional depending on your use-case. If your write batch is such that the records have no ordering in them (e.g uuid), but the pattern is such that mostly the recent partitions are updated with a long tail of updates/deletes to the older partitions, then still bloom index will be faster. But better to turn off range pruning as it just incurs the cost of checking w/o much benefit. \n+\n+For instance, consider a list of file slices in a partition\n+\n+F1 : key_t0 to key_t10000\n+F2 : key_t10001 to key_t20000\n+F3 : key_t20001 to key_t30000\n+F4 : key_t30001 to key_t40000\n+F5 : key_t40001 to key_t50000\n+\n+So, when looking up records ranging from key_t25000 to key_t28000, bloom will filter every file slice except F3 with range pruning. \n+\n+Here is a high level pseudocode used for this bloom:\n+\n+- Fetch interested partitions from incoming records\n+- Load all file info (range info) for every partition. So, we have Map of <partition -> List<FileInfo> >\n+- Find all file -> hoodie key pairs to be looked up.\n+// For every <partition, record key> pairs, use index File filter to filter interested files. Index file filter will leverage file range info and trim down the files to be looked up. Hoodie has a tree map like structure for efficient index file filtering. \n+- Sort <file, hoodie key> pairs. \n+- Load each file and look up mapped keys to find the exact location for the record keys. \n+- Tag back location to incoming records. // this step is required for those newly inserted records in the incoming batch. \n+\n+As you could see, first range pruning is done to cut down on files to be looked up. Following which actual bloom look up is done. By default this is the index type chosen. \n+\n+## 4. Simple Index\n+For a decent sized dataset, Simple index comes in handy. In the bloom index discussed above, hoodie reads the file twice. Once to load the file range info and again to load the bloom filter. So, this simple index simplifies if the data is within reasonable size. \n+\n+- From incoming records, find Pair<record key, partition path>\n+- Load interested fields (record keys, partition path and location) from all files and to find Pair<record key, partition path, location> for all entries in storage. \n+- Join above two outputs to find the location for all incoming records. \n+\n+Since we load only interested fields from files and join directly w/ incoming records, this works pretty well for small scale data even when compared to bloom index. But at larger scale, this may deteriorate since all files are touched w/o any upfront trimming. \n+\n+## 5. HBase\n+Both bloom and simple index are implicit index. In other words, there is no explicit or external index files created/stored. But Hbase is an external index where record locations are stored and retrieved. This is straightforward as fetch location will do a get on hbase table and update location will update the records in hbase. \n+\n+// talk about hbase configs? \n+\n+## 6. UserDefinedIndex\n+Hoodie also support user defined index. All you need to do is to implement \u201corg.apache.hudi.index.SparkHoodieIndex\u201d. You can use this config to set the user defined class name. If this value is set, this will take precedence over \u201choodie.index.type\u201d.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM2MDM1ODUz", "url": "https://github.com/apache/hudi/pull/2245#pullrequestreview-536035853", "createdAt": "2020-11-22T07:29:54Z", "commit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQwNzoyOTo1NFrOH30lZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQwNzoyOTo1NFrOH30lZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODI5NTI3MQ==", "bodyText": "IMO we could add the Flink State index as well", "url": "https://github.com/apache/hudi/pull/2245#discussion_r528295271", "createdAt": "2020-11-22T07:29:54Z", "author": {"login": "garyli1019"}, "path": "docs/_posts/2020-11-11-hudi-indexing-mechanisms.mb", "diffHunk": "@@ -0,0 +1,93 @@\n+---\n+title: \"Apache Hudi Indexing mechanisms\"\n+excerpt: \"Detailing different indexing mechanisms in Hudi and when to use each of them\"\n+author: sivabalan\n+category: blog\n+---\n+\n+\n+## 1. Introduction\n+Hoodie employs index to find and update the location of incoming records during write operations. Hoodie index is a very critical piece in Hoodie as it gives record level lookup support to Hudi for efficient write operations. This blog talks about different indices and when to use which one. \n+\n+Hoodie dataset can be of two types in general, partitioned and non-partitioned. So, most index has two implementations one for partitioned dataset and another for non-partitioned called as global index. \n+\n+These are the types of index supported by Hoodie as of now. \n+\n+- InMemory\n+- Bloom\n+- Simple\n+- Hbase \n+\n+You could use \u201choodie.index.type\u201d to choose any of these indices. \n+\n+### 1.1 Motivation\n+Different workloads have different access patterns. Hudi supports different indexing schemes to cater to the needs of different workloads. So depending on one\u2019s use-case, indexing schema can be chosen. \n+\n+For eg: \u2026\u2026. \n+To Be filled\n+\n+Let's take a brief look at each of these indices.\n+\n+## 2. InMemory\n+Stores an in memory hashmap of records to location mapping. Intended to be used for local testing. \n+\n+## 3. Bloom\n+Leverages bloom index stored with data files to find the location for the incoming records. This is the most commonly used Index in Hudi and is the default one. On a high level, this does a range pruning followed by bloom look up. So, if the record keys are laid out such that it follows some type of ordering like timestamps, then this will essentially cut down a lot of files to be looked up as bloom would have filtered out most of the files. But Range pruning is optional depending on your use-case. If your write batch is such that the records have no ordering in them (e.g uuid), but the pattern is such that mostly the recent partitions are updated with a long tail of updates/deletes to the older partitions, then still bloom index will be faster. But better to turn off range pruning as it just incurs the cost of checking w/o much benefit. \n+\n+For instance, consider a list of file slices in a partition\n+\n+F1 : key_t0 to key_t10000\n+F2 : key_t10001 to key_t20000\n+F3 : key_t20001 to key_t30000\n+F4 : key_t30001 to key_t40000\n+F5 : key_t40001 to key_t50000\n+\n+So, when looking up records ranging from key_t25000 to key_t28000, bloom will filter every file slice except F3 with range pruning. \n+\n+Here is a high level pseudocode used for this bloom:\n+\n+- Fetch interested partitions from incoming records\n+- Load all file info (range info) for every partition. So, we have Map of <partition -> List<FileInfo> >\n+- Find all file -> hoodie key pairs to be looked up.\n+// For every <partition, record key> pairs, use index File filter to filter interested files. Index file filter will leverage file range info and trim down the files to be looked up. Hoodie has a tree map like structure for efficient index file filtering. \n+- Sort <file, hoodie key> pairs. \n+- Load each file and look up mapped keys to find the exact location for the record keys. \n+- Tag back location to incoming records. // this step is required for those newly inserted records in the incoming batch. \n+\n+As you could see, first range pruning is done to cut down on files to be looked up. Following which actual bloom look up is done. By default this is the index type chosen. \n+\n+## 4. Simple Index\n+For a decent sized dataset, Simple index comes in handy. In the bloom index discussed above, hoodie reads the file twice. Once to load the file range info and again to load the bloom filter. So, this simple index simplifies if the data is within reasonable size. \n+\n+- From incoming records, find Pair<record key, partition path>\n+- Load interested fields (record keys, partition path and location) from all files and to find Pair<record key, partition path, location> for all entries in storage. \n+- Join above two outputs to find the location for all incoming records. \n+\n+Since we load only interested fields from files and join directly w/ incoming records, this works pretty well for small scale data even when compared to bloom index. But at larger scale, this may deteriorate since all files are touched w/o any upfront trimming. \n+\n+## 5. HBase\n+Both bloom and simple index are implicit index. In other words, there is no explicit or external index files created/stored. But Hbase is an external index where record locations are stored and retrieved. This is straightforward as fetch location will do a get on hbase table and update location will update the records in hbase. \n+\n+// talk about hbase configs? \n+\n+## 6. UserDefinedIndex\n+Hoodie also support user defined index. All you need to do is to implement \u201corg.apache.hudi.index.SparkHoodieIndex\u201d. You can use this config to set the user defined class name. If this value is set, this will take precedence over \u201choodie.index.type\u201d.\n+\n+## 7. Global versions \n+// Talk about Global versions ? \n+\n+// Talk about Simple vs Dynamic Bloom Filter ?? \n+\n+## 8. Bloom index\n+As far as actual bloom filter is concerned (which is stored along with data file), Hoodie has two types, namely Simple and Dynamic. This can be configured using \u201choodie.bloom.index.filter.type\u201d config. \n+\n+### 8.1. Simple\n+Simple bloom filter is just the regular bloom filter as you might have seen elsewhere. Based on the input values set for num of entries and false positive probability, bloom allocates the bit size and proceeds accordingly. Configs of interest are \u201choodie.index.bloom.num_entries\u201d and \u201choodie.index.bloom.fpp\u201d. You can check the formula used to determine the size and hash functions here. This bloom is static in the sense that the configured fpp will be honored if the entries added to bloom do not surpass the num entries set. But if you keep adding more entries than what was configured, then fpp may not be honored since more entries fill up more buckets. \n+\n+### 8.2. Dynamic\n+Compared to simple, dynamic bloom as the name suggests is dynamic in nature. It grows relatively as the number of entries increases. Basically users are expected to set two configs, namely \u201choodie.index.bloom.num_entries\u201d and \u201choodie.bloom.index.filter.dynamic.max.entries\u201d apart from the fpp. Initially bloom is allocated only for \u201choodie.index.bloom.num_entries\u201d, but as the number of entries reaches this value, the bloom grows to increase to 2x. This proceeds until \u201choodie.bloom.index.filter.dynamic.max.entries\u201d is reached. So until the max value is reached fpp is guaranteed in this bloom type. Beyond that, fpp is not guaranteed similar to Simple bloom. In general this will be beneficial compared to Simple as it may not allocate a larger sized bloom unless or otherwise required. Especially if you don\u2019t have control over your incoming traffic it may be an unnecessary overhead to allocate a larger sized bloom upfront and never get to add so many entries as configured. Because, reading a larger sized bloom will have some impact on your index look up performance. \n+\n+ ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e"}, "originalPosition": 90}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a23d4a3350fd1699feb449e8463dfac0388b5d1", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/7a23d4a3350fd1699feb449e8463dfac0388b5d1", "committedDate": "2020-12-08T20:49:39Z", "message": "Adding Hudi indexing mechanisms blog"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/ad300cdd295ff19c2ef9a3a5299d07c0c43a5c9e", "committedDate": "2020-11-15T15:37:58Z", "message": "Adding Hudi indexing mechanisms blog"}, "afterCommit": {"oid": "7a23d4a3350fd1699feb449e8463dfac0388b5d1", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/7a23d4a3350fd1699feb449e8463dfac0388b5d1", "committedDate": "2020-12-08T20:49:39Z", "message": "Adding Hudi indexing mechanisms blog"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df7aa273e5cec612f6cecfda5d5e30dd1174cc13", "author": {"user": {"login": "nsivabalan", "name": "Sivabalan Narayanan"}}, "url": "https://github.com/apache/hudi/commit/df7aa273e5cec612f6cecfda5d5e30dd1174cc13", "committedDate": "2020-12-15T22:36:44Z", "message": "Adding images and fixing narrative"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzMDE0ODg1", "url": "https://github.com/apache/hudi/pull/2245#pullrequestreview-553014885", "createdAt": "2020-12-15T22:40:18Z", "commit": {"oid": "df7aa273e5cec612f6cecfda5d5e30dd1174cc13"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQyMjo0MDoxOFrOIGjOaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQyMjo0MTowNlrOIGjP2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzczOTQ5Ng==", "bodyText": "Even though the blog talks about only 3 of these, just to be comprehensive, have included InMemory also here.", "url": "https://github.com/apache/hudi/pull/2245#discussion_r543739496", "createdAt": "2020-12-15T22:40:18Z", "author": {"login": "nsivabalan"}, "path": "docs/_posts/2020-11-11-hudi-indexing-mechanisms.md", "diffHunk": "@@ -0,0 +1,80 @@\n+---\n+title: \"Apache Hudi Indexing mechanisms\"\n+excerpt: \"Detailing different indexing mechanisms in Hudi and when to use each of them\"\n+author: sivabalan\n+category: blog\n+---\n+\n+\n+## Introduction\n+Hudi employs index to find and update the location of incoming records during write operations. To be specific, index assist in differentiating \n+inserts vs updates. This blog talks about different indices and when to each of them.\n+\n+Hudi dataset can be of two types in general, partitioned and non-partitioned. So, most index has two implementations, one for partitioned dataset \n+and another for non-partitioned called as global index.\n+\n+These are the types of index supported by Hudi as of now.\n+\n+- InMemory", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df7aa273e5cec612f6cecfda5d5e30dd1174cc13"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzczOTg2NA==", "bodyText": "for now, have added links to RFCs. if you prefer to link jiras, can you assist me w/ right links(for all). I was trying to look for secondary index and couldn't find a jira and hence resorted to use RFC links.", "url": "https://github.com/apache/hudi/pull/2245#discussion_r543739864", "createdAt": "2020-12-15T22:41:06Z", "author": {"login": "nsivabalan"}, "path": "docs/_posts/2020-11-11-hudi-indexing-mechanisms.md", "diffHunk": "@@ -0,0 +1,80 @@\n+---\n+title: \"Apache Hudi Indexing mechanisms\"\n+excerpt: \"Detailing different indexing mechanisms in Hudi and when to use each of them\"\n+author: sivabalan\n+category: blog\n+---\n+\n+\n+## Introduction\n+Hudi employs index to find and update the location of incoming records during write operations. To be specific, index assist in differentiating \n+inserts vs updates. This blog talks about different indices and when to each of them.\n+\n+Hudi dataset can be of two types in general, partitioned and non-partitioned. So, most index has two implementations, one for partitioned dataset \n+and another for non-partitioned called as global index.\n+\n+These are the types of index supported by Hudi as of now.\n+\n+- InMemory\n+- Bloom\n+- Simple\n+- Hbase\n+\n+You could use \u201choodie.index.type\u201d to choose any of these indices.\n+\n+## Different workloads\n+Since data comes in at different volumes, velocity and has different access patterns, different indices could be used for different workloads. \n+Let\u2019s walk through some of the typical workloads and see how to leverage Hudi index for such use-cases.\n+\n+### Fact table\n+These are typical primary table in a dimensional model. It contains measures or quantitative figures and is used for analysis and decision making. \n+For eg, trip tables in case of ride-sharing, user buying and selling of shares, or any other similar use-case can be categorized as fact tables. \n+These tables are usually ever growing with random updates on most recent data with long tail of older data. In other words, most updates go into \n+the latest partitions with few updates going to older ones.\n+\n+![Fact table](/assets/images/blog/hudi-indexes/Hudi_Index_Blog_Fact_table.png)\n+Figure showing the spread of updates for Fact table.\n+\n+Hudi \"BLOOM\" index is the way to go for these kinds of tables, since index look-up will prune a lot of data files. So, effectively actual look up will \n+happen only in a very few data files where the records are most likely present. This bloom index will also benefit a lot for use-cases where record \n+keys have some kind of ordering (timestamp) among them. File pruning will cut down a lot of data files to be looked up resulting in very fast look-up times.\n+On a high level, bloom index does pruning based on ranges of data files, followed by bloom filter look up. Depending on the workload, this could \n+result in a lot of shuffling depending on the amount of data touched. Hudi is planning to support [record level indexing](https://cwiki.apache.org/confluence/display/HUDI/RFC+-+08+%3A+Record+level+indexing+mechanisms+for+Hudi+datasets?src=contextnavpagetreemode) ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df7aa273e5cec612f6cecfda5d5e30dd1174cc13"}, "originalPosition": 42}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d48ef22d638f8e6f18e3c38a4eb087ec177ca6b", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/6d48ef22d638f8e6f18e3c38a4eb087ec177ca6b", "committedDate": "2020-12-19T08:57:41Z", "message": "[BLOG] Employing the right indexes for fast updates, deletes - blog rewrite"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c606e5e491fabe08f6a73feaa394fa2a41ba072c", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/c606e5e491fabe08f6a73feaa394fa2a41ba072c", "committedDate": "2020-12-19T08:59:30Z", "message": "Fix rendering issue"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4293, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}