{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA4MDQ2MTg1", "number": 2197, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzozODowOFrOExvXig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzo0ODowNFrOExvcmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNTkxNzU0OnYy", "diffSide": "RIGHT", "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/configuration/DFSDeltaConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzozODowOFrOHn_-wA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxOTo1MTo1N1rOHpOUBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNDc2OA==", "bodyText": "can you explicitly add scope \"private\" ?", "url": "https://github.com/apache/hudi/pull/2197#discussion_r511704768", "createdAt": "2020-10-26T03:38:08Z", "author": {"login": "n3nash"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/configuration/DFSDeltaConfig.java", "diffHunk": "@@ -36,15 +36,22 @@\n   private final Long maxFileSize;\n   // The current batch id\n   private Integer batchId;\n+  // Paralleism to use when generating input data\n+  int inputParallelism;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjk4ODE2Ng==", "bodyText": "Done.", "url": "https://github.com/apache/hudi/pull/2197#discussion_r512988166", "createdAt": "2020-10-27T19:51:57Z", "author": {"login": "prashantwason"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/configuration/DFSDeltaConfig.java", "diffHunk": "@@ -36,15 +36,22 @@\n   private final Long maxFileSize;\n   // The current batch id\n   private Integer batchId;\n+  // Paralleism to use when generating input data\n+  int inputParallelism;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNDc2OA=="}, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNTkxODEyOnYy", "diffSide": "RIGHT", "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/configuration/DFSDeltaConfig.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzozODozMFrOHn__Bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzozODozMFrOHn__Bw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNDgzOQ==", "bodyText": "rename to inputGeneratorParallelism ?", "url": "https://github.com/apache/hudi/pull/2197#discussion_r511704839", "createdAt": "2020-10-26T03:38:30Z", "author": {"login": "n3nash"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/configuration/DFSDeltaConfig.java", "diffHunk": "@@ -36,15 +36,22 @@\n   private final Long maxFileSize;\n   // The current batch id\n   private Integer batchId;\n+  // Paralleism to use when generating input data\n+  int inputParallelism;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNTkyOTEyOnYy", "diffSide": "RIGHT", "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzo0Njo0NlrOHoAE2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxOTo1MzozNFrOHpOZVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNjMzMQ==", "bodyText": "What is the purpose behind this change ?", "url": "https://github.com/apache/hudi/pull/2197#discussion_r511706331", "createdAt": "2020-10-26T03:46:46Z", "author": {"login": "n3nash"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "diffHunk": "@@ -58,15 +63,15 @@\n \n   private static Logger log = LoggerFactory.getLogger(DeltaGenerator.class);\n \n-  private DeltaConfig deltaOutputConfig;\n+  private DFSDeltaConfig deltaOutputConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjk4OTUyNw==", "bodyText": "DFSDeltaConfig extends DeltaConfig\nThe two settings I have added (getInputParallelism and shouldDeleteOldInputData) are in DFSDeltaConfig.", "url": "https://github.com/apache/hudi/pull/2197#discussion_r512989527", "createdAt": "2020-10-27T19:53:34Z", "author": {"login": "prashantwason"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "diffHunk": "@@ -58,15 +63,15 @@\n \n   private static Logger log = LoggerFactory.getLogger(DeltaGenerator.class);\n \n-  private DeltaConfig deltaOutputConfig;\n+  private DFSDeltaConfig deltaOutputConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNjMzMQ=="}, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNTkyOTc5OnYy", "diffSide": "RIGHT", "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzo0NzoyNFrOHoAFOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxOTo1NzowM1rOHpOhOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNjQyNw==", "bodyText": "This may not work in case the last batches were rolled back. Can you take a look at RollbackNode and see what will be the implication ?", "url": "https://github.com/apache/hudi/pull/2197#discussion_r511706427", "createdAt": "2020-10-26T03:47:24Z", "author": {"login": "n3nash"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "diffHunk": "@@ -77,6 +82,16 @@ public DeltaGenerator(DeltaConfig deltaOutputConfig, JavaSparkContext jsc, Spark\n   }\n \n   public JavaRDD<DeltaWriteStats> writeRecords(JavaRDD<GenericRecord> records) {\n+    if (deltaOutputConfig.shouldDeleteOldInputData() && batchId > 1) {\n+      Path oldInputDir = new Path(deltaOutputConfig.getDeltaBasePath(), Integer.toString(batchId - 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjk5MTU0Nw==", "bodyText": "RollbackNode will rollback the last commit. This should not interfere will these input directories.\nThe shouldDeleteOldInputData() setting only affects the data generated in the \"input\" directory (a separate directory) which is not part of the HUDI dataset under test. For each Node in the yaml, a sub-directory in the input directory (identified by batchId) is created. Within this new sub-directory, the data to be ingested as part of the Node is written as avro files.\nWe are deleting older input sub-directories. The default is to not delete anything.", "url": "https://github.com/apache/hudi/pull/2197#discussion_r512991547", "createdAt": "2020-10-27T19:57:03Z", "author": {"login": "prashantwason"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "diffHunk": "@@ -77,6 +82,16 @@ public DeltaGenerator(DeltaConfig deltaOutputConfig, JavaSparkContext jsc, Spark\n   }\n \n   public JavaRDD<DeltaWriteStats> writeRecords(JavaRDD<GenericRecord> records) {\n+    if (deltaOutputConfig.shouldDeleteOldInputData() && batchId > 1) {\n+      Path oldInputDir = new Path(deltaOutputConfig.getDeltaBasePath(), Integer.toString(batchId - 1));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNjQyNw=="}, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNTkzMDUwOnYy", "diffSide": "RIGHT", "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzo0ODowNFrOHoAFqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxOTowNzo0OVrOHp5c7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNjUzNg==", "bodyText": "Can you please explain the startPartition with an example ? What happens when a spark stage is retried ? Take a look at how spark stage retries mess up the partition numbers to understand more..", "url": "https://github.com/apache/hudi/pull/2197#discussion_r511706536", "createdAt": "2020-10-26T03:48:04Z", "author": {"login": "n3nash"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "diffHunk": "@@ -95,11 +110,19 @@ public DeltaGenerator(DeltaConfig deltaOutputConfig, JavaSparkContext jsc, Spark\n     int numPartitions = operation.getNumInsertPartitions();\n     long recordsPerPartition = operation.getNumRecordsInsert() / numPartitions;\n     int minPayloadSize = operation.getRecordSize();\n-    JavaRDD<GenericRecord> inputBatch = jsc.parallelize(Collections.EMPTY_LIST)\n-        .repartition(numPartitions).mapPartitions(p -> {\n+    int startPartition = operation.getStartPartition();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzA1OTg0Mw==", "bodyText": "Suppose you insert 5 partitions. Then the following 5 new LazyRecordGeneratorIterator will be created:\nnew LazyRecordGeneratorIterator(..., 0)\nnew LazyRecordGeneratorIterator(..., 1)\nnew LazyRecordGeneratorIterator(..., 2)\nnew LazyRecordGeneratorIterator(..., 3)\nnew LazyRecordGeneratorIterator(..., 4)\nWithin the LazyRecordGeneratorIterator code, the integer for partition index (0, 1, .. above) are converted into partition timstamp (as date offset from 1970/01/01). So the first LazyRecordGeneratorIterator will be generating records from 1970/01/01, the second LazyRecordGeneratorIterator will generate records for 1970/01/02 ... and so on.\nWith this schema, the record generation always starts at offset 0. But what if you want to generate for only a specific partition? Or add new partition? This is where the start_offset comes into play.\nnew LazyRecordGeneratorIterator(..., 0 + start_offset)\nnew LazyRecordGeneratorIterator(..., 1 + start_offset)\nnew LazyRecordGeneratorIterator(..., 2 + start_offset)\nnew LazyRecordGeneratorIterator(..., 3 + start_offset)\nnew LazyRecordGeneratorIterator(..., 4 + start_offset)\nBy using a start_offset you can alter where the inserts will take place. Also new partitions can be created.\nSpark retries can alter the partition numbers here. For that, we can use a pre-formatted List with partitions here.", "url": "https://github.com/apache/hudi/pull/2197#discussion_r513059843", "createdAt": "2020-10-27T22:02:39Z", "author": {"login": "prashantwason"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "diffHunk": "@@ -95,11 +110,19 @@ public DeltaGenerator(DeltaConfig deltaOutputConfig, JavaSparkContext jsc, Spark\n     int numPartitions = operation.getNumInsertPartitions();\n     long recordsPerPartition = operation.getNumRecordsInsert() / numPartitions;\n     int minPayloadSize = operation.getRecordSize();\n-    JavaRDD<GenericRecord> inputBatch = jsc.parallelize(Collections.EMPTY_LIST)\n-        .repartition(numPartitions).mapPartitions(p -> {\n+    int startPartition = operation.getStartPartition();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNjUzNg=="}, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzUzNTE5MA==", "bodyText": "Okay, that makes sense @prashantwason. Spark retries are pretty common, lets handle that use-case", "url": "https://github.com/apache/hudi/pull/2197#discussion_r513535190", "createdAt": "2020-10-28T15:24:16Z", "author": {"login": "n3nash"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "diffHunk": "@@ -95,11 +110,19 @@ public DeltaGenerator(DeltaConfig deltaOutputConfig, JavaSparkContext jsc, Spark\n     int numPartitions = operation.getNumInsertPartitions();\n     long recordsPerPartition = operation.getNumRecordsInsert() / numPartitions;\n     int minPayloadSize = operation.getRecordSize();\n-    JavaRDD<GenericRecord> inputBatch = jsc.parallelize(Collections.EMPTY_LIST)\n-        .repartition(numPartitions).mapPartitions(p -> {\n+    int startPartition = operation.getStartPartition();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNjUzNg=="}, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5NDk1OQ==", "bodyText": "Already done. Please see the update.", "url": "https://github.com/apache/hudi/pull/2197#discussion_r513694959", "createdAt": "2020-10-28T19:07:49Z", "author": {"login": "prashantwason"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/DeltaGenerator.java", "diffHunk": "@@ -95,11 +110,19 @@ public DeltaGenerator(DeltaConfig deltaOutputConfig, JavaSparkContext jsc, Spark\n     int numPartitions = operation.getNumInsertPartitions();\n     long recordsPerPartition = operation.getNumRecordsInsert() / numPartitions;\n     int minPayloadSize = operation.getRecordSize();\n-    JavaRDD<GenericRecord> inputBatch = jsc.parallelize(Collections.EMPTY_LIST)\n-        .repartition(numPartitions).mapPartitions(p -> {\n+    int startPartition = operation.getStartPartition();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNjUzNg=="}, "originalCommit": {"oid": "27149aad495ec3b0667e48c01e9be0e7afd3ad1c"}, "originalPosition": 65}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4121, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}