{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg4NTIyOTAy", "number": 1406, "title": "[HUDI-713] Fix conversion of Spark array of struct type to Avro schema", "bodyText": "Tips\n\nThank you very much for contributing to Apache Hudi.\nPlease review https://hudi.apache.org/contributing.html before opening a pull request.\n\nWhat is the purpose of the pull request\nWith migration of Hudi to spark 2.4.4 and to using native spark-avro, there is an issue with conversion of array of struct fields because of the way spark-avro handles avro schema conversion vs databricks-avro. This issue is similar to #1223.\nCurrent struct namespace uses the way how databricks/spark-avro does, the namespace for elements of an array will contain the array name. But for spark/spark-avro, each field in a struct has the same child namespace. So the namespace for elements of an array won't contain the name of array but will contain the struct name.\nFor example, the expected avro schema is:\n{\n  \"type\" : \"record\",\n  \"name\" : \"AWS_TEST_record\",\n  \"namespace\" : \"hoodie.AWS_TEST\",\n  \"fields\" : [ {\n    \"name\" : \"offset\",\n    \"type\" : [ \"long\", \"null\" ]\n  }, {\n    \"name\" : \"partition\",\n    \"type\" : [ \"long\", \"null\" ]\n  }, {\n    \"name\" : \"value\",\n    \"type\" : [ {\n      \"type\" : \"record\",\n      \"name\" : \"value\",\n      \"namespace\" : \"hoodie.AWS_TEST.AWS_TEST_record\",\n      \"fields\" : [ {\n        \"name\" : \"prop1\",\n        \"type\" : [ \"string\", \"null\" ]\n      }, {\n        \"name\" : \"prop2\",\n        \"type\" : [ {\n          \"type\" : \"array\",\n          \"items\" : [ {\n            \"type\" : \"record\",\n            \"name\" : \"prop2\",\n            \"namespace\" : \"hoodie.AWS_TEST.AWS_TEST_record.value\",\n            \"fields\" : [ {\n              \"name\" : \"withinProp1\",\n              \"type\" : [ \"string\", \"null\" ]\n            }, {\n              \"name\" : \"withinProp2\",\n              \"type\" : [ \"long\", \"null\" ]\n            } ]\n          }, \"null\" ]\n        }, \"null\" ]\n      } ]\n    }, \"null\" ]\n  }, {\n    \"name\" : \"op_ts\",\n    \"type\" : [ \"string\", \"null\" ]\n  }, {\n    \"name\" : \"year_partition\",\n    \"type\" : [ \"int\", \"null\" ]\n  }, {\n    \"name\" : \"id\",\n    \"type\" : [ \"string\", \"null\" ]\n  } ]\n}\n\nThe element of array has this namespace hoodie.AWS_TEST.AWS_TEST_record.value, but in current Hudi code, Hudi would create a element with this namespace hoodie.AWS_TEST.AWS_TEST_record.prop2 which would cause the not in union error.\nBrief change log\n\nFix conversion of Spark array of struct type to Avro schema\nModify the schema of data used in unit tests to have array of struct type data as well, so that any issue with array of struct type can be caught earlier\n\nVerify this pull request\n(Please pick either of the following options)\nThis pull request is a trivial rework / code cleanup without any test coverage.\n(or)\nThis pull request is already covered by existing tests, such as (please describe tests).\n(or)\nThis change added tests and can be verified as follows:\n(example:)\n\nAdded integration tests for end-to-end.\nAdded HoodieClientWriteTest to verify the change.\nManually verified the change by running a job locally.\n\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-03-15T01:59:52Z", "url": "https://github.com/apache/hudi/pull/1406", "merged": true, "mergeCommit": {"oid": "ce0a4c64d07d6eea926d1bfb92b69ae387b88f50"}, "closed": true, "closedAt": "2020-03-30T22:52:15Z", "author": {"login": "zhedoubushishi"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcORq0vgBqjMxMzQyNzcxMDM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcS2lDiAFqTM4NDI4MzQ5Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "dec5a88fbc287d95fc2277167ad9f44b53a00060", "author": {"user": null}, "url": "https://github.com/apache/hudi/commit/dec5a88fbc287d95fc2277167ad9f44b53a00060", "committedDate": "2020-03-16T17:35:40Z", "message": "[HUDI-713] Fix conversion of Spark array of struct type to Avro schema"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc2NTIwODA4", "url": "https://github.com/apache/hudi/pull/1406#pullrequestreview-376520808", "createdAt": "2020-03-18T02:14:04Z", "commit": {"oid": "dec5a88fbc287d95fc2277167ad9f44b53a00060"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQwMjoxNDowNFrOF30HRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQwMjoxNDozMVrOF30HqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA2OTgyOA==", "bodyText": "From what I understand, and if you look at the schema generated by Hudi as well..shouldn't the record name tip also be tip_history instead ?", "url": "https://github.com/apache/hudi/pull/1406#discussion_r394069828", "createdAt": "2020-03-18T02:14:04Z", "author": {"login": "umehrot2"}, "path": "hudi-client/src/test/java/org/apache/hudi/common/HoodieTestDataGenerator.java", "diffHunk": "@@ -81,10 +82,12 @@\n       + \"{\\\"name\\\": \\\"end_lat\\\", \\\"type\\\": \\\"double\\\"},\" + \"{\\\"name\\\": \\\"end_lon\\\", \\\"type\\\": \\\"double\\\"},\"\n       + \"{\\\"name\\\": \\\"fare\\\",\\\"type\\\": {\\\"type\\\":\\\"record\\\", \\\"name\\\":\\\"fare\\\",\\\"fields\\\": [\"\n       + \"{\\\"name\\\": \\\"amount\\\",\\\"type\\\": \\\"double\\\"},{\\\"name\\\": \\\"currency\\\", \\\"type\\\": \\\"string\\\"}]}},\"\n+      + \"{\\\"name\\\": \\\"tip_history\\\", \\\"type\\\": {\\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"record\\\", \\\"name\\\": \\\"tip\\\", \\\"fields\\\": [\"\n+      + \"{\\\"name\\\": \\\"amount\\\", \\\"type\\\": \\\"double\\\"}, {\\\"name\\\": \\\"currency\\\", \\\"type\\\": \\\"string\\\"}]}}},\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dec5a88fbc287d95fc2277167ad9f44b53a00060"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA2OTkyOQ==", "bodyText": "Might be good to add a test for Map types as well. We can be sure that we have fixed these issues once and for all, for all the major types we support. Also in future if spark-avro changes something we can immediately fix these issues.", "url": "https://github.com/apache/hudi/pull/1406#discussion_r394069929", "createdAt": "2020-03-18T02:14:31Z", "author": {"login": "umehrot2"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/AvroConversionHelper.scala", "diffHunk": "@@ -324,7 +323,7 @@ object AvroConversionHelper {\n           avroSchema,\n           valueType,\n           structName,\n-          getNewRecordNamespace(valueType, recordNamespace, structName))\n+          recordNamespace)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dec5a88fbc287d95fc2277167ad9f44b53a00060"}, "originalPosition": 22}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dec5a88fbc287d95fc2277167ad9f44b53a00060", "author": {"user": null}, "url": "https://github.com/apache/hudi/commit/dec5a88fbc287d95fc2277167ad9f44b53a00060", "committedDate": "2020-03-16T17:35:40Z", "message": "[HUDI-713] Fix conversion of Spark array of struct type to Avro schema"}, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "2183ad041de499157a252873d71b23ea21348250", "author": {"user": null}, "url": "https://github.com/apache/hudi/commit/2183ad041de499157a252873d71b23ea21348250", "committedDate": "2020-03-20T05:43:12Z", "message": "[HUDI-713] Fix conversion of Spark array of struct type to Avro schema"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "2183ad041de499157a252873d71b23ea21348250", "author": {"user": null}, "url": "https://github.com/apache/hudi/commit/2183ad041de499157a252873d71b23ea21348250", "committedDate": "2020-03-20T05:43:12Z", "message": "[HUDI-713] Fix conversion of Spark array of struct type to Avro schema"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4MzQzNTQ4", "url": "https://github.com/apache/hudi/pull/1406#pullrequestreview-378343548", "createdAt": "2020-03-20T09:47:17Z", "commit": {"oid": "2183ad041de499157a252873d71b23ea21348250"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5MDUzOTc1", "url": "https://github.com/apache/hudi/pull/1406#pullrequestreview-379053975", "createdAt": "2020-03-22T22:23:32Z", "commit": {"oid": "2183ad041de499157a252873d71b23ea21348250"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMlQyMjoyMzozM1rOF5y99Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMlQyMjoyMzozM1rOF5y99Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE0ODIxMw==", "bodyText": "nit: recordNameSpace.size() == 0 ?", "url": "https://github.com/apache/hudi/pull/1406#discussion_r396148213", "createdAt": "2020-03-22T22:23:33Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/AvroConversionHelper.scala", "diffHunk": "@@ -338,12 +337,13 @@ object AvroConversionHelper {\n         }\n       case structType: StructType =>\n         val schema: Schema = SchemaConverters.toAvroType(structType, nullable = false, structName, recordNamespace)\n+        val childNameSpace = if (recordNamespace != \"\") s\"$recordNamespace.$structName\" else structName", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2183ad041de499157a252873d71b23ea21348250"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg0MjgzNDky", "url": "https://github.com/apache/hudi/pull/1406#pullrequestreview-384283492", "createdAt": "2020-03-30T22:41:15Z", "commit": {"oid": "2183ad041de499157a252873d71b23ea21348250"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMjo0MToxNVrOF9-4gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMjo0MToxNVrOF9-4gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDUzNzcyOQ==", "bodyText": "I mean its a nit.. not sure if the line being in spark would change how feel about it.. but again its a nit, happy to let this be this way :)", "url": "https://github.com/apache/hudi/pull/1406#discussion_r400537729", "createdAt": "2020-03-30T22:41:15Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/AvroConversionHelper.scala", "diffHunk": "@@ -338,12 +337,13 @@ object AvroConversionHelper {\n         }\n       case structType: StructType =>\n         val schema: Schema = SchemaConverters.toAvroType(structType, nullable = false, structName, recordNamespace)\n+        val childNameSpace = if (recordNamespace != \"\") s\"$recordNamespace.$structName\" else structName", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE0ODIxMw=="}, "originalCommit": {"oid": "2183ad041de499157a252873d71b23ea21348250"}, "originalPosition": 30}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3884, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}