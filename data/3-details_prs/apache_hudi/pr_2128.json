{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk0NDIxMzA1", "number": 2128, "title": "[HUDI-1303] Some improvements for the HUDI Test Suite.", "bodyText": "What is the purpose of the pull request\n\nUse the DAG Node's label from the yaml as its name instead of UUID names which are not descriptive when debugging issues from logs.\nFix CleanNode constructor which is not correctly implemented\nWhen generating upsets, allows more granualar control over the number of inserts and upserts - zero or more inserts and upserts can be specified instead of always requiring both inserts and upserts.\nFixed generation of records of specific size\n\nThe current code was using a class variable \"shouldAddMore\" which was reset to false after the first record generation causing subsequent records to be of minimum size.\nIn this change, we pre-calculate the extra size of the complex fields. When generating records, for complex fields we read the field size from this map.\n\n\nRefresh the timeline of the DeltaSync service before calling readFromSource. This ensures that only the newest generated data is read and data generated in the older Dag Nodes is ignored (as their AVRO files will have an older timestamp).\nMaking --workload-generator-classname an optional parameter as most probably the default will be used\n\nBrief change log\nVerify this pull request\nThis pull request is a trivial rework / code cleanup without any test coverage.\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-09-28T21:46:23Z", "url": "https://github.com/apache/hudi/pull/2128", "merged": true, "mergeCommit": {"oid": "788d236c443eb4ced819f9305ed8e0460b5984b7"}, "closed": true, "closedAt": "2020-10-07T12:33:52Z", "author": {"login": "prashantwason"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdPT2nYgFqTUwMTY0OTAyMw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdPpHFsgBqjM4NDIxMjU5MzQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNjQ5MDIz", "url": "https://github.com/apache/hudi/pull/2128#pullrequestreview-501649023", "createdAt": "2020-10-04T18:47:24Z", "commit": {"oid": "8c1b46a918dd8714eb2a4793765ad40285b0b35f"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQxODo0NzoyNFrOHcJatg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNFQxODo1Mjo1MVrOHcJcjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI3NjQ3MA==", "bodyText": "minor. we might as well do while (numEntriesToAdd-- > 0) {\nand remove line 208.", "url": "https://github.com/apache/hudi/pull/2128#discussion_r499276470", "createdAt": "2020-10-04T18:47:24Z", "author": {"login": "nsivabalan"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/GenericRecordFullPayloadGenerator.java", "diffHunk": "@@ -205,45 +193,36 @@ private Object typeConvert(Schema schema) {\n       case LONG:\n         return getNextConstrainedLong();\n       case STRING:\n-        return UUID.randomUUID().toString();\n+       return UUID.randomUUID().toString();\n       case ENUM:\n-        List<String> enumSymbols = localSchema.getEnumSymbols();\n-        return new GenericData.EnumSymbol(localSchema, enumSymbols.get(random.nextInt(enumSymbols.size() - 1)));\n+        List<String> enumSymbols = fieldSchema.getEnumSymbols();\n+        return new GenericData.EnumSymbol(fieldSchema, enumSymbols.get(random.nextInt(enumSymbols.size() - 1)));\n       case RECORD:\n-        return convert(localSchema);\n+        return getNewPayload(fieldSchema);\n       case ARRAY:\n-        Schema elementSchema = localSchema.getElementType();\n+        Schema.Field elementField = new Schema.Field(field.name(), fieldSchema.getElementType(), \"\", null);\n         List listRes = new ArrayList();\n-        if (isPrimitive(elementSchema) && this.shouldAddMore) {\n-          int numEntriesToAdd = numEntriesToAdd(elementSchema);\n-          while (numEntriesToAdd > 0) {\n-            listRes.add(typeConvert(elementSchema));\n-            numEntriesToAdd--;\n-          }\n-        } else {\n-          listRes.add(typeConvert(elementSchema));\n+        int numEntriesToAdd = extraEntriesMap.getOrDefault(field.name(), 1);\n+        while (numEntriesToAdd > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c1b46a918dd8714eb2a4793765ad40285b0b35f"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI3Njk0MQ==", "bodyText": "what happens if there is only one complexField and numEntriesToAdd is > 10 ?", "url": "https://github.com/apache/hudi/pull/2128#discussion_r499276941", "createdAt": "2020-10-04T18:52:51Z", "author": {"login": "nsivabalan"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/GenericRecordFullPayloadGenerator.java", "diffHunk": "@@ -333,23 +312,37 @@ private int getSize(Schema elementSchema) {\n    * @param elementSchema\n    * @return Number of entries to add\n    */\n-  private int numEntriesToAdd(Schema elementSchema) {\n-    // Find the size of the primitive data type in bytes\n-    int primitiveDataTypeSize = getSize(elementSchema);\n-    int numEntriesToAdd = numberOfBytesToAdd / primitiveDataTypeSize;\n-    // If more than 10 entries are being added for this same complex field and there are still more complex fields to\n-    // be visited in the schema, reduce the number of entries to add by a factor of 10 to allow for other complex\n-    // fields to pack some entries\n-    if (numEntriesToAdd % 10 > 0 && this.numberOfComplexFields > 1) {\n-      numEntriesToAdd = numEntriesToAdd / 10;\n-      numberOfBytesToAdd -= numEntriesToAdd * primitiveDataTypeSize;\n-      this.shouldAddMore = true;\n-    } else {\n-      this.numberOfBytesToAdd = 0;\n-      this.shouldAddMore = false;\n+  private void determineExtraEntriesRequired(int numberOfComplexFields, int numberOfBytesToAdd) {\n+    for (Schema.Field f : baseSchema.getFields()) {\n+      Schema elementSchema = f.schema();\n+      // Find the size of the primitive data type in bytes\n+      int primitiveDataTypeSize = 0;\n+      if (elementSchema.getType() == Type.ARRAY && isPrimitive(elementSchema.getElementType())) {\n+        primitiveDataTypeSize = getSize(elementSchema.getElementType());\n+      } else if (elementSchema.getType() == Type.MAP && isPrimitive(elementSchema.getValueType())) {\n+        primitiveDataTypeSize = getSize(elementSchema.getValueType());\n+      } else {\n+        continue;\n+      }\n+\n+      int numEntriesToAdd = numberOfBytesToAdd / primitiveDataTypeSize;\n+      // If more than 10 entries are being added for this same complex field and there are still more complex fields to\n+      // be visited in the schema, reduce the number of entries to add by a factor of 10 to allow for other complex\n+      // fields to pack some entries\n+      if (numEntriesToAdd > 10 && numberOfComplexFields > 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c1b46a918dd8714eb2a4793765ad40285b0b35f"}, "originalPosition": 226}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd7a276a68e1b5711aee4356f43b6c2a17cf6c1f", "author": {"user": {"login": "prashantwason", "name": "Prashant Wason"}}, "url": "https://github.com/apache/hudi/commit/bd7a276a68e1b5711aee4356f43b6c2a17cf6c1f", "committedDate": "2020-10-05T19:39:33Z", "message": "[HUDI-1303] Some improvements for the HUDI Test Suite.\n\n1. Use the DAG Node's label from the yaml as its name instead of UUID names which are not descriptive when debugging issues from logs.\n2. Fix CleanNode constructor which is not correctly implemented\n3. When generating upsets, allows more granualar control over the number of inserts and upserts - zero or more inserts and upserts can be specified instead of always requiring both inserts and upserts.\n4. Fixed generation of records of specific size\n   - The current code was using a class variable \"shouldAddMore\" which was reset to false after the first record generation causing subsequent records to be of minimum size.\n   - In this change, we pre-calculate the extra size of the complex fields. When generating records, for complex fields we read the field size from this map.\n5. Refresh the timeline of the DeltaSync service before calling readFromSource. This ensures that only the newest generated data is read and data generated in the older Dag Nodes is ignored (as their AVRO files will have an older timestamp).\n6. Making --workload-generator-classname an optional parameter as most probably the default will be used"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8c1b46a918dd8714eb2a4793765ad40285b0b35f", "author": {"user": {"login": "prashantwason", "name": "Prashant Wason"}}, "url": "https://github.com/apache/hudi/commit/8c1b46a918dd8714eb2a4793765ad40285b0b35f", "committedDate": "2020-09-28T21:44:15Z", "message": "[HUDI-1303] Some improvements for the HUDI Test Suite.\n\n1. Use the DAG Node's label from the yaml as its name instead of UUID names which are not descriptive when debugging issues from logs.\n2. Fix CleanNode constructor which is not correctly implemented\n3. When generating upsets, allows more granualar control over the number of inserts and upserts - zero or more inserts and upserts can be specified instead of always requiring both inserts and upserts.\n4. Fixed generation of records of specific size\n   - The current code was using a class variable \"shouldAddMore\" which was reset to false after the first record generation causing subsequent records to be of minimum size.\n   - In this change, we pre-calculate the extra size of the complex fields. When generating records, for complex fields we read the field size from this map.\n5. Refresh the timeline of the DeltaSync service before calling readFromSource. This ensures that only the newest generated data is read and data generated in the older Dag Nodes is ignored (as their AVRO files will have an older timestamp).\n6. Making --workload-generator-classname an optional parameter as most probably the default will be used"}, "afterCommit": {"oid": "bd7a276a68e1b5711aee4356f43b6c2a17cf6c1f", "author": {"user": {"login": "prashantwason", "name": "Prashant Wason"}}, "url": "https://github.com/apache/hudi/commit/bd7a276a68e1b5711aee4356f43b6c2a17cf6c1f", "committedDate": "2020-10-05T19:39:33Z", "message": "[HUDI-1303] Some improvements for the HUDI Test Suite.\n\n1. Use the DAG Node's label from the yaml as its name instead of UUID names which are not descriptive when debugging issues from logs.\n2. Fix CleanNode constructor which is not correctly implemented\n3. When generating upsets, allows more granualar control over the number of inserts and upserts - zero or more inserts and upserts can be specified instead of always requiring both inserts and upserts.\n4. Fixed generation of records of specific size\n   - The current code was using a class variable \"shouldAddMore\" which was reset to false after the first record generation causing subsequent records to be of minimum size.\n   - In this change, we pre-calculate the extra size of the complex fields. When generating records, for complex fields we read the field size from this map.\n5. Refresh the timeline of the DeltaSync service before calling readFromSource. This ensures that only the newest generated data is read and data generated in the older Dag Nodes is ignored (as their AVRO files will have an older timestamp).\n6. Making --workload-generator-classname an optional parameter as most probably the default will be used"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4605, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}