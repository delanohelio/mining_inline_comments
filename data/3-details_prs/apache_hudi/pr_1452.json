{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk0NTI5MjM4", "number": 1452, "title": "[HUDI-740]Fix can not specify the sparkMaster and code clean for SparkUtil", "bodyText": "Tips\n\nThank you very much for contributing to Apache Hudi.\nPlease review https://hudi.apache.org/contributing.html before opening a pull request.\n\nWhat is the purpose of the pull request\nNow, We can specify the sparkMaster of cleans run command, but it's not work.\nBrief change log\n(for example:)\n\nFix specify the sparkMaster of cleans run command\n\nVerify this pull request\nThis pull request is a trivial rework / code cleanup without any test coverage.\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-03-27T03:25:07Z", "url": "https://github.com/apache/hudi/pull/1452", "merged": true, "mergeCommit": {"oid": "4e5c8671ef3213ffa5c40f09aae27aacfa20f907"}, "closed": true, "closedAt": "2020-04-08T13:33:15Z", "author": {"login": "hddong"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcRoDKTgH2gAyMzk0NTI5MjM4OmQwYmU0NjljNzMyNWYxNzcyMTgxZWI4MzVhZjFiZmY1MmMzYjkzOTM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcVhZrCAFqTM4OTY2OTM3Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "d0be469c7325f1772181eb835af1bff52c3b9393", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/d0be469c7325f1772181eb835af1bff52c3b9393", "committedDate": "2020-03-27T03:22:27Z", "message": "Fix specify the sparkMaster of cleans run command"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyODE3NzAx", "url": "https://github.com/apache/hudi/pull/1452#pullrequestreview-382817701", "createdAt": "2020-03-27T12:36:09Z", "commit": {"oid": "d0be469c7325f1772181eb835af1bff52c3b9393"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxMjozNjoxMFrOF8vPhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxMjozNjoxMFrOF8vPhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTIzMjkwMA==", "bodyText": "Why do you want to implement it specifically for CLEAN command? Any specific reasons? I could not understand the purpose of this PR basically. :)", "url": "https://github.com/apache/hudi/pull/1452#discussion_r399232900", "createdAt": "2020-03-27T12:36:10Z", "author": {"login": "pratyakshsharma"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/SparkMain.java", "diffHunk": "@@ -62,7 +63,9 @@ public static void main(String[] args) throws Exception {\n \n     SparkCommand cmd = SparkCommand.valueOf(command);\n \n-    JavaSparkContext jsc = SparkUtil.initJavaSparkConf(\"hoodie-cli-\" + command);\n+    JavaSparkContext jsc = cmd == SparkCommand.CLEAN", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0be469c7325f1772181eb835af1bff52c3b9393"}, "originalPosition": 13}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bafcb956dbaf8801c0497f6ccb29259700d2b530", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/bafcb956dbaf8801c0497f6ccb29259700d2b530", "committedDate": "2020-03-30T04:08:12Z", "message": "Add compact"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0647035d3b9b7efbac5155b71603074e54587a76", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/0647035d3b9b7efbac5155b71603074e54587a76", "committedDate": "2020-03-30T04:10:55Z", "message": "Merge branch 'master' into fix-clean-run-master"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4ODAwNDU5", "url": "https://github.com/apache/hudi/pull/1452#pullrequestreview-388800459", "createdAt": "2020-04-07T05:48:27Z", "commit": {"oid": "0647035d3b9b7efbac5155b71603074e54587a76"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNTo0ODoyN1rOGBzxGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNTo1MToyOVrOGBz08g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU0OTkxNA==", "bodyText": "Let's use List<SparkCommand>?", "url": "https://github.com/apache/hudi/pull/1452#discussion_r404549914", "createdAt": "2020-04-07T05:48:27Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/SparkMain.java", "diffHunk": "@@ -118,53 +121,55 @@ public static void main(String[] args) throws Exception {\n         break;\n       case COMPACT_VALIDATE:\n         assert (args.length == 7);\n-        doCompactValidate(jsc, args[1], args[2], args[3], Integer.parseInt(args[4]), args[5], args[6]);\n+        doCompactValidate(jsc, args[3], args[4], args[5], Integer.parseInt(args[6]));\n         returnCode = 0;\n         break;\n       case COMPACT_REPAIR:\n         assert (args.length == 8);\n-        doCompactRepair(jsc, args[1], args[2], args[3], Integer.parseInt(args[4]), args[5], args[6],\n+        doCompactRepair(jsc, args[3], args[4], args[5], Integer.parseInt(args[6]),\n             Boolean.parseBoolean(args[7]));\n         returnCode = 0;\n         break;\n       case COMPACT_UNSCHEDULE_FILE:\n         assert (args.length == 9);\n-        doCompactUnscheduleFile(jsc, args[1], args[2], args[3], Integer.parseInt(args[4]), args[5], args[6],\n+        doCompactUnscheduleFile(jsc, args[3], args[4], args[5], Integer.parseInt(args[6]),\n             Boolean.parseBoolean(args[7]), Boolean.parseBoolean(args[8]));\n         returnCode = 0;\n         break;\n       case COMPACT_UNSCHEDULE_PLAN:\n         assert (args.length == 9);\n-        doCompactUnschedule(jsc, args[1], args[2], args[3], Integer.parseInt(args[4]), args[5], args[6],\n+        doCompactUnschedule(jsc, args[3], args[4], args[5], Integer.parseInt(args[6]),\n             Boolean.parseBoolean(args[7]), Boolean.parseBoolean(args[8]));\n         returnCode = 0;\n         break;\n       case CLEAN:\n         assert (args.length >= 5);\n         propsFilePath = null;\n-        if (!StringUtils.isNullOrEmpty(args[3])) {\n-          propsFilePath = args[3];\n+        if (!StringUtils.isNullOrEmpty(args[4])) {\n+          propsFilePath = args[4];\n         }\n         configs = new ArrayList<>();\n         if (args.length > 5) {\n           configs.addAll(Arrays.asList(args).subList(5, args.length));\n         }\n-        clean(jsc, args[1], args[2], propsFilePath, args[4], configs);\n+        clean(jsc, args[3], propsFilePath, configs);\n         break;\n       default:\n         break;\n     }\n     System.exit(returnCode);\n   }\n \n-  private static void clean(JavaSparkContext jsc, String basePath, String sparkMaster, String propsFilePath,\n-                            String sparkMemory, List<String> configs) throws Exception {\n+  private static boolean sparkMasterContained(SparkCommand command) {\n+    List masterContained = Arrays.asList(SparkCommand.COMPACT_VALIDATE, SparkCommand.COMPACT_REPAIR,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0647035d3b9b7efbac5155b71603074e54587a76"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU1MDE2MQ==", "bodyText": "The indent of arg is wrong?", "url": "https://github.com/apache/hudi/pull/1452#discussion_r404550161", "createdAt": "2020-04-07T05:49:10Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/SparkMain.java", "diffHunk": "@@ -118,53 +121,55 @@ public static void main(String[] args) throws Exception {\n         break;\n       case COMPACT_VALIDATE:\n         assert (args.length == 7);\n-        doCompactValidate(jsc, args[1], args[2], args[3], Integer.parseInt(args[4]), args[5], args[6]);\n+        doCompactValidate(jsc, args[3], args[4], args[5], Integer.parseInt(args[6]));\n         returnCode = 0;\n         break;\n       case COMPACT_REPAIR:\n         assert (args.length == 8);\n-        doCompactRepair(jsc, args[1], args[2], args[3], Integer.parseInt(args[4]), args[5], args[6],\n+        doCompactRepair(jsc, args[3], args[4], args[5], Integer.parseInt(args[6]),\n             Boolean.parseBoolean(args[7]));\n         returnCode = 0;\n         break;\n       case COMPACT_UNSCHEDULE_FILE:\n         assert (args.length == 9);\n-        doCompactUnscheduleFile(jsc, args[1], args[2], args[3], Integer.parseInt(args[4]), args[5], args[6],\n+        doCompactUnscheduleFile(jsc, args[3], args[4], args[5], Integer.parseInt(args[6]),\n             Boolean.parseBoolean(args[7]), Boolean.parseBoolean(args[8]));\n         returnCode = 0;\n         break;\n       case COMPACT_UNSCHEDULE_PLAN:\n         assert (args.length == 9);\n-        doCompactUnschedule(jsc, args[1], args[2], args[3], Integer.parseInt(args[4]), args[5], args[6],\n+        doCompactUnschedule(jsc, args[3], args[4], args[5], Integer.parseInt(args[6]),\n             Boolean.parseBoolean(args[7]), Boolean.parseBoolean(args[8]));\n         returnCode = 0;\n         break;\n       case CLEAN:\n         assert (args.length >= 5);\n         propsFilePath = null;\n-        if (!StringUtils.isNullOrEmpty(args[3])) {\n-          propsFilePath = args[3];\n+        if (!StringUtils.isNullOrEmpty(args[4])) {\n+          propsFilePath = args[4];\n         }\n         configs = new ArrayList<>();\n         if (args.length > 5) {\n           configs.addAll(Arrays.asList(args).subList(5, args.length));\n         }\n-        clean(jsc, args[1], args[2], propsFilePath, args[4], configs);\n+        clean(jsc, args[3], propsFilePath, configs);\n         break;\n       default:\n         break;\n     }\n     System.exit(returnCode);\n   }\n \n-  private static void clean(JavaSparkContext jsc, String basePath, String sparkMaster, String propsFilePath,\n-                            String sparkMemory, List<String> configs) throws Exception {\n+  private static boolean sparkMasterContained(SparkCommand command) {\n+    List masterContained = Arrays.asList(SparkCommand.COMPACT_VALIDATE, SparkCommand.COMPACT_REPAIR,\n+        SparkCommand.COMPACT_UNSCHEDULE_PLAN, SparkCommand.COMPACT_UNSCHEDULE_FILE, SparkCommand.CLEAN);\n+    return masterContained.contains(command);\n+  }\n+\n+  private static void clean(JavaSparkContext jsc, String basePath, String propsFilePath,\n+                            List<String> configs) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0647035d3b9b7efbac5155b71603074e54587a76"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU1MDg5OA==", "bodyText": "Can we extract the string literals in this method to be constant fields?", "url": "https://github.com/apache/hudi/pull/1452#discussion_r404550898", "createdAt": "2020-04-07T05:51:29Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/utils/SparkUtil.java", "diffHunk": "@@ -61,9 +62,14 @@ public static SparkLauncher initLauncher(String propertiesFile) throws URISyntax\n   }\n \n   public static JavaSparkContext initJavaSparkConf(String name) {\n+    return initJavaSparkConf(name, Option.empty(), Option.empty());\n+  }\n+\n+  public static JavaSparkContext initJavaSparkConf(String name, Option<String> master,\n+                                                   Option<String> executorMemory) {\n     SparkConf sparkConf = new SparkConf().setAppName(name);\n \n-    String defMasterFromEnv = sparkConf.getenv(\"SPARK_MASTER\");\n+    String defMasterFromEnv = master.orElse(sparkConf.getenv(\"SPARK_MASTER\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0647035d3b9b7efbac5155b71603074e54587a76"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4ODAyNTIw", "url": "https://github.com/apache/hudi/pull/1452#pullrequestreview-388802520", "createdAt": "2020-04-07T05:54:13Z", "commit": {"oid": "0647035d3b9b7efbac5155b71603074e54587a76"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNTo1NDoxM1rOGBz4fQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNTo1NDoxM1rOGBz4fQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU1MTgwNQ==", "bodyText": "indent issue.", "url": "https://github.com/apache/hudi/pull/1452#discussion_r404551805", "createdAt": "2020-04-07T05:54:13Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/utils/SparkUtil.java", "diffHunk": "@@ -61,9 +62,14 @@ public static SparkLauncher initLauncher(String propertiesFile) throws URISyntax\n   }\n \n   public static JavaSparkContext initJavaSparkConf(String name) {\n+    return initJavaSparkConf(name, Option.empty(), Option.empty());\n+  }\n+\n+  public static JavaSparkContext initJavaSparkConf(String name, Option<String> master,\n+                                                   Option<String> executorMemory) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0647035d3b9b7efbac5155b71603074e54587a76"}, "originalPosition": 16}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "97f2504301e32ab0c0bd18639bbf7a35c6331d6d", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/97f2504301e32ab0c0bd18639bbf7a35c6331d6d", "committedDate": "2020-04-07T09:55:19Z", "message": "update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8309ffd409ee18f18596dce69dc8e47a6b7521e8", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/8309ffd409ee18f18596dce69dc8e47a6b7521e8", "committedDate": "2020-04-07T15:23:42Z", "message": "add config"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NjY5Mzcy", "url": "https://github.com/apache/hudi/pull/1452#pullrequestreview-389669372", "createdAt": "2020-04-08T05:53:24Z", "commit": {"oid": "8309ffd409ee18f18596dce69dc8e47a6b7521e8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3261, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}