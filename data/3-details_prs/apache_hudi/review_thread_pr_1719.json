{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxNTU2ODY1", "number": 1719, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMzozODozNlrOEEIRIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwOTowMzo1MlrOEFPgFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzY1MjE2OnYy", "diffSide": "LEFT", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMzozODozNlrOGhjvUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMzozODozNlrOGhjvUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg0MTc0NA==", "bodyText": "hmmm interesting... so right now if we use LATEST as reset key, then we will fall into a dead loop unless we are lucky enough to have message fall in between two consumer.endOffsets(topicPartitions) call.", "url": "https://github.com/apache/hudi/pull/1719#discussion_r437841744", "createdAt": "2020-06-10T03:38:36Z", "author": {"login": "garyli1019"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java", "diffHunk": "@@ -57,10 +57,10 @@ public AvroKafkaSource(TypedProperties props, JavaSparkContext sparkContext, Spa\n   protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n     OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n     long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n+    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n     if (totalNewMsgs <= 0) {\n-      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNzY4MTg5OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMzo1OTozMlrOGhkBnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxMTo0MToyNVrOGhw9Fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg0NjQyOQ==", "bodyText": "could lastCheckpointStr be \"\" here?\nAlso, can we add a test for this case?\nhttps://github.com/apache/hudi/blob/master/hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestKafkaSource.java#L107", "url": "https://github.com/apache/hudi/pull/1719#discussion_r437846429", "createdAt": "2020-06-10T03:59:32Z", "author": {"login": "garyli1019"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java", "diffHunk": "@@ -57,10 +57,10 @@ public AvroKafkaSource(TypedProperties props, JavaSparkContext sparkContext, Spa\n   protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n     OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n     long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n+    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n     if (totalNewMsgs <= 0) {\n-      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n-    } else {\n-      LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n+      return new InputBatch<>(Option.empty(),\n+              lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : CheckpointUtils.offsetsToStr(offsetRanges));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA1ODI2Mg==", "bodyText": "For a hudi table already has a \"\" checkpoint, lastCheckpointStr can be \"\" here, so i change return value to return new endOffsets checkpoint string in all case.\nAnd i add a simple test case for kafka latest offset reset strategy in hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestKafkaSource.java.\nThanks for review! \ud83e\udd1d", "url": "https://github.com/apache/hudi/pull/1719#discussion_r438058262", "createdAt": "2020-06-10T11:41:25Z", "author": {"login": "Litianye"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java", "diffHunk": "@@ -57,10 +57,10 @@ public AvroKafkaSource(TypedProperties props, JavaSparkContext sparkContext, Spa\n   protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n     OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n     long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n+    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n     if (totalNewMsgs <= 0) {\n-      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n-    } else {\n-      LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n+      return new InputBatch<>(Option.empty(),\n+              lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : CheckpointUtils.offsetsToStr(offsetRanges));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg0NjQyOQ=="}, "originalCommit": {"oid": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczOTMyMzA4OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestKafkaSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwOTowMzo1MlrOGjWlBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwOTowMzo1MlrOGjWlBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcyMzI3MQ==", "bodyText": "we would merge the method with createPropsForJsonSource to reuse code.", "url": "https://github.com/apache/hudi/pull/1719#discussion_r439723271", "createdAt": "2020-06-13T09:03:52Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestKafkaSource.java", "diffHunk": "@@ -93,6 +93,18 @@ private TypedProperties createPropsForJsonSource(Long maxEventsToReadFromKafkaSo\n     return props;\n   }\n \n+  private TypedProperties createLatestPropsForJsonSource(Long maxEventsToReadFromKafkaSource) {\n+    TypedProperties props = new TypedProperties();\n+    props.setProperty(\"hoodie.deltastreamer.source.kafka.topic\", TEST_TOPIC_NAME);\n+    props.setProperty(\"bootstrap.servers\", testUtils.brokerAddress());\n+    props.setProperty(\"auto.offset.reset\", \"latest\");\n+    props.setProperty(\"hoodie.deltastreamer.kafka.source.maxEvents\",\n+            maxEventsToReadFromKafkaSource != null ? String.valueOf(maxEventsToReadFromKafkaSource) :\n+                    String.valueOf(Config.maxEventsFromKafkaSource));\n+    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, UUID.randomUUID().toString());\n+    return props;\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2cc2375601dc92139cbfd58492600df44bb90157"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4478, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}