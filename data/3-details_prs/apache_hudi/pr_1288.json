{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY4MzEyOTE4", "number": 1288, "title": "[HUDI-117] Close file handle before throwing an exception due to append\u2026", "bodyText": "\u2026 failure.\nAdd test cases to handle/verify stage failure scenarios.\nWhat is the purpose of the pull request\n\nFix for HDFS \"LeaseRecoveryInProgress\" exception (triggered by an append failure) that results in stage failures and eventually job getting killed.\n\nBrief change log\n\nAdd a shutdown hook to handle JVM crash or executor getting killed, during write.\nUpon encountering an append failure, close the file handle, so that subsequent task attempts on a different executor would be able to acquire lease on the .log file.\n\nVerify this pull request\nThis change added tests and can be verified as follows:\n\nAdded test cases to verify that upon stage failures, data records present in multiple log files can be successfully handled/merged.\n\nCommitter checklist\n\n\n[ x] Has a corresponding JIRA in PR title & commit\n\n\n[x ] Commit message is descriptive of the change\n\n\n[x ] CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-01-29T00:16:00Z", "url": "https://github.com/apache/hudi/pull/1288", "merged": true, "mergeCommit": {"oid": "6f34be1b8dd55304317c40565dad23c09ddda5bf"}, "closed": true, "closedAt": "2020-01-29T23:28:52Z", "author": {"login": "nbalajee"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb--xZRAFqTM0OTg2MzI3MA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABb_Oh8JAFqTM1MDQ5NjA1Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5ODYzMjcw", "url": "https://github.com/apache/hudi/pull/1288#pullrequestreview-349863270", "createdAt": "2020-01-29T05:06:18Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwNTowNjoxOFrOFi8sNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwNTowNjoxOFrOFi8sNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE5MDI2MA==", "bodyText": "Instead of Spark driver, lets just say when \"spark retries..\"", "url": "https://github.com/apache/hudi/pull/1288#discussion_r372190260", "createdAt": "2020-01-29T05:06:18Z", "author": {"login": "n3nash"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/log/HoodieLogFormatWriter.java", "diffHunk": "@@ -256,7 +280,22 @@ private void handleAppendExceptionOrRecoverLease(Path path, RemoteException e)\n         throw new HoodieException(e);\n       }\n     } else {\n-      throw new HoodieIOException(\"Failed to open an append stream \", e);\n+      // When fs.append() has failed and an exception is thrown, by closing the output stream\n+      // we shall force hdfs to release the lease on the log file. When Spark driver retries this task (with", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 51}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5ODYzNTI3", "url": "https://github.com/apache/hudi/pull/1288#pullrequestreview-349863527", "createdAt": "2020-01-29T05:07:32Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwNTowNzozM1rOFi8s6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwNTowNzozM1rOFi8s6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE5MDQ0Mw==", "bodyText": "Can you add a comment here why we are throwing an exception here", "url": "https://github.com/apache/hudi/pull/1288#discussion_r372190443", "createdAt": "2020-01-29T05:07:33Z", "author": {"login": "n3nash"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/log/HoodieLogFormatWriter.java", "diffHunk": "@@ -256,7 +280,22 @@ private void handleAppendExceptionOrRecoverLease(Path path, RemoteException e)\n         throw new HoodieException(e);\n       }\n     } else {\n-      throw new HoodieIOException(\"Failed to open an append stream \", e);\n+      // When fs.append() has failed and an exception is thrown, by closing the output stream\n+      // we shall force hdfs to release the lease on the log file. When Spark driver retries this task (with\n+      // new attemptId, say taskId.1) it will be able to acquire lease on the log file (as output stream was\n+      // closed properly by taskId.0).\n+      //\n+      // If close() call were to fail throwing an exception, our best bet is to rollover to a new log file.\n+      try {\n+        close();\n+        // output stream has been successfully closed and lease on the log file has been released.\n+        throw new HoodieIOException(\"Failed to append to the output stream \", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5ODYzNjQy", "url": "https://github.com/apache/hudi/pull/1288#pullrequestreview-349863642", "createdAt": "2020-01-29T05:08:01Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwNTowODowMVrOFi8tSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwNTowODowMVrOFi8tSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE5MDUzNg==", "bodyText": "nit : s/bloc/block", "url": "https://github.com/apache/hudi/pull/1288#discussion_r372190536", "createdAt": "2020-01-29T05:08:01Z", "author": {"login": "n3nash"}, "path": "hudi-common/src/test/java/org/apache/hudi/common/table/log/TestHoodieLogFormat.java", "diffHunk": "@@ -1113,6 +1113,99 @@ public void testAvroLogRecordReaderWithMixedInsertsCorruptsAndRollback()\n     assertEquals(\"We would read 0 records\", 0, scanner.getTotalLogRecords());\n   }\n \n+  /*\n+   * During a spark stage failure, when the stage is retried, tasks that are part of the previous attempt\n+   * of the stage would continue to run.  As a result two different tasks could be performing the same operation.\n+   * When trying to update the log file, only one of the tasks would succeed (one holding lease on the log file).\n+   *\n+   * In order to make progress in this scenario, second task attempting to update the log file would rollover to\n+   * a new version of the log file.  As a result, we might end up with two log files with same set of data records\n+   * present in both of them.\n+   *\n+   * Following uint tests mimic this scenario to ensure that the reader can handle merging multiple log files with\n+   * duplicate data.\n+   *\n+   */\n+  private void testAvroLogRecordReaderMergingMultipleLogFiles(int numRecordsInLog1, int numRecordsInLog2)\n+      throws IOException, URISyntaxException, InterruptedException {\n+    try {\n+      // Write one Data bloc with same InstantTime (written in same batch)", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5ODYzNzY2", "url": "https://github.com/apache/hudi/pull/1288#pullrequestreview-349863766", "createdAt": "2020-01-29T05:08:42Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87bc99de766a8e077a14e9a5930d215bef67a90f", "author": {"user": {"login": "nbalajee", "name": "Balajee Nagasubramaniam"}}, "url": "https://github.com/apache/hudi/commit/87bc99de766a8e077a14e9a5930d215bef67a90f", "committedDate": "2020-01-29T19:03:45Z", "message": "HUDI-117 Close file handle before throwing an exception due to append failure.\nAdd test cases to handle/verify stage failure scenarios."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "87bc99de766a8e077a14e9a5930d215bef67a90f", "author": {"user": {"login": "nbalajee", "name": "Balajee Nagasubramaniam"}}, "url": "https://github.com/apache/hudi/commit/87bc99de766a8e077a14e9a5930d215bef67a90f", "committedDate": "2020-01-29T19:03:45Z", "message": "HUDI-117 Close file handle before throwing an exception due to append failure.\nAdd test cases to handle/verify stage failure scenarios."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwNDk2MDU3", "url": "https://github.com/apache/hudi/pull/1288#pullrequestreview-350496057", "createdAt": "2020-01-29T23:27:54Z", "commit": {"oid": "87bc99de766a8e077a14e9a5930d215bef67a90f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4164, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}