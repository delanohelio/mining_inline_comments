{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYzNzM1Nzk4", "number": 1924, "title": "[HUDI-999][Performance] Parallelize fetching of bootstrap source data files/partitions", "bodyText": "What is the purpose of the pull request\nThis PR improves the performance of Hudi Bootstrap, by optimizing the listing of source partitions/files using spark parallelism.\nBrief change log\n\nUpdated BootstrapUtils to use spark context to list source partitions/files\nOther changes resulting from API change in BootstrapUtils to accept spark context\n\nVerify this pull request\n\nExisting Bootstrap unit tests\n\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-08-06T02:08:25Z", "url": "https://github.com/apache/hudi/pull/1924", "merged": true, "mergeCommit": {"oid": "ab453f26235c67fa3536b494c6c9f9c31e265ef8"}, "closed": true, "closedAt": "2020-08-07T06:44:58Z", "author": {"login": "umehrot2"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc8LFtmAFqTQ2MjI3MjQ0Mg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc8ep-IAFqTQ2MzA3MDg1OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYyMjcyNDQy", "url": "https://github.com/apache/hudi/pull/1924#pullrequestreview-462272442", "createdAt": "2020-08-06T07:56:43Z", "commit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwNzo1Njo0NFrOG8nmFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwNzo1Njo0NFrOG8nmFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIxNjQ2OA==", "bodyText": "we had some very similar code for marker dir listing? can we see if we can reuse some code here across them?", "url": "https://github.com/apache/hudi/pull/1924#discussion_r466216468", "createdAt": "2020-08-06T07:56:44Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/bootstrap/BootstrapUtils.java", "diffHunk": "@@ -41,37 +48,87 @@\n    * Returns leaf folders with files under a path.\n    * @param fs  File System\n    * @param basePathStr Base Path to look for leaf folders\n-   * @param filePathFilter  Filters to skip directories/paths\n+   * @param jsc Java spark context\n    * @return list of partition paths with files under them.\n    * @throws IOException\n    */\n   public static List<Pair<String, List<HoodieFileStatus>>> getAllLeafFoldersWithFiles(FileSystem fs, String basePathStr,\n-                                                                                      PathFilter filePathFilter) throws IOException {\n+      JavaSparkContext jsc) throws IOException {\n     final Path basePath = new Path(basePathStr);\n     final Map<Integer, List<String>> levelToPartitions = new HashMap<>();\n     final Map<String, List<HoodieFileStatus>> partitionToFiles = new HashMap<>();\n-    FSUtils.processFiles(fs, basePathStr, (status) -> {\n-      if (status.isFile() && filePathFilter.accept(status.getPath())) {\n-        String relativePath = FSUtils.getRelativePartitionPath(basePath, status.getPath().getParent());\n-        List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n-        if (null == statusList) {\n-          Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n-          List<String> dirs = levelToPartitions.get(level);\n-          if (null == dirs) {\n-            dirs = new ArrayList<>();\n-            levelToPartitions.put(level, dirs);\n+    PathFilter filePathFilter = getFilePathFilter();\n+    PathFilter metaPathFilter = getExcludeMetaPathFilter();\n+\n+    FileStatus[] topLevelStatuses = fs.listStatus(new Path(basePathStr));\n+    List<String> subDirectories = new ArrayList<>();\n+\n+    List<Pair<HoodieFileStatus, Pair<Integer, String>>> result = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11"}, "originalPosition": 56}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYyMjczMzc3", "url": "https://github.com/apache/hudi/pull/1924#pullrequestreview-462273377", "createdAt": "2020-08-06T07:57:56Z", "commit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwNzo1Nzo1N1rOG8no0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQwNzo1Nzo1N1rOG8no0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIxNzE2OA==", "bodyText": "can we just use the table's base file format here?", "url": "https://github.com/apache/hudi/pull/1924#discussion_r466217168", "createdAt": "2020-08-06T07:57:57Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/table/action/bootstrap/BootstrapUtils.java", "diffHunk": "@@ -41,37 +48,87 @@\n    * Returns leaf folders with files under a path.\n    * @param fs  File System\n    * @param basePathStr Base Path to look for leaf folders\n-   * @param filePathFilter  Filters to skip directories/paths\n+   * @param jsc Java spark context\n    * @return list of partition paths with files under them.\n    * @throws IOException\n    */\n   public static List<Pair<String, List<HoodieFileStatus>>> getAllLeafFoldersWithFiles(FileSystem fs, String basePathStr,\n-                                                                                      PathFilter filePathFilter) throws IOException {\n+      JavaSparkContext jsc) throws IOException {\n     final Path basePath = new Path(basePathStr);\n     final Map<Integer, List<String>> levelToPartitions = new HashMap<>();\n     final Map<String, List<HoodieFileStatus>> partitionToFiles = new HashMap<>();\n-    FSUtils.processFiles(fs, basePathStr, (status) -> {\n-      if (status.isFile() && filePathFilter.accept(status.getPath())) {\n-        String relativePath = FSUtils.getRelativePartitionPath(basePath, status.getPath().getParent());\n-        List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n-        if (null == statusList) {\n-          Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n-          List<String> dirs = levelToPartitions.get(level);\n-          if (null == dirs) {\n-            dirs = new ArrayList<>();\n-            levelToPartitions.put(level, dirs);\n+    PathFilter filePathFilter = getFilePathFilter();\n+    PathFilter metaPathFilter = getExcludeMetaPathFilter();\n+\n+    FileStatus[] topLevelStatuses = fs.listStatus(new Path(basePathStr));\n+    List<String> subDirectories = new ArrayList<>();\n+\n+    List<Pair<HoodieFileStatus, Pair<Integer, String>>> result = new ArrayList<>();\n+\n+    for (FileStatus topLevelStatus: topLevelStatuses) {\n+      if (topLevelStatus.isFile() && filePathFilter.accept(topLevelStatus.getPath())) {\n+        String relativePath = FSUtils.getRelativePartitionPath(basePath, topLevelStatus.getPath().getParent());\n+        Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n+        HoodieFileStatus hoodieFileStatus = FileStatusUtils.fromFileStatus(topLevelStatus);\n+        result.add(Pair.of(hoodieFileStatus, Pair.of(level, relativePath)));\n+      } else if (metaPathFilter.accept(topLevelStatus.getPath())) {\n+        subDirectories.add(topLevelStatus.getPath().toString());\n+      }\n+    }\n+\n+    if (subDirectories.size() > 0) {\n+      result.addAll(jsc.parallelize(subDirectories, subDirectories.size()).flatMap(directory -> {\n+        PathFilter pathFilter = getFilePathFilter();\n+        Path path = new Path(directory);\n+        FileSystem fileSystem = path.getFileSystem(new Configuration());\n+        RemoteIterator<LocatedFileStatus> itr = fileSystem.listFiles(path, true);\n+        List<Pair<HoodieFileStatus, Pair<Integer, String>>> res = new ArrayList<>();\n+        while (itr.hasNext()) {\n+          FileStatus status = itr.next();\n+          if (pathFilter.accept(status.getPath())) {\n+            String relativePath = FSUtils.getRelativePartitionPath(new Path(basePathStr), status.getPath().getParent());\n+            Integer level = (int) relativePath.chars().filter(ch -> ch == '/').count();\n+            HoodieFileStatus hoodieFileStatus = FileStatusUtils.fromFileStatus(status);\n+            res.add(Pair.of(hoodieFileStatus, Pair.of(level, relativePath)));\n           }\n-          dirs.add(relativePath);\n-          statusList = new ArrayList<>();\n-          partitionToFiles.put(relativePath, statusList);\n         }\n-        statusList.add(FileStatusUtils.fromFileStatus(status));\n+        return res.iterator();\n+      }).collect());\n+    }\n+\n+    result.forEach(val -> {\n+      String relativePath = val.getRight().getRight();\n+      List<HoodieFileStatus> statusList = partitionToFiles.get(relativePath);\n+      if (null == statusList) {\n+        Integer level = val.getRight().getLeft();\n+        List<String> dirs = levelToPartitions.get(level);\n+        if (null == dirs) {\n+          dirs = new ArrayList<>();\n+          levelToPartitions.put(level, dirs);\n+        }\n+        dirs.add(relativePath);\n+        statusList = new ArrayList<>();\n+        partitionToFiles.put(relativePath, statusList);\n       }\n-      return true;\n-    }, true);\n+      statusList.add(val.getLeft());\n+    });\n+\n     OptionalInt maxLevelOpt = levelToPartitions.keySet().stream().mapToInt(x -> x).max();\n     int maxLevel = maxLevelOpt.orElse(-1);\n     return maxLevel >= 0 ? levelToPartitions.get(maxLevel).stream()\n-        .map(d -> Pair.of(d, partitionToFiles.get(d))).collect(Collectors.toList()) : new ArrayList<>();\n+            .map(d -> Pair.of(d, partitionToFiles.get(d))).collect(Collectors.toList()) : new ArrayList<>();\n+  }\n+\n+  private static PathFilter getFilePathFilter() {\n+    return (path) -> {\n+      // TODO: Needs to be abstracted out when supporting different formats\n+      // TODO: Remove hoodieFilter\n+      return path.getName().endsWith(HoodieFileFormat.PARQUET.getFileExtension());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11"}, "originalPosition": 123}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "301059d8c95349c0c29bd152120fb91822f5c7d0", "author": {"user": {"login": "umehrot2", "name": "Udit Mehrotra"}}, "url": "https://github.com/apache/hudi/commit/301059d8c95349c0c29bd152120fb91822f5c7d0", "committedDate": "2020-08-07T01:40:12Z", "message": "[RFC-12] Parallelize fetching of source data files/partitions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3ffe5600fb6b9ae27680e33c0ffb16436571ff11", "author": {"user": {"login": "umehrot2", "name": "Udit Mehrotra"}}, "url": "https://github.com/apache/hudi/commit/3ffe5600fb6b9ae27680e33c0ffb16436571ff11", "committedDate": "2020-08-06T01:14:07Z", "message": "[RFC-12] Parallelize fetching of source data files/partitions"}, "afterCommit": {"oid": "301059d8c95349c0c29bd152120fb91822f5c7d0", "author": {"user": {"login": "umehrot2", "name": "Udit Mehrotra"}}, "url": "https://github.com/apache/hudi/commit/301059d8c95349c0c29bd152120fb91822f5c7d0", "committedDate": "2020-08-07T01:40:12Z", "message": "[RFC-12] Parallelize fetching of source data files/partitions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYzMDcwODU4", "url": "https://github.com/apache/hudi/pull/1924#pullrequestreview-463070858", "createdAt": "2020-08-07T06:44:32Z", "commit": {"oid": "301059d8c95349c0c29bd152120fb91822f5c7d0"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4791, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}