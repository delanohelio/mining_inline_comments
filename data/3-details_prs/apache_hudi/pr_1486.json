{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4OTEzMTg3", "number": 1486, "title": "[HUDI-759] Integrate checkpoint provider with delta streamer", "bodyText": "What is the purpose of the pull request\nIntegrate the initial checkpoint provider with delta streamer\nBrief change log\n\nAdd two options to delta streamer to use the initial checkpoint provider\n\nVerify this pull request\nThis change added tests and can be verified as follows:\n\nAdded unit test in TestHoodieDeltaStreamer\n\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-04-05T05:25:15Z", "url": "https://github.com/apache/hudi/pull/1486", "merged": true, "mergeCommit": {"oid": "14d4fea8339913c0df8ea829036a45a187c55208"}, "closed": true, "closedAt": "2020-04-14T21:51:05Z", "author": {"login": "garyli1019"}, "timelineItems": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcUxj64gBqjMyMDMwNzQyMjA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcXcljZABqjMyMjk1MjA1NTI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5ODM2MjM5", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-389836239", "createdAt": "2020-04-08T10:11:26Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoxMToyNlrOGCobsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoxMToyNlrOGCobsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQxMjc4NA==", "bodyText": "Let us change the variable name to conf?", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405412784", "createdAt": "2020-04-08T10:11:26Z", "author": {"login": "pratyakshsharma"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/DeltaSync.java", "diffHunk": "@@ -153,7 +153,7 @@\n   private transient HoodieWriteClient writeClient;\n \n   public DeltaSync(HoodieDeltaStreamer.Config cfg, SparkSession sparkSession, SchemaProvider schemaProvider,\n-                   TypedProperties props, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf,\n+                   TypedProperties props, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5ODM2Nzcz", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-389836773", "createdAt": "2020-04-08T10:12:15Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoxMjoxNVrOGCodXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoxMjoxNVrOGCodXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQxMzIxMw==", "bodyText": "lets change the variable name from hiveConf to conf?", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405413213", "createdAt": "2020-04-08T10:12:15Z", "author": {"login": "pratyakshsharma"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -90,35 +90,33 @@\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()));\n+        jssc.hadoopConfiguration(), null);\n   }\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, TypedProperties props) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()), props);\n+        jssc.hadoopConfiguration(), props);\n   }\n \n-  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf,\n-                             TypedProperties properties) throws IOException {\n-    this.cfg = cfg;\n-    this.deltaSyncService = new DeltaSyncService(cfg, jssc, fs, hiveConf, properties);\n+  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf) throws IOException {\n+    this(cfg, jssc, fs, hiveConf, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5ODM2ODk0", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-389836894", "createdAt": "2020-04-08T10:12:27Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoxMjoyN1rOGCodxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoxMjoyN1rOGCodxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQxMzMxOA==", "bodyText": "ditto.", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405413318", "createdAt": "2020-04-08T10:12:27Z", "author": {"login": "pratyakshsharma"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -90,35 +90,33 @@\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()));\n+        jssc.hadoopConfiguration(), null);\n   }\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, TypedProperties props) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()), props);\n+        jssc.hadoopConfiguration(), props);\n   }\n \n-  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf,\n-                             TypedProperties properties) throws IOException {\n-    this.cfg = cfg;\n-    this.deltaSyncService = new DeltaSyncService(cfg, jssc, fs, hiveConf, properties);\n+  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf) throws IOException {\n+    this(cfg, jssc, fs, hiveConf, null);\n   }\n \n-  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf) throws IOException {\n+  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5ODM3MjYx", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-389837261", "createdAt": "2020-04-08T10:12:59Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoxMjo1OVrOGCofBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxMDoxMjo1OVrOGCofBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQxMzYzOQ==", "bodyText": "ditto.", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405413639", "createdAt": "2020-04-08T10:12:59Z", "author": {"login": "pratyakshsharma"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -371,7 +379,7 @@ public static void main(String[] args) throws Exception {\n      */\n     private transient DeltaSync deltaSync;\n \n-    public DeltaSyncService(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf,\n+    public DeltaSyncService(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwNDkzNjc0", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-390493674", "createdAt": "2020-04-09T05:07:37Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNTowNzozOFrOGDJwjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNTowNzozOFrOGDJwjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk1ODc5Nw==", "bodyText": "can we not pass null as a sentinel.. its risky business.. would an empty properties/map work?", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405958797", "createdAt": "2020-04-09T05:07:38Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -90,35 +90,33 @@\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()));\n+        jssc.hadoopConfiguration(), null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwNDk0MDg1", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-390494085", "createdAt": "2020-04-09T05:09:09Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNTowOTowOVrOGDJyGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNTozNTo0NVrOGDKMvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk1OTE5Mw==", "bodyText": "let's use Option instead of nulls?", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405959193", "createdAt": "2020-04-09T05:09:09Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -90,35 +90,33 @@\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()));\n+        jssc.hadoopConfiguration(), null);\n   }\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, TypedProperties props) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()), props);\n+        jssc.hadoopConfiguration(), props);\n   }\n \n-  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf,\n-                             TypedProperties properties) throws IOException {\n-    this.cfg = cfg;\n-    this.deltaSyncService = new DeltaSyncService(cfg, jssc, fs, hiveConf, properties);\n+  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf) throws IOException {\n+    this(cfg, jssc, fs, hiveConf, null);\n   }\n \n-  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf) throws IOException {\n+  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf,\n+                             TypedProperties properties) throws IOException {\n+    if (cfg.initialCheckpointProvider != null && cfg.bootstrapFromPath != null && cfg.checkpoint == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk2NjAxNQ==", "bodyText": "IIUC setting cfg.checkpoint will force use of that timestamp instead of what we normally do - read from the last commit?\nShould we do this only when creating the dataset for the first time..", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405966015", "createdAt": "2020-04-09T05:35:45Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -90,35 +90,33 @@\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()));\n+        jssc.hadoopConfiguration(), null);\n   }\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, TypedProperties props) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()), props);\n+        jssc.hadoopConfiguration(), props);\n   }\n \n-  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf,\n-                             TypedProperties properties) throws IOException {\n-    this.cfg = cfg;\n-    this.deltaSyncService = new DeltaSyncService(cfg, jssc, fs, hiveConf, properties);\n+  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf) throws IOException {\n+    this(cfg, jssc, fs, hiveConf, null);\n   }\n \n-  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf) throws IOException {\n+  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf,\n+                             TypedProperties properties) throws IOException {\n+    if (cfg.initialCheckpointProvider != null && cfg.bootstrapFromPath != null && cfg.checkpoint == null) {\n+      InitialCheckPointProvider checkPointProvider =\n+          UtilHelpers.createInitialCheckpointProvider(cfg.initialCheckpointProvider, new Path(cfg.bootstrapFromPath), fs);\n+      cfg.checkpoint = checkPointProvider.getCheckpoint();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwNTAyMzE0", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-390502314", "createdAt": "2020-04-09T05:37:03Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNTozNzowM1rOGDKOGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNTozNzowM1rOGDKOGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk2NjM2MQ==", "bodyText": "testKafkaConnectCheckpointProvider?", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405966361", "createdAt": "2020-04-09T05:37:03Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieDeltaStreamer.java", "diffHunk": "@@ -394,6 +394,26 @@ public void testProps() {\n         props.getString(\"hoodie.datasource.write.keygenerator.class\"));\n   }\n \n+  @Test\n+  public void testInitialCheckpointProvider() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwNTAzOTIw", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-390503920", "createdAt": "2020-04-09T05:42:21Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNTo0MjoyMVrOGDKTzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQwNTo0NTo0M1rOGDKXjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk2NzgyMA==", "bodyText": "this is a path where the current dataset resides? I can see that we can eventually use this for actually bootstrapping the dataset.. but wondering if for now, the CheckpointProvider just takes a property containing the base path for reading/.computing checkpoints?\ni.e we can remove --bootstrap-from.. it almost sounds like we are actually bootstrapping the data.", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405967820", "createdAt": "2020-04-09T05:42:21Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -293,6 +295,12 @@ public Operation convert(String value) throws ParameterException {\n     @Parameter(names = {\"--checkpoint\"}, description = \"Resume Delta Streamer from this checkpoint.\")\n     public String checkpoint = null;\n \n+    @Parameter(names = {\"--bootstrap-from\"}, description = \"Initial bootstrap from this path\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk2ODc4Mg==", "bodyText": "it may be worth turning this into  abstract void init(Path, FileSystem) method? that way all subclasses are forced to implement the right one..\nAlso can we pass the props or the master list of properties (like we do for key generators) into this abstraction and let the CheckpointProvider use an explicit property like hoodie.deltastreamer.checkpointprovider.kafka.connect.path to derive the bootstrap path", "url": "https://github.com/apache/hudi/pull/1486#discussion_r405968782", "createdAt": "2020-04-09T05:45:43Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/checkpointing/InitialCheckPointProvider.java", "diffHunk": "@@ -20,12 +20,23 @@\n \n import org.apache.hudi.exception.HoodieException;\n \n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n /**\n  * Provide the initial checkpoint for delta streamer.\n  */\n-public interface InitialCheckPointProvider {\n+public abstract class InitialCheckPointProvider {\n+  protected final Path path;\n+  protected final FileSystem fs;\n+\n+  public InitialCheckPointProvider(final Path basePath, final FileSystem fileSystem) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 15}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxODgyMjg0", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-391882284", "createdAt": "2020-04-12T18:09:37Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODowOTozN1rOGEXjbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODoxMDo1MVrOGEXj4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMzM4OA==", "bodyText": "I get where you are coming from for final but given we are not following this everywhere.. can we please limit this PR to the minimal changes needed for this functionality..", "url": "https://github.com/apache/hudi/pull/1486#discussion_r407233388", "createdAt": "2020-04-12T18:09:37Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -319,18 +331,18 @@ private static Boolean tableExists(Connection conn, Map<String, String> options)\n    * @return\n    * @throws Exception\n    */\n-  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n-    Connection conn = createConnectionFactory(options);\n-    String url = options.get(JDBCOptions.JDBC_URL());\n-    String table = options.get(JDBCOptions.JDBC_TABLE_NAME());\n-    boolean tableExists = tableExists(conn,options);\n+  public static Schema getJDBCSchema(final Map<String, String> options) throws Exception {\n+    final Connection conn = createConnectionFactory(options);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 284}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMzUwNA==", "bodyText": "I still think its confusing to have it as hiveConf...  esp when you are actually creating  HiveConf from this down below..", "url": "https://github.com/apache/hudi/pull/1486#discussion_r407233504", "createdAt": "2020-04-12T18:10:51Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/DeltaSync.java", "diffHunk": "@@ -153,7 +153,7 @@\n   private transient HoodieWriteClient writeClient;\n \n   public DeltaSync(HoodieDeltaStreamer.Config cfg, SparkSession sparkSession, SchemaProvider schemaProvider,\n-                   TypedProperties props, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf,\n+                   TypedProperties props, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQxMjc4NA=="}, "originalCommit": null, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxODgyNTAz", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-391882503", "createdAt": "2020-04-12T18:12:45Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxOTEwMjcz", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-391910273", "createdAt": "2020-04-13T00:46:32Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwMDo0NjozMlrOGEaBQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwMDo1MzowNFrOGEaEEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI3Mzc5NA==", "bodyText": "are these from intellij formatting...", "url": "https://github.com/apache/hudi/pull/1486#discussion_r407273794", "createdAt": "2020-04-13T00:46:32Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -219,13 +230,13 @@ public static JavaSparkContext buildSparkContext(String appName, String sparkMas\n   /**\n    * Build Hoodie write client.\n    *\n-   * @param jsc Java Spark Context\n-   * @param basePath Base Path\n-   * @param schemaStr Schema\n+   * @param jsc         Java Spark Context", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI3MzkyMg==", "bodyText": "I think there is a setting not to format the lines untouched.. may be we can avoid all these whitespace changes that way..", "url": "https://github.com/apache/hudi/pull/1486#discussion_r407273922", "createdAt": "2020-04-13T00:47:47Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -219,13 +230,13 @@ public static JavaSparkContext buildSparkContext(String appName, String sparkMas\n   /**\n    * Build Hoodie write client.\n    *\n-   * @param jsc Java Spark Context\n-   * @param basePath Base Path\n-   * @param schemaStr Schema\n+   * @param jsc         Java Spark Context\n+   * @param basePath    Base Path\n+   * @param schemaStr   Schema\n    * @param parallelism Parallelism\n    */\n   public static HoodieWriteClient createHoodieClient(JavaSparkContext jsc, String basePath, String schemaStr,\n-      int parallelism, Option<String> compactionStrategyClass, TypedProperties properties) {\n+                                                     int parallelism, Option<String> compactionStrategyClass, TypedProperties properties) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI3NDEwOQ==", "bodyText": "would Configuration be a better choice here? is more general and the user can construct the filesystem from that? It will also carry other configurations picked up sparkContext say aws creds etc", "url": "https://github.com/apache/hudi/pull/1486#discussion_r407274109", "createdAt": "2020-04-13T00:49:19Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/checkpointing/InitialCheckPointProvider.java", "diffHunk": "@@ -18,14 +18,38 @@\n \n package org.apache.hudi.utilities.checkpointing;\n \n+import org.apache.hudi.common.config.TypedProperties;\n import org.apache.hudi.exception.HoodieException;\n \n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n /**\n  * Provide the initial checkpoint for delta streamer.\n  */\n-public interface InitialCheckPointProvider {\n+public abstract class InitialCheckPointProvider {\n+  protected transient Path path;\n+  protected transient FileSystem fs;\n+  protected transient TypedProperties props;\n+\n+  static class Config {\n+    private static String CHECKPOINT_PROVIDER_PATH_PROP = \"hoodie.deltastreamer.checkpoint.provider.path\";\n+  }\n+\n+  public InitialCheckPointProvider(TypedProperties props) {\n+    this.props = props;\n+    this.path = new Path(props.getString(Config.CHECKPOINT_PROVIDER_PATH_PROP));\n+  }\n+\n+  /**\n+   * Initialize the class with the current filesystem.\n+   *\n+   * @param fileSystem\n+   */\n+  public abstract void init(FileSystem fileSystem);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI3NDIzOQ==", "bodyText": ":). thank you.", "url": "https://github.com/apache/hudi/pull/1486#discussion_r407274239", "createdAt": "2020-04-13T00:50:45Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/DeltaSync.java", "diffHunk": "@@ -130,7 +130,7 @@\n   /**\n    * Hive Config.\n    */\n-  private transient HiveConf hiveConf;\n+  private transient Configuration conf;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI3NDI1OQ==", "bodyText": "got it..", "url": "https://github.com/apache/hudi/pull/1486#discussion_r407274259", "createdAt": "2020-04-13T00:50:58Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -90,35 +90,33 @@\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()));\n+        jssc.hadoopConfiguration(), null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk1ODc5Nw=="}, "originalCommit": null, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI3NDUxMw==", "bodyText": "yes.. do you think if we made it such that even if someone runs delta streamer few times after initial bootstrap, the initial checkpoint provider is used just once?  otherwise, you need to scramble to stop the delta streamer after the first run or manually run it by hand once before scheduling it using airflow or deploying in --continuous mode?", "url": "https://github.com/apache/hudi/pull/1486#discussion_r407274513", "createdAt": "2020-04-13T00:53:04Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -90,35 +90,33 @@\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()));\n+        jssc.hadoopConfiguration(), null);\n   }\n \n   public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, TypedProperties props) throws IOException {\n     this(cfg, jssc, FSUtils.getFs(cfg.targetBasePath, jssc.hadoopConfiguration()),\n-        getDefaultHiveConf(jssc.hadoopConfiguration()), props);\n+        jssc.hadoopConfiguration(), props);\n   }\n \n-  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf,\n-                             TypedProperties properties) throws IOException {\n-    this.cfg = cfg;\n-    this.deltaSyncService = new DeltaSyncService(cfg, jssc, fs, hiveConf, properties);\n+  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf) throws IOException {\n+    this(cfg, jssc, fs, hiveConf, null);\n   }\n \n-  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, HiveConf hiveConf) throws IOException {\n+  public HoodieDeltaStreamer(Config cfg, JavaSparkContext jssc, FileSystem fs, Configuration hiveConf,\n+                             TypedProperties properties) throws IOException {\n+    if (cfg.initialCheckpointProvider != null && cfg.bootstrapFromPath != null && cfg.checkpoint == null) {\n+      InitialCheckPointProvider checkPointProvider =\n+          UtilHelpers.createInitialCheckpointProvider(cfg.initialCheckpointProvider, new Path(cfg.bootstrapFromPath), fs);\n+      cfg.checkpoint = checkPointProvider.getCheckpoint();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk2NjAxNQ=="}, "originalCommit": null, "originalPosition": 44}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNjA0MjM5", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-392604239", "createdAt": "2020-04-14T05:01:13Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNTowMToxNFrOGE-TFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNTowMToxNFrOGE-TFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg2ODE4MA==", "bodyText": "InitialCheckPointProvider did you intend to write the name of the class here?", "url": "https://github.com/apache/hudi/pull/1486#discussion_r407868180", "createdAt": "2020-04-14T05:01:14Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -293,6 +296,12 @@ public Operation convert(String value) throws ParameterException {\n     @Parameter(names = {\"--checkpoint\"}, description = \"Resume Delta Streamer from this checkpoint.\")\n     public String checkpoint = null;\n \n+    @Parameter(names = {\"--initial-checkpoint-provider\"}, description = \"Generate check point for delta streamer \"\n+        + \"for the first run. This field will override the checkpoint of last commit using the checkpoint field. \"\n+        + \"Use this field only when switch source, for example, from DFS source to Kafka Source. Check the class \"\n+        + \"org.apache.hudi.utilities.checkpointing for details\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 87}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNjA0NDcw", "url": "https://github.com/apache/hudi/pull/1486#pullrequestreview-392604470", "createdAt": "2020-04-14T05:01:59Z", "commit": null, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestCommit", "commit": {"oid": "b923a97cd98861a068673411e73a341bb0130650", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/b923a97cd98861a068673411e73a341bb0130650", "committedDate": "2020-04-14T05:24:32Z", "message": "HUDI-759 Integrate checkpoint provider with delta streamer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "b923a97cd98861a068673411e73a341bb0130650", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/b923a97cd98861a068673411e73a341bb0130650", "committedDate": "2020-04-14T05:24:32Z", "message": "HUDI-759 Integrate checkpoint provider with delta streamer"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3335, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}