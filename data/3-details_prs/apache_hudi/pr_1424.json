{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkxMzk5ODY2", "number": 1424, "title": "[HUDI-697]Add unit test for ArchivedCommitsCommand", "bodyText": "Tips\n\nThank you very much for contributing to Apache Hudi.\nPlease review https://hudi.apache.org/contributing.html before opening a pull request.\n\nWhat is the purpose of the pull request\nAdd unit test for ArchivedCommitsCommand in hudi-cli module\nBrief change log\n\nAdd unit test for ArchivedCommitsCommand\n\nVerify this pull request\n\nAdd unit test for ArchivedCommitsCommand\n\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-03-20T08:03:03Z", "url": "https://github.com/apache/hudi/pull/1424", "merged": true, "mergeCommit": {"oid": "cafc87041baf4055c39244e7cde0187437bb03d4"}, "closed": true, "closedAt": "2020-03-23T05:46:10Z", "author": {"login": "hddong"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcPbwN9gH2gAyMzkxMzk5ODY2OjkyZDFmZjM3OTAyOTFjNGNhYjJhMzA4YjEwZGZiNDI5ZWJkZGQzMjg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcQXtDlAFqTM3OTE0NTY2Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "92d1ff3790291c4cab2a308b10dfb429ebddd328", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/92d1ff3790291c4cab2a308b10dfb429ebddd328", "committedDate": "2020-03-20T07:55:03Z", "message": "Add-test-ArchivedCommitsCommand"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4NTUwMjcz", "url": "https://github.com/apache/hudi/pull/1424#pullrequestreview-378550273", "createdAt": "2020-03-20T14:50:49Z", "commit": {"oid": "92d1ff3790291c4cab2a308b10dfb429ebddd328"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDo1MDo1MFrOF5W5Lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNToxNDo0NFrOF5X5YQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY4ODIzOQ==", "bodyText": "Will we reuse this class in the future for other test cases? If no, can we move these utility methods into TestArchivedCommitsCommand. If yes, what do you think about renaming to HoodieTestCommitUtilities. It seems utility is more clear than operate here. WDYT?", "url": "https://github.com/apache/hudi/pull/1424#discussion_r395688239", "createdAt": "2020-03-20T14:50:50Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/test/java/org/apache/hudi/cli/common/HoodieTestCommitOperate.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.common;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieWriteStat;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Utility methods to commit instant for test.\n+ */\n+public class HoodieTestCommitOperate {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92d1ff3790291c4cab2a308b10dfb429ebddd328"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5MjQ1MQ==", "bodyText": "IIUC, converter is a noun while convert is a verb.  A method usually means a behavior that starts with a verb actively. So considering the function of this method, wdyt about renaming to convertCommitMetadata? It's an open topic, you can share your thought if you have.", "url": "https://github.com/apache/hudi/pull/1424#discussion_r395692451", "createdAt": "2020-03-20T14:56:43Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/test/java/org/apache/hudi/cli/common/HoodieTestCommitOperate.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.common;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieWriteStat;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Utility methods to commit instant for test.\n+ */\n+public class HoodieTestCommitOperate {\n+\n+  /**\n+   * Converter HoodieCommitMetadata to avro format and ordered by partition.\n+   */\n+  public static org.apache.hudi.avro.model.HoodieCommitMetadata commitMetadataConverterOrdered(\n+      HoodieCommitMetadata hoodieCommitMetadata) {\n+    return orderCommitMetadata(commitMetadataConverter(hoodieCommitMetadata));\n+  }\n+\n+  /**\n+   * Converter HoodieCommitMetadata to avro format.\n+   */\n+  public static org.apache.hudi.avro.model.HoodieCommitMetadata commitMetadataConverter(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92d1ff3790291c4cab2a308b10dfb429ebddd328"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5Mjk4Ng==", "bodyText": "same thought about converter see other relevant comments in this class.", "url": "https://github.com/apache/hudi/pull/1424#discussion_r395692986", "createdAt": "2020-03-20T14:57:27Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/test/java/org/apache/hudi/cli/common/HoodieTestCommitOperate.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.common;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieWriteStat;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Utility methods to commit instant for test.\n+ */\n+public class HoodieTestCommitOperate {\n+\n+  /**\n+   * Converter HoodieCommitMetadata to avro format and ordered by partition.\n+   */\n+  public static org.apache.hudi.avro.model.HoodieCommitMetadata commitMetadataConverterOrdered(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92d1ff3790291c4cab2a308b10dfb429ebddd328"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY5OTAyOQ==", "bodyText": "Why we need to extends HoodieTestDataGenerator ? We only reused some static field here, right? And wdyt about renaming to HoodieTestCommitMetadataGenerator based on the implementation of this class.", "url": "https://github.com/apache/hudi/pull/1424#discussion_r395699029", "createdAt": "2020-03-20T15:06:30Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/test/java/org/apache/hudi/cli/common/HoodieTestCommandDataGenerator.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.common;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.HoodieTestDataGenerator;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieTestUtils;\n+import org.apache.hudi.common.model.HoodieWriteStat;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.HoodieTimeline;\n+import org.apache.hudi.common.util.FSUtils;\n+import org.apache.hudi.exception.HoodieIOException;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Class to be used in tests to keep generating test inserts and updates against a corpus.\n+ */\n+public class HoodieTestCommandDataGenerator extends HoodieTestDataGenerator {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92d1ff3790291c4cab2a308b10dfb429ebddd328"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTcwMDcxMw==", "bodyText": "can we modify the access modifier to private?", "url": "https://github.com/apache/hudi/pull/1424#discussion_r395700713", "createdAt": "2020-03-20T15:08:59Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/test/java/org/apache/hudi/cli/common/HoodieTestCommandDataGenerator.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.common;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.HoodieTestDataGenerator;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieTestUtils;\n+import org.apache.hudi.common.model.HoodieWriteStat;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.HoodieTimeline;\n+import org.apache.hudi.common.util.FSUtils;\n+import org.apache.hudi.exception.HoodieIOException;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Class to be used in tests to keep generating test inserts and updates against a corpus.\n+ */\n+public class HoodieTestCommandDataGenerator extends HoodieTestDataGenerator {\n+\n+  // default commit metadata value\n+  public static final String DEFAULT_PATH = \"path\";\n+  public static final String DEFAULT_FILEID = \"fileId\";\n+  public static final int DEFAULT_TOTAL_WRITE_BYTES = 50;\n+  public static final String DEFAULT_PRE_COMMIT = \"commit-1\";\n+  public static final int DEFAULT_NUM_WRITES = 10;\n+  public static final int DEFAULT_NUM_UPDATE_WRITES = 15;\n+  public static final int DEFAULT_TOTAL_LOG_BLOCKS = 1;\n+  public static final int DEFAULT_TOTAL_LOG_RECORDS = 10;\n+  public static final int DEFAULT_OTHER_VALUE = 0;\n+  public static final String DEFAULT_NULL_VALUE = \"null\";\n+\n+  /**\n+   * Create a commit file with default CommitMetadata.\n+   */\n+  public static void createCommitFileWithMetadata(String basePath, String commitTime, Configuration configuration) {\n+    Arrays.asList(HoodieTimeline.makeCommitFileName(commitTime), HoodieTimeline.makeInflightCommitFileName(commitTime),\n+        HoodieTimeline.makeRequestedCommitFileName(commitTime))\n+        .forEach(f -> {\n+          Path commitFile = new Path(\n+              basePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + f);\n+          FSDataOutputStream os = null;\n+          try {\n+            FileSystem fs = FSUtils.getFs(basePath, configuration);\n+            os = fs.create(commitFile, true);\n+            // Generate commitMetadata\n+            HoodieCommitMetadata commitMetadata = generateCommitMetadata(basePath);\n+            // Write empty commit metadata\n+            os.writeBytes(new String(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n+          } catch (IOException ioe) {\n+            throw new HoodieIOException(ioe.getMessage(), ioe);\n+          } finally {\n+            if (null != os) {\n+              try {\n+                os.close();\n+              } catch (IOException e) {\n+                throw new HoodieIOException(e.getMessage(), e);\n+              }\n+            }\n+          }\n+        });\n+  }\n+\n+  /**\n+   * Generate commitMetadata in path.\n+   */\n+  public static HoodieCommitMetadata generateCommitMetadata(String basePath) throws IOException {\n+    String file1P0C0 =\n+        HoodieTestUtils.createNewDataFile(basePath, DEFAULT_FIRST_PARTITION_PATH, \"000\");\n+    String file1P1C0 =\n+        HoodieTestUtils.createNewDataFile(basePath, DEFAULT_SECOND_PARTITION_PATH, \"000\");\n+    return generateCommitMetadata(new ImmutableMap.Builder()\n+      .put(DEFAULT_FIRST_PARTITION_PATH, new ImmutableList.Builder<>().add(file1P0C0).build())\n+      .put(DEFAULT_SECOND_PARTITION_PATH, new ImmutableList.Builder<>().add(file1P1C0).build())\n+      .build());\n+  }\n+\n+\n+\n+  /**\n+   * Method to generate commit metadata.\n+   */\n+  public static HoodieCommitMetadata generateCommitMetadata(Map<String, List<String>> partitionToFilePaths) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92d1ff3790291c4cab2a308b10dfb429ebddd328"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTcwNDY3Mw==", "bodyText": "Why we should use System.out.println? Do we need to get information from STDOUT?", "url": "https://github.com/apache/hudi/pull/1424#discussion_r395704673", "createdAt": "2020-03-20T15:14:44Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestArchivedCommitsCommand.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.AbstractShellIntegrationTest;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.common.HoodieTestCommandDataGenerator;\n+import org.apache.hudi.cli.common.HoodieTestCommitOperate;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.table.HoodieCommitArchiveLog;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Cases for {@link ArchivedCommitsCommand}.\n+ */\n+public class TestArchivedCommitsCommand extends AbstractShellIntegrationTest {\n+\n+  private String tablePath;\n+\n+  @Before\n+  public void init() throws IOException {\n+    initDFS();\n+    jsc.hadoopConfiguration().addResource(dfs.getConf());\n+    HoodieCLI.conf = dfs.getConf();\n+\n+    // Create table and connect\n+    String tableName = \"test_table\";\n+    tablePath = basePath + File.separator + tableName;\n+    new TableCommand().createTable(\n+        tablePath, tableName,\n+        \"COPY_ON_WRITE\", \"\", 1, \"org.apache.hudi.common.model.HoodieAvroPayload\");\n+\n+    metaClient = HoodieCLI.getTableMetaClient();\n+\n+    // Generate archive\n+    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(tablePath)\n+        .withSchema(HoodieTestCommandDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2)\n+        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n+        .forTable(\"test-trip-table\").build();\n+\n+    // Create six commits\n+    for (int i = 100; i < 106; i++) {\n+      String timestamp = String.valueOf(i);\n+      // Requested Compaction\n+      HoodieTestCommandDataGenerator.createCompactionAuxiliaryMetadata(tablePath,\n+          new HoodieInstant(HoodieInstant.State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, timestamp), dfs.getConf());\n+      // Inflight Compaction\n+      HoodieTestCommandDataGenerator.createCompactionAuxiliaryMetadata(tablePath,\n+          new HoodieInstant(HoodieInstant.State.INFLIGHT, HoodieTimeline.COMPACTION_ACTION, timestamp), dfs.getConf());\n+      HoodieTestCommandDataGenerator.createCommitFileWithMetadata(tablePath, timestamp, dfs.getConf());\n+    }\n+\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    // reload the timeline and get all the commits before archive\n+    HoodieTimeline timeline = metaClient.getActiveTimeline().reload().getAllCommitsTimeline().filterCompletedInstants();\n+    assertEquals(\"Loaded 6 commits and the count should match\", 6, timeline.countInstants());\n+\n+    // archive\n+    HoodieCommitArchiveLog archiveLog = new HoodieCommitArchiveLog(cfg, metaClient);\n+    assertTrue(archiveLog.archiveIfRequired(jsc));\n+  }\n+\n+  @After\n+  public void clean() throws IOException {\n+    cleanupDFS();\n+  }\n+\n+  /**\n+   * Test for command: show archived commit stats.\n+   */\n+  @Test\n+  public void testShowArchivedCommits() {\n+    CommandResult cr = getShell().executeCommand(\"show archived commit stats\");\n+    assertTrue(cr.isSuccess());\n+\n+    TableHeader header = new TableHeader().addTableHeaderField(\"action\").addTableHeaderField(\"instant\")\n+        .addTableHeaderField(\"partition\").addTableHeaderField(\"file_id\").addTableHeaderField(\"prev_instant\")\n+        .addTableHeaderField(\"num_writes\").addTableHeaderField(\"num_inserts\").addTableHeaderField(\"num_deletes\")\n+        .addTableHeaderField(\"num_update_writes\").addTableHeaderField(\"total_log_files\")\n+        .addTableHeaderField(\"total_log_blocks\").addTableHeaderField(\"total_corrupt_log_blocks\")\n+        .addTableHeaderField(\"total_rollback_blocks\").addTableHeaderField(\"total_log_records\")\n+        .addTableHeaderField(\"total_updated_records_compacted\").addTableHeaderField(\"total_write_bytes\")\n+        .addTableHeaderField(\"total_write_errors\");\n+\n+    // Generate expected data\n+    final List<Comparable[]> rows = new ArrayList<>();\n+    for (int i = 100; i < 104; i++) {\n+      String instant = String.valueOf(i);\n+      for (int j = 0; j < 3; j++) {\n+        Comparable[] defaultComp = new Comparable[]{\"commit\", instant,\n+            HoodieTestCommandDataGenerator.DEFAULT_SECOND_PARTITION_PATH,\n+            HoodieTestCommandDataGenerator.DEFAULT_FILEID,\n+            HoodieTestCommandDataGenerator.DEFAULT_PRE_COMMIT,\n+            HoodieTestCommandDataGenerator.DEFAULT_NUM_WRITES,\n+            HoodieTestCommandDataGenerator.DEFAULT_OTHER_VALUE,\n+            HoodieTestCommandDataGenerator.DEFAULT_OTHER_VALUE,\n+            HoodieTestCommandDataGenerator.DEFAULT_NUM_UPDATE_WRITES,\n+            HoodieTestCommandDataGenerator.DEFAULT_NULL_VALUE,\n+            HoodieTestCommandDataGenerator.DEFAULT_TOTAL_LOG_BLOCKS,\n+            HoodieTestCommandDataGenerator.DEFAULT_OTHER_VALUE,\n+            HoodieTestCommandDataGenerator.DEFAULT_OTHER_VALUE,\n+            HoodieTestCommandDataGenerator.DEFAULT_TOTAL_LOG_RECORDS,\n+            HoodieTestCommandDataGenerator.DEFAULT_OTHER_VALUE,\n+            HoodieTestCommandDataGenerator.DEFAULT_TOTAL_WRITE_BYTES,\n+            HoodieTestCommandDataGenerator.DEFAULT_OTHER_VALUE};\n+        rows.add(defaultComp.clone());\n+        defaultComp[2] = HoodieTestCommandDataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+        rows.add(defaultComp);\n+      }\n+    }\n+\n+    String expectedResult = HoodiePrintHelper.print(\n+        header, new HashMap<>(), \"\", false, -1, false, rows);\n+    assertEquals(expectedResult, cr.getResult().toString());\n+  }\n+\n+  /**\n+   * Test for command: show archived commits.\n+   */\n+  @Test\n+  public void testShowCommits() throws IOException {\n+    CommandResult cr = getShell().executeCommand(\"show archived commits\");\n+    assertTrue(cr.isSuccess());\n+    System.out.println(cr.getResult().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92d1ff3790291c4cab2a308b10dfb429ebddd328"}, "originalPosition": 160}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2605ab2f2db655b19c54dfe3025c41d48a8da5d", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/e2605ab2f2db655b19c54dfe3025c41d48a8da5d", "committedDate": "2020-03-22T02:52:33Z", "message": "update name"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5MTA4MzEx", "url": "https://github.com/apache/hudi/pull/1424#pullrequestreview-379108311", "createdAt": "2020-03-23T03:06:16Z", "commit": {"oid": "e2605ab2f2db655b19c54dfe3025c41d48a8da5d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QwMzowNjoxNlrOF51sWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QwMzowNjoyNFrOF51saw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE5Mjg1OA==", "bodyText": "IMO, we'd better to use assertion in a method that marks with @Test annotation. WDYT?", "url": "https://github.com/apache/hudi/pull/1424#discussion_r396192858", "createdAt": "2020-03-23T03:06:16Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestArchivedCommitsCommand.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.AbstractShellIntegrationTest;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.common.HoodieTestCommitMetadataGenerator;\n+import org.apache.hudi.cli.common.HoodieTestCommitUtilities;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.table.HoodieCommitArchiveLog;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Cases for {@link ArchivedCommitsCommand}.\n+ */\n+public class TestArchivedCommitsCommand extends AbstractShellIntegrationTest {\n+\n+  private String tablePath;\n+\n+  @Before\n+  public void init() throws IOException {\n+    initDFS();\n+    jsc.hadoopConfiguration().addResource(dfs.getConf());\n+    HoodieCLI.conf = dfs.getConf();\n+\n+    // Create table and connect\n+    String tableName = \"test_table\";\n+    tablePath = basePath + File.separator + tableName;\n+    new TableCommand().createTable(\n+        tablePath, tableName,\n+        \"COPY_ON_WRITE\", \"\", 1, \"org.apache.hudi.common.model.HoodieAvroPayload\");\n+\n+    metaClient = HoodieCLI.getTableMetaClient();\n+\n+    // Generate archive\n+    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(tablePath)\n+        .withSchema(HoodieTestCommitMetadataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2)\n+        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n+        .forTable(\"test-trip-table\").build();\n+\n+    // Create six commits\n+    for (int i = 100; i < 106; i++) {\n+      String timestamp = String.valueOf(i);\n+      // Requested Compaction\n+      HoodieTestCommitMetadataGenerator.createCompactionAuxiliaryMetadata(tablePath,\n+          new HoodieInstant(HoodieInstant.State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, timestamp), dfs.getConf());\n+      // Inflight Compaction\n+      HoodieTestCommitMetadataGenerator.createCompactionAuxiliaryMetadata(tablePath,\n+          new HoodieInstant(HoodieInstant.State.INFLIGHT, HoodieTimeline.COMPACTION_ACTION, timestamp), dfs.getConf());\n+      HoodieTestCommitMetadataGenerator.createCommitFileWithMetadata(tablePath, timestamp, dfs.getConf());\n+    }\n+\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    // reload the timeline and get all the commits before archive\n+    HoodieTimeline timeline = metaClient.getActiveTimeline().reload().getAllCommitsTimeline().filterCompletedInstants();\n+    assertEquals(\"Loaded 6 commits and the count should match\", 6, timeline.countInstants());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2605ab2f2db655b19c54dfe3025c41d48a8da5d"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE5Mjg3NQ==", "bodyText": "ditto", "url": "https://github.com/apache/hudi/pull/1424#discussion_r396192875", "createdAt": "2020-03-23T03:06:24Z", "author": {"login": "yanghua"}, "path": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestArchivedCommitsCommand.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.AbstractShellIntegrationTest;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.common.HoodieTestCommitMetadataGenerator;\n+import org.apache.hudi.cli.common.HoodieTestCommitUtilities;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.table.HoodieCommitArchiveLog;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Cases for {@link ArchivedCommitsCommand}.\n+ */\n+public class TestArchivedCommitsCommand extends AbstractShellIntegrationTest {\n+\n+  private String tablePath;\n+\n+  @Before\n+  public void init() throws IOException {\n+    initDFS();\n+    jsc.hadoopConfiguration().addResource(dfs.getConf());\n+    HoodieCLI.conf = dfs.getConf();\n+\n+    // Create table and connect\n+    String tableName = \"test_table\";\n+    tablePath = basePath + File.separator + tableName;\n+    new TableCommand().createTable(\n+        tablePath, tableName,\n+        \"COPY_ON_WRITE\", \"\", 1, \"org.apache.hudi.common.model.HoodieAvroPayload\");\n+\n+    metaClient = HoodieCLI.getTableMetaClient();\n+\n+    // Generate archive\n+    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(tablePath)\n+        .withSchema(HoodieTestCommitMetadataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2)\n+        .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n+        .forTable(\"test-trip-table\").build();\n+\n+    // Create six commits\n+    for (int i = 100; i < 106; i++) {\n+      String timestamp = String.valueOf(i);\n+      // Requested Compaction\n+      HoodieTestCommitMetadataGenerator.createCompactionAuxiliaryMetadata(tablePath,\n+          new HoodieInstant(HoodieInstant.State.REQUESTED, HoodieTimeline.COMPACTION_ACTION, timestamp), dfs.getConf());\n+      // Inflight Compaction\n+      HoodieTestCommitMetadataGenerator.createCompactionAuxiliaryMetadata(tablePath,\n+          new HoodieInstant(HoodieInstant.State.INFLIGHT, HoodieTimeline.COMPACTION_ACTION, timestamp), dfs.getConf());\n+      HoodieTestCommitMetadataGenerator.createCommitFileWithMetadata(tablePath, timestamp, dfs.getConf());\n+    }\n+\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    // reload the timeline and get all the commits before archive\n+    HoodieTimeline timeline = metaClient.getActiveTimeline().reload().getAllCommitsTimeline().filterCompletedInstants();\n+    assertEquals(\"Loaded 6 commits and the count should match\", 6, timeline.countInstants());\n+\n+    // archive\n+    HoodieCommitArchiveLog archiveLog = new HoodieCommitArchiveLog(cfg, metaClient);\n+    assertTrue(archiveLog.archiveIfRequired(jsc));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2605ab2f2db655b19c54dfe3025c41d48a8da5d"}, "originalPosition": 96}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "081b2c16c8d7176e138db82cdc685b36d3d06da4", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/081b2c16c8d7176e138db82cdc685b36d3d06da4", "committedDate": "2020-03-23T04:00:09Z", "message": "remove assert in before"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51dfe2213b60199720d0d3e80761ab8555ce853e", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/51dfe2213b60199720d0d3e80761ab8555ce853e", "committedDate": "2020-03-23T04:05:32Z", "message": "change mothod name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f23724fc949f692293f0171f43b17bd7db4df299", "author": {"user": {"login": "hddong", "name": "hongdd"}}, "url": "https://github.com/apache/hudi/commit/f23724fc949f692293f0171f43b17bd7db4df299", "committedDate": "2020-03-23T04:11:50Z", "message": "update"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5MTQ1NjYz", "url": "https://github.com/apache/hudi/pull/1424#pullrequestreview-379145663", "createdAt": "2020-03-23T05:45:54Z", "commit": {"oid": "f23724fc949f692293f0171f43b17bd7db4df299"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3978, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}