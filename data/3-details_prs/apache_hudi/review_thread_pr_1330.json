{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc0NjM0MzI3", "number": 1330, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMjoxMTo0NFrODfwong==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMjoxMjozOFrODfwpEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NjI5Mjc4OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMjoxMTo0NFrOFppvUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQxOTozODowN1rOFttSMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIxOTc5NA==", "bodyText": "Should we do this conversion out in the caller of this method instead?", "url": "https://github.com/apache/hudi/pull/1330#discussion_r379219794", "createdAt": "2020-02-14T02:11:44Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -77,6 +80,11 @@ public static Object getNestedFieldVal(GenericRecord record, String fieldName, b\n \n       // return, if last part of name\n       if (i == parts.length - 1) {\n+\n+        if (isLogicalTypeDate(valueNode, part)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDMzOTcwNw==", "bodyText": "This method seems to me like the right central place to perform this check and conversion. If we check the accessors of this method, it is used by Hudi to retrieve the key values for its metadata fields. It might be more standard to have Hudi treat Date as the actual Date string instead of a Long, across all its keys for its internal usage. It would create a lot of confusion otherwise and accessors of this functions will have to take care of adding this check.\nAlso, we would again have to re-write the same logic/loop again on client side to check for logical type. Because this function basically returns only the value.", "url": "https://github.com/apache/hudi/pull/1330#discussion_r380339707", "createdAt": "2020-02-17T19:28:07Z", "author": {"login": "umehrot2"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -77,6 +80,11 @@ public static Object getNestedFieldVal(GenericRecord record, String fieldName, b\n \n       // return, if last part of name\n       if (i == parts.length - 1) {\n+\n+        if (isLogicalTypeDate(valueNode, part)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIxOTc5NA=="}, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3MjE3Ng==", "bodyText": "Hmmm.. just feel that now, this method is doing multiple things and those get tricky over time.. Simple compromise.. please pull this  conversion code to its own helper method, that we can invoke from here.. that way, over time, more conversions are just added to that helper., while this methods just focusses on getting a nested value .", "url": "https://github.com/apache/hudi/pull/1330#discussion_r383472176", "createdAt": "2020-02-24T19:38:07Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -77,6 +80,11 @@ public static Object getNestedFieldVal(GenericRecord record, String fieldName, b\n \n       // return, if last part of name\n       if (i == parts.length - 1) {\n+\n+        if (isLogicalTypeDate(valueNode, part)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIxOTc5NA=="}, "originalCommit": null, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NjI5Mzk0OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMjoxMjozOFrOFppwAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xN1QxOTo1MjowM1rOFqufzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIxOTk2OQ==", "bodyText": "May not be related to this PR. but is time zone information lost when we convert from Date to Long (row -> avro)?", "url": "https://github.com/apache/hudi/pull/1330#discussion_r379219969", "createdAt": "2020-02-14T02:12:38Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -77,6 +80,11 @@ public static Object getNestedFieldVal(GenericRecord record, String fieldName, b\n \n       // return, if last part of name\n       if (i == parts.length - 1) {\n+\n+        if (isLogicalTypeDate(valueNode, part)) {\n+          return LocalDate.ofEpochDay(Long.parseLong(val.toString()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDM0NjMxOA==", "bodyText": "From my understanding, I don't think Spark's DateType has a timezone. It should be using the Local TimeZone. Same goes for LocalDate.", "url": "https://github.com/apache/hudi/pull/1330#discussion_r380346318", "createdAt": "2020-02-17T19:52:03Z", "author": {"login": "umehrot2"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -77,6 +80,11 @@ public static Object getNestedFieldVal(GenericRecord record, String fieldName, b\n \n       // return, if last part of name\n       if (i == parts.length - 1) {\n+\n+        if (isLogicalTypeDate(valueNode, part)) {\n+          return LocalDate.ofEpochDay(Long.parseLong(val.toString()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIxOTk2OQ=="}, "originalCommit": null, "originalPosition": 23}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4824, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}