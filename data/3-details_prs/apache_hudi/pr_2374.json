{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQ1MTY5MTE5", "number": 2374, "title": "[HUDI-845] Added locking capability to allow multiple writers", "bodyText": "Added LockProvider API for pluggable lock methologies\nAdded Resolution Strategy API to allow for pluggable conflict resolution\n\nThis diff -> #2359 is a pre-requisite for landing this PR.\nTips\n\nThank you very much for contributing to Apache Hudi.\nPlease review https://hudi.apache.org/contributing.html before opening a pull request.\n\nWhat is the purpose of the pull request\n(For example: This pull request adds quick-start document.)\nBrief change log\n(for example:)\n\nModify AnnotationLocation checkstyle rule in checkstyle.xml\n\nVerify this pull request\n(Please pick either of the following options)\nThis pull request is a trivial rework / code cleanup without any test coverage.\n(or)\nThis pull request is already covered by existing tests, such as (please describe tests).\n(or)\nThis change added tests and can be verified as follows:\n(example:)\n\nAdded integration tests for end-to-end.\nAdded HoodieClientWriteTest to verify the change.\nManually verified the change by running a job locally.\n\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-12-24T06:35:33Z", "url": "https://github.com/apache/hudi/pull/2374", "merged": true, "mergeCommit": {"oid": "74241947c123c860a1b0344f25cef316440a70d6"}, "closed": true, "closedAt": "2021-03-16T23:43:54Z", "author": {"login": "n3nash"}, "timelineItems": {"totalCount": 78, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdqfBPaABqjQxNTA5OTE3MzU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABeDwWmCgBqjQ0NjU5Njk0OTU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f2fc4586ced00590cc925ad29c017a4463dc368e", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/f2fc4586ced00590cc925ad29c017a4463dc368e", "committedDate": "2020-12-24T06:33:02Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution"}, "afterCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/592e4bda9aed9af895b60db0d07393b2a6916d30", "committedDate": "2020-12-28T05:09:44Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5MzYyMzE1", "url": "https://github.com/apache/hudi/pull/2374#pullrequestreview-559362315", "createdAt": "2020-12-29T03:00:21Z", "commit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "state": "COMMENTED", "comments": {"totalCount": 30, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQwMzowMDoyMVrOIMF6SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQwMzoyMzoyOVrOIMGIAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MDY2NA==", "bodyText": "AtomicReference to handle multiple threads using the same client object? +1", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549550664", "createdAt": "2020-12-29T03:00:21Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java", "diffHunk": "@@ -48,6 +50,7 @@\n   protected final transient Configuration hadoopConf;\n   protected final HoodieWriteConfig config;\n   protected final String basePath;\n+  protected AtomicReference<Option<HoodieInstant>> latestWriteInstantCompletedBeforeWriter = new AtomicReference<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MDc1Ng==", "bodyText": "Since this is specific to writing, can we put this in the AbstractHoodieWriteClient subclass?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549550756", "createdAt": "2020-12-29T03:01:08Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java", "diffHunk": "@@ -48,6 +50,7 @@\n   protected final transient Configuration hadoopConf;\n   protected final HoodieWriteConfig config;\n   protected final String basePath;\n+  protected AtomicReference<Option<HoodieInstant>> latestWriteInstantCompletedBeforeWriter = new AtomicReference<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MDY2NA=="}, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MDk3Ng==", "bodyText": "use the concurrency mode config introduced by the other PR and use that instead to fence this block?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549550976", "createdAt": "2020-12-29T03:02:40Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTAzNg==", "bodyText": "some more context on basePath, inner exception if any ?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551036", "createdAt": "2020-12-29T03:03:08Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n+          lockConfiguration, fs.getConf());\n+      try {\n+        // TODO : Get timeout and set the timeout\n+        boolean acquired = lockProvider.tryLock();\n+        if (!acquired) {\n+          throw new HoodieException(\"Unable to acquire lock\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTE2Mg==", "bodyText": "is TODO still valid?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551162", "createdAt": "2020-12-29T03:03:47Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n+          lockConfiguration, fs.getConf());\n+      try {\n+        // TODO : Get timeout and set the timeout\n+        boolean acquired = lockProvider.tryLock();\n+        if (!acquired) {\n+          throw new HoodieException(\"Unable to acquire lock\");\n+        }\n+        LOG.info(\"Acquired lock for instant time \" + instantTime);\n+        // TODO : Move the following to a \"critical section\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTIzNw==", "bodyText": "We need a new Exception class here. HoodieWriteConflictException or sth", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551237", "createdAt": "2020-12-29T03:04:23Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n+          lockConfiguration, fs.getConf());\n+      try {\n+        // TODO : Get timeout and set the timeout\n+        boolean acquired = lockProvider.tryLock();\n+        if (!acquired) {\n+          throw new HoodieException(\"Unable to acquire lock\");\n+        }\n+        LOG.info(\"Acquired lock for instant time \" + instantTime);\n+        // TODO : Move the following to a \"critical section\"\n+        // Create a Hoodie table which encapsulated the commits and files visible.\n+        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+        HoodieTable table = createTable(config, hadoopConf);\n+        try {\n+          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n+          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+        } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTI4OQ==", "bodyText": "why unlock here again, when you do it in finally", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551289", "createdAt": "2020-12-29T03:04:36Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n+          lockConfiguration, fs.getConf());\n+      try {\n+        // TODO : Get timeout and set the timeout\n+        boolean acquired = lockProvider.tryLock();\n+        if (!acquired) {\n+          throw new HoodieException(\"Unable to acquire lock\");\n+        }\n+        LOG.info(\"Acquired lock for instant time \" + instantTime);\n+        // TODO : Move the following to a \"critical section\"\n+        // Create a Hoodie table which encapsulated the commits and files visible.\n+        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+        HoodieTable table = createTable(config, hadoopConf);\n+        try {\n+          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n+          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+        } catch (Exception e) {\n+          // if strategy throws exception, first release lock\n+          lockProvider.unlock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTYyMA==", "bodyText": "I was expecting to use the atomic reference above. and just pull all the writes that happened after the latestWriteInstantCompletedBeforeWriter ? Also lets not assume that time in seconds is what we will use here.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551620", "createdAt": "2020-12-29T03:06:36Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -821,6 +865,38 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n+                                            HoodieCommitMetadata thisCommitMetadata) {\n+    Long currentTimeInSecs = System.currentTimeMillis() / 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTc1NA==", "bodyText": "can we move the reflection part to the config object?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551754", "createdAt": "2020-12-29T03:07:16Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTc5Ng==", "bodyText": "typos", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551796", "createdAt": "2020-12-29T03:07:34Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -821,6 +865,38 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n+                                            HoodieCommitMetadata thisCommitMetadata) {\n+    Long currentTimeInSecs = System.currentTimeMillis() / 1000;\n+    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n+        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n+    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .getCommitsAndCompactionTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsInRange(lastInstantTimestamp, String.valueOf(currentTimeInSecs))\n+        .getInstants();\n+\n+    LOG.info(\"Current eligible instants during write oHoodieWriteConfigf instant \" + instantTime + \" = \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjI0MQ==", "bodyText": "we should probably have an API to resolveConflict(instant1, instant2) ? i.e like our preCombine method? that will give resolutionStrategy implementors to just reason between two instants and whether they conflict or not, and if they do, then munge the commit metadata somehow.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552241", "createdAt": "2020-12-29T03:10:10Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -821,6 +865,38 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n+                                            HoodieCommitMetadata thisCommitMetadata) {\n+    Long currentTimeInSecs = System.currentTimeMillis() / 1000;\n+    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n+        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n+    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .getCommitsAndCompactionTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsInRange(lastInstantTimestamp, String.valueOf(currentTimeInSecs))\n+        .getInstants();\n+\n+    LOG.info(\"Current eligible instants during write oHoodieWriteConfigf instant \" + instantTime + \" = \"\n+        + instantStream.collect(Collectors.toList()));\n+\n+    boolean hasConflict = instantStream.anyMatch(instant -> {\n+      try {\n+        return resolutionStrategy.hasConflict(thisCommitMetadata, HoodieCommitMetadata.fromBytes(\n+            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class));\n+      } catch (IOException io) {\n+        throw new HoodieCommitException(\"Unable to determine if conflict exists\", io);\n+      }\n+    });\n+    HoodieCommitMetadata newMetadataAfterConflictResolution = thisCommitMetadata;\n+    if (hasConflict) {\n+      newMetadataAfterConflictResolution = resolutionStrategy.resolveConflict(config, hadoopConf);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjMxNA==", "bodyText": "throw a special purpose exception here please", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552314", "createdAt": "2020-12-29T03:10:51Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public class ConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitMetadata firstInstant, HoodieCommitMetadata secondInstant) {\n+    // TODO : Ensure file ids are only the UUID and not the full name, also cann UUID's clash then for insert/insert ?\n+    Set<String> fileIdsSetForFirstInstant = firstInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+    Set<String> fileIdsSetForSecondInstant = secondInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public HoodieCommitMetadata resolveConflict(HoodieWriteConfig config, Configuration configuration) {\n+    throw new UnsupportedOperationException(\"Cannot resolve conflicts for overlapping writes\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjMzMg==", "bodyText": "more information on these logs", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552332", "createdAt": "2020-12-29T03:11:04Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public class ConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitMetadata firstInstant, HoodieCommitMetadata secondInstant) {\n+    // TODO : Ensure file ids are only the UUID and not the full name, also cann UUID's clash then for insert/insert ?\n+    Set<String> fileIdsSetForFirstInstant = firstInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+    Set<String> fileIdsSetForSecondInstant = secondInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes \" + intersection);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjQzNQ==", "bodyText": "please add APIMaturity annotations and javadocs.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552435", "createdAt": "2020-12-29T03:11:48Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,35 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+\n+/**\n+ * Strategy for conflict resolution with multiple writers. Provide pluggable implementations for different\n+ * kinds of strategies to execute to resolve conflicts when multiple writers are mutating the hoodie table.\n+ */\n+public interface ConflictResolutionStrategy {\n+\n+  boolean hasConflict(HoodieCommitMetadata c1, HoodieCommitMetadata c2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjU0OQ==", "bodyText": "please use FSUtils.getFS() always ! to get the filesystem object", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552549", "createdAt": "2020-12-29T03:12:40Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.exception.HoodieLockException;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.FILESYSTEM_LOCK_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+/**\n+ * This lock provider is used to testing purposes only. It provides a simple file system based lock using HDFS atomic\n+ * create operation. This lock does not support cleaning/expiring the lock after a failed write hence cannot be used\n+ * in production environments.\n+ */\n+public class FileSystemBasedLockProvider extends LockProvider {\n+\n+  private static final String LOCK_NAME = \"acquired\";\n+\n+  private String lockPath;\n+  private FileSystem fs;\n+\n+  public FileSystemBasedLockProvider(LockConfiguration lockConfiguration, final Configuration configuration) {\n+    try {\n+      this.lockConfiguration = lockConfiguration;\n+      this.lockPath = lockConfiguration.getConfig().getString(FILESYSTEM_LOCK_PATH_PROP);\n+      this.fs = FileSystem.get(configuration);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1Mjk1NA==", "bodyText": "whats the guarantee that unlock() will fail for thread B, if thread A had actually created the lock file. Don't think this will work. We should remove this implementation, if we cannot get it right IMO", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552954", "createdAt": "2020-12-29T03:15:09Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.exception.HoodieLockException;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.FILESYSTEM_LOCK_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+/**\n+ * This lock provider is used to testing purposes only. It provides a simple file system based lock using HDFS atomic\n+ * create operation. This lock does not support cleaning/expiring the lock after a failed write hence cannot be used\n+ * in production environments.\n+ */\n+public class FileSystemBasedLockProvider extends LockProvider {\n+\n+  private static final String LOCK_NAME = \"acquired\";\n+\n+  private String lockPath;\n+  private FileSystem fs;\n+\n+  public FileSystemBasedLockProvider(LockConfiguration lockConfiguration, final Configuration configuration) {\n+    try {\n+      this.lockConfiguration = lockConfiguration;\n+      this.lockPath = lockConfiguration.getConfig().getString(FILESYSTEM_LOCK_PATH_PROP);\n+      this.fs = FileSystem.get(configuration);\n+    } catch (IOException io) {\n+      throw new HoodieIOException(\"Unable to create file systems\", io);\n+    }\n+  }\n+\n+  @Override\n+  public void acquireLock() {\n+    try {\n+      fs.create(new Path(lockPath + \"/\" + LOCK_NAME)).close();\n+    } catch (IOException e) {\n+      throw new HoodieIOException(\"Failed to acquire lock\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    fs.close();\n+  }\n+\n+  @Override\n+  public boolean tryLock() {\n+    try {\n+      int numRetries = 0;\n+      while (fs.exists(new Path(lockPath + \"/\" + LOCK_NAME))\n+          && (numRetries <= lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP))) {\n+        Thread.sleep(lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP));\n+      }\n+      acquireLock();\n+      return true;\n+    } catch (IOException | InterruptedException e) {\n+      throw new HoodieLockException(\"Failed to acquire lock\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void unlock() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzAyNA==", "bodyText": "which is indeed hard. I dont its possible on cloud stores.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553024", "createdAt": "2020-12-29T03:15:30Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.exception.HoodieLockException;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.FILESYSTEM_LOCK_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+/**\n+ * This lock provider is used to testing purposes only. It provides a simple file system based lock using HDFS atomic\n+ * create operation. This lock does not support cleaning/expiring the lock after a failed write hence cannot be used\n+ * in production environments.\n+ */\n+public class FileSystemBasedLockProvider extends LockProvider {\n+\n+  private static final String LOCK_NAME = \"acquired\";\n+\n+  private String lockPath;\n+  private FileSystem fs;\n+\n+  public FileSystemBasedLockProvider(LockConfiguration lockConfiguration, final Configuration configuration) {\n+    try {\n+      this.lockConfiguration = lockConfiguration;\n+      this.lockPath = lockConfiguration.getConfig().getString(FILESYSTEM_LOCK_PATH_PROP);\n+      this.fs = FileSystem.get(configuration);\n+    } catch (IOException io) {\n+      throw new HoodieIOException(\"Unable to create file systems\", io);\n+    }\n+  }\n+\n+  @Override\n+  public void acquireLock() {\n+    try {\n+      fs.create(new Path(lockPath + \"/\" + LOCK_NAME)).close();\n+    } catch (IOException e) {\n+      throw new HoodieIOException(\"Failed to acquire lock\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    fs.close();\n+  }\n+\n+  @Override\n+  public boolean tryLock() {\n+    try {\n+      int numRetries = 0;\n+      while (fs.exists(new Path(lockPath + \"/\" + LOCK_NAME))\n+          && (numRetries <= lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP))) {\n+        Thread.sleep(lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP));\n+      }\n+      acquireLock();\n+      return true;\n+    } catch (IOException | InterruptedException e) {\n+      throw new HoodieLockException(\"Failed to acquire lock\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void unlock() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1Mjk1NA=="}, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzEyMg==", "bodyText": "more context?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553122", "createdAt": "2020-12-29T03:16:07Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;\n+  private final AtomicReference<InterProcessMutex> lock = new AtomicReference<>();\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .namespace(lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFramework) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = curatorFramework;\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+  }\n+  \n+  @Override\n+  public void acquireLock() throws Exception {\n+    ValidationUtils.checkArgument(this.lock.get() == null, \"Lock is already acquired\");\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    newLock.acquire();\n+    lock.compareAndSet(null, newLock);\n+  }\n+\n+  @Override\n+  public boolean tryLock() {\n+    LOG.info(\"Trying to acquire lock for ZkBasePath \" + lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP)\n+        + \" and lock key \" + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    try {\n+      acquireLock();\n+    } catch (Exception e) {\n+      throw new HoodieLockException(\"Unable to acquire lock\", e);\n+    }\n+    return lock.get() != null && lock.get().isAcquiredInThisProcess();\n+  }\n+\n+  @Override\n+  public void unlock() {\n+    try {\n+      LOG.info(\"Releasing lock for ZkBasePath \"\n+          + lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \" and lock key \"\n+          + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+      if (lock.get() == null) {\n+        return;\n+      }\n+      lock.get().release();\n+      lock.set(null);\n+      LOG.info(\"Released lock\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzI3Mw==", "bodyText": "lets drop the HOODIE_ prefix from the properties, per how we have named the configs thus far", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553273", "createdAt": "2020-12-29T03:16:50Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.config;\n+\n+import org.apache.hudi.client.lock.ConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.FileSystemBasedLockProvider;\n+import org.apache.hudi.common.config.DefaultHoodieConfig;\n+import org.apache.hudi.common.lock.LockProvider;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_HOODIE_LOCK_ACQUIRE_NUM_RETRIES;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_DATABASE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_TABLE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_PREFIX;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_PORT_PROP;\n+\n+/**\n+ * Write callback related config.\n+ */\n+public class HoodieLockConfig extends DefaultHoodieConfig {\n+\n+  // Pluggable type of lock provider\n+  public static final String HOODIE_LOCK_PROVIDER_CLASS_PROP = HOODIE_LOCK_PREFIX + \"provider\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzM2Ng==", "bodyText": "repeating my earlier comment; lets just use the concurrency mode config from the other PR .", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553366", "createdAt": "2020-12-29T03:17:26Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -122,6 +123,10 @@\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n+  // Enable multi writer support\n+  private static final String HOODIE_TABLE_MULTIWRITER_ENABLED_PROP = \"hoodie.table.multiwriter.enabled\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzU2MA==", "bodyText": "so, I was expecting we will do some kind of atomic swap, not just a set. if you just want to set, even a volatile variable is fine right?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553560", "createdAt": "2020-12-29T03:18:41Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -385,6 +386,10 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n     } else {\n       writeTimer = metrics.getDeltaCommitCtx();\n     }\n+    latestWriteInstantCompletedBeforeWriter.set(table.getMetaClient().getActiveTimeline().getAllCommitsTimeline()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzYyMg==", "bodyText": "why is this relevant here?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553622", "createdAt": "2020-12-29T03:19:07Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/cluster/SparkExecuteClusteringCommitActionExecutor.java", "diffHunk": "@@ -118,7 +118,7 @@ public SparkExecuteClusteringCommitActionExecutor(HoodieEngineContext context,\n       Schema readerSchema = HoodieAvroUtils.addMetadataFields(new Schema.Parser().parse(config.getSchema()));\n       return ((ClusteringExecutionStrategy<T, JavaRDD<HoodieRecord<? extends HoodieRecordPayload>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>>)\n           ReflectionUtils.loadClass(config.getClusteringExecutionStrategyClass(), table, context, config))\n-          .performClustering(inputRecords, clusteringGroup.getNumOutputFileGroups(), instantTime, strategyParams, readerSchema);\n+          .performClustering(inputRecords, 0, instantTime, strategyParams, readerSchema);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzY3Mw==", "bodyText": "back these changes out?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553673", "createdAt": "2020-12-29T03:19:33Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/scala/org/apache/hudi/AvroConversionHelper.scala", "diffHunk": "@@ -314,7 +313,7 @@ object AvroConversionHelper {\n           } else {\n             val sourceArray = item.asInstanceOf[Seq[Any]]\n             val sourceArraySize = sourceArray.size\n-            val targetList = new util.ArrayList[Any](sourceArraySize)\n+            val targetList = new java.util.ArrayList[Any](sourceArraySize)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1Mzc1Mw==", "bodyText": "lets add a new test around the multi writing please. it should ideally be agnostic of COW/MOR. and we can just test MOR.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553753", "createdAt": "2020-12-29T03:20:06Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/client/TestHoodieClientOnCopyOnWriteStorage.java", "diffHunk": "@@ -216,6 +222,71 @@ public void testDeduplicationOnUpsert() throws Exception {\n     testDeduplication(SparkRDDWriteClient::upsert);\n   }\n \n+  @Test\n+  public void testMultiWriter() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzgwMQ==", "bodyText": "Drop the HOODIE_ ?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553801", "createdAt": "2020-12-29T03:20:27Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.config;\n+\n+import java.util.Properties;\n+\n+/**\n+ * Configuration for managing locks. Since this configuration needs to be shared with HiveMetaStore based lock,\n+ * which is in a different package than other lock providers, we use this as a data transfer object in hoodie-common\n+ */\n+public class LockConfiguration {\n+\n+  public static final String HOODIE_LOCK_PREFIX = \"hoodie.writer.lock.\";\n+  public static final String HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = HOODIE_LOCK_PREFIX + \"wait_time_ms\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzgzOQ==", "bodyText": "whats the reason to have this in hudi-common? locking is only used by writing correct.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553839", "createdAt": "2020-12-29T03:20:53Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.config;\n+\n+import java.util.Properties;\n+\n+/**\n+ * Configuration for managing locks. Since this configuration needs to be shared with HiveMetaStore based lock,\n+ * which is in a different package than other lock providers, we use this as a data transfer object in hoodie-common\n+ */\n+public class LockConfiguration {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzkwNg==", "bodyText": "can this be an interface?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553906", "createdAt": "2020-12-29T03:21:25Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider implements Lock, AutoCloseable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1NDA3Mw==", "bodyText": "we should probably support this right. even of the lock() , since this has a timeout param?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549554073", "createdAt": "2020-12-29T03:22:42Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider implements Lock, AutoCloseable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n+\n+  protected LockConfiguration lockConfiguration;\n+\n+  protected abstract void acquireLock() throws Exception;\n+\n+  @Override\n+  public final void lock() {\n+    LOG.info(\"Acquiring lock\");\n+    try {\n+      acquireLock();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+    LOG.info(\"Acquired lock\");\n+  }\n+\n+  @Override\n+  public final void lockInterruptibly() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final boolean tryLock(long time, TimeUnit unit) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1NDE0Mg==", "bodyText": "can this sit somewhere else? in a helper method?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549554142", "createdAt": "2020-12-29T03:23:13Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommitMetadata.java", "diffHunk": "@@ -109,6 +108,17 @@ public void setCompacted(Boolean compacted) {\n     return filePaths;\n   }\n \n+  public HashMap<String, String> getFileIdWithoutSuffixAndRelativePaths() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1NDE3OQ==", "bodyText": "why this change?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549554179", "createdAt": "2020-12-29T03:23:29Z", "author": {"login": "vinothchandar"}, "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/GenericRecordFullPayloadGenerator.java", "diffHunk": "@@ -284,7 +284,7 @@ private Object typeConvert(Schema.Field field) {\n   private Object generateFixedType(Schema localSchema) {\n     // TODO: Need to implement valid data generation for fixed type\n     GenericFixed genericFixed = new GenericData.Fixed(localSchema);\n-    switch (localSchema.getLogicalType().getName()) {\n+    switch (localSchema.getType().getName()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30"}, "originalPosition": 5}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c2f054f6174c8d82a04b21e838ad2c3c7fe30035", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/c2f054f6174c8d82a04b21e838ad2c3c7fe30035", "committedDate": "2021-01-03T08:39:19Z", "message": "Addresing code review comments"}, "afterCommit": {"oid": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/98c3c7ddf879d514e5c14293fee145c92f9416a3", "committedDate": "2021-01-03T08:40:52Z", "message": "Addresing code review comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/98c3c7ddf879d514e5c14293fee145c92f9416a3", "committedDate": "2021-01-03T08:40:52Z", "message": "Addresing code review comments"}, "afterCommit": {"oid": "32df18ea69b24a19cda150875cdc636075544589", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/32df18ea69b24a19cda150875cdc636075544589", "committedDate": "2021-01-05T05:43:36Z", "message": "Addresing code review comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "32df18ea69b24a19cda150875cdc636075544589", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/32df18ea69b24a19cda150875cdc636075544589", "committedDate": "2021-01-05T05:43:36Z", "message": "Addresing code review comments"}, "afterCommit": {"oid": "d81016bdc87968e58e1fcd8809b65000b1a64ff5", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/d81016bdc87968e58e1fcd8809b65000b1a64ff5", "committedDate": "2021-01-05T05:58:50Z", "message": "Addresing code review comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d81016bdc87968e58e1fcd8809b65000b1a64ff5", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/d81016bdc87968e58e1fcd8809b65000b1a64ff5", "committedDate": "2021-01-05T05:58:50Z", "message": "Addresing code review comments"}, "afterCommit": {"oid": "21792c6722dd32dddbc5b6ec743549610cd9a8e0", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/21792c6722dd32dddbc5b6ec743549610cd9a8e0", "committedDate": "2021-01-05T08:20:25Z", "message": "Addresing code review comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "21792c6722dd32dddbc5b6ec743549610cd9a8e0", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/21792c6722dd32dddbc5b6ec743549610cd9a8e0", "committedDate": "2021-01-05T08:20:25Z", "message": "Addresing code review comments"}, "afterCommit": {"oid": "7f975c1dbae58d16c244968b2d7ebaae5f3f99ac", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/7f975c1dbae58d16c244968b2d7ebaae5f3f99ac", "committedDate": "2021-01-08T08:08:13Z", "message": "Addresing code review comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7f975c1dbae58d16c244968b2d7ebaae5f3f99ac", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/7f975c1dbae58d16c244968b2d7ebaae5f3f99ac", "committedDate": "2021-01-08T08:08:13Z", "message": "Addresing code review comments"}, "afterCommit": {"oid": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "committedDate": "2021-01-19T05:18:21Z", "message": "Addresing code review comments and other refactoring"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "committedDate": "2021-01-19T05:18:21Z", "message": "Addresing code review comments and other refactoring"}, "afterCommit": {"oid": "ccc5f9a486b3cb3829359339d858c2dc827e84b9", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/ccc5f9a486b3cb3829359339d858c2dc827e84b9", "committedDate": "2021-01-19T05:19:50Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ccc5f9a486b3cb3829359339d858c2dc827e84b9", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/ccc5f9a486b3cb3829359339d858c2dc827e84b9", "committedDate": "2021-01-19T05:19:50Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution"}, "afterCommit": {"oid": "15157b355d6e977f06c705097eecb22bbd415752", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/15157b355d6e977f06c705097eecb22bbd415752", "committedDate": "2021-01-19T05:27:44Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "15157b355d6e977f06c705097eecb22bbd415752", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/15157b355d6e977f06c705097eecb22bbd415752", "committedDate": "2021-01-19T05:27:44Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "3a462df23a85a66d9e2237ea9d20a47815f1becb", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/3a462df23a85a66d9e2237ea9d20a47815f1becb", "committedDate": "2021-01-19T07:32:22Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3a462df23a85a66d9e2237ea9d20a47815f1becb", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/3a462df23a85a66d9e2237ea9d20a47815f1becb", "committedDate": "2021-01-19T07:32:22Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "8750225e15ade84d4182cbf4c2966cccf6f78c70", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8750225e15ade84d4182cbf4c2966cccf6f78c70", "committedDate": "2021-01-20T09:08:57Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8750225e15ade84d4182cbf4c2966cccf6f78c70", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8750225e15ade84d4182cbf4c2966cccf6f78c70", "committedDate": "2021-01-20T09:08:57Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "97180d4ab0c6c988aa95ac566f63d249dbdbb2dd", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/97180d4ab0c6c988aa95ac566f63d249dbdbb2dd", "committedDate": "2021-01-20T18:03:23Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "97180d4ab0c6c988aa95ac566f63d249dbdbb2dd", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/97180d4ab0c6c988aa95ac566f63d249dbdbb2dd", "committedDate": "2021-01-20T18:03:23Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "7ababeac2cb1c0735a3dff9434522b99fa4f1580", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/7ababeac2cb1c0735a3dff9434522b99fa4f1580", "committedDate": "2021-01-21T05:29:04Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7ababeac2cb1c0735a3dff9434522b99fa4f1580", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/7ababeac2cb1c0735a3dff9434522b99fa4f1580", "committedDate": "2021-01-21T05:29:04Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8b8d5945136066148f200d30c5d3bf6d5be70cbf", "committedDate": "2021-01-21T19:37:14Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgxNjU3ODQ3", "url": "https://github.com/apache/hudi/pull/2374#pullrequestreview-581657847", "createdAt": "2021-02-02T18:39:07Z", "commit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "state": "COMMENTED", "comments": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxODozOTowOFrOIefT-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQxOTowNjoyMlrOIegXow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0MTIxMQ==", "bodyText": "how about empty instead of null. In general, like to avoid using null for any kind of sentinel", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568841211", "createdAt": "2021-02-02T18:39:08Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -188,6 +203,8 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n       postCommit(table, metadata, instantTime, extraMetadata);\n       emitCommitMetrics(instantTime, metadata, commitActionType);\n       LOG.info(\"Committed \" + instantTime);\n+      // Reset the last completed write instant\n+      latestCompletedWriteInstant.set(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0MjY4Mw==", "bodyText": "whats NO_WRITER ? its kind of difficult to understand . can we remove this", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568842683", "createdAt": "2021-02-02T18:41:25Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Different concurrency modes for write operations.\n+ */\n+public enum WriteConcurrencyMode {\n+  NO_WRITER(\"no_writer\"),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0Mzk3Mw==", "bodyText": "rename to : supportsOptimisticConcurrencyControl() to match mode name.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568843973", "createdAt": "2021-02-02T18:43:35Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Different concurrency modes for write operations.\n+ */\n+public enum WriteConcurrencyMode {\n+  NO_WRITER(\"no_writer\"),\n+  // Only a single writer can perform write ops\n+  SINGLE_WRITER(\"single_writer\"),\n+  // Multiple writer can perform write ops with lazy conflict resolution using locks\n+  OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK(\"optimistic_concurrency_control_shared_lock\");\n+\n+  private final String value;\n+\n+  WriteConcurrencyMode(String value) {\n+    this.value = value;\n+  }\n+\n+  /**\n+   * Getter for write concurrency mode.\n+   * @return\n+   */\n+  public String value() {\n+    return value;\n+  }\n+\n+  /**\n+   * Convert string value to WriteConcurrencyMode.\n+   */\n+  public static WriteConcurrencyMode fromValue(String value) {\n+    switch (value.toLowerCase(Locale.ROOT)) {\n+      case \"no_writer\":\n+        return NO_WRITER;\n+      case \"single_writer\":\n+        return SINGLE_WRITER;\n+      case \"optimistic_concurrency_control_shared_lock\":\n+        return OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+      default:\n+        throw new HoodieException(\"Invalid value of Type.\");\n+    }\n+  }\n+\n+  public boolean isMultiWriter() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0NTEzMw==", "bodyText": "lets just add this to an existing class like CommitUtils", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568845133", "createdAt": "2021-02-02T18:45:35Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/util/CommitMetadataUtils.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.util;\n+\n+import org.apache.hudi.common.fs.FSUtils;\n+import org.apache.hudi.common.model.HoodieWriteStat;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Helper class to manipulate commit metadata.\n+ */\n+public class CommitMetadataUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0NTUzMg==", "bodyText": "should archival be here too?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568845532", "createdAt": "2021-02-02T18:46:13Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Supported runtime table services.\n+ */\n+public enum TableService {\n+  COMPACT(\"compact\"),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0NjIxNg==", "bodyText": "rename: Sting name. I actually don't see the need for this field atm now.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568846216", "createdAt": "2021-02-02T18:47:08Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Supported runtime table services.\n+ */\n+public enum TableService {\n+  COMPACT(\"compact\"),\n+  CLUSTER(\"cluster\"),\n+  CLEAN(\"clean\");\n+  private final String value;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0ODc1MA==", "bodyText": "lets call this  initIfNeeded. to avoid overloading bootstrap which has its own meaning. .", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568848750", "createdAt": "2021-02-02T18:50:49Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -220,7 +253,7 @@ void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String\n     }\n   }\n \n-  protected void syncTableMetadata() {\n+  protected void syncTableMetadata(boolean bootstrapIfNeeded) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MDA4NA==", "bodyText": "Do we need this check with OCC mode? in any case, we should ensure the bootstrap code downgrades to single writer, so users don't have to worry about this. Most people do bootstrap then followed by writing anyway.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568850084", "createdAt": "2021-02-02T18:52:59Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -239,6 +272,9 @@ public void bootstrap(Option<Map<String, String>> extraMetadata) {\n     if (rollbackPending) {\n       rollBackInflightBootstrap();\n     }\n+    if (config.getWriteConcurrencyMode().isMultiWriter()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MDM0OA==", "bodyText": "just double check if the indents are okay here?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568850348", "createdAt": "2021-02-02T18:53:26Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -403,30 +439,32 @@ protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata me\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n \n-      // Do an inline compaction if enabled\n-      if (config.isInlineCompaction()) {\n-        runAnyPendingCompactions(table);\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-        inlineCompact(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-      }\n+      if (config.isInlineTableServiceEnabled()) {\n+        // Do an inline compaction if enabled\n+        if (config.isInlineCompaction()) {\n+          runAnyPendingCompactions(table);\n+          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+          inlineCompact(extraMetadata);\n+        } else {\n+          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n+        }\n \n-      // Do an inline clustering if enabled\n-      if (config.isInlineClustering()) {\n-        runAnyPendingClustering(table);\n-        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-        inlineCluster(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-      }\n+        // Do an inline clustering if enabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MTA3MQ==", "bodyText": "why was this change needed", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568851071", "createdAt": "2021-02-02T18:54:32Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -599,6 +637,7 @@ public HoodieRestoreMetadata restoreToInstant(final String instantTime) throws H\n   public HoodieCleanMetadata clean(String cleanInstantTime) throws HoodieIOException {\n     LOG.info(\"Cleaner started\");\n     final Timer.Context timerContext = metrics.getCleanCtx();\n+    scheduleCleaningAtInstant(cleanInstantTime, Option.empty());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MTkyMw==", "bodyText": "so, this block only enables the inline execution of the table services? or does it also cover the scheduling of cleaning, compaction, clustering etc?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568851923", "createdAt": "2021-02-02T18:55:43Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -403,30 +439,32 @@ protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata me\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n \n-      // Do an inline compaction if enabled\n-      if (config.isInlineCompaction()) {\n-        runAnyPendingCompactions(table);\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-        inlineCompact(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-      }\n+      if (config.isInlineTableServiceEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MjMyNw==", "bodyText": "We should also protect the scheduling, correct? (may be it comes down the line)", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568852327", "createdAt": "2021-02-02T18:56:24Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -403,30 +439,32 @@ protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata me\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n \n-      // Do an inline compaction if enabled\n-      if (config.isInlineCompaction()) {\n-        runAnyPendingCompactions(table);\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-        inlineCompact(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-      }\n+      if (config.isInlineTableServiceEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MTkyMw=="}, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MzAxOQ==", "bodyText": "we should clear annotate/document that this we do not support multiple writers on the same writeClient instance.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568853019", "createdAt": "2021-02-02T18:57:30Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -98,6 +112,7 @@\n   private transient HoodieWriteCommitCallback commitCallback;\n   private transient AsyncCleanerService asyncCleanerService;\n   protected final boolean rollbackPending;\n+  protected AtomicReference<Option<HoodieInstant>> latestCompletedWriteInstant = new AtomicReference<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NDUyMQ==", "bodyText": "can this code sit somewhere else?  we should try to keep the write client file pretty lean and do only the control flow", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568854521", "createdAt": "2021-02-02T18:59:45Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -859,6 +973,68 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 350}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NDc2Ng==", "bodyText": "same with this.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568854766", "createdAt": "2021-02-02T19:00:09Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -859,6 +973,68 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n+                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n+      throws HoodieWriteConflictException {\n+    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n+    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n+        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n+    // Get completed instants timeline\n+    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .getCommitsAndCompactionTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n+\n+    // Get pending replace and compaction instants timeline\n+    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .filterPendingCompactionAndReplaceTimeline()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n+    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n+    instantStream.forEach(instant -> {\n+      try {\n+        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n+            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n+        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n+          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n+              + otherOperation.getInstant() + \", attempting to resolve it now\");\n+          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n+        }\n+      } catch (IOException io) {\n+        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n+      }\n+    });\n+    return thisOperation.getCommitMetadata();\n+  }\n+\n+  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 391}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NTIzNQ==", "bodyText": "please move these comments into the actual implementation. and not in this file", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568855235", "createdAt": "2021-02-02T19:00:51Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -907,11 +1083,20 @@ public void close() {\n     // release AsyncCleanerService\n     AsyncCleanerService.forceShutdown(asyncCleanerService);\n     asyncCleanerService = null;\n-\n     // Stop timeline-server if running\n     super.close();\n     // Calling this here releases any resources used by your index, so make sure to finish any related operations\n     // before this point\n     this.index.close();\n+    // HiveMetastoreClient does not implement AutoCloseable. Additionally, we cannot call close() after unlock()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 425}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NjY3NQ==", "bodyText": "we should check somewhere that user cannot turn on both async and inline? , if we are adding an explicit config.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568856675", "createdAt": "2021-02-02T19:03:17Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java", "diffHunk": "@@ -41,7 +41,8 @@\n   public static final String CLEANER_POLICY_PROP = \"hoodie.cleaner.policy\";\n   public static final String AUTO_CLEAN_PROP = \"hoodie.clean.automatic\";\n   public static final String ASYNC_CLEAN_PROP = \"hoodie.clean.async\";\n-\n+  // Turn on inline cleaning\n+  public static final String INLINE_CLEAN_PROP = \"hoodie.clean.inline\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NzQ3OA==", "bodyText": "this does not read easily. rename inlineCleaningEnabled or shouldCleanInline() or something like tht? (same wherever applicable)", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568857478", "createdAt": "2021-02-02T19:04:40Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -389,6 +397,10 @@ public boolean isAsyncClean() {\n     return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.ASYNC_CLEAN_PROP));\n   }\n \n+  public boolean isInlineCleaning() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1ODA4Ng==", "bodyText": "same. rename inlineTableServices()?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568858086", "createdAt": "2021-02-02T19:05:44Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -923,6 +935,39 @@ public int getMetadataCleanerCommitsRetained() {\n     return Integer.parseInt(props.getProperty(HoodieMetadataConfig.CLEANER_COMMITS_RETAINED_PROP));\n   }\n \n+  /**\n+   * Hoodie Client Lock Configs.\n+   * @return\n+   */\n+\n+  public String getLockProviderClass() {\n+    return props.getProperty(HoodieLockConfig.LOCK_PROVIDER_CLASS_PROP);\n+  }\n+\n+  public String getLockHiveDatabaseName() {\n+    return props.getProperty(HIVE_DATABASE_NAME_PROP);\n+  }\n+\n+  public String getLockHiveTableName() {\n+    return props.getProperty(HIVE_TABLE_NAME_PROP);\n+  }\n+\n+  public ConflictResolutionStrategy getWriteConflictResolutionStrategy() {\n+    return ReflectionUtils.loadClass(props.getProperty(HoodieLockConfig.WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP));\n+  }\n+\n+  public Long getLockAcquireWaitTimeoutInMs() {\n+    return Long.valueOf(props.getProperty(LockConfiguration.LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP));\n+  }\n+\n+  public WriteConcurrencyMode getWriteConcurrencyMode() {\n+    return WriteConcurrencyMode.fromValue(props.getProperty(WRITE_CONCURRENCY_MODE_PROP));\n+  }\n+\n+  public Boolean isInlineTableServiceEnabled() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1ODM5NA==", "bodyText": "rename to initIfNeeded consistently", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568858394", "createdAt": "2021-02-02T19:06:08Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java", "diffHunk": "@@ -88,7 +88,7 @@\n   protected SerializableConfiguration hadoopConf;\n   protected final transient HoodieEngineContext engineContext;\n \n-  protected HoodieBackedTableMetadataWriter(Configuration hadoopConf, HoodieWriteConfig writeConfig, HoodieEngineContext engineContext) {\n+  protected HoodieBackedTableMetadataWriter(Configuration hadoopConf, HoodieWriteConfig writeConfig, HoodieEngineContext engineContext, boolean bootstrapIfNeeded) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1ODUzMQ==", "bodyText": "we can also rename this method if needed", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568858531", "createdAt": "2021-02-02T19:06:22Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java", "diffHunk": "@@ -230,13 +235,18 @@ protected void initTableMetadata() {\n     }\n   }\n \n-  protected void bootstrapIfNeeded(HoodieEngineContext engineContext, HoodieTableMetaClient datasetMetaClient) throws IOException {\n-    HoodieTimer timer = new HoodieTimer().startTimer();\n-    boolean exists = datasetMetaClient.getFs().exists(new Path(metadataWriteConfig.getBasePath(), HoodieTableMetaClient.METAFOLDER_NAME));\n-    if (!exists) {\n-      // Initialize for the first time by listing partitions and files directly from the file system\n-      bootstrapFromFilesystem(engineContext, datasetMetaClient);\n-      metrics.ifPresent(m -> m.updateMetrics(HoodieMetadataMetrics.INITIALIZE_STR, timer.endTimer()));\n+  protected void bootstrapIfNeeded(HoodieEngineContext engineContext, HoodieTableMetaClient datasetMetaClient) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "originalPosition": 32}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8b8d5945136066148f200d30c5d3bf6d5be70cbf", "committedDate": "2021-01-21T19:37:14Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/e93d5994cbca54a8a3eb653437ff3df01df12ee7", "committedDate": "2021-02-04T07:14:03Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/e93d5994cbca54a8a3eb653437ff3df01df12ee7", "committedDate": "2021-02-04T07:14:03Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "340efd27821ca9bfeac3bcf3f2cc616948440e2f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/340efd27821ca9bfeac3bcf3f2cc616948440e2f", "committedDate": "2021-02-04T07:16:17Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "340efd27821ca9bfeac3bcf3f2cc616948440e2f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/340efd27821ca9bfeac3bcf3f2cc616948440e2f", "committedDate": "2021-02-04T07:16:17Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "09ba2a5ee6bd79ad616dd7cab835a8511878024b", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/09ba2a5ee6bd79ad616dd7cab835a8511878024b", "committedDate": "2021-02-06T07:32:46Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "09ba2a5ee6bd79ad616dd7cab835a8511878024b", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/09ba2a5ee6bd79ad616dd7cab835a8511878024b", "committedDate": "2021-02-06T07:32:46Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "622880bf42140bb1e1df1874b8cce9f08c4a876d", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/622880bf42140bb1e1df1874b8cce9f08c4a876d", "committedDate": "2021-02-06T08:16:24Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "622880bf42140bb1e1df1874b8cce9f08c4a876d", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/622880bf42140bb1e1df1874b8cce9f08c4a876d", "committedDate": "2021-02-06T08:16:24Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "committedDate": "2021-02-08T01:14:16Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "committedDate": "2021-02-08T01:14:16Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/f5a56cb4137b5f32af17405277c29d5a9088b6c7", "committedDate": "2021-02-08T05:00:58Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/f5a56cb4137b5f32af17405277c29d5a9088b6c7", "committedDate": "2021-02-08T05:00:58Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "21214cb86a490dc3e2f604a8419130ca9db2045a", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/21214cb86a490dc3e2f604a8419130ca9db2045a", "committedDate": "2021-02-08T06:00:21Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bc964dc381b9f831e3e0af941620f10f816be7d4", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/bc964dc381b9f831e3e0af941620f10f816be7d4", "committedDate": "2021-02-09T07:22:44Z", "message": "refactoring"}, "afterCommit": {"oid": "5f8950131414859ddc28a32fd3002eb1eb590e9b", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/5f8950131414859ddc28a32fd3002eb1eb590e9b", "committedDate": "2021-02-09T18:15:47Z", "message": "refactoring"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5f8950131414859ddc28a32fd3002eb1eb590e9b", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/5f8950131414859ddc28a32fd3002eb1eb590e9b", "committedDate": "2021-02-09T18:15:47Z", "message": "refactoring"}, "afterCommit": {"oid": "11dcecf844466de7421139e5254f48ecc467f59c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/11dcecf844466de7421139e5254f48ecc467f59c", "committedDate": "2021-02-09T20:30:49Z", "message": "refactoring"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "11dcecf844466de7421139e5254f48ecc467f59c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/11dcecf844466de7421139e5254f48ecc467f59c", "committedDate": "2021-02-09T20:30:49Z", "message": "refactoring"}, "afterCommit": {"oid": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/49dec09bfb444866e678fe956b28c3bf0ad2f373", "committedDate": "2021-02-15T03:57:26Z", "message": "refactoring"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/49dec09bfb444866e678fe956b28c3bf0ad2f373", "committedDate": "2021-02-15T03:57:26Z", "message": "refactoring"}, "afterCommit": {"oid": "d155914cd673d7699bb5258e6f9cafb85059673a", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/d155914cd673d7699bb5258e6f9cafb85059673a", "committedDate": "2021-02-18T09:11:04Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d155914cd673d7699bb5258e6f9cafb85059673a", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/d155914cd673d7699bb5258e6f9cafb85059673a", "committedDate": "2021-02-18T09:11:04Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "8f2bd5f5539fa72267c4c73c03068e9384df646f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8f2bd5f5539fa72267c4c73c03068e9384df646f", "committedDate": "2021-02-19T07:56:26Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8f2bd5f5539fa72267c4c73c03068e9384df646f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8f2bd5f5539fa72267c4c73c03068e9384df646f", "committedDate": "2021-02-19T07:56:26Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "9d857ed63bba87ec2528eb26bae1e69216814bdd", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/9d857ed63bba87ec2528eb26bae1e69216814bdd", "committedDate": "2021-02-19T22:24:42Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9d857ed63bba87ec2528eb26bae1e69216814bdd", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/9d857ed63bba87ec2528eb26bae1e69216814bdd", "committedDate": "2021-02-19T22:24:42Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "93cdfc8b6d57570cca44070d2f2498b25ad16741", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/93cdfc8b6d57570cca44070d2f2498b25ad16741", "committedDate": "2021-02-19T23:59:23Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "93cdfc8b6d57570cca44070d2f2498b25ad16741", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/93cdfc8b6d57570cca44070d2f2498b25ad16741", "committedDate": "2021-02-19T23:59:23Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/0552abcc6400675c11ee35a4d4f3df109463f6f5", "committedDate": "2021-02-20T06:59:14Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/0552abcc6400675c11ee35a4d4f3df109463f6f5", "committedDate": "2021-02-20T06:59:14Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "ab566b2002a39ebcc98cf5f16d2dc478bcbd1b29", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/ab566b2002a39ebcc98cf5f16d2dc478bcbd1b29", "committedDate": "2021-02-20T07:27:02Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ab566b2002a39ebcc98cf5f16d2dc478bcbd1b29", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/ab566b2002a39ebcc98cf5f16d2dc478bcbd1b29", "committedDate": "2021-02-20T07:27:02Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "289e45a28da6b91fba2a824ec2af3771a34b2930", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/289e45a28da6b91fba2a824ec2af3771a34b2930", "committedDate": "2021-02-20T08:11:15Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "289e45a28da6b91fba2a824ec2af3771a34b2930", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/289e45a28da6b91fba2a824ec2af3771a34b2930", "committedDate": "2021-02-20T08:11:15Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "22b7a6a8e45945ce7175556e0c409263e8ffdc87", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/22b7a6a8e45945ce7175556e0c409263e8ffdc87", "committedDate": "2021-02-21T23:04:20Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "22b7a6a8e45945ce7175556e0c409263e8ffdc87", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/22b7a6a8e45945ce7175556e0c409263e8ffdc87", "committedDate": "2021-02-21T23:04:20Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "15e25022abe1c2f4f1dff00057ad4d18860fb762", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/15e25022abe1c2f4f1dff00057ad4d18860fb762", "committedDate": "2021-02-22T00:28:39Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "15e25022abe1c2f4f1dff00057ad4d18860fb762", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/15e25022abe1c2f4f1dff00057ad4d18860fb762", "committedDate": "2021-02-22T00:28:39Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "44a9129e627e3a61421bb130c816e2781bdd2eed", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/44a9129e627e3a61421bb130c816e2781bdd2eed", "committedDate": "2021-02-22T06:39:46Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "44a9129e627e3a61421bb130c816e2781bdd2eed", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/44a9129e627e3a61421bb130c816e2781bdd2eed", "committedDate": "2021-02-22T06:39:46Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/df38dccc1f6c2193479d23ab62f4f24f27908b55", "committedDate": "2021-03-01T01:17:46Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/df38dccc1f6c2193479d23ab62f4f24f27908b55", "committedDate": "2021-03-01T01:17:46Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "2d7d8901533555af7512dc4bc5c3deb489d503c7", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/2d7d8901533555af7512dc4bc5c3deb489d503c7", "committedDate": "2021-03-01T01:50:20Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2d7d8901533555af7512dc4bc5c3deb489d503c7", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/2d7d8901533555af7512dc4bc5c3deb489d503c7", "committedDate": "2021-03-01T01:50:20Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/61275eac2605bdb087762050588603bab4c4ee2d", "committedDate": "2021-03-01T06:22:45Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/61275eac2605bdb087762050588603bab4c4ee2d", "committedDate": "2021-03-01T06:22:45Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "4b0c990fea2cbacbbba92cdc4a96bb48a625653f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/4b0c990fea2cbacbbba92cdc4a96bb48a625653f", "committedDate": "2021-03-04T05:18:23Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4b0c990fea2cbacbbba92cdc4a96bb48a625653f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/4b0c990fea2cbacbbba92cdc4a96bb48a625653f", "committedDate": "2021-03-04T05:18:23Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/27bae91298c897984335b1c6c3b39e758d962e6b", "committedDate": "2021-03-04T07:50:21Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAzNjc2MTk2", "url": "https://github.com/apache/hudi/pull/2374#pullrequestreview-603676196", "createdAt": "2021-03-04T03:37:54Z", "commit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 57, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQwMzozNzo1NFrOIv2rtg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQxOToyMDowMFrOIwhevA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA0OTkxMA==", "bodyText": "lock as a package name feels off to me. Can we have org.apache.hudi.client.transaction.TransactionManager?\nThen .lock can be a sub package under i.e .transaction.lock.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587049910", "createdAt": "2021-03-04T03:37:54Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -30,16 +31,19 @@\n import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n+import org.apache.hudi.client.lock.TransactionManager;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1MDU3NA==", "bodyText": "So, model package should just contain pojos i.e data structure objects. Lets move TableService elsewhere", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587050574", "createdAt": "2021-03-04T03:38:45Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -30,16 +31,19 @@\n import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n+import org.apache.hudi.client.lock.TransactionManager;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n import org.apache.hudi.common.model.HoodieKey;\n import org.apache.hudi.common.model.HoodieRecordPayload;\n import org.apache.hudi.common.model.HoodieWriteStat;\n+import org.apache.hudi.common.model.TableService;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1MTc5OA==", "bodyText": "lets move the preCommit() call out of here? commit() calling preCommit() is bit confusing to read", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587051798", "createdAt": "2021-03-04T03:40:26Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -193,8 +200,22 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1MjIyMg==", "bodyText": "typo: not supported", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587052222", "createdAt": "2021-03-04T03:40:59Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -210,6 +231,11 @@ void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String\n     }\n   }\n \n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // no-op\n+    // TODO : Conflict resolution is not support for Flink,Java engines", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NDQxMA==", "bodyText": "can the above setters be passed to an overloaded beginTransaction(..) call? Whenever we have these contracts that some setters must be called ahead of a beginTransaction, makes for a harder maintenance/read", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587054410", "createdAt": "2021-03-04T03:43:34Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -359,10 +388,21 @@ public abstract O bulkInsertPreppedRecords(I preppedRecords, final String instan\n    * Common method containing steps to be performed before write (upsert/insert/...\n    * @param instantTime\n    * @param writeOperationType\n+   * @param metaClient\n    */\n-  protected void preWrite(String instantTime, WriteOperationType writeOperationType) {\n+  protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n+      HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    syncTableMetadata();\n+    this.txnManager.setLastCompletedTransaction(metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant());\n+    LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \" + this.txnManager.getLastCompletedTransactionOwner());\n+    this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)));\n+    this.txnManager.beginTransaction();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NTM5Nw==", "bodyText": "do we need to distinguish between endTransaction() and an abort ? i.e any cleanups in the transaction manager to be done here upon exception?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587055397", "createdAt": "2021-03-04T03:44:37Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -359,10 +388,21 @@ public abstract O bulkInsertPreppedRecords(I preppedRecords, final String instan\n    * Common method containing steps to be performed before write (upsert/insert/...\n    * @param instantTime\n    * @param writeOperationType\n+   * @param metaClient\n    */\n-  protected void preWrite(String instantTime, WriteOperationType writeOperationType) {\n+  protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n+      HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    syncTableMetadata();\n+    this.txnManager.setLastCompletedTransaction(metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant());\n+    LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \" + this.txnManager.getLastCompletedTransactionOwner());\n+    this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)));\n+    this.txnManager.beginTransaction();\n+    try {\n+      syncTableMetadata();\n+    } finally {\n+      this.txnManager.endTransaction();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NjIzMA==", "bodyText": "duplicate line?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587056230", "createdAt": "2021-03-04T03:45:36Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -389,29 +429,33 @@ protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata me\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n \n-      // Do an inline compaction if enabled\n-      if (config.isInlineCompaction()) {\n-        runAnyPendingCompactions(table);\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-        inlineCompact(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-      }\n+      if (config.inlineTableServices()) {\n+        // Do an inline compaction if enabled\n+        if (config.inlineCompactionEnabled()) {\n+          runAnyPendingCompactions(table);\n+          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+          inlineCompact(extraMetadata);\n+        } else {\n+          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n+        }\n \n-      // Do an inline clustering if enabled\n-      if (config.isInlineClustering()) {\n-        runAnyPendingClustering(table);\n-        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-        inlineCluster(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+        // Do an inline clustering if enabled\n+        if (config.inlineClusteringEnabled()) {\n+          runAnyPendingClustering(table);\n+          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n+          inlineCluster(extraMetadata);\n+        } else {\n+          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NzgzMQ==", "bodyText": "rename: compactionInstantTime", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587057831", "createdAt": "2021-03-04T03:47:39Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -797,7 +853,9 @@ public Boolean rollbackFailedWrites() {\n    * Performs a compaction operation on a table, serially before or after an insert/upsert action.\n    */\n   protected Option<String> inlineCompact(Option<Map<String, String>> extraMetadata) {\n-    Option<String> compactionInstantTimeOpt = scheduleCompaction(extraMetadata);\n+    String schedulingCompactionInstant = HoodieActiveTimeline.createNewInstantTime();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNDQ4Ng==", "bodyText": "rename: getCandidateInstants() to clarify intent.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587704486", "createdAt": "2021-03-04T18:14:24Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.ApiMaturityLevel;\n+import org.apache.hudi.PublicAPIMethod;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+\n+import java.util.stream.Stream;\n+\n+/**\n+ * Strategy interface for conflict resolution with multiple writers.\n+ * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n+ * writers are mutating the hoodie table.\n+ */\n+public interface ConflictResolutionStrategy {\n+\n+  /**\n+   * Stream of instants to check conflicts against.\n+   * @return\n+   */\n+  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNDYzMg==", "bodyText": "this reads nicely :)", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587704632", "createdAt": "2021-03-04T18:14:40Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.ApiMaturityLevel;\n+import org.apache.hudi.PublicAPIMethod;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+\n+import java.util.stream.Stream;\n+\n+/**\n+ * Strategy interface for conflict resolution with multiple writers.\n+ * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n+ * writers are mutating the hoodie table.\n+ */\n+public interface ConflictResolutionStrategy {\n+\n+  /**\n+   * Stream of instants to check conflicts against.\n+   * @return\n+   */\n+  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+\n+  /**\n+   * Implementations of this method will determine whether a conflict exists between 2 commits.\n+   * @param thisOperation\n+   * @param otherOperation\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNTUwNg==", "bodyText": "having the metadata writer passed in, feels off. any way to avoid this?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587705506", "createdAt": "2021-03-04T18:15:49Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.ApiMaturityLevel;\n+import org.apache.hudi.PublicAPIMethod;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+\n+import java.util.stream.Stream;\n+\n+/**\n+ * Strategy interface for conflict resolution with multiple writers.\n+ * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n+ * writers are mutating the hoodie table.\n+ */\n+public interface ConflictResolutionStrategy {\n+\n+  /**\n+   * Stream of instants to check conflicts against.\n+   * @return\n+   */\n+  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+\n+  /**\n+   * Implementations of this method will determine whether a conflict exists between 2 commits.\n+   * @param thisOperation\n+   * @param otherOperation\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n+\n+  /**\n+   * Implementations of this method will determine how to resolve a conflict between 2 commits.\n+   * @param thisOperation\n+   * @param otherOperation\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNjEzMQ==", "bodyText": "rename: ConflictingOperation", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587706131", "createdAt": "2021-03-04T18:16:46Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.CommitUtils;\n+import org.apache.hudi.common.util.Option;\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMMIT_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.DELTA_COMMIT_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is used to hold all information used to identify how to resolve conflicts between instants.\n+ * Since we interchange payload types between AVRO specific records and POJO's, this object serves as\n+ * a common payload to manage these conversions.\n+ */\n+public class HoodieCommitOperation {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNzY3OQ==", "bodyText": "any special handling for InterruptedException? this is a common cause of bugs in such locking code paths", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587707679", "createdAt": "2021-03-04T18:19:04Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.config.SerializableConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ReflectionUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * This class wraps implementations of {@link LockProvider} and provides an easy way to manage the lifecycle of a lock.\n+ */\n+public class LockManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockManager.class);\n+  private final HoodieWriteConfig writeConfig;\n+  private final LockConfiguration lockConfiguration;\n+  private final SerializableConfiguration hadoopConf;\n+  private volatile LockProvider lockProvider;\n+  // Holds the latest completed write instant to know which ones to check conflict against\n+  private final AtomicReference<Option<HoodieInstant>> latestCompletedWriteInstant;\n+\n+  public LockManager(HoodieWriteConfig writeConfig, FileSystem fs) {\n+    this.latestCompletedWriteInstant = new AtomicReference<>(Option.empty());\n+    this.writeConfig = writeConfig;\n+    this.hadoopConf = new SerializableConfiguration(fs.getConf());\n+    this.lockConfiguration = new LockConfiguration(writeConfig.getProps());\n+  }\n+\n+  public void lock() {\n+    if (writeConfig.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      LockProvider lockProvider = getLockProvider();\n+      boolean acquired = false;\n+      try {\n+        int retries = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP);\n+        long waitTimeInMs = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP);\n+        int retryCount = 0;\n+        while (retryCount <= retries) {\n+          acquired = lockProvider.tryLock(writeConfig.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n+          if (acquired) {\n+            break;\n+          }\n+          LOG.info(\"Retrying...\");\n+          Thread.sleep(waitTimeInMs);\n+          retryCount++;\n+        }\n+      } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwODIyMQ==", "bodyText": "I assume the providers unlock() will throw more exceptions.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587708221", "createdAt": "2021-03-04T18:19:57Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.config.SerializableConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ReflectionUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * This class wraps implementations of {@link LockProvider} and provides an easy way to manage the lifecycle of a lock.\n+ */\n+public class LockManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockManager.class);\n+  private final HoodieWriteConfig writeConfig;\n+  private final LockConfiguration lockConfiguration;\n+  private final SerializableConfiguration hadoopConf;\n+  private volatile LockProvider lockProvider;\n+  // Holds the latest completed write instant to know which ones to check conflict against\n+  private final AtomicReference<Option<HoodieInstant>> latestCompletedWriteInstant;\n+\n+  public LockManager(HoodieWriteConfig writeConfig, FileSystem fs) {\n+    this.latestCompletedWriteInstant = new AtomicReference<>(Option.empty());\n+    this.writeConfig = writeConfig;\n+    this.hadoopConf = new SerializableConfiguration(fs.getConf());\n+    this.lockConfiguration = new LockConfiguration(writeConfig.getProps());\n+  }\n+\n+  public void lock() {\n+    if (writeConfig.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      LockProvider lockProvider = getLockProvider();\n+      boolean acquired = false;\n+      try {\n+        int retries = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP);\n+        long waitTimeInMs = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP);\n+        int retryCount = 0;\n+        while (retryCount <= retries) {\n+          acquired = lockProvider.tryLock(writeConfig.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n+          if (acquired) {\n+            break;\n+          }\n+          LOG.info(\"Retrying...\");\n+          Thread.sleep(waitTimeInMs);\n+          retryCount++;\n+        }\n+      } catch (Exception e) {\n+        throw new HoodieLockException(\"Unable to acquire lock \", e);\n+      }\n+      if (!acquired) {\n+        throw new HoodieLockException(\"Unable to acquire lock, lock object \" + lockProvider.getLock());\n+      }\n+    }\n+  }\n+\n+  public void unlock() {\n+    if (writeConfig.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      getLockProvider().unlock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMDkxOA==", "bodyText": "can we avoid passing the \"0\" or use an existing constant for init instant time etc", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587710918", "createdAt": "2021-03-04T18:24:04Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMTc4NQ==", "bodyText": "is this an error though. can we move to INFO", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587711785", "createdAt": "2021-03-04T18:25:24Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMzU4Ng==", "bodyText": "but replace commit can also result from INSERT_OVERWRITE correct? how do we distinguish this? I feel we need a more nuanced check here. So ensure only writes fail each other.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587713586", "createdAt": "2021-03-04T18:27:57Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation\n+          + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n+                                              HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC. Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation as a regular commit.\n+    if (otherOperation.getOperationType() == WriteOperationType.UNKNOWN", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNDM1Mg==", "bodyText": "combine into a single log line?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587714352", "createdAt": "2021-03-04T18:29:05Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * This class allows clients to start and end transactions. Anything done between a start and end transaction is\n+ * guaranteed to be atomic.\n+ */\n+public class TransactionManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionManager.class);\n+\n+  private final LockManager lockManager;\n+  private Option<HoodieInstant> currentTxnOwnerInstant;\n+  private Option<HoodieInstant> lastCompletedTxnOwnerInstant;\n+\n+  public TransactionManager(HoodieWriteConfig config, FileSystem fs) {\n+    this.lockManager = new LockManager(config, fs);\n+  }\n+\n+  public synchronized void setLastCompletedTransaction(Option<HoodieInstant> instant) {\n+    this.lastCompletedTxnOwnerInstant = instant;\n+    lockManager.compareAndSetLatestCompletedWriteInstant(lockManager.getLatestCompletedWriteInstant().get(), instant);\n+    LOG.info(\"Latest completed transaction instant \" + instant);\n+  }\n+\n+  public synchronized void setTransactionOwner(Option<HoodieInstant> instant) {\n+    this.currentTxnOwnerInstant = instant;\n+    LOG.info(\"Current transaction instant \" + instant);\n+  }\n+\n+  public synchronized void beginTransaction() {\n+    LOG.info(\"Transaction starting\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNDQwNQ==", "bodyText": "same . combine?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587714405", "createdAt": "2021-03-04T18:29:11Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * This class allows clients to start and end transactions. Anything done between a start and end transaction is\n+ * guaranteed to be atomic.\n+ */\n+public class TransactionManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionManager.class);\n+\n+  private final LockManager lockManager;\n+  private Option<HoodieInstant> currentTxnOwnerInstant;\n+  private Option<HoodieInstant> lastCompletedTxnOwnerInstant;\n+\n+  public TransactionManager(HoodieWriteConfig config, FileSystem fs) {\n+    this.lockManager = new LockManager(config, fs);\n+  }\n+\n+  public synchronized void setLastCompletedTransaction(Option<HoodieInstant> instant) {\n+    this.lastCompletedTxnOwnerInstant = instant;\n+    lockManager.compareAndSetLatestCompletedWriteInstant(lockManager.getLatestCompletedWriteInstant().get(), instant);\n+    LOG.info(\"Latest completed transaction instant \" + instant);\n+  }\n+\n+  public synchronized void setTransactionOwner(Option<HoodieInstant> instant) {\n+    this.currentTxnOwnerInstant = instant;\n+    LOG.info(\"Current transaction instant \" + instant);\n+  }\n+\n+  public synchronized void beginTransaction() {\n+    LOG.info(\"Transaction starting\");\n+    LOG.info(\"Transaction Owner \" + currentTxnOwnerInstant);\n+    lockManager.lock();\n+    LOG.info(\"Transaction started\");\n+  }\n+\n+  public synchronized void endTransaction() {\n+    LOG.info(\"Transaction ending\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNTU0NQ==", "bodyText": "make it final. In general, can you make a pass to ensure what can be final is made final.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587715545", "createdAt": "2021-03-04T18:30:48Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNjYxMA==", "bodyText": "how are you testing this? I don't see curator added to any of the bundles? Same for the zookeeper dependencies. This is a really really important part", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587716610", "createdAt": "2021-03-04T18:32:31Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxODMwMA==", "bodyText": "but we seem to synchronize down below?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587718300", "createdAt": "2021-03-04T18:35:06Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxOTIxMQ==", "bodyText": "why public", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587719211", "createdAt": "2021-03-04T18:35:48Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+  }\n+  \n+  public void acquireLock(long time, TimeUnit unit) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMDc5Nw==", "bodyText": "so, the lock can be acquired by another process and we don't raise this exception?  is that ok? I see lines 94-96 above, where we simply do the assignment and not raise any exceptions from an else block", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587720797", "createdAt": "2021-03-04T18:37:23Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+  }\n+  \n+  public void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    newLock.acquire(time, unit);\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    }\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    try {\n+      acquireLock(time, unit);\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMTQyMA==", "bodyText": "does this have an unit test on its own?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587721420", "createdAt": "2021-03-04T18:38:14Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+import org.apache.hudi.avro.model.HoodieCompactionPlan;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n+import org.apache.hudi.avro.model.HoodieSavepointMetadata;\n+import org.apache.hudi.client.ReplaceArchivalHelper;\n+import org.apache.hudi.common.model.ActionType;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CompactionUtils;\n+import java.io.IOException;\n+\n+/**\n+ * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n+ */\n+public class HoodieMetadataConversionUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMTcxMg==", "bodyText": "would this come back to haunt us ?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587721712", "createdAt": "2021-03-04T18:38:38Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+import org.apache.hudi.avro.model.HoodieCompactionPlan;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n+import org.apache.hudi.avro.model.HoodieSavepointMetadata;\n+import org.apache.hudi.client.ReplaceArchivalHelper;\n+import org.apache.hudi.common.model.ActionType;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CompactionUtils;\n+import java.io.IOException;\n+\n+/**\n+ * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n+ */\n+public class HoodieMetadataConversionUtils {\n+\n+  public static HoodieArchivedMetaEntry createMetaWrapper(HoodieInstant hoodieInstant, HoodieTableMetaClient metaClient) throws IOException {\n+    HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();\n+    archivedMetaWrapper.setCommitTime(hoodieInstant.getTimestamp());\n+    archivedMetaWrapper.setActionState(hoodieInstant.getState().name());\n+    switch (hoodieInstant.getAction()) {\n+      case HoodieTimeline.CLEAN_ACTION: {\n+        if (hoodieInstant.isCompleted()) {\n+          archivedMetaWrapper.setHoodieCleanMetadata(CleanerUtils.getCleanerMetadata(metaClient, hoodieInstant));\n+        } else {\n+          archivedMetaWrapper.setHoodieCleanerPlan(CleanerUtils.getCleanerPlan(metaClient, hoodieInstant));\n+        }\n+        archivedMetaWrapper.setActionType(ActionType.clean.name());\n+        break;\n+      }\n+      case HoodieTimeline.COMMIT_ACTION:\n+      case HoodieTimeline.DELTA_COMMIT_ACTION: {\n+        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n+                .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieCommitMetadata.class);\n+        archivedMetaWrapper.setHoodieCommitMetadata(convertCommitMetadata(commitMetadata));\n+        archivedMetaWrapper.setActionType(ActionType.commit.name());\n+        break;\n+      }\n+      case HoodieTimeline.REPLACE_COMMIT_ACTION: {\n+        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n+                .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieReplaceCommitMetadata.class);\n+        archivedMetaWrapper.setHoodieReplaceCommitMetadata(ReplaceArchivalHelper.convertReplaceCommitMetadata(replaceCommitMetadata));\n+        archivedMetaWrapper.setActionType(ActionType.replacecommit.name());\n+        break;\n+      }\n+      case HoodieTimeline.ROLLBACK_ACTION: {\n+        archivedMetaWrapper.setHoodieRollbackMetadata(TimelineMetadataUtils.deserializeAvroMetadata(\n+                metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieRollbackMetadata.class));\n+        archivedMetaWrapper.setActionType(ActionType.rollback.name());\n+        break;\n+      }\n+      case HoodieTimeline.SAVEPOINT_ACTION: {\n+        archivedMetaWrapper.setHoodieSavePointMetadata(TimelineMetadataUtils.deserializeAvroMetadata(\n+                metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieSavepointMetadata.class));\n+        archivedMetaWrapper.setActionType(ActionType.savepoint.name());\n+        break;\n+      }\n+      case HoodieTimeline.COMPACTION_ACTION: {\n+        HoodieCompactionPlan plan = CompactionUtils.getCompactionPlan(metaClient, hoodieInstant.getTimestamp());\n+        archivedMetaWrapper.setHoodieCompactionPlan(plan);\n+        archivedMetaWrapper.setActionType(ActionType.compaction.name());\n+        break;\n+      }\n+      default: {\n+        throw new UnsupportedOperationException(\"Action not fully supported yet\");\n+      }\n+    }\n+    return archivedMetaWrapper;\n+  }\n+\n+  public static HoodieArchivedMetaEntry createMetaWrapper(HoodieInstant hoodieInstant,\n+                                                          HoodieCommitMetadata hoodieCommitMetadata) {\n+    HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();\n+    archivedMetaWrapper.setCommitTime(hoodieInstant.getTimestamp());\n+    archivedMetaWrapper.setActionState(hoodieInstant.getState().name());\n+    archivedMetaWrapper.setHoodieCommitMetadata(convertCommitMetadata(hoodieCommitMetadata));\n+    archivedMetaWrapper.setActionType(ActionType.commit.name());\n+    return archivedMetaWrapper;\n+  }\n+\n+  public static org.apache.hudi.avro.model.HoodieCommitMetadata convertCommitMetadata(\n+          HoodieCommitMetadata hoodieCommitMetadata) {\n+    ObjectMapper mapper = new ObjectMapper();\n+    // Need this to ignore other public get() methods\n+    mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);\n+    org.apache.hudi.avro.model.HoodieCommitMetadata avroMetaData =\n+            mapper.convertValue(hoodieCommitMetadata, org.apache.hudi.avro.model.HoodieCommitMetadata.class);\n+    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer\n+    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n+    return avroMetaData;\n+  }\n+\n+  // TODO : Fix converting from SpecificRecord to POJO", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMjA1Ng==", "bodyText": "Do we need this? is this TODO still relevant", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587722056", "createdAt": "2021-03-04T18:39:11Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.HoodieCommitOperation;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import java.io.IOException;\n+import java.util.stream.Stream;\n+\n+public class TransactionUtils {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionUtils.class);\n+\n+  /**\n+   * Resolve any write conflicts when committing data.\n+   * @param table\n+   * @param metadataWriter\n+   * @param currentTxnOwnerInstant\n+   * @param thisCommitMetadata\n+   * @param config\n+   * @param lastCompletedTxnOwnerInstant\n+   * @return\n+   * @throws HoodieWriteConflictException\n+   */\n+  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieBackedTableMetadataWriter> metadataWriter,\n+                                                                       final Option<HoodieInstant> currentTxnOwnerInstant, final Option<HoodieCommitMetadata> thisCommitMetadata,\n+                                                                       final HoodieWriteConfig config, Option<HoodieInstant> lastCompletedTxnOwnerInstant)\n+      throws HoodieWriteConflictException {\n+    if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n+      Stream<HoodieInstant> instantStream = resolutionStrategy.getInstantsStream(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n+      // TODO : metadataWriter.reload() inside resolve write conflict ??", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMjM2MQ==", "bodyText": "rename to MetadataConversionUtils ?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587722361", "createdAt": "2021-03-04T18:39:38Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+import org.apache.hudi.avro.model.HoodieCompactionPlan;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n+import org.apache.hudi.avro.model.HoodieSavepointMetadata;\n+import org.apache.hudi.client.ReplaceArchivalHelper;\n+import org.apache.hudi.common.model.ActionType;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CompactionUtils;\n+import java.io.IOException;\n+\n+/**\n+ * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n+ */\n+public class HoodieMetadataConversionUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMzU0NA==", "bodyText": "unit test this method?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587723544", "createdAt": "2021-03-04T18:41:20Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.HoodieCommitOperation;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import java.io.IOException;\n+import java.util.stream.Stream;\n+\n+public class TransactionUtils {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionUtils.class);\n+\n+  /**\n+   * Resolve any write conflicts when committing data.\n+   * @param table\n+   * @param metadataWriter\n+   * @param currentTxnOwnerInstant\n+   * @param thisCommitMetadata\n+   * @param config\n+   * @param lastCompletedTxnOwnerInstant\n+   * @return\n+   * @throws HoodieWriteConflictException\n+   */\n+  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieBackedTableMetadataWriter> metadataWriter,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNTgxNw==", "bodyText": "should there be a single property? i.e hoodie.clean.async= false does imply hoodie.clean.inline=true right?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587725817", "createdAt": "2021-03-04T18:45:06Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java", "diffHunk": "@@ -43,7 +43,8 @@\n   public static final String CLEANER_POLICY_PROP = \"hoodie.cleaner.policy\";\n   public static final String AUTO_CLEAN_PROP = \"hoodie.clean.automatic\";\n   public static final String ASYNC_CLEAN_PROP = \"hoodie.clean.async\";\n-\n+  // Turn on inline cleaning\n+  public static final String INLINE_CLEAN_PROP = \"hoodie.clean.inline\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNjUwNw==", "bodyText": "auto clean is different from the cleaning mode itself. lets just have an assignment to the hardcoded string \"true\"?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587726507", "createdAt": "2021-03-04T18:46:01Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java", "diffHunk": "@@ -114,6 +115,7 @@\n       HoodieFailedWritesCleaningPolicy.EAGER.name();\n   private static final String DEFAULT_AUTO_CLEAN = \"true\";\n   private static final String DEFAULT_ASYNC_CLEAN = \"false\";\n+  private static final String DEFAULT_INLINE_CLEAN = DEFAULT_AUTO_CLEAN;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNzk0Ng==", "bodyText": "are these ever used in hudi-common? if we don't anticipate readers using this. we should just keep all this in hudi-client-common under a transaction package", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587727946", "createdAt": "2021-03-04T18:48:07Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.config;\n+\n+import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n+import org.apache.hudi.common.config.DefaultHoodieConfig;\n+import org.apache.hudi.common.lock.LockProvider;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyOTI1Mg==", "bodyText": "given we have had some typo related issues recently, please check each line once for correctness", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587729252", "createdAt": "2021-03-04T18:50:08Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.config;\n+\n+import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n+import org.apache.hudi.common.config.DefaultHoodieConfig;\n+import org.apache.hudi.common.lock.LockProvider;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_CLIENT_NUM_RETRIES;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_NUM_RETRIES;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_DATABASE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_TABLE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_PREFIX;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_PORT_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+\n+/**\n+ * Hoodie Configs for Locks.\n+ */\n+public class HoodieLockConfig extends DefaultHoodieConfig {\n+\n+  // Pluggable type of lock provider\n+  public static final String LOCK_PROVIDER_CLASS_PROP = LOCK_PREFIX + \"provider\";\n+  public static final String DEFAULT_LOCK_PROVIDER_CLASS = ZookeeperBasedLockProvider.class.getName();\n+  // Pluggable strategies to use when resolving conflicts\n+  public static final String WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP =\n+      LOCK_PREFIX + \"conflict.resolution.strategy\";\n+  public static final String DEFAULT_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS =\n+      SimpleConcurrentFileWritesConflictResolutionStrategy.class.getName();\n+\n+  private HoodieLockConfig(Properties props) {\n+    super(props);\n+  }\n+\n+  public static HoodieLockConfig.Builder newBuilder() {\n+    return new HoodieLockConfig.Builder();\n+  }\n+\n+  public static class Builder {\n+\n+    private final Properties props = new Properties();\n+\n+    public HoodieLockConfig.Builder fromFile(File propertiesFile) throws IOException {\n+      try (FileReader reader = new FileReader(propertiesFile)) {\n+        this.props.load(reader);\n+        return this;\n+      }\n+    }\n+\n+    public HoodieLockConfig.Builder fromProperties(Properties props) {\n+      this.props.putAll(props);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withLockProvider(Class<? extends LockProvider> lockProvider) {\n+      props.setProperty(LOCK_PROVIDER_CLASS_PROP, lockProvider.getName());\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withHiveDatabaseName(String databaseName) {\n+      props.setProperty(HIVE_DATABASE_NAME_PROP, databaseName);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withHiveTableName(String tableName) {\n+      props.setProperty(HIVE_TABLE_NAME_PROP, tableName);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkQuorum(String zkQuorum) {\n+      props.setProperty(ZK_CONNECT_URL_PROP, zkQuorum);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkBasePath(String zkBasePath) {\n+      props.setProperty(ZK_BASE_PATH_PROP, zkBasePath);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkPort(String zkPort) {\n+      props.setProperty(ZK_PORT_PROP, zkPort);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkLockKey(String zkLockKey) {\n+      props.setProperty(ZK_LOCK_KEY_PROP, zkLockKey);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkConnectionTimeoutInMs(Long connectionTimeoutInMs) {\n+      props.setProperty(ZK_CONNECTION_TIMEOUT_MS_PROP, String.valueOf(connectionTimeoutInMs));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkSessionTimeoutInMs(Long sessionTimeoutInMs) {\n+      props.setProperty(ZK_SESSION_TIMEOUT_MS_PROP, String.valueOf(sessionTimeoutInMs));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withNumRetries(int numRetries) {\n+      props.setProperty(LOCK_ACQUIRE_NUM_RETRIES_PROP, String.valueOf(numRetries));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withRetryWaitTimeInMillis(Long retryWaitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP, String.valueOf(retryWaitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withClientNumRetries(int clientNumRetries) {\n+      props.setProperty(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP, String.valueOf(clientNumRetries));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withClientRetryWaitTimeInMillis(Long clientRetryWaitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP, String.valueOf(clientRetryWaitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withLockWaitTimeInMillis(Long waitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP, String.valueOf(waitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withConflictResolutionStrategy(ConflictResolutionStrategy conflictResolutionStrategy) {\n+      props.setProperty(WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP, conflictResolutionStrategy.getClass().getName());\n+      return this;\n+    }\n+\n+    public HoodieLockConfig build() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMTc1Mw==", "bodyText": "I don't understand why we just pick the last cleaned metadata. Lets do the generically right thing. If you want to handle more than more cleaning operation, lets return a list?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587731753", "createdAt": "2021-03-04T18:54:00Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanActionExecutor.java", "diffHunk": "@@ -195,30 +126,24 @@ private HoodieCleanMetadata runClean(HoodieTable<T, I, K, O> table, HoodieInstan\n \n   @Override\n   public HoodieCleanMetadata execute() {\n+    List<HoodieCleanMetadata> cleanMetadataList = new ArrayList<>();\n     // If there are inflight(failed) or previously requested clean operation, first perform them\n     List<HoodieInstant> pendingCleanInstants = table.getCleanTimeline()\n         .filterInflightsAndRequested().getInstants().collect(Collectors.toList());\n     if (pendingCleanInstants.size() > 0) {\n       pendingCleanInstants.forEach(hoodieInstant -> {\n         LOG.info(\"Finishing previously unfinished cleaner instant=\" + hoodieInstant);\n         try {\n-          runPendingClean(table, hoodieInstant);\n+          cleanMetadataList.add(runPendingClean(table, hoodieInstant));\n         } catch (Exception e) {\n           LOG.warn(\"Failed to perform previous clean operation, instant: \" + hoodieInstant, e);\n         }\n       });\n       table.getMetaClient().reloadActiveTimeline();\n     }\n-\n-    // Plan and execute a new clean action\n-    Option<HoodieCleanerPlan> cleanerPlanOpt = requestClean(instantTime);\n-    if (cleanerPlanOpt.isPresent()) {\n-      table.getMetaClient().reloadActiveTimeline();\n-      HoodieCleanerPlan cleanerPlan = cleanerPlanOpt.get();\n-      if ((cleanerPlan.getFilePathsToBeDeletedPerPartition() != null) && !cleanerPlan.getFilePathsToBeDeletedPerPartition().isEmpty()) {\n-        return runClean(table, HoodieTimeline.getCleanRequestedInstant(instantTime), cleanerPlan);\n-      }\n-    }\n-    return null;\n+    // return the last clean metadata for now\n+    // TODO (NA) : Clean only the earliest pending clean just like how we do for other table services", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMTk2OA==", "bodyText": "Won't this for e.g mess up the metadata table? by missing some deletes?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587731968", "createdAt": "2021-03-04T18:54:19Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanActionExecutor.java", "diffHunk": "@@ -195,30 +126,24 @@ private HoodieCleanMetadata runClean(HoodieTable<T, I, K, O> table, HoodieInstan\n \n   @Override\n   public HoodieCleanMetadata execute() {\n+    List<HoodieCleanMetadata> cleanMetadataList = new ArrayList<>();\n     // If there are inflight(failed) or previously requested clean operation, first perform them\n     List<HoodieInstant> pendingCleanInstants = table.getCleanTimeline()\n         .filterInflightsAndRequested().getInstants().collect(Collectors.toList());\n     if (pendingCleanInstants.size() > 0) {\n       pendingCleanInstants.forEach(hoodieInstant -> {\n         LOG.info(\"Finishing previously unfinished cleaner instant=\" + hoodieInstant);\n         try {\n-          runPendingClean(table, hoodieInstant);\n+          cleanMetadataList.add(runPendingClean(table, hoodieInstant));\n         } catch (Exception e) {\n           LOG.warn(\"Failed to perform previous clean operation, instant: \" + hoodieInstant, e);\n         }\n       });\n       table.getMetaClient().reloadActiveTimeline();\n     }\n-\n-    // Plan and execute a new clean action\n-    Option<HoodieCleanerPlan> cleanerPlanOpt = requestClean(instantTime);\n-    if (cleanerPlanOpt.isPresent()) {\n-      table.getMetaClient().reloadActiveTimeline();\n-      HoodieCleanerPlan cleanerPlan = cleanerPlanOpt.get();\n-      if ((cleanerPlan.getFilePathsToBeDeletedPerPartition() != null) && !cleanerPlan.getFilePathsToBeDeletedPerPartition().isEmpty()) {\n-        return runClean(table, HoodieTimeline.getCleanRequestedInstant(instantTime), cleanerPlan);\n-      }\n-    }\n-    return null;\n+    // return the last clean metadata for now\n+    // TODO (NA) : Clean only the earliest pending clean just like how we do for other table services", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMTc1Mw=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMzI2NQ==", "bodyText": "I assume, this is all just code moved from the other class. if not , please point out what has changed", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587733265", "createdAt": "2021-03-04T18:56:11Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanPlanActionExecutor.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.clean;\n+\n+import org.apache.hudi.avro.model.HoodieActionInstant;\n+import org.apache.hudi.avro.model.HoodieCleanFileInfo;\n+import org.apache.hudi.avro.model.HoodieCleanerPlan;\n+import org.apache.hudi.common.engine.HoodieEngineContext;\n+import org.apache.hudi.common.model.HoodieCleaningPolicy;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.collection.Pair;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.table.action.BaseActionExecutor;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+public abstract class BaseCleanPlanActionExecutor<T extends HoodieRecordPayload, I, K, O> extends BaseActionExecutor<T, I, K, O, Option<HoodieCleanerPlan>> {\n+\n+  private static final Logger LOG = LogManager.getLogger(CleanPlanner.class);\n+\n+  private final Option<Map<String, String>> extraMetadata;\n+\n+  public BaseCleanPlanActionExecutor(HoodieEngineContext context,\n+                                     HoodieWriteConfig config,\n+                                     HoodieTable<T, I, K, O> table,\n+                                     String instantTime,\n+                                     Option<Map<String, String>> extraMetadata) {\n+    super(context, config, table, instantTime);\n+    this.extraMetadata = extraMetadata;\n+  }\n+\n+  protected abstract Option<HoodieCleanerPlan> createCleanerPlan();\n+\n+  /**\n+   * Generates List of files to be cleaned.\n+   *\n+   * @param context HoodieEngineContext\n+   * @return Cleaner Plan\n+   */\n+  HoodieCleanerPlan requestClean(HoodieEngineContext context) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMzY0Mw==", "bodyText": "lets create a code cleanup JIRA for this. else we may not get to this.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587733643", "createdAt": "2021-03-04T18:56:50Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java", "diffHunk": "@@ -66,6 +70,11 @@ public BaseCommitActionExecutor(HoodieEngineContext context, HoodieWriteConfig c\n     this.operationType = operationType;\n     this.extraMetadata = extraMetadata;\n     this.taskContextSupplier = context.getTaskContextSupplier();\n+    this.txnManager = new TransactionManager(config, table.getMetaClient().getFs());\n+    // TODO : Remove this once we refactor and move out autoCommit method from here, since the TxnManager is held in {@link AbstractHoodieWriteClient}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczNTI3OA==", "bodyText": "is the metadataWriter really used inside this method?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587735278", "createdAt": "2021-03-04T18:59:04Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.HoodieCommitOperation;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import java.io.IOException;\n+import java.util.stream.Stream;\n+\n+public class TransactionUtils {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionUtils.class);\n+\n+  /**\n+   * Resolve any write conflicts when committing data.\n+   * @param table\n+   * @param metadataWriter\n+   * @param currentTxnOwnerInstant\n+   * @param thisCommitMetadata\n+   * @param config\n+   * @param lastCompletedTxnOwnerInstant\n+   * @return\n+   * @throws HoodieWriteConflictException\n+   */\n+  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieBackedTableMetadataWriter> metadataWriter,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMzU0NA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczNTY0MQ==", "bodyText": "revisit the todo?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587735641", "createdAt": "2021-03-04T18:59:39Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java", "diffHunk": "@@ -117,12 +126,24 @@ protected String getCommitActionType() {\n   protected void commitOnAutoCommit(HoodieWriteMetadata result) {\n     if (config.shouldAutoCommit()) {\n       LOG.info(\"Auto commit enabled: Committing \" + instantTime);\n-      commit(extraMetadata, result);\n+      autoCommit(extraMetadata, result);\n     } else {\n       LOG.info(\"Auto commit disabled for \" + instantTime);\n     }\n   }\n \n+  protected void autoCommit(Option<Map<String, String>> extraMetadata, HoodieWriteMetadata<O> result) {\n+    this.txnManager.beginTransaction();\n+    try {\n+      // TODO : Refactor this method so we can pass a valid metadata table writer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczODA3OA==", "bodyText": "I think the common term is . zookeeper chroot?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587738078", "createdAt": "2021-03-04T19:02:00Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.config;\n+\n+import java.io.Serializable;\n+import java.util.Properties;\n+\n+/**\n+ * Configuration for managing locks. Since this configuration needs to be shared with HiveMetaStore based lock,\n+ * which is in a different package than other lock providers, we use this as a data transfer object in hoodie-common\n+ */\n+public class LockConfiguration implements Serializable {\n+\n+  public static final String LOCK_PREFIX = \"hoodie.writer.lock.\";\n+  public static final String LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(5000L);\n+  public static final String LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"client.wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(10000L);\n+  public static final String LOCK_ACQUIRE_NUM_RETRIES_PROP = LOCK_PREFIX + \"num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_NUM_RETRIES = String.valueOf(3);\n+  public static final String LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP = LOCK_PREFIX + \"client.num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_NUM_RETRIES = String.valueOf(0);\n+  public static final String LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP = LOCK_PREFIX + \"wait_time_ms\";\n+  public static final int DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS = 60 * 1000;\n+  // configs for file system based locks. NOTE: This only works for DFS with atomic create/delete operation\n+  public static final String FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"filesystem.\";\n+  public static final String FILESYSTEM_LOCK_PATH_PROP = FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX + \"path\";\n+  // configs for metastore based locks\n+  public static final String HIVE_METASTORE_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"hivemetastore.\";\n+  public static final String HIVE_DATABASE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"database\";\n+  public static final String HIVE_TABLE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"table\";\n+  // Zookeeper configs for zk based locks\n+  public static final String ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"zookeeper.\";\n+  public static final String ZK_BASE_PATH_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"zk_base_path\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczOTI1NQ==", "bodyText": "can this be an interface?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587739255", "createdAt": "2021-03-04T19:02:44Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MDAyMA==", "bodyText": "if there is no shared code here, we should go for an interface vs an abstract class", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587740020", "createdAt": "2021-03-04T19:03:11Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczOTI1NQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTAzNA==", "bodyText": "rename: HoodieMetadataWrapper", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587741034", "createdAt": "2021-03-04T19:04:16Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommonMetadata.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+\n+public class HoodieCommonMetadata {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTIyOA==", "bodyText": "rename: TableServiceType", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587741228", "createdAt": "2021-03-04T19:04:36Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+\n+/**\n+ * Supported runtime table services.\n+ */\n+public enum TableService {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTQ3MA==", "bodyText": "rename: isOptimistic... ?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587741470", "createdAt": "2021-03-04T19:04:58Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Different concurrency modes for write operations.\n+ */\n+public enum WriteConcurrencyMode {\n+  // Only a single writer can perform write ops\n+  SINGLE_WRITER(\"single_writer\"),\n+  // Multiple writer can perform write ops with lazy conflict resolution using locks\n+  OPTIMISTIC_CONCURRENCY_CONTROL(\"optimistic_concurrency_control\");\n+\n+  private final String value;\n+\n+  WriteConcurrencyMode(String value) {\n+    this.value = value;\n+  }\n+\n+  /**\n+   * Getter for write concurrency mode.\n+   * @return\n+   */\n+  public String value() {\n+    return value;\n+  }\n+\n+  /**\n+   * Convert string value to WriteConcurrencyMode.\n+   */\n+  public static WriteConcurrencyMode fromValue(String value) {\n+    switch (value.toLowerCase(Locale.ROOT)) {\n+      case \"single_writer\":\n+        return SINGLE_WRITER;\n+      case \"optimistic_concurrency_control\":\n+        return OPTIMISTIC_CONCURRENCY_CONTROL;\n+      default:\n+        throw new HoodieException(\"Invalid value of Type.\");\n+    }\n+  }\n+\n+  public boolean supportsOptimisticConcurrencyControl() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTk4MQ==", "bodyText": "what is this really?  how can there be an write that is unknown?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587741981", "createdAt": "2021-03-04T19:05:39Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteOperationType.java", "diffHunk": "@@ -82,6 +84,10 @@ public static WriteOperationType fromValue(String value) {\n         return INSERT_OVERWRITE_TABLE;\n       case \"cluster\":\n         return CLUSTER;\n+      case \"compact\":\n+        return COMPACT;\n+      case \"unknown\":", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MjU2OQ==", "bodyText": "lets unit tests these?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587742569", "createdAt": "2021-03-04T19:06:30Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java", "diffHunk": "@@ -93,4 +95,28 @@ private static HoodieCommitMetadata buildMetadataFromStats(List<HoodieWriteStat>\n         + \"numReplaceFileIds:\" + partitionToReplaceFileIds.values().stream().mapToInt(e -> e.size()).sum());\n     return commitMetadata;\n   }\n+\n+  public static HashMap<String, String> getFileIdWithoutSuffixAndRelativePaths(Map<String, List<org.apache.hudi.avro.model.HoodieWriteStat>>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NDAwOQ==", "bodyText": "revisit todo?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587744009", "createdAt": "2021-03-04T19:08:43Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java", "diffHunk": "@@ -313,6 +320,16 @@ public void cleanHandles() {\n     return writeHandle;\n   }\n \n+  @Override\n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    // TODO : Metadata Writer is not supported for Flink", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NDMwNg==", "bodyText": "this does not seem ok to do?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587744306", "createdAt": "2021-03-04T19:09:16Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java", "diffHunk": "@@ -265,6 +266,20 @@ public void rollbackBootstrap(HoodieEngineContext context, String instantTime) {\n     throw new HoodieNotSupportedException(\"Bootstrap is not supported yet\");\n   }\n \n+  /**\n+   * TODO :\n+   * Refactor {@link FlinkCleanActionExecutor} to support scheduling of cleaning.\n+   * @param context HoodieEngineContext\n+   * @param instantTime Instant Time for scheduling cleaning\n+   * @param extraMetadata additional metadata to write into plan\n+   * @return\n+   */\n+  @Override\n+  public Option<HoodieCleanerPlan> scheduleCleaning(HoodieEngineContext context, String instantTime, Option<Map<String, String>> extraMetadata) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NTI2Mw==", "bodyText": "revisit comment.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587745263", "createdAt": "2021-03-04T19:10:46Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java", "diffHunk": "@@ -224,6 +231,16 @@ protected void completeCompaction(HoodieCommitMetadata metadata,\n     return getTableAndInitCtx(metaClient, operationType);\n   }\n \n+  @Override\n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    // TODO : Metadata Writer is not supported for Java", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NjQzMg==", "bodyText": "lets clean this up?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587746432", "createdAt": "2021-03-04T19:12:46Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n+      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NzU4MA==", "bodyText": "lets add a method needsUpgradeOrDowngrade()  to the upgradedowngrade class?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587747580", "createdAt": "2021-03-04T19:14:39Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0Nzg5NA==", "bodyText": "should we check concurrency mode before taking these locks?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587747894", "createdAt": "2021-03-04T19:15:12Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n+      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed\n+      // this.rollbackFailedWrites();\n+      this.txnManager.beginTransaction();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0ODM4Nw==", "bodyText": "comment valid? What should we do about this issue? Can you elabortate?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587748387", "createdAt": "2021-03-04T19:15:54Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n+      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed\n+      // this.rollbackFailedWrites();\n+      this.txnManager.beginTransaction();\n+      try {\n+        // Ensure no inflight commits\n+        TransactionUtils.resolveConflictIfAnyForUpgradeDowngrade(metaClient);\n+        new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n+      } finally {\n+        this.txnManager.endTransaction();\n+      }\n+    }\n+    return getTableAndInitCtx(metaClient, operationType, instantTime);\n   }\n \n-  private HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(HoodieTableMetaClient metaClient, WriteOperationType operationType) {\n+  // TODO : To enforce priority between table service and ingestion writer, use transactions here and invoke strategy", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0OTU3MQ==", "bodyText": "we lose auto closing by moving to  a regular try-catch. Why is this change needed?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587749571", "createdAt": "2021-03-04T19:17:38Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -401,13 +441,25 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try (HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n+    try {\n+      HoodieTableMetadataWriter writer =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MDAxOQ==", "bodyText": "should we recreate? again, we need to revisit this whole passing of metadatawriter to resolve conflict. Don't understand this part", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587750019", "createdAt": "2021-03-04T19:18:19Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -401,13 +441,25 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try (HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n+    try {\n+      HoodieTableMetadataWriter writer =\n+          SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n     }\n   }\n \n+  @Override\n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MTEwMA==", "bodyText": "I think all this can be removed. from all action executors? can't we take the lock in post commit/write from the write client level?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587751100", "createdAt": "2021-03-04T19:20:00Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/bootstrap/SparkBootstrapCommitActionExecutor.java", "diffHunk": "@@ -222,6 +225,17 @@ protected void commit(Option<Map<String, String>> extraMetadata, HoodieWriteMeta\n     LOG.info(\"Committing metadata bootstrap !!\");\n   }\n \n+  @Override\n+  protected void syncTableMetadata() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTgzMDc0MTcy", "url": "https://github.com/apache/hudi/pull/2374#pullrequestreview-583074172", "createdAt": "2021-02-04T06:37:56Z", "commit": {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf"}, "state": "COMMENTED", "comments": {"totalCount": 35, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQxOTo1NTo1M1rOIwjEQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQwOToyMDoyNVrOIw5otA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc3NzA4OQ==", "bodyText": "I kept it here because WriteOperationType is also here.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587777089", "createdAt": "2021-03-04T19:55:53Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -30,16 +31,19 @@\n import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n+import org.apache.hudi.client.lock.TransactionManager;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n import org.apache.hudi.common.model.HoodieKey;\n import org.apache.hudi.common.model.HoodieRecordPayload;\n import org.apache.hudi.common.model.HoodieWriteStat;\n+import org.apache.hudi.common.model.TableService;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1MDU3NA=="}, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc3OTUwOA==", "bodyText": "I also realized this during implementation but wanted to keep beginTransaction(..) API simple. I've added a overridden method now", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587779508", "createdAt": "2021-03-04T19:58:03Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -359,10 +388,21 @@ public abstract O bulkInsertPreppedRecords(I preppedRecords, final String instan\n    * Common method containing steps to be performed before write (upsert/insert/...\n    * @param instantTime\n    * @param writeOperationType\n+   * @param metaClient\n    */\n-  protected void preWrite(String instantTime, WriteOperationType writeOperationType) {\n+  protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n+      HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    syncTableMetadata();\n+    this.txnManager.setLastCompletedTransaction(metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant());\n+    LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \" + this.txnManager.getLastCompletedTransactionOwner());\n+    this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)));\n+    this.txnManager.beginTransaction();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NDQxMA=="}, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxMzY4NA==", "bodyText": "So this is being passed to allow for the metadata to be manipulated to do some kind of conflict resolution. Right now it's not being used anywhere, I can remove it but will need to be added sometime soon when we need to do conflict resolution more than just throwing exception.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587813684", "createdAt": "2021-03-04T20:47:24Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.ApiMaturityLevel;\n+import org.apache.hudi.PublicAPIMethod;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+\n+import java.util.stream.Stream;\n+\n+/**\n+ * Strategy interface for conflict resolution with multiple writers.\n+ * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n+ * writers are mutating the hoodie table.\n+ */\n+public interface ConflictResolutionStrategy {\n+\n+  /**\n+   * Stream of instants to check conflicts against.\n+   * @return\n+   */\n+  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+\n+  /**\n+   * Implementations of this method will determine whether a conflict exists between 2 commits.\n+   * @param thisOperation\n+   * @param otherOperation\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n+\n+  /**\n+   * Implementations of this method will determine how to resolve a conflict between 2 commits.\n+   * @param thisOperation\n+   * @param otherOperation\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNTUwNg=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxNjA5NQ==", "bodyText": "So this is just wrap the CommitMetadata to a common payload. ConflictingOperation suggests this is already a conflicting operation which it is not yet. Open to other suggestions if you have", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587816095", "createdAt": "2021-03-04T20:51:22Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.CommitUtils;\n+import org.apache.hudi.common.util.Option;\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMMIT_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.DELTA_COMMIT_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is used to hold all information used to identify how to resolve conflicts between instants.\n+ * Since we interchange payload types between AVRO specific records and POJO's, this object serves as\n+ * a common payload to manage these conversions.\n+ */\n+public class HoodieCommitOperation {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNjEzMQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxNjcwNQ==", "bodyText": "Used HoodieTimeline.INIT_INSTANT_TS now", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587816705", "createdAt": "2021-03-04T20:52:29Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMDkxOA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxNzA5OQ==", "bodyText": "I can make it WARN. This is useful to debug issues and INFO might get ignored.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587817099", "createdAt": "2021-03-04T20:53:11Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMTc4NQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxOTg2MA==", "bodyText": "The synchronized method is just for testing to start the ZK else parallel tests end up triggering start multiple times and that causes issues.. Since we don't use @VisibleTesting, I've put a comment", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587819860", "createdAt": "2021-03-04T20:57:33Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxODMwMA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgyNTIzOQ==", "bodyText": "I've removed the method for now to be sure no one uses it.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587825239", "createdAt": "2021-03-04T21:06:52Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+import org.apache.hudi.avro.model.HoodieCompactionPlan;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n+import org.apache.hudi.avro.model.HoodieSavepointMetadata;\n+import org.apache.hudi.client.ReplaceArchivalHelper;\n+import org.apache.hudi.common.model.ActionType;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CompactionUtils;\n+import java.io.IOException;\n+\n+/**\n+ * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n+ */\n+public class HoodieMetadataConversionUtils {\n+\n+  public static HoodieArchivedMetaEntry createMetaWrapper(HoodieInstant hoodieInstant, HoodieTableMetaClient metaClient) throws IOException {\n+    HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();\n+    archivedMetaWrapper.setCommitTime(hoodieInstant.getTimestamp());\n+    archivedMetaWrapper.setActionState(hoodieInstant.getState().name());\n+    switch (hoodieInstant.getAction()) {\n+      case HoodieTimeline.CLEAN_ACTION: {\n+        if (hoodieInstant.isCompleted()) {\n+          archivedMetaWrapper.setHoodieCleanMetadata(CleanerUtils.getCleanerMetadata(metaClient, hoodieInstant));\n+        } else {\n+          archivedMetaWrapper.setHoodieCleanerPlan(CleanerUtils.getCleanerPlan(metaClient, hoodieInstant));\n+        }\n+        archivedMetaWrapper.setActionType(ActionType.clean.name());\n+        break;\n+      }\n+      case HoodieTimeline.COMMIT_ACTION:\n+      case HoodieTimeline.DELTA_COMMIT_ACTION: {\n+        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n+                .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieCommitMetadata.class);\n+        archivedMetaWrapper.setHoodieCommitMetadata(convertCommitMetadata(commitMetadata));\n+        archivedMetaWrapper.setActionType(ActionType.commit.name());\n+        break;\n+      }\n+      case HoodieTimeline.REPLACE_COMMIT_ACTION: {\n+        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n+                .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieReplaceCommitMetadata.class);\n+        archivedMetaWrapper.setHoodieReplaceCommitMetadata(ReplaceArchivalHelper.convertReplaceCommitMetadata(replaceCommitMetadata));\n+        archivedMetaWrapper.setActionType(ActionType.replacecommit.name());\n+        break;\n+      }\n+      case HoodieTimeline.ROLLBACK_ACTION: {\n+        archivedMetaWrapper.setHoodieRollbackMetadata(TimelineMetadataUtils.deserializeAvroMetadata(\n+                metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieRollbackMetadata.class));\n+        archivedMetaWrapper.setActionType(ActionType.rollback.name());\n+        break;\n+      }\n+      case HoodieTimeline.SAVEPOINT_ACTION: {\n+        archivedMetaWrapper.setHoodieSavePointMetadata(TimelineMetadataUtils.deserializeAvroMetadata(\n+                metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieSavepointMetadata.class));\n+        archivedMetaWrapper.setActionType(ActionType.savepoint.name());\n+        break;\n+      }\n+      case HoodieTimeline.COMPACTION_ACTION: {\n+        HoodieCompactionPlan plan = CompactionUtils.getCompactionPlan(metaClient, hoodieInstant.getTimestamp());\n+        archivedMetaWrapper.setHoodieCompactionPlan(plan);\n+        archivedMetaWrapper.setActionType(ActionType.compaction.name());\n+        break;\n+      }\n+      default: {\n+        throw new UnsupportedOperationException(\"Action not fully supported yet\");\n+      }\n+    }\n+    return archivedMetaWrapper;\n+  }\n+\n+  public static HoodieArchivedMetaEntry createMetaWrapper(HoodieInstant hoodieInstant,\n+                                                          HoodieCommitMetadata hoodieCommitMetadata) {\n+    HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();\n+    archivedMetaWrapper.setCommitTime(hoodieInstant.getTimestamp());\n+    archivedMetaWrapper.setActionState(hoodieInstant.getState().name());\n+    archivedMetaWrapper.setHoodieCommitMetadata(convertCommitMetadata(hoodieCommitMetadata));\n+    archivedMetaWrapper.setActionType(ActionType.commit.name());\n+    return archivedMetaWrapper;\n+  }\n+\n+  public static org.apache.hudi.avro.model.HoodieCommitMetadata convertCommitMetadata(\n+          HoodieCommitMetadata hoodieCommitMetadata) {\n+    ObjectMapper mapper = new ObjectMapper();\n+    // Need this to ignore other public get() methods\n+    mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);\n+    org.apache.hudi.avro.model.HoodieCommitMetadata avroMetaData =\n+            mapper.convertValue(hoodieCommitMetadata, org.apache.hudi.avro.model.HoodieCommitMetadata.class);\n+    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer\n+    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n+    return avroMetaData;\n+  }\n+\n+  // TODO : Fix converting from SpecificRecord to POJO", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMTcxMg=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgyNTY0MQ==", "bodyText": "Replied above.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587825641", "createdAt": "2021-03-04T21:07:10Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.HoodieCommitOperation;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import java.io.IOException;\n+import java.util.stream.Stream;\n+\n+public class TransactionUtils {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionUtils.class);\n+\n+  /**\n+   * Resolve any write conflicts when committing data.\n+   * @param table\n+   * @param metadataWriter\n+   * @param currentTxnOwnerInstant\n+   * @param thisCommitMetadata\n+   * @param config\n+   * @param lastCompletedTxnOwnerInstant\n+   * @return\n+   * @throws HoodieWriteConflictException\n+   */\n+  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieBackedTableMetadataWriter> metadataWriter,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMzU0NA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgyNjgwMA==", "bodyText": "I put this TODO since we are going to need a way to use the MetadataWriter to manipulate any concurrent actions performed, we will address this use-case in a follow up PR. I have removed metadata writer for now.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587826800", "createdAt": "2021-03-04T21:08:16Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.HoodieCommitOperation;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import java.io.IOException;\n+import java.util.stream.Stream;\n+\n+public class TransactionUtils {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionUtils.class);\n+\n+  /**\n+   * Resolve any write conflicts when committing data.\n+   * @param table\n+   * @param metadataWriter\n+   * @param currentTxnOwnerInstant\n+   * @param thisCommitMetadata\n+   * @param config\n+   * @param lastCompletedTxnOwnerInstant\n+   * @return\n+   * @throws HoodieWriteConflictException\n+   */\n+  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieBackedTableMetadataWriter> metadataWriter,\n+                                                                       final Option<HoodieInstant> currentTxnOwnerInstant, final Option<HoodieCommitMetadata> thisCommitMetadata,\n+                                                                       final HoodieWriteConfig config, Option<HoodieInstant> lastCompletedTxnOwnerInstant)\n+      throws HoodieWriteConflictException {\n+    if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n+      Stream<HoodieInstant> instantStream = resolutionStrategy.getInstantsStream(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n+      // TODO : metadataWriter.reload() inside resolve write conflict ??", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMjA1Ng=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzMDk5OA==", "bodyText": "These configs are cross used for HiveMetastoreLockProvider which does not depend on hudi-client-common. Hence these are in hudi-common", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587830998", "createdAt": "2021-03-04T21:15:47Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.config;\n+\n+import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n+import org.apache.hudi.common.config.DefaultHoodieConfig;\n+import org.apache.hudi.common.lock.LockProvider;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNzk0Ng=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzMTQzNA==", "bodyText": "Yes, no change.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587831434", "createdAt": "2021-03-04T21:16:36Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanPlanActionExecutor.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.clean;\n+\n+import org.apache.hudi.avro.model.HoodieActionInstant;\n+import org.apache.hudi.avro.model.HoodieCleanFileInfo;\n+import org.apache.hudi.avro.model.HoodieCleanerPlan;\n+import org.apache.hudi.common.engine.HoodieEngineContext;\n+import org.apache.hudi.common.model.HoodieCleaningPolicy;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.collection.Pair;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.table.action.BaseActionExecutor;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+public abstract class BaseCleanPlanActionExecutor<T extends HoodieRecordPayload, I, K, O> extends BaseActionExecutor<T, I, K, O, Option<HoodieCleanerPlan>> {\n+\n+  private static final Logger LOG = LogManager.getLogger(CleanPlanner.class);\n+\n+  private final Option<Map<String, String>> extraMetadata;\n+\n+  public BaseCleanPlanActionExecutor(HoodieEngineContext context,\n+                                     HoodieWriteConfig config,\n+                                     HoodieTable<T, I, K, O> table,\n+                                     String instantTime,\n+                                     Option<Map<String, String>> extraMetadata) {\n+    super(context, config, table, instantTime);\n+    this.extraMetadata = extraMetadata;\n+  }\n+\n+  protected abstract Option<HoodieCleanerPlan> createCleanerPlan();\n+\n+  /**\n+   * Generates List of files to be cleaned.\n+   *\n+   * @param context HoodieEngineContext\n+   * @return Cleaner Plan\n+   */\n+  HoodieCleanerPlan requestClean(HoodieEngineContext context) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMzI2NQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzMTg4Nw==", "bodyText": "Removed metadata writer for now.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587831887", "createdAt": "2021-03-04T21:17:21Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java", "diffHunk": "@@ -117,12 +126,24 @@ protected String getCommitActionType() {\n   protected void commitOnAutoCommit(HoodieWriteMetadata result) {\n     if (config.shouldAutoCommit()) {\n       LOG.info(\"Auto commit enabled: Committing \" + instantTime);\n-      commit(extraMetadata, result);\n+      autoCommit(extraMetadata, result);\n     } else {\n       LOG.info(\"Auto commit disabled for \" + instantTime);\n     }\n   }\n \n+  protected void autoCommit(Option<Map<String, String>> extraMetadata, HoodieWriteMetadata<O> result) {\n+    this.txnManager.beginTransaction();\n+    try {\n+      // TODO : Refactor this method so we can pass a valid metadata table writer", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczNTY0MQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzMzcyNg==", "bodyText": "Reverted", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587833726", "createdAt": "2021-03-04T21:20:30Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -401,13 +441,25 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try (HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n+    try {\n+      HoodieTableMetadataWriter writer =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0OTU3MQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzNDIzOA==", "bodyText": "removed the metadtawriter.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587834238", "createdAt": "2021-03-04T21:21:31Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -401,13 +441,25 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try (HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n+    try {\n+      HoodieTableMetadataWriter writer =\n+          SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n     }\n   }\n \n+  @Override\n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MDAxOQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzNjk4Mw==", "bodyText": "I feel supportsOptimisticConcurrencyControl as it is more direct vs isOptimisticConcurrencyControl which sounds a little weird. Let me know if you have a strong preference.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587836983", "createdAt": "2021-03-04T21:26:16Z", "author": {"login": "n3nash"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Different concurrency modes for write operations.\n+ */\n+public enum WriteConcurrencyMode {\n+  // Only a single writer can perform write ops\n+  SINGLE_WRITER(\"single_writer\"),\n+  // Multiple writer can perform write ops with lazy conflict resolution using locks\n+  OPTIMISTIC_CONCURRENCY_CONTROL(\"optimistic_concurrency_control\");\n+\n+  private final String value;\n+\n+  WriteConcurrencyMode(String value) {\n+    this.value = value;\n+  }\n+\n+  /**\n+   * Getter for write concurrency mode.\n+   * @return\n+   */\n+  public String value() {\n+    return value;\n+  }\n+\n+  /**\n+   * Convert string value to WriteConcurrencyMode.\n+   */\n+  public static WriteConcurrencyMode fromValue(String value) {\n+    switch (value.toLowerCase(Locale.ROOT)) {\n+      case \"single_writer\":\n+        return SINGLE_WRITER;\n+      case \"optimistic_concurrency_control\":\n+        return OPTIMISTIC_CONCURRENCY_CONTROL;\n+      default:\n+        throw new HoodieException(\"Invalid value of Type.\");\n+    }\n+  }\n+\n+  public boolean supportsOptimisticConcurrencyControl() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTQ3MA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzNzUyNg==", "bodyText": "This was introduced to address older metadata when we don't store the WriteOperationType in the metadata..", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587837526", "createdAt": "2021-03-04T21:27:14Z", "author": {"login": "n3nash"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteOperationType.java", "diffHunk": "@@ -82,6 +84,10 @@ public static WriteOperationType fromValue(String value) {\n         return INSERT_OVERWRITE_TABLE;\n       case \"cluster\":\n         return CLUSTER;\n+      case \"compact\":\n+        return COMPACT;\n+      case \"unknown\":", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTk4MQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg2NzE5MA==", "bodyText": "I want to mark some methods as not implementable which is why abstract class is chosen", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587867190", "createdAt": "2021-03-04T22:18:18Z", "author": {"login": "n3nash"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczOTI1NQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg2ODY4Mw==", "bodyText": "This is the base path for the zk lock which users can select. I have not exposed a config to change the chroot. This will be the default.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587868683", "createdAt": "2021-03-04T22:21:03Z", "author": {"login": "n3nash"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.config;\n+\n+import java.io.Serializable;\n+import java.util.Properties;\n+\n+/**\n+ * Configuration for managing locks. Since this configuration needs to be shared with HiveMetaStore based lock,\n+ * which is in a different package than other lock providers, we use this as a data transfer object in hoodie-common\n+ */\n+public class LockConfiguration implements Serializable {\n+\n+  public static final String LOCK_PREFIX = \"hoodie.writer.lock.\";\n+  public static final String LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(5000L);\n+  public static final String LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"client.wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(10000L);\n+  public static final String LOCK_ACQUIRE_NUM_RETRIES_PROP = LOCK_PREFIX + \"num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_NUM_RETRIES = String.valueOf(3);\n+  public static final String LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP = LOCK_PREFIX + \"client.num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_NUM_RETRIES = String.valueOf(0);\n+  public static final String LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP = LOCK_PREFIX + \"wait_time_ms\";\n+  public static final int DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS = 60 * 1000;\n+  // configs for file system based locks. NOTE: This only works for DFS with atomic create/delete operation\n+  public static final String FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"filesystem.\";\n+  public static final String FILESYSTEM_LOCK_PATH_PROP = FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX + \"path\";\n+  // configs for metastore based locks\n+  public static final String HIVE_METASTORE_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"hivemetastore.\";\n+  public static final String HIVE_DATABASE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"database\";\n+  public static final String HIVE_TABLE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"table\";\n+  // Zookeeper configs for zk based locks\n+  public static final String ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"zookeeper.\";\n+  public static final String ZK_BASE_PATH_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"zk_base_path\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczODA3OA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg3MDI3Ng==", "bodyText": "This is required due to autoCommit code in BaseCommitActionExecutor. We already have to take a lock in BaseCommitActionExecutor for committing the data, instead of taking a lock again in the write client level, I have moved this sync into the same critical section as commit.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587870276", "createdAt": "2021-03-04T22:24:19Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/bootstrap/SparkBootstrapCommitActionExecutor.java", "diffHunk": "@@ -222,6 +225,17 @@ protected void commit(Option<Map<String, String>> extraMetadata, HoodieWriteMeta\n     LOG.info(\"Committing metadata bootstrap !!\");\n   }\n \n+  @Override\n+  protected void syncTableMetadata() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MTEwMA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg3MzI5NQ==", "bodyText": "So basically the following is a use-case for us in production :\n\nWriter starts to write fresh data to files f1,f2, c1 is inflight\nSchedule clustering, c2.cluster for files f1,f2\nc1 and c2 in progress\nc2.cluster finishes\nc1 attempts to finish and notices that c2 has overlapping file ids and aborts\n\nWe want to override the priority of c1 over c2 to avoid violating freshness SLA. A design and PR for this is going to follow after this PR is landed.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587873295", "createdAt": "2021-03-04T22:29:59Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n+      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed\n+      // this.rollbackFailedWrites();\n+      this.txnManager.beginTransaction();\n+      try {\n+        // Ensure no inflight commits\n+        TransactionUtils.resolveConflictIfAnyForUpgradeDowngrade(metaClient);\n+        new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n+      } finally {\n+        this.txnManager.endTransaction();\n+      }\n+    }\n+    return getTableAndInitCtx(metaClient, operationType, instantTime);\n   }\n \n-  private HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(HoodieTableMetaClient metaClient, WriteOperationType operationType) {\n+  // TODO : To enforce priority between table service and ingestion writer, use transactions here and invoke strategy", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0ODM4Nw=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODAwMDU5MA==", "bodyText": "https://issues.apache.org/jira/browse/HUDI-1665", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588000590", "createdAt": "2021-03-05T03:09:49Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java", "diffHunk": "@@ -66,6 +70,11 @@ public BaseCommitActionExecutor(HoodieEngineContext context, HoodieWriteConfig c\n     this.operationType = operationType;\n     this.extraMetadata = extraMetadata;\n     this.taskContextSupplier = context.getTaskContextSupplier();\n+    this.txnManager = new TransactionManager(config, table.getMetaClient().getFs());\n+    // TODO : Remove this once we refactor and move out autoCommit method from here, since the TxnManager is held in {@link AbstractHoodieWriteClient}.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMzY0Mw=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODAwNTUwMQ==", "bodyText": "Currently, the clean metadata from runPendingClean is never returned if you see above in line 205. The current logic is as follows\n\nFor all pending clean operations, we just return null.\nIf there is new clean to be done, we do the new clean and return the metadata.\n\nClean metadata is always persisted before this method inside the runClean method and the return value of this method is NOT used by the client.\nI made above changes to reuse the same methods and  to keep the same behavior, except with one change :\n\nFor all pending clean operations, we return the latest pending clean from previous runs.\nIf there is new clean to be done, we do the new clean and return the metadata.\n\nOther logic remains the same. The returned metadata is ONLY used for a) Logging b) Metrics.\nLet's refactor all these issues in the ActionExecutor in follow up PR. Filed issue here -> https://issues.apache.org/jira/browse/HUDI-1666", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588005501", "createdAt": "2021-03-05T03:26:48Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanActionExecutor.java", "diffHunk": "@@ -195,30 +126,24 @@ private HoodieCleanMetadata runClean(HoodieTable<T, I, K, O> table, HoodieInstan\n \n   @Override\n   public HoodieCleanMetadata execute() {\n+    List<HoodieCleanMetadata> cleanMetadataList = new ArrayList<>();\n     // If there are inflight(failed) or previously requested clean operation, first perform them\n     List<HoodieInstant> pendingCleanInstants = table.getCleanTimeline()\n         .filterInflightsAndRequested().getInstants().collect(Collectors.toList());\n     if (pendingCleanInstants.size() > 0) {\n       pendingCleanInstants.forEach(hoodieInstant -> {\n         LOG.info(\"Finishing previously unfinished cleaner instant=\" + hoodieInstant);\n         try {\n-          runPendingClean(table, hoodieInstant);\n+          cleanMetadataList.add(runPendingClean(table, hoodieInstant));\n         } catch (Exception e) {\n           LOG.warn(\"Failed to perform previous clean operation, instant: \" + hoodieInstant, e);\n         }\n       });\n       table.getMetaClient().reloadActiveTimeline();\n     }\n-\n-    // Plan and execute a new clean action\n-    Option<HoodieCleanerPlan> cleanerPlanOpt = requestClean(instantTime);\n-    if (cleanerPlanOpt.isPresent()) {\n-      table.getMetaClient().reloadActiveTimeline();\n-      HoodieCleanerPlan cleanerPlan = cleanerPlanOpt.get();\n-      if ((cleanerPlan.getFilePathsToBeDeletedPerPartition() != null) && !cleanerPlan.getFilePathsToBeDeletedPerPartition().isEmpty()) {\n-        return runClean(table, HoodieTimeline.getCleanRequestedInstant(instantTime), cleanerPlan);\n-      }\n-    }\n-    return null;\n+    // return the last clean metadata for now\n+    // TODO (NA) : Clean only the earliest pending clean just like how we do for other table services", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMTc1Mw=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA0NDcxMg==", "bodyText": "checked", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588044712", "createdAt": "2021-03-05T05:37:14Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.config;\n+\n+import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n+import org.apache.hudi.common.config.DefaultHoodieConfig;\n+import org.apache.hudi.common.lock.LockProvider;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_CLIENT_NUM_RETRIES;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_NUM_RETRIES;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_DATABASE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_TABLE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_PREFIX;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_PORT_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+\n+/**\n+ * Hoodie Configs for Locks.\n+ */\n+public class HoodieLockConfig extends DefaultHoodieConfig {\n+\n+  // Pluggable type of lock provider\n+  public static final String LOCK_PROVIDER_CLASS_PROP = LOCK_PREFIX + \"provider\";\n+  public static final String DEFAULT_LOCK_PROVIDER_CLASS = ZookeeperBasedLockProvider.class.getName();\n+  // Pluggable strategies to use when resolving conflicts\n+  public static final String WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP =\n+      LOCK_PREFIX + \"conflict.resolution.strategy\";\n+  public static final String DEFAULT_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS =\n+      SimpleConcurrentFileWritesConflictResolutionStrategy.class.getName();\n+\n+  private HoodieLockConfig(Properties props) {\n+    super(props);\n+  }\n+\n+  public static HoodieLockConfig.Builder newBuilder() {\n+    return new HoodieLockConfig.Builder();\n+  }\n+\n+  public static class Builder {\n+\n+    private final Properties props = new Properties();\n+\n+    public HoodieLockConfig.Builder fromFile(File propertiesFile) throws IOException {\n+      try (FileReader reader = new FileReader(propertiesFile)) {\n+        this.props.load(reader);\n+        return this;\n+      }\n+    }\n+\n+    public HoodieLockConfig.Builder fromProperties(Properties props) {\n+      this.props.putAll(props);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withLockProvider(Class<? extends LockProvider> lockProvider) {\n+      props.setProperty(LOCK_PROVIDER_CLASS_PROP, lockProvider.getName());\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withHiveDatabaseName(String databaseName) {\n+      props.setProperty(HIVE_DATABASE_NAME_PROP, databaseName);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withHiveTableName(String tableName) {\n+      props.setProperty(HIVE_TABLE_NAME_PROP, tableName);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkQuorum(String zkQuorum) {\n+      props.setProperty(ZK_CONNECT_URL_PROP, zkQuorum);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkBasePath(String zkBasePath) {\n+      props.setProperty(ZK_BASE_PATH_PROP, zkBasePath);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkPort(String zkPort) {\n+      props.setProperty(ZK_PORT_PROP, zkPort);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkLockKey(String zkLockKey) {\n+      props.setProperty(ZK_LOCK_KEY_PROP, zkLockKey);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkConnectionTimeoutInMs(Long connectionTimeoutInMs) {\n+      props.setProperty(ZK_CONNECTION_TIMEOUT_MS_PROP, String.valueOf(connectionTimeoutInMs));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkSessionTimeoutInMs(Long sessionTimeoutInMs) {\n+      props.setProperty(ZK_SESSION_TIMEOUT_MS_PROP, String.valueOf(sessionTimeoutInMs));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withNumRetries(int numRetries) {\n+      props.setProperty(LOCK_ACQUIRE_NUM_RETRIES_PROP, String.valueOf(numRetries));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withRetryWaitTimeInMillis(Long retryWaitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP, String.valueOf(retryWaitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withClientNumRetries(int clientNumRetries) {\n+      props.setProperty(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP, String.valueOf(clientNumRetries));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withClientRetryWaitTimeInMillis(Long clientRetryWaitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP, String.valueOf(clientRetryWaitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withLockWaitTimeInMillis(Long waitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP, String.valueOf(waitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withConflictResolutionStrategy(ConflictResolutionStrategy conflictResolutionStrategy) {\n+      props.setProperty(WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP, conflictResolutionStrategy.getClass().getName());\n+      return this;\n+    }\n+\n+    public HoodieLockConfig build() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyOTI1Mg=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA0NTA4OQ==", "bodyText": "done", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588045089", "createdAt": "2021-03-05T05:38:24Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java", "diffHunk": "@@ -114,6 +115,7 @@\n       HoodieFailedWritesCleaningPolicy.EAGER.name();\n   private static final String DEFAULT_AUTO_CLEAN = \"true\";\n   private static final String DEFAULT_ASYNC_CLEAN = \"false\";\n+  private static final String DEFAULT_INLINE_CLEAN = DEFAULT_AUTO_CLEAN;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNjUwNw=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA2Mjk0OQ==", "bodyText": "Yes, both providers underlying implementation return void but throw exceptions", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588062949", "createdAt": "2021-03-05T06:32:45Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.config.SerializableConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ReflectionUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * This class wraps implementations of {@link LockProvider} and provides an easy way to manage the lifecycle of a lock.\n+ */\n+public class LockManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockManager.class);\n+  private final HoodieWriteConfig writeConfig;\n+  private final LockConfiguration lockConfiguration;\n+  private final SerializableConfiguration hadoopConf;\n+  private volatile LockProvider lockProvider;\n+  // Holds the latest completed write instant to know which ones to check conflict against\n+  private final AtomicReference<Option<HoodieInstant>> latestCompletedWriteInstant;\n+\n+  public LockManager(HoodieWriteConfig writeConfig, FileSystem fs) {\n+    this.latestCompletedWriteInstant = new AtomicReference<>(Option.empty());\n+    this.writeConfig = writeConfig;\n+    this.hadoopConf = new SerializableConfiguration(fs.getConf());\n+    this.lockConfiguration = new LockConfiguration(writeConfig.getProps());\n+  }\n+\n+  public void lock() {\n+    if (writeConfig.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      LockProvider lockProvider = getLockProvider();\n+      boolean acquired = false;\n+      try {\n+        int retries = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP);\n+        long waitTimeInMs = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP);\n+        int retryCount = 0;\n+        while (retryCount <= retries) {\n+          acquired = lockProvider.tryLock(writeConfig.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n+          if (acquired) {\n+            break;\n+          }\n+          LOG.info(\"Retrying...\");\n+          Thread.sleep(waitTimeInMs);\n+          retryCount++;\n+        }\n+      } catch (Exception e) {\n+        throw new HoodieLockException(\"Unable to acquire lock \", e);\n+      }\n+      if (!acquired) {\n+        throw new HoodieLockException(\"Unable to acquire lock, lock object \" + lockProvider.getLock());\n+      }\n+    }\n+  }\n+\n+  public void unlock() {\n+    if (writeConfig.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      getLockProvider().unlock();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwODIyMQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA2NjAwNw==", "bodyText": "If the lock was accepted by the LockProvider server but an interrupted exception happens then we rely on the fact that the lock will timeout after X mins (settings in HiveMetastore & Zookeeper). I have tested in in my production runs.\nI have added some special checks for HiveMetastore in case of interruptedException but for Zookeeper it's not possible to do those checks.\n acquired = lockProvider.tryLock(writeConfig.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n          if (acquired) {\n            break;\n          }\n\nAnother extremely low probability is for the above code, lock is acquired but the running thread gets Interrupted before it can break. Again in this case, we just rely on the Lock Timeout on the server side of the LockProviders.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588066007", "createdAt": "2021-03-05T06:40:54Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.config.SerializableConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ReflectionUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * This class wraps implementations of {@link LockProvider} and provides an easy way to manage the lifecycle of a lock.\n+ */\n+public class LockManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockManager.class);\n+  private final HoodieWriteConfig writeConfig;\n+  private final LockConfiguration lockConfiguration;\n+  private final SerializableConfiguration hadoopConf;\n+  private volatile LockProvider lockProvider;\n+  // Holds the latest completed write instant to know which ones to check conflict against\n+  private final AtomicReference<Option<HoodieInstant>> latestCompletedWriteInstant;\n+\n+  public LockManager(HoodieWriteConfig writeConfig, FileSystem fs) {\n+    this.latestCompletedWriteInstant = new AtomicReference<>(Option.empty());\n+    this.writeConfig = writeConfig;\n+    this.hadoopConf = new SerializableConfiguration(fs.getConf());\n+    this.lockConfiguration = new LockConfiguration(writeConfig.getProps());\n+  }\n+\n+  public void lock() {\n+    if (writeConfig.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      LockProvider lockProvider = getLockProvider();\n+      boolean acquired = false;\n+      try {\n+        int retries = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP);\n+        long waitTimeInMs = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP);\n+        int retryCount = 0;\n+        while (retryCount <= retries) {\n+          acquired = lockProvider.tryLock(writeConfig.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n+          if (acquired) {\n+            break;\n+          }\n+          LOG.info(\"Retrying...\");\n+          Thread.sleep(waitTimeInMs);\n+          retryCount++;\n+        }\n+      } catch (Exception e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNzY3OQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA4Njg1MQ==", "bodyText": "Re-did the comments let me know if it's more clear now.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588086851", "createdAt": "2021-03-05T07:34:02Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation\n+          + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n+                                              HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC. Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation as a regular commit.\n+    if (otherOperation.getOperationType() == WriteOperationType.UNKNOWN", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMzU4Ng=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODExODMyMw==", "bodyText": "ZK & Curator comes with Hbase-Server. Do you want me to add it explicitly in the bundles ?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588118323", "createdAt": "2021-03-05T08:34:56Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNjYxMA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODExOTc1OA==", "bodyText": "Right now, endTransaction() is doing the job or end & abort - no difference in behavior. Both ensure that if lock was acquired release and cleanup other state.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588119758", "createdAt": "2021-03-05T08:37:21Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -359,10 +388,21 @@ public abstract O bulkInsertPreppedRecords(I preppedRecords, final String instan\n    * Common method containing steps to be performed before write (upsert/insert/...\n    * @param instantTime\n    * @param writeOperationType\n+   * @param metaClient\n    */\n-  protected void preWrite(String instantTime, WriteOperationType writeOperationType) {\n+  protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n+      HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    syncTableMetadata();\n+    this.txnManager.setLastCompletedTransaction(metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant());\n+    LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \" + this.txnManager.getLastCompletedTransactionOwner());\n+    this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)));\n+    this.txnManager.beginTransaction();\n+    try {\n+      syncTableMetadata();\n+    } finally {\n+      this.txnManager.endTransaction();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NTM5Nw=="}, "originalCommit": {"oid": "61275eac2605bdb087762050588603bab4c4ee2d"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODEyNDgyNQ==", "bodyText": "This is not the code on my local. Something amiss happened during rebase and squash commits on my local. I have re-done the merge to ensure nothing got lost.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588124825", "createdAt": "2021-03-05T08:45:58Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+  }\n+  \n+  public void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    newLock.acquire(time, unit);\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    }\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    try {\n+      acquireLock(time, unit);\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMDc5Nw=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODEyNDk3Ng==", "bodyText": "Added one now", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588124976", "createdAt": "2021-03-05T08:46:15Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+import org.apache.hudi.avro.model.HoodieCompactionPlan;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n+import org.apache.hudi.avro.model.HoodieSavepointMetadata;\n+import org.apache.hudi.client.ReplaceArchivalHelper;\n+import org.apache.hudi.common.model.ActionType;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CompactionUtils;\n+import java.io.IOException;\n+\n+/**\n+ * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n+ */\n+public class HoodieMetadataConversionUtils {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMTQyMA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODE0MDYzMg==", "bodyText": "I was trying to keep the same concepts of inline for clustering, compact. The problem is there are autoClean & autoCommit but no autoCompact or autoCluster etc. Additionally, we used inline as the flag to toggle between inline & async for compact & cluster while we have chosen async as the flag for clean.\nI have removed hoodie.clean.inline. We can address these in another PR after we decide what convention to follow.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588140632", "createdAt": "2021-03-05T09:10:54Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java", "diffHunk": "@@ -43,7 +43,8 @@\n   public static final String CLEANER_POLICY_PROP = \"hoodie.cleaner.policy\";\n   public static final String AUTO_CLEAN_PROP = \"hoodie.clean.automatic\";\n   public static final String ASYNC_CLEAN_PROP = \"hoodie.clean.async\";\n-\n+  // Turn on inline cleaning\n+  public static final String INLINE_CLEAN_PROP = \"hoodie.clean.inline\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNTgxNw=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODE0MTI1Mw==", "bodyText": "Added", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588141253", "createdAt": "2021-03-05T09:11:59Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NzU4MA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODE0Njg2OA==", "bodyText": "Yeah, had a TODO on this, addressed it now.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588146868", "createdAt": "2021-03-05T09:20:25Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java", "diffHunk": "@@ -265,6 +266,20 @@ public void rollbackBootstrap(HoodieEngineContext context, String instantTime) {\n     throw new HoodieNotSupportedException(\"Bootstrap is not supported yet\");\n   }\n \n+  /**\n+   * TODO :\n+   * Refactor {@link FlinkCleanActionExecutor} to support scheduling of cleaning.\n+   * @param context HoodieEngineContext\n+   * @param instantTime Instant Time for scheduling cleaning\n+   * @param extraMetadata additional metadata to write into plan\n+   * @return\n+   */\n+  @Override\n+  public Option<HoodieCleanerPlan> scheduleCleaning(HoodieEngineContext context, String instantTime, Option<Map<String, String>> extraMetadata) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NDMwNg=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 21}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/27bae91298c897984335b1c6c3b39e758d962e6b", "committedDate": "2021-03-04T07:50:21Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "b40c06af091472daa40db8bf777bea1f3d06c16c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/b40c06af091472daa40db8bf777bea1f3d06c16c", "committedDate": "2021-03-05T09:21:08Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b40c06af091472daa40db8bf777bea1f3d06c16c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/b40c06af091472daa40db8bf777bea1f3d06c16c", "committedDate": "2021-03-05T09:21:08Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "c9ded3690d29b22a910eac381001995297084bcb", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/c9ded3690d29b22a910eac381001995297084bcb", "committedDate": "2021-03-05T09:27:17Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c9ded3690d29b22a910eac381001995297084bcb", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/c9ded3690d29b22a910eac381001995297084bcb", "committedDate": "2021-03-05T09:27:17Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "630f1410aadd947d3f2c9fa0d6a4f69cd67e1c4f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/630f1410aadd947d3f2c9fa0d6a4f69cd67e1c4f", "committedDate": "2021-03-05T18:05:55Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "630f1410aadd947d3f2c9fa0d6a4f69cd67e1c4f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/630f1410aadd947d3f2c9fa0d6a4f69cd67e1c4f", "committedDate": "2021-03-05T18:05:55Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "committedDate": "2021-03-05T18:37:24Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA1NTY5Nzky", "url": "https://github.com/apache/hudi/pull/2374#pullrequestreview-605569792", "createdAt": "2021-03-05T20:19:47Z", "commit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQyMDoxOTo0N1rOIxZGcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQyMDoyMTowN1rOIxZLXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY2MjM4Nw==", "bodyText": "lets file a JIRA for clustering/concurrent updates.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588662387", "createdAt": "2021-03-05T20:19:47Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n+          + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation\n+    // as a regular commit. Regular commit, deltacommits and replace are candidates for conflict\n+    // replace is used for a) clustering without update support b) insert_overwrite both of which are\n+    // candidates for conflict. We need to add CLUSTER here once it supports concurrent updates", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY2MzY0Nw==", "bodyText": "vmacs:target vs$ jar tf hudi-spark-bundle_2.11-0.8.0-SNAPSHOT.jar | grep curator | wc -l\n       0\nvmacs:target vs$ jar tf hudi-spark-bundle_2.11-0.8.0-SNAPSHOT.jar | grep hbase | wc -l\n    4734\nvmacs:target vs$ \n\nDon't see curator, in fact.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588663647", "createdAt": "2021-03-05T20:21:07Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNjYxMA=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA1NTc1NTQ0", "url": "https://github.com/apache/hudi/pull/2374#pullrequestreview-605575544", "createdAt": "2021-03-05T20:28:54Z", "commit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQyMDoyODo1NFrOIxZqYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQyMDozMDoxM1rOIxZvmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3MTU4NQ==", "bodyText": "what about async clustering? would it raise an exception? may be it wont today, given its always picks non conflicting files alreayd?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588671585", "createdAt": "2021-03-05T20:28:54Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n+          + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation\n+    // as a regular commit. Regular commit, deltacommits and replace are candidates for conflict\n+    // replace is used for a) clustering without update support b) insert_overwrite both of which are\n+    // candidates for conflict. We need to add CLUSTER here once it supports concurrent updates\n+    // like COMPACT.\n+    if (otherOperation.getOperationType() == WriteOperationType.COMPACT", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3MjUyNg==", "bodyText": "I just want to ensure that async clustering can happen, as long as the the files don't overlap.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588672526", "createdAt": "2021-03-05T20:29:52Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n+          + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation\n+    // as a regular commit. Regular commit, deltacommits and replace are candidates for conflict\n+    // replace is used for a) clustering without update support b) insert_overwrite both of which are\n+    // candidates for conflict. We need to add CLUSTER here once it supports concurrent updates\n+    // like COMPACT.\n+    if (otherOperation.getOperationType() == WriteOperationType.COMPACT", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3MTU4NQ=="}, "originalCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3MjkyMQ==", "bodyText": "See newer review, for followup", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588672921", "createdAt": "2021-03-05T20:30:13Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation\n+          + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n+                                              HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC. Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation as a regular commit.\n+    if (otherOperation.getOperationType() == WriteOperationType.UNKNOWN", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMzU4Ng=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 94}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA1NTgwNTY3", "url": "https://github.com/apache/hudi/pull/2374#pullrequestreview-605580567", "createdAt": "2021-03-05T20:37:12Z", "commit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQyMDozNzoxMlrOIxaI3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQyMDo0MTowNVrOIxaXZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3OTM5MA==", "bodyText": "a better validation message, than just the enum name?  (applicable for any such usage)", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588679390", "createdAt": "2021-03-05T20:37:12Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private final CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    try {\n+      acquireLock(time, unit);\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n+    }\n+    return lock != null && lock.isAcquiredInThisProcess();\n+  }\n+\n+  @Override\n+  public void unlock() {\n+    try {\n+      LOG.info(generateLogStatement(LockState.RELEASING, generateLogSuffixString()));\n+      if (lock == null || !lock.isAcquiredInThisProcess()) {\n+        return;\n+      }\n+      lock.release();\n+      lock = null;\n+      LOG.info(generateLogStatement(LockState.RELEASED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()), e);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      if (lock != null) {\n+        lock.release();\n+        lock = null;\n+      }\n+      this.curatorFrameworkClient.close();\n+    } catch (Exception e) {\n+      LOG.error(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n+    }\n+  }\n+\n+  @Override\n+  public InterProcessMutex getLock() {\n+    return this.lock;\n+  }\n+\n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4MTU1NA==", "bodyText": "this will lead to a LockException being wrapped inside another LockException in tryLock()?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588681554", "createdAt": "2021-03-05T20:39:28Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private final CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    try {\n+      acquireLock(time, unit);\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n+    }\n+    return lock != null && lock.isAcquiredInThisProcess();\n+  }\n+\n+  @Override\n+  public void unlock() {\n+    try {\n+      LOG.info(generateLogStatement(LockState.RELEASING, generateLogSuffixString()));\n+      if (lock == null || !lock.isAcquiredInThisProcess()) {\n+        return;\n+      }\n+      lock.release();\n+      lock = null;\n+      LOG.info(generateLogStatement(LockState.RELEASED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()), e);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      if (lock != null) {\n+        lock.release();\n+        lock = null;\n+      }\n+      this.curatorFrameworkClient.close();\n+    } catch (Exception e) {\n+      LOG.error(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n+    }\n+  }\n+\n+  @Override\n+  public InterProcessMutex getLock() {\n+    return this.lock;\n+  }\n+\n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4MjE3OQ==", "bodyText": "Can we handle this specially and just rethrow the lock exception without the wrapping.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588682179", "createdAt": "2021-03-05T20:40:08Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private final CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    try {\n+      acquireLock(time, unit);\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n+    }\n+    return lock != null && lock.isAcquiredInThisProcess();\n+  }\n+\n+  @Override\n+  public void unlock() {\n+    try {\n+      LOG.info(generateLogStatement(LockState.RELEASING, generateLogSuffixString()));\n+      if (lock == null || !lock.isAcquiredInThisProcess()) {\n+        return;\n+      }\n+      lock.release();\n+      lock = null;\n+      LOG.info(generateLogStatement(LockState.RELEASED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()), e);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      if (lock != null) {\n+        lock.release();\n+        lock = null;\n+      }\n+      this.curatorFrameworkClient.close();\n+    } catch (Exception e) {\n+      LOG.error(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n+    }\n+  }\n+\n+  @Override\n+  public InterProcessMutex getLock() {\n+    return this.lock;\n+  }\n+\n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4MTU1NA=="}, "originalCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4MzEwOA==", "bodyText": "I think the actual code you have know handles this.", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588683108", "createdAt": "2021-03-05T20:41:05Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+  }\n+  \n+  public void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    newLock.acquire(time, unit);\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    }\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    try {\n+      acquireLock(time, unit);\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMDc5Nw=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 106}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA1Njc1NTU3", "url": "https://github.com/apache/hudi/pull/2374#pullrequestreview-605675557", "createdAt": "2021-03-05T23:06:34Z", "commit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQyMzowNjozNFrOIxf--w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNVQyMzowNzoxM1rOIxf_4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3NTE2Mw==", "bodyText": "is this a recursive call? won't it recurse infinitely?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588775163", "createdAt": "2021-03-05T23:06:34Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n+\n+  protected LockConfiguration lockConfiguration;\n+\n+  @Override\n+  public final void lockInterruptibly() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final void lock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final boolean tryLock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    try {\n+      return tryLock(time, unit);\n+    } catch (Exception e) {\n+      throw new HoodieLockException(e);\n+    }\n+  }\n+\n+  public T getLock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final Condition newCondition() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3NTI2Nw==", "bodyText": "same here. infinite loop?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588775267", "createdAt": "2021-03-05T23:06:50Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n+\n+  protected LockConfiguration lockConfiguration;\n+\n+  @Override\n+  public final void lockInterruptibly() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final void lock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final boolean tryLock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    try {\n+      return tryLock(time, unit);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3NTM5Mg==", "bodyText": "We can always to interface and default methods, right?", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588775392", "createdAt": "2021-03-05T23:07:13Z", "author": {"login": "vinothchandar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczOTI1NQ=="}, "originalCommit": {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b"}, "originalPosition": 34}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "committedDate": "2021-03-05T18:37:24Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "45e931ec410685bcc1ec8dd974560add27dac684", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/45e931ec410685bcc1ec8dd974560add27dac684", "committedDate": "2021-03-07T00:29:12Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f1372043f7e45a0d048f6db1be2f8dfa37615dec", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/f1372043f7e45a0d048f6db1be2f8dfa37615dec", "committedDate": "2021-03-10T07:43:18Z", "message": "refactor 2"}, "afterCommit": {"oid": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/1b41b773c6bb94ac28609bf829e875cefce6e5d3", "committedDate": "2021-03-10T08:08:24Z", "message": "refactor 2"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/1b41b773c6bb94ac28609bf829e875cefce6e5d3", "committedDate": "2021-03-10T08:08:24Z", "message": "refactor 2"}, "afterCommit": {"oid": "8cb6bd09678f320038a36b1d84e3b5739fab0a2e", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8cb6bd09678f320038a36b1d84e3b5739fab0a2e", "committedDate": "2021-03-11T06:03:11Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8cb6bd09678f320038a36b1d84e3b5739fab0a2e", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8cb6bd09678f320038a36b1d84e3b5739fab0a2e", "committedDate": "2021-03-11T06:03:11Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services"}, "afterCommit": {"oid": "c7323ada211503eae62842f5f2eb31769da2b8bc", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/c7323ada211503eae62842f5f2eb31769da2b8bc", "committedDate": "2021-03-11T07:19:41Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c7323ada211503eae62842f5f2eb31769da2b8bc", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/c7323ada211503eae62842f5f2eb31769da2b8bc", "committedDate": "2021-03-11T07:19:41Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}, "afterCommit": {"oid": "4888b0f34bbd8a6a55628e517f7e2db8a23ef59c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/4888b0f34bbd8a6a55628e517f7e2db8a23ef59c", "committedDate": "2021-03-11T07:28:06Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4888b0f34bbd8a6a55628e517f7e2db8a23ef59c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/4888b0f34bbd8a6a55628e517f7e2db8a23ef59c", "committedDate": "2021-03-11T07:28:06Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}, "afterCommit": {"oid": "9c678ffebf5e065f66f5bc0989b6af829fb3723c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/9c678ffebf5e065f66f5bc0989b6af829fb3723c", "committedDate": "2021-03-11T07:39:28Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9c678ffebf5e065f66f5bc0989b6af829fb3723c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/9c678ffebf5e065f66f5bc0989b6af829fb3723c", "committedDate": "2021-03-11T07:39:28Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}, "afterCommit": {"oid": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "committedDate": "2021-03-11T19:51:16Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "committedDate": "2021-03-11T19:51:16Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}, "afterCommit": {"oid": "8b50f955609cf85d32aefc47734a50b011c99339", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8b50f955609cf85d32aefc47734a50b011c99339", "committedDate": "2021-03-11T20:37:00Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8b50f955609cf85d32aefc47734a50b011c99339", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8b50f955609cf85d32aefc47734a50b011c99339", "committedDate": "2021-03-11T20:37:00Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}, "afterCommit": {"oid": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/02efbb661e7ed13c3614ddee7ab5157623070f7c", "committedDate": "2021-03-12T06:50:43Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/02efbb661e7ed13c3614ddee7ab5157623070f7c", "committedDate": "2021-03-12T06:50:43Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}, "afterCommit": {"oid": "b5c5c987c5fbf8e83ffac9288260ed2242b59c18", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/b5c5c987c5fbf8e83ffac9288260ed2242b59c18", "committedDate": "2021-03-12T08:08:26Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b5c5c987c5fbf8e83ffac9288260ed2242b59c18", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/b5c5c987c5fbf8e83ffac9288260ed2242b59c18", "committedDate": "2021-03-12T08:08:26Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}, "afterCommit": {"oid": "47403db3c55938e97a8e9baa21f65d6d09c04ee9", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/47403db3c55938e97a8e9baa21f65d6d09c04ee9", "committedDate": "2021-03-12T20:04:14Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "47403db3c55938e97a8e9baa21f65d6d09c04ee9", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/47403db3c55938e97a8e9baa21f65d6d09c04ee9", "committedDate": "2021-03-12T20:04:14Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}, "afterCommit": {"oid": "99b341e7ae369b856926b129e1f4e89215cc0f49", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/99b341e7ae369b856926b129e1f4e89215cc0f49", "committedDate": "2021-03-12T20:29:30Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1c8f0460657a5ac209130ec10518c9a015764bbd", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/1c8f0460657a5ac209130ec10518c9a015764bbd", "committedDate": "2021-03-14T09:11:11Z", "message": "Adding MultiWriter tests for DeltaStreamer"}, "afterCommit": {"oid": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/1886bbd803f1a51e3d261705dd1283cfa8caf06b", "committedDate": "2021-03-14T09:15:43Z", "message": "Adding MultiWriter tests for DeltaStreamer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/1886bbd803f1a51e3d261705dd1283cfa8caf06b", "committedDate": "2021-03-14T09:15:43Z", "message": "Adding MultiWriter tests for DeltaStreamer"}, "afterCommit": {"oid": "01577fda0944e2cb710f0907965ca8e602650f8a", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/01577fda0944e2cb710f0907965ca8e602650f8a", "committedDate": "2021-03-14T09:21:38Z", "message": "Adding MultiWriter tests for DeltaStreamer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "01577fda0944e2cb710f0907965ca8e602650f8a", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/01577fda0944e2cb710f0907965ca8e602650f8a", "committedDate": "2021-03-14T09:21:38Z", "message": "Adding MultiWriter tests for DeltaStreamer"}, "afterCommit": {"oid": "4e029d324c4ea812ec09acb2a3bcd487b2d35eb8", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/4e029d324c4ea812ec09acb2a3bcd487b2d35eb8", "committedDate": "2021-03-14T22:19:49Z", "message": "Adding MultiWriter tests for DeltaStreamer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4e029d324c4ea812ec09acb2a3bcd487b2d35eb8", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/4e029d324c4ea812ec09acb2a3bcd487b2d35eb8", "committedDate": "2021-03-14T22:19:49Z", "message": "Adding MultiWriter tests for DeltaStreamer"}, "afterCommit": {"oid": "9278889bad4fe529a7c403857f20bcd0198322e6", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/9278889bad4fe529a7c403857f20bcd0198322e6", "committedDate": "2021-03-15T04:02:32Z", "message": "Adding MultiWriter tests for DeltaStreamer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/461047d03e9b7b73b34536ccf290a24f4aada6b0", "committedDate": "2021-03-15T04:06:27Z", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9278889bad4fe529a7c403857f20bcd0198322e6", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/9278889bad4fe529a7c403857f20bcd0198322e6", "committedDate": "2021-03-15T04:02:32Z", "message": "Adding MultiWriter tests for DeltaStreamer"}, "afterCommit": {"oid": "a466320b7537bf2862df853344e80fbd0be6d16a", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/a466320b7537bf2862df853344e80fbd0be6d16a", "committedDate": "2021-03-15T04:09:56Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a466320b7537bf2862df853344e80fbd0be6d16a", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/a466320b7537bf2862df853344e80fbd0be6d16a", "committedDate": "2021-03-15T04:09:56Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}, "afterCommit": {"oid": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8c092be25de58e65cd339478e9b2c0ba37d20e5e", "committedDate": "2021-03-15T04:24:30Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/8c092be25de58e65cd339478e9b2c0ba37d20e5e", "committedDate": "2021-03-15T04:24:30Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}, "afterCommit": {"oid": "bbb02ab5c74551803f8003900d066d056646c951", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/bbb02ab5c74551803f8003900d066d056646c951", "committedDate": "2021-03-15T04:28:59Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bbb02ab5c74551803f8003900d066d056646c951", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/bbb02ab5c74551803f8003900d066d056646c951", "committedDate": "2021-03-15T04:28:59Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}, "afterCommit": {"oid": "d47718945d2ad86eb653daafc03f1f74a57b6881", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/d47718945d2ad86eb653daafc03f1f74a57b6881", "committedDate": "2021-03-15T06:02:56Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d47718945d2ad86eb653daafc03f1f74a57b6881", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/d47718945d2ad86eb653daafc03f1f74a57b6881", "committedDate": "2021-03-15T06:02:56Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}, "afterCommit": {"oid": "2a305dc45a1a175ebb07c96b9a9e8c698088283e", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/2a305dc45a1a175ebb07c96b9a9e8c698088283e", "committedDate": "2021-03-15T07:13:01Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2a305dc45a1a175ebb07c96b9a9e8c698088283e", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/2a305dc45a1a175ebb07c96b9a9e8c698088283e", "committedDate": "2021-03-15T07:13:01Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}, "afterCommit": {"oid": "f7685b4a61f6b7a7b641af778497b06349e75256", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/f7685b4a61f6b7a7b641af778497b06349e75256", "committedDate": "2021-03-15T07:31:36Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEyNjIxMzI3", "url": "https://github.com/apache/hudi/pull/2374#pullrequestreview-612621327", "createdAt": "2021-03-15T20:36:24Z", "commit": {"oid": "f7685b4a61f6b7a7b641af778497b06349e75256"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f7685b4a61f6b7a7b641af778497b06349e75256", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/f7685b4a61f6b7a7b641af778497b06349e75256", "committedDate": "2021-03-15T07:31:36Z", "message": "Adding tests for Deltastreamer and fixing some documentation"}, "afterCommit": {"oid": "bcc0f5baddc3eefad510441865cbf40a44c9a719", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/bcc0f5baddc3eefad510441865cbf40a44c9a719", "committedDate": "2021-03-16T07:14:38Z", "message": "Adding tests for Deltastreamer, fixing some documentation and added metadata overriding"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "committedDate": "2021-03-16T17:30:02Z", "message": "Adding tests for Deltastreamer, fixing some documentation and added metadata overriding"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bcc0f5baddc3eefad510441865cbf40a44c9a719", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/bcc0f5baddc3eefad510441865cbf40a44c9a719", "committedDate": "2021-03-16T07:14:38Z", "message": "Adding tests for Deltastreamer, fixing some documentation and added metadata overriding"}, "afterCommit": {"oid": "0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "author": {"user": {"login": "n3nash", "name": null}}, "url": "https://github.com/apache/hudi/commit/0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "committedDate": "2021-03-16T17:30:02Z", "message": "Adding tests for Deltastreamer, fixing some documentation and added metadata overriding"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4090, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}