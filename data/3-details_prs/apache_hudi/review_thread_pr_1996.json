{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcwODEzMDQ5", "number": 1996, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMzoxOToxOFrOEbN1AA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMzoxOToxOFrOEbN1AA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTczNTY4OnYy", "diffSide": "RIGHT", "path": "docs/_posts/2020-08-21-async-compaction-deployment-model.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxMzoxOToxOFrOHFFLEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwMDowMzoxMVrOHFRGag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4OTY4Mg==", "bodyText": "DeltaStreamer", "url": "https://github.com/apache/hudi/pull/1996#discussion_r475089682", "createdAt": "2020-08-22T13:19:18Z", "author": {"login": "leesf"}, "path": "docs/_posts/2020-08-21-async-compaction-deployment-model.md", "diffHunk": "@@ -0,0 +1,99 @@\n+---\n+title: \"Async Compaction Deployment Models\"\n+excerpt: \"Mechanisms for executing compaction jobs in Hudi asynchronously\"\n+author: vbalaji\n+category: blog\n+---\n+\n+We will look at different deployment models for executing compactions asynchronously.\n+\n+# Compaction\n+\n+For Merge-On-Read table, data is stored using a combination of columnar (e.g parquet) + row based (e.g avro) file formats. \n+Updates are logged to delta files & later compacted to produce new versions of columnar files synchronously or \n+asynchronously. One of th main motivations behind Merge-On-Read is to reduce data latency when ingesting records.\n+Hence, it makes sense to run compaction asynchronously without blocking ingestion.\n+\n+\n+# Async Compaction\n+\n+Async Compaction is performed in 2 steps:\n+\n+1. ***Compaction Scheduling***: This is done by the ingestion job. In this step, Hudi scans the partitions and selects **file \n+slices** to be compacted. A compaction plan is finally written to Hudi timeline.\n+1. ***Compaction Execution***: A separate process reads the compaction plan and performs compaction of file slices.\n+\n+  \n+# Deployment Models\n+\n+There are few ways by which we can execute compactions asynchronously. \n+\n+## Spark Structured Streaming\n+\n+With 0.6.0, we now have support for running async compactions in Spark \n+Structured Streaming jobs. Compactions are scheduled and executed asynchronously inside the \n+streaming job.  Async Compactions are enabled by default for structured streaming jobs\n+on Merge-On-Read table.\n+\n+Here is an example snippet in java\n+\n+```properties\n+import org.apache.hudi.DataSourceWriteOptions;\n+import org.apache.hudi.HoodieDataSourceHelpers;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+\n+import org.apache.spark.sql.streaming.OutputMode;\n+import org.apache.spark.sql.streaming.ProcessingTime;\n+\n+\n+ DataStreamWriter<Row> writer = streamingInput.writeStream().format(\"org.apache.hudi\")\n+        .option(DataSourceWriteOptions.OPERATION_OPT_KEY(), operationType)\n+        .option(DataSourceWriteOptions.TABLE_TYPE_OPT_KEY(), tableType)\n+        .option(DataSourceWriteOptions.RECORDKEY_FIELD_OPT_KEY(), \"_row_key\")\n+        .option(DataSourceWriteOptions.PARTITIONPATH_FIELD_OPT_KEY(), \"partition\")\n+        .option(DataSourceWriteOptions.PRECOMBINE_FIELD_OPT_KEY(), \"timestamp\")\n+        .option(HoodieCompactionConfig.INLINE_COMPACT_NUM_DELTA_COMMITS_PROP, \"10\")\n+        .option(DataSourceWriteOptions.ASYNC_COMPACT_ENABLE_OPT_KEY(), \"true\")\n+        .option(HoodieWriteConfig.TABLE_NAME, tableName).option(\"checkpointLocation\", checkpointLocation)\n+        .outputMode(OutputMode.Append());\n+ writer.trigger(new ProcessingTime(30000)).start(tablePath);\n+```\n+\n+## DeltaStreaminer Continuous Mode", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a100f3acecfd55e342b297a0755df52e710083e"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTI4NTA5OA==", "bodyText": "Fixed. Thanks,", "url": "https://github.com/apache/hudi/pull/1996#discussion_r475285098", "createdAt": "2020-08-24T00:03:11Z", "author": {"login": "bvaradar"}, "path": "docs/_posts/2020-08-21-async-compaction-deployment-model.md", "diffHunk": "@@ -0,0 +1,99 @@\n+---\n+title: \"Async Compaction Deployment Models\"\n+excerpt: \"Mechanisms for executing compaction jobs in Hudi asynchronously\"\n+author: vbalaji\n+category: blog\n+---\n+\n+We will look at different deployment models for executing compactions asynchronously.\n+\n+# Compaction\n+\n+For Merge-On-Read table, data is stored using a combination of columnar (e.g parquet) + row based (e.g avro) file formats. \n+Updates are logged to delta files & later compacted to produce new versions of columnar files synchronously or \n+asynchronously. One of th main motivations behind Merge-On-Read is to reduce data latency when ingesting records.\n+Hence, it makes sense to run compaction asynchronously without blocking ingestion.\n+\n+\n+# Async Compaction\n+\n+Async Compaction is performed in 2 steps:\n+\n+1. ***Compaction Scheduling***: This is done by the ingestion job. In this step, Hudi scans the partitions and selects **file \n+slices** to be compacted. A compaction plan is finally written to Hudi timeline.\n+1. ***Compaction Execution***: A separate process reads the compaction plan and performs compaction of file slices.\n+\n+  \n+# Deployment Models\n+\n+There are few ways by which we can execute compactions asynchronously. \n+\n+## Spark Structured Streaming\n+\n+With 0.6.0, we now have support for running async compactions in Spark \n+Structured Streaming jobs. Compactions are scheduled and executed asynchronously inside the \n+streaming job.  Async Compactions are enabled by default for structured streaming jobs\n+on Merge-On-Read table.\n+\n+Here is an example snippet in java\n+\n+```properties\n+import org.apache.hudi.DataSourceWriteOptions;\n+import org.apache.hudi.HoodieDataSourceHelpers;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+\n+import org.apache.spark.sql.streaming.OutputMode;\n+import org.apache.spark.sql.streaming.ProcessingTime;\n+\n+\n+ DataStreamWriter<Row> writer = streamingInput.writeStream().format(\"org.apache.hudi\")\n+        .option(DataSourceWriteOptions.OPERATION_OPT_KEY(), operationType)\n+        .option(DataSourceWriteOptions.TABLE_TYPE_OPT_KEY(), tableType)\n+        .option(DataSourceWriteOptions.RECORDKEY_FIELD_OPT_KEY(), \"_row_key\")\n+        .option(DataSourceWriteOptions.PARTITIONPATH_FIELD_OPT_KEY(), \"partition\")\n+        .option(DataSourceWriteOptions.PRECOMBINE_FIELD_OPT_KEY(), \"timestamp\")\n+        .option(HoodieCompactionConfig.INLINE_COMPACT_NUM_DELTA_COMMITS_PROP, \"10\")\n+        .option(DataSourceWriteOptions.ASYNC_COMPACT_ENABLE_OPT_KEY(), \"true\")\n+        .option(HoodieWriteConfig.TABLE_NAME, tableName).option(\"checkpointLocation\", checkpointLocation)\n+        .outputMode(OutputMode.Append());\n+ writer.trigger(new ProcessingTime(30000)).start(tablePath);\n+```\n+\n+## DeltaStreaminer Continuous Mode", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4OTY4Mg=="}, "originalCommit": {"oid": "3a100f3acecfd55e342b297a0755df52e710083e"}, "originalPosition": 63}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4447, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}