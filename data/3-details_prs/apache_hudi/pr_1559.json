{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4ODA3NjQ1", "number": 1559, "title": "[HUDI-838] Support schema from HoodieCommitMetadata for HiveSync", "bodyText": "Tips\n\nThank you very much for contributing to Apache Hudi.\nPlease review https://hudi.apache.org/contributing.html before opening a pull request.\n\nWhat is the purpose of the pull request\nSupport to store and read schema from HoodieCommitMetadata has been added in Hudi recently. This PR integrated Hive Sync to read schema from the metadata, and fallback to reading from files only if the schema from metadata is unavailable (for backwards compatibility).\nThis is a pre-requisite to https://jira.apache.org/jira/browse/HUDI-620 where we want to store the merged bootstrap schema in commit metadata and obtain it during hive-sync. This avoids us having to look up the indexes for external files and merging the schemas just for hive-sync.\nIn addition, this PR does a fix in HoodieWrite client to fallback on reading schema from the files in case schema from metadata is not available (for validating the schema).\nBrief change log\n\nFix in HoodieWriteClient to fallback on reading schema from files\nHive sync changes and unit tests to read schema from HoodieCommitMetadata\n\nVerify this pull request\nThis change added unit tests.\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-04-24T23:30:32Z", "url": "https://github.com/apache/hudi/pull/1559", "merged": true, "mergeCommit": {"oid": "d54b4b8a525868ea6d15e2e2cc6ffccc62d5c43c"}, "closed": true, "closedAt": "2020-05-07T23:33:09Z", "author": {"login": "umehrot2"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABca6nOVgBqjMyNzEzNzM2NzE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcfF5ZQgFqTQwNzkwMzk4Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyMTYwMjA1", "url": "https://github.com/apache/hudi/pull/1559#pullrequestreview-402160205", "createdAt": "2020-04-28T19:50:13Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxOTo1MDoxNVrOGNkUEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxOTo1MDoxNVrOGNkUEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg3OTYzMw==", "bodyText": "Rename to just getTableAvroSchema ?", "url": "https://github.com/apache/hudi/pull/1559#discussion_r416879633", "createdAt": "2020-04-28T19:50:15Z", "author": {"login": "bvaradar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -145,23 +146,37 @@ public MessageType getDataSchema() throws Exception {\n    * @return Avro schema for this table\n    * @throws Exception\n    */\n-  public Schema getTableSchema() throws Exception {\n-    return convertParquetSchemaToAvro(getDataSchema());\n+  public Schema getTableSchemaInAvroFormat() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyMTY0OTc5", "url": "https://github.com/apache/hudi/pull/1559#pullrequestreview-402164979", "createdAt": "2020-04-28T19:57:08Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxOTo1NzowOFrOGNkjbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQyMDoxMToxMlrOGNlBkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4MzU2Nw==", "bodyText": "You can introduce a getTableAvroSchemaFromDataFile to return in avro format.", "url": "https://github.com/apache/hudi/pull/1559#discussion_r416883567", "createdAt": "2020-04-28T19:57:08Z", "author": {"login": "bvaradar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -145,23 +146,37 @@ public MessageType getDataSchema() throws Exception {\n    * @return Avro schema for this table\n    * @throws Exception\n    */\n-  public Schema getTableSchema() throws Exception {\n-    return convertParquetSchemaToAvro(getDataSchema());\n+  public Schema getTableSchemaInAvroFormat() throws Exception {\n+    Option<Schema> schemaFromCommitMetadata = getTableSchemaFromCommitMetadata();\n+    return schemaFromCommitMetadata.isPresent() ? schemaFromCommitMetadata.get() :\n+           convertParquetSchemaToAvro(getDataSchema());\n+  }\n+\n+  /**\n+   * Gets the schema for a hoodie table in Parquet format.\n+   *\n+   * @return Parquet schema for the table\n+   * @throws Exception\n+   */\n+  public MessageType getTableSchemaInParquetFormat() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NDIxMQ==", "bodyText": "Please check ParquetUtils class for similar APIs", "url": "https://github.com/apache/hudi/pull/1559#discussion_r416884211", "createdAt": "2020-04-28T19:58:13Z", "author": {"login": "bvaradar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -178,6 +193,17 @@ public Schema convertParquetSchemaToAvro(MessageType parquetSchema) {\n     return avroSchemaConverter.convert(parquetSchema);\n   }\n \n+  /**\n+   * Convert a avro scheme to the parquet format.\n+   *\n+   * @param schema The avro schema to convert\n+   * @return The converted parquet schema\n+   */\n+  public MessageType convertAvroSchemaToParquet(Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg5MTI4MQ==", "bodyText": "On a related note :  As we are start to rely on avro schema to be present in commit-metadata, we should store avro-schema as first-level entity in commit metadata instead of storing it in extra-metadata map and handle upgrade-downgrade (Added https://jira.apache.org/jira/browse/HUDI-844)", "url": "https://github.com/apache/hudi/pull/1559#discussion_r416891281", "createdAt": "2020-04-28T20:11:12Z", "author": {"login": "bvaradar"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/table/TableSchemaResolver.java", "diffHunk": "@@ -145,23 +146,37 @@ public MessageType getDataSchema() throws Exception {\n    * @return Avro schema for this table\n    * @throws Exception\n    */\n-  public Schema getTableSchema() throws Exception {\n-    return convertParquetSchemaToAvro(getDataSchema());\n+  public Schema getTableSchemaInAvroFormat() throws Exception {\n+    Option<Schema> schemaFromCommitMetadata = getTableSchemaFromCommitMetadata();\n+    return schemaFromCommitMetadata.isPresent() ? schemaFromCommitMetadata.get() :\n+           convertParquetSchemaToAvro(getDataSchema());\n+  }\n+\n+  /**\n+   * Gets the schema for a hoodie table in Parquet format.\n+   *\n+   * @return Parquet schema for the table\n+   * @throws Exception\n+   */\n+  public MessageType getTableSchemaInParquetFormat() throws Exception {\n+    Option<Schema> schemaFromCommitMetadata = getTableSchemaFromCommitMetadata();\n+    return schemaFromCommitMetadata.isPresent() ? convertAvroSchemaToParquet(schemaFromCommitMetadata.get()) :\n+           getDataSchema();\n   }\n \n   /**\n    * Gets the schema for a hoodie table in Avro format from the HoodieCommitMetadata of the last commit.\n    *\n    * @return Avro schema for this table\n-   * @throws Exception\n    */\n-  public Schema getTableSchemaFromCommitMetadata() throws Exception {\n+  private Option<Schema> getTableSchemaFromCommitMetadata() {\n     try {\n       HoodieTimeline timeline = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants();\n       byte[] data = timeline.getInstantDetails(timeline.lastInstant().get()).get();\n       HoodieCommitMetadata metadata = HoodieCommitMetadata.fromBytes(data, HoodieCommitMetadata.class);\n       String existingSchemaStr = metadata.getMetadata(HoodieCommitMetadata.SCHEMA_KEY);\n-      return new Schema.Parser().parse(existingSchemaStr);\n+      return StringUtils.isNullOrEmpty(existingSchemaStr) ? Option.empty() :", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 46}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "6f30a6deb26f389f9cc8a6cabf6bdd2c6041920c", "author": {"user": {"login": "umehrot2", "name": "Udit Mehrotra"}}, "url": "https://github.com/apache/hudi/commit/6f30a6deb26f389f9cc8a6cabf6bdd2c6041920c", "committedDate": "2020-04-29T02:38:44Z", "message": "Support schema from HoodieCommitMetadata for HiveSync\n\ncr https://code.amazon.com/reviews/CR-24090847"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6f30a6deb26f389f9cc8a6cabf6bdd2c6041920c", "author": {"user": {"login": "umehrot2", "name": "Udit Mehrotra"}}, "url": "https://github.com/apache/hudi/commit/6f30a6deb26f389f9cc8a6cabf6bdd2c6041920c", "committedDate": "2020-04-29T02:38:44Z", "message": "Support schema from HoodieCommitMetadata for HiveSync\n\ncr https://code.amazon.com/reviews/CR-24090847"}, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3NzkxNjk4", "url": "https://github.com/apache/hudi/pull/1559#pullrequestreview-407791698", "createdAt": "2020-05-07T19:57:55Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2acdb900ea8cb3a1c245467e474ee5fd659cedd", "author": {"user": {"login": "umehrot2", "name": "Udit Mehrotra"}}, "url": "https://github.com/apache/hudi/commit/e2acdb900ea8cb3a1c245467e474ee5fd659cedd", "committedDate": "2020-05-07T20:49:05Z", "message": "Support schema from HoodieCommitMetadata for HiveSync"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "e2acdb900ea8cb3a1c245467e474ee5fd659cedd", "author": {"user": {"login": "umehrot2", "name": "Udit Mehrotra"}}, "url": "https://github.com/apache/hudi/commit/e2acdb900ea8cb3a1c245467e474ee5fd659cedd", "committedDate": "2020-05-07T20:49:05Z", "message": "Support schema from HoodieCommitMetadata for HiveSync"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3OTAzOTgz", "url": "https://github.com/apache/hudi/pull/1559#pullrequestreview-407903983", "createdAt": "2020-05-07T23:29:57Z", "commit": {"oid": "e2acdb900ea8cb3a1c245467e474ee5fd659cedd"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3015, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}