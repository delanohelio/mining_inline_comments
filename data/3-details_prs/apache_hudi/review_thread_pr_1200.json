{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYwODI3MjY1", "number": 1200, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQwNjo1NTo0MFrODXXGsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxMzowMzowNFrODecdjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1ODIyMzg3OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/pom.xml", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQwNjo1NTo0MFrOFcoHoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQwNjo1NTo0MFrOFcoHoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTU2MTc2MA==", "bodyText": "can you clarify why these pom changes are needed?", "url": "https://github.com/apache/hudi/pull/1200#discussion_r365561760", "createdAt": "2020-01-12T06:55:40Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/pom.xml", "diffHunk": "@@ -69,6 +100,12 @@\n   </build>\n \n   <dependencies>\n+    <!-- Scala -->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926c4490f42ee6cf48cb523e7bd9be9a6cf4d73"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1ODIyNDY1OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/main/scala/org/apache/hudi/utilities/JdbcProviderUtils.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQwNjo1ODowMlrOFcoH_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMlQwNjo1ODowMlrOFcoH_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTU2MTg1Mw==", "bodyText": "could we avoid this and keep this code in Java?", "url": "https://github.com/apache/hudi/pull/1200#discussion_r365561853", "createdAt": "2020-01-12T06:58:02Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/scala/org/apache/hudi/utilities/JdbcProviderUtils.scala", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities\n+\n+import org.apache.avro.Schema\n+import org.apache.hudi.AvroConversionUtils\n+import org.apache.hudi.exception.HoodieException\n+import org.apache.spark.sql.execution.datasources.jdbc.{JDBCOptions, JdbcUtils}\n+import org.apache.spark.sql.jdbc.JdbcDialects\n+\n+import scala.collection.JavaConverters._", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1926c4490f42ee6cf48cb523e7bd9be9a6cf4d73"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjMxNjExOnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNzoyMDo1MVrOFdN-9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNzoyMDo1MVrOFdN-9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MjEzNQ==", "bodyText": "rename to getJDBCSchema?", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366182135", "createdAt": "2020-01-14T07:20:51Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -236,4 +250,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getSchema(Map<String, String> options) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0a4cffeb68b4bae34f9984447d38a58a25074c0c"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjMyMjMwOnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNzoyNDoxN1rOFdOCgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNzoyNDoxN1rOFdOCgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzA0MQ==", "bodyText": "change to table does not exist!?", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366183041", "createdAt": "2020-01-14T07:24:17Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -236,4 +250,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try {\n+        PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table));\n+        try {\n+          statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+          ResultSet rs = statement.executeQuery();\n+          try {\n+            StructType structType;\n+            if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+              structType = JdbcUtils.getSchema(rs, dialect, true);\n+            } else {\n+              structType = JdbcUtils.getSchema(rs, dialect, false);\n+            }\n+            return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+          } finally {\n+            rs.close();\n+          }\n+        } finally {\n+          statement.close();\n+        }\n+      } finally {\n+        conn.close();\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table not exists!\", table));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0a4cffeb68b4bae34f9984447d38a58a25074c0c"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjMyNDI4OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNzoyNToyOVrOFdODng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOVQxMzozNzowOVrOFnVG0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzMyNg==", "bodyText": "import the java collection classes?Map, List, ArrayList ?", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366183326", "createdAt": "2020-01-14T07:25:29Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -236,4 +250,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try {\n+        PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table));\n+        try {\n+          statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+          ResultSet rs = statement.executeQuery();\n+          try {\n+            StructType structType;\n+            if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+              structType = JdbcUtils.getSchema(rs, dialect, true);\n+            } else {\n+              structType = JdbcUtils.getSchema(rs, dialect, false);\n+            }\n+            return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+          } finally {\n+            rs.close();\n+          }\n+        } finally {\n+          statement.close();\n+        }\n+      } finally {\n+        conn.close();\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table not exists!\", table));\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private static <K, V> scala.collection.immutable.Map<K, V> toScalaImmutableMap(java.util.Map<K, V> javaMap) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0a4cffeb68b4bae34f9984447d38a58a25074c0c"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMwOTkxMw==", "bodyText": "Because the underlying spark function only accepts parameters of type scala.collection.immutable.Map, I provide a private conversion function from java map to scala immutable Map.", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366309913", "createdAt": "2020-01-14T12:27:05Z", "author": {"login": "OpenOpened"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -236,4 +250,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try {\n+        PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table));\n+        try {\n+          statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+          ResultSet rs = statement.executeQuery();\n+          try {\n+            StructType structType;\n+            if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+              structType = JdbcUtils.getSchema(rs, dialect, true);\n+            } else {\n+              structType = JdbcUtils.getSchema(rs, dialect, false);\n+            }\n+            return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+          } finally {\n+            rs.close();\n+          }\n+        } finally {\n+          statement.close();\n+        }\n+      } finally {\n+        conn.close();\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table not exists!\", table));\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private static <K, V> scala.collection.immutable.Map<K, V> toScalaImmutableMap(java.util.Map<K, V> javaMap) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzMyNg=="}, "originalCommit": {"oid": "0a4cffeb68b4bae34f9984447d38a58a25074c0c"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc4NDU5Mg==", "bodyText": "also is the method(toScalaImmutableMap) copied from other projects or implemented on our own?", "url": "https://github.com/apache/hudi/pull/1200#discussion_r376784592", "createdAt": "2020-02-09T13:37:09Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -236,4 +250,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try {\n+        PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table));\n+        try {\n+          statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+          ResultSet rs = statement.executeQuery();\n+          try {\n+            StructType structType;\n+            if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+              structType = JdbcUtils.getSchema(rs, dialect, true);\n+            } else {\n+              structType = JdbcUtils.getSchema(rs, dialect, false);\n+            }\n+            return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+          } finally {\n+            rs.close();\n+          }\n+        } finally {\n+          statement.close();\n+        }\n+      } finally {\n+        conn.close();\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table not exists!\", table));\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private static <K, V> scala.collection.immutable.Map<K, V> toScalaImmutableMap(java.util.Map<K, V> javaMap) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzMyNg=="}, "originalCommit": {"oid": "0a4cffeb68b4bae34f9984447d38a58a25074c0c"}, "originalPosition": 155}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjMyNTY4OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieDeltaStreamer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNzoyNjozMFrOFdOEgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNzoyNjozMFrOFdOEgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzU1NA==", "bodyText": "can we create a separate test class for this? given you are only testing the schema provider?", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366183554", "createdAt": "2020-01-14T07:26:30Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieDeltaStreamer.java", "diffHunk": "@@ -511,6 +524,22 @@ public void testNullSchemaProvider() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testJdbcbasedSchemaProvider() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0a4cffeb68b4bae34f9984447d38a58a25074c0c"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2MjMzMDU0OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/test/resources/delta-streamer-config/source-jdbc.avsc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQwNzoyOToxNVrOFdOHYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxMjoyNToyMFrOFdVvdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4NDI5MA==", "bodyText": "any reason why the existing source.avsc won't work for you? Like to avoid creating new schema if possible", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366184290", "createdAt": "2020-01-14T07:29:15Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/test/resources/delta-streamer-config/source-jdbc.avsc", "diffHunk": "@@ -0,0 +1,59 @@\n+/*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0a4cffeb68b4bae34f9984447d38a58a25074c0c"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMwOTIzOA==", "bodyText": "Because the data structure of source.avs is too complex, the schema of the database table cannot achieve a similar effect.", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366309238", "createdAt": "2020-01-14T12:25:20Z", "author": {"login": "OpenOpened"}, "path": "hudi-utilities/src/test/resources/delta-streamer-config/source-jdbc.avsc", "diffHunk": "@@ -0,0 +1,59 @@\n+/*", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4NDI5MA=="}, "originalCommit": {"oid": "0a4cffeb68b4bae34f9984447d38a58a25074c0c"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMDEwMzA0OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQxMTo1MTozMFrOFnQSmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOFQxMjo0NToxOVrOFnQcDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwNTY5MA==", "bodyText": "Would be changed to try-with-resources? since try-catch-finnaly has been optimized to try-with-resources in the project now.", "url": "https://github.com/apache/hudi/pull/1200#discussion_r376705690", "createdAt": "2020-02-08T11:51:30Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -235,4 +248,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try {\n+        PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table));\n+        try {\n+          statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+          ResultSet rs = statement.executeQuery();\n+          try {\n+            StructType structType;\n+            if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+              structType = JdbcUtils.getSchema(rs, dialect, true);\n+            } else {\n+              structType = JdbcUtils.getSchema(rs, dialect, false);\n+            }\n+            return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+          } finally {\n+            rs.close();\n+          }\n+        } finally {\n+          statement.close();\n+        }\n+      } finally {\n+        conn.close();\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d18385136e454b56d4aa0cd4470c7c426aa0965a"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwODEwOA==", "bodyText": "thank you for your advice. i wll do it.", "url": "https://github.com/apache/hudi/pull/1200#discussion_r376708108", "createdAt": "2020-02-08T12:45:19Z", "author": {"login": "OpenOpened"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -235,4 +248,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try {\n+        PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table));\n+        try {\n+          statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+          ResultSet rs = statement.executeQuery();\n+          try {\n+            StructType structType;\n+            if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+              structType = JdbcUtils.getSchema(rs, dialect, true);\n+            } else {\n+              structType = JdbcUtils.getSchema(rs, dialect, false);\n+            }\n+            return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+          } finally {\n+            rs.close();\n+          }\n+        } finally {\n+          statement.close();\n+        }\n+      } finally {\n+        conn.close();\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwNTY5MA=="}, "originalCommit": {"oid": "d18385136e454b56d4aa0cd4470c7c426aa0965a"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMjUwMTg4OnYy", "diffSide": "RIGHT", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxMzowMzowNFrOFnlOZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwOTozNzowOFrOFongLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA==", "bodyText": "I think we could remove this line, If we copy from other projects, we may need add copyright to LICENSE. but if copied from stackoverflow, it would be removed.", "url": "https://github.com/apache/hudi/pull/1200#discussion_r377048678", "createdAt": "2020-02-10T13:03:04Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -235,4 +248,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * The code logic implementation refers to spark 2.4.x and spark 3.x.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try (PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table))) {\n+        statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+        try (ResultSet rs = statement.executeQuery()) {\n+          StructType structType;\n+          if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+            structType = JdbcUtils.getSchema(rs, dialect, true);\n+          } else {\n+            structType = JdbcUtils.getSchema(rs, dialect, false);\n+          }\n+          return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+        }\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table does not exists!\", table));\n+    }\n+  }\n+\n+  /**\n+   * Replace java map with scala immutable map.\n+   * refers: https://stackoverflow.com/questions/11903167/convert-java-util-hashmap-to-scala-collection-immutable-map-in-java/11903737#11903737", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f7914c163e895ad103278c22bd11eb4e07fd368a"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA3ODUxMA==", "bodyText": "ok, i will remove it.", "url": "https://github.com/apache/hudi/pull/1200#discussion_r377078510", "createdAt": "2020-02-10T14:00:14Z", "author": {"login": "OpenOpened"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -235,4 +248,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * The code logic implementation refers to spark 2.4.x and spark 3.x.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try (PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table))) {\n+        statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+        try (ResultSet rs = statement.executeQuery()) {\n+          StructType structType;\n+          if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+            structType = JdbcUtils.getSchema(rs, dialect, true);\n+          } else {\n+            structType = JdbcUtils.getSchema(rs, dialect, false);\n+          }\n+          return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+        }\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table does not exists!\", table));\n+    }\n+  }\n+\n+  /**\n+   * Replace java map with scala immutable map.\n+   * refers: https://stackoverflow.com/questions/11903167/convert-java-util-hashmap-to-scala-collection-immutable-map-in-java/11903737#11903737", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA=="}, "originalCommit": {"oid": "f7914c163e895ad103278c22bd11eb4e07fd368a"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzNTE2Ng==", "bodyText": "Sorry to be a pain. but this piece of code would be problematic since its exactly https://stackoverflow.com/a/45992769 ? Please re-implement this", "url": "https://github.com/apache/hudi/pull/1200#discussion_r378035166", "createdAt": "2020-02-12T04:26:20Z", "author": {"login": "vinothchandar"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -235,4 +248,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * The code logic implementation refers to spark 2.4.x and spark 3.x.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try (PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table))) {\n+        statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+        try (ResultSet rs = statement.executeQuery()) {\n+          StructType structType;\n+          if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+            structType = JdbcUtils.getSchema(rs, dialect, true);\n+          } else {\n+            structType = JdbcUtils.getSchema(rs, dialect, false);\n+          }\n+          return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+        }\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table does not exists!\", table));\n+    }\n+  }\n+\n+  /**\n+   * Replace java map with scala immutable map.\n+   * refers: https://stackoverflow.com/questions/11903167/convert-java-util-hashmap-to-scala-collection-immutable-map-in-java/11903737#11903737", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA=="}, "originalCommit": {"oid": "f7914c163e895ad103278c22bd11eb4e07fd368a"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODA1NTI4OA==", "bodyText": "Do you guys have a better way? I checked the relevant information. If you want to achieve conversion elegantly, there are only two methods. First, using scala code to do the conversion, you need to implement a scala conversion class. Second, rewrite the related spark method with java. The disadvantage is that it may cause compatibility problems in the future.", "url": "https://github.com/apache/hudi/pull/1200#discussion_r378055288", "createdAt": "2020-02-12T06:06:56Z", "author": {"login": "OpenOpened"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -235,4 +248,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * The code logic implementation refers to spark 2.4.x and spark 3.x.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try (PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table))) {\n+        statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+        try (ResultSet rs = statement.executeQuery()) {\n+          StructType structType;\n+          if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+            structType = JdbcUtils.getSchema(rs, dialect, true);\n+          } else {\n+            structType = JdbcUtils.getSchema(rs, dialect, false);\n+          }\n+          return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+        }\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table does not exists!\", table));\n+    }\n+  }\n+\n+  /**\n+   * Replace java map with scala immutable map.\n+   * refers: https://stackoverflow.com/questions/11903167/convert-java-util-hashmap-to-scala-collection-immutable-map-in-java/11903737#11903737", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA=="}, "originalCommit": {"oid": "f7914c163e895ad103278c22bd11eb4e07fd368a"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEzNDU3Mg==", "bodyText": "@vinothchandar @leesf I reimplemented the relevant logic using the second approach.", "url": "https://github.com/apache/hudi/pull/1200#discussion_r378134572", "createdAt": "2020-02-12T09:37:08Z", "author": {"login": "OpenOpened"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -235,4 +248,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * The code logic implementation refers to spark 2.4.x and spark 3.x.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try (PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table))) {\n+        statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+        try (ResultSet rs = statement.executeQuery()) {\n+          StructType structType;\n+          if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+            structType = JdbcUtils.getSchema(rs, dialect, true);\n+          } else {\n+            structType = JdbcUtils.getSchema(rs, dialect, false);\n+          }\n+          return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+        }\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table does not exists!\", table));\n+    }\n+  }\n+\n+  /**\n+   * Replace java map with scala immutable map.\n+   * refers: https://stackoverflow.com/questions/11903167/convert-java-util-hashmap-to-scala-collection-immutable-map-in-java/11903737#11903737", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA=="}, "originalCommit": {"oid": "f7914c163e895ad103278c22bd11eb4e07fd368a"}, "originalPosition": 82}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 85, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}