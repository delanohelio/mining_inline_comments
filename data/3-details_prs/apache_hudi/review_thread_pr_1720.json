{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxNTYwNjYy", "number": 1720, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxNTo1MjoyMlrOED8zcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQxMToyMjo0MlrOEFUEMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNTc3Mzk1OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxNTo1MjoyMlrOGhRRcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwODoxNjo1NVrOGhp_Og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzUzOTE4NQ==", "bodyText": "can we add a test case for this?", "url": "https://github.com/apache/hudi/pull/1720#discussion_r437539185", "createdAt": "2020-06-09T15:52:22Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala", "diffHunk": "@@ -247,7 +247,13 @@ private[hudi] object HoodieSparkSqlWriter {\n     hiveSyncConfig.hivePass = parameters(HIVE_PASS_OPT_KEY)\n     hiveSyncConfig.jdbcUrl = parameters(HIVE_URL_OPT_KEY)\n     hiveSyncConfig.partitionFields =\n-      ListBuffer(parameters(HIVE_PARTITION_FIELDS_OPT_KEY).split(\",\").map(_.trim).filter(!_.isEmpty).toList: _*)\n+      // Reset partition_fields to empty, when sync hudi non-parititioned table to hive.\n+      if (classOf[NonPartitionedExtractor].getName.equals(parameters(HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d92ce1682c4c11361728b5ada086f4a1cb2c2b53"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk0NDEyMg==", "bodyText": "Yes will be adding test covering this line.", "url": "https://github.com/apache/hudi/pull/1720#discussion_r437944122", "createdAt": "2020-06-10T08:16:55Z", "author": {"login": "cloud-luoyajun"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala", "diffHunk": "@@ -247,7 +247,13 @@ private[hudi] object HoodieSparkSqlWriter {\n     hiveSyncConfig.hivePass = parameters(HIVE_PASS_OPT_KEY)\n     hiveSyncConfig.jdbcUrl = parameters(HIVE_URL_OPT_KEY)\n     hiveSyncConfig.partitionFields =\n-      ListBuffer(parameters(HIVE_PARTITION_FIELDS_OPT_KEY).split(\",\").map(_.trim).filter(!_.isEmpty).toList: _*)\n+      // Reset partition_fields to empty, when sync hudi non-parititioned table to hive.\n+      if (classOf[NonPartitionedExtractor].getName.equals(parameters(HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzUzOTE4NQ=="}, "originalCommit": {"oid": "d92ce1682c4c11361728b5ada086f4a1cb2c2b53"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczOTE1NzIyOnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjozNDo1MFrOGjVQsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QxMjo0NTo1MFrOGjXZOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMTY4MQ==", "bodyText": "I think we would move the logic to hudi-hive module, using sparkdatasource writing data to hudi and sync to hive is one way, also, users may also use api(HiveSyncTool) to sync to hive, we should handle this case as well.", "url": "https://github.com/apache/hudi/pull/1720#discussion_r439701681", "createdAt": "2020-06-13T02:34:50Z", "author": {"login": "leesf"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala", "diffHunk": "@@ -247,7 +247,13 @@ private[hudi] object HoodieSparkSqlWriter {\n     hiveSyncConfig.hivePass = parameters(HIVE_PASS_OPT_KEY)\n     hiveSyncConfig.jdbcUrl = parameters(HIVE_URL_OPT_KEY)\n     hiveSyncConfig.partitionFields =\n-      ListBuffer(parameters(HIVE_PARTITION_FIELDS_OPT_KEY).split(\",\").map(_.trim).filter(!_.isEmpty).toList: _*)\n+      // Set partitionFields to empty, when the NonPartitionedExtractor is used\n+      if (classOf[NonPartitionedExtractor].getName.equals(parameters(HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY))) {\n+        log.warn(s\"Parameter '$HIVE_PARTITION_FIELDS_OPT_KEY' is ignored, since the NonPartitionedExtractor is used\")\n+        Array.empty[String].toList\n+      } else {\n+        ListBuffer(parameters(HIVE_PARTITION_FIELDS_OPT_KEY).split(\",\").map(_.trim).filter(!_.isEmpty).toList: _*)\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af82cda0a912df2eb0aa76c56cac4f2683eb8a3e"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTczNjYzMw==", "bodyText": "Moved", "url": "https://github.com/apache/hudi/pull/1720#discussion_r439736633", "createdAt": "2020-06-13T12:45:50Z", "author": {"login": "cloud-luoyajun"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala", "diffHunk": "@@ -247,7 +247,13 @@ private[hudi] object HoodieSparkSqlWriter {\n     hiveSyncConfig.hivePass = parameters(HIVE_PASS_OPT_KEY)\n     hiveSyncConfig.jdbcUrl = parameters(HIVE_URL_OPT_KEY)\n     hiveSyncConfig.partitionFields =\n-      ListBuffer(parameters(HIVE_PARTITION_FIELDS_OPT_KEY).split(\",\").map(_.trim).filter(!_.isEmpty).toList: _*)\n+      // Set partitionFields to empty, when the NonPartitionedExtractor is used\n+      if (classOf[NonPartitionedExtractor].getName.equals(parameters(HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY))) {\n+        log.warn(s\"Parameter '$HIVE_PARTITION_FIELDS_OPT_KEY' is ignored, since the NonPartitionedExtractor is used\")\n+        Array.empty[String].toList\n+      } else {\n+        ListBuffer(parameters(HIVE_PARTITION_FIELDS_OPT_KEY).split(\",\").map(_.trim).filter(!_.isEmpty).toList: _*)\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMTY4MQ=="}, "originalCommit": {"oid": "af82cda0a912df2eb0aa76c56cac4f2683eb8a3e"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczOTE1NzU0OnYy", "diffSide": "RIGHT", "path": "pom.xml", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjozNToxOVrOGjVQ2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QxMjo0NjoyNVrOGjXZYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMTcyMA==", "bodyText": "if not used, it would be removed.", "url": "https://github.com/apache/hudi/pull/1720#discussion_r439701720", "createdAt": "2020-06-13T02:35:19Z", "author": {"login": "leesf"}, "path": "pom.xml", "diffHunk": "@@ -761,10 +761,10 @@\n         <version>${hive.version}</version>\n         <scope>provided</scope>\n         <exclusions>\n-          <exclusion>\n+          <!--<exclusion>\n             <groupId>javax.transaction</groupId>\n             <artifactId>jta</artifactId>\n-          </exclusion>\n+          </exclusion>-->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af82cda0a912df2eb0aa76c56cac4f2683eb8a3e"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTczNjY3Mg==", "bodyText": "Removed", "url": "https://github.com/apache/hudi/pull/1720#discussion_r439736672", "createdAt": "2020-06-13T12:46:25Z", "author": {"login": "cloud-luoyajun"}, "path": "pom.xml", "diffHunk": "@@ -761,10 +761,10 @@\n         <version>${hive.version}</version>\n         <scope>provided</scope>\n         <exclusions>\n-          <exclusion>\n+          <!--<exclusion>\n             <groupId>javax.transaction</groupId>\n             <artifactId>jta</artifactId>\n-          </exclusion>\n+          </exclusion>-->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMTcyMA=="}, "originalCommit": {"oid": "af82cda0a912df2eb0aa76c56cac4f2683eb8a3e"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczOTQ3NTUwOnYy", "diffSide": "RIGHT", "path": "hudi-hive-sync/src/main/java/org/apache/hudi/hive/HiveSyncTool.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QxNDoyNzozNFrOGjXyUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQwNzozNzo1NlrOGjbVrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc0MzA1Ng==", "bodyText": "remove this one?", "url": "https://github.com/apache/hudi/pull/1720#discussion_r439743056", "createdAt": "2020-06-13T14:27:34Z", "author": {"login": "leesf"}, "path": "hudi-hive-sync/src/main/java/org/apache/hudi/hive/HiveSyncTool.java", "diffHunk": "@@ -18,6 +18,7 @@\n \n package org.apache.hudi.hive;\n \n+import static jdk.nashorn.internal.runtime.regexp.joni.Config.log;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "81498b56998d24f667844b64f4f5c9670bec7f2a"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTgwMTI2Mw==", "bodyText": "Done", "url": "https://github.com/apache/hudi/pull/1720#discussion_r439801263", "createdAt": "2020-06-14T07:37:56Z", "author": {"login": "cloud-luoyajun"}, "path": "hudi-hive-sync/src/main/java/org/apache/hudi/hive/HiveSyncTool.java", "diffHunk": "@@ -18,6 +18,7 @@\n \n package org.apache.hudi.hive;\n \n+import static jdk.nashorn.internal.runtime.regexp.joni.Config.log;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc0MzA1Ng=="}, "originalCommit": {"oid": "81498b56998d24f667844b64f4f5c9670bec7f2a"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0MDA3MDg5OnYy", "diffSide": "RIGHT", "path": "hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQxMToyMjo0MlrOGjcbrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQxMzo1NTo1OFrOGjdPtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTgxOTE4MQ==", "bodyText": "I think we would remove this assert.", "url": "https://github.com/apache/hudi/pull/1720#discussion_r439819181", "createdAt": "2020-06-14T11:22:42Z", "author": {"login": "leesf"}, "path": "hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java", "diffHunk": "@@ -457,6 +457,37 @@ public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n         \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n   }\n \n+  @ParameterizedTest\n+  @MethodSource(\"useJdbc\")\n+  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n+    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n+    String instantTime = \"100\";\n+    HiveTestUtil.createCOWTable(instantTime, 5, true);\n+\n+    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n+    // Set partition value extractor to NonPartitionedExtractor\n+    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n+    hiveSyncConfig.tableName = \"non_partitioned\";\n+    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n+    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n+\n+    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n+    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n+            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n+    // Lets do the sync\n+    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n+    tool.syncHoodieTable();\n+    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n+            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n+    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n+            hiveClient.getDataSchema().getColumns().size(),\n+            \"Hive Schema should match the table schema\uff0cignoring the partition fields\");\n+    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n+            \"Table should not have partitions because of the NonPartitionedExtractor\");\n+    assertEquals(0, hiveClient.getTablePartitionKeys(hiveSyncConfig.tableName).size(),\n+            \"Table should not have partition keys because of the NonPartitionedExtractor\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "66d67705f75d660b4ec5327af5ed9acbf28b5f3e"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTgzMjUwMQ==", "bodyText": "Yes we do not need it indeed. Done. Thanks for your review.", "url": "https://github.com/apache/hudi/pull/1720#discussion_r439832501", "createdAt": "2020-06-14T13:55:58Z", "author": {"login": "cloud-luoyajun"}, "path": "hudi-hive-sync/src/test/java/org/apache/hudi/hive/TestHiveSyncTool.java", "diffHunk": "@@ -457,6 +457,37 @@ public void testMultiPartitionKeySync(boolean useJdbc) throws Exception {\n         \"The last commit that was sycned should be updated in the TBLPROPERTIES\");\n   }\n \n+  @ParameterizedTest\n+  @MethodSource(\"useJdbc\")\n+  public void testNonPartitionedSync(boolean useJdbc) throws Exception {\n+    HiveTestUtil.hiveSyncConfig.useJdbc = useJdbc;\n+    String instantTime = \"100\";\n+    HiveTestUtil.createCOWTable(instantTime, 5, true);\n+\n+    HiveSyncConfig hiveSyncConfig = HiveSyncConfig.copy(HiveTestUtil.hiveSyncConfig);\n+    // Set partition value extractor to NonPartitionedExtractor\n+    hiveSyncConfig.partitionValueExtractorClass = NonPartitionedExtractor.class.getCanonicalName();\n+    hiveSyncConfig.tableName = \"non_partitioned\";\n+    hiveSyncConfig.partitionFields = Arrays.asList(\"year\", \"month\", \"day\");\n+    HiveTestUtil.getCreatedTablesSet().add(hiveSyncConfig.databaseName + \".\" + hiveSyncConfig.tableName);\n+\n+    HoodieHiveClient hiveClient = new HoodieHiveClient(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n+    assertFalse(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n+            \"Table \" + hiveSyncConfig.tableName + \" should not exist initially\");\n+    // Lets do the sync\n+    HiveSyncTool tool = new HiveSyncTool(hiveSyncConfig, HiveTestUtil.getHiveConf(), HiveTestUtil.fileSystem);\n+    tool.syncHoodieTable();\n+    assertTrue(hiveClient.doesTableExist(hiveSyncConfig.tableName),\n+            \"Table \" + hiveSyncConfig.tableName + \" should exist after sync completes\");\n+    assertEquals(hiveClient.getTableSchema(hiveSyncConfig.tableName).size(),\n+            hiveClient.getDataSchema().getColumns().size(),\n+            \"Hive Schema should match the table schema\uff0cignoring the partition fields\");\n+    assertEquals(0, hiveClient.scanTablePartitions(hiveSyncConfig.tableName).size(),\n+            \"Table should not have partitions because of the NonPartitionedExtractor\");\n+    assertEquals(0, hiveClient.getTablePartitionKeys(hiveSyncConfig.tableName).size(),\n+            \"Table should not have partition keys because of the NonPartitionedExtractor\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTgxOTE4MQ=="}, "originalCommit": {"oid": "66d67705f75d660b4ec5327af5ed9acbf28b5f3e"}, "originalPosition": 32}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4482, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}