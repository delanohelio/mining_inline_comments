{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyNjYwNDcx", "number": 1312, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQxODoyODoxMVrODfST0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMjo1Mjo0M1rODfuc_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0MTMyNDMzOnYy", "diffSide": "RIGHT", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CompactionCommand.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQxODoyODoxMVrOFo5uPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMDowMzozMFrOFphxzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQzMzA4Ng==", "bodyText": "Pass timeline containing commit + compaction actions only, instead of activeTimeline (which may have other actions)?\nHoodieTimeline timeline = activeTimeline.getCommitsAndCompactionTimeline();", "url": "https://github.com/apache/hudi/pull/1312#discussion_r378433086", "createdAt": "2020-02-12T18:28:11Z", "author": {"login": "nbalajee"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CompactionCommand.java", "diffHunk": "@@ -95,51 +101,9 @@ public String compactionsAll(\n       throws IOException {\n     HoodieTableMetaClient client = checkAndGetMetaClient();\n     HoodieActiveTimeline activeTimeline = client.getActiveTimeline();\n-    HoodieTimeline timeline = activeTimeline.getCommitsAndCompactionTimeline();\n-    HoodieTimeline commitTimeline = activeTimeline.getCommitTimeline().filterCompletedInstants();\n-    Set<String> committed = commitTimeline.getInstants().map(HoodieInstant::getTimestamp).collect(Collectors.toSet());\n-\n-    List<HoodieInstant> instants = timeline.getReverseOrderedInstants().collect(Collectors.toList());\n-    List<Comparable[]> rows = new ArrayList<>();\n-    for (HoodieInstant instant : instants) {\n-      HoodieCompactionPlan compactionPlan = null;\n-      if (!HoodieTimeline.COMPACTION_ACTION.equals(instant.getAction())) {\n-        try {\n-          // This could be a completed compaction. Assume a compaction request file is present but skip if fails\n-          compactionPlan = AvroUtils.deserializeCompactionPlan(\n-              activeTimeline.readCompactionPlanAsBytes(\n-                  HoodieTimeline.getCompactionRequestedInstant(instant.getTimestamp())).get());\n-        } catch (HoodieIOException ioe) {\n-          // SKIP\n-        }\n-      } else {\n-        compactionPlan = AvroUtils.deserializeCompactionPlan(activeTimeline.readCompactionPlanAsBytes(\n-            HoodieTimeline.getCompactionRequestedInstant(instant.getTimestamp())).get());\n-      }\n-\n-      if (null != compactionPlan) {\n-        State state = instant.getState();\n-        if (committed.contains(instant.getTimestamp())) {\n-          state = State.COMPLETED;\n-        }\n-        if (includeExtraMetadata) {\n-          rows.add(new Comparable[] {instant.getTimestamp(), state.toString(),\n-              compactionPlan.getOperations() == null ? 0 : compactionPlan.getOperations().size(),\n-              compactionPlan.getExtraMetadata().toString()});\n-        } else {\n-          rows.add(new Comparable[] {instant.getTimestamp(), state.toString(),\n-              compactionPlan.getOperations() == null ? 0 : compactionPlan.getOperations().size()});\n-        }\n-      }\n-    }\n-\n-    Map<String, Function<Object, String>> fieldNameToConverterMap = new HashMap<>();\n-    TableHeader header = new TableHeader().addTableHeaderField(\"Compaction Instant Time\").addTableHeaderField(\"State\")\n-        .addTableHeaderField(\"Total FileIds to be Compacted\");\n-    if (includeExtraMetadata) {\n-      header = header.addTableHeaderField(\"Extra Metadata\");\n-    }\n-    return HoodiePrintHelper.print(header, fieldNameToConverterMap, sortByField, descending, limit, headerOnly, rows);\n+    return printAllCompactions(activeTimeline,\n+            compactionPlanReader(this::readCompactionPlanForActiveTimeline, activeTimeline),", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ3NTIxMg==", "bodyText": "@nbalajee printAllCompactions only calls compcationPlanReader for commits and compactions. As part of refactor, timeline.getCommitsAndCompactionTimeline has been moved into printAllCompactions (to reuse between active/archive timelines). I just verified this works as expected even in presence of cleans.\nLet me know if you think there is a better way to organize this.", "url": "https://github.com/apache/hudi/pull/1312#discussion_r378475212", "createdAt": "2020-02-12T19:47:47Z", "author": {"login": "satishkotha"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CompactionCommand.java", "diffHunk": "@@ -95,51 +101,9 @@ public String compactionsAll(\n       throws IOException {\n     HoodieTableMetaClient client = checkAndGetMetaClient();\n     HoodieActiveTimeline activeTimeline = client.getActiveTimeline();\n-    HoodieTimeline timeline = activeTimeline.getCommitsAndCompactionTimeline();\n-    HoodieTimeline commitTimeline = activeTimeline.getCommitTimeline().filterCompletedInstants();\n-    Set<String> committed = commitTimeline.getInstants().map(HoodieInstant::getTimestamp).collect(Collectors.toSet());\n-\n-    List<HoodieInstant> instants = timeline.getReverseOrderedInstants().collect(Collectors.toList());\n-    List<Comparable[]> rows = new ArrayList<>();\n-    for (HoodieInstant instant : instants) {\n-      HoodieCompactionPlan compactionPlan = null;\n-      if (!HoodieTimeline.COMPACTION_ACTION.equals(instant.getAction())) {\n-        try {\n-          // This could be a completed compaction. Assume a compaction request file is present but skip if fails\n-          compactionPlan = AvroUtils.deserializeCompactionPlan(\n-              activeTimeline.readCompactionPlanAsBytes(\n-                  HoodieTimeline.getCompactionRequestedInstant(instant.getTimestamp())).get());\n-        } catch (HoodieIOException ioe) {\n-          // SKIP\n-        }\n-      } else {\n-        compactionPlan = AvroUtils.deserializeCompactionPlan(activeTimeline.readCompactionPlanAsBytes(\n-            HoodieTimeline.getCompactionRequestedInstant(instant.getTimestamp())).get());\n-      }\n-\n-      if (null != compactionPlan) {\n-        State state = instant.getState();\n-        if (committed.contains(instant.getTimestamp())) {\n-          state = State.COMPLETED;\n-        }\n-        if (includeExtraMetadata) {\n-          rows.add(new Comparable[] {instant.getTimestamp(), state.toString(),\n-              compactionPlan.getOperations() == null ? 0 : compactionPlan.getOperations().size(),\n-              compactionPlan.getExtraMetadata().toString()});\n-        } else {\n-          rows.add(new Comparable[] {instant.getTimestamp(), state.toString(),\n-              compactionPlan.getOperations() == null ? 0 : compactionPlan.getOperations().size()});\n-        }\n-      }\n-    }\n-\n-    Map<String, Function<Object, String>> fieldNameToConverterMap = new HashMap<>();\n-    TableHeader header = new TableHeader().addTableHeaderField(\"Compaction Instant Time\").addTableHeaderField(\"State\")\n-        .addTableHeaderField(\"Total FileIds to be Compacted\");\n-    if (includeExtraMetadata) {\n-      header = header.addTableHeaderField(\"Extra Metadata\");\n-    }\n-    return HoodiePrintHelper.print(header, fieldNameToConverterMap, sortByField, descending, limit, headerOnly, rows);\n+    return printAllCompactions(activeTimeline,\n+            compactionPlanReader(this::readCompactionPlanForActiveTimeline, activeTimeline),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQzMzA4Ng=="}, "originalCommit": null, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA4OTM1OQ==", "bodyText": "Got it.  LGTM.", "url": "https://github.com/apache/hudi/pull/1312#discussion_r379089359", "createdAt": "2020-02-13T20:03:30Z", "author": {"login": "nbalajee"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CompactionCommand.java", "diffHunk": "@@ -95,51 +101,9 @@ public String compactionsAll(\n       throws IOException {\n     HoodieTableMetaClient client = checkAndGetMetaClient();\n     HoodieActiveTimeline activeTimeline = client.getActiveTimeline();\n-    HoodieTimeline timeline = activeTimeline.getCommitsAndCompactionTimeline();\n-    HoodieTimeline commitTimeline = activeTimeline.getCommitTimeline().filterCompletedInstants();\n-    Set<String> committed = commitTimeline.getInstants().map(HoodieInstant::getTimestamp).collect(Collectors.toSet());\n-\n-    List<HoodieInstant> instants = timeline.getReverseOrderedInstants().collect(Collectors.toList());\n-    List<Comparable[]> rows = new ArrayList<>();\n-    for (HoodieInstant instant : instants) {\n-      HoodieCompactionPlan compactionPlan = null;\n-      if (!HoodieTimeline.COMPACTION_ACTION.equals(instant.getAction())) {\n-        try {\n-          // This could be a completed compaction. Assume a compaction request file is present but skip if fails\n-          compactionPlan = AvroUtils.deserializeCompactionPlan(\n-              activeTimeline.readCompactionPlanAsBytes(\n-                  HoodieTimeline.getCompactionRequestedInstant(instant.getTimestamp())).get());\n-        } catch (HoodieIOException ioe) {\n-          // SKIP\n-        }\n-      } else {\n-        compactionPlan = AvroUtils.deserializeCompactionPlan(activeTimeline.readCompactionPlanAsBytes(\n-            HoodieTimeline.getCompactionRequestedInstant(instant.getTimestamp())).get());\n-      }\n-\n-      if (null != compactionPlan) {\n-        State state = instant.getState();\n-        if (committed.contains(instant.getTimestamp())) {\n-          state = State.COMPLETED;\n-        }\n-        if (includeExtraMetadata) {\n-          rows.add(new Comparable[] {instant.getTimestamp(), state.toString(),\n-              compactionPlan.getOperations() == null ? 0 : compactionPlan.getOperations().size(),\n-              compactionPlan.getExtraMetadata().toString()});\n-        } else {\n-          rows.add(new Comparable[] {instant.getTimestamp(), state.toString(),\n-              compactionPlan.getOperations() == null ? 0 : compactionPlan.getOperations().size()});\n-        }\n-      }\n-    }\n-\n-    Map<String, Function<Object, String>> fieldNameToConverterMap = new HashMap<>();\n-    TableHeader header = new TableHeader().addTableHeaderField(\"Compaction Instant Time\").addTableHeaderField(\"State\")\n-        .addTableHeaderField(\"Total FileIds to be Compacted\");\n-    if (includeExtraMetadata) {\n-      header = header.addTableHeaderField(\"Extra Metadata\");\n-    }\n-    return HoodiePrintHelper.print(header, fieldNameToConverterMap, sortByField, descending, limit, headerOnly, rows);\n+    return printAllCompactions(activeTimeline,\n+            compactionPlanReader(this::readCompactionPlanForActiveTimeline, activeTimeline),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQzMzA4Ng=="}, "originalCommit": null, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM0NTkzNTMzOnYy", "diffSide": "RIGHT", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CompactionCommand.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMjo1Mjo0M1rOFpmXYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMjoxNzoyNVrOFppz2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NDUxMw==", "bodyText": "what does this comment mean ?", "url": "https://github.com/apache/hudi/pull/1312#discussion_r379164513", "createdAt": "2020-02-13T22:52:43Z", "author": {"login": "n3nash"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CompactionCommand.java", "diffHunk": "@@ -249,6 +262,128 @@ public String compact(\n     return \"Compaction successfully completed for \" + compactionInstantTime;\n   }\n \n+  /**\n+   * Prints all compaction details.\n+   * Note values in compactionsPlans and instants lists are expected to be in cohesion", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIyMDk1Mg==", "bodyText": "its no longer relevant. so removed it. I intially had two parameters: List and List. But that didnt seem good, so changed it to one parameter.", "url": "https://github.com/apache/hudi/pull/1312#discussion_r379220952", "createdAt": "2020-02-14T02:17:25Z", "author": {"login": "satishkotha"}, "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CompactionCommand.java", "diffHunk": "@@ -249,6 +262,128 @@ public String compact(\n     return \"Compaction successfully completed for \" + compactionInstantTime;\n   }\n \n+  /**\n+   * Prints all compaction details.\n+   * Note values in compactionsPlans and instants lists are expected to be in cohesion", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NDUxMw=="}, "originalCommit": null, "originalPosition": 174}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 47, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}