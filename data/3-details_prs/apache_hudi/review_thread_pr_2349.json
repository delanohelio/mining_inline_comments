{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQyNzQ4ODcy", "number": 2349, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yNlQxODoxNDo1MFrOFJRnEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yNlQxODoxNDo1MFrOFJRnEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ1MjcwMDMyOnYy", "diffSide": "RIGHT", "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/index/hbase/TestHBaseIndex.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yNlQxODoxNDo1MFrOILlVyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOVQwMDoxNTozMFrOIMEWFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzAzMw==", "bodyText": "sorry, shouldn't this return 0 since the commit is rolled back? I see a test in this class testSimpleTagLocationAndUpdateWithRollback which tests that rolledback records don't have current location set. am I missing something?", "url": "https://github.com/apache/hudi/pull/2349#discussion_r549017033", "createdAt": "2020-12-26T18:14:50Z", "author": {"login": "nsivabalan"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/index/hbase/TestHBaseIndex.java", "diffHunk": "@@ -307,6 +308,125 @@ public void testSimpleTagLocationAndUpdateWithRollback() throws Exception {\n     assertEquals(0, records3.stream().filter(record -> record.getCurrentLocation() != null).count());\n   }\n \n+  /*\n+   * Test case to verify that for taglocation entries present in HBase, if the corresponding commit instant is missing\n+   * in timeline and the commit is not archived, taglocation would reset the current record location to null.\n+   */\n+  @Test\n+  public void testSimpleTagLocationWithInvalidCommit() throws Exception {\n+    // Load to memory\n+    HoodieWriteConfig config = getConfig();\n+    SparkHoodieHBaseIndex index = new SparkHoodieHBaseIndex(config);\n+    SparkRDDWriteClient writeClient = getHoodieWriteClient(config);\n+\n+    String newCommitTime = writeClient.startCommit();\n+    // make a commit with 199 records\n+    JavaRDD<HoodieRecord> writeRecords = generateAndCommitRecords(writeClient, 199);\n+\n+    // make a second commit with a single record\n+    String invalidCommit = writeClient.startCommit();\n+    JavaRDD<HoodieRecord> invalidWriteRecords = generateAndCommitRecords(writeClient, 1, invalidCommit);\n+\n+    // verify location is tagged.\n+    HoodieTable hoodieTable = HoodieSparkTable.create(config, context, metaClient);\n+    JavaRDD<HoodieRecord> javaRDD0 = index.tagLocation(invalidWriteRecords, context(), hoodieTable);\n+    assert (javaRDD0.collect().size() == 1);   // one record present\n+    assert (javaRDD0.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 1); // it is tagged\n+    assert (javaRDD0.collect().get(0).getCurrentLocation().getInstantTime().equals(invalidCommit));\n+\n+    // rollback the invalid commit, so that hbase will be left with a stale entry.\n+    writeClient.rollback(invalidCommit);\n+\n+    // Now tagLocation for the valid records, hbaseIndex should tag them\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    hoodieTable = HoodieSparkTable.create(config, context, metaClient);\n+    JavaRDD<HoodieRecord> javaRDD1 = index.tagLocation(writeRecords, context(), hoodieTable);\n+    assert (javaRDD1.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 199);\n+\n+    // tagLocation for the invalid record - commit is not present in timeline due to rollback.\n+    JavaRDD<HoodieRecord> javaRDD2 = index.tagLocation(invalidWriteRecords, context(), hoodieTable);\n+    assert (javaRDD2.collect().size() == 1);   // one record present\n+    assert (javaRDD2.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 0); // it is not tagged\n+  }\n+\n+  /*\n+   * Test case to verify that taglocation() uses the commit timeline to validate the commitTS stored in hbase.\n+   * When CheckIfValidCommit() in HbaseIndex uses the incorrect timeline filtering, this test would fail.\n+   */\n+  @Test\n+  public void testEnsureTagLocationUsesCommitTimeline() throws Exception {\n+    // Load to memory\n+    HoodieWriteConfig config = getConfig();\n+    SparkHoodieHBaseIndex index = new SparkHoodieHBaseIndex(config);\n+    SparkRDDWriteClient writeClient = getHoodieWriteClient(config);\n+\n+    String commitTime1 = writeClient.startCommit();\n+    JavaRDD<HoodieRecord> writeRecords1 = generateAndCommitRecords(writeClient, 20, commitTime1);\n+\n+    // rollback the commit - leaves a clean file in timeline.\n+    writeClient.rollback(commitTime1);\n+\n+    // create a second commit with 20 records\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    generateAndCommitRecords(writeClient, 20);\n+\n+    // Now tagLocation for the first set of rolledback records, hbaseIndex should tag them\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    HoodieTable hoodieTable = HoodieSparkTable.create(config, context, metaClient);\n+    JavaRDD<HoodieRecord> javaRDD1 = index.tagLocation(writeRecords1, context(), hoodieTable);\n+    assert (javaRDD1.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 20);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71df84f851413e1bba166f76f5c1fd621fa8754a"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ1ODk3Ng==", "bodyText": "These tests are added mainly to validate checkIfValidCommit() is using the completed commit timeline (older version of this function was not using the timeline with all instants, causing dupes).\nWhen the rolled back commit is older than the earliest available commit, then it is treated as an archived commit.", "url": "https://github.com/apache/hudi/pull/2349#discussion_r549458976", "createdAt": "2020-12-28T19:19:00Z", "author": {"login": "nbalajee"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/index/hbase/TestHBaseIndex.java", "diffHunk": "@@ -307,6 +308,125 @@ public void testSimpleTagLocationAndUpdateWithRollback() throws Exception {\n     assertEquals(0, records3.stream().filter(record -> record.getCurrentLocation() != null).count());\n   }\n \n+  /*\n+   * Test case to verify that for taglocation entries present in HBase, if the corresponding commit instant is missing\n+   * in timeline and the commit is not archived, taglocation would reset the current record location to null.\n+   */\n+  @Test\n+  public void testSimpleTagLocationWithInvalidCommit() throws Exception {\n+    // Load to memory\n+    HoodieWriteConfig config = getConfig();\n+    SparkHoodieHBaseIndex index = new SparkHoodieHBaseIndex(config);\n+    SparkRDDWriteClient writeClient = getHoodieWriteClient(config);\n+\n+    String newCommitTime = writeClient.startCommit();\n+    // make a commit with 199 records\n+    JavaRDD<HoodieRecord> writeRecords = generateAndCommitRecords(writeClient, 199);\n+\n+    // make a second commit with a single record\n+    String invalidCommit = writeClient.startCommit();\n+    JavaRDD<HoodieRecord> invalidWriteRecords = generateAndCommitRecords(writeClient, 1, invalidCommit);\n+\n+    // verify location is tagged.\n+    HoodieTable hoodieTable = HoodieSparkTable.create(config, context, metaClient);\n+    JavaRDD<HoodieRecord> javaRDD0 = index.tagLocation(invalidWriteRecords, context(), hoodieTable);\n+    assert (javaRDD0.collect().size() == 1);   // one record present\n+    assert (javaRDD0.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 1); // it is tagged\n+    assert (javaRDD0.collect().get(0).getCurrentLocation().getInstantTime().equals(invalidCommit));\n+\n+    // rollback the invalid commit, so that hbase will be left with a stale entry.\n+    writeClient.rollback(invalidCommit);\n+\n+    // Now tagLocation for the valid records, hbaseIndex should tag them\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    hoodieTable = HoodieSparkTable.create(config, context, metaClient);\n+    JavaRDD<HoodieRecord> javaRDD1 = index.tagLocation(writeRecords, context(), hoodieTable);\n+    assert (javaRDD1.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 199);\n+\n+    // tagLocation for the invalid record - commit is not present in timeline due to rollback.\n+    JavaRDD<HoodieRecord> javaRDD2 = index.tagLocation(invalidWriteRecords, context(), hoodieTable);\n+    assert (javaRDD2.collect().size() == 1);   // one record present\n+    assert (javaRDD2.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 0); // it is not tagged\n+  }\n+\n+  /*\n+   * Test case to verify that taglocation() uses the commit timeline to validate the commitTS stored in hbase.\n+   * When CheckIfValidCommit() in HbaseIndex uses the incorrect timeline filtering, this test would fail.\n+   */\n+  @Test\n+  public void testEnsureTagLocationUsesCommitTimeline() throws Exception {\n+    // Load to memory\n+    HoodieWriteConfig config = getConfig();\n+    SparkHoodieHBaseIndex index = new SparkHoodieHBaseIndex(config);\n+    SparkRDDWriteClient writeClient = getHoodieWriteClient(config);\n+\n+    String commitTime1 = writeClient.startCommit();\n+    JavaRDD<HoodieRecord> writeRecords1 = generateAndCommitRecords(writeClient, 20, commitTime1);\n+\n+    // rollback the commit - leaves a clean file in timeline.\n+    writeClient.rollback(commitTime1);\n+\n+    // create a second commit with 20 records\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    generateAndCommitRecords(writeClient, 20);\n+\n+    // Now tagLocation for the first set of rolledback records, hbaseIndex should tag them\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    HoodieTable hoodieTable = HoodieSparkTable.create(config, context, metaClient);\n+    JavaRDD<HoodieRecord> javaRDD1 = index.tagLocation(writeRecords1, context(), hoodieTable);\n+    assert (javaRDD1.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 20);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzAzMw=="}, "originalCommit": {"oid": "71df84f851413e1bba166f76f5c1fd621fa8754a"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyNTAxNA==", "bodyText": "@nsivabalan ^", "url": "https://github.com/apache/hudi/pull/2349#discussion_r549525014", "createdAt": "2020-12-29T00:15:30Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/index/hbase/TestHBaseIndex.java", "diffHunk": "@@ -307,6 +308,125 @@ public void testSimpleTagLocationAndUpdateWithRollback() throws Exception {\n     assertEquals(0, records3.stream().filter(record -> record.getCurrentLocation() != null).count());\n   }\n \n+  /*\n+   * Test case to verify that for taglocation entries present in HBase, if the corresponding commit instant is missing\n+   * in timeline and the commit is not archived, taglocation would reset the current record location to null.\n+   */\n+  @Test\n+  public void testSimpleTagLocationWithInvalidCommit() throws Exception {\n+    // Load to memory\n+    HoodieWriteConfig config = getConfig();\n+    SparkHoodieHBaseIndex index = new SparkHoodieHBaseIndex(config);\n+    SparkRDDWriteClient writeClient = getHoodieWriteClient(config);\n+\n+    String newCommitTime = writeClient.startCommit();\n+    // make a commit with 199 records\n+    JavaRDD<HoodieRecord> writeRecords = generateAndCommitRecords(writeClient, 199);\n+\n+    // make a second commit with a single record\n+    String invalidCommit = writeClient.startCommit();\n+    JavaRDD<HoodieRecord> invalidWriteRecords = generateAndCommitRecords(writeClient, 1, invalidCommit);\n+\n+    // verify location is tagged.\n+    HoodieTable hoodieTable = HoodieSparkTable.create(config, context, metaClient);\n+    JavaRDD<HoodieRecord> javaRDD0 = index.tagLocation(invalidWriteRecords, context(), hoodieTable);\n+    assert (javaRDD0.collect().size() == 1);   // one record present\n+    assert (javaRDD0.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 1); // it is tagged\n+    assert (javaRDD0.collect().get(0).getCurrentLocation().getInstantTime().equals(invalidCommit));\n+\n+    // rollback the invalid commit, so that hbase will be left with a stale entry.\n+    writeClient.rollback(invalidCommit);\n+\n+    // Now tagLocation for the valid records, hbaseIndex should tag them\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    hoodieTable = HoodieSparkTable.create(config, context, metaClient);\n+    JavaRDD<HoodieRecord> javaRDD1 = index.tagLocation(writeRecords, context(), hoodieTable);\n+    assert (javaRDD1.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 199);\n+\n+    // tagLocation for the invalid record - commit is not present in timeline due to rollback.\n+    JavaRDD<HoodieRecord> javaRDD2 = index.tagLocation(invalidWriteRecords, context(), hoodieTable);\n+    assert (javaRDD2.collect().size() == 1);   // one record present\n+    assert (javaRDD2.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 0); // it is not tagged\n+  }\n+\n+  /*\n+   * Test case to verify that taglocation() uses the commit timeline to validate the commitTS stored in hbase.\n+   * When CheckIfValidCommit() in HbaseIndex uses the incorrect timeline filtering, this test would fail.\n+   */\n+  @Test\n+  public void testEnsureTagLocationUsesCommitTimeline() throws Exception {\n+    // Load to memory\n+    HoodieWriteConfig config = getConfig();\n+    SparkHoodieHBaseIndex index = new SparkHoodieHBaseIndex(config);\n+    SparkRDDWriteClient writeClient = getHoodieWriteClient(config);\n+\n+    String commitTime1 = writeClient.startCommit();\n+    JavaRDD<HoodieRecord> writeRecords1 = generateAndCommitRecords(writeClient, 20, commitTime1);\n+\n+    // rollback the commit - leaves a clean file in timeline.\n+    writeClient.rollback(commitTime1);\n+\n+    // create a second commit with 20 records\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    generateAndCommitRecords(writeClient, 20);\n+\n+    // Now tagLocation for the first set of rolledback records, hbaseIndex should tag them\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    HoodieTable hoodieTable = HoodieSparkTable.create(config, context, metaClient);\n+    JavaRDD<HoodieRecord> javaRDD1 = index.tagLocation(writeRecords1, context(), hoodieTable);\n+    assert (javaRDD1.filter(HoodieRecord::isCurrentLocationKnown).collect().size() == 20);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzAzMw=="}, "originalCommit": {"oid": "71df84f851413e1bba166f76f5c1fd621fa8754a"}, "originalPosition": 78}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4027, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}