{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMzMDE0Mzkz", "number": 2300, "title": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat", "bodyText": "What is the purpose of the pull request\nBugfix. Examples in the Jira: https://issues.apache.org/jira/browse/HUDI-1434\n#1567 move the logic to determine whether we need to roll over the log file version when actually writing the file, but we write the log path to HoodieWriteStat when initializing the HoodieAppendHandle. If the log file is not appendable, the log file will roll over to the next version, but the HoodieWriteStat will still have the previous version, and this will make the deltacommit metadata has the wrong path.\nBrief change log\nModified how we store the file path in HoodieAppendHandle\nVerify this pull request\n(Please pick either of the following options)\nTests will be covered by #1938\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-12-05T13:02:29Z", "url": "https://github.com/apache/hudi/pull/2300", "merged": true, "mergeCommit": {"oid": "605b617cfa9a25bff48e618beccfaa7b4eaeee56"}, "closed": true, "closedAt": "2020-12-30T22:22:16Z", "author": {"login": "garyli1019"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdjOJcLABqjQwNzU2OTczNTM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdrW-CTgFqTU2MDIxNzY0NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a7d1822fd4723193ff317678e5da87ea776ff7e2", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/a7d1822fd4723193ff317678e5da87ea776ff7e2", "committedDate": "2020-12-05T13:01:43Z", "message": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat"}, "afterCommit": {"oid": "d4b29b9a98295bff1c57f0c7c72d5f7dd9223e3d", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/d4b29b9a98295bff1c57f0c7c72d5f7dd9223e3d", "committedDate": "2020-12-05T15:33:19Z", "message": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d4b29b9a98295bff1c57f0c7c72d5f7dd9223e3d", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/d4b29b9a98295bff1c57f0c7c72d5f7dd9223e3d", "committedDate": "2020-12-05T15:33:19Z", "message": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat"}, "afterCommit": {"oid": "db85097aff54d3f0a6177150cde405b01e3af977", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/db85097aff54d3f0a6177150cde405b01e3af977", "committedDate": "2020-12-05T15:35:46Z", "message": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "db85097aff54d3f0a6177150cde405b01e3af977", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/db85097aff54d3f0a6177150cde405b01e3af977", "committedDate": "2020-12-05T15:35:46Z", "message": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat"}, "afterCommit": {"oid": "a0b89bef67bb5d0a3ed20f02af8e10d8bd65a16e", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/a0b89bef67bb5d0a3ed20f02af8e10d8bd65a16e", "committedDate": "2020-12-19T12:03:42Z", "message": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a0b89bef67bb5d0a3ed20f02af8e10d8bd65a16e", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/a0b89bef67bb5d0a3ed20f02af8e10d8bd65a16e", "committedDate": "2020-12-19T12:03:42Z", "message": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat"}, "afterCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0", "committedDate": "2020-12-19T13:04:30Z", "message": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2NzM2Mzk3", "url": "https://github.com/apache/hudi/pull/2300#pullrequestreview-556736397", "createdAt": "2020-12-21T23:58:22Z", "commit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMzo1ODoyM1rOIJpvag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwODo0NjoyOVrOIJzGxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk5MTk3OA==", "bodyText": "while we are at it. fix this log statement? New AppendHandle for ..", "url": "https://github.com/apache/hudi/pull/2300#discussion_r546991978", "createdAt": "2020-12-21T23:58:23Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -125,19 +129,26 @@ private void init(HoodieRecord record) {\n       Option<FileSlice> fileSlice = rtView.getLatestFileSlice(partitionPath, fileId);\n       // Set the base commit time as the current instantTime for new inserts into log files\n       String baseInstantTime;\n+      String baseFile = \"\";\n+      List<String> logFiles = new ArrayList<>();\n       if (fileSlice.isPresent()) {\n         baseInstantTime = fileSlice.get().getBaseInstantTime();\n+        baseFile = fileSlice.get().getBaseFile().map(BaseFile::getFileName).orElse(\"\");\n+        logFiles = fileSlice.get().getLogFiles().map(HoodieLogFile::getFileName).collect(Collectors.toList());\n       } else {\n         baseInstantTime = instantTime;\n         // This means there is no base data file, start appending to a new log file\n         fileSlice = Option.of(new FileSlice(partitionPath, baseInstantTime, this.fileId));\n         LOG.info(\"New InsertHandle for partition :\" + partitionPath);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTAzMw==", "bodyText": "so this sets the baseFile and the logFiles that existed before this delta commit?", "url": "https://github.com/apache/hudi/pull/2300#discussion_r547141033", "createdAt": "2020-12-22T08:37:29Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -125,19 +129,26 @@ private void init(HoodieRecord record) {\n       Option<FileSlice> fileSlice = rtView.getLatestFileSlice(partitionPath, fileId);\n       // Set the base commit time as the current instantTime for new inserts into log files\n       String baseInstantTime;\n+      String baseFile = \"\";\n+      List<String> logFiles = new ArrayList<>();\n       if (fileSlice.isPresent()) {\n         baseInstantTime = fileSlice.get().getBaseInstantTime();\n+        baseFile = fileSlice.get().getBaseFile().map(BaseFile::getFileName).orElse(\"\");\n+        logFiles = fileSlice.get().getLogFiles().map(HoodieLogFile::getFileName).collect(Collectors.toList());\n       } else {\n         baseInstantTime = instantTime;\n         // This means there is no base data file, start appending to a new log file\n         fileSlice = Option.of(new FileSlice(partitionPath, baseInstantTime, this.fileId));\n         LOG.info(\"New InsertHandle for partition :\" + partitionPath);\n       }\n-      writeStatus.getStat().setPrevCommit(baseInstantTime);\n+      HoodieDeltaWriteStat deltaWriteStat = (HoodieDeltaWriteStat) writeStatus.getStat();\n+      deltaWriteStat.setPrevCommit(baseInstantTime);\n       writeStatus.setFileId(fileId);\n       writeStatus.setPartitionPath(partitionPath);\n-      writeStatus.getStat().setPartitionPath(partitionPath);\n-      writeStatus.getStat().setFileId(fileId);\n+      deltaWriteStat.setPartitionPath(partitionPath);\n+      deltaWriteStat.setFileId(fileId);\n+      deltaWriteStat.setBaseFile(baseFile);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MzEwMw==", "bodyText": "in general., naming these variables with some context with some documentation, would help readability of this file.\ne.g initialLogVersion ,  filePath -> logFilePathWritten etc", "url": "https://github.com/apache/hudi/pull/2300#discussion_r547143103", "createdAt": "2020-12-22T08:41:48Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -87,6 +88,9 @@\n   private long averageRecordSize = 0;\n   private HoodieLogFile currentLogFile;\n   private Writer writer;\n+  private String filePath = \"null\";\n+  private int logVersion = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0NDAyMA==", "bodyText": "this offset would still point to the file at which the write started?", "url": "https://github.com/apache/hudi/pull/2300#discussion_r547144020", "createdAt": "2020-12-22T08:43:39Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -258,20 +265,32 @@ public WriteStatus close() {\n       // flush any remaining records to disk\n       doAppend(header);\n \n+      String latestLogFile = \"\";\n       if (writer != null) {\n         sizeInBytes = writer.getCurrentSize();\n+        latestLogFile = writer.getLogFile().getFileName();\n+        filePath = partitionPath.length() == 0 ? new Path(latestLogFile).toString()\n+            : new Path(partitionPath, latestLogFile).toString();\n+        logVersion = writer.getLogFile().getLogVersion();\n         writer.close();\n       }\n \n-      HoodieWriteStat stat = writeStatus.getStat();\n+      HoodieDeltaWriteStat stat = (HoodieDeltaWriteStat) writeStatus.getStat();\n       stat.setFileId(this.fileId);\n+      stat.setPath(this.filePath);\n+      stat.setLogVersion(logVersion);\n+      stat.setLogOffset(logOffset);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0NDU2Mw==", "bodyText": "why is this change needed?", "url": "https://github.com/apache/hudi/pull/2300#discussion_r547144563", "createdAt": "2020-12-22T08:44:41Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -303,6 +322,7 @@ private Writer createLogWriter(Option<FileSlice> fileSlice, String baseCommitTim\n         .onParentPath(FSUtils.getPartitionPath(hoodieTable.getMetaClient().getBasePath(), partitionPath))\n         .withFileId(fileId).overBaseCommit(baseCommitTime)\n         .withLogVersion(latestLogFile.map(HoodieLogFile::getLogVersion).orElse(HoodieLogFile.LOGFILE_BASE_VERSION))\n+        .withFileSize(latestLogFile.map(HoodieLogFile::getFileSize).orElse(0L))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0NTQxNQ==", "bodyText": "wht if we had rolled over the log files in between? i.e created more than one new log file during write. I think we should add to the list of log files, during every rollOver, not just at close", "url": "https://github.com/apache/hudi/pull/2300#discussion_r547145415", "createdAt": "2020-12-22T08:46:29Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -258,20 +265,32 @@ public WriteStatus close() {\n       // flush any remaining records to disk\n       doAppend(header);\n \n+      String latestLogFile = \"\";\n       if (writer != null) {\n         sizeInBytes = writer.getCurrentSize();\n+        latestLogFile = writer.getLogFile().getFileName();\n+        filePath = partitionPath.length() == 0 ? new Path(latestLogFile).toString()\n+            : new Path(partitionPath, latestLogFile).toString();\n+        logVersion = writer.getLogFile().getLogVersion();\n         writer.close();\n       }\n \n-      HoodieWriteStat stat = writeStatus.getStat();\n+      HoodieDeltaWriteStat stat = (HoodieDeltaWriteStat) writeStatus.getStat();\n       stat.setFileId(this.fileId);\n+      stat.setPath(this.filePath);\n+      stat.setLogVersion(logVersion);\n+      stat.setLogOffset(logOffset);\n       stat.setNumWrites(recordsWritten);\n       stat.setNumUpdateWrites(updatedRecordsWritten);\n       stat.setNumInserts(insertRecordsWritten);\n       stat.setNumDeletes(recordsDeleted);\n       stat.setTotalWriteBytes(estimatedNumberOfBytesWritten);\n       stat.setFileSizeInBytes(sizeInBytes);\n       stat.setTotalWriteErrors(writeStatus.getTotalErrorRecords());\n+      // update total log file list if the latest log file was new\n+      if (!stat.getLogFiles().contains(latestLogFile)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 111}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MDg3ODQ0", "url": "https://github.com/apache/hudi/pull/2300#pullrequestreview-557087844", "createdAt": "2020-12-22T13:43:55Z", "commit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxMzo0Mzo1NlrOIJ7nqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNDowMzoxMFrOIJ8OOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzI4NDkwNw==", "bodyText": "right, since we got this information from the flieSlice", "url": "https://github.com/apache/hudi/pull/2300#discussion_r547284907", "createdAt": "2020-12-22T13:43:56Z", "author": {"login": "garyli1019"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -125,19 +129,26 @@ private void init(HoodieRecord record) {\n       Option<FileSlice> fileSlice = rtView.getLatestFileSlice(partitionPath, fileId);\n       // Set the base commit time as the current instantTime for new inserts into log files\n       String baseInstantTime;\n+      String baseFile = \"\";\n+      List<String> logFiles = new ArrayList<>();\n       if (fileSlice.isPresent()) {\n         baseInstantTime = fileSlice.get().getBaseInstantTime();\n+        baseFile = fileSlice.get().getBaseFile().map(BaseFile::getFileName).orElse(\"\");\n+        logFiles = fileSlice.get().getLogFiles().map(HoodieLogFile::getFileName).collect(Collectors.toList());\n       } else {\n         baseInstantTime = instantTime;\n         // This means there is no base data file, start appending to a new log file\n         fileSlice = Option.of(new FileSlice(partitionPath, baseInstantTime, this.fileId));\n         LOG.info(\"New InsertHandle for partition :\" + partitionPath);\n       }\n-      writeStatus.getStat().setPrevCommit(baseInstantTime);\n+      HoodieDeltaWriteStat deltaWriteStat = (HoodieDeltaWriteStat) writeStatus.getStat();\n+      deltaWriteStat.setPrevCommit(baseInstantTime);\n       writeStatus.setFileId(fileId);\n       writeStatus.setPartitionPath(partitionPath);\n-      writeStatus.getStat().setPartitionPath(partitionPath);\n-      writeStatus.getStat().setFileId(fileId);\n+      deltaWriteStat.setPartitionPath(partitionPath);\n+      deltaWriteStat.setFileId(fileId);\n+      deltaWriteStat.setBaseFile(baseFile);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTAzMw=="}, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzI4NzMyNQ==", "bodyText": "this offset should be 0 if we write to a new log file, but the file size of the existing log file if we do append. Currently this offset seems not working because I am don't see anywhere this can get the log file size.", "url": "https://github.com/apache/hudi/pull/2300#discussion_r547287325", "createdAt": "2020-12-22T13:48:46Z", "author": {"login": "garyli1019"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -258,20 +265,32 @@ public WriteStatus close() {\n       // flush any remaining records to disk\n       doAppend(header);\n \n+      String latestLogFile = \"\";\n       if (writer != null) {\n         sizeInBytes = writer.getCurrentSize();\n+        latestLogFile = writer.getLogFile().getFileName();\n+        filePath = partitionPath.length() == 0 ? new Path(latestLogFile).toString()\n+            : new Path(partitionPath, latestLogFile).toString();\n+        logVersion = writer.getLogFile().getLogVersion();\n         writer.close();\n       }\n \n-      HoodieWriteStat stat = writeStatus.getStat();\n+      HoodieDeltaWriteStat stat = (HoodieDeltaWriteStat) writeStatus.getStat();\n       stat.setFileId(this.fileId);\n+      stat.setPath(this.filePath);\n+      stat.setLogVersion(logVersion);\n+      stat.setLogOffset(logOffset);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0NDAyMA=="}, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzI4ODcyNg==", "bodyText": "Not quite sure about the rollover case. Is that possible that two log files will be written in one commit? If we will write two log files, then the path should contain 2 files as well?", "url": "https://github.com/apache/hudi/pull/2300#discussion_r547288726", "createdAt": "2020-12-22T13:51:42Z", "author": {"login": "garyli1019"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -258,20 +265,32 @@ public WriteStatus close() {\n       // flush any remaining records to disk\n       doAppend(header);\n \n+      String latestLogFile = \"\";\n       if (writer != null) {\n         sizeInBytes = writer.getCurrentSize();\n+        latestLogFile = writer.getLogFile().getFileName();\n+        filePath = partitionPath.length() == 0 ? new Path(latestLogFile).toString()\n+            : new Path(partitionPath, latestLogFile).toString();\n+        logVersion = writer.getLogFile().getLogVersion();\n         writer.close();\n       }\n \n-      HoodieWriteStat stat = writeStatus.getStat();\n+      HoodieDeltaWriteStat stat = (HoodieDeltaWriteStat) writeStatus.getStat();\n       stat.setFileId(this.fileId);\n+      stat.setPath(this.filePath);\n+      stat.setLogVersion(logVersion);\n+      stat.setLogOffset(logOffset);\n       stat.setNumWrites(recordsWritten);\n       stat.setNumUpdateWrites(updatedRecordsWritten);\n       stat.setNumInserts(insertRecordsWritten);\n       stat.setNumDeletes(recordsDeleted);\n       stat.setTotalWriteBytes(estimatedNumberOfBytesWritten);\n       stat.setFileSizeInBytes(sizeInBytes);\n       stat.setTotalWriteErrors(writeStatus.getTotalErrorRecords());\n+      // update total log file list if the latest log file was new\n+      if (!stat.getLogFiles().contains(latestLogFile)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0NTQxNQ=="}, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzI5NDc3Ng==", "bodyText": "trying to store the offset in the writer, so this will be sync with the log version. when the log version being changed, we can change the offset as well.", "url": "https://github.com/apache/hudi/pull/2300#discussion_r547294776", "createdAt": "2020-12-22T14:03:10Z", "author": {"login": "garyli1019"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -303,6 +322,7 @@ private Writer createLogWriter(Option<FileSlice> fileSlice, String baseCommitTim\n         .onParentPath(FSUtils.getPartitionPath(hoodieTable.getMetaClient().getBasePath(), partitionPath))\n         .withFileId(fileId).overBaseCommit(baseCommitTime)\n         .withLogVersion(latestLogFile.map(HoodieLogFile::getLogVersion).orElse(HoodieLogFile.LOGFILE_BASE_VERSION))\n+        .withFileSize(latestLogFile.map(HoodieLogFile::getFileSize).orElse(0L))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0NDU2Mw=="}, "originalCommit": {"oid": "7f375aaf12e0c070c7f9cebe21dc25eb5a2894f0"}, "originalPosition": 121}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6c03311cab24d39908937ab5e0372dfd6c5403d", "author": {"user": {"login": "garyli1019", "name": "Gary Li"}}, "url": "https://github.com/apache/hudi/commit/a6c03311cab24d39908937ab5e0372dfd6c5403d", "committedDate": "2020-12-26T14:56:31Z", "message": "[HUDI-1434] fix incorrect log file path in HoodieWriteStat"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c25633033caed35cb45d0b9e188fa86b0ef1ca0", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/9c25633033caed35cb45d0b9e188fa86b0ef1ca0", "committedDate": "2020-12-26T14:56:32Z", "message": "HoodieWriteHandle#close() returns a list of WriteStatus objs"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "daf21398d2a3087a1e1587be4301b31b70445c64", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/daf21398d2a3087a1e1587be4301b31b70445c64", "committedDate": "2020-12-25T01:42:34Z", "message": "Handle rolled-over log files and return a WriteStatus per log file written\n\nOpen\n - the write status overcounts the amount of inserts/deltes\n - tests don't pass due to this."}, "afterCommit": {"oid": "34d09b7616c1b386a1bef88f07cc39c6a48bc414", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/34d09b7616c1b386a1bef88f07cc39c6a48bc414", "committedDate": "2020-12-26T15:05:15Z", "message": "Handle rolled-over log files and return a WriteStatus per log file written\n\n - Combined data and delete block logging into a single call\n - Lazily initialize and manage write status based on returned AppendResult\n - Use FSUtils.getFileSize() to set final file size, consistent with other handles"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "34d09b7616c1b386a1bef88f07cc39c6a48bc414", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/34d09b7616c1b386a1bef88f07cc39c6a48bc414", "committedDate": "2020-12-26T15:05:15Z", "message": "Handle rolled-over log files and return a WriteStatus per log file written\n\n - Combined data and delete block logging into a single call\n - Lazily initialize and manage write status based on returned AppendResult\n - Use FSUtils.getFileSize() to set final file size, consistent with other handles"}, "afterCommit": {"oid": "2930bffaaf5bf1083f5a8e69a4883e28b8c3a9a6", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/2930bffaaf5bf1083f5a8e69a4883e28b8c3a9a6", "committedDate": "2020-12-26T15:07:11Z", "message": "Handle rolled-over log files and return a WriteStatus per log file written\n\n - Combined data and delete block logging into a single call\n - Lazily initialize and manage write status based on returned AppendResult\n - Use FSUtils.getFileSize() to set final file size, consistent with other handles"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2930bffaaf5bf1083f5a8e69a4883e28b8c3a9a6", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/2930bffaaf5bf1083f5a8e69a4883e28b8c3a9a6", "committedDate": "2020-12-26T15:07:11Z", "message": "Handle rolled-over log files and return a WriteStatus per log file written\n\n - Combined data and delete block logging into a single call\n - Lazily initialize and manage write status based on returned AppendResult\n - Use FSUtils.getFileSize() to set final file size, consistent with other handles"}, "afterCommit": {"oid": "207b04671876da7a64255459de00baa6a8d46477", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/207b04671876da7a64255459de00baa6a8d46477", "committedDate": "2020-12-26T15:19:43Z", "message": "Handle rolled-over log files and return a WriteStatus per log file written\n\n - Combined data and delete block logging into a single call\n - Lazily initialize and manage write status based on returned AppendResult\n - Use FSUtils.getFileSize() to set final file size, consistent with other handles"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU4OTE1MTc5", "url": "https://github.com/apache/hudi/pull/2300#pullrequestreview-558915179", "createdAt": "2020-12-27T09:30:03Z", "commit": {"oid": "207b04671876da7a64255459de00baa6a8d46477"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yN1QwOTozMDowM1rOILpu-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yN1QwOTozMDowM1rOILpu-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA4OTAxOA==", "bodyText": "I am seeing the log version start from 2 in my local test. I guess it's probably we removed the write token here and initializing the token will increment the log version by 1. The HoodieLogFile.LOGFILE_BASE_VERSION is 1.", "url": "https://github.com/apache/hudi/pull/2300#discussion_r549089018", "createdAt": "2020-12-27T09:30:03Z", "author": {"login": "garyli1019"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -303,8 +404,8 @@ private Writer createLogWriter(Option<FileSlice> fileSlice, String baseCommitTim\n         .onParentPath(FSUtils.getPartitionPath(hoodieTable.getMetaClient().getBasePath(), partitionPath))\n         .withFileId(fileId).overBaseCommit(baseCommitTime)\n         .withLogVersion(latestLogFile.map(HoodieLogFile::getLogVersion).orElse(HoodieLogFile.LOGFILE_BASE_VERSION))\n+        .withFileSize(latestLogFile.map(HoodieLogFile::getFileSize).orElse(0L))\n         .withSizeThreshold(config.getLogFileMaxSize()).withFs(fs)\n-        .withLogWriteToken(latestLogFile.map(x -> FSUtils.getWriteTokenFromLogPath(x.getPath())).orElse(writeToken))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "207b04671876da7a64255459de00baa6a8d46477"}, "originalPosition": 390}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU4OTAxMzM5", "url": "https://github.com/apache/hudi/pull/2300#pullrequestreview-558901339", "createdAt": "2020-12-27T03:18:41Z", "commit": {"oid": "207b04671876da7a64255459de00baa6a8d46477"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yN1QwMzoxODo0MVrOILn4KA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yN1QwMzo0MjowMFrOILn-rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA1ODYwMA==", "bodyText": "Will this offset contain the offset of the last log file the append handle writes to ?", "url": "https://github.com/apache/hudi/pull/2300#discussion_r549058600", "createdAt": "2020-12-27T03:18:41Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -203,31 +213,136 @@ private void init(HoodieRecord record) {\n     return Option.empty();\n   }\n \n+  private void initNewStatus() {\n+    HoodieDeltaWriteStat prevStat = (HoodieDeltaWriteStat) this.writeStatus.getStat();\n+    // Make a new write status and copy basic fields over.\n+    HoodieDeltaWriteStat stat = new HoodieDeltaWriteStat();\n+    stat.setFileId(fileId);\n+    stat.setPartitionPath(partitionPath);\n+    stat.setPrevCommit(prevStat.getPrevCommit());\n+    stat.setBaseFile(prevStat.getBaseFile());\n+    stat.setLogFiles(new ArrayList<>(prevStat.getLogFiles()));\n+\n+    this.writeStatus = (WriteStatus) ReflectionUtils.loadClass(config.getWriteStatusClassName(),\n+        !hoodieTable.getIndex().isImplicitWithStorage(), config.getWriteStatusFailureFraction());\n+    this.writeStatus.setFileId(fileId);\n+    this.writeStatus.setPartitionPath(partitionPath);\n+    this.writeStatus.setStat(stat);\n+  }\n+\n+  private String makeFilePath(HoodieLogFile logFile) {\n+    return partitionPath.length() == 0\n+        ? new Path(logFile.getFileName()).toString()\n+        : new Path(partitionPath, logFile.getFileName()).toString();\n+  }\n+\n+  private void resetWriteCounts() {\n+    recordsWritten = 0;\n+    updatedRecordsWritten = 0;\n+    insertRecordsWritten = 0;\n+    recordsDeleted = 0;\n+  }\n+\n+  private void updateWriteCounts(HoodieDeltaWriteStat stat, AppendResult result) {\n+    stat.setNumWrites(recordsWritten);\n+    stat.setNumUpdateWrites(updatedRecordsWritten);\n+    stat.setNumInserts(insertRecordsWritten);\n+    stat.setNumDeletes(recordsDeleted);\n+    stat.setTotalWriteBytes(result.size());\n+  }\n+\n+  private void accumulateWriteCounts(HoodieDeltaWriteStat stat, AppendResult result) {\n+    stat.setNumWrites(stat.getNumWrites() + recordsWritten);\n+    stat.setNumUpdateWrites(stat.getNumUpdateWrites() + updatedRecordsWritten);\n+    stat.setNumInserts(stat.getNumInserts() + insertRecordsWritten);\n+    stat.setNumDeletes(stat.getNumDeletes() + recordsDeleted);\n+    stat.setTotalWriteBytes(stat.getTotalWriteBytes() + result.size());\n+  }\n+\n+  private void updateWriteStat(HoodieDeltaWriteStat stat, AppendResult result) {\n+    stat.setPath(makeFilePath(result.logFile()));\n+    stat.setLogOffset(result.offset());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "207b04671876da7a64255459de00baa6a8d46477"}, "originalPosition": 222}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA1OTAzOQ==", "bodyText": "Nit: addLogFile or appendLogFile", "url": "https://github.com/apache/hudi/pull/2300#discussion_r549059039", "createdAt": "2020-12-27T03:25:16Z", "author": {"login": "n3nash"}, "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieDeltaWriteStat.java", "diffHunk": "@@ -44,4 +49,24 @@ public void setLogOffset(long logOffset) {\n   public long getLogOffset() {\n     return logOffset;\n   }\n+\n+  public void setBaseFile(String baseFile) {\n+    this.baseFile = baseFile;\n+  }\n+\n+  public String getBaseFile() {\n+    return baseFile;\n+  }\n+\n+  public void setLogFiles(List<String> logFiles) {\n+    this.logFiles = logFiles;\n+  }\n+\n+  public void appendLogFiles(String logFile) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "207b04671876da7a64255459de00baa6a8d46477"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA2MDI3MA==", "bodyText": "High level question - it looks like you are passing the information from the previous WriteStatus and HoodieWriteStat for one log file to the new one if rolled over, what is the need to return list of write statuses ?", "url": "https://github.com/apache/hudi/pull/2300#discussion_r549060270", "createdAt": "2020-12-27T03:42:00Z", "author": {"login": "n3nash"}, "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -203,31 +213,136 @@ private void init(HoodieRecord record) {\n     return Option.empty();\n   }\n \n+  private void initNewStatus() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "207b04671876da7a64255459de00baa6a8d46477"}, "originalPosition": 174}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "150d1832855060664a0ed76cff9a6f0c65890bc0", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/150d1832855060664a0ed76cff9a6f0c65890bc0", "committedDate": "2020-12-29T22:29:34Z", "message": "Handle rolled-over log files and return a WriteStatus per log file written\n\n - Combined data and delete block logging into a single call\n - Lazily initialize and manage write status based on returned AppendResult\n - Use FSUtils.getFileSize() to set final file size, consistent with other handles\n - Added tests around returned values in AppendResult\n - Added validation of the file sizes returned in write stat"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "207b04671876da7a64255459de00baa6a8d46477", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/207b04671876da7a64255459de00baa6a8d46477", "committedDate": "2020-12-26T15:19:43Z", "message": "Handle rolled-over log files and return a WriteStatus per log file written\n\n - Combined data and delete block logging into a single call\n - Lazily initialize and manage write status based on returned AppendResult\n - Use FSUtils.getFileSize() to set final file size, consistent with other handles"}, "afterCommit": {"oid": "150d1832855060664a0ed76cff9a6f0c65890bc0", "author": {"user": {"login": "vinothchandar", "name": "vinoth chandar"}}, "url": "https://github.com/apache/hudi/commit/150d1832855060664a0ed76cff9a6f0c65890bc0", "committedDate": "2020-12-29T22:29:34Z", "message": "Handle rolled-over log files and return a WriteStatus per log file written\n\n - Combined data and delete block logging into a single call\n - Lazily initialize and manage write status based on returned AppendResult\n - Use FSUtils.getFileSize() to set final file size, consistent with other handles\n - Added tests around returned values in AppendResult\n - Added validation of the file sizes returned in write stat"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwMjE3NjQ0", "url": "https://github.com/apache/hudi/pull/2300#pullrequestreview-560217644", "createdAt": "2020-12-30T22:21:39Z", "commit": {"oid": "150d1832855060664a0ed76cff9a6f0c65890bc0"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4391, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}