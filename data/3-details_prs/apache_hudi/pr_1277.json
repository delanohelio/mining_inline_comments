{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY2NTcyMzcy", "number": 1277, "title": "[HUDI-543] release notes for 0.5.1", "bodyText": "Tips\n\nThank you very much for contributing to Apache Hudi.\nPlease review https://hudi.apache.org/contributing.html before opening a pull request.\n\nWhat is the purpose of the pull request\nAdd release notes for 0.5.1\nBrief change log\n(for example:)\n\nModify releases.md\n\nVerify this pull request\nThis pull request is a trivial rework / code cleanup without any test coverage.\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.\n\n\ncc @vinothchandar @bvaradar Please review in advance though it is still WIP.", "createdAt": "2020-01-23T21:19:38Z", "url": "https://github.com/apache/hudi/pull/1277", "merged": true, "mergeCommit": {"oid": "20ede76c4c79c0804518a4fe148b8fcd48391f5c"}, "closed": true, "closedAt": "2020-01-31T07:27:58Z", "author": {"login": "leesf"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb9RDTNAH2gAyMzY2NTcyMzcyOjllOGI5ZDI1Y2ZiMWRiZGJmNGE0ZjFhNTAxMTM3MTAwMzNmZjFmZGU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb_bzs6AFqTM1MDg4NTIxNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "9e8b9d25cfb1dbdbf4a4f1a50113710033ff1fde", "author": {"user": {"login": "leesf", "name": "leesf"}}, "url": "https://github.com/apache/hudi/commit/9e8b9d25cfb1dbdbf4a4f1a50113710033ff1fde", "committedDate": "2020-01-23T21:16:18Z", "message": "[HUDI-543] release notes for 0.5.1"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NjE3MzUy", "url": "https://github.com/apache/hudi/pull/1277#pullrequestreview-347617352", "createdAt": "2020-01-23T21:24:19Z", "commit": {"oid": "9e8b9d25cfb1dbdbf4a4f1a50113710033ff1fde"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QyMToyNDoxOVrOFhNGiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QyMToyNDoxOVrOFhNGiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM2MTk5Mg==", "bodyText": "we don't support Spark 2.4, only 2.4+ - is that what this means?", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370361992", "createdAt": "2020-01-23T21:24:19Z", "author": {"login": "smarthi"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4 supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e8b9d25cfb1dbdbf4a4f1a50113710033ff1fde"}, "originalPosition": 11}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1", "author": {"user": {"login": "leesf", "name": "leesf"}}, "url": "https://github.com/apache/hudi/commit/b4a824128461d68989913f1b9c0e1268119298f1", "committedDate": "2020-01-23T21:54:30Z", "message": "address comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NzI0MTU0", "url": "https://github.com/apache/hudi/pull/1277#pullrequestreview-347724154", "createdAt": "2020-01-24T02:24:48Z", "commit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNFQwMjoyNDo0OFrOFhSfVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNFQwMjoyNzowMVrOFhSg7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ1MDI2Mg==", "bodyText": "The second kafka -> Kafka?", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370450262", "createdAt": "2020-01-24T02:24:48Z", "author": {"login": "yanghua"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle\n+ are changed according hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}, scala_version here includes 2.11 and 2.12.\n+ * Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring kafka reset offset strategies in deltastreamer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ1MDQ5OQ==", "bodyText": "Remove the first comma?", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370450499", "createdAt": "2020-01-24T02:26:10Z", "author": {"login": "yanghua"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle\n+ are changed according hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}, scala_version here includes 2.11 and 2.12.\n+ * Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring kafka reset offset strategies in deltastreamer.\n+ * Need shade Avro if implement custom payload, which is similar to hudi-hadoop-mr-bundle.\n+ * Better delete support in DeltaStreamer, would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ1MDY3MA==", "bodyText": "scala -> Scala?", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370450670", "createdAt": "2020-01-24T02:27:01Z", "author": {"login": "yanghua"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NzYxNzM0", "url": "https://github.com/apache/hudi/pull/1277#pullrequestreview-347761734", "createdAt": "2020-01-24T05:55:10Z", "commit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNFQwNTo1NToxMFrOFhUfXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNFQwNjozNzo0N1rOFhU-Iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ4MzAzOQ==", "bodyText": "Minor : Formatting changes. Can you change the layout so the version changes is more visible.\nLike\n\nDependency Version Upgrades\n** Spark from 2.1.0 to 2.4.4\n** Avro from .....\n** parquet from .... to ...\nIMPORTANT This version requires your runtime spark version to be upgraded to 2.4+", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370483039", "createdAt": "2020-01-24T05:55:10Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ4MzUxMA==", "bodyText": "Reword:\n\"are changed according hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}, scala_version here includes 2.11 and 2.12.\"\nchange to\n\"are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}. Note that scala_version here is one of  (2.11, 2.12)", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370483510", "createdAt": "2020-01-24T05:57:36Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle\n+ are changed according hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}, scala_version here includes 2.11 and 2.12.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ4MzcyMg==", "bodyText": "Can you point to the configuration name also for this ?", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370483722", "createdAt": "2020-01-24T05:58:34Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle\n+ are changed according hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}, scala_version here includes 2.11 and 2.12.\n+ * Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring kafka reset offset strategies in deltastreamer.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ1MDI2Mg=="}, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ4NjUxMw==", "bodyText": "We need to describe what needs to change in configuration. You need to list down what the user will have to change when they use the following APIs for ingesting\nYou should add a statement saying that : If you are using overridden key generator classes (configuration (\"hoodie.datasource.write.keygenerator.class\")) that comes with hudi package, please make change the fully qualified class name is changed accordingly.", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370486513", "createdAt": "2020-01-24T06:13:41Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ4NjYzMA==", "bodyText": "Include the scala version. Package name must be org.apache.spark:spark-avro_2.11:2.4.4", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370486630", "createdAt": "2020-01-24T06:14:22Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ4NzAyNg==", "bodyText": "Reword:\nDeltaStreamer CLI parameter for capturing table type is changed from --storage-type to --table-type.", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370487026", "createdAt": "2020-01-24T06:16:37Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ4NzEyNQ==", "bodyText": "Can you move this to second point ?", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370487125", "createdAt": "2020-01-24T06:17:16Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MDY1OA==", "bodyText": "We need to elaborate on this. I would move this to last point as I am not expecting many users to be impacted by this.\nPlease reword to:\n\"With 0.5.1, hudi-hadoop-mr-bundle which is used by query engines such as presto and hive includes shaded avro package to support hudi real time queries through these engines. Hudi supports pluggable logic for merging of records. Users provide their own implementation of HoodieRecordPayload. If you are using this feature, you need to relocate the avro dependencies in your custom record payload class to be consistent with internal hudi shading. You need to add the following relocation when shading the package containing the record payload implementation\n                <relocation>\n                  <pattern>org.apache.avro.</pattern>\n                  <shadedPattern>org.apache.hudi.org.apache.avro.</shadedPattern>\n                </relocation>", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370490658", "createdAt": "2020-01-24T06:36:45Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle\n+ are changed according hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}, scala_version here includes 2.11 and 2.12.\n+ * Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring kafka reset offset strategies in deltastreamer.\n+ * Need shade Avro if implement custom payload, which is similar to hudi-hadoop-mr-bundle.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MDkxNQ==", "bodyText": "You need to link the blogs that were added.", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370490915", "createdAt": "2020-01-24T06:37:47Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle\n+ are changed according hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}, scala_version here includes 2.11 and 2.12.\n+ * Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring kafka reset offset strategies in deltastreamer.\n+ * Need shade Avro if implement custom payload, which is similar to hudi-hadoop-mr-bundle.\n+ * Better delete support in DeltaStreamer, would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Support for AWS Database Migration Service(DMS) in DeltaStreamer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "752174a0d1ab801e8491766f88f61d76ceba8549", "author": {"user": {"login": "leesf", "name": "leesf"}}, "url": "https://github.com/apache/hudi/commit/752174a0d1ab801e8491766f88f61d76ceba8549", "committedDate": "2020-01-24T09:19:51Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ4MzM3OTQ2", "url": "https://github.com/apache/hudi/pull/1277#pullrequestreview-348337946", "createdAt": "2020-01-25T18:12:04Z", "commit": {"oid": "752174a0d1ab801e8491766f88f61d76ceba8549"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNVQxODoxMjowNVrOFhw1Tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNVQxODoxNjoxMlrOFhw2NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk0NzQwNg==", "bodyText": "Reword:\n\"please make change the fully qualified class name is changed accordingly.\"\nto\n\"please ensure the fully qualified class name is changed accordingly.\"", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370947406", "createdAt": "2020-01-25T18:12:05Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,47 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.\n+* CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+* DeltaStreamer CLI parameter for capturing table type is changed from --storage-type to --table-type. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+* Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring Kafka reset offset strategies with configuration(auto.offset.reset) in deltastreamer.\n+* When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro_2.11:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+* Key generator moved to separate package under org.apache.hudi.keygen. If you are using overridden key generator classes (configuration (\"hoodie.datasource.write.keygenerator.class\")) that comes with hudi package, please make change the fully qualified class name is changed accordingly.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "752174a0d1ab801e8491766f88f61d76ceba8549"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk0NzUzNA==", "bodyText": "Alternatively, you can append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties\nneeds to change to\nAlternatively, you can use \"repair overwrite-hoodie-props\" to append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370947534", "createdAt": "2020-01-25T18:14:09Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,47 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "752174a0d1ab801e8491766f88f61d76ceba8549"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk0NzU4Nw==", "bodyText": "This is already covered in the point above.", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370947587", "createdAt": "2020-01-25T18:15:27Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,47 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.\n+* CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+* DeltaStreamer CLI parameter for capturing table type is changed from --storage-type to --table-type. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+* Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring Kafka reset offset strategies with configuration(auto.offset.reset) in deltastreamer.\n+* When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro_2.11:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+* Key generator moved to separate package under org.apache.hudi.keygen. If you are using overridden key generator classes (configuration (\"hoodie.datasource.write.keygenerator.class\")) that comes with hudi package, please make change the fully qualified class name is changed accordingly.\n+* Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+* With 0.5.1, hudi-hadoop-mr-bundle which is used by query engines such as presto and hive includes shaded avro package to support hudi real time queries through these engines. Hudi supports pluggable logic for merging of records. Users provide their own implementation of [HoodieRecordPayload](https://github.com/apache/incubator-hudi/blob/master/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java).\n+If you are using this feature, you need to relocate the avro dependencies in your custom record payload class to be consistent with internal hudi shading. You need to add the following relocation when shading the package containing the record payload implementation.\n+\n+ ```xml\n+<relocation>\n+    <pattern>org.apache.avro.</pattern>\n+    <shadedPattern>org.apache.hudi.org.apache.avro.</shadedPattern>\n+</relocation>\n+ ```\n+\n+ * Better delete support in DeltaStreamer would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Support for AWS Database Migration Service(DMS) in DeltaStreamer\n+ * Support for DynamicBloomFilter.\n+ * Support option to overwrite payload implementation in hoodie.properties file.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "752174a0d1ab801e8491766f88f61d76ceba8549"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk0NzYzNw==", "bodyText": "We need to describe that this is turned off by default and how to turn this on.", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370947637", "createdAt": "2020-01-25T18:16:12Z", "author": {"login": "bvaradar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,47 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.\n+* CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+* DeltaStreamer CLI parameter for capturing table type is changed from --storage-type to --table-type. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+* Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring Kafka reset offset strategies with configuration(auto.offset.reset) in deltastreamer.\n+* When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro_2.11:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+* Key generator moved to separate package under org.apache.hudi.keygen. If you are using overridden key generator classes (configuration (\"hoodie.datasource.write.keygenerator.class\")) that comes with hudi package, please make change the fully qualified class name is changed accordingly.\n+* Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+* With 0.5.1, hudi-hadoop-mr-bundle which is used by query engines such as presto and hive includes shaded avro package to support hudi real time queries through these engines. Hudi supports pluggable logic for merging of records. Users provide their own implementation of [HoodieRecordPayload](https://github.com/apache/incubator-hudi/blob/master/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java).\n+If you are using this feature, you need to relocate the avro dependencies in your custom record payload class to be consistent with internal hudi shading. You need to add the following relocation when shading the package containing the record payload implementation.\n+\n+ ```xml\n+<relocation>\n+    <pattern>org.apache.avro.</pattern>\n+    <shadedPattern>org.apache.hudi.org.apache.avro.</shadedPattern>\n+</relocation>\n+ ```\n+\n+ * Better delete support in DeltaStreamer would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Support for AWS Database Migration Service(DMS) in DeltaStreamer\n+ * Support for DynamicBloomFilter.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "752174a0d1ab801e8491766f88f61d76ceba8549"}, "originalPosition": 39}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cddf57bbb20caa9adae69692969447ca0184575d", "author": {"user": {"login": "leesf", "name": "leesf"}}, "url": "https://github.com/apache/hudi/commit/cddf57bbb20caa9adae69692969447ca0184575d", "committedDate": "2020-01-26T02:50:48Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ4MzY0MjMw", "url": "https://github.com/apache/hudi/pull/1277#pullrequestreview-348364230", "createdAt": "2020-01-26T08:10:55Z", "commit": {"oid": "cddf57bbb20caa9adae69692969447ca0184575d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwODoxMDo1NlrOFhy3lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNlQwODoyMDowN1rOFhy5Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk4MDc1OQ==", "bodyText": "nit : existing hudi tables", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370980759", "createdAt": "2020-01-26T08:10:56Z", "author": {"login": "vinothchandar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,46 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cddf57bbb20caa9adae69692969447ca0184575d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk4MDgyMg==", "bodyText": "we probably need to update configurations page as well? were there other configs added in 0.5.1?  @bvaradar ?", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370980822", "createdAt": "2020-01-26T08:11:58Z", "author": {"login": "vinothchandar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,46 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can use \"repair overwrite-hoodie-props\" to append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cddf57bbb20caa9adae69692969447ca0184575d"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk4MDkyMA==", "bodyText": "add: specified file, for one-time updates to table name or even enabling the new timeline layout above. Note that few queries may temporarily fail while the overwrite happens (few milliseconds).", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370980920", "createdAt": "2020-01-26T08:15:11Z", "author": {"login": "vinothchandar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,46 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can use \"repair overwrite-hoodie-props\" to append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.\n+* CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cddf57bbb20caa9adae69692969447ca0184575d"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk4MDk3Mg==", "bodyText": "May be also call out the Kafka version change above at the top?", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370980972", "createdAt": "2020-01-26T08:16:14Z", "author": {"login": "vinothchandar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,46 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can use \"repair overwrite-hoodie-props\" to append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.\n+* CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+* DeltaStreamer CLI parameter for capturing table type is changed from --storage-type to --table-type. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+* Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring Kafka reset offset strategies with configuration(auto.offset.reset) in deltastreamer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cddf57bbb20caa9adae69692969447ca0184575d"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk4MTA2NA==", "bodyText": "lets use  (backtick)--packages org.apache.spark:spark-avro_2.11:2.4.4(backtick) , to get it rendered nicely like --packages org.apache.spark:spark-avro_2.11:2.4.4 ?", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370981064", "createdAt": "2020-01-26T08:18:02Z", "author": {"login": "vinothchandar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,46 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can use \"repair overwrite-hoodie-props\" to append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.\n+* CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+* DeltaStreamer CLI parameter for capturing table type is changed from --storage-type to --table-type. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+* Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring Kafka reset offset strategies with configuration(auto.offset.reset) in deltastreamer.\n+* When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro_2.11:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cddf57bbb20caa9adae69692969447ca0184575d"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk4MTEwOQ==", "bodyText": "change to:  in sync config to retain the old naming without the _ro suffix", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370981109", "createdAt": "2020-01-26T08:18:57Z", "author": {"login": "vinothchandar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,46 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can use \"repair overwrite-hoodie-props\" to append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.\n+* CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+* DeltaStreamer CLI parameter for capturing table type is changed from --storage-type to --table-type. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+* Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring Kafka reset offset strategies with configuration(auto.offset.reset) in deltastreamer.\n+* When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro_2.11:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+* Key generator moved to separate package under org.apache.hudi.keygen. If you are using overridden key generator classes (configuration (\"hoodie.datasource.write.keygenerator.class\")) that comes with hudi package, please ensure the fully qualified class name is changed accordingly.\n+* Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cddf57bbb20caa9adae69692969447ca0184575d"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk4MTE0Mw==", "bodyText": "meaning? moving them to the site? if so, is that work scoped?\nsorry, I would not fully understand the meaning, which site to move them to? remove DMS support in release notes? @vinothchandar", "url": "https://github.com/apache/hudi/pull/1277#discussion_r370981143", "createdAt": "2020-01-26T08:20:07Z", "author": {"login": "vinothchandar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle\n+ are changed according hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}, scala_version here includes 2.11 and 2.12.\n+ * Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring kafka reset offset strategies in deltastreamer.\n+ * Need shade Avro if implement custom payload, which is similar to hudi-hadoop-mr-bundle.\n+ * Better delete support in DeltaStreamer, would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Support for AWS Database Migration Service(DMS) in DeltaStreamer", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MDkxNQ=="}, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6592c29f889da2e2bb723d86df8118b852a90cf", "author": {"user": {"login": "leesf", "name": "leesf"}}, "url": "https://github.com/apache/hudi/commit/e6592c29f889da2e2bb723d86df8118b852a90cf", "committedDate": "2020-01-27T02:10:05Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwNjE0Nzgx", "url": "https://github.com/apache/hudi/pull/1277#pullrequestreview-350614781", "createdAt": "2020-01-30T07:06:00Z", "commit": {"oid": "e6592c29f889da2e2bb723d86df8118b852a90cf"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQwNzowNjowMFrOFjhFlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQwNzowOTowM1rOFjhIjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjc4NjU4MQ==", "bodyText": "I think the 0.8 and 0.10 refer to the underlying kafka version.. Might be good to mention once.. you can make the final call. Dont have strong opinions.\n\nDone", "url": "https://github.com/apache/hudi/pull/1277#discussion_r372786581", "createdAt": "2020-01-30T07:06:00Z", "author": {"login": "vinothchandar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,46 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](deployment_link), before enabling this feature for existing hudi table.\n+To enable the new hudi timeline layout which avoids renames, use the write config \"hoodie.timeline.layout.version=1\". Alternatively, you can use \"repair overwrite-hoodie-props\" to append the line \"hoodie.timeline.layout.version=1\" to hoodie.properties. Note that in any case, upgrade hudi readers (query engines) first with 0.5.1-incubating release before upgrading writer.\n+* CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+* DeltaStreamer CLI parameter for capturing table type is changed from --storage-type to --table-type. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+* Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring Kafka reset offset strategies with configuration(auto.offset.reset) in deltastreamer.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDk4MDk3Mg=="}, "originalCommit": {"oid": "cddf57bbb20caa9adae69692969447ca0184575d"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjc4NzM0Mg==", "bodyText": "I was trying to understand what you mean by \"refreshed\".. both the blogs are up at cwiki site already right.. can we link them here?\n\nDone @vinothchandar", "url": "https://github.com/apache/hudi/pull/1277#discussion_r372787342", "createdAt": "2020-01-30T07:09:03Z", "author": {"login": "vinothchandar"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,31 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+ * Upgrade from Spark 2.1.0 to Spark 2.4.4 and upgrade from avro 1.7.7 to avro 1.8.2 accordingly. Spark 2.4+ supports drop and please use Spark 2.4+ for Hudi 0.5.1+ above.\n+ * When using spark-shell to give a quick peek at Hudi, please provide --packages org.apache.spark:spark-avro:2.4.4, more details would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Key generator moved to separate package under org.apache.hudi.keygen.\n+ * CLI supports `repair overwrite-hoodie-props` to overwrite the table's hoodie.properties with specified file.\n+ * Hive Sync tool will register RO tables for MOR with a _ro suffix, so query with _ro suffix. You would use `--skip-ro-suffix` in sync config to control suffix.\n+ * DeltaStreamer configs changed including from `storage-type` to `table-type`. Refer to [wiki](https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture) with more latest terminologies.\n+ * Hudi now supports both scala 2.11 and scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with scala 2.12. Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle\n+ are changed according hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}, scala_version here includes 2.11 and 2.12.\n+ * Configuration Value change for Kafka Reset Offset Strategies. Enum values are changed from LARGEST to LATEST, SMALLEST to EARLIEST for configuring kafka reset offset strategies in deltastreamer.\n+ * Need shade Avro if implement custom payload, which is similar to hudi-hadoop-mr-bundle.\n+ * Better delete support in DeltaStreamer, would refer to [latest quickstart docs](https://hudi.apache.org/docs/quick-start-guide.html)\n+ * Support for AWS Database Migration Service(DMS) in DeltaStreamer", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MDkxNQ=="}, "originalCommit": {"oid": "b4a824128461d68989913f1b9c0e1268119298f1"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b1ae9fb8867d8bf889e3095301a731c9544329b1", "author": {"user": {"login": "leesf", "name": "leesf"}}, "url": "https://github.com/apache/hudi/commit/b1ae9fb8867d8bf889e3095301a731c9544329b1", "committedDate": "2020-01-30T14:34:11Z", "message": "update cWiki link"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e6f3192499fee7868366f846c6d9f5d8beb8972", "author": {"user": {"login": "leesf", "name": "leesf"}}, "url": "https://github.com/apache/hudi/commit/2e6f3192499fee7868366f846c6d9f5d8beb8972", "committedDate": "2020-01-30T14:36:02Z", "message": "fix scala version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2abe273dbc9ce8c0bdeb4fe1d9ecb579d3d1a2f9", "author": {"user": {"login": "leesf", "name": "leesf"}}, "url": "https://github.com/apache/hudi/commit/2abe273dbc9ce8c0bdeb4fe1d9ecb579d3d1a2f9", "committedDate": "2020-01-30T14:37:27Z", "message": "quick update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37b5d841ed24538d9da7f4ae268d0c61eb4cd443", "author": {"user": {"login": "leesf", "name": "leesf"}}, "url": "https://github.com/apache/hudi/commit/37b5d841ed24538d9da7f4ae268d0c61eb4cd443", "committedDate": "2020-01-30T14:45:29Z", "message": "update section link"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwODc4MTQ2", "url": "https://github.com/apache/hudi/pull/1277#pullrequestreview-350878146", "createdAt": "2020-01-30T14:47:30Z", "commit": {"oid": "37b5d841ed24538d9da7f4ae268d0c61eb4cd443"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNDo0NzozMVrOFjtkjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMFQxNDo0NzozMVrOFjtkjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk5MTExNg==", "bodyText": "I have updated the section link here(https://hudi.apache.org/docs/deployment.html#upgrading) according to the new website, it should work once the website is updated. cc @vinothchandar", "url": "https://github.com/apache/hudi/pull/1277#discussion_r372991116", "createdAt": "2020-01-30T14:47:31Z", "author": {"login": "leesf"}, "path": "docs/_pages/releases.md", "diffHunk": "@@ -6,6 +6,47 @@ toc: true\n last_modified_at: 2019-12-30T15:59:57-04:00\n ---\n \n+## [Release 0.5.1-incubating]\n+\n+### Download Information\n+ * Source Release : [Apache Hudi(incubating) 0.5.1-incubating Source Release](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz) ([asc](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.asc), [sha512](https://www.apache.org/dist/incubator/hudi/0.5.1-incubating/hudi-0.5.1-incubating.src.tgz.sha512))\n+ * Apache Hudi (incubating) jars corresponding to this release is available [here](https://repository.apache.org/#nexus-search;quick~hudi)\n+\n+### Release Highlights\n+* Dependency Version Upgrades\n+    * Upgrade from Spark 2.1.0 to Spark 2.4.4\n+    * Upgrade from Avro 1.7.7 to Avro 1.8.2\n+    * Upgrade from Parquet 1.8.1 to Parquet 1.10.1\n+    * Upgrade from Kafka 0.8.2.1 to Kafka 2.0.0 as a result of updating spark-streaming-kafka artifact from 0.8_2.11/2.12 to 0.10_2.11/2.12.\n+* **IMPORTANT** This version requires your runtime spark version to be upgraded to 2.4+.\n+* Hudi now supports both Scala 2.11 and Scala 2.12, please refer to [Build with Scala 2.12](https://github.com/apache/incubator-hudi#build-with-scala-212) to build with Scala 2.12.\n+Also, the packages hudi-spark, hudi-utilities, hudi-spark-bundle and hudi-utilities-bundle are changed correspondingly to hudi-spark_{scala_version}, hudi-spark_{scala_version}, hudi-utilities_{scala_version}, hudi-spark-bundle_{scala_version} and hudi-utilities-bundle_{scala_version}.\n+Note that scala_version here is one of (2.11, 2.12).\n+* With 0.5.1, we added functionality to stop using renames for Hudi timeline metadata operations. This feature is automatically enabled for newly created Hudi tables. For existing tables, this feature is turned off by default. Please read this [section](https://hudi.apache.org/docs/deployment.html#upgrading), before enabling this feature for existing hudi tables.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b5d841ed24538d9da7f4ae268d0c61eb4cd443"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwODg1MjE2", "url": "https://github.com/apache/hudi/pull/1277#pullrequestreview-350885216", "createdAt": "2020-01-30T14:56:04Z", "commit": {"oid": "37b5d841ed24538d9da7f4ae268d0c61eb4cd443"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4136, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}