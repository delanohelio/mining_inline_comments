{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAxMTM4MzIz", "number": 1500, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODowMjo0N1rODxFAKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxODowNzozNFrODyngAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNzg4Nzc3OnYy", "diffSide": "RIGHT", "path": "hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODowMjo0N1rOGEXgVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwMDoxMToxNVrOGFlS0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjU5Ng==", "bodyText": "rename to .user.defined.partitioner.class", "url": "https://github.com/apache/hudi/pull/1500#discussion_r407232596", "createdAt": "2020-04-12T18:02:47Z", "author": {"login": "vinothchandar"}, "path": "hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -55,6 +55,7 @@\n   private static final String DEFAULT_PARALLELISM = \"1500\";\n   private static final String INSERT_PARALLELISM = \"hoodie.insert.shuffle.parallelism\";\n   private static final String BULKINSERT_PARALLELISM = \"hoodie.bulkinsert.shuffle.parallelism\";\n+  private static final String BULKINSERT_USER_DEFINED_PARTITIONER_CLASS = \"hoodie.bulkinsert.user_defined.partitioner.class\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc3NzgyNw==", "bodyText": "Sure, I will change it.", "url": "https://github.com/apache/hudi/pull/1500#discussion_r407777827", "createdAt": "2020-04-13T23:30:51Z", "author": {"login": "kwondw"}, "path": "hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -55,6 +55,7 @@\n   private static final String DEFAULT_PARALLELISM = \"1500\";\n   private static final String INSERT_PARALLELISM = \"hoodie.insert.shuffle.parallelism\";\n   private static final String BULKINSERT_PARALLELISM = \"hoodie.bulkinsert.shuffle.parallelism\";\n+  private static final String BULKINSERT_USER_DEFINED_PARTITIONER_CLASS = \"hoodie.bulkinsert.user_defined.partitioner.class\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjU5Ng=="}, "originalCommit": null, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUwNzA4OQ==", "bodyText": "it has been updated.", "url": "https://github.com/apache/hudi/pull/1500#discussion_r408507089", "createdAt": "2020-04-15T00:11:15Z", "author": {"login": "kwondw"}, "path": "hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -55,6 +55,7 @@\n   private static final String DEFAULT_PARALLELISM = \"1500\";\n   private static final String INSERT_PARALLELISM = \"hoodie.insert.shuffle.parallelism\";\n   private static final String BULKINSERT_PARALLELISM = \"hoodie.bulkinsert.shuffle.parallelism\";\n+  private static final String BULKINSERT_USER_DEFINED_PARTITIONER_CLASS = \"hoodie.bulkinsert.user_defined.partitioner.class\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjU5Ng=="}, "originalCommit": null, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNzg4OTA4OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODowMzo1OVrOGEXg9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QyMzozMDo0NlrOGE4yCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjc1OA==", "bodyText": "theres probably a method in StringUtils that will do this check for you?", "url": "https://github.com/apache/hudi/pull/1500#discussion_r407232758", "createdAt": "2020-04-12T18:03:59Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -152,6 +154,24 @@ public static KeyGenerator createKeyGenerator(TypedProperties props) throws IOEx\n     }\n   }\n \n+  /**\n+   * Create a UserDefinedBulkInsertPartitioner class via reflection,\n+   * <br>\n+   * if the class name of UserDefinedBulkInsertPartitioner is configured through the HoodieWriteConfig.\n+   * @see HoodieWriteConfig#getUserDefinedBulkInsertPartitionerClass()\n+   */\n+  private static Option<UserDefinedBulkInsertPartitioner> createUserDefinedBulkInsertPartitioner(HoodieWriteConfig config)\n+          throws IOException {\n+    String bulkInsertPartitionerClass = config.getUserDefinedBulkInsertPartitionerClass();\n+    try {\n+      return bulkInsertPartitionerClass == null || bulkInsertPartitionerClass.isEmpty()", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc3NzgwMQ==", "bodyText": "Please let me update it.", "url": "https://github.com/apache/hudi/pull/1500#discussion_r407777801", "createdAt": "2020-04-13T23:30:46Z", "author": {"login": "kwondw"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -152,6 +154,24 @@ public static KeyGenerator createKeyGenerator(TypedProperties props) throws IOEx\n     }\n   }\n \n+  /**\n+   * Create a UserDefinedBulkInsertPartitioner class via reflection,\n+   * <br>\n+   * if the class name of UserDefinedBulkInsertPartitioner is configured through the HoodieWriteConfig.\n+   * @see HoodieWriteConfig#getUserDefinedBulkInsertPartitionerClass()\n+   */\n+  private static Option<UserDefinedBulkInsertPartitioner> createUserDefinedBulkInsertPartitioner(HoodieWriteConfig config)\n+          throws IOException {\n+    String bulkInsertPartitionerClass = config.getUserDefinedBulkInsertPartitionerClass();\n+    try {\n+      return bulkInsertPartitionerClass == null || bulkInsertPartitionerClass.isEmpty()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjc1OA=="}, "originalCommit": null, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNzg4OTU4OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODowNDoyN1rOGEXhOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMTo0OToxOFrOGG4ZgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjgyNA==", "bodyText": "throw a HoodieException?  this is not an IOException per se?", "url": "https://github.com/apache/hudi/pull/1500#discussion_r407232824", "createdAt": "2020-04-12T18:04:27Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -152,6 +154,24 @@ public static KeyGenerator createKeyGenerator(TypedProperties props) throws IOEx\n     }\n   }\n \n+  /**\n+   * Create a UserDefinedBulkInsertPartitioner class via reflection,\n+   * <br>\n+   * if the class name of UserDefinedBulkInsertPartitioner is configured through the HoodieWriteConfig.\n+   * @see HoodieWriteConfig#getUserDefinedBulkInsertPartitionerClass()\n+   */\n+  private static Option<UserDefinedBulkInsertPartitioner> createUserDefinedBulkInsertPartitioner(HoodieWriteConfig config)\n+          throws IOException {\n+    String bulkInsertPartitionerClass = config.getUserDefinedBulkInsertPartitionerClass();\n+    try {\n+      return bulkInsertPartitionerClass == null || bulkInsertPartitionerClass.isEmpty()\n+              ? Option.empty() :\n+              Option.of((UserDefinedBulkInsertPartitioner) ReflectionUtils.loadClass(bulkInsertPartitionerClass));\n+    } catch (Throwable e) {\n+      throw new IOException(\"Could not create UserDefinedBulkInsertPartitioner class \" + bulkInsertPartitionerClass, e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc3Nzc0Ng==", "bodyText": "While I was reading the code of DataSourceUtils, I had the impression that it tries to throw IOException as a configuration issue of user's while Hoodie*Exception would means as more toward some sort of Hudi internal error.\nFor example, failed to load of hoodie.datasource.write.keygenerator.class class throws as IOException from createKeyGenerator, and hoodie.datasource.write.payload.class too from createPayload, so question is when a user mis-configure as class name, should it be considered as \"hoodie\" error? or general configuration error as user mistake?\nI hope there is specific user configuration exception separately, but I wasn't sure the intention of IOException from other configurations, so I followed existing ways.\nPlease let me know if you think this should be HoodieException, I can update it.", "url": "https://github.com/apache/hudi/pull/1500#discussion_r407777746", "createdAt": "2020-04-13T23:30:38Z", "author": {"login": "kwondw"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -152,6 +154,24 @@ public static KeyGenerator createKeyGenerator(TypedProperties props) throws IOEx\n     }\n   }\n \n+  /**\n+   * Create a UserDefinedBulkInsertPartitioner class via reflection,\n+   * <br>\n+   * if the class name of UserDefinedBulkInsertPartitioner is configured through the HoodieWriteConfig.\n+   * @see HoodieWriteConfig#getUserDefinedBulkInsertPartitionerClass()\n+   */\n+  private static Option<UserDefinedBulkInsertPartitioner> createUserDefinedBulkInsertPartitioner(HoodieWriteConfig config)\n+          throws IOException {\n+    String bulkInsertPartitionerClass = config.getUserDefinedBulkInsertPartitionerClass();\n+    try {\n+      return bulkInsertPartitionerClass == null || bulkInsertPartitionerClass.isEmpty()\n+              ? Option.empty() :\n+              Option.of((UserDefinedBulkInsertPartitioner) ReflectionUtils.loadClass(bulkInsertPartitionerClass));\n+    } catch (Throwable e) {\n+      throw new IOException(\"Could not create UserDefinedBulkInsertPartitioner class \" + bulkInsertPartitionerClass, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjgyNA=="}, "originalCommit": null, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc0NzQyMQ==", "bodyText": "correct.. a cleanup of these exceptions would be a good follow up.. For now, let's try fixing in baby steps, by having this throw a generic HoodieException (both are uncaught for the user anwyay).", "url": "https://github.com/apache/hudi/pull/1500#discussion_r409747421", "createdAt": "2020-04-16T18:00:27Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -152,6 +154,24 @@ public static KeyGenerator createKeyGenerator(TypedProperties props) throws IOEx\n     }\n   }\n \n+  /**\n+   * Create a UserDefinedBulkInsertPartitioner class via reflection,\n+   * <br>\n+   * if the class name of UserDefinedBulkInsertPartitioner is configured through the HoodieWriteConfig.\n+   * @see HoodieWriteConfig#getUserDefinedBulkInsertPartitionerClass()\n+   */\n+  private static Option<UserDefinedBulkInsertPartitioner> createUserDefinedBulkInsertPartitioner(HoodieWriteConfig config)\n+          throws IOException {\n+    String bulkInsertPartitionerClass = config.getUserDefinedBulkInsertPartitionerClass();\n+    try {\n+      return bulkInsertPartitionerClass == null || bulkInsertPartitionerClass.isEmpty()\n+              ? Option.empty() :\n+              Option.of((UserDefinedBulkInsertPartitioner) ReflectionUtils.loadClass(bulkInsertPartitionerClass));\n+    } catch (Throwable e) {\n+      throw new IOException(\"Could not create UserDefinedBulkInsertPartitioner class \" + bulkInsertPartitionerClass, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjgyNA=="}, "originalCommit": null, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg2ODY3Mw==", "bodyText": "Ok, I will change it.", "url": "https://github.com/apache/hudi/pull/1500#discussion_r409868673", "createdAt": "2020-04-16T21:49:18Z", "author": {"login": "kwondw"}, "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -152,6 +154,24 @@ public static KeyGenerator createKeyGenerator(TypedProperties props) throws IOEx\n     }\n   }\n \n+  /**\n+   * Create a UserDefinedBulkInsertPartitioner class via reflection,\n+   * <br>\n+   * if the class name of UserDefinedBulkInsertPartitioner is configured through the HoodieWriteConfig.\n+   * @see HoodieWriteConfig#getUserDefinedBulkInsertPartitionerClass()\n+   */\n+  private static Option<UserDefinedBulkInsertPartitioner> createUserDefinedBulkInsertPartitioner(HoodieWriteConfig config)\n+          throws IOException {\n+    String bulkInsertPartitionerClass = config.getUserDefinedBulkInsertPartitionerClass();\n+    try {\n+      return bulkInsertPartitionerClass == null || bulkInsertPartitionerClass.isEmpty()\n+              ? Option.empty() :\n+              Option.of((UserDefinedBulkInsertPartitioner) ReflectionUtils.loadClass(bulkInsertPartitionerClass));\n+    } catch (Throwable e) {\n+      throw new IOException(\"Could not create UserDefinedBulkInsertPartitioner class \" + bulkInsertPartitionerClass, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjgyNA=="}, "originalCommit": null, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNzg5MDI4OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/test/java/DataSourceUtilsTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODowNToyM1rOGEXhlg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODowNToyM1rOGEXhlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMjkxOA==", "bodyText": "I wish our tests were all like this :). .. easy to read.. cc @xushiyan  :)", "url": "https://github.com/apache/hudi/pull/1500#discussion_r407232918", "createdAt": "2020-04-12T18:05:23Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/test/java/DataSourceUtilsTest.java", "diffHunk": "@@ -59,4 +99,47 @@ public void testAvroRecordsFieldConversion() {\n     assertEquals(\"Hudi Meetup\", DataSourceUtils.getNestedFieldValAsString(record, \"event_name\", true));\n     assertEquals(\"Hudi PMC\", DataSourceUtils.getNestedFieldValAsString(record, \"event_organizer\", true));\n   }\n+\n+  @Test\n+  public void testDoWriteOperationWithoutUserDefinedBulkInsertPartitioner() throws IOException {\n+    DataSourceUtils.doWriteOperation(hoodieWriteClient, hoodieRecords, \"test-time\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNzg5MTI1OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/test/java/org/apache/hudi/table/NoOpBulkInsertPartitioner.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODowNjo0MFrOGEXiFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMTo0OTozOFrOGG4aFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMzA0NA==", "bodyText": "anyway we can use a lambda to implement an anonymuous partitioner instance and avoid this test class", "url": "https://github.com/apache/hudi/pull/1500#discussion_r407233044", "createdAt": "2020-04-12T18:06:40Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/test/java/org/apache/hudi/table/NoOpBulkInsertPartitioner.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table;\n+\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.spark.api.java.JavaRDD;\n+\n+public class NoOpBulkInsertPartitioner<T extends HoodieRecordPayload>", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc4MDc5OQ==", "bodyText": "I can use Lambda to implement it, however to test it, the class should be able to be loaded(created) by reflection API(Class.forName(clazzName)) with its class name. I wasn't sure how classLoader can load lambda class from its class name?\nFrom my quick test, it doesn't work? do you have any suggestion?", "url": "https://github.com/apache/hudi/pull/1500#discussion_r407780799", "createdAt": "2020-04-13T23:40:11Z", "author": {"login": "kwondw"}, "path": "hudi-spark/src/test/java/org/apache/hudi/table/NoOpBulkInsertPartitioner.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table;\n+\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.spark.api.java.JavaRDD;\n+\n+public class NoOpBulkInsertPartitioner<T extends HoodieRecordPayload>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMzA0NA=="}, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1MTkwOQ==", "bodyText": "You are right.. some cases are tricky. I would just suggest to move this as an inner class for the test itself and leave it be", "url": "https://github.com/apache/hudi/pull/1500#discussion_r409751909", "createdAt": "2020-04-16T18:08:05Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/test/java/org/apache/hudi/table/NoOpBulkInsertPartitioner.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table;\n+\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.spark.api.java.JavaRDD;\n+\n+public class NoOpBulkInsertPartitioner<T extends HoodieRecordPayload>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMzA0NA=="}, "originalCommit": null, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg2ODgyMQ==", "bodyText": "Sure, I will update it.", "url": "https://github.com/apache/hudi/pull/1500#discussion_r409868821", "createdAt": "2020-04-16T21:49:38Z", "author": {"login": "kwondw"}, "path": "hudi-spark/src/test/java/org/apache/hudi/table/NoOpBulkInsertPartitioner.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table;\n+\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.spark.api.java.JavaRDD;\n+\n+public class NoOpBulkInsertPartitioner<T extends HoodieRecordPayload>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzMzA0NA=="}, "originalCommit": null, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MDM2Njk5OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/test/java/DataSourceUtilsTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQyMjozNToyMVrOGGN_Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QwMDo1NjozOVrOGG8QzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE3Mzc4Mw==", "bodyText": "@kwondw We're moving to Junit 5.. could you please switch to Junit 5 api ?  thank you.", "url": "https://github.com/apache/hudi/pull/1500#discussion_r409173783", "createdAt": "2020-04-15T22:35:21Z", "author": {"login": "xushiyan"}, "path": "hudi-spark/src/test/java/DataSourceUtilsTest.java", "diffHunk": "@@ -17,18 +17,58 @@\n  */\n \n import org.apache.hudi.DataSourceUtils;\n+import org.apache.hudi.DataSourceWriteOptions;\n+import org.apache.hudi.client.HoodieWriteClient;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.table.NoOpBulkInsertPartitioner;\n \n import org.apache.avro.Schema;\n import org.apache.avro.generic.GenericData;\n import org.apache.avro.generic.GenericRecord;\n-import org.junit.jupiter.api.Test;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE5ODUwNg==", "bodyText": "I'm using mockito, until mockito upgrade to version that support junit 5, it doesn't seem to work.\nI think same as https://github.com/apache/incubator-hudi/blob/master/hudi-common/src/test/java/org/apache/hudi/common/table/view/TestPriorityBasedFileSystemView.java#L54", "url": "https://github.com/apache/hudi/pull/1500#discussion_r409198506", "createdAt": "2020-04-15T23:48:18Z", "author": {"login": "kwondw"}, "path": "hudi-spark/src/test/java/DataSourceUtilsTest.java", "diffHunk": "@@ -17,18 +17,58 @@\n  */\n \n import org.apache.hudi.DataSourceUtils;\n+import org.apache.hudi.DataSourceWriteOptions;\n+import org.apache.hudi.client.HoodieWriteClient;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.table.NoOpBulkInsertPartitioner;\n \n import org.apache.avro.Schema;\n import org.apache.avro.generic.GenericData;\n import org.apache.avro.generic.GenericRecord;\n-import org.junit.jupiter.api.Test;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE3Mzc4Mw=="}, "originalCommit": null, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMxMzAwMA==", "bodyText": "@kwondw my bad...i should have migrated mockito together when i added the junit 5 dep.. I've opened up #1521 to migrate mockito.\n@vinothchandar @yanghua To make all ongoing PRs ready to use JUnit 5, we would hope to get  #1521 merged sooner. Thank you.", "url": "https://github.com/apache/hudi/pull/1500#discussion_r409313000", "createdAt": "2020-04-16T06:32:57Z", "author": {"login": "xushiyan"}, "path": "hudi-spark/src/test/java/DataSourceUtilsTest.java", "diffHunk": "@@ -17,18 +17,58 @@\n  */\n \n import org.apache.hudi.DataSourceUtils;\n+import org.apache.hudi.DataSourceWriteOptions;\n+import org.apache.hudi.client.HoodieWriteClient;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.table.NoOpBulkInsertPartitioner;\n \n import org.apache.avro.Schema;\n import org.apache.avro.generic.GenericData;\n import org.apache.avro.generic.GenericRecord;\n-import org.junit.jupiter.api.Test;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE3Mzc4Mw=="}, "originalCommit": null, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkzMTk4MQ==", "bodyText": "Thanks for @yanghua prompt review.. the mockito lib was upgraded. it should work for junit 5 now..", "url": "https://github.com/apache/hudi/pull/1500#discussion_r409931981", "createdAt": "2020-04-17T00:56:39Z", "author": {"login": "xushiyan"}, "path": "hudi-spark/src/test/java/DataSourceUtilsTest.java", "diffHunk": "@@ -17,18 +17,58 @@\n  */\n \n import org.apache.hudi.DataSourceUtils;\n+import org.apache.hudi.DataSourceWriteOptions;\n+import org.apache.hudi.client.HoodieWriteClient;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.table.NoOpBulkInsertPartitioner;\n \n import org.apache.avro.Schema;\n import org.apache.avro.generic.GenericData;\n import org.apache.avro.generic.GenericRecord;\n-import org.junit.jupiter.api.Test;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE3Mzc4Mw=="}, "originalCommit": null, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDAyNTYyOnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/test/java/DataSourceUtilsTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxODowNzozNFrOGGxQBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxODowNzozNFrOGGxQBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1MTU1Nw==", "bodyText": "I guess this wont work with an anonymous class ;/", "url": "https://github.com/apache/hudi/pull/1500#discussion_r409751557", "createdAt": "2020-04-16T18:07:34Z", "author": {"login": "vinothchandar"}, "path": "hudi-spark/src/test/java/DataSourceUtilsTest.java", "diffHunk": "@@ -59,4 +99,47 @@ public void testAvroRecordsFieldConversion() {\n     assertEquals(\"Hudi Meetup\", DataSourceUtils.getNestedFieldValAsString(record, \"event_name\", true));\n     assertEquals(\"Hudi PMC\", DataSourceUtils.getNestedFieldValAsString(record, \"event_organizer\", true));\n   }\n+\n+  @Test\n+  public void testDoWriteOperationWithoutUserDefinedBulkInsertPartitioner() throws IOException {\n+    DataSourceUtils.doWriteOperation(hoodieWriteClient, hoodieRecords, \"test-time\",\n+            DataSourceWriteOptions.BULK_INSERT_OPERATION_OPT_VAL());\n+\n+    verify(hoodieWriteClient, times(1)).bulkInsert(any(hoodieRecords.getClass()), anyString(),\n+            optionCaptor.capture());\n+\n+    assertThat(optionCaptor.getValue(), is(equalTo(Option.empty())));\n+  }\n+\n+  @Test (expected = IOException.class)\n+  public void testDoWriteOperationWithNonExistUserDefinedBulkInsertPartitioner() throws IOException {\n+    verifyAndSetHoodieWriteClient(\"NonExistClassName\");\n+\n+    DataSourceUtils.doWriteOperation(hoodieWriteClient, hoodieRecords, \"test-time\",\n+            DataSourceWriteOptions.BULK_INSERT_OPERATION_OPT_VAL());\n+  }\n+\n+  @Test\n+  public void testDoWriteOperationWithUserDefinedBulkInsertPartitioner() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 86}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4761, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}