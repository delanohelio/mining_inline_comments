{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE1ODAzNDkz", "number": 1612, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTo0OToxNlrOD7TFWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTo1MDoxN1rOD7THIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzNTA1MjQzOnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTo0OToxNlrOGTiVMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDo1MzozMFrOGUhXog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEzODYwOQ==", "bodyText": "Original Avro Schema (without hudi fields) is now getting written in commit metadata. Can we try reading it first and fallback to reading from parquet if we cannot find schema in commit metadata ?", "url": "https://github.com/apache/hudi/pull/1612#discussion_r423138609", "createdAt": "2020-05-11T15:49:16Z", "author": {"login": "bvaradar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -65,15 +65,20 @@ class IncrementalRelation(val sqlContext: SQLContext,\n       s\"option ${DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY}\")\n   }\n \n-  val lastInstant = commitTimeline.lastInstant().get()\n+  private val lastInstant = commitTimeline.getReverseOrderedInstants.iterator().find(instant => {\n+    // Skip empty instants\n+    HoodieCommitMetadata\n+      .fromBytes(commitTimeline.getInstantDetails(instant).get(), classOf[HoodieCommitMetadata])\n+      .fetchTotalRecordsWritten() > 0\n+  }).getOrElse(throw new HoodieException(\"Couldn't find any non empty instant in the hoodie commit timeline.\"))\n \n-  val commitsToReturn = commitTimeline.findInstantsInRange(\n+  private val commitsToReturn = commitTimeline.findInstantsInRange(\n     optParams(DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY),\n     optParams.getOrElse(DataSourceReadOptions.END_INSTANTTIME_OPT_KEY, lastInstant.getTimestamp))\n     .getInstants.iterator().toList\n \n   // use schema from a file produced in the latest instant\n-  val latestSchema = {\n+  private val latestSchema = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE3MTQyNg==", "bodyText": "Done, fallback to reading from parquet was already handled by TableSchemaResolver", "url": "https://github.com/apache/hudi/pull/1612#discussion_r424171426", "createdAt": "2020-05-13T04:53:30Z", "author": {"login": "garyli1019"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -65,15 +65,20 @@ class IncrementalRelation(val sqlContext: SQLContext,\n       s\"option ${DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY}\")\n   }\n \n-  val lastInstant = commitTimeline.lastInstant().get()\n+  private val lastInstant = commitTimeline.getReverseOrderedInstants.iterator().find(instant => {\n+    // Skip empty instants\n+    HoodieCommitMetadata\n+      .fromBytes(commitTimeline.getInstantDetails(instant).get(), classOf[HoodieCommitMetadata])\n+      .fetchTotalRecordsWritten() > 0\n+  }).getOrElse(throw new HoodieException(\"Couldn't find any non empty instant in the hoodie commit timeline.\"))\n \n-  val commitsToReturn = commitTimeline.findInstantsInRange(\n+  private val commitsToReturn = commitTimeline.findInstantsInRange(\n     optParams(DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY),\n     optParams.getOrElse(DataSourceReadOptions.END_INSTANTTIME_OPT_KEY, lastInstant.getTimestamp))\n     .getInstants.iterator().toList\n \n   // use schema from a file produced in the latest instant\n-  val latestSchema = {\n+  private val latestSchema = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEzODYwOQ=="}, "originalCommit": null, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYzNTA1Njk3OnYy", "diffSide": "RIGHT", "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTo1MDoxN1rOGTiYCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QwNDo1NDo0M1rOGUhYuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEzOTMzNw==", "bodyText": "Can we return an empty relation instead of throwing an error here.", "url": "https://github.com/apache/hudi/pull/1612#discussion_r423139337", "createdAt": "2020-05-11T15:50:17Z", "author": {"login": "bvaradar"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -65,15 +65,20 @@ class IncrementalRelation(val sqlContext: SQLContext,\n       s\"option ${DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY}\")\n   }\n \n-  val lastInstant = commitTimeline.lastInstant().get()\n+  private val lastInstant = commitTimeline.getReverseOrderedInstants.iterator().find(instant => {\n+    // Skip empty instants\n+    HoodieCommitMetadata\n+      .fromBytes(commitTimeline.getInstantDetails(instant).get(), classOf[HoodieCommitMetadata])\n+      .fetchTotalRecordsWritten() > 0\n+  }).getOrElse(throw new HoodieException(\"Couldn't find any non empty instant in the hoodie commit timeline.\"))", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE3MTcwNA==", "bodyText": "No longer need to handle empty commit here since schema was handled by TableSchemaResolver", "url": "https://github.com/apache/hudi/pull/1612#discussion_r424171704", "createdAt": "2020-05-13T04:54:43Z", "author": {"login": "garyli1019"}, "path": "hudi-spark/src/main/scala/org/apache/hudi/IncrementalRelation.scala", "diffHunk": "@@ -65,15 +65,20 @@ class IncrementalRelation(val sqlContext: SQLContext,\n       s\"option ${DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY}\")\n   }\n \n-  val lastInstant = commitTimeline.lastInstant().get()\n+  private val lastInstant = commitTimeline.getReverseOrderedInstants.iterator().find(instant => {\n+    // Skip empty instants\n+    HoodieCommitMetadata\n+      .fromBytes(commitTimeline.getInstantDetails(instant).get(), classOf[HoodieCommitMetadata])\n+      .fetchTotalRecordsWritten() > 0\n+  }).getOrElse(throw new HoodieException(\"Couldn't find any non empty instant in the hoodie commit timeline.\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEzOTMzNw=="}, "originalCommit": null, "originalPosition": 30}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4640, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}