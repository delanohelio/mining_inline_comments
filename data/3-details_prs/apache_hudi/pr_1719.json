{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxNTU2ODY1", "number": 1719, "title": "[HUDI-1006]deltastreamer use kafkaSource with offset reset strategy:latest can't consume data", "bodyText": "What is the purpose of the pull request\nThis pull request fix deltastreamer use kafkasource (such as JsonKafkaSource / AvroKafkaSource)  with offset reset strategy:latest can't consume data because the checkpoint string store in .commit file .commit file will always be an empty string.\nFor example, i want to inject data from kafka into a new hudi table.\nFrom org.apache.hudi.utilities.deltastreamer.DeltaSync#readFromSource, the first time consume resumeCheckpointStr will be Option.empty(), and the lastCkptStr used in org.apache.hudi.utilities.sources.Source#fetchNewData will also be Option.empty().\nFetch new data code like this:\nprotected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n    OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n    long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n    if (totalNewMsgs <= 0) {\n      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n    } else {\n      LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n    }\n    JavaRDD<GenericRecord> newDataRDD = toRDD(offsetRanges);\n    return new InputBatch<>(Option.of(newDataRDD), KafkaOffsetGen.CheckpointUtils.offsetsToStr(offsetRanges));\n  }\nWhen get next offset ranges in org.apache.hudi.utilities.sources.helpers.KafkaOffsetGen#getNextOffsetRanges code like this:\n// Determine the offset ranges to read from\nif (lastCheckpointStr.isPresent() && !lastCheckpointStr.get().isEmpty()) {\n    fromOffsets = checkupValidOffsets(consumer, lastCheckpointStr, topicPartitions);\n} else {\n    KafkaResetOffsetStrategies autoResetValue = KafkaResetOffsetStrategies\n                .valueOf(props.getString(\"auto.offset.reset\", Config.DEFAULT_AUTO_RESET_OFFSET.toString()).toUpperCase());\n    switch (autoResetValue) {\n        case EARLIEST:\n            fromOffsets = consumer.beginningOffsets(topicPartitions);\n            break;\n        case LATEST:\n            fromOffsets = consumer.endOffsets(topicPartitions);\n            break;\n        default:\n             throw new HoodieNotSupportedException(\"Auto reset value must be one of 'earliest' or 'latest' \");\n    }\n}\n// Obtain the latest offsets.\ntoOffsets = consumer.endOffsets(topicPartitions);\nBecause lastCkptStr is Option.empty(), fromOffsets and toOffsets all will be consumer's endOffsets, totalNewMsgs size is 0 and first time consume checkpoint string return value is an empty string.\nNext consume operation will get this empty string checkpoint, in KafkaOffsetGen offset range will always be handled to reset as latest and return another empty string checkpoint.\nBy watching, checkpoint will be normal only if kafka latest offset change between fromOffsets and toOffsets get end offset value.\nBrief change log\n\nModify checkpoint string return value of JsonKafkaSource & AvroKafkaSource method fetchNewData(), when offsetRanges total message count <= 0.\n\nVerify this pull request\nThis pull request is already covered by existing tests, such as :\nRun TestKafkaSource\nCommitter checklist\n\n\n Has a corresponding JIRA in PR title & commit\n\n\n Commit message is descriptive of the change\n\n\n CI is green\n\n\n Necessary doc changes done or have another open PR\n\n\n For large changes, please consider breaking it into sub-tasks under an umbrella JIRA.", "createdAt": "2020-06-09T06:02:26Z", "url": "https://github.com/apache/hudi/pull/1719", "merged": true, "mergeCommit": {"oid": "ede6c9bda4dba8a9981252bd05f0725ff1024b95"}, "closed": true, "closedAt": "2020-06-14T10:01:45Z", "author": {"login": "Litianye"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcpdG1EgH2gAyNDMxNTU2ODY1OjU2NWY5YjRlODJmYTJlNjliYWFiMWI0ZTkyZGJjMGY5YzFjOTdhZDg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcrJGreAFqTQzMDIwNDU4OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8", "author": {"user": {"login": "Litianye", "name": null}}, "url": "https://github.com/apache/hudi/commit/565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8", "committedDate": "2020-06-09T04:11:41Z", "message": "[HUDI-1006]deltastreamer use kafkaSource with offset reset strategy: latest can't consume data"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3Njg4Njkz", "url": "https://github.com/apache/hudi/pull/1719#pullrequestreview-427688693", "createdAt": "2020-06-10T03:38:36Z", "commit": {"oid": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMzozODozNlrOGhjvUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMzo1OTozMlrOGhkBnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg0MTc0NA==", "bodyText": "hmmm interesting... so right now if we use LATEST as reset key, then we will fall into a dead loop unless we are lucky enough to have message fall in between two consumer.endOffsets(topicPartitions) call.", "url": "https://github.com/apache/hudi/pull/1719#discussion_r437841744", "createdAt": "2020-06-10T03:38:36Z", "author": {"login": "garyli1019"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java", "diffHunk": "@@ -57,10 +57,10 @@ public AvroKafkaSource(TypedProperties props, JavaSparkContext sparkContext, Spa\n   protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n     OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n     long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n+    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n     if (totalNewMsgs <= 0) {\n-      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg0NjQyOQ==", "bodyText": "could lastCheckpointStr be \"\" here?\nAlso, can we add a test for this case?\nhttps://github.com/apache/hudi/blob/master/hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestKafkaSource.java#L107", "url": "https://github.com/apache/hudi/pull/1719#discussion_r437846429", "createdAt": "2020-06-10T03:59:32Z", "author": {"login": "garyli1019"}, "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java", "diffHunk": "@@ -57,10 +57,10 @@ public AvroKafkaSource(TypedProperties props, JavaSparkContext sparkContext, Spa\n   protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n     OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n     long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n+    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n     if (totalNewMsgs <= 0) {\n-      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n-    } else {\n-      LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n+      return new InputBatch<>(Option.empty(),\n+              lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : CheckpointUtils.offsetsToStr(offsetRanges));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8"}, "originalPosition": 10}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f344b8e74eda103b1869a9d3141df286974622f", "author": {"user": {"login": "Litianye", "name": null}}, "url": "https://github.com/apache/hudi/commit/5f344b8e74eda103b1869a9d3141df286974622f", "committedDate": "2020-06-10T11:28:57Z", "message": "for case when last checkpoint str is an empty string & add test case for offset reset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6853b8d8c1e02435bdfc0049b22cbe9539090bb9", "author": {"user": {"login": "Litianye", "name": null}}, "url": "https://github.com/apache/hudi/commit/6853b8d8c1e02435bdfc0049b22cbe9539090bb9", "committedDate": "2020-06-10T13:55:52Z", "message": "change TestKafkaSource local variable name for CI build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "690d9937d6041895795099959727b08bd5d52afe", "author": {"user": {"login": "Litianye", "name": null}}, "url": "https://github.com/apache/hudi/commit/690d9937d6041895795099959727b08bd5d52afe", "committedDate": "2020-06-11T07:49:43Z", "message": "handle empty string checkpoint in DeltaSync"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e26a478118c510ecb0fd148eb67281f20f8119d", "author": {"user": {"login": "Litianye", "name": null}}, "url": "https://github.com/apache/hudi/commit/4e26a478118c510ecb0fd148eb67281f20f8119d", "committedDate": "2020-06-11T08:03:27Z", "message": "handle empty string checkpoint in DeltaSync"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46287522f5d0c43dea2fcab321145330c04f6f78", "author": {"user": {"login": "Litianye", "name": null}}, "url": "https://github.com/apache/hudi/commit/46287522f5d0c43dea2fcab321145330c04f6f78", "committedDate": "2020-06-11T08:49:39Z", "message": "delete whitespace for CI build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e04512121ce33c8ad3e578657b1dd4533a64735e", "author": {"user": {"login": "Litianye", "name": null}}, "url": "https://github.com/apache/hudi/commit/e04512121ce33c8ad3e578657b1dd4533a64735e", "committedDate": "2020-06-12T07:24:22Z", "message": "remove checkpoint length check in kafkaOffsetGen"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2cc2375601dc92139cbfd58492600df44bb90157", "author": {"user": {"login": "Litianye", "name": null}}, "url": "https://github.com/apache/hudi/commit/2cc2375601dc92139cbfd58492600df44bb90157", "committedDate": "2020-06-12T07:34:16Z", "message": "revert changes in DeltaSync"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwMDM0NzE5", "url": "https://github.com/apache/hudi/pull/1719#pullrequestreview-430034719", "createdAt": "2020-06-12T20:59:43Z", "commit": {"oid": "2cc2375601dc92139cbfd58492600df44bb90157"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwMTI1Njg2", "url": "https://github.com/apache/hudi/pull/1719#pullrequestreview-430125686", "createdAt": "2020-06-13T09:03:52Z", "commit": {"oid": "2cc2375601dc92139cbfd58492600df44bb90157"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwOTowMzo1MlrOGjWlBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwOTowMzo1MlrOGjWlBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcyMzI3MQ==", "bodyText": "we would merge the method with createPropsForJsonSource to reuse code.", "url": "https://github.com/apache/hudi/pull/1719#discussion_r439723271", "createdAt": "2020-06-13T09:03:52Z", "author": {"login": "leesf"}, "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestKafkaSource.java", "diffHunk": "@@ -93,6 +93,18 @@ private TypedProperties createPropsForJsonSource(Long maxEventsToReadFromKafkaSo\n     return props;\n   }\n \n+  private TypedProperties createLatestPropsForJsonSource(Long maxEventsToReadFromKafkaSource) {\n+    TypedProperties props = new TypedProperties();\n+    props.setProperty(\"hoodie.deltastreamer.source.kafka.topic\", TEST_TOPIC_NAME);\n+    props.setProperty(\"bootstrap.servers\", testUtils.brokerAddress());\n+    props.setProperty(\"auto.offset.reset\", \"latest\");\n+    props.setProperty(\"hoodie.deltastreamer.kafka.source.maxEvents\",\n+            maxEventsToReadFromKafkaSource != null ? String.valueOf(maxEventsToReadFromKafkaSource) :\n+                    String.valueOf(Config.maxEventsFromKafkaSource));\n+    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, UUID.randomUUID().toString());\n+    return props;\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2cc2375601dc92139cbfd58492600df44bb90157"}, "originalPosition": 15}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da0e2cb38562e00e95dfb3a82e63c08d9e8a34e6", "author": {"user": {"login": "Litianye", "name": null}}, "url": "https://github.com/apache/hudi/commit/da0e2cb38562e00e95dfb3a82e63c08d9e8a34e6", "committedDate": "2020-06-14T08:03:44Z", "message": "merge method reuse code"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwMjA0NTg4", "url": "https://github.com/apache/hudi/pull/1719#pullrequestreview-430204588", "createdAt": "2020-06-14T10:01:17Z", "commit": {"oid": "da0e2cb38562e00e95dfb3a82e63c08d9e8a34e6"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4963, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}