{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg2ODg5ODU0", "number": 751, "reviewThreads": {"totalCount": 28, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNjowNDozMlrOEjqeVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjo1MTo0NFrOEoqA4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1ODMxNTA5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNjowNDozMlrOHSJHOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNjowNDozMlrOHSJHOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODc4NTcyMw==", "bodyText": "nit: \"Any further sends by this task will not work\"\nAlso, do you think we should add a small sentence about how this affects existing tasks that share the same producer? i.e. their inflight records will attempt to flushed, but if it doesn't complete, they'll see send failures, but this is okay since they'll be able to create a new producer on the next send?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r488785723", "createdAt": "2020-09-15T16:04:32Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,7 +182,12 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    boolean taskPresent = _tasks.remove(task);\n+    // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+    // there are no in-flight sends. Any further send will not work.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1ODM4ODE3OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNjoyMToyMVrOHSJ0VA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNToxOTo1OVrOHX1U7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODc5NzI2OA==", "bodyText": "Does adding a comment here make sense, that if the task is not assigned, production should be disallowed?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r488797268", "createdAt": "2020-09-15T16:21:21Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -166,6 +166,11 @@ private void populateDefaultProducerConfigs() {\n \n   private Optional<Producer<K, V>> maybeGetKafkaProducer(DatastreamTask task) {\n     Producer<K, V> producer = _kafkaProducer;\n+    if (!_tasks.contains(task)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc1MzAwNQ==", "bodyText": "I feel the code is self explainatory.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494753005", "createdAt": "2020-09-25T05:19:59Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -166,6 +166,11 @@ private void populateDefaultProducerConfigs() {\n \n   private Optional<Producer<K, V>> maybeGetKafkaProducer(DatastreamTask task) {\n     Producer<K, V> producer = _kafkaProducer;\n+    if (!_tasks.contains(task)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODc5NzI2OA=="}, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1ODQwNDIzOnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNjoyNTowOFrOHSJ-UQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNToyMzo1N1rOHX1ZAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODc5OTgyNQ==", "bodyText": "One thing to note here is that since shutdownProducer() requires obtaining the lock, this operation can get stuck waiting on this lock. Operations such as flush can take a while (up to 15 minutes for BMM with the current flush timeout). Once concern might be that unassignTask() is called from the onAssignmentChange() threads, right? And have a limited time of 30-60 seconds within which it needs to complete?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r488799825", "createdAt": "2020-09-15T16:25:08Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,7 +182,12 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    boolean taskPresent = _tasks.remove(task);\n+    // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+    // there are no in-flight sends. Any further send will not work.\n+    if (taskPresent) {\n+      shutdownProducer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc1NDA0OQ==", "bodyText": "handled it.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494754049", "createdAt": "2020-09-25T05:23:57Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,7 +182,12 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    boolean taskPresent = _tasks.remove(task);\n+    // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+    // there are no in-flight sends. Any further send will not work.\n+    if (taskPresent) {\n+      shutdownProducer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODc5OTgyNQ=="}, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1ODQyMDYzOnYy", "diffSide": "RIGHT", "path": "datastream-server/src/main/java/com/linkedin/datastream/server/DatastreamTaskImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNjoyOToyNFrOHSKI6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNjoyOToyNFrOHSKI6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgwMjUzOQ==", "bodyText": "Can you add  a comment here or somewhere in this file that if a new field is added along with a setter, or any function that modifies the values, the setter/function must call computeHashCode()?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r488802539", "createdAt": "2020-09-15T16:29:24Z", "author": {"login": "somandal"}, "path": "datastream-server/src/main/java/com/linkedin/datastream/server/DatastreamTaskImpl.java", "diffHunk": "@@ -89,6 +89,7 @@\n   private DatastreamEventProducer _eventProducer;\n   private String _transportProviderName;\n   private SerDeSet _destinationSerDes = new SerDeSet(null, null, null);\n+  private int _hashCode;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MTMxMDc2OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMjo1NzozN1rOHXDuGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMjo1NzozN1rOHXDuGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0MDI1MQ==", "bodyText": "nit: _waitOnNoProducerClose -> _waitOnProducerClose", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r493940251", "createdAt": "2020-09-23T22:57:37Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -111,11 +114,13 @@\n   private final String _metricsNamesPrefix;\n \n   // A lock used to synchronize access to operations performed on the _kafkaProducer object\n-  private final Object _producerLock = new Object();\n+  private final Lock _producerLock = new ReentrantLock();\n+  private final Condition _waitOnNoProducerClose = _producerLock.newCondition();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MTMxMjkwOnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMjo1ODo0MFrOHXDvZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMjo1ODo0MFrOHXDvZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0MDU4MQ==", "bodyText": "You should move the \"closeInProgress\" here and mention that it also needs to be accessed from under the same lock.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r493940581", "createdAt": "2020-09-23T22:58:40Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -111,11 +114,13 @@\n   private final String _metricsNamesPrefix;\n \n   // A lock used to synchronize access to operations performed on the _kafkaProducer object", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MTMxNDc5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMjo1OTozM1rOHXDwfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMjo1OTozM1rOHXDwfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0MDg2MA==", "bodyText": "nit: closeInProgress -> _closeInProgress\nAlso move this to where the lock is declared, and make it clear that the lock protects updates to this too.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r493940860", "createdAt": "2020-09-23T22:59:33Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -111,11 +114,13 @@\n   private final String _metricsNamesPrefix;\n \n   // A lock used to synchronize access to operations performed on the _kafkaProducer object\n-  private final Object _producerLock = new Object();\n+  private final Lock _producerLock = new ReentrantLock();\n+  private final Condition _waitOnNoProducerClose = _producerLock.newCondition();\n \n   // An executor to spawn threads to close the producer.\n   private final ExecutorService _producerCloseExecutorService = Executors.newSingleThreadExecutor(\n       new ThreadFactoryBuilder().setNameFormat(\"KafkaProducerWrapperClose-%d\").build());\n+  private boolean closeInProgress = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MTMxNzYyOnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMzowMDo1MVrOHXDyGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMzowMDo1MVrOHXDyGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0MTI3Mw==", "bodyText": "nit: unassignTask  -> unassignTasks (since it can unassign multiple tasks)", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r493941273", "createdAt": "2020-09-23T23:00:51Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,29 +191,54 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    unassignTask(Collections.singletonList(task));\n+  }\n+\n+  void unassignTask(List<DatastreamTask> taskList) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTY5NTY0OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMTozODoxNVrOHXtjQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMTozODoxNVrOHXtjQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYyNTYwMg==", "bodyText": "nit:  there are no in-flight sends -> there are no pending in-flight sends\nnit: Any further send will not work -> Further sends will fail until the producer is re-initialized by a valid task", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494625602", "createdAt": "2020-09-24T21:38:15Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,29 +191,54 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    unassignTask(Collections.singletonList(task));\n+  }\n+\n+  void unassignTask(List<DatastreamTask> taskList) {\n+    boolean taskPresent = _tasks.removeAll(taskList);\n+    try {\n+      _producerLock.lock();\n+\n+      // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+      // there are no in-flight sends. Any further send will not work.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTczOTk0OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMTo1NDozNlrOHXt9nQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMTo1NDozNlrOHXt9nQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYzMjM0OQ==", "bodyText": "Let's add comments here explaining why it's okay to only shutdown the producer when the task list is empty (i.e. we are on shutdown path)? It becomes confusing since in unassignTask(), we need to close the producer ever time we remove a task.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494632349", "createdAt": "2020-09-24T21:54:36Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,92 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      if (_kafkaProducer == null || closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n+\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          try {\n+            _producerLock.lock();\n+            closeInProgress = false;\n+            _waitOnNoProducerClose.signalAll();\n+          } finally {\n+            _producerLock.unlock();\n+          }\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n-      try {\n-        if (_kafkaProducer != null) {\n-          _kafkaProducer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n-        }\n-      } catch (InterruptException | TimeoutException e) {\n-        // The KafkaProducer object should not be reused on an interrupted flush\n-        _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", _kafkaProducer);\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {\n+      if (producer != null) {\n+          producer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+      }\n+    } catch (InterruptException | TimeoutException e) {\n+      // The KafkaProducer object should not be reused on an interrupted flush\n+      if (producer == _kafkaProducer) {\n+        _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", producer);\n         shutdownProducer();\n-        throw e;\n+      } else {\n+        _log.warn(\"Kafka producer flush interrupted/timed out, producer {} already closed.\", producer);\n       }\n+      throw e;\n     }\n   }\n \n   void close(DatastreamTask task) {\n-    synchronized (_producerLock) {\n-      _tasks.remove(task);\n-      if (_kafkaProducer != null && _tasks.isEmpty()) {\n-        shutdownProducer();\n-      }\n+    if (_tasks.remove(task) && _tasks.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 259}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTc1NDI2OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMTo1OTo0MlrOHXuGGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMTo1OTo0MlrOHXuGGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYzNDUyMw==", "bodyText": "So we already check for this before we call initializeProducer, is this really needed here too? If yes, can you add comments explaining why?\nI feel a little bit like assignTask/unassignTask aren't synchronizing access to _tasks as such, which means the state of _tasks can change at any point in time anyways. So I don't see much point in checking for this twice. Do correct me if I missed something though.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494634523", "createdAt": "2020-09-24T21:59:42Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,29 +191,54 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    unassignTask(Collections.singletonList(task));\n+  }\n+\n+  void unassignTask(List<DatastreamTask> taskList) {\n+    boolean taskPresent = _tasks.removeAll(taskList);\n+    try {\n+      _producerLock.lock();\n+\n+      // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+      // there are no in-flight sends. Any further send will not work.\n+      if (taskPresent && _kafkaProducer != null && !closeInProgress) {\n+        shutdownProducer();\n+      }\n+    } finally {\n+      _producerLock.unlock();\n+    }\n   }\n \n   int getTasksSize() {\n     return _tasks.size();\n   }\n \n-  private Producer<K, V> initializeProducer(DatastreamTask task) {\n+  private Producer<K, V> initializeProducer(DatastreamTask task) throws InterruptedException {\n+    if (!_tasks.contains(task)) {\n+      _log.warn(\"Task {} has been unassigned for producer, abort the send\", task);\n+      return null;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTc2OTA4OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjowNToyMlrOHXuPCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjowNToyMlrOHXuPCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYzNjgwOA==", "bodyText": "nit: Close not completed. Retry -> Close did not complete in {} ms, retrying {}th time\n(or something along those lines - maybe skip the number of retries)\nI somehow think we should make this an info/warn. Will be hard to debug if for some reason we get stuck in this loop.\nAlso, what if close is stuck indefinitely? Looks like this thread will just be stuck waiting forever in that case. We should definitely at least log periodically if not every time we finish an await().\nAlso a good idea to add  some comments here calling out that this can affect other tasks that use the same producer and cause some latency, but it is necessary for correctness. Don't want history to repeat itself.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494636808", "createdAt": "2020-09-24T22:05:22Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,29 +191,54 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    unassignTask(Collections.singletonList(task));\n+  }\n+\n+  void unassignTask(List<DatastreamTask> taskList) {\n+    boolean taskPresent = _tasks.removeAll(taskList);\n+    try {\n+      _producerLock.lock();\n+\n+      // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+      // there are no in-flight sends. Any further send will not work.\n+      if (taskPresent && _kafkaProducer != null && !closeInProgress) {\n+        shutdownProducer();\n+      }\n+    } finally {\n+      _producerLock.unlock();\n+    }\n   }\n \n   int getTasksSize() {\n     return _tasks.size();\n   }\n \n-  private Producer<K, V> initializeProducer(DatastreamTask task) {\n+  private Producer<K, V> initializeProducer(DatastreamTask task) throws InterruptedException {\n+    if (!_tasks.contains(task)) {\n+      _log.warn(\"Task {} has been unassigned for producer, abort the send\", task);\n+      return null;\n+    }\n     // Must be protected by a lock to avoid creating duplicate producers when multiple concurrent\n     // sends are in-flight and _kafkaProducer has been set to null as a result of previous\n     // producer exception.\n-    synchronized (_producerLock) {\n-      if (!_tasks.contains(task)) {\n-        _log.warn(\"Task {} has been unassigned for producer, abort the send\", task);\n-        return null;\n-      } else {\n-        if (_kafkaProducer == null) {\n-          _rateLimiter.acquire();\n-          _kafkaProducer = createKafkaProducer();\n-          NUM_PRODUCERS.incrementAndGet();\n+    try {\n+      _producerLock.lock();\n+\n+      while (closeInProgress) {\n+        boolean closeCompleted = _waitOnNoProducerClose.await(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+        if (!closeCompleted) {\n+          _log.debug(\"Close not completed. Retry\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTgzNDYxOnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjozMjo0MlrOHXu1sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNToyNDo0OFrOHX1aBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0NjcwNw==", "bodyText": "Shall we move this block into a separate function? Looks very long here and can be a little confusing to read (first I  thought you're releasing the lock in two different finally blocks, and then realized that the first one is a separate thread)", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494646707", "createdAt": "2020-09-24T22:32:42Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,92 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      if (_kafkaProducer == null || closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n+\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          try {\n+            _producerLock.lock();\n+            closeInProgress = false;\n+            _waitOnNoProducerClose.signalAll();\n+          } finally {\n+            _producerLock.unlock();\n+          }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc1NDMxMA==", "bodyText": "I moved the finally block in another method to improve readability.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494754310", "createdAt": "2020-09-25T05:24:48Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,92 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      if (_kafkaProducer == null || closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n+\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          try {\n+            _producerLock.lock();\n+            closeInProgress = false;\n+            _waitOnNoProducerClose.signalAll();\n+          } finally {\n+            _producerLock.unlock();\n+          }\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0NjcwNw=="}, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 196}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTg0MTc3OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjozNTozM1rOHXu5uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNTozNzo0NlrOHX1ntw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0NzczOQ==", "bodyText": "we're checking _kafkaProducer outside the lock. _kafkaProducer may change by the time shutdownProducer() is called. Can we instead have a shutdownProducer(producer) that does this comparison under the lock and calls shutdownProducer(), or something along those lines?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494647739", "createdAt": "2020-09-24T22:35:33Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,92 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      if (_kafkaProducer == null || closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n+\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          try {\n+            _producerLock.lock();\n+            closeInProgress = false;\n+            _waitOnNoProducerClose.signalAll();\n+          } finally {\n+            _producerLock.unlock();\n+          }\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n-      try {\n-        if (_kafkaProducer != null) {\n-          _kafkaProducer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n-        }\n-      } catch (InterruptException | TimeoutException e) {\n-        // The KafkaProducer object should not be reused on an interrupted flush\n-        _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", _kafkaProducer);\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {\n+      if (producer != null) {\n+          producer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+      }\n+    } catch (InterruptException | TimeoutException e) {\n+      // The KafkaProducer object should not be reused on an interrupted flush\n+      if (producer == _kafkaProducer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 242}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc1MzY3OQ==", "bodyText": "The reason to skip here is to avoid closing the other producer. I initially thought of passing producer to the method, but that will imply making the producer final to be passed from send callback and I wanted to avoid it from garbage collection point of view and producer is a heavyweight object in general.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494753679", "createdAt": "2020-09-25T05:22:23Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,92 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      if (_kafkaProducer == null || closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n+\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          try {\n+            _producerLock.lock();\n+            closeInProgress = false;\n+            _waitOnNoProducerClose.signalAll();\n+          } finally {\n+            _producerLock.unlock();\n+          }\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n-      try {\n-        if (_kafkaProducer != null) {\n-          _kafkaProducer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n-        }\n-      } catch (InterruptException | TimeoutException e) {\n-        // The KafkaProducer object should not be reused on an interrupted flush\n-        _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", _kafkaProducer);\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {\n+      if (producer != null) {\n+          producer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+      }\n+    } catch (InterruptException | TimeoutException e) {\n+      // The KafkaProducer object should not be reused on an interrupted flush\n+      if (producer == _kafkaProducer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0NzczOQ=="}, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 242}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc1NzgxNQ==", "bodyText": "I wasn't implying always passing the producer object to shutdownProducer(). I was thinking that you can keep shutdownProducer() as is, but add:\nvoid shutdownProducer(KafkaProducer producer) { _producerLock.lock() try { if (producer == _kafkaProducer) { shutdownProducer() } } finally { _producerLock.unlock() } }\nThis new method would be called from flush() only. The send callback path will just call the existing shutdownProducer() directly, since this method acquires the lock anyways.\nI'd like to avoid access to _kafkaProducer outside the lock as much as possible. Makes the code much cleaner and easier to reason about. Otherwise one will always need to remember that another code path can potentially have changed the  _kafkaProducer object from underneath us by the time we actually call shutdownProducer(), implying that we've just closed a newly created producer, etc.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494757815", "createdAt": "2020-09-25T05:37:46Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,92 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      if (_kafkaProducer == null || closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n+\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          try {\n+            _producerLock.lock();\n+            closeInProgress = false;\n+            _waitOnNoProducerClose.signalAll();\n+          } finally {\n+            _producerLock.unlock();\n+          }\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n-      try {\n-        if (_kafkaProducer != null) {\n-          _kafkaProducer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n-        }\n-      } catch (InterruptException | TimeoutException e) {\n-        // The KafkaProducer object should not be reused on an interrupted flush\n-        _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", _kafkaProducer);\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {\n+      if (producer != null) {\n+          producer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+      }\n+    } catch (InterruptException | TimeoutException e) {\n+      // The KafkaProducer object should not be reused on an interrupted flush\n+      if (producer == _kafkaProducer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0NzczOQ=="}, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 242}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTg0Nzc3OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjozODoxOVrOHXu9WA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjozODoxOVrOHXu9WA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0ODY2NA==", "bodyText": "nit: remove extra line?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494648664", "createdAt": "2020-09-24T22:38:19Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "diffHunk": "@@ -172,6 +173,24 @@ public void unassignTransportProvider(DatastreamTask task) {\n     }\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {\n+    Validate.notNull(taskList, \"null task\");\n+    Set<KafkaProducerWrapper<byte[], byte[]>> producers = new HashSet<>();\n+    for (DatastreamTask task : taskList) {\n+      if (_transportProviders.containsKey(task)) {\n+        KafkaTransportProvider transportProvider = _transportProviders.remove(task);\n+        producers.addAll(transportProvider.getProducers());\n+        //transportProvider.getProducers().forEach(p -> p.unassignTask(task));\n+      } else {\n+        LOG.warn(\"Trying to unassign already unassigned transport provider for task {}.\", task);\n+      }\n+    }\n+\n+    producers.forEach(p -> p.unassignTask(taskList));\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTg0OTI0OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjozODo1OVrOHXu-PA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjozODo1OVrOHXu-PA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0ODg5Mg==", "bodyText": "nit: \"null task\" -> \"null task list\"\nDo we need validate for list size too?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494648892", "createdAt": "2020-09-24T22:38:59Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "diffHunk": "@@ -172,6 +173,24 @@ public void unassignTransportProvider(DatastreamTask task) {\n     }\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {\n+    Validate.notNull(taskList, \"null task\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTg2MTMyOnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjo0NDozOFrOHXvFXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjo0NDozOFrOHXvFXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY1MDcxNw==", "bodyText": "remove this commented out code? or is the intention to do this here?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494650717", "createdAt": "2020-09-24T22:44:38Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "diffHunk": "@@ -172,6 +173,24 @@ public void unassignTransportProvider(DatastreamTask task) {\n     }\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {\n+    Validate.notNull(taskList, \"null task\");\n+    Set<KafkaProducerWrapper<byte[], byte[]>> producers = new HashSet<>();\n+    for (DatastreamTask task : taskList) {\n+      if (_transportProviders.containsKey(task)) {\n+        KafkaTransportProvider transportProvider = _transportProviders.remove(task);\n+        producers.addAll(transportProvider.getProducers());\n+        //transportProvider.getProducers().forEach(p -> p.unassignTask(task));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTg3MDc3OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjo0ODo1NlrOHXvK2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNToyNToxN1rOHX1asQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY1MjEyMQ==", "bodyText": "So we gather all the producers and pass the taskList as is without worrying about the fact that only a subset of tasks will actually be assigned to that producer? Is this to ensure that you unassign all the tasks assigned to the producer, and only call shutdown once?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494652121", "createdAt": "2020-09-24T22:48:56Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "diffHunk": "@@ -172,6 +173,24 @@ public void unassignTransportProvider(DatastreamTask task) {\n     }\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {\n+    Validate.notNull(taskList, \"null task\");\n+    Set<KafkaProducerWrapper<byte[], byte[]>> producers = new HashSet<>();\n+    for (DatastreamTask task : taskList) {\n+      if (_transportProviders.containsKey(task)) {\n+        KafkaTransportProvider transportProvider = _transportProviders.remove(task);\n+        producers.addAll(transportProvider.getProducers());\n+        //transportProvider.getProducers().forEach(p -> p.unassignTask(task));\n+      } else {\n+        LOG.warn(\"Trying to unassign already unassigned transport provider for task {}.\", task);\n+      }\n+    }\n+\n+    producers.forEach(p -> p.unassignTask(taskList));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc1NDQ4MQ==", "bodyText": "Yes, that is true.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494754481", "createdAt": "2020-09-25T05:25:17Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "diffHunk": "@@ -172,6 +173,24 @@ public void unassignTransportProvider(DatastreamTask task) {\n     }\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {\n+    Validate.notNull(taskList, \"null task\");\n+    Set<KafkaProducerWrapper<byte[], byte[]>> producers = new HashSet<>();\n+    for (DatastreamTask task : taskList) {\n+      if (_transportProviders.containsKey(task)) {\n+        KafkaTransportProvider transportProvider = _transportProviders.remove(task);\n+        producers.addAll(transportProvider.getProducers());\n+        //transportProvider.getProducers().forEach(p -> p.unassignTask(task));\n+      } else {\n+        LOG.warn(\"Trying to unassign already unassigned transport provider for task {}.\", task);\n+      }\n+    }\n+\n+    producers.forEach(p -> p.unassignTask(taskList));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY1MjEyMQ=="}, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NTg4NTk5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjo1NToyNlrOHXvTXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNToyNTozNlrOHX1bGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY1NDMwMQ==", "bodyText": "Should we have a test where we assign two tasks, unassign one and check that the second task is still able to send (with a new producer of course)?\nAlso this part of the test onwards looks very similar to the first part onwards. Is that intended? Not clear what's being tested.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494654301", "createdAt": "2020-09-24T22:55:26Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "diffHunk": "@@ -94,37 +95,104 @@ private void testFlushBehaviorOnException(Class<? extends Throwable> exceptionCl\n \n     producerWrapper.verifySend(1);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(1);\n+    producerWrapper.verifyClose(1, 1);\n \n     // Second send should create a new producer, resetting flush() and close() invocation counts\n     producerWrapper.send(task, producerRecord, null);\n     producerWrapper.verifySend(1);\n     producerWrapper.verifyFlush(0);\n-    producerWrapper.verifyClose(0);\n+    producerWrapper.verifyClose(0, 1);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n \n     // Second producer's flush() has not been mocked to throw exceptions, this should not throw\n     producerWrapper.flush();\n     producerWrapper.verifySend(1);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(0);\n+    producerWrapper.verifyClose(0, 1);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n \n     // Send should reuse the older producer and the counts should not be reset\n     producerWrapper.send(task, producerRecord, null);\n     producerWrapper.verifySend(2);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(0);\n+    producerWrapper.verifyClose(0, 1);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n \n     // Closing the producer's task. Since this is the only task, the producer should be closed\n     producerWrapper.close(task);\n     producerWrapper.verifySend(2);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(1);\n+    producerWrapper.verifyClose(1, 2);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n   }\n \n+  @Test\n+  public void testAssignAndUnassignTask() throws Exception {\n+    DynamicMetricsManager.createInstance(new MetricRegistry(), getClass().getSimpleName());\n+    Properties transportProviderProperties = new Properties();\n+    transportProviderProperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:1234\");\n+    transportProviderProperties.put(ProducerConfig.CLIENT_ID_CONFIG, \"testClient\");\n+    transportProviderProperties.put(KafkaTransportProviderAdmin.ZK_CONNECT_STRING_CONFIG, \"zk-connect-string\");\n+    transportProviderProperties.put(KafkaProducerWrapper.CFG_PRODUCER_FLUSH_TIMEOUT_MS, \"1\");\n+\n+    String topicName = \"topic-43\";\n+\n+    MockKafkaProducerWrapper<byte[], byte[]> producerWrapper =\n+        new MockKafkaProducerWrapper<>(\"log-suffix\", transportProviderProperties, \"metrics\",\n+            TimeoutException.class);\n+\n+    String destinationUri = \"localhost:1234/\" + topicName;\n+    Datastream ds = DatastreamTestUtils.createDatastream(\"test\", \"ds1\", \"source\", destinationUri, 1);\n+\n+    DatastreamTask task = new DatastreamTaskImpl(Collections.singletonList(ds));\n+    ProducerRecord<byte[], byte[]> producerRecord = new ProducerRecord<>(topicName, null, null);\n+    producerWrapper.assignTask(task);\n+\n+    // Sending first event, send should pass, none of the other methods on the producer should have been called\n+    producerWrapper.send(task, producerRecord, null);\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(0, 0);\n+    Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 1);\n+\n+    producerWrapper.unassignTask(task);\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(1, 1);\n+\n+    // Second send should fail as the task is unassigned\n+    Assert.assertThrows(DatastreamRuntimeException.class, () -> producerWrapper.send(task, producerRecord, null));\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(1, 1);\n+\n+    // Closing the producer's task. Since this is the only task, the producer should be closed\n+    producerWrapper.close(task);\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(1, 1);\n+    Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 1);\n+\n+    producerWrapper.assignTask(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc1NDU4Ng==", "bodyText": "added.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494754586", "createdAt": "2020-09-25T05:25:36Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "diffHunk": "@@ -94,37 +95,104 @@ private void testFlushBehaviorOnException(Class<? extends Throwable> exceptionCl\n \n     producerWrapper.verifySend(1);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(1);\n+    producerWrapper.verifyClose(1, 1);\n \n     // Second send should create a new producer, resetting flush() and close() invocation counts\n     producerWrapper.send(task, producerRecord, null);\n     producerWrapper.verifySend(1);\n     producerWrapper.verifyFlush(0);\n-    producerWrapper.verifyClose(0);\n+    producerWrapper.verifyClose(0, 1);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n \n     // Second producer's flush() has not been mocked to throw exceptions, this should not throw\n     producerWrapper.flush();\n     producerWrapper.verifySend(1);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(0);\n+    producerWrapper.verifyClose(0, 1);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n \n     // Send should reuse the older producer and the counts should not be reset\n     producerWrapper.send(task, producerRecord, null);\n     producerWrapper.verifySend(2);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(0);\n+    producerWrapper.verifyClose(0, 1);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n \n     // Closing the producer's task. Since this is the only task, the producer should be closed\n     producerWrapper.close(task);\n     producerWrapper.verifySend(2);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(1);\n+    producerWrapper.verifyClose(1, 2);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n   }\n \n+  @Test\n+  public void testAssignAndUnassignTask() throws Exception {\n+    DynamicMetricsManager.createInstance(new MetricRegistry(), getClass().getSimpleName());\n+    Properties transportProviderProperties = new Properties();\n+    transportProviderProperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:1234\");\n+    transportProviderProperties.put(ProducerConfig.CLIENT_ID_CONFIG, \"testClient\");\n+    transportProviderProperties.put(KafkaTransportProviderAdmin.ZK_CONNECT_STRING_CONFIG, \"zk-connect-string\");\n+    transportProviderProperties.put(KafkaProducerWrapper.CFG_PRODUCER_FLUSH_TIMEOUT_MS, \"1\");\n+\n+    String topicName = \"topic-43\";\n+\n+    MockKafkaProducerWrapper<byte[], byte[]> producerWrapper =\n+        new MockKafkaProducerWrapper<>(\"log-suffix\", transportProviderProperties, \"metrics\",\n+            TimeoutException.class);\n+\n+    String destinationUri = \"localhost:1234/\" + topicName;\n+    Datastream ds = DatastreamTestUtils.createDatastream(\"test\", \"ds1\", \"source\", destinationUri, 1);\n+\n+    DatastreamTask task = new DatastreamTaskImpl(Collections.singletonList(ds));\n+    ProducerRecord<byte[], byte[]> producerRecord = new ProducerRecord<>(topicName, null, null);\n+    producerWrapper.assignTask(task);\n+\n+    // Sending first event, send should pass, none of the other methods on the producer should have been called\n+    producerWrapper.send(task, producerRecord, null);\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(0, 0);\n+    Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 1);\n+\n+    producerWrapper.unassignTask(task);\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(1, 1);\n+\n+    // Second send should fail as the task is unassigned\n+    Assert.assertThrows(DatastreamRuntimeException.class, () -> producerWrapper.send(task, producerRecord, null));\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(1, 1);\n+\n+    // Closing the producer's task. Since this is the only task, the producer should be closed\n+    producerWrapper.close(task);\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(1, 1);\n+    Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 1);\n+\n+    producerWrapper.assignTask(task);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY1NDMwMQ=="}, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NjEwODUzOnYy", "diffSide": "RIGHT", "path": "datastream-server/src/main/java/com/linkedin/datastream/server/Coordinator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwMDo0NzoyN1rOHXxRog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwMDo0NzoyN1rOHXxRog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY4NjYyNg==", "bodyText": "not you fault, but can you change the input variable to be \"tasks\" instead of \"t\". It's much easier to read.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494686626", "createdAt": "2020-09-25T00:47:27Z", "author": {"login": "somandal"}, "path": "datastream-server/src/main/java/com/linkedin/datastream/server/Coordinator.java", "diffHunk": "@@ -710,10 +710,17 @@ private DatastreamTask getDatastreamTask(String taskName) {\n     });\n   }\n \n-  private void uninitializeTask(DatastreamTask t) {\n-    TransportProviderAdmin tpAdmin = _transportProviderAdmins.get(t.getTransportProviderName());\n-    tpAdmin.unassignTransportProvider(t);\n-    _cpProvider.unassignDatastreamTask(t);\n+  private void uninitializeTask(List<DatastreamTask> t) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDIzOTM5OnYy", "diffSide": "RIGHT", "path": "datastream-server/src/main/java/com/linkedin/datastream/server/DatastreamTaskImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNTozODo0OVrOHZz1jQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNTozODo0OVrOHZz1jQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjgyNTc0MQ==", "bodyText": "Add a comment explaining the hashcode field as it is not obvious why this optimization is important", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496825741", "createdAt": "2020-09-29T15:38:49Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-server/src/main/java/com/linkedin/datastream/server/DatastreamTaskImpl.java", "diffHunk": "@@ -89,6 +89,7 @@\n   private DatastreamEventProducer _eventProducer;\n   private String _transportProviderName;\n   private SerDeSet _destinationSerDes = new SerDeSet(null, null, null);\n+  private int _hashCode;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDQzNjI1OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjowNzozNVrOHZ1sig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjowNzozNVrOHZ1sig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg1NjIwMg==", "bodyText": "extreme nit: move this after the below check.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496856202", "createdAt": "2020-09-29T16:07:35Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -166,8 +173,17 @@ private void populateDefaultProducerConfigs() {\n \n   private Optional<Producer<K, V>> maybeGetKafkaProducer(DatastreamTask task) {\n     Producer<K, V> producer = _kafkaProducer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDQ1ODc5OnYy", "diffSide": "RIGHT", "path": "datastream-directory/src/main/java/com/linkedin/datastream/server/DirectoryTransportProviderAdmin.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoxMTowMVrOHZ16OA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjo1OTo1OFrOHZ4OaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg1OTcwNA==", "bodyText": "nit: Would a Set rather than a List be better to use here?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496859704", "createdAt": "2020-09-29T16:11:01Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-directory/src/main/java/com/linkedin/datastream/server/DirectoryTransportProviderAdmin.java", "diffHunk": "@@ -39,6 +40,10 @@ public TransportProvider assignTransportProvider(DatastreamTask task) {\n   public void unassignTransportProvider(DatastreamTask task) {\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg5NzY0MQ==", "bodyText": "Keeping aligned with the other interfaces used in connector that pass bunch of task object, uses list and not set.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496897641", "createdAt": "2020-09-29T16:59:58Z", "author": {"login": "vmaheshw"}, "path": "datastream-directory/src/main/java/com/linkedin/datastream/server/DirectoryTransportProviderAdmin.java", "diffHunk": "@@ -39,6 +40,10 @@ public TransportProvider assignTransportProvider(DatastreamTask task) {\n   public void unassignTransportProvider(DatastreamTask task) {\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg1OTcwNA=="}, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDQ3MTMyOnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoxMjo1NVrOHZ2B0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNzowMTowOFrOHZ4RPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg2MTY1MA==", "bodyText": "Does access to _tasks not need to be synchronized?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496861650", "createdAt": "2020-09-29T16:12:55Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -166,8 +173,17 @@ private void populateDefaultProducerConfigs() {\n \n   private Optional<Producer<K, V>> maybeGetKafkaProducer(DatastreamTask task) {\n     Producer<K, V> producer = _kafkaProducer;\n+    if (!_tasks.contains(task)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg5ODM2Ng==", "bodyText": "_tasks is a concurrent Hash map and based on its usage, it really does not have to be in synchronized block. We have added other checks as well to catch the misuse. for eg, every send checks if the task is present in _tasks or not.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496898366", "createdAt": "2020-09-29T17:01:08Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -166,8 +173,17 @@ private void populateDefaultProducerConfigs() {\n \n   private Optional<Producer<K, V>> maybeGetKafkaProducer(DatastreamTask task) {\n     Producer<K, V> producer = _kafkaProducer;\n+    if (!_tasks.contains(task)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg2MTY1MA=="}, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDUyOTk5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoyMjowMVrOHZ2l7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNzowNDozNFrOHZ4Yzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3MDg5NA==", "bodyText": "nit: Make this line\nProducer<K, V> producer = maybeGetKafkaProducer(task).get() instead  and use the if (producer == null) check first to throw so you don't need the else block.\nDoes it help to print the task in question in the exception?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496870894", "createdAt": "2020-09-29T16:22:01Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -219,13 +258,18 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n     while (retry) {\n       try {\n         ++numberOfAttempt;\n-        maybeGetKafkaProducer(task).ifPresent(p -> p.send(producerRecord, (metadata, exception) -> {\n-          if (exception == null) {\n-            onComplete.onCompletion(metadata, null);\n-          } else {\n-            onComplete.onCompletion(metadata, generateSendFailure(exception));\n-          }\n-        }));\n+        Optional<Producer<K, V>> producer = maybeGetKafkaProducer(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjkwMDMwMg==", "bodyText": "I want to avoid calling get() without isPresent() check. Java 11 has introduced a new api ifPresentOrElse() that will make this api cleaner.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496900302", "createdAt": "2020-09-29T17:04:34Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -219,13 +258,18 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n     while (retry) {\n       try {\n         ++numberOfAttempt;\n-        maybeGetKafkaProducer(task).ifPresent(p -> p.send(producerRecord, (metadata, exception) -> {\n-          if (exception == null) {\n-            onComplete.onCompletion(metadata, null);\n-          } else {\n-            onComplete.onCompletion(metadata, generateSendFailure(exception));\n-          }\n-        }));\n+        Optional<Producer<K, V>> producer = maybeGetKafkaProducer(task);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3MDg5NA=="}, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDU3OTI1OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjozMDo1MFrOHZ3D-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNzowODowOFrOHZ4hJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3ODU4NQ==", "bodyText": "is this comment still relevant now that producer access is protected with lock? The code is not harmful, but may be the comment can go if this is not relevant as it might cause some confusion on the intent of the code.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496878585", "createdAt": "2020-09-29T16:30:50Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,103 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      // if there is no producer or the producer close is in progress, return.\n+      if (_kafkaProducer == null || _closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      _closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjkwMjQzNg==", "bodyText": "Actually I feel the comment helps in understanding the intent, even though we have made sure that the producer close in progress will block the send anyway. In the send() if the producer is not null, it does not check for close in progress.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496902436", "createdAt": "2020-09-29T17:08:08Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,103 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      // if there is no producer or the producer close is in progress, return.\n+      if (_kafkaProducer == null || _closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      _closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3ODU4NQ=="}, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDYzNzMyOnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjo0NDozOFrOHZ3nPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNzoxNDozOFrOHZ4wYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4NzYxNQ==", "bodyText": "sorry I might be missing the reason the code looks like this but should it read\n    if (producer != null) {\n       try {\n          producer.flush (...)\n       } catch (..) {\n         ...\n       }\n  } ```", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496887615", "createdAt": "2020-09-29T16:44:38Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,103 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      // if there is no producer or the producer close is in progress, return.\n+      if (_kafkaProducer == null || _closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      _closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          markProducerCloseComplete();\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private void markProducerCloseComplete() {\n+    try {\n+      _producerLock.lock();\n+      _closeInProgress = false;\n+      _waitOnProducerClose.signalAll();\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+  }\n+\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjkwNjMzOQ==", "bodyText": "done.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496906339", "createdAt": "2020-09-29T17:14:38Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,103 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      // if there is no producer or the producer close is in progress, return.\n+      if (_kafkaProducer == null || _closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      _closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          markProducerCloseComplete();\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private void markProducerCloseComplete() {\n+    try {\n+      _producerLock.lock();\n+      _closeInProgress = false;\n+      _waitOnProducerClose.signalAll();\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+  }\n+\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4NzYxNQ=="}, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 229}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMDY2ODQ4OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjo1MTo0NFrOHZ350g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNzoxNDoyNVrOHZ4v1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg5MjM3MA==", "bodyText": "Is the interruption/timeout typical? Wondering about the use of log.warn which are not too noticeable in logs.. wondering if log.error might be better, but I know it raises false alarms in thinking something is wrong when it is being handled here fine.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496892370", "createdAt": "2020-09-29T16:51:44Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,103 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      // if there is no producer or the producer close is in progress, return.\n+      if (_kafkaProducer == null || _closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      _closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          markProducerCloseComplete();\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private void markProducerCloseComplete() {\n+    try {\n+      _producerLock.lock();\n+      _closeInProgress = false;\n+      _waitOnProducerClose.signalAll();\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+  }\n+\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {\n+      if (producer != null) {\n+          producer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+      }\n+    } catch (InterruptException | TimeoutException e) {\n+      // The KafkaProducer object should not be reused on an interrupted flush\n       try {\n-        if (_kafkaProducer != null) {\n-          _kafkaProducer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+        _producerLock.lock();\n+        if (producer == _kafkaProducer) {\n+          _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", producer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 240}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjkwNjE5Nw==", "bodyText": "This will be useful in identifying the producer stuck on flush issues. Yes, you are correct. The reason to not add it as ERROR  is to avoid false alarm. This is a self-recovering scenario which should not need extra attention. So, warns will be sufficient to  identify if this issue happened.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496906197", "createdAt": "2020-09-29T17:14:25Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,103 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      // if there is no producer or the producer close is in progress, return.\n+      if (_kafkaProducer == null || _closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      _closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          markProducerCloseComplete();\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private void markProducerCloseComplete() {\n+    try {\n+      _producerLock.lock();\n+      _closeInProgress = false;\n+      _waitOnProducerClose.signalAll();\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+  }\n+\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {\n+      if (producer != null) {\n+          producer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+      }\n+    } catch (InterruptException | TimeoutException e) {\n+      // The KafkaProducer object should not be reused on an interrupted flush\n       try {\n-        if (_kafkaProducer != null) {\n-          _kafkaProducer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+        _producerLock.lock();\n+        if (producer == _kafkaProducer) {\n+          _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", producer);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg5MjM3MA=="}, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 240}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 883, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}