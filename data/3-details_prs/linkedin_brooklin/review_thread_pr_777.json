{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE2MjU2Nzk5", "number": 777, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxODo0Mjo0MFrOE1yxyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxODo1OToxNFrOE1zJUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0ODQxOTI5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxODo0Mjo0MFrOHuRSHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQyMjo0NjoyN1rOHuZn0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3OTcwOQ==", "bodyText": "Please catch only the WakeupException here to commit safe offsets to ensure we only commit here on the shutdown path. I want to make sure that we understand any other exceptions thrown before we add code to catch those and commit safe offsets.", "url": "https://github.com/linkedin/brooklin/pull/777#discussion_r518279709", "createdAt": "2020-11-05T18:42:40Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -485,6 +483,30 @@ public KafkaDatastreamStatesResponse getKafkaDatastreamStatesResponse() {\n         _isFlushlessModeEnabled ? _flushlessProducer.getInFlightMessagesCounts() : Collections.emptyMap());\n   }\n \n+  @VisibleForTesting\n+  protected void seekToLastCheckpoint(Set<TopicPartition> topicPartitions) {\n+    try {\n+      super.seekToLastCheckpoint(topicPartitions);\n+    } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b3ca1a8e9e0b71463d2becd6113502888f36387"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQxNjMzNw==", "bodyText": "The reason to catch any exception is, it does not really matter. safeOffset should be good to commit irrespective of the exception type.", "url": "https://github.com/linkedin/brooklin/pull/777#discussion_r518416337", "createdAt": "2020-11-05T22:46:27Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -485,6 +483,30 @@ public KafkaDatastreamStatesResponse getKafkaDatastreamStatesResponse() {\n         _isFlushlessModeEnabled ? _flushlessProducer.getInFlightMessagesCounts() : Collections.emptyMap());\n   }\n \n+  @VisibleForTesting\n+  protected void seekToLastCheckpoint(Set<TopicPartition> topicPartitions) {\n+    try {\n+      super.seekToLastCheckpoint(topicPartitions);\n+    } catch (Exception e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3OTcwOQ=="}, "originalCommit": {"oid": "5b3ca1a8e9e0b71463d2becd6113502888f36387"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0ODQyMDc1OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxODo0MzowNFrOHuRTAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxODo0MzowNFrOHuRTAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3OTkzOA==", "bodyText": "nit: add a space after \"//\"\nreword: Flushless mode tracks the successfully received acks, so it is safe to commit offsets even if flush throws an exception. Commit the safe offsets to reduce send duplication.", "url": "https://github.com/linkedin/brooklin/pull/777#discussion_r518279938", "createdAt": "2020-11-05T18:43:04Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -376,14 +376,12 @@ protected void maybeCommitOffsets(Consumer<?, ?> consumer, boolean hardCommit) {\n     if (_isFlushlessModeEnabled) {\n       if (hardCommit) { // hard commit (flush and commit checkpoints)\n         LOG.info(\"Calling flush on the producer.\");\n-        _datastreamTask.getEventProducer().flush();\n-        // Flush may succeed even though some of the records received send failures. Flush only guarantees that all\n-        // outstanding send() calls have completed, without providing any guarantees about their successful completion.\n-        // Thus it is possible that some send callbacks returned an exception and such TopicPartitions must be rewound\n-        // to their last committed offset to avoid data loss.\n-        rewindAndPausePartitionsOnSendException();\n-        commitSafeOffsets(consumer);\n-\n+        try {\n+          _datastreamTask.getEventProducer().flush();\n+        } finally {\n+          //committing the safe offsets will reduce the send duplication.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b3ca1a8e9e0b71463d2becd6113502888f36387"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0ODQzMjU2OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxODo0NjoxOFrOHuRaOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxODo0NjoxOFrOHuRaOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI4MTc4NA==", "bodyText": "Can you add a comment explaining why you aren't just calling super.getLastCheckpointToSeekTo(lastCheckpoint, tpWithNoCommits, tp);", "url": "https://github.com/linkedin/brooklin/pull/777#discussion_r518281784", "createdAt": "2020-11-05T18:46:18Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -485,6 +483,30 @@ public KafkaDatastreamStatesResponse getKafkaDatastreamStatesResponse() {\n         _isFlushlessModeEnabled ? _flushlessProducer.getInFlightMessagesCounts() : Collections.emptyMap());\n   }\n \n+  @VisibleForTesting\n+  protected void seekToLastCheckpoint(Set<TopicPartition> topicPartitions) {\n+    try {\n+      super.seekToLastCheckpoint(topicPartitions);\n+    } catch (Exception e) {\n+      commitSafeOffsets(_consumer);\n+      throw e;\n+    }\n+  }\n+\n+  @Override\n+  protected void getLastCheckpointToSeekTo(Map<TopicPartition, OffsetAndMetadata> lastCheckpoint,\n+      Set<TopicPartition> tpWithNoCommits, TopicPartition tp) {\n+    if (_isFlushlessModeEnabled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b3ca1a8e9e0b71463d2becd6113502888f36387"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0ODQ3OTUyOnYy", "diffSide": "LEFT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxODo1OToxNFrOHuR35Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQyMjo1MToxOVrOHuZvQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI4OTM4MQ==", "bodyText": "was removing this error log intended? if so, why?", "url": "https://github.com/linkedin/brooklin/pull/777#discussion_r518289381", "createdAt": "2020-11-05T18:59:14Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -274,7 +274,6 @@ protected void rewindAndPausePartitionOnException(TopicPartition srcTopicPartiti\n       // Seek to last checkpoint failed. Throw an exception to avoid any data loss scenarios where the consumed\n       // offset can be committed even though the send for that offset has failed.\n       String errorMessage = String.format(\"Partition rewind for %s failed due to \", srcTopicPartition);\n-      _logger.error(errorMessage, e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b3ca1a8e9e0b71463d2becd6113502888f36387"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQxODI0Mw==", "bodyText": "This error was duplicate in the logs. The caller of this method prints the exception, or there is a print when the thread dies with the exception.", "url": "https://github.com/linkedin/brooklin/pull/777#discussion_r518418243", "createdAt": "2020-11-05T22:51:19Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -274,7 +274,6 @@ protected void rewindAndPausePartitionOnException(TopicPartition srcTopicPartiti\n       // Seek to last checkpoint failed. Throw an exception to avoid any data loss scenarios where the consumed\n       // offset can be committed even though the send for that offset has failed.\n       String errorMessage = String.format(\"Partition rewind for %s failed due to \", srcTopicPartition);\n-      _logger.error(errorMessage, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI4OTM4MQ=="}, "originalCommit": {"oid": "5b3ca1a8e9e0b71463d2becd6113502888f36387"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 920, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}