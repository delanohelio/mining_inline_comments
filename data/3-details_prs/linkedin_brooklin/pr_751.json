{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg2ODg5ODU0", "number": 751, "title": "shutdown producer in KafkaProducerWrapper during task assign/unassign call.", "bodyText": "The producer should be not have any pending inflight sends post the task is unassigned. KafkaProducerWrapper should not allow any more send operation for the task after it is unassigned. In the current code, the tasks share the producer and if the producer is initialized, it does not check whether the task is allowed to send or not. Adding a check to stop that. Since multiple tasks share the same KafkaProducerWrapper, when one task is unassigned, we should shutdown the producer to ensure that there are no pending inflight sends. Kafka allows a longer time for pending inflight sends. So, the sends are not aborted or forced to complete, the destination can see  wrong ordering of the messages. Flushing the kafka producer will not achieve this. The only way is to shutdown the producer which internally force close the kafka producer after a specified timeout.\nIn our current code, the producer is closed only for the existing tasks. So, if there are tasks which were just unassigned, the corresponding producer will never be forced shutdown. This is fine so far because the shutdown was called only during the coordinator stop. But, with recent change to handle session expiry, all the producers are expected to be shutdown before reconnecting the new session. So, it is important to shutdown the producers of the tasks which were recently unassigned as well.  Adding the shutdown logic while unassignTask will take care of this.\nA new producer should not be created till the older producer is marked as closed. This is to avoid out-of-order record generation. Also, made the synchronization blocks light, so that the no thread holds the lock for a long time.\nMoved the kafka producer flush outside the synchronized block, because it is okay for two threads sharing kafka producer to call flush() at the same time.\nDuring send call, we will check if the task is part of the current assigned task list, which will internally calculate the hash every time. To optimize and avoid repetition of this operation, we will cache the hash in DatastreamTaskImpl.\nMaking an optimization to call all the tasks getting unassigned in one shot to make sure that the producer is closed only once. Adding a new interface in TransportProviderAdmin to handle it. This will give TransportProviderAdmins more power to optimize logic if there is any sharing involved.\nAlso, reducing the shutdown timer in AbstractKafkaConnector to be in alignment with 30 second debounce timer.", "createdAt": "2020-09-14T21:21:58Z", "url": "https://github.com/linkedin/brooklin/pull/751", "merged": true, "mergeCommit": {"oid": "502eadfb4fdb210b7f528fdedf96351486fd2e4c"}, "closed": true, "closedAt": "2020-09-29T23:25:45Z", "author": {"login": "vmaheshw"}, "timelineItems": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABboAf5CAH2gAyNDg2ODg5ODU0OmMzMWNkNGExNWNjOGRkNjliMGE2NTNkYmU0MjAxZGU5MzRlYTZkNjU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdNtg03AFqTQ5ODgyMDI0MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c31cd4a15cc8dd69b0a653dbe4201de934ea6d65", "author": {"user": {"login": "vmaheshw", "name": "Vaibhav Maheshwari"}}, "url": "https://github.com/linkedin/brooklin/commit/c31cd4a15cc8dd69b0a653dbe4201de934ea6d65", "committedDate": "2019-11-18T20:06:44Z", "message": "Merge pull request #1 from linkedin/master\n\nPull latest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8db5941e3dd2292f5ebbc40962874d08bfe4b38f", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/8db5941e3dd2292f5ebbc40962874d08bfe4b38f", "committedDate": "2020-09-14T21:14:51Z", "message": "Fix KafkaProducerWrapper to not allow any send/flush operation for a task after unassign"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/261567c3ca629c22be99e773dea67f4b6590f610", "committedDate": "2020-09-14T21:50:08Z", "message": "Fix build failure"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4ODM5Mzc0", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-488839374", "createdAt": "2020-09-15T16:04:31Z", "commit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNjowNDozMlrOHSJHOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNjoyOToyNFrOHSKI6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODc4NTcyMw==", "bodyText": "nit: \"Any further sends by this task will not work\"\nAlso, do you think we should add a small sentence about how this affects existing tasks that share the same producer? i.e. their inflight records will attempt to flushed, but if it doesn't complete, they'll see send failures, but this is okay since they'll be able to create a new producer on the next send?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r488785723", "createdAt": "2020-09-15T16:04:32Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,7 +182,12 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    boolean taskPresent = _tasks.remove(task);\n+    // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+    // there are no in-flight sends. Any further send will not work.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODc5NzI2OA==", "bodyText": "Does adding a comment here make sense, that if the task is not assigned, production should be disallowed?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r488797268", "createdAt": "2020-09-15T16:21:21Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -166,6 +166,11 @@ private void populateDefaultProducerConfigs() {\n \n   private Optional<Producer<K, V>> maybeGetKafkaProducer(DatastreamTask task) {\n     Producer<K, V> producer = _kafkaProducer;\n+    if (!_tasks.contains(task)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODc5OTgyNQ==", "bodyText": "One thing to note here is that since shutdownProducer() requires obtaining the lock, this operation can get stuck waiting on this lock. Operations such as flush can take a while (up to 15 minutes for BMM with the current flush timeout). Once concern might be that unassignTask() is called from the onAssignmentChange() threads, right? And have a limited time of 30-60 seconds within which it needs to complete?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r488799825", "createdAt": "2020-09-15T16:25:08Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,7 +182,12 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    boolean taskPresent = _tasks.remove(task);\n+    // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+    // there are no in-flight sends. Any further send will not work.\n+    if (taskPresent) {\n+      shutdownProducer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgwMjUzOQ==", "bodyText": "Can you add  a comment here or somewhere in this file that if a new field is added along with a setter, or any function that modifies the values, the setter/function must call computeHashCode()?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r488802539", "createdAt": "2020-09-15T16:29:24Z", "author": {"login": "somandal"}, "path": "datastream-server/src/main/java/com/linkedin/datastream/server/DatastreamTaskImpl.java", "diffHunk": "@@ -89,6 +89,7 @@\n   private DatastreamEventProducer _eventProducer;\n   private String _transportProviderName;\n   private SerDeSet _destinationSerDes = new SerDeSet(null, null, null);\n+  private int _hashCode;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "261567c3ca629c22be99e773dea67f4b6590f610"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1d1688689d6ec083a647554146dfbf478d7d94a", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/e1d1688689d6ec083a647554146dfbf478d7d94a", "committedDate": "2020-09-21T19:22:07Z", "message": "Merge branch 'master' of github.com:vmaheshw/Brooklin into fixKafkaProducerWrapper"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca788a52a629ed332efb97868dcc0f868c3fabb5", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/ca788a52a629ed332efb97868dcc0f868c3fabb5", "committedDate": "2020-09-21T19:24:02Z", "message": "Merge changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b96260b1f27844b27061d49963d97e837742648", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/0b96260b1f27844b27061d49963d97e837742648", "committedDate": "2020-09-21T23:31:03Z", "message": "Add interface to TransportProviderAdmin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91cb2378a8678ccd02ecac30434f850868b442b6", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/91cb2378a8678ccd02ecac30434f850868b442b6", "committedDate": "2020-09-21T23:34:43Z", "message": "Fix code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6893a7faeacde6c74aac74213266b6f06948485d", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/6893a7faeacde6c74aac74213266b6f06948485d", "committedDate": "2020-09-21T23:40:03Z", "message": "Build failures"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001", "committedDate": "2020-09-23T04:07:19Z", "message": "Refactor producerlock"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f8e6759819a260be1e48b9e556de963b7decbca", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/5f8e6759819a260be1e48b9e556de963b7decbca", "committedDate": "2020-09-24T04:39:51Z", "message": "Fix comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MTAzNzY5", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-495103769", "createdAt": "2020-09-23T22:57:36Z", "commit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "state": "DISMISSED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMjo1NzozN1rOHXDuGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwMDo0NzoyN1rOHXxRog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0MDI1MQ==", "bodyText": "nit: _waitOnNoProducerClose -> _waitOnProducerClose", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r493940251", "createdAt": "2020-09-23T22:57:37Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -111,11 +114,13 @@\n   private final String _metricsNamesPrefix;\n \n   // A lock used to synchronize access to operations performed on the _kafkaProducer object\n-  private final Object _producerLock = new Object();\n+  private final Lock _producerLock = new ReentrantLock();\n+  private final Condition _waitOnNoProducerClose = _producerLock.newCondition();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0MDU4MQ==", "bodyText": "You should move the \"closeInProgress\" here and mention that it also needs to be accessed from under the same lock.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r493940581", "createdAt": "2020-09-23T22:58:40Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -111,11 +114,13 @@\n   private final String _metricsNamesPrefix;\n \n   // A lock used to synchronize access to operations performed on the _kafkaProducer object", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0MDg2MA==", "bodyText": "nit: closeInProgress -> _closeInProgress\nAlso move this to where the lock is declared, and make it clear that the lock protects updates to this too.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r493940860", "createdAt": "2020-09-23T22:59:33Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -111,11 +114,13 @@\n   private final String _metricsNamesPrefix;\n \n   // A lock used to synchronize access to operations performed on the _kafkaProducer object\n-  private final Object _producerLock = new Object();\n+  private final Lock _producerLock = new ReentrantLock();\n+  private final Condition _waitOnNoProducerClose = _producerLock.newCondition();\n \n   // An executor to spawn threads to close the producer.\n   private final ExecutorService _producerCloseExecutorService = Executors.newSingleThreadExecutor(\n       new ThreadFactoryBuilder().setNameFormat(\"KafkaProducerWrapperClose-%d\").build());\n+  private boolean closeInProgress = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0MTI3Mw==", "bodyText": "nit: unassignTask  -> unassignTasks (since it can unassign multiple tasks)", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r493941273", "createdAt": "2020-09-23T23:00:51Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,29 +191,54 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    unassignTask(Collections.singletonList(task));\n+  }\n+\n+  void unassignTask(List<DatastreamTask> taskList) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYyNTYwMg==", "bodyText": "nit:  there are no in-flight sends -> there are no pending in-flight sends\nnit: Any further send will not work -> Further sends will fail until the producer is re-initialized by a valid task", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494625602", "createdAt": "2020-09-24T21:38:15Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,29 +191,54 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    unassignTask(Collections.singletonList(task));\n+  }\n+\n+  void unassignTask(List<DatastreamTask> taskList) {\n+    boolean taskPresent = _tasks.removeAll(taskList);\n+    try {\n+      _producerLock.lock();\n+\n+      // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+      // there are no in-flight sends. Any further send will not work.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYzMjM0OQ==", "bodyText": "Let's add comments here explaining why it's okay to only shutdown the producer when the task list is empty (i.e. we are on shutdown path)? It becomes confusing since in unassignTask(), we need to close the producer ever time we remove a task.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494632349", "createdAt": "2020-09-24T21:54:36Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,92 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      if (_kafkaProducer == null || closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n+\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          try {\n+            _producerLock.lock();\n+            closeInProgress = false;\n+            _waitOnNoProducerClose.signalAll();\n+          } finally {\n+            _producerLock.unlock();\n+          }\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n-      try {\n-        if (_kafkaProducer != null) {\n-          _kafkaProducer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n-        }\n-      } catch (InterruptException | TimeoutException e) {\n-        // The KafkaProducer object should not be reused on an interrupted flush\n-        _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", _kafkaProducer);\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {\n+      if (producer != null) {\n+          producer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+      }\n+    } catch (InterruptException | TimeoutException e) {\n+      // The KafkaProducer object should not be reused on an interrupted flush\n+      if (producer == _kafkaProducer) {\n+        _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", producer);\n         shutdownProducer();\n-        throw e;\n+      } else {\n+        _log.warn(\"Kafka producer flush interrupted/timed out, producer {} already closed.\", producer);\n       }\n+      throw e;\n     }\n   }\n \n   void close(DatastreamTask task) {\n-    synchronized (_producerLock) {\n-      _tasks.remove(task);\n-      if (_kafkaProducer != null && _tasks.isEmpty()) {\n-        shutdownProducer();\n-      }\n+    if (_tasks.remove(task) && _tasks.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 259}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYzNDUyMw==", "bodyText": "So we already check for this before we call initializeProducer, is this really needed here too? If yes, can you add comments explaining why?\nI feel a little bit like assignTask/unassignTask aren't synchronizing access to _tasks as such, which means the state of _tasks can change at any point in time anyways. So I don't see much point in checking for this twice. Do correct me if I missed something though.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494634523", "createdAt": "2020-09-24T21:59:42Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,29 +191,54 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    unassignTask(Collections.singletonList(task));\n+  }\n+\n+  void unassignTask(List<DatastreamTask> taskList) {\n+    boolean taskPresent = _tasks.removeAll(taskList);\n+    try {\n+      _producerLock.lock();\n+\n+      // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+      // there are no in-flight sends. Any further send will not work.\n+      if (taskPresent && _kafkaProducer != null && !closeInProgress) {\n+        shutdownProducer();\n+      }\n+    } finally {\n+      _producerLock.unlock();\n+    }\n   }\n \n   int getTasksSize() {\n     return _tasks.size();\n   }\n \n-  private Producer<K, V> initializeProducer(DatastreamTask task) {\n+  private Producer<K, V> initializeProducer(DatastreamTask task) throws InterruptedException {\n+    if (!_tasks.contains(task)) {\n+      _log.warn(\"Task {} has been unassigned for producer, abort the send\", task);\n+      return null;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYzNjgwOA==", "bodyText": "nit: Close not completed. Retry -> Close did not complete in {} ms, retrying {}th time\n(or something along those lines - maybe skip the number of retries)\nI somehow think we should make this an info/warn. Will be hard to debug if for some reason we get stuck in this loop.\nAlso, what if close is stuck indefinitely? Looks like this thread will just be stuck waiting forever in that case. We should definitely at least log periodically if not every time we finish an await().\nAlso a good idea to add  some comments here calling out that this can affect other tasks that use the same producer and cause some latency, but it is necessary for correctness. Don't want history to repeat itself.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494636808", "createdAt": "2020-09-24T22:05:22Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -177,29 +191,54 @@ void assignTask(DatastreamTask task) {\n   }\n \n   void unassignTask(DatastreamTask task) {\n-    _tasks.remove(task);\n+    unassignTask(Collections.singletonList(task));\n+  }\n+\n+  void unassignTask(List<DatastreamTask> taskList) {\n+    boolean taskPresent = _tasks.removeAll(taskList);\n+    try {\n+      _producerLock.lock();\n+\n+      // whenever a task is unassigned the kafka producer should be shutdown to ensure that\n+      // there are no in-flight sends. Any further send will not work.\n+      if (taskPresent && _kafkaProducer != null && !closeInProgress) {\n+        shutdownProducer();\n+      }\n+    } finally {\n+      _producerLock.unlock();\n+    }\n   }\n \n   int getTasksSize() {\n     return _tasks.size();\n   }\n \n-  private Producer<K, V> initializeProducer(DatastreamTask task) {\n+  private Producer<K, V> initializeProducer(DatastreamTask task) throws InterruptedException {\n+    if (!_tasks.contains(task)) {\n+      _log.warn(\"Task {} has been unassigned for producer, abort the send\", task);\n+      return null;\n+    }\n     // Must be protected by a lock to avoid creating duplicate producers when multiple concurrent\n     // sends are in-flight and _kafkaProducer has been set to null as a result of previous\n     // producer exception.\n-    synchronized (_producerLock) {\n-      if (!_tasks.contains(task)) {\n-        _log.warn(\"Task {} has been unassigned for producer, abort the send\", task);\n-        return null;\n-      } else {\n-        if (_kafkaProducer == null) {\n-          _rateLimiter.acquire();\n-          _kafkaProducer = createKafkaProducer();\n-          NUM_PRODUCERS.incrementAndGet();\n+    try {\n+      _producerLock.lock();\n+\n+      while (closeInProgress) {\n+        boolean closeCompleted = _waitOnNoProducerClose.await(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+        if (!closeCompleted) {\n+          _log.debug(\"Close not completed. Retry\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0NjcwNw==", "bodyText": "Shall we move this block into a separate function? Looks very long here and can be a little confusing to read (first I  thought you're releasing the lock in two different finally blocks, and then realized that the first one is a separate thread)", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494646707", "createdAt": "2020-09-24T22:32:42Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,92 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      if (_kafkaProducer == null || closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n+\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          try {\n+            _producerLock.lock();\n+            closeInProgress = false;\n+            _waitOnNoProducerClose.signalAll();\n+          } finally {\n+            _producerLock.unlock();\n+          }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0NzczOQ==", "bodyText": "we're checking _kafkaProducer outside the lock. _kafkaProducer may change by the time shutdownProducer() is called. Can we instead have a shutdownProducer(producer) that does this comparison under the lock and calls shutdownProducer(), or something along those lines?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494647739", "createdAt": "2020-09-24T22:35:33Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,92 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      if (_kafkaProducer == null || closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n+\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          try {\n+            _producerLock.lock();\n+            closeInProgress = false;\n+            _waitOnNoProducerClose.signalAll();\n+          } finally {\n+            _producerLock.unlock();\n+          }\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n-      try {\n-        if (_kafkaProducer != null) {\n-          _kafkaProducer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n-        }\n-      } catch (InterruptException | TimeoutException e) {\n-        // The KafkaProducer object should not be reused on an interrupted flush\n-        _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", _kafkaProducer);\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {\n+      if (producer != null) {\n+          producer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+      }\n+    } catch (InterruptException | TimeoutException e) {\n+      // The KafkaProducer object should not be reused on an interrupted flush\n+      if (producer == _kafkaProducer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 242}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0ODY2NA==", "bodyText": "nit: remove extra line?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494648664", "createdAt": "2020-09-24T22:38:19Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "diffHunk": "@@ -172,6 +173,24 @@ public void unassignTransportProvider(DatastreamTask task) {\n     }\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {\n+    Validate.notNull(taskList, \"null task\");\n+    Set<KafkaProducerWrapper<byte[], byte[]>> producers = new HashSet<>();\n+    for (DatastreamTask task : taskList) {\n+      if (_transportProviders.containsKey(task)) {\n+        KafkaTransportProvider transportProvider = _transportProviders.remove(task);\n+        producers.addAll(transportProvider.getProducers());\n+        //transportProvider.getProducers().forEach(p -> p.unassignTask(task));\n+      } else {\n+        LOG.warn(\"Trying to unassign already unassigned transport provider for task {}.\", task);\n+      }\n+    }\n+\n+    producers.forEach(p -> p.unassignTask(taskList));\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0ODg5Mg==", "bodyText": "nit: \"null task\" -> \"null task list\"\nDo we need validate for list size too?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494648892", "createdAt": "2020-09-24T22:38:59Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "diffHunk": "@@ -172,6 +173,24 @@ public void unassignTransportProvider(DatastreamTask task) {\n     }\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {\n+    Validate.notNull(taskList, \"null task\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY1MDcxNw==", "bodyText": "remove this commented out code? or is the intention to do this here?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494650717", "createdAt": "2020-09-24T22:44:38Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "diffHunk": "@@ -172,6 +173,24 @@ public void unassignTransportProvider(DatastreamTask task) {\n     }\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {\n+    Validate.notNull(taskList, \"null task\");\n+    Set<KafkaProducerWrapper<byte[], byte[]>> producers = new HashSet<>();\n+    for (DatastreamTask task : taskList) {\n+      if (_transportProviders.containsKey(task)) {\n+        KafkaTransportProvider transportProvider = _transportProviders.remove(task);\n+        producers.addAll(transportProvider.getProducers());\n+        //transportProvider.getProducers().forEach(p -> p.unassignTask(task));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY1MjEyMQ==", "bodyText": "So we gather all the producers and pass the taskList as is without worrying about the fact that only a subset of tasks will actually be assigned to that producer? Is this to ensure that you unassign all the tasks assigned to the producer, and only call shutdown once?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494652121", "createdAt": "2020-09-24T22:48:56Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaTransportProviderAdmin.java", "diffHunk": "@@ -172,6 +173,24 @@ public void unassignTransportProvider(DatastreamTask task) {\n     }\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {\n+    Validate.notNull(taskList, \"null task\");\n+    Set<KafkaProducerWrapper<byte[], byte[]>> producers = new HashSet<>();\n+    for (DatastreamTask task : taskList) {\n+      if (_transportProviders.containsKey(task)) {\n+        KafkaTransportProvider transportProvider = _transportProviders.remove(task);\n+        producers.addAll(transportProvider.getProducers());\n+        //transportProvider.getProducers().forEach(p -> p.unassignTask(task));\n+      } else {\n+        LOG.warn(\"Trying to unassign already unassigned transport provider for task {}.\", task);\n+      }\n+    }\n+\n+    producers.forEach(p -> p.unassignTask(taskList));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY1NDMwMQ==", "bodyText": "Should we have a test where we assign two tasks, unassign one and check that the second task is still able to send (with a new producer of course)?\nAlso this part of the test onwards looks very similar to the first part onwards. Is that intended? Not clear what's being tested.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494654301", "createdAt": "2020-09-24T22:55:26Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "diffHunk": "@@ -94,37 +95,104 @@ private void testFlushBehaviorOnException(Class<? extends Throwable> exceptionCl\n \n     producerWrapper.verifySend(1);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(1);\n+    producerWrapper.verifyClose(1, 1);\n \n     // Second send should create a new producer, resetting flush() and close() invocation counts\n     producerWrapper.send(task, producerRecord, null);\n     producerWrapper.verifySend(1);\n     producerWrapper.verifyFlush(0);\n-    producerWrapper.verifyClose(0);\n+    producerWrapper.verifyClose(0, 1);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n \n     // Second producer's flush() has not been mocked to throw exceptions, this should not throw\n     producerWrapper.flush();\n     producerWrapper.verifySend(1);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(0);\n+    producerWrapper.verifyClose(0, 1);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n \n     // Send should reuse the older producer and the counts should not be reset\n     producerWrapper.send(task, producerRecord, null);\n     producerWrapper.verifySend(2);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(0);\n+    producerWrapper.verifyClose(0, 1);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n \n     // Closing the producer's task. Since this is the only task, the producer should be closed\n     producerWrapper.close(task);\n     producerWrapper.verifySend(2);\n     producerWrapper.verifyFlush(1);\n-    producerWrapper.verifyClose(1);\n+    producerWrapper.verifyClose(1, 2);\n     Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 2);\n   }\n \n+  @Test\n+  public void testAssignAndUnassignTask() throws Exception {\n+    DynamicMetricsManager.createInstance(new MetricRegistry(), getClass().getSimpleName());\n+    Properties transportProviderProperties = new Properties();\n+    transportProviderProperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:1234\");\n+    transportProviderProperties.put(ProducerConfig.CLIENT_ID_CONFIG, \"testClient\");\n+    transportProviderProperties.put(KafkaTransportProviderAdmin.ZK_CONNECT_STRING_CONFIG, \"zk-connect-string\");\n+    transportProviderProperties.put(KafkaProducerWrapper.CFG_PRODUCER_FLUSH_TIMEOUT_MS, \"1\");\n+\n+    String topicName = \"topic-43\";\n+\n+    MockKafkaProducerWrapper<byte[], byte[]> producerWrapper =\n+        new MockKafkaProducerWrapper<>(\"log-suffix\", transportProviderProperties, \"metrics\",\n+            TimeoutException.class);\n+\n+    String destinationUri = \"localhost:1234/\" + topicName;\n+    Datastream ds = DatastreamTestUtils.createDatastream(\"test\", \"ds1\", \"source\", destinationUri, 1);\n+\n+    DatastreamTask task = new DatastreamTaskImpl(Collections.singletonList(ds));\n+    ProducerRecord<byte[], byte[]> producerRecord = new ProducerRecord<>(topicName, null, null);\n+    producerWrapper.assignTask(task);\n+\n+    // Sending first event, send should pass, none of the other methods on the producer should have been called\n+    producerWrapper.send(task, producerRecord, null);\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(0, 0);\n+    Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 1);\n+\n+    producerWrapper.unassignTask(task);\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(1, 1);\n+\n+    // Second send should fail as the task is unassigned\n+    Assert.assertThrows(DatastreamRuntimeException.class, () -> producerWrapper.send(task, producerRecord, null));\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(1, 1);\n+\n+    // Closing the producer's task. Since this is the only task, the producer should be closed\n+    producerWrapper.close(task);\n+    producerWrapper.verifySend(1);\n+    producerWrapper.verifyFlush(0);\n+    producerWrapper.verifyClose(1, 1);\n+    Assert.assertEquals(producerWrapper.getNumCreateKafkaProducerCalls(), 1);\n+\n+    producerWrapper.assignTask(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY4NjYyNg==", "bodyText": "not you fault, but can you change the input variable to be \"tasks\" instead of \"t\". It's much easier to read.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r494686626", "createdAt": "2020-09-25T00:47:27Z", "author": {"login": "somandal"}, "path": "datastream-server/src/main/java/com/linkedin/datastream/server/Coordinator.java", "diffHunk": "@@ -710,10 +710,17 @@ private DatastreamTask getDatastreamTask(String taskName) {\n     });\n   }\n \n-  private void uninitializeTask(DatastreamTask t) {\n-    TransportProviderAdmin tpAdmin = _transportProviderAdmins.get(t.getTransportProviderName());\n-    tpAdmin.unassignTransportProvider(t);\n-    _cpProvider.unassignDatastreamTask(t);\n+  private void uninitializeTask(List<DatastreamTask> t) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e6c7bd9cebf647fcb82063ef9f99ac9d2f07001"}, "originalPosition": 17}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ccf2995710d5d0bdbf26ff4d54e2f06988c03cfb", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/ccf2995710d5d0bdbf26ff4d54e2f06988c03cfb", "committedDate": "2020-09-25T05:16:25Z", "message": "Address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/528e8b5153543bf4b41712f5124d04ebe0710278", "committedDate": "2020-09-25T06:03:58Z", "message": "Address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2NTMwNjE2", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-496530616", "createdAt": "2020-09-25T15:33:23Z", "commit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4NjI2MDUx", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-498626051", "createdAt": "2020-09-29T15:38:49Z", "commit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNTozODo0OVrOHZz1jQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNTozODo0OVrOHZz1jQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjgyNTc0MQ==", "bodyText": "Add a comment explaining the hashcode field as it is not obvious why this optimization is important", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496825741", "createdAt": "2020-09-29T15:38:49Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-server/src/main/java/com/linkedin/datastream/server/DatastreamTaskImpl.java", "diffHunk": "@@ -89,6 +89,7 @@\n   private DatastreamEventProducer _eventProducer;\n   private String _transportProviderName;\n   private SerDeSet _destinationSerDes = new SerDeSet(null, null, null);\n+  private int _hashCode;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4NjUzNDM5", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-498653439", "createdAt": "2020-09-29T16:07:34Z", "commit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjowNzozNVrOHZ1sig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjowNzozNVrOHZ1sig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg1NjIwMg==", "bodyText": "extreme nit: move this after the below check.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496856202", "createdAt": "2020-09-29T16:07:35Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -166,8 +173,17 @@ private void populateDefaultProducerConfigs() {\n \n   private Optional<Producer<K, V>> maybeGetKafkaProducer(DatastreamTask task) {\n     Producer<K, V> producer = _kafkaProducer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4NjU2NDY2", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-498656466", "createdAt": "2020-09-29T16:11:01Z", "commit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoxMTowMVrOHZ16OA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoxMTowMVrOHZ16OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg1OTcwNA==", "bodyText": "nit: Would a Set rather than a List be better to use here?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496859704", "createdAt": "2020-09-29T16:11:01Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-directory/src/main/java/com/linkedin/datastream/server/DirectoryTransportProviderAdmin.java", "diffHunk": "@@ -39,6 +40,10 @@ public TransportProvider assignTransportProvider(DatastreamTask task) {\n   public void unassignTransportProvider(DatastreamTask task) {\n   }\n \n+  @Override\n+  public void unassignTransportProvider(List<DatastreamTask> taskList) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4NjU4MTgy", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-498658182", "createdAt": "2020-09-29T16:12:55Z", "commit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoxMjo1NVrOHZ2B0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoxMjo1NVrOHZ2B0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg2MTY1MA==", "bodyText": "Does access to _tasks not need to be synchronized?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496861650", "createdAt": "2020-09-29T16:12:55Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -166,8 +173,17 @@ private void populateDefaultProducerConfigs() {\n \n   private Optional<Producer<K, V>> maybeGetKafkaProducer(DatastreamTask task) {\n     Producer<K, V> producer = _kafkaProducer;\n+    if (!_tasks.contains(task)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4NjY1OTQw", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-498665940", "createdAt": "2020-09-29T16:22:01Z", "commit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoyMjowMVrOHZ2l7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjoyMjowMVrOHZ2l7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3MDg5NA==", "bodyText": "nit: Make this line\nProducer<K, V> producer = maybeGetKafkaProducer(task).get() instead  and use the if (producer == null) check first to throw so you don't need the else block.\nDoes it help to print the task in question in the exception?", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496870894", "createdAt": "2020-09-29T16:22:01Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -219,13 +258,18 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n     while (retry) {\n       try {\n         ++numberOfAttempt;\n-        maybeGetKafkaProducer(task).ifPresent(p -> p.send(producerRecord, (metadata, exception) -> {\n-          if (exception == null) {\n-            onComplete.onCompletion(metadata, null);\n-          } else {\n-            onComplete.onCompletion(metadata, generateSendFailure(exception));\n-          }\n-        }));\n+        Optional<Producer<K, V>> producer = maybeGetKafkaProducer(task);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4NjczNDc5", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-498673479", "createdAt": "2020-09-29T16:30:49Z", "commit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjozMDo1MFrOHZ3D-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjozMDo1MFrOHZ3D-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3ODU4NQ==", "bodyText": "is this comment still relevant now that producer access is protected with lock? The code is not harmful, but may be the comment can go if this is not relevant as it might cause some confusion on the intent of the code.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496878585", "createdAt": "2020-09-29T16:30:50Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,103 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      // if there is no producer or the producer close is in progress, return.\n+      if (_kafkaProducer == null || _closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      _closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 163}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4Njg0ODA5", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-498684809", "createdAt": "2020-09-29T16:44:37Z", "commit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "state": "DISMISSED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjo0NDozOFrOHZ3nPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNjo1MTo0NFrOHZ350g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4NzYxNQ==", "bodyText": "sorry I might be missing the reason the code looks like this but should it read\n    if (producer != null) {\n       try {\n          producer.flush (...)\n       } catch (..) {\n         ...\n       }\n  } ```", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496887615", "createdAt": "2020-09-29T16:44:38Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,103 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      // if there is no producer or the producer close is in progress, return.\n+      if (_kafkaProducer == null || _closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      _closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          markProducerCloseComplete();\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private void markProducerCloseComplete() {\n+    try {\n+      _producerLock.lock();\n+      _closeInProgress = false;\n+      _waitOnProducerClose.signalAll();\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+  }\n+\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg5MjM3MA==", "bodyText": "Is the interruption/timeout typical? Wondering about the use of log.warn which are not too noticeable in logs.. wondering if log.error might be better, but I know it raises false alarms in thinking something is wrong when it is being handled here fine.", "url": "https://github.com/linkedin/brooklin/pull/751#discussion_r496892370", "createdAt": "2020-09-29T16:51:44Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -254,67 +298,103 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n       } catch (Exception e) {\n         _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n-        throw generateSendFailure(e);\n+        throw generateSendFailure(e, task);\n       }\n     }\n   }\n \n   @VisibleForTesting\n   void shutdownProducer() {\n     Producer<K, V> producer;\n-    synchronized (_producerLock) {\n+    try {\n+      _producerLock.lock();\n+      // if there is no producer or the producer close is in progress, return.\n+      if (_kafkaProducer == null || _closeInProgress) {\n+        return;\n+      }\n       producer = _kafkaProducer;\n+      _closeInProgress = true;\n       // Nullify first to prevent subsequent send() to use\n       // the current producer which is being shutdown.\n       _kafkaProducer = null;\n-    }\n \n-    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n-    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n-    // thread\n-    if (producer != null) {\n+      // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+      // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+      // thread\n       _producerCloseExecutorService.submit(() -> {\n         _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n-        producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n-        NUM_PRODUCERS.decrementAndGet();\n-        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        try {\n+          producer.close(CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+          NUM_PRODUCERS.decrementAndGet();\n+          _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+        } finally {\n+          markProducerCloseComplete();\n+        }\n       });\n+    } finally {\n+      _producerLock.unlock();\n     }\n   }\n \n-  private DatastreamRuntimeException generateSendFailure(Exception exception) {\n+  private void markProducerCloseComplete() {\n+    try {\n+      _producerLock.lock();\n+      _closeInProgress = false;\n+      _waitOnProducerClose.signalAll();\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+  }\n+\n+  private DatastreamRuntimeException generateSendFailure(Exception exception, DatastreamTask task) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n       _log.warn(\"Send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n       _log.warn(\"Send failed with a non-transient exception. Shutting down producer, exception: \", exception);\n-      shutdownProducer();\n+      if (_tasks.contains(task)) {\n+        shutdownProducer();\n+      }\n       return new DatastreamRuntimeException(exception);\n     }\n   }\n \n   void flush() {\n-    synchronized (_producerLock) {\n+    Producer<K, V> producer;\n+    try {\n+      _producerLock.lock();\n+      producer = _kafkaProducer;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    try {\n+      if (producer != null) {\n+          producer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+      }\n+    } catch (InterruptException | TimeoutException e) {\n+      // The KafkaProducer object should not be reused on an interrupted flush\n       try {\n-        if (_kafkaProducer != null) {\n-          _kafkaProducer.flush(_producerFlushTimeoutMs, TimeUnit.MILLISECONDS);\n+        _producerLock.lock();\n+        if (producer == _kafkaProducer) {\n+          _log.warn(\"Kafka producer flush interrupted/timed out, closing producer {}.\", producer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "528e8b5153543bf4b41712f5124d04ebe0710278"}, "originalPosition": 240}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b58d1442147bc9eca70dacf839cdecb181e1a26c", "author": {"user": null}, "url": "https://github.com/linkedin/brooklin/commit/b58d1442147bc9eca70dacf839cdecb181e1a26c", "committedDate": "2020-09-29T17:34:51Z", "message": "Address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4NzM5NzUw", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-498739750", "createdAt": "2020-09-29T17:54:02Z", "commit": {"oid": "b58d1442147bc9eca70dacf839cdecb181e1a26c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4ODIwMjQx", "url": "https://github.com/linkedin/brooklin/pull/751#pullrequestreview-498820241", "createdAt": "2020-09-29T19:39:50Z", "commit": {"oid": "b58d1442147bc9eca70dacf839cdecb181e1a26c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 290, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}