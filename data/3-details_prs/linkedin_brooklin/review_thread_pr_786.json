{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM5NzM2Mzkw", "number": 786, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxOTo0NDoyM1rOFFLdLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwMToyMzoyN1rOFH_O3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwOTc0ODk0OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxOTo0NDoyM1rOIFjwCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMjo0OTowN1rOIFvqIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjY5OTUyOQ==", "bodyText": "It'll be good if the postCommitHook() can get hold of the exception causing the commit to fail.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r542699529", "createdAt": "2020-12-14T19:44:23Z", "author": {"login": "abhishekmendhekar"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -774,6 +770,23 @@ protected void preConsumerPollHook() {\n     }\n   }\n \n+  /**\n+   * Pre commit hook for all operations that need to be performed before committing offsets.\n+   */\n+  protected void preCommitHook() { }\n+\n+  /**\n+   * Post commit hook for all operations that need to be performed after committing offsets.\n+   * @param success Indicates whether the commit attempt was successful or not.\n+   */\n+  protected void postCommitHook(boolean success) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62c4c658ae95fa53ab3f9a69fa58f5ebee8c9599"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc3ODY1NQ==", "bodyText": "Since we have multiple retries for commit, caching  the last exception should be sufficient.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r542778655", "createdAt": "2020-12-14T20:59:06Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -774,6 +770,23 @@ protected void preConsumerPollHook() {\n     }\n   }\n \n+  /**\n+   * Pre commit hook for all operations that need to be performed before committing offsets.\n+   */\n+  protected void preCommitHook() { }\n+\n+  /**\n+   * Post commit hook for all operations that need to be performed after committing offsets.\n+   * @param success Indicates whether the commit attempt was successful or not.\n+   */\n+  protected void postCommitHook(boolean success) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjY5OTUyOQ=="}, "originalCommit": {"oid": "62c4c658ae95fa53ab3f9a69fa58f5ebee8c9599"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc5NzQ3NA==", "bodyText": "I'm not sure if there's value in propagating the Kafka exception up except for logging purposes, and the code in commitWithRetries already logs the exception. Do you think that there's value in propagating the last exception, @somandal?\nEdit: by up I mean in the class hierarchy.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r542797474", "createdAt": "2020-12-14T21:16:44Z", "author": {"login": "jzakaryan"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -774,6 +770,23 @@ protected void preConsumerPollHook() {\n     }\n   }\n \n+  /**\n+   * Pre commit hook for all operations that need to be performed before committing offsets.\n+   */\n+  protected void preCommitHook() { }\n+\n+  /**\n+   * Post commit hook for all operations that need to be performed after committing offsets.\n+   * @param success Indicates whether the commit attempt was successful or not.\n+   */\n+  protected void postCommitHook(boolean success) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjY5OTUyOQ=="}, "originalCommit": {"oid": "62c4c658ae95fa53ab3f9a69fa58f5ebee8c9599"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjgwMTI1OA==", "bodyText": "Right, at the moment I don't really fully see a need for the postCommitHook either, so i'm not yet clear about how the exception will help as such. I'll leave it up to you @jzakaryan to make a call on this.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r542801258", "createdAt": "2020-12-14T21:20:11Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -774,6 +770,23 @@ protected void preConsumerPollHook() {\n     }\n   }\n \n+  /**\n+   * Pre commit hook for all operations that need to be performed before committing offsets.\n+   */\n+  protected void preCommitHook() { }\n+\n+  /**\n+   * Post commit hook for all operations that need to be performed after committing offsets.\n+   * @param success Indicates whether the commit attempt was successful or not.\n+   */\n+  protected void postCommitHook(boolean success) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjY5OTUyOQ=="}, "originalCommit": {"oid": "62c4c658ae95fa53ab3f9a69fa58f5ebee8c9599"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjg5NDYyNQ==", "bodyText": "Assuming there is a set of actions that follow post commit using this hook.\ntrue/false will give a signal of commit succeed or failed but an exception can help understand why it failed. Are you saying that there are more than 1 exception thrown? Generally Kafka should send only one commit message for a given consumer group and if this method commits more than 1 CG then I suggest returning a Map<String, Exception>. This gives user the most flexibility in terms of using this API.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r542894625", "createdAt": "2020-12-14T22:49:07Z", "author": {"login": "abhishekmendhekar"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -774,6 +770,23 @@ protected void preConsumerPollHook() {\n     }\n   }\n \n+  /**\n+   * Pre commit hook for all operations that need to be performed before committing offsets.\n+   */\n+  protected void preCommitHook() { }\n+\n+  /**\n+   * Post commit hook for all operations that need to be performed after committing offsets.\n+   * @param success Indicates whether the commit attempt was successful or not.\n+   */\n+  protected void postCommitHook(boolean success) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjY5OTUyOQ=="}, "originalCommit": {"oid": "62c4c658ae95fa53ab3f9a69fa58f5ebee8c9599"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwOTc2MTM2OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxOTo0NjoxNlrOIFj39g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMDo1Nzo1NVrOIFogFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcwMTU1OA==", "bodyText": "I think the postCommitHook() should not throw the exception because if the method is overridden the derived class and it fails to implement this logic then ab exception will never be thrown.\nInstead the logic should remain the same as before and this operation can remain as a no-op.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r542701558", "createdAt": "2020-12-14T19:46:16Z", "author": {"login": "abhishekmendhekar"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -774,6 +770,23 @@ protected void preConsumerPollHook() {\n     }\n   }\n \n+  /**\n+   * Pre commit hook for all operations that need to be performed before committing offsets.\n+   */\n+  protected void preCommitHook() { }\n+\n+  /**\n+   * Post commit hook for all operations that need to be performed after committing offsets.\n+   * @param success Indicates whether the commit attempt was successful or not.\n+   */\n+  protected void postCommitHook(boolean success) {\n+    if (!success) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62c4c658ae95fa53ab3f9a69fa58f5ebee8c9599"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc3NzM2NA==", "bodyText": "+1", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r542777364", "createdAt": "2020-12-14T20:57:55Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -774,6 +770,23 @@ protected void preConsumerPollHook() {\n     }\n   }\n \n+  /**\n+   * Pre commit hook for all operations that need to be performed before committing offsets.\n+   */\n+  protected void preCommitHook() { }\n+\n+  /**\n+   * Post commit hook for all operations that need to be performed after committing offsets.\n+   * @param success Indicates whether the commit attempt was successful or not.\n+   */\n+  protected void postCommitHook(boolean success) {\n+    if (!success) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcwMTU1OA=="}, "originalCommit": {"oid": "62c4c658ae95fa53ab3f9a69fa58f5ebee8c9599"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMDUwNjg4OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMTozOTozM1rOIFrOvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMjoxMzozNFrOIFtcpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjgyMjA3OA==", "bodyText": "I think there are many other exceptions that can be thrown here, other than KafkaException. (check documentation for commitSync())\nI'd suggest adding a catch block for those exceptions too, where you just cache the exception.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r542822078", "createdAt": "2020-12-14T21:39:33Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -618,6 +621,7 @@ protected void commitWithRetries(Consumer<?, ?> consumer, Optional<Map<TopicPart\n         }\n         _logger.info(\"Commit succeeded.\");\n       } catch (KafkaException e) {\n+        lastKafkaExceptionRef.set(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20d280afce29a4a4938ca84402a3caec7cb9ed5a"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjg1ODQwNg==", "bodyText": "According to API reference, commitSync indeed throws a variety of exceptions other than KafkaException. However, I think there's a reason these exceptions are not handled here and are left to propagate up the call stack and I don't think there's a need to trigger the post-commit hook with the cached exception in this case.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r542858406", "createdAt": "2020-12-14T22:13:34Z", "author": {"login": "jzakaryan"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -618,6 +621,7 @@ protected void commitWithRetries(Consumer<?, ?> consumer, Optional<Map<TopicPart\n         }\n         _logger.info(\"Commit succeeded.\");\n       } catch (KafkaException e) {\n+        lastKafkaExceptionRef.set(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjgyMjA3OA=="}, "originalCommit": {"oid": "20d280afce29a4a4938ca84402a3caec7cb9ed5a"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNzgzODQyOnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMTowMTozNlrOIIIpPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwMDoyMDoxMVrOIJqFzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQwMTE0OA==", "bodyText": "During shutdown, if it hits KafkaException, it returns true, which does not really mean success. This can impact the postCommit hook.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r545401148", "createdAt": "2020-12-17T21:01:36Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -618,6 +621,7 @@ protected void commitWithRetries(Consumer<?, ?> consumer, Optional<Map<TopicPart\n         }\n         _logger.info(\"Commit succeeded.\");\n       } catch (KafkaException e) {\n+        lastKafkaExceptionRef.set(e);\n         if (_shutdown) {\n           _logger.info(\"Caught KafkaException in commitWithRetries while shutting down, so exiting.\", e);\n           return true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb64c11ff076a7f4c5ffde48b12e3814dead4802"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk5NzcxMA==", "bodyText": "This is no longer relevant now that post-commit hook is removed.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r546997710", "createdAt": "2020-12-22T00:20:11Z", "author": {"login": "jzakaryan"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -618,6 +621,7 @@ protected void commitWithRetries(Consumer<?, ?> consumer, Optional<Map<TopicPart\n         }\n         _logger.info(\"Commit succeeded.\");\n       } catch (KafkaException e) {\n+        lastKafkaExceptionRef.set(e);\n         if (_shutdown) {\n           _logger.info(\"Caught KafkaException in commitWithRetries while shutting down, so exiting.\", e);\n           return true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQwMTE0OA=="}, "originalCommit": {"oid": "cb64c11ff076a7f4c5ffde48b12e3814dead4802"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNzg0NDMxOnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMTowMzoyMFrOIIIsow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMTowMzoyMFrOIIIsow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQwMjAxOQ==", "bodyText": "Since, we don't have a concrete usage for this hook in open source and we currently have identified only the need for preCommit hook, will it be okay to postpone it, till either we identify the use for it or we get any pull/feature request. This will help us in avoiding an unnecessary tech debt to keep on maintaining.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r545402019", "createdAt": "2020-12-17T21:03:20Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -774,6 +780,22 @@ protected void preConsumerPollHook() {\n     }\n   }\n \n+  /**\n+   * Pre commit hook for all operations that need to be performed before committing offsets.\n+   */\n+  protected void preCommitHook() { }\n+\n+  /**\n+   * Post commit hook for all operations that need to be performed after committing offsets.\n+   * <p>\n+   *     Note: A commit attempt can be declared successful even when there's an exception. This can happen when a commit\n+   *     exception is thrown during task shutdown.\n+   * </p>\n+   * @param success Indicates whether the commit attempt was successful or not.\n+   * @param exception Exception caught during a commit attempt.\n+   */\n+  protected void postCommitHook(boolean success, KafkaException exception) { }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb64c11ff076a7f4c5ffde48b12e3814dead4802"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNzg2ODM3OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMToxMDowOVrOIII6ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwMDoyMDo0NFrOIJqGTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQwNTYyNg==", "bodyText": "If preCommitHook() threw exception, the commit will not go through. Your current use-case to have audit related drain in the preCommitHook() also adds a dependency that if there is any failure in audit, the commits will not go through. Is this really expected ? Is it possible to have the audit system throwing errors while the regular producers are working fine.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r545405626", "createdAt": "2020-12-17T21:10:09Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -608,6 +609,8 @@ protected void maybeCommitOffsetsInternal(Consumer<?, ?> consumer, boolean force\n \n   protected void commitWithRetries(Consumer<?, ?> consumer, Optional<Map<TopicPartition, OffsetAndMetadata>> offsets)\n       throws DatastreamRuntimeException {\n+    preCommitHook();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb64c11ff076a7f4c5ffde48b12e3814dead4802"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk5NzgzOQ==", "bodyText": "I made it explicit in javadoc that the overriding class needs to take care of handling exceptions from pre-commit hook.", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r546997839", "createdAt": "2020-12-22T00:20:44Z", "author": {"login": "jzakaryan"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -608,6 +609,8 @@ protected void maybeCommitOffsetsInternal(Consumer<?, ?> consumer, boolean force\n \n   protected void commitWithRetries(Consumer<?, ?> consumer, Optional<Map<TopicPartition, OffsetAndMetadata>> offsets)\n       throws DatastreamRuntimeException {\n+    preCommitHook();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQwNTYyNg=="}, "originalCommit": {"oid": "cb64c11ff076a7f4c5ffde48b12e3814dead4802"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzOTIwMzUwOnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwMToyMzoyN1rOIJrHbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQyMDozNzoxNlrOIOAPuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzAxNDUwOA==", "bodyText": "Can we remove this now that we no longer need to pass it to the postCommitHook()?", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r547014508", "createdAt": "2020-12-22T01:23:27Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -608,6 +609,8 @@ protected void maybeCommitOffsetsInternal(Consumer<?, ?> consumer, boolean force\n \n   protected void commitWithRetries(Consumer<?, ?> consumer, Optional<Map<TopicPartition, OffsetAndMetadata>> offsets)\n       throws DatastreamRuntimeException {\n+    preCommitHook();\n+    AtomicReference<KafkaException> lastKafkaExceptionRef = new AtomicReference<>(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cee0e986d31ac1437a4b1900bc43f98b7e1e86e5"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTU1NTAwMw==", "bodyText": "Done", "url": "https://github.com/linkedin/brooklin/pull/786#discussion_r551555003", "createdAt": "2021-01-04T20:37:16Z", "author": {"login": "jzakaryan"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -608,6 +609,8 @@ protected void maybeCommitOffsetsInternal(Consumer<?, ?> consumer, boolean force\n \n   protected void commitWithRetries(Consumer<?, ?> consumer, Optional<Map<TopicPartition, OffsetAndMetadata>> offsets)\n       throws DatastreamRuntimeException {\n+    preCommitHook();\n+    AtomicReference<KafkaException> lastKafkaExceptionRef = new AtomicReference<>(null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzAxNDUwOA=="}, "originalCommit": {"oid": "cee0e986d31ac1437a4b1900bc43f98b7e1e86e5"}, "originalPosition": 13}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 937, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}