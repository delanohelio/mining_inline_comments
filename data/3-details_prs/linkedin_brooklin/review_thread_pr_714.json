{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIyMDQ5NjY5", "number": 714, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMDo1NjoxNFrOD_2DQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzo1MjowNVrOEA_BkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MjcyNDQ4OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMDo1NjoxNFrOGawBRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNjoxNDozN1rOGbSkRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjkxNg==", "bodyText": "Why 10 as opposed to a single thread?", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430702916", "createdAt": "2020-05-26T20:56:14Z", "author": {"login": "ahmedahamid"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +105,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final ReentrantLock _producerLock = new ReentrantLock();\n+\n+  // An executor to spawn threads to close the producer.\n+  private final ExecutorService _producerCloseExecutorService = Executors.newFixedThreadPool(10,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzM2OA==", "bodyText": "changed to 1", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817368", "createdAt": "2020-05-27T02:05:50Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +105,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final ReentrantLock _producerLock = new ReentrantLock();\n+\n+  // An executor to spawn threads to close the producer.\n+  private final ExecutorService _producerCloseExecutorService = Executors.newFixedThreadPool(10,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjkxNg=="}, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg3NDk1Nw==", "bodyText": "newSingleThreadExecutor is slightly better. To quote the javadocs:\n\nUnlike the otherwise equivalent newFixedThreadPool(1) the returned executor is guaranteed not to be reconfigurable to use additional threads.", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430874957", "createdAt": "2020-05-27T06:01:19Z", "author": {"login": "ahmedahamid"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +105,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final ReentrantLock _producerLock = new ReentrantLock();\n+\n+  // An executor to spawn threads to close the producer.\n+  private final ExecutorService _producerCloseExecutorService = Executors.newFixedThreadPool(10,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjkxNg=="}, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI2ODkzNA==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r431268934", "createdAt": "2020-05-27T16:14:37Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +105,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final ReentrantLock _producerLock = new ReentrantLock();\n+\n+  // An executor to spawn threads to close the producer.\n+  private final ExecutorService _producerCloseExecutorService = Executors.newFixedThreadPool(10,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjkxNg=="}, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MjczMjU5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMDo1ODo1MFrOGawGeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjowNTo0MlrOGa3AQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNDI1MA==", "bodyText": "Since we're not using any of ReentrantLock's advanced capabilities, I'd recommend just defining an Object and locking it using synchronized blocks; they're easier to read, do not require try/finally blocks, do not require separate lock/unlock statements, the lock/unlock are lexically defined with a block scope, are also reentrant, and are generally simpler.", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430704250", "createdAt": "2020-05-26T20:58:50Z", "author": {"login": "ahmedahamid"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +105,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final ReentrantLock _producerLock = new ReentrantLock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzM0NQ==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817345", "createdAt": "2020-05-27T02:05:42Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +105,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final ReentrantLock _producerLock = new ReentrantLock();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNDI1MA=="}, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mjc0MjE2OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowMjowOVrOGawM3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjowNTo1NlrOGa3Afg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNTg4NQ==", "bodyText": "Do you think it would be better to move this javadoc inside the method? It's slightly confusing now since it could be misinterpreted to mean a lock has to be acquired before this method is called.", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430705885", "createdAt": "2020-05-26T21:02:09Z", "author": {"login": "ahmedahamid"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -163,22 +177,27 @@ int getTasksSize() {\n   }\n \n   /**\n-   * Must be synchronized to avoid creating duplicate producers when multiple concurrent\n+   * Must be protected by a lock to avoid creating duplicate producers when multiple concurrent\n    * sends are in-flight and _kafkaProducer has been set to null as a result of previous\n    * producer exception.\n    */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzQwNg==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817406", "createdAt": "2020-05-27T02:05:56Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -163,22 +177,27 @@ int getTasksSize() {\n   }\n \n   /**\n-   * Must be synchronized to avoid creating duplicate producers when multiple concurrent\n+   * Must be protected by a lock to avoid creating duplicate producers when multiple concurrent\n    * sends are in-flight and _kafkaProducer has been set to null as a result of previous\n    * producer exception.\n    */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNTg4NQ=="}, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4Mjc2MTk3OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMTowOTowNFrOGawZXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjowNjowMlrOGa3AmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwOTA4Nw==", "bodyText": "If it may be come in handy during debugging and isn't produced too frequently, it may not be such a bad idea to turn the two debug logs within this block to info instead. I don't have as much experience as you do with these logs though.", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430709087", "createdAt": "2020-05-26T21:09:04Z", "author": {"login": "ahmedahamid"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -221,61 +240,87 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n         // Set a max_send_attempts for KafkaException as it may be non-recoverable\n         if (numberOfAttempt > MAX_SEND_ATTEMPTS || ((cause instanceof Error || cause instanceof RuntimeException))) {\n-          _log.error(\"Send failed for partition {} with a non retriable exception\", producerRecord.partition(), e);\n+          _log.error(String.format(\"Send failed for partition %d with a non-retriable exception\",\n+              producerRecord.partition()), e);\n           throw generateSendFailure(e);\n         } else {\n-          _log.warn(\"Send failed for partition {} with retriable exception, retry {} out of {} in {} ms.\",\n-              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs, e);\n+          _log.warn(String.format(\n+              \"Send failed for partition %d with a retriable exception, retry %d out of %d in %d ms.\",\n+              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs), e);\n           Thread.sleep(_sendFailureRetryWaitTimeMs);\n         }\n       } catch (Exception e) {\n-        _log.error(\"Send failed for partition {} with an exception\", producerRecord.partition(), e);\n+        _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n         throw generateSendFailure(e);\n       }\n     }\n   }\n \n-  private synchronized void shutdownProducer() {\n-    Producer<K, V> producer = _kafkaProducer;\n-    // Nullify first to prevent subsequent send() to use\n-    // the current producer which is being shutdown.\n-    _kafkaProducer = null;\n+  @VisibleForTesting\n+  void shutdownProducer() {\n+    Producer<K, V> producer;\n+    _producerLock.lock();\n+    try {\n+      producer = _kafkaProducer;\n+      // Nullify first to prevent subsequent send() to use\n+      // the current producer which is being shutdown.\n+      _kafkaProducer = null;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+    // thread\n     if (producer != null) {\n-      producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n-      NUM_PRODUCERS.decrementAndGet();\n+      _producerCloseExecutorService.submit(() -> {\n+        _log.debug(\"KafkaProducerWrapper: Closing the Kafka Producer\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzQzMg==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817432", "createdAt": "2020-05-27T02:06:02Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -221,61 +240,87 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n         // Set a max_send_attempts for KafkaException as it may be non-recoverable\n         if (numberOfAttempt > MAX_SEND_ATTEMPTS || ((cause instanceof Error || cause instanceof RuntimeException))) {\n-          _log.error(\"Send failed for partition {} with a non retriable exception\", producerRecord.partition(), e);\n+          _log.error(String.format(\"Send failed for partition %d with a non-retriable exception\",\n+              producerRecord.partition()), e);\n           throw generateSendFailure(e);\n         } else {\n-          _log.warn(\"Send failed for partition {} with retriable exception, retry {} out of {} in {} ms.\",\n-              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs, e);\n+          _log.warn(String.format(\n+              \"Send failed for partition %d with a retriable exception, retry %d out of %d in %d ms.\",\n+              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs), e);\n           Thread.sleep(_sendFailureRetryWaitTimeMs);\n         }\n       } catch (Exception e) {\n-        _log.error(\"Send failed for partition {} with an exception\", producerRecord.partition(), e);\n+        _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n         throw generateSendFailure(e);\n       }\n     }\n   }\n \n-  private synchronized void shutdownProducer() {\n-    Producer<K, V> producer = _kafkaProducer;\n-    // Nullify first to prevent subsequent send() to use\n-    // the current producer which is being shutdown.\n-    _kafkaProducer = null;\n+  @VisibleForTesting\n+  void shutdownProducer() {\n+    Producer<K, V> producer;\n+    _producerLock.lock();\n+    try {\n+      producer = _kafkaProducer;\n+      // Nullify first to prevent subsequent send() to use\n+      // the current producer which is being shutdown.\n+      _kafkaProducer = null;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+    // thread\n     if (producer != null) {\n-      producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n-      NUM_PRODUCERS.decrementAndGet();\n+      _producerCloseExecutorService.submit(() -> {\n+        _log.debug(\"KafkaProducerWrapper: Closing the Kafka Producer\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwOTA4Nw=="}, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 160}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MzA4NjI3OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMzoyNjowOFrOGazk3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjowNjo0M1rOGa3BIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2MTE4Mg==", "bodyText": "Please, feel free to ignore this comment.\nI generally dislike polling in tests for several reasons. I'll just mention the most relevant ones here:\n\nIt's a source of flakiness (I know you used a timeout of 10s for that reason)\nWhen we do verifyClose(0), count == numExpected will return true immediately, a racey behavior that does not affect this test because it has a subsequent assertion that verifies shutdownProducer() itself hasn't been called.\nAssert.assertEquals(_numShutdownProducerCalls, numExpected)\nbut this begs the question: do we have to assert on _mockProducer.produce() in the first place?", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430761182", "createdAt": "2020-05-26T23:26:08Z", "author": {"login": "ahmedahamid"}, "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "diffHunk": "@@ -141,8 +153,17 @@ void verifyFlush(int numExpected) {\n       verify(_mockProducer, times(numExpected)).flush();\n     }\n \n-    void verifyClose(int numExpected) {\n+    void verifyClose(int numExpected) throws NoSuchMethodException {\n+      // Producer close is invoked in a separate thread. Must wait for the thread to get scheduled and call close\n+      Method method = Producer.class.getMethod(\"close\", long.class, TimeUnit.class);\n+      PollUtils.poll(() -> {\n+        Collection<Invocation> invocations = mockingDetails(_mockProducer).getInvocations();\n+        long count = invocations.stream().filter(invocation -> invocation.getMethod().equals(method)).count();\n+        return count == numExpected;\n+      }, 1000, 10000);\n       verify(_mockProducer, times(numExpected)).close(anyLong(), any(TimeUnit.class));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzU3MA==", "bodyText": "As discussed offline, it does make sense to leave this as is since we want to test both that shutdownProducer is called and that mockProducer's close() is called.", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817570", "createdAt": "2020-05-27T02:06:43Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "diffHunk": "@@ -141,8 +153,17 @@ void verifyFlush(int numExpected) {\n       verify(_mockProducer, times(numExpected)).flush();\n     }\n \n-    void verifyClose(int numExpected) {\n+    void verifyClose(int numExpected) throws NoSuchMethodException {\n+      // Producer close is invoked in a separate thread. Must wait for the thread to get scheduled and call close\n+      Method method = Producer.class.getMethod(\"close\", long.class, TimeUnit.class);\n+      PollUtils.poll(() -> {\n+        Collection<Invocation> invocations = mockingDetails(_mockProducer).getInvocations();\n+        long count = invocations.stream().filter(invocation -> invocation.getMethod().equals(method)).count();\n+        return count == numExpected;\n+      }, 1000, 10000);\n       verify(_mockProducer, times(numExpected)).close(anyLong(), any(TimeUnit.class));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2MTE4Mg=="}, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MzA5NDI5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMzozMDoyOVrOGazp8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QwMjowNzowNlrOGa3Bfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2MjQ4MA==", "bodyText": "Unlike the other two verify*() methods, this one resets its call count (_numShutdownProducerCalls). This is a little confusing because the call counts passed to the other methods in testFlushInterrupt() are all cumulative.", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430762480", "createdAt": "2020-05-26T23:30:29Z", "author": {"login": "ahmedahamid"}, "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "diffHunk": "@@ -141,8 +153,17 @@ void verifyFlush(int numExpected) {\n       verify(_mockProducer, times(numExpected)).flush();\n     }\n \n-    void verifyClose(int numExpected) {\n+    void verifyClose(int numExpected) throws NoSuchMethodException {\n+      // Producer close is invoked in a separate thread. Must wait for the thread to get scheduled and call close\n+      Method method = Producer.class.getMethod(\"close\", long.class, TimeUnit.class);\n+      PollUtils.poll(() -> {\n+        Collection<Invocation> invocations = mockingDetails(_mockProducer).getInvocations();\n+        long count = invocations.stream().filter(invocation -> invocation.getMethod().equals(method)).count();\n+        return count == numExpected;\n+      }, 1000, 10000);\n       verify(_mockProducer, times(numExpected)).close(anyLong(), any(TimeUnit.class));\n+      Assert.assertEquals(_numShutdownProducerCalls, numExpected);\n+      _numShutdownProducerCalls = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzY2Mw==", "bodyText": "As discussed offline, leaving this as is since mockProducers can be created and removed during the test", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817663", "createdAt": "2020-05-27T02:07:06Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "diffHunk": "@@ -141,8 +153,17 @@ void verifyFlush(int numExpected) {\n       verify(_mockProducer, times(numExpected)).flush();\n     }\n \n-    void verifyClose(int numExpected) {\n+    void verifyClose(int numExpected) throws NoSuchMethodException {\n+      // Producer close is invoked in a separate thread. Must wait for the thread to get scheduled and call close\n+      Method method = Producer.class.getMethod(\"close\", long.class, TimeUnit.class);\n+      PollUtils.poll(() -> {\n+        Collection<Invocation> invocations = mockingDetails(_mockProducer).getInvocations();\n+        long count = invocations.stream().filter(invocation -> invocation.getMethod().equals(method)).count();\n+        return count == numExpected;\n+      }, 1000, 10000);\n       verify(_mockProducer, times(numExpected)).close(anyLong(), any(TimeUnit.class));\n+      Assert.assertEquals(_numShutdownProducerCalls, numExpected);\n+      _numShutdownProducerCalls = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2MjQ4MA=="}, "originalCommit": {"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDE2NDA4OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNToyNDowNVrOGchZzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxODowNToxM1rOGcm9yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjU2MDU5MQ==", "bodyText": "nit: not sure why this method called generateSendFailure. Should this be renamed to handleSendFailure?", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432560591", "createdAt": "2020-05-29T15:24:05Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -221,47 +234,63 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n         // Set a max_send_attempts for KafkaException as it may be non-recoverable\n         if (numberOfAttempt > MAX_SEND_ATTEMPTS || ((cause instanceof Error || cause instanceof RuntimeException))) {\n-          _log.error(\"Send failed for partition {} with a non retriable exception\", producerRecord.partition(), e);\n+          _log.error(String.format(\"Send failed for partition %d with a non-retriable exception\",\n+              producerRecord.partition()), e);\n           throw generateSendFailure(e);\n         } else {\n-          _log.warn(\"Send failed for partition {} with retriable exception, retry {} out of {} in {} ms.\",\n-              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs, e);\n+          _log.warn(String.format(\n+              \"Send failed for partition %d with a retriable exception, retry %d out of %d in %d ms.\",\n+              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs), e);\n           Thread.sleep(_sendFailureRetryWaitTimeMs);\n         }\n       } catch (Exception e) {\n-        _log.error(\"Send failed for partition {} with an exception\", producerRecord.partition(), e);\n+        _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n         throw generateSendFailure(e);\n       }\n     }\n   }\n \n-  private synchronized void shutdownProducer() {\n-    Producer<K, V> producer = _kafkaProducer;\n-    // Nullify first to prevent subsequent send() to use\n-    // the current producer which is being shutdown.\n-    _kafkaProducer = null;\n+  @VisibleForTesting\n+  void shutdownProducer() {\n+    Producer<K, V> producer;\n+    synchronized (_producerLock) {\n+      producer = _kafkaProducer;\n+      // Nullify first to prevent subsequent send() to use\n+      // the current producer which is being shutdown.\n+      _kafkaProducer = null;\n+    }\n+\n+    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+    // thread\n     if (producer != null) {\n-      producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n-      NUM_PRODUCERS.decrementAndGet();\n+      _producerCloseExecutorService.submit(() -> {\n+        _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n+        producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n+        NUM_PRODUCERS.decrementAndGet();\n+        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+      });\n     }\n   }\n \n   private DatastreamRuntimeException generateSendFailure(Exception exception) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MTcyMg==", "bodyText": "Went back and forth in my head on this. throws handleSendFailure looks very weird to me. So leaving this as is.", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432651722", "createdAt": "2020-05-29T18:05:13Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -221,47 +234,63 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n         // Set a max_send_attempts for KafkaException as it may be non-recoverable\n         if (numberOfAttempt > MAX_SEND_ATTEMPTS || ((cause instanceof Error || cause instanceof RuntimeException))) {\n-          _log.error(\"Send failed for partition {} with a non retriable exception\", producerRecord.partition(), e);\n+          _log.error(String.format(\"Send failed for partition %d with a non-retriable exception\",\n+              producerRecord.partition()), e);\n           throw generateSendFailure(e);\n         } else {\n-          _log.warn(\"Send failed for partition {} with retriable exception, retry {} out of {} in {} ms.\",\n-              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs, e);\n+          _log.warn(String.format(\n+              \"Send failed for partition %d with a retriable exception, retry %d out of %d in %d ms.\",\n+              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs), e);\n           Thread.sleep(_sendFailureRetryWaitTimeMs);\n         }\n       } catch (Exception e) {\n-        _log.error(\"Send failed for partition {} with an exception\", producerRecord.partition(), e);\n+        _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n         throw generateSendFailure(e);\n       }\n     }\n   }\n \n-  private synchronized void shutdownProducer() {\n-    Producer<K, V> producer = _kafkaProducer;\n-    // Nullify first to prevent subsequent send() to use\n-    // the current producer which is being shutdown.\n-    _kafkaProducer = null;\n+  @VisibleForTesting\n+  void shutdownProducer() {\n+    Producer<K, V> producer;\n+    synchronized (_producerLock) {\n+      producer = _kafkaProducer;\n+      // Nullify first to prevent subsequent send() to use\n+      // the current producer which is being shutdown.\n+      _kafkaProducer = null;\n+    }\n+\n+    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+    // thread\n     if (producer != null) {\n-      producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n-      NUM_PRODUCERS.decrementAndGet();\n+      _producerCloseExecutorService.submit(() -> {\n+        _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n+        producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n+        NUM_PRODUCERS.decrementAndGet();\n+        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+      });\n     }\n   }\n \n   private DatastreamRuntimeException generateSendFailure(Exception exception) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjU2MDU5MQ=="}, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 162}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDYzNDgzOnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzozNzozMFrOGcmHBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxODowMjo1OVrOGcm5rA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzNzcwMQ==", "bodyText": "nit: A lock used to \"synchronize\" access to", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432637701", "createdAt": "2020-05-29T17:37:30Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +104,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MDY2OA==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432650668", "createdAt": "2020-05-29T18:02:59Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +104,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzNzcwMQ=="}, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDY0MTM3OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzozOTo0NFrOGcmLTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxODowNDozOFrOGcm8wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzODc5Ng==", "bodyText": "I am guessing we can now use setName API instead without the %d format since you changed to singleThreadExecutor?", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432638796", "createdAt": "2020-05-29T17:39:44Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +104,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final Object _producerLock = new Object();\n+\n+  // An executor to spawn threads to close the producer.\n+  private final ExecutorService _producerCloseExecutorService = Executors.newSingleThreadExecutor(\n+      new ThreadFactoryBuilder().setNameFormat(\"KafkaProducerWrapperClose-%d\").build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MTQ1OA==", "bodyText": "as discussed, there is no setName API for the  ThreadFactoryBuilder,  so leaving this as is.", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432651458", "createdAt": "2020-05-29T18:04:38Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +104,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final Object _producerLock = new Object();\n+\n+  // An executor to spawn threads to close the producer.\n+  private final ExecutorService _producerCloseExecutorService = Executors.newSingleThreadExecutor(\n+      new ThreadFactoryBuilder().setNameFormat(\"KafkaProducerWrapperClose-%d\").build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzODc5Ng=="}, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDY0NjAyOnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzo0MDo1OVrOGcmOIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxODowNDo0M1rOGcm86g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzOTUyMA==", "bodyText": "nit: Should we use StringUtils ?", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432639520", "createdAt": "2020-05-29T17:40:59Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -117,7 +130,7 @@\n \n     _clientId = transportProviderProperties.getProperty(ProducerConfig.CLIENT_ID_CONFIG);\n     if (_clientId == null || _clientId.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MTQ5OA==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432651498", "createdAt": "2020-05-29T18:04:43Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -117,7 +130,7 @@\n \n     _clientId = transportProviderProperties.getProperty(ProducerConfig.CLIENT_ID_CONFIG);\n     if (_clientId == null || _clientId.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzOTUyMA=="}, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDY4MDQ5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzo1MjowNVrOGcmkiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxODowNjozN1rOGcnAWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY0NTI1Ng==", "bodyText": "nit: should this read: \"send failed with a non-transient exception. Shutting down producer\" to match what is being done in the method.", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432645256", "createdAt": "2020-05-29T17:52:05Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -221,47 +234,63 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n         // Set a max_send_attempts for KafkaException as it may be non-recoverable\n         if (numberOfAttempt > MAX_SEND_ATTEMPTS || ((cause instanceof Error || cause instanceof RuntimeException))) {\n-          _log.error(\"Send failed for partition {} with a non retriable exception\", producerRecord.partition(), e);\n+          _log.error(String.format(\"Send failed for partition %d with a non-retriable exception\",\n+              producerRecord.partition()), e);\n           throw generateSendFailure(e);\n         } else {\n-          _log.warn(\"Send failed for partition {} with retriable exception, retry {} out of {} in {} ms.\",\n-              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs, e);\n+          _log.warn(String.format(\n+              \"Send failed for partition %d with a retriable exception, retry %d out of %d in %d ms.\",\n+              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs), e);\n           Thread.sleep(_sendFailureRetryWaitTimeMs);\n         }\n       } catch (Exception e) {\n-        _log.error(\"Send failed for partition {} with an exception\", producerRecord.partition(), e);\n+        _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n         throw generateSendFailure(e);\n       }\n     }\n   }\n \n-  private synchronized void shutdownProducer() {\n-    Producer<K, V> producer = _kafkaProducer;\n-    // Nullify first to prevent subsequent send() to use\n-    // the current producer which is being shutdown.\n-    _kafkaProducer = null;\n+  @VisibleForTesting\n+  void shutdownProducer() {\n+    Producer<K, V> producer;\n+    synchronized (_producerLock) {\n+      producer = _kafkaProducer;\n+      // Nullify first to prevent subsequent send() to use\n+      // the current producer which is being shutdown.\n+      _kafkaProducer = null;\n+    }\n+\n+    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+    // thread\n     if (producer != null) {\n-      producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n-      NUM_PRODUCERS.decrementAndGet();\n+      _producerCloseExecutorService.submit(() -> {\n+        _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n+        producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n+        NUM_PRODUCERS.decrementAndGet();\n+        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+      });\n     }\n   }\n \n   private DatastreamRuntimeException generateSendFailure(Exception exception) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n-      _log.warn(\"sent failure transiently, exception: \", exception);\n+      _log.warn(\"send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n-      _log.warn(\"sent failure, restart producer, exception: \", exception);\n+      _log.warn(\"send failed, restart producer, exception: \", exception);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MjM3Nw==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432652377", "createdAt": "2020-05-29T18:06:37Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -221,47 +234,63 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n         // Set a max_send_attempts for KafkaException as it may be non-recoverable\n         if (numberOfAttempt > MAX_SEND_ATTEMPTS || ((cause instanceof Error || cause instanceof RuntimeException))) {\n-          _log.error(\"Send failed for partition {} with a non retriable exception\", producerRecord.partition(), e);\n+          _log.error(String.format(\"Send failed for partition %d with a non-retriable exception\",\n+              producerRecord.partition()), e);\n           throw generateSendFailure(e);\n         } else {\n-          _log.warn(\"Send failed for partition {} with retriable exception, retry {} out of {} in {} ms.\",\n-              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs, e);\n+          _log.warn(String.format(\n+              \"Send failed for partition %d with a retriable exception, retry %d out of %d in %d ms.\",\n+              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs), e);\n           Thread.sleep(_sendFailureRetryWaitTimeMs);\n         }\n       } catch (Exception e) {\n-        _log.error(\"Send failed for partition {} with an exception\", producerRecord.partition(), e);\n+        _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n         throw generateSendFailure(e);\n       }\n     }\n   }\n \n-  private synchronized void shutdownProducer() {\n-    Producer<K, V> producer = _kafkaProducer;\n-    // Nullify first to prevent subsequent send() to use\n-    // the current producer which is being shutdown.\n-    _kafkaProducer = null;\n+  @VisibleForTesting\n+  void shutdownProducer() {\n+    Producer<K, V> producer;\n+    synchronized (_producerLock) {\n+      producer = _kafkaProducer;\n+      // Nullify first to prevent subsequent send() to use\n+      // the current producer which is being shutdown.\n+      _kafkaProducer = null;\n+    }\n+\n+    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+    // thread\n     if (producer != null) {\n-      producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n-      NUM_PRODUCERS.decrementAndGet();\n+      _producerCloseExecutorService.submit(() -> {\n+        _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n+        producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n+        NUM_PRODUCERS.decrementAndGet();\n+        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+      });\n     }\n   }\n \n   private DatastreamRuntimeException generateSendFailure(Exception exception) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n-      _log.warn(\"sent failure transiently, exception: \", exception);\n+      _log.warn(\"send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n-      _log.warn(\"sent failure, restart producer, exception: \", exception);\n+      _log.warn(\"send failed, restart producer, exception: \", exception);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY0NTI1Ng=="}, "originalCommit": {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485"}, "originalPosition": 170}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1004, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}