{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUzODg3MDUw", "number": 732, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzoyMjozNlrOERQLNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNjowNjoyNVrOER4Xug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTI2MjYwOnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzoyMjozNlrOG13jnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxODozNDoyN1rOG2WxbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzNzk0OA==", "bodyText": "This patch LGTM. Any reason, you want to convert this to a String and not use it as it is?", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r459137948", "createdAt": "2020-07-22T23:22:36Z", "author": {"login": "MayureshGharat"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -241,6 +244,16 @@ protected DatastreamProducerRecord translate(ConsumerRecord<?, ?> fromKafka, Ins\n     String offsetStr = String.valueOf(offset);\n     metadata.put(KAFKA_ORIGIN_OFFSET, offsetStr);\n     metadata.put(BrooklinEnvelopeMetadataConstants.EVENT_TIMESTAMP, String.valueOf(eventsSourceTimestamp));\n+    if (Boolean.TRUE.toString()\n+        .equals(_datastream.getMetadata().get(KafkaDatastreamMetadataConstants.USE_PASSTHROUGH_COMPRESSION))) {\n+      // If passthrough mode is enabled, we need to create a Kafka header on the transport side for supporting\n+      // Kafka broker message format bump. The magic byte contains details about the message format for the passthrough\n+      // record and it needs to be preserved and set via the Kafka headers to ensure that the correct message format\n+      // can be negotiated.\n+      PassThroughConsumerRecord<?, ?> passThroughConsumerRecord = (PassThroughConsumerRecord<?, ?>) fromKafka;\n+      metadata.put(KafkaPassthroughRecordMagicConverter.PASS_THROUGH_MAGIC_VALUE,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzOTYwOA==", "bodyText": "@MayureshGharat we convert the ConsumerRecord to a DatastreamProducerRecord, and DatastreamProdcuerRecord has a list  of BrooklinEnvelope. BrooklinEnvelope has a generic field which stores all \"metadata\" and is a Map<String, String> . If I didn't convert the magic to String to store in this generic \"metadata\", I'd have to introduce a new field to store the magic as a byte. Which isn't a bad option, but this will only be used by BMM passthrough.\n@DEEPTHIKORAT and @jzakaryan can you folks also comment on whether using \"metadata\" and doing string conversion makes more sense, or it's okay to introduce this byte field to store the magic? The only use case would be BMM passthrough.", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r459139608", "createdAt": "2020-07-22T23:27:50Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -241,6 +244,16 @@ protected DatastreamProducerRecord translate(ConsumerRecord<?, ?> fromKafka, Ins\n     String offsetStr = String.valueOf(offset);\n     metadata.put(KAFKA_ORIGIN_OFFSET, offsetStr);\n     metadata.put(BrooklinEnvelopeMetadataConstants.EVENT_TIMESTAMP, String.valueOf(eventsSourceTimestamp));\n+    if (Boolean.TRUE.toString()\n+        .equals(_datastream.getMetadata().get(KafkaDatastreamMetadataConstants.USE_PASSTHROUGH_COMPRESSION))) {\n+      // If passthrough mode is enabled, we need to create a Kafka header on the transport side for supporting\n+      // Kafka broker message format bump. The magic byte contains details about the message format for the passthrough\n+      // record and it needs to be preserved and set via the Kafka headers to ensure that the correct message format\n+      // can be negotiated.\n+      PassThroughConsumerRecord<?, ?> passThroughConsumerRecord = (PassThroughConsumerRecord<?, ?>) fromKafka;\n+      metadata.put(KafkaPassthroughRecordMagicConverter.PASS_THROUGH_MAGIC_VALUE,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzNzk0OA=="}, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTYyMDU0MQ==", "bodyText": "Here's my two cents. @somandal I wouldn't introduce a \"magic\" byte as a separate field, because it only makes sense in the scope of BMM passthrough, and it would be useless and confusing out of that limited scope.\nThe only precaution with the current approach would be the conversion overhead, but since it's just being done once for a batch, it should be fine.", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r459620541", "createdAt": "2020-07-23T17:43:36Z", "author": {"login": "jzakaryan"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -241,6 +244,16 @@ protected DatastreamProducerRecord translate(ConsumerRecord<?, ?> fromKafka, Ins\n     String offsetStr = String.valueOf(offset);\n     metadata.put(KAFKA_ORIGIN_OFFSET, offsetStr);\n     metadata.put(BrooklinEnvelopeMetadataConstants.EVENT_TIMESTAMP, String.valueOf(eventsSourceTimestamp));\n+    if (Boolean.TRUE.toString()\n+        .equals(_datastream.getMetadata().get(KafkaDatastreamMetadataConstants.USE_PASSTHROUGH_COMPRESSION))) {\n+      // If passthrough mode is enabled, we need to create a Kafka header on the transport side for supporting\n+      // Kafka broker message format bump. The magic byte contains details about the message format for the passthrough\n+      // record and it needs to be preserved and set via the Kafka headers to ensure that the correct message format\n+      // can be negotiated.\n+      PassThroughConsumerRecord<?, ?> passThroughConsumerRecord = (PassThroughConsumerRecord<?, ?>) fromKafka;\n+      metadata.put(KafkaPassthroughRecordMagicConverter.PASS_THROUGH_MAGIC_VALUE,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzNzk0OA=="}, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY0OTM4OA==", "bodyText": "@jzakaryan thank you!", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r459649388", "createdAt": "2020-07-23T18:34:27Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -241,6 +244,16 @@ protected DatastreamProducerRecord translate(ConsumerRecord<?, ?> fromKafka, Ins\n     String offsetStr = String.valueOf(offset);\n     metadata.put(KAFKA_ORIGIN_OFFSET, offsetStr);\n     metadata.put(BrooklinEnvelopeMetadataConstants.EVENT_TIMESTAMP, String.valueOf(eventsSourceTimestamp));\n+    if (Boolean.TRUE.toString()\n+        .equals(_datastream.getMetadata().get(KafkaDatastreamMetadataConstants.USE_PASSTHROUGH_COMPRESSION))) {\n+      // If passthrough mode is enabled, we need to create a Kafka header on the transport side for supporting\n+      // Kafka broker message format bump. The magic byte contains details about the message format for the passthrough\n+      // record and it needs to be preserved and set via the Kafka headers to ensure that the correct message format\n+      // can be negotiated.\n+      PassThroughConsumerRecord<?, ?> passThroughConsumerRecord = (PassThroughConsumerRecord<?, ?>) fromKafka;\n+      metadata.put(KafkaPassthroughRecordMagicConverter.PASS_THROUGH_MAGIC_VALUE,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzNzk0OA=="}, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MDMyODgwOnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwODoxMzozN1rOG2mz6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNjozNToyMFrOG22IrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTkxMjE3MA==", "bodyText": "nit: would it make sense to have a member field for isPassThrough to avoid checking this for each translate?", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r459912170", "createdAt": "2020-07-24T08:13:37Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -241,6 +244,16 @@ protected DatastreamProducerRecord translate(ConsumerRecord<?, ?> fromKafka, Ins\n     String offsetStr = String.valueOf(offset);\n     metadata.put(KAFKA_ORIGIN_OFFSET, offsetStr);\n     metadata.put(BrooklinEnvelopeMetadataConstants.EVENT_TIMESTAMP, String.valueOf(eventsSourceTimestamp));\n+    if (Boolean.TRUE.toString()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2MzI0NA==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r460163244", "createdAt": "2020-07-24T16:35:20Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -241,6 +244,16 @@ protected DatastreamProducerRecord translate(ConsumerRecord<?, ?> fromKafka, Ins\n     String offsetStr = String.valueOf(offset);\n     metadata.put(KAFKA_ORIGIN_OFFSET, offsetStr);\n     metadata.put(BrooklinEnvelopeMetadataConstants.EVENT_TIMESTAMP, String.valueOf(eventsSourceTimestamp));\n+    if (Boolean.TRUE.toString()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTkxMjE3MA=="}, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MTcyNjQ0OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaPassthroughRecordMagicConverter.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNTozMzo0MVrOG20Bqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNjozNTo0M1rOG22Jhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEyODY4Mg==", "bodyText": "Can it return a single byte instead? since we are using ISO-8 we can be sure not to get multiple bytes. Makes the APIs look consistent in the encode and decode with taking 1 byte and returning 1 byte.", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r460128682", "createdAt": "2020-07-24T15:33:41Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaPassthroughRecordMagicConverter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/**\n+ *  Copyright 2020 LinkedIn Corporation. All rights reserved.\n+ *  Licensed under the BSD 2-Clause License. See the LICENSE file in the project root for license information.\n+ *  See the NOTICE file in the project root for additional information regarding copyright ownership.\n+ */\n+package com.linkedin.datastream.kafka;\n+\n+import java.io.UnsupportedEncodingException;\n+\n+import org.apache.kafka.common.header.internals.RecordHeader;\n+import org.apache.kafka.common.header.internals.RecordHeaders;\n+\n+import com.linkedin.datastream.common.DatastreamRuntimeException;\n+\n+\n+/**\n+ * This class is a utility class to convert the PassthroughConsumerRecord's magic() to a String, and back into byte.\n+ * It also adds a utility to create the RecordHeaders which can be used to pass headers with the magic set to the\n+ * ProducerRecord for passthrough message format bump support.\n+ */\n+public class KafkaPassthroughRecordMagicConverter {\n+  private static final String CHARSET = \"ISO-8859-1\";\n+\n+  public static final String PASS_THROUGH_MAGIC_VALUE = \"__passThroughMagicValue\";\n+\n+  /**\n+   * Convert the magic byte of the PassthroughConsumerRecord to a String\n+   */\n+  public static String convertMagicToString(byte magic) {\n+    try {\n+      return new String(new byte[] { magic }, CHARSET);\n+    } catch (UnsupportedEncodingException e) {\n+      throw new DatastreamRuntimeException(String.format(\"Cannot convert magic byte %02X to String\", magic), e);\n+    }\n+  }\n+\n+  /**\n+   * Convert the converted magic String back into a byte array\n+   */\n+  public static byte[] convertMagicStringToByteArray(String magic) {\n+    try {\n+      return magic.getBytes(CHARSET);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzcwMw==", "bodyText": "oh nvm, looks like RecordHeader does require a byte array.", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r460133703", "createdAt": "2020-07-24T15:42:15Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaPassthroughRecordMagicConverter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/**\n+ *  Copyright 2020 LinkedIn Corporation. All rights reserved.\n+ *  Licensed under the BSD 2-Clause License. See the LICENSE file in the project root for license information.\n+ *  See the NOTICE file in the project root for additional information regarding copyright ownership.\n+ */\n+package com.linkedin.datastream.kafka;\n+\n+import java.io.UnsupportedEncodingException;\n+\n+import org.apache.kafka.common.header.internals.RecordHeader;\n+import org.apache.kafka.common.header.internals.RecordHeaders;\n+\n+import com.linkedin.datastream.common.DatastreamRuntimeException;\n+\n+\n+/**\n+ * This class is a utility class to convert the PassthroughConsumerRecord's magic() to a String, and back into byte.\n+ * It also adds a utility to create the RecordHeaders which can be used to pass headers with the magic set to the\n+ * ProducerRecord for passthrough message format bump support.\n+ */\n+public class KafkaPassthroughRecordMagicConverter {\n+  private static final String CHARSET = \"ISO-8859-1\";\n+\n+  public static final String PASS_THROUGH_MAGIC_VALUE = \"__passThroughMagicValue\";\n+\n+  /**\n+   * Convert the magic byte of the PassthroughConsumerRecord to a String\n+   */\n+  public static String convertMagicToString(byte magic) {\n+    try {\n+      return new String(new byte[] { magic }, CHARSET);\n+    } catch (UnsupportedEncodingException e) {\n+      throw new DatastreamRuntimeException(String.format(\"Cannot convert magic byte %02X to String\", magic), e);\n+    }\n+  }\n+\n+  /**\n+   * Convert the converted magic String back into a byte array\n+   */\n+  public static byte[] convertMagicStringToByteArray(String magic) {\n+    try {\n+      return magic.getBytes(CHARSET);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEyODY4Mg=="}, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2MzQ2Mg==", "bodyText": "yeah, that's why I decided to return a byte[] instead of byte.", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r460163462", "createdAt": "2020-07-24T16:35:43Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaPassthroughRecordMagicConverter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/**\n+ *  Copyright 2020 LinkedIn Corporation. All rights reserved.\n+ *  Licensed under the BSD 2-Clause License. See the LICENSE file in the project root for license information.\n+ *  See the NOTICE file in the project root for additional information regarding copyright ownership.\n+ */\n+package com.linkedin.datastream.kafka;\n+\n+import java.io.UnsupportedEncodingException;\n+\n+import org.apache.kafka.common.header.internals.RecordHeader;\n+import org.apache.kafka.common.header.internals.RecordHeaders;\n+\n+import com.linkedin.datastream.common.DatastreamRuntimeException;\n+\n+\n+/**\n+ * This class is a utility class to convert the PassthroughConsumerRecord's magic() to a String, and back into byte.\n+ * It also adds a utility to create the RecordHeaders which can be used to pass headers with the magic set to the\n+ * ProducerRecord for passthrough message format bump support.\n+ */\n+public class KafkaPassthroughRecordMagicConverter {\n+  private static final String CHARSET = \"ISO-8859-1\";\n+\n+  public static final String PASS_THROUGH_MAGIC_VALUE = \"__passThroughMagicValue\";\n+\n+  /**\n+   * Convert the magic byte of the PassthroughConsumerRecord to a String\n+   */\n+  public static String convertMagicToString(byte magic) {\n+    try {\n+      return new String(new byte[] { magic }, CHARSET);\n+    } catch (UnsupportedEncodingException e) {\n+      throw new DatastreamRuntimeException(String.format(\"Cannot convert magic byte %02X to String\", magic), e);\n+    }\n+  }\n+\n+  /**\n+   * Convert the converted magic String back into a byte array\n+   */\n+  public static byte[] convertMagicStringToByteArray(String magic) {\n+    try {\n+      return magic.getBytes(CHARSET);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEyODY4Mg=="}, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MTg0ODI2OnYy", "diffSide": "RIGHT", "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaPassthroughRecordMagicConverter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNjowNjoyNVrOG21MzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNjozNTo1MFrOG22Jsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE0NzkxNw==", "bodyText": "nit and feel free to ignore, but the test might read better as a for loop iterating over all possibly magic byte values.", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r460147917", "createdAt": "2020-07-24T16:06:25Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaPassthroughRecordMagicConverter.java", "diffHunk": "@@ -0,0 +1,38 @@\n+/**\n+ *  Copyright 2020 LinkedIn Corporation. All rights reserved.\n+ *  Licensed under the BSD 2-Clause License. See the LICENSE file in the project root for license information.\n+ *  See the NOTICE file in the project root for additional information regarding copyright ownership.\n+ */\n+package com.linkedin.datastream.kafka;\n+\n+import org.apache.kafka.common.record.RecordBatch;\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+\n+/**\n+ * Tests for {@link KafkaPassthroughRecordMagicConverter}.\n+ */\n+@Test\n+public class TestKafkaPassthroughRecordMagicConverter {\n+\n+  @Test\n+  public void testMagicConversion() {\n+    String magicValue0 = KafkaPassthroughRecordMagicConverter.convertMagicToString(RecordBatch.MAGIC_VALUE_V0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2MzUwNw==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/732#discussion_r460163507", "createdAt": "2020-07-24T16:35:50Z", "author": {"login": "somandal"}, "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaPassthroughRecordMagicConverter.java", "diffHunk": "@@ -0,0 +1,38 @@\n+/**\n+ *  Copyright 2020 LinkedIn Corporation. All rights reserved.\n+ *  Licensed under the BSD 2-Clause License. See the LICENSE file in the project root for license information.\n+ *  See the NOTICE file in the project root for additional information regarding copyright ownership.\n+ */\n+package com.linkedin.datastream.kafka;\n+\n+import org.apache.kafka.common.record.RecordBatch;\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+\n+/**\n+ * Tests for {@link KafkaPassthroughRecordMagicConverter}.\n+ */\n+@Test\n+public class TestKafkaPassthroughRecordMagicConverter {\n+\n+  @Test\n+  public void testMagicConversion() {\n+    String magicValue0 = KafkaPassthroughRecordMagicConverter.convertMagicToString(RecordBatch.MAGIC_VALUE_V0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE0NzkxNw=="}, "originalCommit": {"oid": "a08e43369d894ac0b2fc1414761e464a5c286c72"}, "originalPosition": 21}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1031, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}