{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA1MTMxMjE3", "number": 768, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQyMzoxNDowMFrOEutPXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQyMzoxNDowMFrOEutPXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE3NDExMTY3OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/KafkaBasedConnectorConfig.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQyMzoxNDowMFrOHjSFdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNlQyMzoyMToxMlrOHjSLeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1ODUxNw==", "bodyText": "Do we need to make this a configurable? Why not add it without the config?", "url": "https://github.com/linkedin/brooklin/pull/768#discussion_r506758517", "createdAt": "2020-10-16T23:14:00Z", "author": {"login": "vishwajith-s"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/KafkaBasedConnectorConfig.java", "diffHunk": "@@ -32,6 +32,7 @@\n   public static final String CONFIG_PAUSE_PARTITION_ON_ERROR = \"pausePartitionOnError\";\n   public static final String CONFIG_PAUSE_ERROR_PARTITION_DURATION_MILLIS = \"pauseErrorPartitionDurationMs\";\n   public static final String ENABLE_ADDITIONAL_METRICS = \"enableAdditionalMetrics\";\n+  public static final String INCLUDE_DATASTREAM_NAME_IN_CONSUMER_CLIENT_ID = \"includeDatastreamNameInConsumerClientId\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "422e25dc3487ac8fdc98da5d2a99636a4ca4bd8c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc2MDA1OA==", "bodyText": "Want to make this configurable for two reasons:\n\nKafka quotas are currently enforced based on client.id. Kafka is in the process of migrating away from this model, but I don't want to break the client.ids until we are sure that the migration is complete and successful. So was thinking we can enable this on a per cluster basis.\nI don't expect us to hit metrics limitations in BMM, but want to make sure we have a knob to turn this off in case we start having problems with metrics.\n\nOnce we roll this out everywhere and all looks good, I can create a new PR to remove the config. How does that sound?", "url": "https://github.com/linkedin/brooklin/pull/768#discussion_r506760058", "createdAt": "2020-10-16T23:21:12Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/KafkaBasedConnectorConfig.java", "diffHunk": "@@ -32,6 +32,7 @@\n   public static final String CONFIG_PAUSE_PARTITION_ON_ERROR = \"pausePartitionOnError\";\n   public static final String CONFIG_PAUSE_ERROR_PARTITION_DURATION_MILLIS = \"pauseErrorPartitionDurationMs\";\n   public static final String ENABLE_ADDITIONAL_METRICS = \"enableAdditionalMetrics\";\n+  public static final String INCLUDE_DATASTREAM_NAME_IN_CONSUMER_CLIENT_ID = \"includeDatastreamNameInConsumerClientId\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1ODUxNw=="}, "originalCommit": {"oid": "422e25dc3487ac8fdc98da5d2a99636a4ca4bd8c"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 901, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}