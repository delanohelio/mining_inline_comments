{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI0ODMzMDk2", "number": 717, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjo0MToyNlrOEB1FeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODo0MzozNFrOEB4E5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMzUzNzg1OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/test/java/com/linkedin/datastream/connectors/kafka/mirrormaker/TestKafkaMirrorMakerConnectorTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjo0MToyNlrOGd6h5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMDoxMjoxNVrOGeCUVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAyMDgzNw==", "bodyText": "nit: wondering if the setter can take true/false to allow for stop failing send failures also.", "url": "https://github.com/linkedin/brooklin/pull/717#discussion_r434020837", "createdAt": "2020-06-02T16:41:26Z", "author": {"login": "DEEPTHIKORAT"}, "path": "datastream-kafka-connector/src/test/java/com/linkedin/datastream/connectors/kafka/mirrormaker/TestKafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -344,12 +345,24 @@ protected void postShutdownHook() {\n       try {\n         super.postShutdownHook();\n       } catch (Exception e) {\n-        postShutdownHookExceptionCaught = true;\n+        _postShutdownHookExceptionCaught = true;\n       }\n     }\n \n+    @Override\n+    protected void seekToLastCheckpoint(Set<TopicPartition> topicPartitions) {\n+      if (_failOnSeekToLastCheckpoint) {\n+        throw new KafkaException(\"KafkaException: failed to seek\");\n+      }\n+      super.seekToLastCheckpoint(topicPartitions);\n+    }\n+\n+    void setFailOnSeekToLastCheckpoint() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a510d3185d37fcba3b882a11277d4144cd7b5aa"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE0ODQzOQ==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/717#discussion_r434148439", "createdAt": "2020-06-02T20:12:15Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/test/java/com/linkedin/datastream/connectors/kafka/mirrormaker/TestKafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -344,12 +345,24 @@ protected void postShutdownHook() {\n       try {\n         super.postShutdownHook();\n       } catch (Exception e) {\n-        postShutdownHookExceptionCaught = true;\n+        _postShutdownHookExceptionCaught = true;\n       }\n     }\n \n+    @Override\n+    protected void seekToLastCheckpoint(Set<TopicPartition> topicPartitions) {\n+      if (_failOnSeekToLastCheckpoint) {\n+        throw new KafkaException(\"KafkaException: failed to seek\");\n+      }\n+      super.seekToLastCheckpoint(topicPartitions);\n+    }\n+\n+    void setFailOnSeekToLastCheckpoint() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAyMDgzNw=="}, "originalCommit": {"oid": "8a510d3185d37fcba3b882a11277d4144cd7b5aa"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNDAxMjE1OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODozODoxOVrOGd_OsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMDowNToyOVrOGeCGjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA5Nzg0MQ==", "bodyText": "nit: do you need both ',' and 'and'", "url": "https://github.com/linkedin/brooklin/pull/717#discussion_r434097841", "createdAt": "2020-06-02T18:38:19Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -282,15 +284,21 @@ protected void rewindAndPausePartitionOnException(TopicPartition srcTopicPartiti\n   }\n \n   protected void rewindAndPausePartitionsOnSendException() {\n-    // For all topic partitions which have seen send exceptions, attempt to rewind them to the last checkpoint\n+    // For all topic partitions which have seen send exceptions, attempt to rewind them to the last checkpoint.\n+    // The outcome of the rewind can fall into three categories:\n+    // 1) The rewind is successful and the Exception returned by the SendCallback is transient. This TopicPartition is\n+    //    not added to the auto-pause list.\n+    // 2) The rewind is successful and the Exception returned by the SendCallback is non-transient. This TopicPartition\n+    //    is added to the auto-pause list with SEND_ERROR as the reason.\n+    // 3) The rewind itself failed. An exception is thrown, and the connector task is brought down to avoid wrongfully", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b1e1f19c1eeabedc25a5a17c8a97a91de7cc88d"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA5ODczMA==", "bodyText": "also, can you rephrase this comment may be: the connector task is brought down to avoid committing wrong checkpoints.", "url": "https://github.com/linkedin/brooklin/pull/717#discussion_r434098730", "createdAt": "2020-06-02T18:40:02Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -282,15 +284,21 @@ protected void rewindAndPausePartitionOnException(TopicPartition srcTopicPartiti\n   }\n \n   protected void rewindAndPausePartitionsOnSendException() {\n-    // For all topic partitions which have seen send exceptions, attempt to rewind them to the last checkpoint\n+    // For all topic partitions which have seen send exceptions, attempt to rewind them to the last checkpoint.\n+    // The outcome of the rewind can fall into three categories:\n+    // 1) The rewind is successful and the Exception returned by the SendCallback is transient. This TopicPartition is\n+    //    not added to the auto-pause list.\n+    // 2) The rewind is successful and the Exception returned by the SendCallback is non-transient. This TopicPartition\n+    //    is added to the auto-pause list with SEND_ERROR as the reason.\n+    // 3) The rewind itself failed. An exception is thrown, and the connector task is brought down to avoid wrongfully", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA5Nzg0MQ=="}, "originalCommit": {"oid": "4b1e1f19c1eeabedc25a5a17c8a97a91de7cc88d"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE0NDkwOA==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/717#discussion_r434144908", "createdAt": "2020-06-02T20:05:29Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaBasedConnectorTask.java", "diffHunk": "@@ -282,15 +284,21 @@ protected void rewindAndPausePartitionOnException(TopicPartition srcTopicPartiti\n   }\n \n   protected void rewindAndPausePartitionsOnSendException() {\n-    // For all topic partitions which have seen send exceptions, attempt to rewind them to the last checkpoint\n+    // For all topic partitions which have seen send exceptions, attempt to rewind them to the last checkpoint.\n+    // The outcome of the rewind can fall into three categories:\n+    // 1) The rewind is successful and the Exception returned by the SendCallback is transient. This TopicPartition is\n+    //    not added to the auto-pause list.\n+    // 2) The rewind is successful and the Exception returned by the SendCallback is non-transient. This TopicPartition\n+    //    is added to the auto-pause list with SEND_ERROR as the reason.\n+    // 3) The rewind itself failed. An exception is thrown, and the connector task is brought down to avoid wrongfully", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA5Nzg0MQ=="}, "originalCommit": {"oid": "4b1e1f19c1eeabedc25a5a17c8a97a91de7cc88d"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNDAyMjQ5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/test/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTestUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODo0MTo1M1rOGd_V-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMDowNTozNFrOGeCGsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA5OTcwNw==", "bodyText": "nit, can you merge the two lines", "url": "https://github.com/linkedin/brooklin/pull/717#discussion_r434099707", "createdAt": "2020-06-02T18:41:53Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka-connector/src/test/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTestUtils.java", "diffHunk": "@@ -132,9 +132,15 @@ static KafkaMirrorMakerConnectorTask createFlushlessKafkaMirrorMakerConnectorTas\n \n   static Thread runKafkaMirrorMakerConnectorTask(KafkaMirrorMakerConnectorTask connectorTask)\n       throws InterruptedException {\n+    return runKafkaMirrorMakerConnectorTask(connectorTask, (t, e) -> Assert.fail(\"connector thread died\", e));\n+  }\n+\n+  static Thread runKafkaMirrorMakerConnectorTask(KafkaMirrorMakerConnectorTask connectorTask,\n+      Thread.UncaughtExceptionHandler exceptionHandler)\n+      throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b1e1f19c1eeabedc25a5a17c8a97a91de7cc88d"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE0NDk0NQ==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/717#discussion_r434144945", "createdAt": "2020-06-02T20:05:34Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/test/java/com/linkedin/datastream/connectors/kafka/mirrormaker/KafkaMirrorMakerConnectorTestUtils.java", "diffHunk": "@@ -132,9 +132,15 @@ static KafkaMirrorMakerConnectorTask createFlushlessKafkaMirrorMakerConnectorTas\n \n   static Thread runKafkaMirrorMakerConnectorTask(KafkaMirrorMakerConnectorTask connectorTask)\n       throws InterruptedException {\n+    return runKafkaMirrorMakerConnectorTask(connectorTask, (t, e) -> Assert.fail(\"connector thread died\", e));\n+  }\n+\n+  static Thread runKafkaMirrorMakerConnectorTask(KafkaMirrorMakerConnectorTask connectorTask,\n+      Thread.UncaughtExceptionHandler exceptionHandler)\n+      throws InterruptedException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDA5OTcwNw=="}, "originalCommit": {"oid": "4b1e1f19c1eeabedc25a5a17c8a97a91de7cc88d"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNDAyNzg5OnYy", "diffSide": "RIGHT", "path": "datastream-kafka-connector/src/test/java/com/linkedin/datastream/connectors/kafka/mirrormaker/TestKafkaMirrorMakerConnectorTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxODo0MzozNFrOGd_ZqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMDowNTozOFrOGeCG1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDEwMDY0OQ==", "bodyText": "typo zkAdatper", "url": "https://github.com/linkedin/brooklin/pull/717#discussion_r434100649", "createdAt": "2020-06-02T18:43:34Z", "author": {"login": "vmaheshw"}, "path": "datastream-kafka-connector/src/test/java/com/linkedin/datastream/connectors/kafka/mirrormaker/TestKafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -821,6 +834,56 @@ public void testAutoPauseAndResumeOnSendFailure() throws Exception {\n         \"did not shut down on time\");\n   }\n \n+  @Test\n+  public void testValidateTaskDiesOnRewindFailure() throws InterruptedException {\n+    String yummyTopic = \"YummyPizza\";\n+    createTopic(_zkUtils, yummyTopic);\n+\n+    // create a datastream to consume from topics ending in \"Pizza\"\n+    Datastream datastream = KafkaMirrorMakerConnectorTestUtils.createDatastream(\"pizzaStream\", _broker, \"\\\\w+Pizza\");\n+\n+    DatastreamTaskImpl task = new DatastreamTaskImpl(Collections.singletonList(datastream));\n+    // create event producer that fails on 3rd event (of 5)\n+    MockDatastreamEventProducer datastreamProducer =\n+        new MockDatastreamEventProducer((r) -> new String((byte[]) r.getEvents().get(0).key().get()).equals(\"key-2\"));\n+    task.setEventProducer(datastreamProducer);\n+\n+    ZkAdapter zkAdatper = new ZkAdapter(_kafkaCluster.getZkConnection(), \"testCluster\", null,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b1e1f19c1eeabedc25a5a17c8a97a91de7cc88d"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE0NDk4MA==", "bodyText": "done", "url": "https://github.com/linkedin/brooklin/pull/717#discussion_r434144980", "createdAt": "2020-06-02T20:05:38Z", "author": {"login": "somandal"}, "path": "datastream-kafka-connector/src/test/java/com/linkedin/datastream/connectors/kafka/mirrormaker/TestKafkaMirrorMakerConnectorTask.java", "diffHunk": "@@ -821,6 +834,56 @@ public void testAutoPauseAndResumeOnSendFailure() throws Exception {\n         \"did not shut down on time\");\n   }\n \n+  @Test\n+  public void testValidateTaskDiesOnRewindFailure() throws InterruptedException {\n+    String yummyTopic = \"YummyPizza\";\n+    createTopic(_zkUtils, yummyTopic);\n+\n+    // create a datastream to consume from topics ending in \"Pizza\"\n+    Datastream datastream = KafkaMirrorMakerConnectorTestUtils.createDatastream(\"pizzaStream\", _broker, \"\\\\w+Pizza\");\n+\n+    DatastreamTaskImpl task = new DatastreamTaskImpl(Collections.singletonList(datastream));\n+    // create event producer that fails on 3rd event (of 5)\n+    MockDatastreamEventProducer datastreamProducer =\n+        new MockDatastreamEventProducer((r) -> new String((byte[]) r.getEvents().get(0).key().get()).equals(\"key-2\"));\n+    task.setEventProducer(datastreamProducer);\n+\n+    ZkAdapter zkAdatper = new ZkAdapter(_kafkaCluster.getZkConnection(), \"testCluster\", null,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDEwMDY0OQ=="}, "originalCommit": {"oid": "4b1e1f19c1eeabedc25a5a17c8a97a91de7cc88d"}, "originalPosition": 55}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1009, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}