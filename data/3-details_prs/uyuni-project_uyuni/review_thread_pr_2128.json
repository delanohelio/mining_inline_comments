{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA0NDY2MjQy", "number": 2128, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTozODozNlrODyj6Tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNzo0Nzo1NFrOD1pEFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MzQzNzU4OnYy", "diffSide": "RIGHT", "path": "susemanager-utils/susemanager-sls/salt/clusters/addnode.sls", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTozODozNlrOGGrZOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTozODozNlrOGGrZOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY1NTYxMA==", "bodyText": "Please start all our ids with mgr_ and use also a unique name.\nIf somebody call addnode and removenode in one state.apply it will fail.\nI think it is better to use always unique ids.", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r409655610", "createdAt": "2020-04-16T15:38:36Z", "author": {"login": "mcalmer"}, "path": "susemanager-utils/susemanager-sls/salt/clusters/addnode.sls", "diffHunk": "@@ -0,0 +1,24 @@\n+{%- if pillar.get('ssh_auth_sock', False) %}\n+ssh_agent_socket:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "598fcc0bd066618341892dd7b6c71f12bab495ee"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NjU1MzAzOnYy", "diffSide": "RIGHT", "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxMDo1ODo1M1rOGHJjKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxMToxMjo0M1rOGHJ56g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE0OTY3NQ==", "bodyText": "For consistency maybe this parameter should be called skuba_cluster_path.", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410149675", "createdAt": "2020-04-17T10:58:53Z", "author": {"login": "mateiw"}, "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-\n+'''\n+SUSE Manager CaaSP Cluster Manager module for Salt\n+\n+'''\n+from __future__ import absolute_import\n+\n+\n+import logging\n+import os\n+import subprocess\n+\n+import salt.utils.stringutils\n+import salt.utils.timed_subprocess\n+\n+try:\n+    from salt.utils.path import which\n+except ImportError:\n+    from salt.utils import which\n+\n+from salt.utils.dictupdate import merge_list\n+from salt.exceptions import CommandExecutionError\n+\n+\n+log = logging.getLogger(__name__)\n+\n+__virtualname__ = 'caasp'\n+\n+DEFAULT_TIMEOUT = 1200\n+\n+\n+def __virtual__():\n+    '''\n+    This module is always enabled while 'skuba' CLI tools is available.\n+    '''\n+    return __virtualname__ if which('skuba') else (False, 'skuba is not available')\n+\n+\n+def _call_skuba(skuba_cluster_path,\n+                cmd_args,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    log.debug(\"Calling Skuba CLI: 'skuba {}' - Timeout: {}\".format(cmd_args, timeout))\n+    try:\n+        skuba_proc = salt.utils.timed_subprocess.TimedProc(\n+            [\"skuba\"] + cmd_args.split(),\n+            stdout=subprocess.PIPE,\n+            stderr=subprocess.PIPE,\n+            timeout=timeout,\n+            cwd=skuba_cluster_path,\n+        )\n+        skuba_proc.run()\n+        return skuba_proc\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while calling skuba: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+\n+def _sanitize_skuba_output_values(items):\n+    ret = []\n+    for i in items:\n+        if i.lower() == 'no':\n+            ret.append(False)\n+        elif i.lower() == 'yes':\n+            ret.append(True)\n+        elif i.lower() == '<none>':\n+            ret.append(None)\n+        else:\n+            ret.append(i)\n+    return ret\n+\n+\n+def list_nodes(skuba_cluster_path,\n+               timeout=DEFAULT_TIMEOUT,\n+               **kwargs):\n+    skuba_proc = _call_skuba(skuba_cluster_path, \"cluster status\")\n+    if skuba_proc.process.returncode != 0 or skuba_proc.stderr:\n+        error_msg = \"Unexpected error {} at skuba when listing nodes: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    skuba_proc_lines = salt.utils.stringutils.to_str(skuba_proc.stdout).splitlines()\n+\n+    ret = {}\n+    try:\n+        # The first line of skuba output are the headers\n+        headers = [x.strip().lower() for x in skuba_proc_lines[0].split('  ') if x]\n+        name_idx = headers.index('name')\n+        headers.remove('name')\n+        for line in skuba_proc_lines[1:]:\n+            items = [x.strip() for x in line.split('  ') if x]\n+            node_name = items.pop(name_idx)\n+            node_zip = zip(headers, _sanitize_skuba_output_values(items))\n+            ret[node_name] = dict(node_zip)\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while parsing skuba output: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    return ret\n+\n+\n+def remove_node(skuba_cluster_path,\n+                node_name,\n+                drain_timeout=None,\n+                verbosity=None,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    cmd_args = \"node remove {}\".format(node_name)\n+\n+    if drain_timeout:\n+        cmd_args += \" --drain-timeout {}\".format(drain_timeout)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when removing a node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def add_node(skuba_cluster_path,\n+             node_name,\n+             role,\n+             target,\n+             ignore_preflight_errors=None,\n+             port=None,\n+             sudo=None,\n+             user=None,\n+             verbosity=None,\n+             timeout=DEFAULT_TIMEOUT,\n+             **kwargs):\n+\n+    cmd_args = \"node join --role {} --target {} {}\".format(role, target, node_name)\n+\n+    if ignore_preflight_errors:\n+        cmd_args += \" --ignore-preflight-errors {}\".format(ignore_preflight_errors)\n+    if port:\n+        cmd_args += \" --port {}\".format(port)\n+    if sudo:\n+        cmd_args += \" --sudo\"\n+    if user:\n+        cmd_args += \" --user {}\".format(user)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when adding a new node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_cluster(skuba_cluster_path,\n+                    verbosity=None,\n+                    timeout=DEFAULT_TIMEOUT,\n+                    **kwargs):\n+\n+    cmd_args = \"cluster upgrade plan\"\n+\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when upgrading the cluster: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_node(skuba_cluster_path,\n+                 verbosity=None,\n+                 timeout=DEFAULT_TIMEOUT,\n+                 plan=False,\n+                 **kwargs):\n+\n+    cmd_args = \"node upgrade {}\".format(\"plan\" if plan else \"apply\")\n+\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when upgrading the node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def cluster_init(name,\n+                 cluster_path,\n+                 target,\n+                 cloud_provider=None,\n+                 strict_capability_defaults=False,\n+                 verbosity=None,\n+                 timeout=DEFAULT_TIMEOUT,\n+                 **kwargs):\n+\n+    cmd_args = \"cluster init --control-plane {} {}\".format(target, name)\n+\n+    if cloud_provider:\n+        cmd_args += \" --cloud-provider {}\".format(cloud_provider)\n+    if strict_capability_defaults:\n+        cmd_args += \" --strict-capability-defaults\"\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when initializing the cluster: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def master_bootstrap(node_name,\n+                     skuba_cluster_path,\n+                     target,\n+                     ignore_preflight_errors=None,\n+                     port=None,\n+                     sudo=None,\n+                     user=None,\n+                     verbosity=None,\n+                     timeout=DEFAULT_TIMEOUT,\n+                     **kwargs):\n+\n+    cmd_args = \"node bootstrap --target {} {}\".format(target, node_name)\n+\n+    if ignore_preflight_errors:\n+        cmd_args += \" --ignore-preflight-errors {}\".format(ignore_preflight_errors)\n+    if port:\n+        cmd_args += \" --port {}\".format(port)\n+    if sudo:\n+        cmd_args += \" --sudo\"\n+    if user:\n+        cmd_args += \" --user {}\".format(user)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when bootstrapping the node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def create_cluster(cluster_name,\n+                   cluster_path,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05c42779a492d7cab84333c867efc6229a9b26c"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE1NTQ5OA==", "bodyText": "@mateiw actually those two parameters are not representing the same:\n\ncluster_path would be something like /srv/my-clusters/. The path where the cluster directory will be created.\nskuba_cluster_path is where your particular cluster is stored: i.a. /srv/my-clusters/my-first-cluster/\n\nSince they sound similar, maybe I should change cluster_path to something else more descriptive to avoid the confusion. I'll go maybe with base_path", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410155498", "createdAt": "2020-04-17T11:12:43Z", "author": {"login": "meaksh"}, "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-\n+'''\n+SUSE Manager CaaSP Cluster Manager module for Salt\n+\n+'''\n+from __future__ import absolute_import\n+\n+\n+import logging\n+import os\n+import subprocess\n+\n+import salt.utils.stringutils\n+import salt.utils.timed_subprocess\n+\n+try:\n+    from salt.utils.path import which\n+except ImportError:\n+    from salt.utils import which\n+\n+from salt.utils.dictupdate import merge_list\n+from salt.exceptions import CommandExecutionError\n+\n+\n+log = logging.getLogger(__name__)\n+\n+__virtualname__ = 'caasp'\n+\n+DEFAULT_TIMEOUT = 1200\n+\n+\n+def __virtual__():\n+    '''\n+    This module is always enabled while 'skuba' CLI tools is available.\n+    '''\n+    return __virtualname__ if which('skuba') else (False, 'skuba is not available')\n+\n+\n+def _call_skuba(skuba_cluster_path,\n+                cmd_args,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    log.debug(\"Calling Skuba CLI: 'skuba {}' - Timeout: {}\".format(cmd_args, timeout))\n+    try:\n+        skuba_proc = salt.utils.timed_subprocess.TimedProc(\n+            [\"skuba\"] + cmd_args.split(),\n+            stdout=subprocess.PIPE,\n+            stderr=subprocess.PIPE,\n+            timeout=timeout,\n+            cwd=skuba_cluster_path,\n+        )\n+        skuba_proc.run()\n+        return skuba_proc\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while calling skuba: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+\n+def _sanitize_skuba_output_values(items):\n+    ret = []\n+    for i in items:\n+        if i.lower() == 'no':\n+            ret.append(False)\n+        elif i.lower() == 'yes':\n+            ret.append(True)\n+        elif i.lower() == '<none>':\n+            ret.append(None)\n+        else:\n+            ret.append(i)\n+    return ret\n+\n+\n+def list_nodes(skuba_cluster_path,\n+               timeout=DEFAULT_TIMEOUT,\n+               **kwargs):\n+    skuba_proc = _call_skuba(skuba_cluster_path, \"cluster status\")\n+    if skuba_proc.process.returncode != 0 or skuba_proc.stderr:\n+        error_msg = \"Unexpected error {} at skuba when listing nodes: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    skuba_proc_lines = salt.utils.stringutils.to_str(skuba_proc.stdout).splitlines()\n+\n+    ret = {}\n+    try:\n+        # The first line of skuba output are the headers\n+        headers = [x.strip().lower() for x in skuba_proc_lines[0].split('  ') if x]\n+        name_idx = headers.index('name')\n+        headers.remove('name')\n+        for line in skuba_proc_lines[1:]:\n+            items = [x.strip() for x in line.split('  ') if x]\n+            node_name = items.pop(name_idx)\n+            node_zip = zip(headers, _sanitize_skuba_output_values(items))\n+            ret[node_name] = dict(node_zip)\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while parsing skuba output: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    return ret\n+\n+\n+def remove_node(skuba_cluster_path,\n+                node_name,\n+                drain_timeout=None,\n+                verbosity=None,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    cmd_args = \"node remove {}\".format(node_name)\n+\n+    if drain_timeout:\n+        cmd_args += \" --drain-timeout {}\".format(drain_timeout)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when removing a node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def add_node(skuba_cluster_path,\n+             node_name,\n+             role,\n+             target,\n+             ignore_preflight_errors=None,\n+             port=None,\n+             sudo=None,\n+             user=None,\n+             verbosity=None,\n+             timeout=DEFAULT_TIMEOUT,\n+             **kwargs):\n+\n+    cmd_args = \"node join --role {} --target {} {}\".format(role, target, node_name)\n+\n+    if ignore_preflight_errors:\n+        cmd_args += \" --ignore-preflight-errors {}\".format(ignore_preflight_errors)\n+    if port:\n+        cmd_args += \" --port {}\".format(port)\n+    if sudo:\n+        cmd_args += \" --sudo\"\n+    if user:\n+        cmd_args += \" --user {}\".format(user)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when adding a new node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_cluster(skuba_cluster_path,\n+                    verbosity=None,\n+                    timeout=DEFAULT_TIMEOUT,\n+                    **kwargs):\n+\n+    cmd_args = \"cluster upgrade plan\"\n+\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when upgrading the cluster: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_node(skuba_cluster_path,\n+                 verbosity=None,\n+                 timeout=DEFAULT_TIMEOUT,\n+                 plan=False,\n+                 **kwargs):\n+\n+    cmd_args = \"node upgrade {}\".format(\"plan\" if plan else \"apply\")\n+\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when upgrading the node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def cluster_init(name,\n+                 cluster_path,\n+                 target,\n+                 cloud_provider=None,\n+                 strict_capability_defaults=False,\n+                 verbosity=None,\n+                 timeout=DEFAULT_TIMEOUT,\n+                 **kwargs):\n+\n+    cmd_args = \"cluster init --control-plane {} {}\".format(target, name)\n+\n+    if cloud_provider:\n+        cmd_args += \" --cloud-provider {}\".format(cloud_provider)\n+    if strict_capability_defaults:\n+        cmd_args += \" --strict-capability-defaults\"\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when initializing the cluster: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def master_bootstrap(node_name,\n+                     skuba_cluster_path,\n+                     target,\n+                     ignore_preflight_errors=None,\n+                     port=None,\n+                     sudo=None,\n+                     user=None,\n+                     verbosity=None,\n+                     timeout=DEFAULT_TIMEOUT,\n+                     **kwargs):\n+\n+    cmd_args = \"node bootstrap --target {} {}\".format(target, node_name)\n+\n+    if ignore_preflight_errors:\n+        cmd_args += \" --ignore-preflight-errors {}\".format(ignore_preflight_errors)\n+    if port:\n+        cmd_args += \" --port {}\".format(port)\n+    if sudo:\n+        cmd_args += \" --sudo\"\n+    if user:\n+        cmd_args += \" --user {}\".format(user)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when bootstrapping the node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def create_cluster(cluster_name,\n+                   cluster_path,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE0OTY3NQ=="}, "originalCommit": {"oid": "c05c42779a492d7cab84333c867efc6229a9b26c"}, "originalPosition": 306}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NzUyNTA5OnYy", "diffSide": "RIGHT", "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNTo0MzozNlrOGHTMsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNTo0MzozNlrOGHTMsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMwNzc2MA==", "bodyText": "@ereslibre : this is the core of what we would be using to call skuba via Salt.\nWould you please review it if it makes sense from the skuba standpoint?", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410307760", "createdAt": "2020-04-17T15:43:36Z", "author": {"login": "mbologna"}, "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "711e983f49d7dab6b5451c5a9b155ae1295295cf"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NzUzMzA0OnYy", "diffSide": "RIGHT", "path": "susemanager-utils/susemanager-sls/salt/clusters/createcluster.sls", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNTo0NTo0OFrOGHTR-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNjoxMjowM1rOGHURAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMwOTExNA==", "bodyText": "I assume that if a specific type of cluster does not offer the init workflow, we can skip the initialization and jump directly to other operations, correct?", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410309114", "createdAt": "2020-04-17T15:45:48Z", "author": {"login": "mbologna"}, "path": "susemanager-utils/susemanager-sls/salt/clusters/createcluster.sls", "diffHunk": "@@ -0,0 +1,24 @@\n+{%- if pillar.get('ssh_auth_sock', False) %}\n+mgr_ssh_agent_socket_clusters_createcluster:\n+  environ.setenv:\n+    - name: SSH_AUTH_SOCK\n+    - value: {{ pillar['ssh_auth_sock'] }}\n+{%- endif %}\n+\n+mgr_cluster_create_cluster:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "711e983f49d7dab6b5451c5a9b155ae1295295cf"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMyNTI1MA==", "bodyText": "That's correct. Or, even in the case of CaaSP, if the cluster has been already created, we can directly operate it with i.a. clusters.addnode.", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410325250", "createdAt": "2020-04-17T16:12:03Z", "author": {"login": "meaksh"}, "path": "susemanager-utils/susemanager-sls/salt/clusters/createcluster.sls", "diffHunk": "@@ -0,0 +1,24 @@\n+{%- if pillar.get('ssh_auth_sock', False) %}\n+mgr_ssh_agent_socket_clusters_createcluster:\n+  environ.setenv:\n+    - name: SSH_AUTH_SOCK\n+    - value: {{ pillar['ssh_auth_sock'] }}\n+{%- endif %}\n+\n+mgr_cluster_create_cluster:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMwOTExNA=="}, "originalCommit": {"oid": "711e983f49d7dab6b5451c5a9b155ae1295295cf"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NzU3NzI3OnYy", "diffSide": "RIGHT", "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNTo1NzoxN1rOGHTuag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxNjoxMjozN1rOGHUSNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMxNjM5NA==", "bodyText": "I think timeout  timeout should be passed as arg to every call to _call_skuba, am I assuming correctly?", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410316394", "createdAt": "2020-04-17T15:57:17Z", "author": {"login": "mbologna"}, "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-\n+'''\n+SUSE Manager CaaSP Cluster Manager module for Salt\n+\n+'''\n+from __future__ import absolute_import\n+\n+\n+import logging\n+import os\n+import subprocess\n+\n+import salt.utils.stringutils\n+import salt.utils.timed_subprocess\n+\n+try:\n+    from salt.utils.path import which\n+except ImportError:\n+    from salt.utils import which\n+\n+from salt.utils.dictupdate import merge_list\n+from salt.exceptions import CommandExecutionError\n+\n+\n+log = logging.getLogger(__name__)\n+\n+__virtualname__ = 'caasp'\n+\n+DEFAULT_TIMEOUT = 1200\n+\n+\n+def __virtual__():\n+    '''\n+    This module is always enabled while 'skuba' CLI tools is available.\n+    '''\n+    return __virtualname__ if which('skuba') else (False, 'skuba is not available')\n+\n+\n+def _call_skuba(skuba_cluster_path,\n+                cmd_args,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    log.debug(\"Calling Skuba CLI: 'skuba {}' - Timeout: {}\".format(cmd_args, timeout))\n+    try:\n+        skuba_proc = salt.utils.timed_subprocess.TimedProc(\n+            [\"skuba\"] + cmd_args.split(),\n+            stdout=subprocess.PIPE,\n+            stderr=subprocess.PIPE,\n+            timeout=timeout,\n+            cwd=skuba_cluster_path,\n+        )\n+        skuba_proc.run()\n+        return skuba_proc\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while calling skuba: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+\n+def _sanitize_skuba_output_values(items):\n+    ret = []\n+    for i in items:\n+        if i.lower() == 'no':\n+            ret.append(False)\n+        elif i.lower() == 'yes':\n+            ret.append(True)\n+        elif i.lower() == '<none>':\n+            ret.append(None)\n+        else:\n+            ret.append(i)\n+    return ret\n+\n+\n+def list_nodes(skuba_cluster_path,\n+               timeout=DEFAULT_TIMEOUT,\n+               **kwargs):\n+    skuba_proc = _call_skuba(skuba_cluster_path, \"cluster status\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "711e983f49d7dab6b5451c5a9b155ae1295295cf"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMyNTU1OA==", "bodyText": "You're correct. Good catch! I've missed that :)", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410325558", "createdAt": "2020-04-17T16:12:37Z", "author": {"login": "meaksh"}, "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-\n+'''\n+SUSE Manager CaaSP Cluster Manager module for Salt\n+\n+'''\n+from __future__ import absolute_import\n+\n+\n+import logging\n+import os\n+import subprocess\n+\n+import salt.utils.stringutils\n+import salt.utils.timed_subprocess\n+\n+try:\n+    from salt.utils.path import which\n+except ImportError:\n+    from salt.utils import which\n+\n+from salt.utils.dictupdate import merge_list\n+from salt.exceptions import CommandExecutionError\n+\n+\n+log = logging.getLogger(__name__)\n+\n+__virtualname__ = 'caasp'\n+\n+DEFAULT_TIMEOUT = 1200\n+\n+\n+def __virtual__():\n+    '''\n+    This module is always enabled while 'skuba' CLI tools is available.\n+    '''\n+    return __virtualname__ if which('skuba') else (False, 'skuba is not available')\n+\n+\n+def _call_skuba(skuba_cluster_path,\n+                cmd_args,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    log.debug(\"Calling Skuba CLI: 'skuba {}' - Timeout: {}\".format(cmd_args, timeout))\n+    try:\n+        skuba_proc = salt.utils.timed_subprocess.TimedProc(\n+            [\"skuba\"] + cmd_args.split(),\n+            stdout=subprocess.PIPE,\n+            stderr=subprocess.PIPE,\n+            timeout=timeout,\n+            cwd=skuba_cluster_path,\n+        )\n+        skuba_proc.run()\n+        return skuba_proc\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while calling skuba: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+\n+def _sanitize_skuba_output_values(items):\n+    ret = []\n+    for i in items:\n+        if i.lower() == 'no':\n+            ret.append(False)\n+        elif i.lower() == 'yes':\n+            ret.append(True)\n+        elif i.lower() == '<none>':\n+            ret.append(None)\n+        else:\n+            ret.append(i)\n+    return ret\n+\n+\n+def list_nodes(skuba_cluster_path,\n+               timeout=DEFAULT_TIMEOUT,\n+               **kwargs):\n+    skuba_proc = _call_skuba(skuba_cluster_path, \"cluster status\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMxNjM5NA=="}, "originalCommit": {"oid": "711e983f49d7dab6b5451c5a9b155ae1295295cf"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3NTczOTEwOnYy", "diffSide": "RIGHT", "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNzo0Nzo1NFrOGLLBkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMDoyMDoyMVrOGMbwYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM2ODE0Ng==", "bodyText": "Just a comment for the near future (non-blocking). When performing upgrades there are different stages when it comes to upgrading addons and nodes, so in general:\n\nUpgrade addons to the latest version of the current platform version (skuba addon upgrade plan/apply)\nUpgrade all nodes normally (skuba node upgrade plan/apply)\nUpgrade addons to the new version of the platform (skuba addon upgrade plan/apply)\n\n1. and 3. are not always required (depends on what changes on each release), but can always be run to ensure the most constraining scenario.", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r414368146", "createdAt": "2020-04-24T07:47:54Z", "author": {"login": "ereslibre"}, "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-\n+'''\n+SUSE Manager CaaSP Cluster Manager module for Salt\n+\n+'''\n+from __future__ import absolute_import\n+\n+\n+import logging\n+import os\n+import subprocess\n+\n+import salt.utils.stringutils\n+import salt.utils.timed_subprocess\n+\n+try:\n+    from salt.utils.path import which\n+except ImportError:\n+    from salt.utils import which\n+\n+from salt.utils.dictupdate import merge_list\n+from salt.exceptions import CommandExecutionError\n+\n+\n+log = logging.getLogger(__name__)\n+\n+__virtualname__ = 'caasp'\n+\n+DEFAULT_TIMEOUT = 1200\n+\n+\n+def __virtual__():\n+    '''\n+    This module is always enabled while 'skuba' CLI tools is available.\n+    '''\n+    return __virtualname__ if which('skuba') else (False, 'skuba is not available')\n+\n+\n+def _call_skuba(skuba_cluster_path,\n+                cmd_args,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    log.debug(\"Calling Skuba CLI: 'skuba {}' - Timeout: {}\".format(cmd_args, timeout))\n+    try:\n+        skuba_proc = salt.utils.timed_subprocess.TimedProc(\n+            [\"skuba\"] + cmd_args.split(),\n+            stdout=subprocess.PIPE,\n+            stderr=subprocess.PIPE,\n+            timeout=timeout,\n+            cwd=skuba_cluster_path,\n+        )\n+        skuba_proc.run()\n+        return skuba_proc\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while calling skuba: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+\n+def _sanitize_skuba_output_values(items):\n+    ret = []\n+    for i in items:\n+        if i.lower() == 'no':\n+            ret.append(False)\n+        elif i.lower() == 'yes':\n+            ret.append(True)\n+        elif i.lower() == '<none>':\n+            ret.append(None)\n+        else:\n+            ret.append(i)\n+    return ret\n+\n+\n+def list_nodes(skuba_cluster_path,\n+               timeout=DEFAULT_TIMEOUT,\n+               **kwargs):\n+    skuba_proc = _call_skuba(skuba_cluster_path, \"cluster status\", timeout=timeout)\n+    if skuba_proc.process.returncode != 0 or skuba_proc.stderr:\n+        error_msg = \"Unexpected error {} at skuba when listing nodes: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    skuba_proc_lines = salt.utils.stringutils.to_str(skuba_proc.stdout).splitlines()\n+\n+    ret = {}\n+    try:\n+        # The first line of skuba output are the headers\n+        headers = [x.strip().lower() for x in skuba_proc_lines[0].split('  ') if x]\n+        name_idx = headers.index('name')\n+        headers.remove('name')\n+        for line in skuba_proc_lines[1:]:\n+            items = [x.strip() for x in line.split('  ') if x]\n+            node_name = items.pop(name_idx)\n+            node_zip = zip(headers, _sanitize_skuba_output_values(items))\n+            ret[node_name] = dict(node_zip)\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while parsing skuba output: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    return ret\n+\n+\n+def remove_node(skuba_cluster_path,\n+                node_name,\n+                drain_timeout=None,\n+                verbosity=None,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    cmd_args = \"node remove {}\".format(node_name)\n+\n+    if drain_timeout:\n+        cmd_args += \" --drain-timeout {}\".format(drain_timeout)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args, timeout=timeout)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when removing a node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def add_node(skuba_cluster_path,\n+             node_name,\n+             role,\n+             target,\n+             ignore_preflight_errors=None,\n+             port=None,\n+             sudo=None,\n+             user=None,\n+             verbosity=None,\n+             timeout=DEFAULT_TIMEOUT,\n+             **kwargs):\n+\n+    cmd_args = \"node join --role {} --target {} {}\".format(role, target, node_name)\n+\n+    if ignore_preflight_errors:\n+        cmd_args += \" --ignore-preflight-errors {}\".format(ignore_preflight_errors)\n+    if port:\n+        cmd_args += \" --port {}\".format(port)\n+    if sudo:\n+        cmd_args += \" --sudo\"\n+    if user:\n+        cmd_args += \" --user {}\".format(user)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args, timeout=timeout)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when adding a new node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_cluster(skuba_cluster_path,\n+                    verbosity=None,\n+                    timeout=DEFAULT_TIMEOUT,\n+                    **kwargs):\n+\n+    cmd_args = \"cluster upgrade plan\"\n+\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args, timeout=timeout)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when upgrading the cluster: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_node(skuba_cluster_path,\n+                 verbosity=None,\n+                 timeout=DEFAULT_TIMEOUT,\n+                 plan=False,\n+                 **kwargs):\n+\n+    cmd_args = \"node upgrade {}\".format(\"plan\" if plan else \"apply\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "752181d41f679c1d4d85fe3e1ab7243c1e27db1f"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTY5MDg1MA==", "bodyText": "@ereslibre thanks for clarifying the upgrade stages! I'll be pushing those missing methods on the next round of PR. \ud83d\udc4d", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r415690850", "createdAt": "2020-04-27T10:20:21Z", "author": {"login": "meaksh"}, "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-\n+'''\n+SUSE Manager CaaSP Cluster Manager module for Salt\n+\n+'''\n+from __future__ import absolute_import\n+\n+\n+import logging\n+import os\n+import subprocess\n+\n+import salt.utils.stringutils\n+import salt.utils.timed_subprocess\n+\n+try:\n+    from salt.utils.path import which\n+except ImportError:\n+    from salt.utils import which\n+\n+from salt.utils.dictupdate import merge_list\n+from salt.exceptions import CommandExecutionError\n+\n+\n+log = logging.getLogger(__name__)\n+\n+__virtualname__ = 'caasp'\n+\n+DEFAULT_TIMEOUT = 1200\n+\n+\n+def __virtual__():\n+    '''\n+    This module is always enabled while 'skuba' CLI tools is available.\n+    '''\n+    return __virtualname__ if which('skuba') else (False, 'skuba is not available')\n+\n+\n+def _call_skuba(skuba_cluster_path,\n+                cmd_args,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    log.debug(\"Calling Skuba CLI: 'skuba {}' - Timeout: {}\".format(cmd_args, timeout))\n+    try:\n+        skuba_proc = salt.utils.timed_subprocess.TimedProc(\n+            [\"skuba\"] + cmd_args.split(),\n+            stdout=subprocess.PIPE,\n+            stderr=subprocess.PIPE,\n+            timeout=timeout,\n+            cwd=skuba_cluster_path,\n+        )\n+        skuba_proc.run()\n+        return skuba_proc\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while calling skuba: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+\n+def _sanitize_skuba_output_values(items):\n+    ret = []\n+    for i in items:\n+        if i.lower() == 'no':\n+            ret.append(False)\n+        elif i.lower() == 'yes':\n+            ret.append(True)\n+        elif i.lower() == '<none>':\n+            ret.append(None)\n+        else:\n+            ret.append(i)\n+    return ret\n+\n+\n+def list_nodes(skuba_cluster_path,\n+               timeout=DEFAULT_TIMEOUT,\n+               **kwargs):\n+    skuba_proc = _call_skuba(skuba_cluster_path, \"cluster status\", timeout=timeout)\n+    if skuba_proc.process.returncode != 0 or skuba_proc.stderr:\n+        error_msg = \"Unexpected error {} at skuba when listing nodes: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    skuba_proc_lines = salt.utils.stringutils.to_str(skuba_proc.stdout).splitlines()\n+\n+    ret = {}\n+    try:\n+        # The first line of skuba output are the headers\n+        headers = [x.strip().lower() for x in skuba_proc_lines[0].split('  ') if x]\n+        name_idx = headers.index('name')\n+        headers.remove('name')\n+        for line in skuba_proc_lines[1:]:\n+            items = [x.strip() for x in line.split('  ') if x]\n+            node_name = items.pop(name_idx)\n+            node_zip = zip(headers, _sanitize_skuba_output_values(items))\n+            ret[node_name] = dict(node_zip)\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while parsing skuba output: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    return ret\n+\n+\n+def remove_node(skuba_cluster_path,\n+                node_name,\n+                drain_timeout=None,\n+                verbosity=None,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    cmd_args = \"node remove {}\".format(node_name)\n+\n+    if drain_timeout:\n+        cmd_args += \" --drain-timeout {}\".format(drain_timeout)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args, timeout=timeout)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when removing a node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def add_node(skuba_cluster_path,\n+             node_name,\n+             role,\n+             target,\n+             ignore_preflight_errors=None,\n+             port=None,\n+             sudo=None,\n+             user=None,\n+             verbosity=None,\n+             timeout=DEFAULT_TIMEOUT,\n+             **kwargs):\n+\n+    cmd_args = \"node join --role {} --target {} {}\".format(role, target, node_name)\n+\n+    if ignore_preflight_errors:\n+        cmd_args += \" --ignore-preflight-errors {}\".format(ignore_preflight_errors)\n+    if port:\n+        cmd_args += \" --port {}\".format(port)\n+    if sudo:\n+        cmd_args += \" --sudo\"\n+    if user:\n+        cmd_args += \" --user {}\".format(user)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args, timeout=timeout)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when adding a new node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_cluster(skuba_cluster_path,\n+                    verbosity=None,\n+                    timeout=DEFAULT_TIMEOUT,\n+                    **kwargs):\n+\n+    cmd_args = \"cluster upgrade plan\"\n+\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args, timeout=timeout)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when upgrading the cluster: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_node(skuba_cluster_path,\n+                 verbosity=None,\n+                 timeout=DEFAULT_TIMEOUT,\n+                 plan=False,\n+                 **kwargs):\n+\n+    cmd_args = \"node upgrade {}\".format(\"plan\" if plan else \"apply\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM2ODE0Ng=="}, "originalCommit": {"oid": "752181d41f679c1d4d85fe3e1ab7243c1e27db1f"}, "originalPosition": 210}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4333, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}