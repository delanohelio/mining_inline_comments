{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDczODMyODE0", "number": 2525, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo0OTozM1rOEcnKMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMjoyODoxOFrOEgXQKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NDM3MTY4OnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo0OTozM1rOHHP1VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo0OTozM1rOHHP1VQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2MTQ5Mw==", "bodyText": "state is an attribute for \"<target>\". Here it seems you set it on <trans-unit> .\nBut I think we do not need to set state=new as a missing <target> has the same effect", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477361493", "createdAt": "2020-08-26T14:49:33Z", "author": {"login": "mcalmer"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51d60ad30ddc761fda44cda76ca697e317defec0"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NDM3NDgwOnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1MDoxMFrOHHP3SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1MDoxMFrOHHP3SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2MTk5Mg==", "bodyText": "state is an attribute for \"<target>\". Here it seems you set it on <trans-unit>\nhttp://docs.oasis-open.org/xliff/v1.2/os/xliff-core.html#state", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477361992", "createdAt": "2020-08-26T14:50:10Z", "author": {"login": "mcalmer"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51d60ad30ddc761fda44cda76ca697e317defec0"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NDM4NDgyOnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1MjoxN1rOHHP9fA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1MjoxN1rOHHP9fA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2MzU4MA==", "bodyText": "Can we be sure that trans_unit[0] is element \"source\"? I think we better pick the source element explicit.", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477363580", "createdAt": "2020-08-26T14:52:17Z", "author": {"login": "mcalmer"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')\n+        trans_unit[0].text = id_new_value_dict[trans_unit.attrib['id']]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51d60ad30ddc761fda44cda76ca697e317defec0"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NDM4Njg0OnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1Mjo0N1rOHHP-1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1Mjo0N1rOHHP-1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2MzkyNA==", "bodyText": "Can we be sure that tr_unit[0] is element \"source\"? I think we better pick the source element explicit.", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477363924", "createdAt": "2020-08-26T14:52:47Z", "author": {"login": "mcalmer"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')\n+        trans_unit[0].text = id_new_value_dict[trans_unit.attrib['id']]\n+\n+\n+def process(original_file, translation_file):\n+    xml_tree_original = ET.parse(original_file)\n+    xml_tree_translation = ET.parse(translation_file)\n+    original_body_element, original_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, translation_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in original_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in translation_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, translation_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, original_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    translation_trans_units = list(translation_body_element)\n+\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in original file {original_file}')\n+    if len(translation_trans_units) == len(original_trans_units):\n+        trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in translation_trans_units}\n+        org_trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in original_trans_units}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51d60ad30ddc761fda44cda76ca697e317defec0"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NDM5MTYwOnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1Mzo0NlrOHHQBtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1Mzo0NlrOHHQBtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2NDY2MA==", "bodyText": "What about else: (if len(translation_trans_units) == len(original_trans_units):)\nI think we should at least write a message", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477364660", "createdAt": "2020-08-26T14:53:46Z", "author": {"login": "mcalmer"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')\n+        trans_unit[0].text = id_new_value_dict[trans_unit.attrib['id']]\n+\n+\n+def process(original_file, translation_file):\n+    xml_tree_original = ET.parse(original_file)\n+    xml_tree_translation = ET.parse(translation_file)\n+    original_body_element, original_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, translation_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in original_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in translation_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, translation_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, original_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    translation_trans_units = list(translation_body_element)\n+\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in original file {original_file}')\n+    if len(translation_trans_units) == len(original_trans_units):\n+        trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in translation_trans_units}\n+        org_trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in original_trans_units}\n+        to_update = {k: org_trans_units_sources[k] for k,_ in set(org_trans_units_sources.items()) - set(trans_units_sources.items())}\n+        logging.info(f' These (id,new_source_value) -> {to_update}, will be updated in the {translation_file} ')\n+        update_trans_units(translation_body_element,translation_trans_units,to_update)\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51d60ad30ddc761fda44cda76ca697e317defec0"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NDM5NTczOnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1NDozOVrOHHQESQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNDo1NDozOVrOHHQESQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2NTMyMQ==", "bodyText": "Would be good if we could provide the working directory as command line parameter.", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477365321", "createdAt": "2020-08-26T14:54:39Z", "author": {"login": "mcalmer"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')\n+        trans_unit[0].text = id_new_value_dict[trans_unit.attrib['id']]\n+\n+\n+def process(original_file, translation_file):\n+    xml_tree_original = ET.parse(original_file)\n+    xml_tree_translation = ET.parse(translation_file)\n+    original_body_element, original_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, translation_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in original_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in translation_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, translation_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, original_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    translation_trans_units = list(translation_body_element)\n+\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in original file {original_file}')\n+    if len(translation_trans_units) == len(original_trans_units):\n+        trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in translation_trans_units}\n+        org_trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in original_trans_units}\n+        to_update = {k: org_trans_units_sources[k] for k,_ in set(org_trans_units_sources.items()) - set(trans_units_sources.items())}\n+        logging.info(f' These (id,new_source_value) -> {to_update}, will be updated in the {translation_file} ')\n+        update_trans_units(translation_body_element,translation_trans_units,to_update)\n+\n+\n+    #xml_tree_translation.write(translation, encoding='utf-8', xml_declaration=True)\n+    logging.info(\"########## FINISH ##########\")\n+\n+\n+def get_trans_units(xml_tree):\n+    root_node = xml_tree.getroot()\n+    # file_tag = root_node[0]\n+    body_element = root_node[0][0]\n+    return body_element, list(body_element)\n+\n+\n+ET.register_namespace('', \"urn:oasis:names:tc:xliff:document:1.1\")\n+ET.register_namespace('xyz', \"urn:appInfo:Items\")\n+ET.register_namespace('xsi', \"http://www.w3.org/2001/XMLSchema-instance\")\n+\n+files = os.listdir('.')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51d60ad30ddc761fda44cda76ca697e317defec0"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMzYyMDMzOnYy", "diffSide": "RIGHT", "path": "scripts/translation/trans-units-extractor.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMTo1ODoxNFrOHNKzDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMTo1ODoxNFrOHNKzDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU3MDQ0NQ==", "bodyText": "This parameter is not being used. I guess it can be removed?", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483570445", "createdAt": "2020-09-04T11:58:14Z", "author": {"login": "parlt91"}, "path": "scripts/translation/trans-units-extractor.py", "diffHunk": "@@ -0,0 +1,62 @@\n+#!/usr/bin/python3\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+import argparse\n+argparser = argparse.ArgumentParser()\n+argparser.add_argument(\"path\", help=\"Path to look into for translation files!\")\n+args = argparser.parse_args()\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+class CommentedTreeBuilder(ET.TreeBuilder):\n+    def comment(self, data):\n+        self.start(ET.Comment, {})\n+        self.data(data)\n+        self.end(ET.Comment)\n+\n+\n+def get_groups(xml_tree):\n+    root_node = xml_tree.getroot()\n+    file_tag = root_node.find('d:file', ns)\n+    body_element = file_tag.find('d:body', ns)\n+    groups = list(body_element.findall('d:group', ns))\n+    logging.info(\"'{0}' <group> elements are found\".format(len(groups)))\n+    return body_element, groups\n+\n+\n+def extract_trans_units(org_file):\n+    parser = ET.XMLParser(target=CommentedTreeBuilder())\n+    tree = ET.parse(file, parser=parser)\n+    body_element, groups = get_groups(tree)\n+    for group in groups:\n+        all_child_elements_of_body = list(body_element)\n+        context_group = group.find('d:context-group', ns)\n+        group_trans_units = group.findall('d:trans-unit', ns)\n+        index = all_child_elements_of_body.index(group)\n+        group_trans_units.reverse()\n+        for group_trans_unit in group_trans_units:\n+            if context_group is not None:\n+                group_trans_unit.append(context_group)\n+            body_element.insert(index, group_trans_unit)\n+        body_element.remove(group)\n+\n+    tree.write(org_file, encoding='utf-8', xml_declaration=True)\n+\n+\n+\n+ET.register_namespace('', \"urn:oasis:names:tc:xliff:document:1.1\")\n+ET.register_namespace('xyz', \"urn:appInfo:Items\")\n+ET.register_namespace('xsi', \"http://www.w3.org/2001/XMLSchema-instance\")\n+ns = {'d': 'urn:oasis:names:tc:xliff:document:1.1'}\n+\n+os.chdir(args.path)\n+files = os.listdir(args.path)\n+logging.debug(files)\n+\n+for file in files:\n+    if file.startswith('StringResource_') and file.endswith('.xml'):\n+        original = 'StringResource_en_US.xml'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab049c99da4a96e073cd91d8be71324841b259a4"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMzY0NDUyOnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMjowNzowMlrOHNLBrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMjowNzowMlrOHNLBrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU3NDE4OQ==", "bodyText": "parser -> argparser", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483574189", "createdAt": "2020-09-04T12:07:02Z", "author": {"login": "parlt91"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,122 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+import argparse\n+argparser = argparse.ArgumentParser()\n+argparser.add_argument(\"path\", help=\"Path to look into for translation files!\")\n+args = parser.parse_args()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab049c99da4a96e073cd91d8be71324841b259a4"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMzY5NjQyOnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMjoyNDoxNlrOHNLg3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMjoyNjoyMlrOHNLkyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4MjE3NQ==", "bodyText": "Using the same instance of parser two parse both files does not seem to work for me\nINFO:root:\nprocessing StringResource_ca.xml\nTraceback (most recent call last):\n  File \"/home/pascal/git/uyuni/scripts/translation/xliffmerger.py\", line 123, in <module>\n    process(original, translation)\n  File \"/home/pascal/git/uyuni/scripts/translation/xliffmerger.py\", line 53, in process\n    xml_tree_original = ET.parse(original_file, parser=parser)\n  File \"/usr/lib64/python3.6/xml/etree/ElementTree.py\", line 1196, in parse\n    tree.parse(source, parser)\n  File \"/usr/lib64/python3.6/xml/etree/ElementTree.py\", line 603, in parse\n    parser.feed(data)\nxml.etree.ElementTree.ParseError: parsing finished: line 23921, column 8", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483582175", "createdAt": "2020-09-04T12:24:16Z", "author": {"login": "parlt91"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -40,8 +47,9 @@ def update_trans_units(body_element, trans_units, id_new_value_dict):\n \n \n def process(original_file, translation_file):\n-    xml_tree_original = ET.parse(original_file)\n-    xml_tree_translation = ET.parse(translation_file)\n+    parser = ET.XMLParser(target=CommentedTreeBuilder())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab049c99da4a96e073cd91d8be71324841b259a4"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4MzE3OA==", "bodyText": "Creating two parsers seems to work\nparser1 = ET.XMLParser(target=CommentedTreeBuilder())\nparser2 = ET.XMLParser(target=CommentedTreeBuilder())\nxml_tree_original = ET.parse(original_file, parser=parser1)\nxml_tree_translation = ET.parse(translation_file, parser=parser2)\n\nI have no idea why though", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483583178", "createdAt": "2020-09-04T12:26:22Z", "author": {"login": "parlt91"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -40,8 +47,9 @@ def update_trans_units(body_element, trans_units, id_new_value_dict):\n \n \n def process(original_file, translation_file):\n-    xml_tree_original = ET.parse(original_file)\n-    xml_tree_translation = ET.parse(translation_file)\n+    parser = ET.XMLParser(target=CommentedTreeBuilder())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4MjE3NQ=="}, "originalCommit": {"oid": "ab049c99da4a96e073cd91d8be71324841b259a4"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMzcwNjM0OnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMjoyNzozNFrOHNLm8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMjoyNzozNFrOHNLm8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4MzcyOA==", "bodyText": "Should be un-commented before merging", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483583728", "createdAt": "2020-09-04T12:27:34Z", "author": {"login": "parlt91"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,122 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+import argparse\n+argparser = argparse.ArgumentParser()\n+argparser.add_argument(\"path\", help=\"Path to look into for translation files!\")\n+args = parser.parse_args()\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+class CommentedTreeBuilder(ET.TreeBuilder):\n+    def comment(self, data):\n+        self.start(ET.Comment, {})\n+        self.data(data)\n+        self.end(ET.Comment)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        target_element = ET.Element('target', {'state': 'new'})\n+        target_element.tail = \"\\n  \"\n+        item.append(target_element)\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        source_element = trans_unit.find('d:source', ns)\n+        source_element.text = id_new_value_dict[trans_unit.attrib['id']]\n+        target_element = trans_unit.find('d:target', ns)\n+        if target_element is None:\n+            target_element = ET.Element('target', {'state': 'needs-adaptation'})\n+            target_element.tail = \"\\n      \"\n+            trans_unit.append(target_element)\n+        else:\n+            target_element.set('state', 'needs-adaptation')\n+\n+\n+def process(original_file, translation_file):\n+    parser = ET.XMLParser(target=CommentedTreeBuilder())\n+    xml_tree_original = ET.parse(original_file, parser=parser)\n+    xml_tree_translation = ET.parse(translation_file, parser=parser)\n+    original_body_element, orig_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, trans_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(orig_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(trans_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in orig_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in trans_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, trans_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, orig_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    trans_trans_units = list(translation_body_element.findall('d:trans-unit', ns))\n+\n+    logging.debug(f'{len(orig_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(trans_trans_units)} trans_units in original file {original_file}')\n+    if len(trans_trans_units) == len(orig_trans_units):\n+        trans_units_srcs = {tr_unit.attrib['id']: tr_unit.find('d:source', ns).text for tr_unit in trans_trans_units}\n+        org_trans_units_srcs = {tr_unit.attrib['id']: tr_unit.find('d:source', ns).text for tr_unit in orig_trans_units}\n+        to_update = {k: org_trans_units_srcs[k] for k, _ in\n+                     set(org_trans_units_srcs.items()) - set(trans_units_srcs.items())}\n+        logging.info(f' These (id,new_source_value) -> {to_update}, will be updated in the {translation_file} ')\n+        update_trans_units(translation_body_element, trans_trans_units, to_update)\n+    else:\n+        logging.info(\"Something went wrong, this should not have happend!\")\n+\n+\n+    #xml_tree_translation.write(translation, encoding='utf-8', xml_declaration=True)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab049c99da4a96e073cd91d8be71324841b259a4"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMzcwODU3OnYy", "diffSide": "RIGHT", "path": "scripts/translation/xliffmerger.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMjoyODoxOFrOHNLoUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxMjoyODoxOFrOHNLoUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4NDA4MA==", "bodyText": "Also make sure to remove unneeded comments", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483584080", "createdAt": "2020-09-04T12:28:18Z", "author": {"login": "parlt91"}, "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,122 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+import argparse\n+argparser = argparse.ArgumentParser()\n+argparser.add_argument(\"path\", help=\"Path to look into for translation files!\")\n+args = parser.parse_args()\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+class CommentedTreeBuilder(ET.TreeBuilder):\n+    def comment(self, data):\n+        self.start(ET.Comment, {})\n+        self.data(data)\n+        self.end(ET.Comment)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        target_element = ET.Element('target', {'state': 'new'})\n+        target_element.tail = \"\\n  \"\n+        item.append(target_element)\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        source_element = trans_unit.find('d:source', ns)\n+        source_element.text = id_new_value_dict[trans_unit.attrib['id']]\n+        target_element = trans_unit.find('d:target', ns)\n+        if target_element is None:\n+            target_element = ET.Element('target', {'state': 'needs-adaptation'})\n+            target_element.tail = \"\\n      \"\n+            trans_unit.append(target_element)\n+        else:\n+            target_element.set('state', 'needs-adaptation')\n+\n+\n+def process(original_file, translation_file):\n+    parser = ET.XMLParser(target=CommentedTreeBuilder())\n+    xml_tree_original = ET.parse(original_file, parser=parser)\n+    xml_tree_translation = ET.parse(translation_file, parser=parser)\n+    original_body_element, orig_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, trans_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(orig_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(trans_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in orig_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in trans_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, trans_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, orig_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    trans_trans_units = list(translation_body_element.findall('d:trans-unit', ns))\n+\n+    logging.debug(f'{len(orig_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(trans_trans_units)} trans_units in original file {original_file}')\n+    if len(trans_trans_units) == len(orig_trans_units):\n+        trans_units_srcs = {tr_unit.attrib['id']: tr_unit.find('d:source', ns).text for tr_unit in trans_trans_units}\n+        org_trans_units_srcs = {tr_unit.attrib['id']: tr_unit.find('d:source', ns).text for tr_unit in orig_trans_units}\n+        to_update = {k: org_trans_units_srcs[k] for k, _ in\n+                     set(org_trans_units_srcs.items()) - set(trans_units_srcs.items())}\n+        logging.info(f' These (id,new_source_value) -> {to_update}, will be updated in the {translation_file} ')\n+        update_trans_units(translation_body_element, trans_trans_units, to_update)\n+    else:\n+        logging.info(\"Something went wrong, this should not have happend!\")\n+\n+\n+    #xml_tree_translation.write(translation, encoding='utf-8', xml_declaration=True)\n+\n+\n+def get_trans_units(xml_tree):\n+    root_node = xml_tree.getroot()\n+    # file_tag = root_node[0]\n+    file_tag = root_node.find('d:file', ns)\n+    # body_element = root_node[0][0]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab049c99da4a96e073cd91d8be71324841b259a4"}, "originalPosition": 103}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4163, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}