{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMyMTc0ODUz", "number": 511, "reviewThreads": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1MToyMFrOFG-8Lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDowMDo0OFrOFNdYvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY2OTkxOnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1MToyMFrOIIP-Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQyMzowNDo1MlrOIOEPQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTIzNA==", "bodyText": "so what will happen when val is null and toFlatten == true ? It will NPE on val.toString(). What should be the expected result ? We also need a unit test for this.", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545521234", "createdAt": "2020-12-18T01:51:20Z", "author": {"login": "denalex"}, "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -611,8 +612,8 @@ private void resolvePrimitive(Object o, PrimitiveObjectInspector oi,\n             case STRING: {\n                 val = (o != null) ? ((StringObjectInspector) oi).getPrimitiveJavaObject(o)\n                         : null;\n-                addOneFieldToRecord(record, DataType.TEXT,\n-                        toFlatten ? String.format(\"\\\"%s\\\"\", val) : val);\n+                val = toFlatten ? String.format(\"\\\"%s\\\"\", StringEscapeUtils.escapeJava(val.toString())) : val;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTYyMDQxOA==", "bodyText": "We added an additional conditional as well as an automation test for the null case.", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r551620418", "createdAt": "2021-01-04T23:04:52Z", "author": {"login": "ashuka24"}, "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -611,8 +612,8 @@ private void resolvePrimitive(Object o, PrimitiveObjectInspector oi,\n             case STRING: {\n                 val = (o != null) ? ((StringObjectInspector) oi).getPrimitiveJavaObject(o)\n                         : null;\n-                addOneFieldToRecord(record, DataType.TEXT,\n-                        toFlatten ? String.format(\"\\\"%s\\\"\", val) : val);\n+                val = toFlatten ? String.format(\"\\\"%s\\\"\", StringEscapeUtils.escapeJava(val.toString())) : val;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTIzNA=="}, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY3MTE5OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1MjowNFrOIIP_DQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQyMzowNjo1M1rOIOESkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTQyMQ==", "bodyText": "so \\u0002 is a separator of data within the struct value ?", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545521421", "createdAt": "2020-12-18T01:52:04Z", "author": {"login": "denalex"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"plain string\\u00021001\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTYyMTI2NQ==", "bodyText": "Yes, I found this value by debugging a live session containing a nested struct. Further nesting would result in larger numbers, ex: \\u0003 signifies a separation of data nested further down the struct.", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r551621265", "createdAt": "2021-01-04T23:06:53Z", "author": {"login": "ashuka24"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"plain string\\u00021001\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTQyMQ=="}, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY3MjQ2OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1MjozOFrOIIP_uA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1MjozOFrOIIP_uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTU5Mg==", "bodyText": "Why do we need to escape the string using java rules? can we add a comment why we are doing this?", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545521592", "createdAt": "2020-12-18T01:52:38Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -611,8 +612,8 @@ private void resolvePrimitive(Object o, PrimitiveObjectInspector oi,\n             case STRING: {\n                 val = (o != null) ? ((StringObjectInspector) oi).getPrimitiveJavaObject(o)\n                         : null;\n-                addOneFieldToRecord(record, DataType.TEXT,\n-                        toFlatten ? String.format(\"\\\"%s\\\"\", val) : val);\n+                val = toFlatten ? String.format(\"\\\"%s\\\"\", StringEscapeUtils.escapeJava(val.toString())) : val;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY3NjI2OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1NDozMVrOIIQB0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1NDozMVrOIIQB0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMjEzMQ==", "bodyText": "\ud83d\udc4d  +1 for adding this class", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545522131", "createdAt": "2020-12-18T01:54:31Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY4NDY3OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1ODoyM1rOIIQGaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1ODoyM1rOIIQGaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMzMwNw==", "bodyText": "i don't think it matters , but just to make it accurate, can we change the indexes here:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n          \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n          \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 0, \"text\", null));\n          \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 1, \"float8\", null));", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545523307", "createdAt": "2020-12-18T01:58:23Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY4Njg2OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMTo1OTozMVrOIIQHsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQyMjo1Mjo1OVrOIOD-6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMzYzMg==", "bodyText": "can we remove the comment?\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n          \n          \n            \n                    context.setMetadata(new HiveMetadata(properties, null, hiveIndexes));", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545523632", "createdAt": "2020-12-18T01:59:31Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTYxNjIzMw==", "bodyText": "I have the comment there for clarity. It is mostly to show that HiveMetadata requires a list of HivePartitions, but for these test cases this list is not necessary.", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r551616233", "createdAt": "2021-01-04T22:52:59Z", "author": {"login": "ashuka24"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMzYzMg=="}, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY4ODgwOnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowMDoyNlrOIIQIyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowMDoyNlrOIIQIyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMzkxNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"plain string\\u00011000\"));", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545523915", "createdAt": "2020-12-18T02:00:26Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY5MDM2OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowMToyMVrOIIQJrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowMToyMVrOIIQJrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNDE0MQ==", "bodyText": "aren't we expecting two OneFields since we have two columns?", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545524141", "createdAt": "2020-12-18T02:01:21Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY5MjMzOnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowMjoxN1rOIIQKug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowMjoxN1rOIIQKug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNDQxMA==", "bodyText": "same comment as above?", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545524410", "createdAt": "2020-12-18T02:02:17Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY5NDk2OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowMzozOVrOIIQMUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowMzozOVrOIIQMUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNDgxOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545524819", "createdAt": "2020-12-18T02:03:39Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODY5NjI5OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowNDoxM1rOIIQNEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowNDoxM1rOIIQNEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNTAwOA==", "bodyText": "again, here shouldn't we expect two OneFields in the resulting list?", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545525008", "createdAt": "2020-12-18T02:04:13Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODcwMjIwOnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowNzowMFrOIIQQdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowNzowMFrOIIQQdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNTg3OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n          \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 0, \"struct\", null));", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545525879", "createdAt": "2020-12-18T02:07:00Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODcwNDA1OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowNzo0NlrOIIQRhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowNzo0NlrOIIQRhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNjE0OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545526148", "createdAt": "2020-12-18T02:07:46Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"plain string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODcwODA5OnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowOToyOFrOIIQTuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjowOToyOFrOIIQTuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNjcxMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\",\\\"zipcode\\\":1001}\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"{\\\"street\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\",\\\"zipcode\\\":1001}\"));", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545526712", "createdAt": "2020-12-18T02:09:28Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"plain string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));\n+    }\n+\n+    @Test\n+    public void testStructSpecialCharString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"a really \\\"fancy\\\" string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\",\\\"zipcode\\\":1001}\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyODcxMDAxOnYy", "diffSide": "RIGHT", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjoxMDozMVrOIIQU3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwMjoxMDozMVrOIIQU3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNzAwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"{\\\"line1\\\":{\\\"number\\\":1000,\\\"street_name\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\"},\\\"line2\\\":{\\\"city\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}}\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"{\\\"line1\\\":{\\\"number\\\":1000,\\\"street_name\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\"},\\\"line2\\\":{\\\"city\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}}\"));", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545527005", "createdAt": "2020-12-18T02:10:31Z", "author": {"login": "frankgh"}, "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"plain string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));\n+    }\n+\n+    @Test\n+    public void testStructSpecialCharString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"a really \\\"fancy\\\" string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\",\\\"zipcode\\\":1001}\"));\n+    }\n+\n+    @Test\n+    public void testNestedStruct() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_NESTED_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_NESTED_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"1000\\u0003a really \\\"fancy\\\" string\\u0002plain string\\u00031001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"line1\\\":{\\\"number\\\":1000,\\\"street_name\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\"},\\\"line2\\\":{\\\"city\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}}\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5"}, "originalPosition": 163}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjU3Mjc4OnYy", "diffSide": "RIGHT", "path": "automation/jsystem.properties", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDowMDo0OFrOIRr5XA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDowMDo0OFrOIRr5XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQxNTkwMA==", "bodyText": "you probably don't want to commit this change", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r555415900", "createdAt": "2021-01-12T00:00:48Z", "author": {"login": "denalex"}, "path": "automation/jsystem.properties", "diffHunk": "@@ -13,5 +13,5 @@ reporter.classes=jsystem.extensions.report.html.LevelHtmlTestReporter;jsystem.fr\n resources.src=/home/gpadmin/workspace/pxf/automation/src/main/resources\n sutClassName=jsystem.framework.sut.SutImpl\n sutFile=default.xml\n-tests.dir=/home/gpadmin/workspace/pxf/automation/target/test-classes\n+tests.dir=/Users/axue/workspace/pxf/automation/target/test-classes", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "baa70eadf71f04097d355043a04c98e47aac8d57"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3373, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}