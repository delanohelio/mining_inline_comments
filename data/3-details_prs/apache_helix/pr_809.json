{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc5OTU5NDQy", "number": 809, "title": "Add system property options to config write size limit for ZNRecord Serializer", "bodyText": "Issues\n\n My PR addresses the following Helix issues and references them in the PR description:\n\nImplements #808\nDescription\n\n Here are some details about my PR, including screenshots of any UI changes:\n\nAuto compression is by default enabled now in ZK serializer. Customers requested an option to config threshold based on their requirements.\nThis PR adds two system property options\n\nto config ZNRecord serializer threshold to limit serialized data write size. If the serialized data size exceeds the configured threshold, the data will NOT be written to ZK.\nto enable/disable auto compression in ZNRecord serializer. By default, it is enabled.\n\n\n\n\nproperty name\nvalue type\ndefault value\n\n\n\n\nzk.serializer.znrecord.write.size.limit.bytes\ninteger\n1 MB\n\n\nzk.serializer.znrecord.auto-compress.enabled\nboolean\ntrue\n\n\n\nTests\n\n\n The following tests are written for this issue:\n\n\nTestZNRecordSerializeCompression.testZNRecordSerializerCompressThreshold\n\n\nTestZNRecordSizeLimit.testZNRecordSerializerCompressThreshold\n\n\nTestZNRecordSizeLimit.testZNRecordStreamingSerializerCompressThreshold\n\n\n The following is the result of the \"mvn test\" command on the appropriate module:\n\n\nResults :\n\nFailed tests:\norg.apache.helix.integration.rebalancer.CrushRebalancers.TestCrushAutoRebalanceNonRack.testLackEnoughInstances(org.apache.helix.integration.rebalancer.CrushRebalancers.TestCrushAutoRebalanceNonRack)\n  Run 1: PASS\n  Run 2: TestCrushAutoRebalanceNonRack.testLackEnoughInstances:250 \u00bb ZkClient Failed to...\n\norg.apache.helix.integration.rebalancer.CrushRebalancers.TestCrushAutoRebalanceTopoplogyAwareDisabled.testLackEnoughInstances(org.apache.helix.integration.rebalancer.CrushRebalancers.TestCrushAutoRebalanceTopoplogyAwareDisabled)\n  Run 1: PASS\n  Run 2: TestCrushAutoRebalanceTopoplogyAwareDisabled.testLackEnoughInstances:86->TestCrushAutoRebalanceNonRack.testLackEnoughInstances:250 \u00bb ZkClient\n\n  TestTaskRebalancer.timeouts:200 expected:<true> but was:<false>\n  TestWorkflowTermination.testWorkflowRunningTimeout:131->verifyWorkflowCleanup:257 expected:<true> but was:<false>\n\nTests run: 1082, Failures: 4, Errors: 0, Skipped: 1\n\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  01:07 h\n[INFO] Finished at: 2020-02-28T19:19:01-08:00\n[INFO] ------------------------------------------------------------------------\n\n\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.543 sec - in org.apache.helix.integration.rebalancer.CrushRebalancers.TestCrushAutoRebalanceNonRack\n\nResults :\n\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0\n\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  19.846 s\n[INFO] Finished at: 2020-02-28T20:21:35-08:00\n[INFO] ------------------------------------------------------------------------\n\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.56 sec - in org.apache.helix.integration.rebalancer.CrushRebalancers.TestCrushAutoRebalanceTopoplogyAwareDisabled\n\nResults :\n\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0\n\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  20.932 s\n[INFO] Finished at: 2020-02-28T20:22:27-08:00\n[INFO] ------------------------------------------------------------------------\n\n\nIn zookeeper-api module:\n\nTests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.522 sec - in TestSuite\n\nResults :\n\nTests run: 2, Failures: 0, Errors: 0, Skipped: 0\n\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  7.526 s\n[INFO] Finished at: 2020-02-28T20:37:34-08:00\n[INFO] ------------------------------------------------------------------------\n\n\nCommits\n\n My commits all reference appropriate Apache Helix GitHub issues in their subject lines, and I have squashed multiple commits if they address the same issue. In addition, my commits follow the guidelines from \"How to write a good git commit message\":\n\nSubject is separated from body by a blank line\nSubject is limited to 50 characters (not including Jira issue reference)\nSubject does not end with a period\nSubject uses the imperative mood (\"add\", not \"adding\")\nBody wraps at 72 characters\nBody explains \"what\" and \"why\", not \"how\"\n\n\n\nDocumentation\n\n In case of new functionality, my PR adds documentation in the following wiki page:\n\n(Link the GitHub wiki you added)\nCode Quality\n\n My diff has been formatted using helix-style.xml", "createdAt": "2020-02-26T02:00:10Z", "url": "https://github.com/apache/helix/pull/809", "merged": true, "mergeCommit": {"oid": "0f3c64be152d07db272d8560a50fcdcedff2e5b6"}, "closed": true, "closedAt": "2020-02-29T17:19:32Z", "author": {"login": "huizhilu"}, "timelineItems": {"totalCount": 44, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcH9XaYABqjMwNzE5MDE0OTM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcI_lQDgFqTM2Njc4MzkxNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ccc9dbdec86d280a89f242907e47de2ead9ff9dc", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/ccc9dbdec86d280a89f242907e47de2ead9ff9dc", "committedDate": "2020-02-26T01:40:08Z", "message": "Add options to config auto compression."}, "afterCommit": {"oid": "a844abe838743838306712294b05aaf81cc1748a", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/a844abe838743838306712294b05aaf81cc1748a", "committedDate": "2020-02-26T01:40:36Z", "message": "Add options to config auto compression"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/3d772ffd135b8d648ec914fa253002dce9b5616c", "committedDate": "2020-02-26T03:47:59Z", "message": "Add options to config auto compression"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a844abe838743838306712294b05aaf81cc1748a", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/a844abe838743838306712294b05aaf81cc1748a", "committedDate": "2020-02-26T01:40:36Z", "message": "Add options to config auto compression"}, "afterCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/3d772ffd135b8d648ec914fa253002dce9b5616c", "committedDate": "2020-02-26T03:47:59Z", "message": "Add options to config auto compression"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MTEyMzA0", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-365112304", "createdAt": "2020-02-26T17:50:45Z", "commit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo1MDo0NVrOFu1zbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo1MDo0NVrOFu1zbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY2MDMzNQ==", "bodyText": "What if user inputs a typo?", "url": "https://github.com/apache/helix/pull/809#discussion_r384660335", "createdAt": "2020-02-26T17:50:45Z", "author": {"login": "junkaixue"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -38,6 +39,17 @@\n public class ZNRecordSerializer implements ZkSerializer {\n   private static Logger logger = LoggerFactory.getLogger(ZNRecordSerializer.class);\n \n+  // Reads from system property and represents whether auto compression is enabled or not.\n+  // If and only if this property is set to \"true\", auto compression is enabled.\n+  private final boolean autoCompressionEnabled =\n+      Boolean.getBoolean(ZkSystemPropertyKeys.ZK_SERIALIZER_AUTO_COMPRESSION_ENABLED);\n+\n+  // Reads from system property and represents the data size threshold in bytes for\n+  // auto compression.\n+  private final int autoCompressionThreshold = Integer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MTEyNzcz", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-365112773", "createdAt": "2020-02-26T17:51:25Z", "commit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo1MToyNVrOFu107A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo1MToyNVrOFu107A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY2MDcxNg==", "bodyText": "Is default value true with this statement?", "url": "https://github.com/apache/helix/pull/809#discussion_r384660716", "createdAt": "2020-02-26T17:51:25Z", "author": {"login": "junkaixue"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -38,6 +39,17 @@\n public class ZNRecordSerializer implements ZkSerializer {\n   private static Logger logger = LoggerFactory.getLogger(ZNRecordSerializer.class);\n \n+  // Reads from system property and represents whether auto compression is enabled or not.\n+  // If and only if this property is set to \"true\", auto compression is enabled.\n+  private final boolean autoCompressionEnabled =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MTE1ODM4", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-365115838", "createdAt": "2020-02-26T17:55:46Z", "commit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo1NTo0NlrOFu1-Ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo1ODozM1rOFu2ELw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY2MzA0Mg==", "bodyText": "No. By default: not set or empty or invalid string, it is false. Like the comment said, If and only if this property is set to \"true\", auto compression is enabled.", "url": "https://github.com/apache/helix/pull/809#discussion_r384663042", "createdAt": "2020-02-26T17:55:46Z", "author": {"login": "huizhilu"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -38,6 +39,17 @@\n public class ZNRecordSerializer implements ZkSerializer {\n   private static Logger logger = LoggerFactory.getLogger(ZNRecordSerializer.class);\n \n+  // Reads from system property and represents whether auto compression is enabled or not.\n+  // If and only if this property is set to \"true\", auto compression is enabled.\n+  private final boolean autoCompressionEnabled =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY2MDcxNg=="}, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY2NDYyMw==", "bodyText": "If there is no property of the specified name, if the property does not have the correct numeric format, or if the specified name is empty or null, the default value ZNRecord.SIZE_LIMIT would be used.", "url": "https://github.com/apache/helix/pull/809#discussion_r384664623", "createdAt": "2020-02-26T17:58:33Z", "author": {"login": "huizhilu"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -38,6 +39,17 @@\n public class ZNRecordSerializer implements ZkSerializer {\n   private static Logger logger = LoggerFactory.getLogger(ZNRecordSerializer.class);\n \n+  // Reads from system property and represents whether auto compression is enabled or not.\n+  // If and only if this property is set to \"true\", auto compression is enabled.\n+  private final boolean autoCompressionEnabled =\n+      Boolean.getBoolean(ZkSystemPropertyKeys.ZK_SERIALIZER_AUTO_COMPRESSION_ENABLED);\n+\n+  // Reads from system property and represents the data size threshold in bytes for\n+  // auto compression.\n+  private final int autoCompressionThreshold = Integer", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY2MDMzNQ=="}, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MTM3OTEy", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-365137912", "createdAt": "2020-02-26T18:28:48Z", "commit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxODoyODo0OFrOFu3EEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxODoyODo1NFrOFu3EQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY4MDk3OA==", "bodyText": "It's actually the ZNRecord serializer, not zkSerializer, right? I don't think we support auto-compression in ZkSerializer?", "url": "https://github.com/apache/helix/pull/809#discussion_r384680978", "createdAt": "2020-02-26T18:28:48Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/constant/ZkSystemPropertyKeys.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package org.apache.helix.zookeeper.constant;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+public class ZkSystemPropertyKeys {\n+  /**\n+   * Setting this property to true in system properties enables auto compression in ZK serializer.\n+   * The data will be automatically compressed by\n+   * {@link org.apache.helix.zookeeper.util.GZipCompressionUtil} when being written to Zookeeper\n+   * if size of serialized data exceeds the configured threshold.\n+   */\n+  public static final String ZK_SERIALIZER_AUTO_COMPRESSION_ENABLED =\n+      \"zk.serializer.auto-compression.enabled\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY4MTAyNg==", "bodyText": "It's actually the ZNRecord serializer, not zkSerializer, right? I don't think we support auto-compression in ZkSerializer?", "url": "https://github.com/apache/helix/pull/809#discussion_r384681026", "createdAt": "2020-02-26T18:28:54Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/constant/ZkSystemPropertyKeys.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package org.apache.helix.zookeeper.constant;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+public class ZkSystemPropertyKeys {\n+  /**\n+   * Setting this property to true in system properties enables auto compression in ZK serializer.\n+   * The data will be automatically compressed by\n+   * {@link org.apache.helix.zookeeper.util.GZipCompressionUtil} when being written to Zookeeper\n+   * if size of serialized data exceeds the configured threshold.\n+   */\n+  public static final String ZK_SERIALIZER_AUTO_COMPRESSION_ENABLED =\n+      \"zk.serializer.auto-compression.enabled\";\n+\n+  /**\n+   * This is property that defines the threshold in bytes for auto compression in ZK serializer.\n+   * Given auto compression is enabled, if the size of data exceeds this configured threshold,\n+   * the data will be automatically compressed when being written to Zookeeper.\n+   */\n+  public static final String ZK_SERIALIZER_AUTO_COMPRESSION_THRESHOLD_BYTES =\n+      \"zk.serializer.auto-compression.threshold.bytes\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MTQwMjk5", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-365140299", "createdAt": "2020-02-26T18:32:13Z", "commit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxODozMjoxM1rOFu3LRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxODozMjoxM1rOFu3LRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY4MjgyMg==", "bodyText": "ZnRecordStreamingSerializer also has this logic. It would be great if you could refactor this piece of logic out so that we support this in all of our ZNRecord serializers :)", "url": "https://github.com/apache/helix/pull/809#discussion_r384682822", "createdAt": "2020-02-26T18:32:13Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -86,7 +98,8 @@ private static int getListFieldBound(ZNRecord record) {\n       mapper.writeValue(baos, data);\n       serializedBytes = baos.toByteArray();\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (record.getBooleanField(\"enableCompression\", false) || (autoCompressionEnabled\n+          && serializedBytes.length > autoCompressionThreshold)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MjE1MTk5", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-365215199", "createdAt": "2020-02-26T20:23:32Z", "commit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDoyMzozMlrOFu65Qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMDoyODo1MVrOFu7C2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc0Mzc0Ng==", "bodyText": "Just call it ZNRECORD_AUTO_COMPRESSION_ENABLED?", "url": "https://github.com/apache/helix/pull/809#discussion_r384743746", "createdAt": "2020-02-26T20:23:32Z", "author": {"login": "jiajunwang"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/constant/ZkSystemPropertyKeys.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package org.apache.helix.zookeeper.constant;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+public class ZkSystemPropertyKeys {\n+  /**\n+   * Setting this property to true in system properties enables auto compression in ZK serializer.\n+   * The data will be automatically compressed by\n+   * {@link org.apache.helix.zookeeper.util.GZipCompressionUtil} when being written to Zookeeper\n+   * if size of serialized data exceeds the configured threshold.\n+   */\n+  public static final String ZK_SERIALIZER_AUTO_COMPRESSION_ENABLED =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc0Mzg3NQ==", "bodyText": "Same here, ZK_SERIALIZER -> ZNRECORD", "url": "https://github.com/apache/helix/pull/809#discussion_r384743875", "createdAt": "2020-02-26T20:23:52Z", "author": {"login": "jiajunwang"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/constant/ZkSystemPropertyKeys.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package org.apache.helix.zookeeper.constant;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+public class ZkSystemPropertyKeys {\n+  /**\n+   * Setting this property to true in system properties enables auto compression in ZK serializer.\n+   * The data will be automatically compressed by\n+   * {@link org.apache.helix.zookeeper.util.GZipCompressionUtil} when being written to Zookeeper\n+   * if size of serialized data exceeds the configured threshold.\n+   */\n+  public static final String ZK_SERIALIZER_AUTO_COMPRESSION_ENABLED =\n+      \"zk.serializer.auto-compression.enabled\";\n+\n+  /**\n+   * This is property that defines the threshold in bytes for auto compression in ZK serializer.\n+   * Given auto compression is enabled, if the size of data exceeds this configured threshold,\n+   * the data will be automatically compressed when being written to Zookeeper.\n+   */\n+  public static final String ZK_SERIALIZER_AUTO_COMPRESSION_THRESHOLD_BYTES =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc0NjIwMQ==", "bodyText": "This logic could go to the ZNRecord class. isAutoCompression()", "url": "https://github.com/apache/helix/pull/809#discussion_r384746201", "createdAt": "2020-02-26T20:28:51Z", "author": {"login": "jiajunwang"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -86,7 +98,8 @@ private static int getListFieldBound(ZNRecord record) {\n       mapper.writeValue(baos, data);\n       serializedBytes = baos.toByteArray();\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (record.getBooleanField(\"enableCompression\", false) || (autoCompressionEnabled\n+          && serializedBytes.length > autoCompressionThreshold)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY4MjgyMg=="}, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDAwNjMz", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366000633", "createdAt": "2020-02-27T21:11:16Z", "commit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMToxMToxNlrOFvhUgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMToxMToxNlrOFvhUgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTM3MzMxNA==", "bodyText": "The default should be ENABLED if this is for Pinot, right?", "url": "https://github.com/apache/helix/pull/809#discussion_r385373314", "createdAt": "2020-02-27T21:11:16Z", "author": {"login": "lei-xia"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -38,6 +39,17 @@\n public class ZNRecordSerializer implements ZkSerializer {\n   private static Logger logger = LoggerFactory.getLogger(ZNRecordSerializer.class);\n \n+  // Reads from system property and represents whether auto compression is enabled or not.\n+  // If and only if this property is set to \"true\", auto compression is enabled.\n+  private final boolean autoCompressionEnabled =\n+      Boolean.getBoolean(ZkSystemPropertyKeys.ZK_SERIALIZER_AUTO_COMPRESSION_ENABLED);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d772ffd135b8d648ec914fa253002dce9b5616c"}, "originalPosition": 15}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f8d8874d850409b42bb2fb31fbe3cf8d295c06b", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/7f8d8874d850409b42bb2fb31fbe3cf8d295c06b", "committedDate": "2020-02-27T23:09:20Z", "message": "Enable auto compression by default"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDY1NzI3", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366065727", "createdAt": "2020-02-27T23:13:32Z", "commit": {"oid": "7f8d8874d850409b42bb2fb31fbe3cf8d295c06b"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMzoxMzozMlrOFvkeYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMzoyMToyMFrOFvkoPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyNDk5NA==", "bodyText": "Remove it.", "url": "https://github.com/apache/helix/pull/809#discussion_r385424994", "createdAt": "2020-02-27T23:13:32Z", "author": {"login": "junkaixue"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/ZNRecord.java", "diffHunk": "@@ -49,6 +50,16 @@\n   @JsonIgnore(true)\n   public static final String LIST_FIELD_BOUND = \"listField.bound\";\n \n+  @JsonIgnore\n+  public static final String ENABLE_COMPRESSION_BOOLEAN_FIELD = \"enableCompression\";\n+\n+  /**\n+   * Default value for system property\n+   * {@link ZkSystemPropertyKeys#ZNRECORD_SERIALIZER_COMPRESS}\n+   */\n+  @JsonIgnore\n+  public static final String ZNRECORD_SERIALIZER_COMPRESS_DEFAULT_VALUE = \"true\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f8d8874d850409b42bb2fb31fbe3cf8d295c06b"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyNTM1Mw==", "bodyText": "We should not allow 0", "url": "https://github.com/apache/helix/pull/809#discussion_r385425353", "createdAt": "2020-02-27T23:14:43Z", "author": {"login": "junkaixue"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/ZNRecord.java", "diffHunk": "@@ -621,6 +632,22 @@ public void subtract(ZNRecord value) {\n     }\n   }\n \n+  /**\n+   * Returns compression threshold in bytes. The threshold is a smaller number determined by the\n+   * configured threshold and {@link ZNRecord#SIZE_LIMIT}.\n+   *\n+   * @return compress threshold in bytes\n+   */\n+  @JsonIgnore\n+  public int getCompressThreshold() {\n+    Integer threshold =\n+        Integer.getInteger(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES);\n+    if (threshold == null || threshold < 0 || threshold > ZNRecord.SIZE_LIMIT) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f8d8874d850409b42bb2fb31fbe3cf8d295c06b"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyNjEyNA==", "bodyText": "Move it to util", "url": "https://github.com/apache/helix/pull/809#discussion_r385426124", "createdAt": "2020-02-27T23:17:04Z", "author": {"login": "junkaixue"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/ZNRecord.java", "diffHunk": "@@ -621,6 +632,22 @@ public void subtract(ZNRecord value) {\n     }\n   }\n \n+  /**\n+   * Returns compression threshold in bytes. The threshold is a smaller number determined by the\n+   * configured threshold and {@link ZNRecord#SIZE_LIMIT}.\n+   *\n+   * @return compress threshold in bytes\n+   */\n+  @JsonIgnore\n+  public int getCompressThreshold() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f8d8874d850409b42bb2fb31fbe3cf8d295c06b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyNzUxNw==", "bodyText": "Let's put a TODO here for further clean up for the logs.", "url": "https://github.com/apache/helix/pull/809#discussion_r385427517", "createdAt": "2020-02-27T23:21:20Z", "author": {"login": "junkaixue"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -81,24 +82,38 @@ private static int getListFieldBound(ZNRecord record) {\n     serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n     serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n     ByteArrayOutputStream baos = new ByteArrayOutputStream();\n-    byte[] serializedBytes;\n+    byte[] serializedBytes = new byte[0];\n     try {\n       mapper.writeValue(baos, data);\n       serializedBytes = baos.toByteArray();\n+\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n         serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n       }\n     } catch (Exception e) {\n-      logger.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n-          + new String(baos.toByteArray()).substring(0, 1024), e);\n+      if (serializedBytes.length == 0 || GZipCompressionUtil.isCompressed(serializedBytes)) {\n+        serializedBytes = baos.toByteArray();\n+      }\n+      int firstBytesLength = Math.min(serializedBytes.length, 1024);\n+      LOG.error(\"Exception during data serialization. Will not write to zk.\"\n+              + \" The first {} bytes of data: {}\", firstBytesLength,\n+          new String(serializedBytes, 0, firstBytesLength), e);\n       throw new ZkClientException(e);\n     }\n-    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n-      logger.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n-          + \". Will not write to zk. Data (first 1k): \"\n-          + new String(serializedBytes).substring(0, 1024));\n-      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n+\n+    int compressThreshold = record.getCompressThreshold();\n+    if (serializedBytes.length > compressThreshold) {\n+      if (GZipCompressionUtil.isCompressed(serializedBytes)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f8d8874d850409b42bb2fb31fbe3cf8d295c06b"}, "originalPosition": 72}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e7b779a4d2e26cb9ff169c484a9417926de4a921", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/e7b779a4d2e26cb9ff169c484a9417926de4a921", "committedDate": "2020-02-27T23:47:15Z", "message": "Address comments."}, "afterCommit": {"oid": "1ed24303840f68aa50a1b95625806e200c453978", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/1ed24303840f68aa50a1b95625806e200c453978", "committedDate": "2020-02-27T23:52:28Z", "message": "Address comments."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1ed24303840f68aa50a1b95625806e200c453978", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/1ed24303840f68aa50a1b95625806e200c453978", "committedDate": "2020-02-27T23:52:28Z", "message": "Address comments."}, "afterCommit": {"oid": "0c85da48438242469357f81f5bd8bdda0e0d0734", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/0c85da48438242469357f81f5bd8bdda0e0d0734", "committedDate": "2020-02-27T23:56:01Z", "message": "Address comments."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0c85da48438242469357f81f5bd8bdda0e0d0734", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/0c85da48438242469357f81f5bd8bdda0e0d0734", "committedDate": "2020-02-27T23:56:01Z", "message": "Address comments."}, "afterCommit": {"oid": "8bf289f1aeb8d8b4ff2a5b0d8c6f18f1547260a7", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/8bf289f1aeb8d8b4ff2a5b0d8c6f18f1547260a7", "committedDate": "2020-02-28T01:08:48Z", "message": "Address comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/99b29378b98550fbda2da2588f8bedf4a469a039", "committedDate": "2020-02-28T01:12:41Z", "message": "Add tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8bf289f1aeb8d8b4ff2a5b0d8c6f18f1547260a7", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/8bf289f1aeb8d8b4ff2a5b0d8c6f18f1547260a7", "committedDate": "2020-02-28T01:08:48Z", "message": "Address comments."}, "afterCommit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/99b29378b98550fbda2da2588f8bedf4a469a039", "committedDate": "2020-02-28T01:12:41Z", "message": "Add tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MTExNDI1", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366111425", "createdAt": "2020-02-28T01:29:54Z", "commit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwMToyOTo1NFrOFvm4VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwMToyOTo1NFrOFvm4VQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ2NDQwNQ==", "bodyText": "nit: getCompressionThreshold", "url": "https://github.com/apache/helix/pull/809#discussion_r385464405", "createdAt": "2020-02-28T01:29:54Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/util/ZNRecordUtil.java", "diffHunk": "@@ -0,0 +1,59 @@\n+package org.apache.helix.zookeeper.util;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import org.apache.helix.zookeeper.constant.ZkSystemPropertyKeys;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+\n+\n+/**\n+ * This utility class contains various methods for manipulating ZNRecord.\n+ */\n+public class ZNRecordUtil {\n+\n+  /**\n+   * Checks whether or not a serialized ZNRecord bytes should be compressed before being written to\n+   * Zookeeper.\n+   *\n+   * @param record raw ZNRecord before being serialized\n+   * @param serializedLength length of the serialized bytes array\n+   * @return\n+   */\n+  public static boolean shouldCompress(ZNRecord record, int serializedLength) {\n+    if (record.getBooleanField(ZNRecord.ENABLE_COMPRESSION_BOOLEAN_FIELD, false)) {\n+      return true;\n+    }\n+\n+    return serializedLength > getCompressThreshold();\n+  }\n+\n+  /**\n+   * Returns compression threshold in bytes. The threshold is a smaller number determined by the\n+   * configured threshold and {@link ZNRecord#SIZE_LIMIT}.\n+   */\n+  public static int getCompressThreshold() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "originalPosition": 51}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MTEyOTkx", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366112991", "createdAt": "2020-02-28T01:35:12Z", "commit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwMTozNToxMlrOFvm9rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwMTo0NTo0OFrOFvnICg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ2NTc3NQ==", "bodyText": "I think it might be a good idea to also log and include in the exception message whether the ZNRecord was compressed or not. Adding a boolean isCompressed would do?", "url": "https://github.com/apache/helix/pull/809#discussion_r385465775", "createdAt": "2020-02-28T01:35:12Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordStreamingSerializer.java", "diffHunk": "@@ -154,20 +155,31 @@ private static int getListFieldBound(ZNRecord record) {\n       g.close();\n       serializedBytes = baos.toByteArray();\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n         serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n       }\n     } catch (Exception e) {\n-      LOG.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n-          + new String(baos.toByteArray()).substring(0, 1024), e);\n+      if (serializedBytes.length == 0 || GZipCompressionUtil.isCompressed(serializedBytes)) {\n+        serializedBytes = baos.toByteArray();\n+      }\n+      int firstBytesLength = Math.min(serializedBytes.length, 1024);\n+      // TODO: remove logging first N bytes of data to reduce log size.\n+      LOG.error(\"Exception during data serialization. Will not write to zk.\"\n+              + \" The first {} bytes of data: {}\", firstBytesLength,\n+          new String(serializedBytes, 0, firstBytesLength), e);\n       throw new ZkClientException(e);\n     }\n     // check size\n-    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n-      LOG.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n-          + \". Will not write to zk. Data (first 1k): \"\n-          + new String(serializedBytes).substring(0, 1024));\n-      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n+    int compressThreshold = ZNRecordUtil.getCompressThreshold();\n+    if (serializedBytes.length > compressThreshold) {\n+      int firstBytesLength = Math.min(serializedBytes.length, 1024);\n+      // TODO: remove logging first N bytes of data to reduce log size.\n+      LOG.error(\"Data size: {} is greater than {} bytes, ZNRecord.id: {}.\"\n+              + \" Data will not be written to Zookeeper. The first {} bytes of data: {}\",\n+          serializedBytes.length, compressThreshold, record.getId(), firstBytesLength,\n+          new String(serializedBytes, 0, firstBytesLength));\n+      throw new ZkClientException(\"Data size: \" + serializedBytes.length + \" is greater than \"\n+          + compressThreshold + \" bytes, ZNRecord.id: \" + record.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ2NTgzMA==", "bodyText": "I think it might be a good idea to also log and include in the exception message whether the ZNRecord was compressed or not. Adding a boolean isCompressed would do?", "url": "https://github.com/apache/helix/pull/809#discussion_r385465830", "createdAt": "2020-02-28T01:35:22Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -81,24 +82,39 @@ private static int getListFieldBound(ZNRecord record) {\n     serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n     serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n     ByteArrayOutputStream baos = new ByteArrayOutputStream();\n-    byte[] serializedBytes;\n+    byte[] serializedBytes = new byte[0];\n     try {\n       mapper.writeValue(baos, data);\n       serializedBytes = baos.toByteArray();\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n         serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n       }\n     } catch (Exception e) {\n-      logger.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n-          + new String(baos.toByteArray()).substring(0, 1024), e);\n+      if (serializedBytes.length == 0 || GZipCompressionUtil.isCompressed(serializedBytes)) {\n+        serializedBytes = baos.toByteArray();\n+      }\n+      int firstBytesLength = Math.min(serializedBytes.length, 1024);\n+      // TODO: remove logging first N bytes of data to reduce log size.\n+      LOG.error(\"Exception during data serialization. Will not write to zk.\"\n+              + \" The first {} bytes of data: {}\", firstBytesLength,\n+          new String(serializedBytes, 0, firstBytesLength), e);\n       throw new ZkClientException(e);\n     }\n-    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n-      logger.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n-          + \". Will not write to zk. Data (first 1k): \"\n-          + new String(serializedBytes).substring(0, 1024));\n-      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n+\n+    int compressThreshold = ZNRecordUtil.getCompressThreshold();\n+    if (serializedBytes.length > compressThreshold) {\n+      if (GZipCompressionUtil.isCompressed(serializedBytes)) {\n+        serializedBytes = baos.toByteArray();\n+      }\n+      int firstBytesLength = Math.min(serializedBytes.length, 1024);\n+      // TODO: remove logging first N bytes of data to reduce log size.\n+      LOG.error(\"Data size: {} is greater than {} bytes, ZNRecord.id: {}.\"\n+              + \" Data will not be written to Zookeeper. The first {} bytes of data: {}\",\n+          serializedBytes.length, compressThreshold, record.getId(), firstBytesLength,\n+          new String(serializedBytes, 0, firstBytesLength));\n+      throw new ZkClientException(\"Data size: \" + serializedBytes.length + \" is greater than \"\n+          + compressThreshold + \" bytes, ZNRecord.id: \" + record.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ2NjI4MQ==", "bodyText": "Nit: Good to add a TestHelper check here given how often deleteRecursively could fail. To make sure things have been really cleaned up.", "url": "https://github.com/apache/helix/pull/809#discussion_r385466281", "createdAt": "2020-02-28T01:37:05Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/manager/zk/TestZNRecordSizeLimit.java", "diffHunk": "@@ -290,4 +292,176 @@ public void testZNRecordSizeLimitUseZNRecordStreamingSerializer() {\n     System.out.println(\"END testZNRecordSizeLimitUseZNRecordStreamingSerializer at \" + new Date(\n         System.currentTimeMillis()));\n   }\n+\n+  /*\n+   * Tests ZNRecordSerializer auto compression threshold.\n+   * Two cases:\n+   * 1. serialized data size is less than threshold and could be written to ZK.\n+   * 2. serialized data size is greater than threshold, so ZkClientException is thrown.\n+   */\n+  @Test(dependsOnMethods = \"testZNRecordSizeLimitUseZNRecordStreamingSerializer\")\n+  public void testZNRecordSerializerCompressThreshold() {\n+    // Backup properties for later resetting.\n+    final String compressionThresholdProperty =\n+        System.getProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES);\n+\n+    ZNRecordSerializer serializer = new ZNRecordSerializer();\n+\n+    String root = getShortClassName();\n+\n+    byte[] buf = new byte[1024];\n+    for (int i = 0; i < 1024; i++) {\n+      buf[i] = 'a';\n+    }\n+    String bufStr = new String(buf);\n+\n+    // 1. legal-sized data gets written to zk\n+    // write a znode of size less than threshold\n+    int rawZnRecordSize = 900;\n+    int thresholdKB = 800;\n+    int compressionThreshold = thresholdKB * 1024;\n+    System.setProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES,\n+        String.valueOf(compressionThreshold));\n+\n+    final ZNRecord normalSizeRecord = new ZNRecord(\"normal-size\");\n+    for (int i = 0; i < rawZnRecordSize; i++) {\n+      normalSizeRecord.setSimpleField(Integer.toString(i), bufStr);\n+    }\n+\n+    String path = \"/\" + root + \"/normal\";\n+    _gZkClient.createPersistent(path, true);\n+    _gZkClient.writeData(path, normalSizeRecord);\n+\n+    ZNRecord record = _gZkClient.readData(path);\n+\n+    // Successfully reads the same data.\n+    Assert.assertEquals(normalSizeRecord, record);\n+\n+    int length = serializer.serialize(record).length;\n+\n+    // Less than compression threshold so it is written to ZK.\n+    Assert.assertTrue(length < compressionThreshold);\n+\n+    // 2. Large size data is not allowed to write to ZK\n+    // Set raw record size to be large enough so its compressed data exceeds the threshold.\n+    rawZnRecordSize = 5000;\n+    // Set the threshold to very small so compressed data size exceeds the threshold.\n+    thresholdKB = 1;\n+    compressionThreshold = thresholdKB * 1024;\n+    System.setProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES,\n+        String.valueOf(compressionThreshold));\n+\n+    final ZNRecord largeRecord = new ZNRecord(\"large-size\");\n+    for (int i = 0; i < rawZnRecordSize; i++) {\n+      largeRecord.setSimpleField(Integer.toString(i), bufStr);\n+    }\n+\n+    path = \"/\" + root + \"/large\";\n+    _gZkClient.createPersistent(path, true);\n+\n+    try {\n+      _gZkClient.writeData(path, largeRecord);\n+      Assert.fail(\"Data should not written to ZK because data size exceeds threshold!\");\n+    } catch (ZkClientException expected) {\n+      Assert.assertTrue(\n+          expected.getMessage().contains(\" is greater than \" + compressionThreshold + \" bytes\"));\n+    }\n+\n+    // Delete the nodes.\n+    _gZkClient.deleteRecursively(\"/\" + root);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ2NjM5OQ==", "bodyText": "Nit: Good to add a TestHelper check here given how often deleteRecursively could fail. To make sure things have been really cleaned up.", "url": "https://github.com/apache/helix/pull/809#discussion_r385466399", "createdAt": "2020-02-28T01:37:32Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/manager/zk/TestZNRecordSizeLimit.java", "diffHunk": "@@ -290,4 +292,176 @@ public void testZNRecordSizeLimitUseZNRecordStreamingSerializer() {\n     System.out.println(\"END testZNRecordSizeLimitUseZNRecordStreamingSerializer at \" + new Date(\n         System.currentTimeMillis()));\n   }\n+\n+  /*\n+   * Tests ZNRecordSerializer auto compression threshold.\n+   * Two cases:\n+   * 1. serialized data size is less than threshold and could be written to ZK.\n+   * 2. serialized data size is greater than threshold, so ZkClientException is thrown.\n+   */\n+  @Test(dependsOnMethods = \"testZNRecordSizeLimitUseZNRecordStreamingSerializer\")\n+  public void testZNRecordSerializerCompressThreshold() {\n+    // Backup properties for later resetting.\n+    final String compressionThresholdProperty =\n+        System.getProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES);\n+\n+    ZNRecordSerializer serializer = new ZNRecordSerializer();\n+\n+    String root = getShortClassName();\n+\n+    byte[] buf = new byte[1024];\n+    for (int i = 0; i < 1024; i++) {\n+      buf[i] = 'a';\n+    }\n+    String bufStr = new String(buf);\n+\n+    // 1. legal-sized data gets written to zk\n+    // write a znode of size less than threshold\n+    int rawZnRecordSize = 900;\n+    int thresholdKB = 800;\n+    int compressionThreshold = thresholdKB * 1024;\n+    System.setProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES,\n+        String.valueOf(compressionThreshold));\n+\n+    final ZNRecord normalSizeRecord = new ZNRecord(\"normal-size\");\n+    for (int i = 0; i < rawZnRecordSize; i++) {\n+      normalSizeRecord.setSimpleField(Integer.toString(i), bufStr);\n+    }\n+\n+    String path = \"/\" + root + \"/normal\";\n+    _gZkClient.createPersistent(path, true);\n+    _gZkClient.writeData(path, normalSizeRecord);\n+\n+    ZNRecord record = _gZkClient.readData(path);\n+\n+    // Successfully reads the same data.\n+    Assert.assertEquals(normalSizeRecord, record);\n+\n+    int length = serializer.serialize(record).length;\n+\n+    // Less than compression threshold so it is written to ZK.\n+    Assert.assertTrue(length < compressionThreshold);\n+\n+    // 2. Large size data is not allowed to write to ZK\n+    // Set raw record size to be large enough so its compressed data exceeds the threshold.\n+    rawZnRecordSize = 5000;\n+    // Set the threshold to very small so compressed data size exceeds the threshold.\n+    thresholdKB = 1;\n+    compressionThreshold = thresholdKB * 1024;\n+    System.setProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES,\n+        String.valueOf(compressionThreshold));\n+\n+    final ZNRecord largeRecord = new ZNRecord(\"large-size\");\n+    for (int i = 0; i < rawZnRecordSize; i++) {\n+      largeRecord.setSimpleField(Integer.toString(i), bufStr);\n+    }\n+\n+    path = \"/\" + root + \"/large\";\n+    _gZkClient.createPersistent(path, true);\n+\n+    try {\n+      _gZkClient.writeData(path, largeRecord);\n+      Assert.fail(\"Data should not written to ZK because data size exceeds threshold!\");\n+    } catch (ZkClientException expected) {\n+      Assert.assertTrue(\n+          expected.getMessage().contains(\" is greater than \" + compressionThreshold + \" bytes\"));\n+    }\n+\n+    // Delete the nodes.\n+    _gZkClient.deleteRecursively(\"/\" + root);\n+\n+    // Reset: add the properties back to system properties if they were originally available.\n+    if (compressionThresholdProperty != null) {\n+      System.setProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES,\n+          compressionThresholdProperty);\n+    } else {\n+      System.clearProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES);\n+    }\n+  }\n+\n+  /*\n+   * Tests ZNRecordStreamingSerializer auto compression threshold.\n+   * Two cases:\n+   * 1. serialized data size is less than threshold and could be written to ZK.\n+   * 2. serialized data size is greater than threshold, so ZkClientException is thrown.\n+   */\n+  @Test(dependsOnMethods = \"testZNRecordSerializerCompressThreshold\")\n+  public void testZNRecordStreamingSerializerCompressThreshold() {\n+    // Backup properties for later resetting.\n+    final String compressionThresholdProperty =\n+        System.getProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES);\n+\n+    ZNRecordStreamingSerializer serializer = new ZNRecordStreamingSerializer();\n+\n+    String root = getShortClassName();\n+\n+    byte[] buf = new byte[1024];\n+    for (int i = 0; i < 1024; i++) {\n+      buf[i] = 'a';\n+    }\n+    String bufStr = new String(buf);\n+\n+    // 1. legal-sized data gets written to zk\n+    // write a znode of size less than threshold\n+    int rawZnRecordSize = 900;\n+    int thresholdKB = 800;\n+    int compressionThreshold = thresholdKB * 1024;\n+    System.setProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES,\n+        String.valueOf(compressionThreshold));\n+\n+    final ZNRecord normalSizeRecord = new ZNRecord(\"normal-size\");\n+    for (int i = 0; i < rawZnRecordSize; i++) {\n+      normalSizeRecord.setSimpleField(Integer.toString(i), bufStr);\n+    }\n+\n+    String path = \"/\" + root + \"/normal\";\n+    _gZkClient.createPersistent(path, true);\n+    _gZkClient.writeData(path, normalSizeRecord);\n+\n+    ZNRecord record = _gZkClient.readData(path);\n+\n+    // Successfully reads the same data.\n+    Assert.assertEquals(normalSizeRecord, record);\n+\n+    int length = serializer.serialize(record).length;\n+\n+    // Less than compression threshold so it is written to ZK.\n+    Assert.assertTrue(length < compressionThreshold);\n+\n+    // 2. Large size data is not allowed to write to ZK\n+    // Set raw record size to be large enough so its compressed data exceeds the threshold.\n+    rawZnRecordSize = 5000;\n+    // Set the threshold to very small so compressed data size exceeds the threshold.\n+    thresholdKB = 1;\n+    compressionThreshold = thresholdKB * 1024;\n+    System.setProperty(ZkSystemPropertyKeys.ZNRECORD_SERIALIZER_COMPRESS_THRESHOLD_BYTES,\n+        String.valueOf(compressionThreshold));\n+\n+    final ZNRecord largeRecord = new ZNRecord(\"large-size\");\n+    for (int i = 0; i < rawZnRecordSize; i++) {\n+      largeRecord.setSimpleField(Integer.toString(i), bufStr);\n+    }\n+\n+    path = \"/\" + root + \"/large\";\n+    _gZkClient.createPersistent(path, true);\n+\n+    try {\n+      _gZkClient.writeData(path, largeRecord);\n+      Assert.fail(\"Data should not written to ZK because data size exceeds threshold!\");\n+    } catch (ZkClientException expected) {\n+      Assert.assertTrue(\n+          expected.getMessage().contains(\" is greater than \" + compressionThreshold + \" bytes\"));\n+    }\n+\n+    // Delete the nodes.\n+    _gZkClient.deleteRecursively(\"/\" + root);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ2ODQyNg==", "bodyText": "Shouldn't this be\nserializedBytes.length > 1MB (or ZK's Djute.maxbuffer)? \nA case to consider:\nSuppose some user wants every ZNode compressed. So sets this threshold to be 1 byte.\nI write 1 byte, and this 1 byte gets compressed (and after compression, say it's greater than or equal to 1 byte), and this write will not go through even after compression because you won't ever allow any writes larger than 1 byte.\nNow I am confused because I set the \"compression threshold\", not the \"ZNode size threshold\"?\nI'm pretty sure this isn't the intended behavior?\nSame thing applies to ZNRecordSerializer.\nHint: I think it might be a good idea to decouple compression threshold from ZNode size limit.", "url": "https://github.com/apache/helix/pull/809#discussion_r385468426", "createdAt": "2020-02-28T01:45:48Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordStreamingSerializer.java", "diffHunk": "@@ -154,20 +155,31 @@ private static int getListFieldBound(ZNRecord record) {\n       g.close();\n       serializedBytes = baos.toByteArray();\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n         serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n       }\n     } catch (Exception e) {\n-      LOG.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n-          + new String(baos.toByteArray()).substring(0, 1024), e);\n+      if (serializedBytes.length == 0 || GZipCompressionUtil.isCompressed(serializedBytes)) {\n+        serializedBytes = baos.toByteArray();\n+      }\n+      int firstBytesLength = Math.min(serializedBytes.length, 1024);\n+      // TODO: remove logging first N bytes of data to reduce log size.\n+      LOG.error(\"Exception during data serialization. Will not write to zk.\"\n+              + \" The first {} bytes of data: {}\", firstBytesLength,\n+          new String(serializedBytes, 0, firstBytesLength), e);\n       throw new ZkClientException(e);\n     }\n     // check size\n-    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n-      LOG.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n-          + \". Will not write to zk. Data (first 1k): \"\n-          + new String(serializedBytes).substring(0, 1024));\n-      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n+    int compressThreshold = ZNRecordUtil.getCompressThreshold();\n+    if (serializedBytes.length > compressThreshold) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MTE2NzA5", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366116709", "createdAt": "2020-02-28T01:48:23Z", "commit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwMTo0ODoyM1rOFvnKkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwMTo0ODoyM1rOFvnKkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ2OTA3Mg==", "bodyText": "Nit: did you mean to make this @JsonIgnore(true) ?", "url": "https://github.com/apache/helix/pull/809#discussion_r385469072", "createdAt": "2020-02-28T01:48:23Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/ZNRecord.java", "diffHunk": "@@ -49,6 +50,10 @@\n   @JsonIgnore(true)\n   public static final String LIST_FIELD_BOUND = \"listField.bound\";\n \n+  /** A field name in ZNRecord's boolean fields to enable compression in ZNRecord serializers. */\n+  @JsonIgnore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "99b29378b98550fbda2da2588f8bedf4a469a039"}, "originalPosition": 13}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/f72feac2e51b3bd38503d3841374be13dfb8c348", "committedDate": "2020-02-28T03:34:11Z", "message": "Change config to limit serialized znrecord size."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f693151253bc17732574d136edb8c5d68367484c", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/f693151253bc17732574d136edb8c5d68367484c", "committedDate": "2020-02-28T03:25:41Z", "message": "Change config to limit serialized znrecord size."}, "afterCommit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/f72feac2e51b3bd38503d3841374be13dfb8c348", "committedDate": "2020-02-28T03:34:11Z", "message": "Change config to limit serialized znrecord size."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MjAyNTQ3", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366202547", "createdAt": "2020-02-28T07:30:13Z", "commit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozMDoxM1rOFvrvRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozMDoxM1rOFvrvRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU0NDAwNQ==", "bodyText": "nit: do we want to use long here?", "url": "https://github.com/apache/helix/pull/809#discussion_r385544005", "createdAt": "2020-02-28T07:30:13Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -81,24 +82,44 @@ private static int getListFieldBound(ZNRecord record) {\n     serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n     serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n     ByteArrayOutputStream baos = new ByteArrayOutputStream();\n-    byte[] serializedBytes;\n+    byte[] serializedBytes = new byte[0];\n+    boolean isCompressed = false;\n+\n     try {\n       mapper.writeValue(baos, data);\n       serializedBytes = baos.toByteArray();\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n         serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n+        isCompressed = true;\n       }\n     } catch (Exception e) {\n-      logger.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n-          + new String(baos.toByteArray()).substring(0, 1024), e);\n+      if (serializedBytes.length == 0 || GZipCompressionUtil.isCompressed(serializedBytes)) {\n+        serializedBytes = baos.toByteArray();\n+      }\n+      int firstBytesLength = Math.min(serializedBytes.length, 1024);\n+      // TODO: remove logging first N bytes of data to reduce log size.\n+      LOG.error(\"Exception during data serialization. Will not write to zk.\"\n+              + \" The first {} bytes of data: {}\", firstBytesLength,\n+          new String(serializedBytes, 0, firstBytesLength), e);\n       throw new ZkClientException(e);\n     }\n-    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n-      logger.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n-          + \". Will not write to zk. Data (first 1k): \"\n-          + new String(serializedBytes).substring(0, 1024));\n-      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n+\n+    int threshold = ZNRecordUtil.getSerializerThreshold();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "originalPosition": 71}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MjAzMzY1", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366203365", "createdAt": "2020-02-28T07:32:11Z", "commit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozMjoxMVrOFvryGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozMjoxMVrOFvryGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU0NDcyOA==", "bodyText": "Either use length throughout or just use serializedBytes.length?", "url": "https://github.com/apache/helix/pull/809#discussion_r385544728", "createdAt": "2020-02-28T07:32:11Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -81,24 +82,44 @@ private static int getListFieldBound(ZNRecord record) {\n     serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n     serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n     ByteArrayOutputStream baos = new ByteArrayOutputStream();\n-    byte[] serializedBytes;\n+    byte[] serializedBytes = new byte[0];\n+    boolean isCompressed = false;\n+\n     try {\n       mapper.writeValue(baos, data);\n       serializedBytes = baos.toByteArray();\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n         serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n+        isCompressed = true;\n       }\n     } catch (Exception e) {\n-      logger.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n-          + new String(baos.toByteArray()).substring(0, 1024), e);\n+      if (serializedBytes.length == 0 || GZipCompressionUtil.isCompressed(serializedBytes)) {\n+        serializedBytes = baos.toByteArray();\n+      }\n+      int firstBytesLength = Math.min(serializedBytes.length, 1024);\n+      // TODO: remove logging first N bytes of data to reduce log size.\n+      LOG.error(\"Exception during data serialization. Will not write to zk.\"\n+              + \" The first {} bytes of data: {}\", firstBytesLength,\n+          new String(serializedBytes, 0, firstBytesLength), e);\n       throw new ZkClientException(e);\n     }\n-    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n-      logger.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n-          + \". Will not write to zk. Data (first 1k): \"\n-          + new String(serializedBytes).substring(0, 1024));\n-      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n+\n+    int threshold = ZNRecordUtil.getSerializerThreshold();\n+    if (serializedBytes.length > threshold) {\n+      int length = serializedBytes.length;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "originalPosition": 73}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MjA0MjM4", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366204238", "createdAt": "2020-02-28T07:34:34Z", "commit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozNDozNFrOFvr0vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozNDozNFrOFvr0vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU0NTQwNw==", "bodyText": "Nit: Just plain THRESHOLD is a little vague. Could we say\nWRITE_THRESHOLD or WRITE_SIZE_LIMIT?", "url": "https://github.com/apache/helix/pull/809#discussion_r385545407", "createdAt": "2020-02-28T07:34:34Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/constant/ZkSystemPropertyKeys.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package org.apache.helix.zookeeper.constant;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/**\n+ * This class contains various ZK system property keys.\n+ */\n+public class ZkSystemPropertyKeys {\n+\n+  /**\n+   * This is property that defines the threshold in bytes for ZKRecord's two serializers before\n+   * serialized data is ready to be written to ZK. This property applies to\n+   * 1. {@link org.apache.helix.zookeeper.datamodel.serializer.ZNRecordSerializer}\n+   * 2. {@link org.apache.helix.zookeeper.datamodel.serializer.ZNRecordStreamingSerializer}.\n+   * <p>\n+   * If the size of serialized data exceeds this configured threshold, the data will NOT be written\n+   * to Zookeeper. Default value is 1024000 (1 MB). If the configured threshold is greater than\n+   * 1 MB or less than or equal to 0 byte, 1 MB will be used.\n+   */\n+  public static final String ZNRECORD_SERIALIZER_THRESHOLD_BYTES =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MjA0NTM4", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366204538", "createdAt": "2020-02-28T07:35:28Z", "commit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozNToyOFrOFvr1rQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozNToyOFrOFvr1rQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU0NTY0NQ==", "bodyText": "Nit: just an issue with naming. Can we call this getSerializerWriteSizeLimit()? or WriteSizeThreshold?", "url": "https://github.com/apache/helix/pull/809#discussion_r385545645", "createdAt": "2020-02-28T07:35:28Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordStreamingSerializer.java", "diffHunk": "@@ -154,20 +157,34 @@ private static int getListFieldBound(ZNRecord record) {\n       g.close();\n       serializedBytes = baos.toByteArray();\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n         serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n+        isCompressed = true;\n       }\n     } catch (Exception e) {\n-      LOG.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n-          + new String(baos.toByteArray()).substring(0, 1024), e);\n+      if (serializedBytes.length == 0 || GZipCompressionUtil.isCompressed(serializedBytes)) {\n+        serializedBytes = baos.toByteArray();\n+      }\n+      int firstBytesLength = Math.min(serializedBytes.length, 1024);\n+      // TODO: remove logging first N bytes of data to reduce log size.\n+      LOG.error(\"Exception during data serialization. Will not write to zk.\"\n+              + \" The first {} bytes of data: {}\", firstBytesLength,\n+          new String(serializedBytes, 0, firstBytesLength), e);\n       throw new ZkClientException(e);\n     }\n     // check size\n-    if (serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n-      LOG.error(\"Data size larger than 1M, ZNRecord.id: \" + record.getId()\n-          + \". Will not write to zk. Data (first 1k): \"\n-          + new String(serializedBytes).substring(0, 1024));\n-      throw new ZkClientException(\"Data size larger than 1M, ZNRecord.id: \" + record.getId());\n+    int threshold = ZNRecordUtil.getSerializerThreshold();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MjA1MDE3", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366205017", "createdAt": "2020-02-28T07:36:45Z", "commit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozNjo0NVrOFvr3Qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwNzozNjo0NVrOFvr3Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU0NjA1MQ==", "bodyText": "What threshold is it? There could be thresholds for a whole bunch of things.\nI vote to use getSerializerWriteSizeLimit() or getSerializerWriteSizeThreshold(). This way, it's not ambiguous and clear about what this value stands for.\nAlso should we use long instead of int here? Is overflow possible?", "url": "https://github.com/apache/helix/pull/809#discussion_r385546051", "createdAt": "2020-02-28T07:36:45Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/util/ZNRecordUtil.java", "diffHunk": "@@ -0,0 +1,61 @@\n+package org.apache.helix.zookeeper.util;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import org.apache.helix.zookeeper.constant.ZkSystemPropertyKeys;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+\n+\n+/**\n+ * This utility class contains various methods for manipulating ZNRecord.\n+ */\n+public class ZNRecordUtil {\n+\n+  /**\n+   * Checks whether or not a serialized ZNRecord bytes should be compressed before being written to\n+   * Zookeeper.\n+   *\n+   * @param record raw ZNRecord before being serialized\n+   * @param serializedLength length of the serialized bytes array\n+   * @return\n+   */\n+  public static boolean shouldCompress(ZNRecord record, int serializedLength) {\n+    if (record.getBooleanField(ZNRecord.ENABLE_COMPRESSION_BOOLEAN_FIELD, false)) {\n+      return true;\n+    }\n+\n+    return serializedLength > ZNRecord.SIZE_LIMIT;\n+  }\n+\n+  /**\n+   * Returns compression threshold in bytes. The threshold is a smaller number determined by the\n+   * configured threshold and {@link ZNRecord#SIZE_LIMIT}.\n+   */\n+  public static int getSerializerThreshold() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f72feac2e51b3bd38503d3841374be13dfb8c348"}, "originalPosition": 51}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21d443ed9a89630b29006ac581446e212d28e6c9", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/21d443ed9a89630b29006ac581446e212d28e6c9", "committedDate": "2020-02-28T08:09:19Z", "message": "Rename property to znrecord.serializer.output.limit.bytes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8378d7a36ab6158274e228089b0c483a6f2c6436", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/8378d7a36ab6158274e228089b0c483a6f2c6436", "committedDate": "2020-02-28T23:51:38Z", "message": "Add test."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a7a0b2ac56d4ae4a4a935ce433860076f6cc2158", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/a7a0b2ac56d4ae4a4a935ce433860076f6cc2158", "committedDate": "2020-02-29T00:24:11Z", "message": "Remove first 1kb data logging"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NzU1ODM1", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366755835", "createdAt": "2020-02-29T00:26:22Z", "commit": {"oid": "a7a0b2ac56d4ae4a4a935ce433860076f6cc2158"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwMDoyNjoyMlrOFwGVIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwMDoyNjoyMlrOFwGVIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk3OTY4MQ==", "bodyText": "This is what we are going to decide. We should reduce this default value.", "url": "https://github.com/apache/helix/pull/809#discussion_r385979681", "createdAt": "2020-02-29T00:26:22Z", "author": {"login": "huizhilu"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/ZNRecord.java", "diffHunk": "@@ -49,6 +50,10 @@\n   @JsonIgnore(true)\n   public static final String LIST_FIELD_BOUND = \"listField.bound\";\n \n+  /** A field name in ZNRecord's boolean fields to enable compression in ZNRecord serializers. */\n+  @JsonIgnore\n+  public static final String ENABLE_COMPRESSION_BOOLEAN_FIELD = \"enableCompression\";\n+\n   @JsonIgnore(true)\n   public static final int SIZE_LIMIT = 1000 * 1024; // leave a margin out of 1M", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a7a0b2ac56d4ae4a4a935ce433860076f6cc2158"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NzQ5NTA3", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366749507", "createdAt": "2020-02-28T23:56:48Z", "commit": {"oid": "8378d7a36ab6158274e228089b0c483a6f2c6436"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQyMzo1Njo0OFrOFwF_KA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwMDowODozN1rOFwGIcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk3NDA1Ng==", "bodyText": "nit, regardless of the java field name, should the content be zk.serializer.znrecord.write.size.limit.bytes?", "url": "https://github.com/apache/helix/pull/809#discussion_r385974056", "createdAt": "2020-02-28T23:56:48Z", "author": {"login": "jiajunwang"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/constant/ZkSystemPropertyKeys.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package org.apache.helix.zookeeper.constant;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/**\n+ * This class contains various ZK system property keys.\n+ */\n+public class ZkSystemPropertyKeys {\n+\n+  /**\n+   * This is property that defines the maximum write size in bytes for ZKRecord's two serializers\n+   * before serialized data is ready to be written to ZK. This property applies to\n+   * 1. {@link org.apache.helix.zookeeper.datamodel.serializer.ZNRecordSerializer}\n+   * 2. {@link org.apache.helix.zookeeper.datamodel.serializer.ZNRecordStreamingSerializer}.\n+   * <p>\n+   * If the size of serialized data exceeds this configured limit, the data will NOT be written\n+   * to Zookeeper. Default value is 1 MB. If the configured limit is greater than\n+   * 1 MB or less than or equal to 0 byte, 1 MB will be used.\n+   */\n+  public static final String ZNRECORD_SERIALIZER_WRITE_SIZE_LIMIT_BYTES =\n+      \"znrecord.serializer.write.size.limit.bytes\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8378d7a36ab6158274e228089b0c483a6f2c6436"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk3NDQ3Ng==", "bodyText": "nit, The field name....\nAnd what does \"boolean fields\" mean? Should it be simple fields?", "url": "https://github.com/apache/helix/pull/809#discussion_r385974476", "createdAt": "2020-02-28T23:58:44Z", "author": {"login": "jiajunwang"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/ZNRecord.java", "diffHunk": "@@ -49,6 +50,10 @@\n   @JsonIgnore(true)\n   public static final String LIST_FIELD_BOUND = \"listField.bound\";\n \n+  /** A field name in ZNRecord's boolean fields to enable compression in ZNRecord serializers. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8378d7a36ab6158274e228089b0c483a6f2c6436"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk3NDg0OQ==", "bodyText": "Can we follow the convention that has an enum for the properties?", "url": "https://github.com/apache/helix/pull/809#discussion_r385974849", "createdAt": "2020-02-29T00:00:35Z", "author": {"login": "jiajunwang"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/ZNRecord.java", "diffHunk": "@@ -49,6 +50,10 @@\n   @JsonIgnore(true)\n   public static final String LIST_FIELD_BOUND = \"listField.bound\";\n \n+  /** A field name in ZNRecord's boolean fields to enable compression in ZNRecord serializers. */\n+  @JsonIgnore\n+  public static final String ENABLE_COMPRESSION_BOOLEAN_FIELD = \"enableCompression\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8378d7a36ab6158274e228089b0c483a6f2c6436"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk3NjQzMg==", "bodyText": "This is a potential bug, \"serializedBytes = baos.toByteArray();\" is called in the try block. As we discussed, either split the try block, or just don't try to read the content in catch block.", "url": "https://github.com/apache/helix/pull/809#discussion_r385976432", "createdAt": "2020-02-29T00:08:37Z", "author": {"login": "jiajunwang"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/datamodel/serializer/ZNRecordSerializer.java", "diffHunk": "@@ -81,25 +82,48 @@ private static int getListFieldBound(ZNRecord record) {\n     serializationConfig.set(SerializationConfig.Feature.AUTO_DETECT_FIELDS, true);\n     serializationConfig.set(SerializationConfig.Feature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n     ByteArrayOutputStream baos = new ByteArrayOutputStream();\n-    byte[] serializedBytes;\n+    byte[] serializedBytes = new byte[0];\n+    boolean isCompressed = false;\n+\n     try {\n       mapper.writeValue(baos, data);\n       serializedBytes = baos.toByteArray();\n       // apply compression if needed\n-      if (record.getBooleanField(\"enableCompression\", false) || serializedBytes.length > ZNRecord.SIZE_LIMIT) {\n+      if (ZNRecordUtil.shouldCompress(record, serializedBytes.length)) {\n         serializedBytes = GZipCompressionUtil.compress(serializedBytes);\n+        isCompressed = true;\n       }\n     } catch (Exception e) {\n-      logger.error(\"Exception during data serialization. Will not write to zk. Data (first 1k): \"\n-          + new String(baos.toByteArray()).substring(0, 1024), e);\n+      if (serializedBytes.length == 0 || GZipCompressionUtil.isCompressed(serializedBytes)) {\n+        serializedBytes = baos.toByteArray();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8378d7a36ab6158274e228089b0c483a6f2c6436"}, "originalPosition": 56}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2933d7d2f53f88674f71b72048b7397452484a4f", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/2933d7d2f53f88674f71b72048b7397452484a4f", "committedDate": "2020-02-29T02:17:02Z", "message": "Add auto compress enabled config."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6c328a34063584c06a35be96475cba0a03d0f1c8", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/6c328a34063584c06a35be96475cba0a03d0f1c8", "committedDate": "2020-02-29T02:10:37Z", "message": "Add auto compress enabled config."}, "afterCommit": {"oid": "2933d7d2f53f88674f71b72048b7397452484a4f", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/2933d7d2f53f88674f71b72048b7397452484a4f", "committedDate": "2020-02-29T02:17:02Z", "message": "Add auto compress enabled config."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8dea00710f12c43f130f047a41800c1e95c3b6e3", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/8dea00710f12c43f130f047a41800c1e95c3b6e3", "committedDate": "2020-02-29T04:33:08Z", "message": "Format style"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d7a659a04188d3061eafb1e85931bbdd954fe27b", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/d7a659a04188d3061eafb1e85931bbdd954fe27b", "committedDate": "2020-02-29T02:52:09Z", "message": "Format style"}, "afterCommit": {"oid": "8dea00710f12c43f130f047a41800c1e95c3b6e3", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/8dea00710f12c43f130f047a41800c1e95c3b6e3", "committedDate": "2020-02-29T04:33:08Z", "message": "Format style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a307ff73534fec27f13ef5accede9d2b068707f", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/4a307ff73534fec27f13ef5accede9d2b068707f", "committedDate": "2020-02-29T04:37:09Z", "message": "Include tests in zookeeper-api module"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NzgxMzQx", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366781341", "createdAt": "2020-02-29T06:32:11Z", "commit": {"oid": "4a307ff73534fec27f13ef5accede9d2b068707f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwNjozMjoxMlrOFwH-Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwNjozMjoxMlrOFwH-Cw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjAwNjUzOQ==", "bodyText": "Nit: clarify that this \"write size limit\" refers to \"zk.serializer.znrecord.write.size.limit.bytes\"?", "url": "https://github.com/apache/helix/pull/809#discussion_r386006539", "createdAt": "2020-02-29T06:32:12Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/constant/ZkSystemPropertyKeys.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.apache.helix.zookeeper.constant;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/**\n+ * This class contains various ZK system property keys.\n+ */\n+public class ZkSystemPropertyKeys {\n+\n+  /**\n+   * Setting this property to true in system properties enables auto compression in ZK serializer.\n+   * The data will be automatically compressed by\n+   * {@link org.apache.helix.zookeeper.util.GZipCompressionUtil} when being written to Zookeeper\n+   * if size of serialized data exceeds the write size limit. The default value is enabled.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a307ff73534fec27f13ef5accede9d2b068707f"}, "originalPosition": 31}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NzgxODkw", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366781890", "createdAt": "2020-02-29T06:46:53Z", "commit": {"oid": "4a307ff73534fec27f13ef5accede9d2b068707f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwNjo0Njo1M1rOFwIBQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwNjo0Njo1M1rOFwIBQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjAwNzM2Mw==", "bodyText": "What if the user sets their zookeeper's jute maxbuffer to some value greater than 1MB?", "url": "https://github.com/apache/helix/pull/809#discussion_r386007363", "createdAt": "2020-02-29T06:46:53Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/constant/ZkSystemPropertyKeys.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.apache.helix.zookeeper.constant;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/**\n+ * This class contains various ZK system property keys.\n+ */\n+public class ZkSystemPropertyKeys {\n+\n+  /**\n+   * Setting this property to true in system properties enables auto compression in ZK serializer.\n+   * The data will be automatically compressed by\n+   * {@link org.apache.helix.zookeeper.util.GZipCompressionUtil} when being written to Zookeeper\n+   * if size of serialized data exceeds the write size limit. The default value is enabled.\n+   */\n+  public static final String ZK_SERIALIZER_ZNRECORD_AUTO_COMPRESS_ENABLED =\n+      \"zk.serializer.znrecord.auto-compress.enabled\";\n+\n+  /**\n+   * This is property that defines the maximum write size in bytes for ZKRecord's two serializers\n+   * before serialized data is ready to be written to ZK. This property applies to\n+   * 1. {@link org.apache.helix.zookeeper.datamodel.serializer.ZNRecordSerializer}\n+   * 2. {@link org.apache.helix.zookeeper.datamodel.serializer.ZNRecordStreamingSerializer}.\n+   * <p>\n+   * If the size of serialized data exceeds this configured limit, the data will NOT be written\n+   * to Zookeeper. Default value is 1 MB. If the configured limit is greater than\n+   * 1 MB or less than or equal to 0 byte, 1 MB will be used.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a307ff73534fec27f13ef5accede9d2b068707f"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NzgxOTEx", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366781911", "createdAt": "2020-02-29T06:47:30Z", "commit": {"oid": "4a307ff73534fec27f13ef5accede9d2b068707f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwNjo0NzozMFrOFwIBWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOVQwNjo0NzozMFrOFwIBWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjAwNzM4Ng==", "bodyText": "Lets make it clear that this will apply no matter whether the data has been compressed or not", "url": "https://github.com/apache/helix/pull/809#discussion_r386007386", "createdAt": "2020-02-29T06:47:30Z", "author": {"login": "narendly"}, "path": "zookeeper-api/src/main/java/org/apache/helix/zookeeper/constant/ZkSystemPropertyKeys.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.apache.helix.zookeeper.constant;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/**\n+ * This class contains various ZK system property keys.\n+ */\n+public class ZkSystemPropertyKeys {\n+\n+  /**\n+   * Setting this property to true in system properties enables auto compression in ZK serializer.\n+   * The data will be automatically compressed by\n+   * {@link org.apache.helix.zookeeper.util.GZipCompressionUtil} when being written to Zookeeper\n+   * if size of serialized data exceeds the write size limit. The default value is enabled.\n+   */\n+  public static final String ZK_SERIALIZER_ZNRECORD_AUTO_COMPRESS_ENABLED =\n+      \"zk.serializer.znrecord.auto-compress.enabled\";\n+\n+  /**\n+   * This is property that defines the maximum write size in bytes for ZKRecord's two serializers\n+   * before serialized data is ready to be written to ZK. This property applies to\n+   * 1. {@link org.apache.helix.zookeeper.datamodel.serializer.ZNRecordSerializer}\n+   * 2. {@link org.apache.helix.zookeeper.datamodel.serializer.ZNRecordStreamingSerializer}.\n+   * <p>\n+   * If the size of serialized data exceeds this configured limit, the data will NOT be written", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a307ff73534fec27f13ef5accede9d2b068707f"}, "originalPosition": 42}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "efc43a2ee57d7fe52884dbca58e759768f087f02", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/efc43a2ee57d7fe52884dbca58e759768f087f02", "committedDate": "2020-02-29T07:03:31Z", "message": "Comments."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1524f5bf5bb4d730f4c60029f12352d388412e46", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/1524f5bf5bb4d730f4c60029f12352d388412e46", "committedDate": "2020-02-29T07:00:14Z", "message": "Comments."}, "afterCommit": {"oid": "efc43a2ee57d7fe52884dbca58e759768f087f02", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/efc43a2ee57d7fe52884dbca58e759768f087f02", "committedDate": "2020-02-29T07:03:31Z", "message": "Comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b4f1742b5f99564fc6aa9fb12d43e9ebab18fb7", "author": {"user": {"login": "huizhilu", "name": "Huizhi Lu"}}, "url": "https://github.com/apache/helix/commit/4b4f1742b5f99564fc6aa9fb12d43e9ebab18fb7", "committedDate": "2020-02-29T07:08:15Z", "message": "Format lines."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NzgzOTE2", "url": "https://github.com/apache/helix/pull/809#pullrequestreview-366783916", "createdAt": "2020-02-29T07:42:11Z", "commit": {"oid": "4b4f1742b5f99564fc6aa9fb12d43e9ebab18fb7"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4969, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}