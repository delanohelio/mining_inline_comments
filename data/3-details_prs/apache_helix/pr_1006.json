{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3NTA0NzMx", "number": 1006, "title": "Fix the RuntimeJobDag issue for queues", "bodyText": "Issues\n\n My PR addresses the following Helix issues and references them in the PR title:\nFixes #1005\n\nDescription\n\n Here are some details about my PR, including screenshots of any UI changes:\nIn this PR, a fix has been implemented to avoid _readyJobList in RuntimeJobDag to contain multiple entries of a job. In this RuntimeJobDah.finishJob we add the next job without considering of it has already been added or not. In this PR, added a test which proves this can happen and I proposed a fix for this issue.\n\nTests\n\n\n The following tests are written for this issue:\nTestEnqueueJobs.testQueueParallelJobs\n\n\n The following is the result of the \"mvn test\" command on the appropriate module:\n\n\n[INFO] Results:\n[INFO] \n[ERROR] Failures: \n[ERROR]   TestRecurringJobQueue.deleteRecreateRecurrentQueue \u00bb ThreadTimeout Method org....\n[ERROR]   TestWorkflowTermination.testWorkflowJobFail:223 \u00bb Helix Workflow \"testWorkflow...\n[INFO] \n[ERROR] Tests run: 1145, Failures: 2, Errors: 0, Skipped: 0\n[INFO] \n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  01:24 h\n[INFO] Finished at: 2020-05-13T13:55:21-07:00\n[INFO] ------------------------------------------------------------------------\n\nThe failed tests have passed when I ran them individually.\nmvn test -Dtest=\"TestRecurringJobQueue,TestWorkflowTermination\"\n[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 137.835 s - in TestSuite\n[INFO] \n[INFO] Results:\n[INFO] \n[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0\n[INFO] \n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  02:23 min\n[INFO] Finished at: 2020-05-13T14:21:58-07:00\n[INFO] ------------------------------------------------------------------------\n\nCommits\n\n My commits all reference appropriate Apache Helix GitHub issues in their subject lines, and I have squashed multiple commits if they address the same issue. In addition, my commits follow the guidelines from \"How to write a good git commit message\":\n\nSubject is separated from body by a blank line\nSubject is limited to 50 characters (not including Jira issue reference)\nSubject does not end with a period\nSubject uses the imperative mood (\"add\", not \"adding\")\nBody wraps at 72 characters\nBody explains \"what\" and \"why\", not \"how\"\n\n\n\nCode Quality\n\n My diff has been formatted using helix-style.xml", "createdAt": "2020-05-13T17:23:35Z", "url": "https://github.com/apache/helix/pull/1006", "merged": true, "mergeCommit": {"oid": "07999003c7832414822cabe2cb418cde42f2bd0f"}, "closed": true, "closedAt": "2020-05-26T17:12:55Z", "author": {"login": "alirezazamani"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcg8UisABqjMzMzMxNDY5OTA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABck0rm3gFqTQxNzg0MzQ4NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "57b8a5e049c15223d7d49289234933b11deba78d", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/57b8a5e049c15223d7d49289234933b11deba78d", "committedDate": "2020-05-12T02:08:11Z", "message": "Fix the RuntimeJobDag issue for queues\n\nIn this commit, a fix has been implemented to avoid\n _readyJobList in RuntimeJobDag cannot contain multiple\nenry for same job."}, "afterCommit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/75c285a5e587335c3ea4a2da1270aa8f189845aa", "committedDate": "2020-05-13T17:26:38Z", "message": "Fix the RuntimeJobDag issue for queues with ParallelJob set to more than 1\n\nIn this commit, a fix has been implemented to avoid\n _readyJobList in RuntimeJobDag to contain multiple\nentries of the same job."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExMjUyMDA0", "url": "https://github.com/apache/helix/pull/1006#pullrequestreview-411252004", "createdAt": "2020-05-13T19:55:18Z", "commit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxOTo1NToxOFrOGVBRQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxOTo1NToxOFrOGVBRQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5NDA4Mw==", "bodyText": "Better to have some comments here. I think this is an optimization instead of fix. Even if you add the scheduled one as next job. It will be skipped in schedule job part in WorkflowDispatcher.\nWould that cause problem for get another next job?", "url": "https://github.com/apache/helix/pull/1006#discussion_r424694083", "createdAt": "2020-05-13T19:55:18Z", "author": {"login": "junkaixue"}, "path": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java", "diffHunk": "@@ -146,8 +146,13 @@ public boolean finishJob(String job) {\n     }\n     // Add finished job's successors to ready-list\n     if (_isJobQueue) {\n-      if (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n-        _readyJobList.offer(_parentsToChildren.get(_lastJob).iterator().next());\n+      while (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExMzI5MTg2", "url": "https://github.com/apache/helix/pull/1006#pullrequestreview-411329186", "createdAt": "2020-05-13T21:58:52Z", "commit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QyMTo1ODo1MlrOGVE_wA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QyMTo1OToyN1rOGVFAvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1NTEzNg==", "bodyText": "Could nextJob be null?", "url": "https://github.com/apache/helix/pull/1006#discussion_r424755136", "createdAt": "2020-05-13T21:58:52Z", "author": {"login": "narendly"}, "path": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java", "diffHunk": "@@ -146,8 +146,13 @@ public boolean finishJob(String job) {\n     }\n     // Add finished job's successors to ready-list\n     if (_isJobQueue) {\n-      if (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n-        _readyJobList.offer(_parentsToChildren.get(_lastJob).iterator().next());\n+      while (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n+        String nextJob = _parentsToChildren.get(_lastJob).iterator().next();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1NTM5MA==", "bodyText": "Let's make these magic numbers descriptive variables?", "url": "https://github.com/apache/helix/pull/1006#discussion_r424755390", "createdAt": "2020-05-13T21:59:27Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java", "diffHunk": "@@ -96,4 +102,60 @@ public void testJobSubmitGenericWorkflows() throws InterruptedException {\n \n     _driver.pollForWorkflowState(workflowName, TaskState.COMPLETED);\n   }\n-}\n\\ No newline at end of file\n+\n+  @Test\n+  public void testQueueParallelJobs() throws InterruptedException {\n+    String queueName = TestHelper.getTestMethodName();\n+    JobQueue.Builder builder = TaskTestUtil.buildJobQueue(queueName);\n+    WorkflowConfig.Builder workflowCfgBuilder = new WorkflowConfig.Builder()\n+        .setWorkflowId(queueName).setParallelJobs(3).setAllowOverlapJobAssignment(true);\n+    _driver.start(builder.setWorkflowConfig(workflowCfgBuilder.build()).build());\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2)\n+            .setJobCommandConfigMap(Collections.singletonMap(MockTask.JOB_DELAY, \"10000\"));\n+\n+    // Add 4 jobs to the queue\n+    for (int i = 0; i <= 3; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa"}, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzODcyODIw", "url": "https://github.com/apache/helix/pull/1006#pullrequestreview-413872820", "createdAt": "2020-05-18T19:18:30Z", "commit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxOToxODozMVrOGXEYYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxOToyNTo0NVrOGXEmgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0MjIwOQ==", "bodyText": "Could you help understand: If you are only checking one: maxEndtime > maxStartime, why are HashSets necessary?", "url": "https://github.com/apache/helix/pull/1006#discussion_r426842209", "createdAt": "2020-05-18T19:18:31Z", "author": {"login": "huizhilu"}, "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java", "diffHunk": "@@ -96,4 +102,60 @@ public void testJobSubmitGenericWorkflows() throws InterruptedException {\n \n     _driver.pollForWorkflowState(workflowName, TaskState.COMPLETED);\n   }\n-}\n\\ No newline at end of file\n+\n+  @Test\n+  public void testQueueParallelJobs() throws InterruptedException {\n+    String queueName = TestHelper.getTestMethodName();\n+    JobQueue.Builder builder = TaskTestUtil.buildJobQueue(queueName);\n+    WorkflowConfig.Builder workflowCfgBuilder = new WorkflowConfig.Builder()\n+        .setWorkflowId(queueName).setParallelJobs(3).setAllowOverlapJobAssignment(true);\n+    _driver.start(builder.setWorkflowConfig(workflowCfgBuilder.build()).build());\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2)\n+            .setJobCommandConfigMap(Collections.singletonMap(MockTask.JOB_DELAY, \"10000\"));\n+\n+    // Add 4 jobs to the queue\n+    for (int i = 0; i <= 3; i++) {\n+      _driver.enqueueJob(queueName, \"JOB\" + i, jobBuilder);\n+    }\n+\n+    // Wait until all of the enqueued jobs (Job0 to Job3) are finished\n+    for (int i = 0; i <= 3; i++) {\n+      _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + i),\n+          TaskState.COMPLETED);\n+    }\n+\n+    // Stop the Controller\n+    _controller.syncStop();\n+\n+    // Add 3 more jobs to the queue which should run in parallel after the Controller is started\n+    for (int i = 4; i <= 6; i++) {\n+      _driver.enqueueJob(queueName, \"JOB\" + i, jobBuilder);\n+    }\n+\n+    // Start the Controller\n+    String controllerName = CONTROLLER_PREFIX + \"_0\";\n+    _controller = new ClusterControllerManager(ZK_ADDR, CLUSTER_NAME, controllerName);\n+    _controller.syncStart();\n+\n+    // Wait until all of the newly added jobs (Job4 to Job6) are finished\n+    for (int i = 4; i <= 6; i++) {\n+      _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + i),\n+          TaskState.COMPLETED);\n+    }\n+\n+    // Make sure the jobs have been running in parallel by checking the jobs start time and finish\n+    // time\n+    Set<Long> startTimes = new HashSet<>();\n+    Set<Long> endTime = new HashSet<>();\n+\n+    for (int i = 4; i <= 6; i++) {\n+      JobContext jobContext =\n+          _driver.getJobContext(TaskUtil.getNamespacedJobName(queueName, \"JOB\" + i));\n+      startTimes.add(jobContext.getStartTime());\n+      endTime.add(jobContext.getFinishTime());\n+    }\n+    Assert.assertTrue(Collections.min(endTime) > Collections.max(startTimes));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0NTgyNQ==", "bodyText": "What's the time complexity of this operation?", "url": "https://github.com/apache/helix/pull/1006#discussion_r426845825", "createdAt": "2020-05-18T19:25:45Z", "author": {"login": "huizhilu"}, "path": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java", "diffHunk": "@@ -146,8 +146,13 @@ public boolean finishJob(String job) {\n     }\n     // Add finished job's successors to ready-list\n     if (_isJobQueue) {\n-      if (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n-        _readyJobList.offer(_parentsToChildren.get(_lastJob).iterator().next());\n+      while (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n+        String nextJob = _parentsToChildren.get(_lastJob).iterator().next();\n+        if (!_readyJobList.contains(nextJob)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2531e22d3544919a695c41bbd978c5f679c9d093", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/2531e22d3544919a695c41bbd978c5f679c9d093", "committedDate": "2020-05-18T19:55:03Z", "message": "Fix the RuntimeJobDag issue for queues with ParallelJob set to more than 1\n\nIn this commit, a fix has been implemented to avoid\n _readyJobList in RuntimeJobDag to contain multiple\nentries of the same job."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fdad13a156e31af745d70bc58c04104b3dfca95", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/5fdad13a156e31af745d70bc58c04104b3dfca95", "committedDate": "2020-05-18T21:43:01Z", "message": "Address the comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/75c285a5e587335c3ea4a2da1270aa8f189845aa", "committedDate": "2020-05-13T17:26:38Z", "message": "Fix the RuntimeJobDag issue for queues with ParallelJob set to more than 1\n\nIn this commit, a fix has been implemented to avoid\n _readyJobList in RuntimeJobDag to contain multiple\nentries of the same job."}, "afterCommit": {"oid": "5fdad13a156e31af745d70bc58c04104b3dfca95", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/5fdad13a156e31af745d70bc58c04104b3dfca95", "committedDate": "2020-05-18T21:43:01Z", "message": "Address the comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzOTc5Mzcy", "url": "https://github.com/apache/helix/pull/1006#pullrequestreview-413979372", "createdAt": "2020-05-18T22:26:17Z", "commit": {"oid": "5fdad13a156e31af745d70bc58c04104b3dfca95"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQyMjoyNjoxN1rOGXJegQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQyMjoyNjoxN1rOGXJegQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTY5Nw==", "bodyText": "Have a follow up question. What do you mean the job gets added several times to the readyJobList?\nIf there's a controller switch, we'll be creating readyJobList/inflightJobList from scratch, and add everything from the beginning (or the first available job from the step-by-step topological sort). Then as long as the controller doesn't switch, it only gets added once, right?\nIn other words, for each controller should add a job exactly once. Is that correct?\nAlso even though a job might get added to readyJobList multiple times (exactly once in different controllers), our scheduling logic just skips it I believe (if jobState is complete/progress we just skip?). Could you help me understand how this could help? It seems that although this wouldn't hurt to do...", "url": "https://github.com/apache/helix/pull/1006#discussion_r426925697", "createdAt": "2020-05-18T22:26:17Z", "author": {"login": "narendly"}, "path": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java", "diffHunk": "@@ -145,9 +145,21 @@ public boolean finishJob(String job) {\n           String.format(\"Job: %s has either finished already, never been scheduled, or been removed from DAG\", job));\n     }\n     // Add finished job's successors to ready-list\n+\n+    // If it is a jobQueue, there should be a check to make sure that the a job has not been added\n+    // to the _readyJobList multiple times. This check is necessary because once the controller\n+    // switch happens, the _readyJobList and _inflightJobList will be created from scratch. In this\n+    // case, since there might be many jobs that have been finished before, we do not want to have a\n+    // job several times to the _readyJobList. If _readyJobList has multiple instances of the same\n+    // job, it can compromise the functionality of the parallel jobs.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fdad13a156e31af745d70bc58c04104b3dfca95"}, "originalPosition": 10}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzOTc5NTA3", "url": "https://github.com/apache/helix/pull/1006#pullrequestreview-413979507", "createdAt": "2020-05-18T22:26:36Z", "commit": {"oid": "5fdad13a156e31af745d70bc58c04104b3dfca95"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQyMjoyNjozNlrOGXJe5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQyMjozMToyN1rOGXJlcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTc5Nw==", "bodyText": "Don't forget to remove unused imports.", "url": "https://github.com/apache/helix/pull/1006#discussion_r426925797", "createdAt": "2020-05-18T22:26:36Z", "author": {"login": "huizhilu"}, "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java", "diffHunk": "@@ -1,12 +1,18 @@\n package org.apache.helix.integration.task;\n \n+import java.util.Collections;\n+import java.util.HashSet;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fdad13a156e31af745d70bc58c04104b3dfca95"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNzQ3Mg==", "bodyText": "This is within a while loop. How many times this check will be run?", "url": "https://github.com/apache/helix/pull/1006#discussion_r426927472", "createdAt": "2020-05-18T22:31:27Z", "author": {"login": "huizhilu"}, "path": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java", "diffHunk": "@@ -146,8 +146,13 @@ public boolean finishJob(String job) {\n     }\n     // Add finished job's successors to ready-list\n     if (_isJobQueue) {\n-      if (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n-        _readyJobList.offer(_parentsToChildren.get(_lastJob).iterator().next());\n+      while (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n+        String nextJob = _parentsToChildren.get(_lastJob).iterator().next();\n+        if (!_readyJobList.contains(nextJob)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0NTgyNQ=="}, "originalCommit": {"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9325b3b948b998733d56e3fb7f329c6fdc26431c", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/9325b3b948b998733d56e3fb7f329c6fdc26431c", "committedDate": "2020-05-18T23:18:16Z", "message": "Address new comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE1NzI4NTM3", "url": "https://github.com/apache/helix/pull/1006#pullrequestreview-415728537", "createdAt": "2020-05-20T21:30:30Z", "commit": {"oid": "9325b3b948b998733d56e3fb7f329c6fdc26431c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3ODQzNDg0", "url": "https://github.com/apache/helix/pull/1006#pullrequestreview-417843484", "createdAt": "2020-05-25T18:50:03Z", "commit": {"oid": "9325b3b948b998733d56e3fb7f329c6fdc26431c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4819, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}