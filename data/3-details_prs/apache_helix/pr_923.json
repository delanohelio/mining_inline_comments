{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk2NTEwNjQ0", "number": 923, "title": "Fix the scheduling decision for multiple currentStates", "bodyText": "Issues\n\n My PR addresses the following Helix issues and references them in the PR title:\nFixes #461\nFixes #922\n\nDescription\n\n Here are some details about my PR, including screenshots of any UI changes:\nThis commit specifically targets the scenario where there are multiple currentstates and previous assignment existed for one partition. In this case, since paMap has only one field for the mapping, the final result of scheduling is not deterministic. In this case, tasks can be stuck in INIT -> RUNNING and RUNNING -> DROPPED on the wrong instance. This PR fixes this scenario.\n\nTests\n\n\n The following tests are written for this issue:\nTestTargetedTaskStateChange\nTestTaskSchedulingTwoCurrentStates\n\n\n The following is the result of the \"mvn test\" command on the appropriate module:\nTest Result 1: mvn test\nFailed tests:\nTestWorkflowTermination.testWorkflowPausedTimeout:170->verifyWorkflowCleanup:257 expected: but was:\n\n\nTests run: 1094, Failures: 1, Errors: 0, Skipped: 0\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  01:13 h\n[INFO] Finished at: 2020-03-30T17:11:26-07:00\n[INFO] ------------------------------------------------------------------------\nThe failed test has passed when I ran it individually.\nCommits\n\n My commits all reference appropriate Apache Helix GitHub issues in their subject lines, and I have squashed multiple commits if they address the same issue. In addition, my commits follow the guidelines from \"How to write a good git commit message\":\n\nSubject is separated from body by a blank line\nSubject is limited to 50 characters (not including Jira issue reference)\nSubject does not end with a period\nSubject uses the imperative mood (\"add\", not \"adding\")\nBody wraps at 72 characters\nBody explains \"what\" and \"why\", not \"how\"\n\n\n\nCode Quality\n\n My diff has been formatted using helix-style.xml", "createdAt": "2020-03-31T18:19:36Z", "url": "https://github.com/apache/helix/pull/923", "merged": true, "mergeCommit": {"oid": "184a50ac173c18e0ea3d40ffb5a0f93d31aa558f"}, "closed": true, "closedAt": "2020-04-02T16:43:16Z", "author": {"login": "alirezazamani"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcTFyG7AH2gAyMzk2NTEwNjQ0OjY3ZjE1Y2ZkY2Q3N2UyZTU4NWQ2NDFiZTg1NjBjOGJmMTAwMTM3OTA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcTiuocgH2gAyMzk2NTEwNjQ0OjZkZjM3ZTRlNDhjMGVlNjZjOWQxYTU0NzkwYzg2MTI0ZDJlYjNlMGY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "67f15cfdcd77e2e585d641be8560c8bf10013790", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/67f15cfdcd77e2e585d641be8560c8bf10013790", "committedDate": "2020-03-31T16:34:54Z", "message": "Fix the scheduling decision for multiple currentStates\n\nIn this commit, the problem of scheduling and dropping the tasks\non the slave node has been addressed.\nA new test has been added."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MDA4MDYx", "url": "https://github.com/apache/helix/pull/923#pullrequestreview-385008061", "createdAt": "2020-03-31T18:44:46Z", "commit": {"oid": "67f15cfdcd77e2e585d641be8560c8bf10013790"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxODo0NDo0NlrOF-jViw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxODo0Nzo0MFrOF-jcdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTEzNDk4Nw==", "bodyText": "I suggest using  {}-style parameters.", "url": "https://github.com/apache/helix/pull/923#discussion_r401134987", "createdAt": "2020-03-31T18:44:46Z", "author": {"login": "huizhilu"}, "path": "helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java", "diffHunk": "@@ -115,6 +115,12 @@ public void updatePreviousAssignedTasksStatus(\n         TaskPartitionState currState = updateJobContextAndGetTaskCurrentState(currStateOutput,\n             jobResource, pId, pName, instance, jobCtx, jobTgtState);\n \n+        if (!instance.equals(jobCtx.getAssignedParticipant(pId))) {\n+          LOG.warn(String.format(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67f15cfdcd77e2e585d641be8560c8bf10013790"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTEzNjc1OQ==", "bodyText": "Can we have a more descriptive name for this class?", "url": "https://github.com/apache/helix/pull/923#discussion_r401136759", "createdAt": "2020-03-31T18:47:40Z", "author": {"login": "huizhilu"}, "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "diffHunk": "@@ -0,0 +1,348 @@\n+package org.apache.helix.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.helix.common.caches.TaskDataCache;\n+import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n+import org.apache.helix.controller.stages.BestPossibleStateOutput;\n+import org.apache.helix.controller.stages.CurrentStateOutput;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.InstanceConfig;\n+import org.apache.helix.model.LiveInstance;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestTargetedTaskStateChange {\n+  private static final String CLUSTER_NAME = \"TestCluster\";\n+  private static final String INSTANCE_PREFIX = \"Instance_\";\n+  private static final int NUM_PARTICIPANTS = 3;\n+  private static final String WORKFLOW_NAME = \"TestWorkflow\";\n+  private static final String JOB_NAME = \"TestJob\";\n+  private static final String PARTITION_NAME = \"0\";\n+  private static final String TARGET_RESOURCES = \"TestDB\";\n+  private static final int NUM_TASKS = 1;\n+  private Map<String, LiveInstance> _liveInstances;\n+  private Map<String, InstanceConfig> _instanceConfigs;\n+  private ClusterConfig _clusterConfig;\n+  private AssignableInstanceManager _assignableInstanceManager;\n+\n+  @BeforeClass\n+  public void beforeClass() {\n+    System.out.println(\n+        \"START \" + this.getClass().getSimpleName() + \" at \" + new Date(System.currentTimeMillis()));\n+    // Populate live instances and their corresponding instance configs\n+    _liveInstances = new HashMap<>();\n+    _instanceConfigs = new HashMap<>();\n+    _clusterConfig = new ClusterConfig(CLUSTER_NAME);\n+    for (int i = 0; i < NUM_PARTICIPANTS; i++) {\n+      String instanceName = INSTANCE_PREFIX + i;\n+      LiveInstance liveInstance = new LiveInstance(instanceName);\n+      InstanceConfig instanceConfig = new InstanceConfig(instanceName);\n+      _liveInstances.put(instanceName, liveInstance);\n+      _instanceConfigs.put(instanceName, instanceConfig);\n+    }\n+    _assignableInstanceManager = new AssignableInstanceManager();\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there are two current states for two\n+   * different instances.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Running\n+   * CurrentState: Instance0: Running, Instance1: Running\n+   * Expected paMap: Instance0 -> Dropped\n+   */\n+  @Test\n+  public void testTwoRunningCurrentStates() {\n+    Mock mock = new Mock();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(true);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.DROPPED.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"0\"));\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there is one current state which is\n+   * different from\n+   * Previous Assignment information.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Dropped\n+   * CurrentState: Instance0: Running\n+   * Expected paMap: Instance1 -> Running\n+   */\n+  @Test\n+  public void testOneRunningOneNull() {\n+    Mock mock = new Mock();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment2);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(false);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput2, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.RUNNING.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"1\"));\n+  }\n+\n+  private WorkflowConfig prepareWorkflowConfig() {\n+    WorkflowConfig.Builder workflowConfigBuilder = new WorkflowConfig.Builder();\n+    workflowConfigBuilder.setWorkflowId(WORKFLOW_NAME);\n+    workflowConfigBuilder.setTerminable(false);\n+    workflowConfigBuilder.setTargetState(TargetState.START);\n+    workflowConfigBuilder.setJobQueue(true);\n+    JobDag jobDag = new JobDag();\n+    jobDag.addNode(JOB_NAME);\n+    workflowConfigBuilder.setJobDag(jobDag);\n+    WorkflowConfig workflowConfig = workflowConfigBuilder.build();\n+\n+    return workflowConfig;\n+  }\n+\n+  private JobConfig prepareJobConfig() {\n+    JobConfig.Builder jobConfigBuilder = new JobConfig.Builder();\n+    jobConfigBuilder.setWorkflow(WORKFLOW_NAME);\n+    jobConfigBuilder.setCommand(\"TestCommand\");\n+    jobConfigBuilder.setTargetResource(TARGET_RESOURCES);\n+    jobConfigBuilder.setJobId(JOB_NAME);\n+    List<String> targetPartition = new ArrayList<>();\n+    targetPartition.add(TARGET_RESOURCES + \"_0\");\n+    jobConfigBuilder.setTargetPartitions(targetPartition);\n+    Set<String> targetPartitionStates = new HashSet<>();\n+    targetPartitionStates.add(\"MASTER\");\n+    List<TaskConfig> taskConfigs = new ArrayList<>();\n+    TaskConfig.Builder taskConfigBuilder = new TaskConfig.Builder();\n+    taskConfigBuilder.setTaskId(\"0\");\n+    taskConfigs.add(taskConfigBuilder.build());\n+    jobConfigBuilder.setTargetPartitionStates(targetPartitionStates);\n+    jobConfigBuilder.addTaskConfigs(taskConfigs);\n+    JobConfig jobConfig = jobConfigBuilder.build();\n+    return jobConfig;\n+  }\n+\n+  private WorkflowContext prepareWorkflowContext() {\n+    ZNRecord record = new ZNRecord(WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.StartTime.name(), \"0\");\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.NAME.name(), WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.STATE.name(),\n+        TaskState.IN_PROGRESS.name());\n+    Map<String, String> jobState = new HashMap<>();\n+    jobState.put(JOB_NAME, TaskState.IN_PROGRESS.name());\n+    record.setMapField(WorkflowContext.WorkflowContextProperties.JOB_STATES.name(), jobState);\n+    return new WorkflowContext(record);\n+  }\n+\n+  private JobContext prepareJobContext(String instance) {\n+    Set<Integer> _taskPartitionSet;\n+    Map<Integer, TaskPartitionState> _taskPartitionStateMap;\n+    Map<Integer, String> _partitionToTaskIDMap;\n+    Map<Integer, String> _taskToInstanceMap;\n+    _taskPartitionSet = new HashSet<>();\n+    _taskPartitionStateMap = new HashMap<>();\n+    _partitionToTaskIDMap = new HashMap<>();\n+    _taskToInstanceMap = new HashMap<>();\n+\n+    _taskPartitionSet.add(0);\n+    _taskPartitionStateMap.put(0, TaskPartitionState.RUNNING);\n+    _partitionToTaskIDMap.put(0, \"0\");\n+    String someInstance = INSTANCE_PREFIX + 0;\n+    _taskToInstanceMap.put(0, someInstance);\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    JobContext jobContext = new JobContext(record);\n+    jobContext.setStartTime(0L);\n+    jobContext.setName(JOB_NAME);\n+    jobContext.setStartTime(0L);\n+    jobContext.setPartitionState(0, TaskPartitionState.RUNNING);\n+    jobContext.setPartitionTarget(0, instance);\n+    jobContext.setPartitionTarget(0, TARGET_RESOURCES + \"_0\");\n+    return jobContext;\n+  }\n+\n+  private Map<String, IdealState> prepareIdealStates(String instance1, String instance2,\n+      String instance3) {\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    record.setSimpleField(IdealState.IdealStateProperty.NUM_PARTITIONS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.EXTERNAL_VIEW_DISABLED.name(), \"true\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"TASK\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"Task\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_FACTORY_NAME.name(), \"DEFAULT\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.task.JobRebalancer\");\n+    record.setMapField(JOB_NAME + \"_\" + PARTITION_NAME, new HashMap<>());\n+    record.setListField(JOB_NAME + \"_\" + PARTITION_NAME, new ArrayList<>());\n+    Map<String, IdealState> idealStates = new HashMap<>();\n+    idealStates.put(JOB_NAME, new IdealState(record));\n+\n+    ZNRecord recordDB = new ZNRecord(TARGET_RESOURCES);\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"3\");\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"FULL_AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO_REBALANCE\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"MasterSlave\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(),\n+        \"org.apache.helix.controller.rebalancer.strategy.CrushEdRebalanceStrategy\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.controller.rebalancer.DelayedAutoRebalancer\");\n+    Map<String, String> mapping = new HashMap<>();\n+    mapping.put(instance1, \"MASTER\");\n+    mapping.put(instance2, \"SLAVE\");\n+    mapping.put(instance3, \"SLAVE\");\n+    recordDB.setMapField(TARGET_RESOURCES + \"_0\", mapping);\n+    List<String> listField = new ArrayList<>();\n+    listField.add(instance1);\n+    listField.add(instance2);\n+    listField.add(instance3);\n+    recordDB.setListField(TARGET_RESOURCES + \"_0\", listField);\n+    idealStates.put(TARGET_RESOURCES, new IdealState(recordDB));\n+\n+    return idealStates;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState(String masterInstance, String slaveInstance,\n+      String masterState, String slaveState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, slaveInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, slaveInstance, slaveState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, slaveInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState2(String masterInstance, String masterState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private ResourceAssignment preparePreviousAssignment(String instance, String state) {\n+    ResourceAssignment prevAssignment = new ResourceAssignment(JOB_NAME);\n+    Map<String, String> replicaMap = new HashMap<>();\n+    replicaMap.put(instance, state);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    prevAssignment.addReplicaMap(taskPartition, replicaMap);\n+    return prevAssignment;\n+  }\n+\n+  private class Mock {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67f15cfdcd77e2e585d641be8560c8bf10013790"}, "originalPosition": 322}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/82584289cf6bae1d5c0195f79bbe2c4f910c08bf", "committedDate": "2020-03-31T23:49:52Z", "message": "Address comments and add integration test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1ODk1ODE4", "url": "https://github.com/apache/helix/pull/923#pullrequestreview-385895818", "createdAt": "2020-04-01T19:44:41Z", "commit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDIzNDQw", "url": "https://github.com/apache/helix/pull/923#pullrequestreview-386023440", "createdAt": "2020-04-01T23:46:27Z", "commit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzo0NjoyN1rOF_WiWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzo0NjoyN1rOF_WiWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3Mzg0OA==", "bodyText": "\"private static final String\" for constants? Or just use DEFAULT_TGT_DB directly.", "url": "https://github.com/apache/helix/pull/923#discussion_r401973848", "createdAt": "2020-04-01T23:46:27Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskSchedulingTwoCurrentStates.java", "diffHunk": "@@ -0,0 +1,219 @@\n+package org.apache.helix.integration.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import com.google.common.collect.Sets;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.HelixDataAccessor;\n+import org.apache.helix.HelixManagerFactory;\n+import org.apache.helix.InstanceType;\n+import org.apache.helix.PropertyKey;\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.ZkTestHelper;\n+import org.apache.helix.integration.manager.MockParticipantManager;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.CurrentState;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.MasterSlaveSMD;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.participant.StateMachineEngine;\n+import org.apache.helix.task.JobConfig;\n+import org.apache.helix.task.JobContext;\n+import org.apache.helix.task.JobQueue;\n+import org.apache.helix.task.TaskCallbackContext;\n+import org.apache.helix.task.TaskDriver;\n+import org.apache.helix.task.TaskFactory;\n+import org.apache.helix.task.TaskPartitionState;\n+import org.apache.helix.task.TaskState;\n+import org.apache.helix.task.TaskStateModelFactory;\n+import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.apache.helix.zookeeper.impl.client.ZkClient;\n+import org.apache.zookeeper.data.Stat;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Test to check if targeted tasks correctly get assigned and also if cancel messages are not being\n+ * sent when there are two CurrentStates.\n+ */\n+public class TestTaskSchedulingTwoCurrentStates extends TaskTestBase {\n+  private final String DATABASE = WorkflowGenerator.DEFAULT_TGT_DB;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDIzNzc5", "url": "https://github.com/apache/helix/pull/923#pullrequestreview-386023779", "createdAt": "2020-04-01T23:47:32Z", "commit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzo0NzozMlrOF_Wjgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzo0NzozMlrOF_Wjgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3NDE0Ng==", "bodyText": "Possible to merge these two loops?", "url": "https://github.com/apache/helix/pull/923#discussion_r401974146", "createdAt": "2020-04-01T23:47:32Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskSchedulingTwoCurrentStates.java", "diffHunk": "@@ -0,0 +1,219 @@\n+package org.apache.helix.integration.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import com.google.common.collect.Sets;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.HelixDataAccessor;\n+import org.apache.helix.HelixManagerFactory;\n+import org.apache.helix.InstanceType;\n+import org.apache.helix.PropertyKey;\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.ZkTestHelper;\n+import org.apache.helix.integration.manager.MockParticipantManager;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.CurrentState;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.MasterSlaveSMD;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.participant.StateMachineEngine;\n+import org.apache.helix.task.JobConfig;\n+import org.apache.helix.task.JobContext;\n+import org.apache.helix.task.JobQueue;\n+import org.apache.helix.task.TaskCallbackContext;\n+import org.apache.helix.task.TaskDriver;\n+import org.apache.helix.task.TaskFactory;\n+import org.apache.helix.task.TaskPartitionState;\n+import org.apache.helix.task.TaskState;\n+import org.apache.helix.task.TaskStateModelFactory;\n+import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.apache.helix.zookeeper.impl.client.ZkClient;\n+import org.apache.zookeeper.data.Stat;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Test to check if targeted tasks correctly get assigned and also if cancel messages are not being\n+ * sent when there are two CurrentStates.\n+ */\n+public class TestTaskSchedulingTwoCurrentStates extends TaskTestBase {\n+  private final String DATABASE = WorkflowGenerator.DEFAULT_TGT_DB;\n+  protected HelixDataAccessor _accessor;\n+  private PropertyKey.Builder _keyBuilder;\n+  private static final AtomicInteger CANCEL_COUNT = new AtomicInteger(0);\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception {\n+    _numPartitions = 1;\n+    _numNodes = 3;\n+    super.beforeClass();\n+    _manager = HelixManagerFactory.getZKHelixManager(CLUSTER_NAME, \"Admin\",\n+        InstanceType.ADMINISTRATOR, ZK_ADDR);\n+\n+    // Stop participants that have been started in super class\n+    for (int i = 0; i < _numNodes; i++) {\n+      super.stopParticipant(i);\n+    }\n+\n+    // Check that participants are actually stopped\n+    for (int i = 0; i < _numNodes; i++) {\n+      Assert.assertFalse(_participants[i].isConnected());\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "originalPosition": 88}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDI0NDE1", "url": "https://github.com/apache/helix/pull/923#pullrequestreview-386024415", "createdAt": "2020-04-01T23:49:23Z", "commit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzo0OToyM1rOF_Wl2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzo0OToyM1rOF_Wl2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3NDc0Nw==", "bodyText": "Why do these local variables have underscores?", "url": "https://github.com/apache/helix/pull/923#discussion_r401974747", "createdAt": "2020-04-01T23:49:23Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "diffHunk": "@@ -0,0 +1,348 @@\n+package org.apache.helix.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.helix.common.caches.TaskDataCache;\n+import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n+import org.apache.helix.controller.stages.BestPossibleStateOutput;\n+import org.apache.helix.controller.stages.CurrentStateOutput;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.InstanceConfig;\n+import org.apache.helix.model.LiveInstance;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestTargetedTaskStateChange {\n+  private static final String CLUSTER_NAME = \"TestCluster\";\n+  private static final String INSTANCE_PREFIX = \"Instance_\";\n+  private static final int NUM_PARTICIPANTS = 3;\n+  private static final String WORKFLOW_NAME = \"TestWorkflow\";\n+  private static final String JOB_NAME = \"TestJob\";\n+  private static final String PARTITION_NAME = \"0\";\n+  private static final String TARGET_RESOURCES = \"TestDB\";\n+  private static final int NUM_TASKS = 1;\n+  private Map<String, LiveInstance> _liveInstances;\n+  private Map<String, InstanceConfig> _instanceConfigs;\n+  private ClusterConfig _clusterConfig;\n+  private AssignableInstanceManager _assignableInstanceManager;\n+\n+  @BeforeClass\n+  public void beforeClass() {\n+    System.out.println(\n+        \"START \" + this.getClass().getSimpleName() + \" at \" + new Date(System.currentTimeMillis()));\n+    // Populate live instances and their corresponding instance configs\n+    _liveInstances = new HashMap<>();\n+    _instanceConfigs = new HashMap<>();\n+    _clusterConfig = new ClusterConfig(CLUSTER_NAME);\n+    for (int i = 0; i < NUM_PARTICIPANTS; i++) {\n+      String instanceName = INSTANCE_PREFIX + i;\n+      LiveInstance liveInstance = new LiveInstance(instanceName);\n+      InstanceConfig instanceConfig = new InstanceConfig(instanceName);\n+      _liveInstances.put(instanceName, liveInstance);\n+      _instanceConfigs.put(instanceName, instanceConfig);\n+    }\n+    _assignableInstanceManager = new AssignableInstanceManager();\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there are two current states for two\n+   * different instances.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Running\n+   * CurrentState: Instance0: Running, Instance1: Running\n+   * Expected paMap: Instance0 -> Dropped\n+   */\n+  @Test\n+  public void testTwoRunningCurrentStates() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(true);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.DROPPED.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"0\"));\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there is one current state which is\n+   * different from\n+   * Previous Assignment information.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Dropped\n+   * CurrentState: Instance0: Running\n+   * Expected paMap: Instance1 -> Running\n+   */\n+  @Test\n+  public void testOneRunningOneNull() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment2);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(false);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput2, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.RUNNING.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"1\"));\n+  }\n+\n+  private WorkflowConfig prepareWorkflowConfig() {\n+    WorkflowConfig.Builder workflowConfigBuilder = new WorkflowConfig.Builder();\n+    workflowConfigBuilder.setWorkflowId(WORKFLOW_NAME);\n+    workflowConfigBuilder.setTerminable(false);\n+    workflowConfigBuilder.setTargetState(TargetState.START);\n+    workflowConfigBuilder.setJobQueue(true);\n+    JobDag jobDag = new JobDag();\n+    jobDag.addNode(JOB_NAME);\n+    workflowConfigBuilder.setJobDag(jobDag);\n+    WorkflowConfig workflowConfig = workflowConfigBuilder.build();\n+\n+    return workflowConfig;\n+  }\n+\n+  private JobConfig prepareJobConfig() {\n+    JobConfig.Builder jobConfigBuilder = new JobConfig.Builder();\n+    jobConfigBuilder.setWorkflow(WORKFLOW_NAME);\n+    jobConfigBuilder.setCommand(\"TestCommand\");\n+    jobConfigBuilder.setTargetResource(TARGET_RESOURCES);\n+    jobConfigBuilder.setJobId(JOB_NAME);\n+    List<String> targetPartition = new ArrayList<>();\n+    targetPartition.add(TARGET_RESOURCES + \"_0\");\n+    jobConfigBuilder.setTargetPartitions(targetPartition);\n+    Set<String> targetPartitionStates = new HashSet<>();\n+    targetPartitionStates.add(\"MASTER\");\n+    List<TaskConfig> taskConfigs = new ArrayList<>();\n+    TaskConfig.Builder taskConfigBuilder = new TaskConfig.Builder();\n+    taskConfigBuilder.setTaskId(\"0\");\n+    taskConfigs.add(taskConfigBuilder.build());\n+    jobConfigBuilder.setTargetPartitionStates(targetPartitionStates);\n+    jobConfigBuilder.addTaskConfigs(taskConfigs);\n+    JobConfig jobConfig = jobConfigBuilder.build();\n+    return jobConfig;\n+  }\n+\n+  private WorkflowContext prepareWorkflowContext() {\n+    ZNRecord record = new ZNRecord(WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.StartTime.name(), \"0\");\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.NAME.name(), WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.STATE.name(),\n+        TaskState.IN_PROGRESS.name());\n+    Map<String, String> jobState = new HashMap<>();\n+    jobState.put(JOB_NAME, TaskState.IN_PROGRESS.name());\n+    record.setMapField(WorkflowContext.WorkflowContextProperties.JOB_STATES.name(), jobState);\n+    return new WorkflowContext(record);\n+  }\n+\n+  private JobContext prepareJobContext(String instance) {\n+    Set<Integer> _taskPartitionSet;\n+    Map<Integer, TaskPartitionState> _taskPartitionStateMap;\n+    Map<Integer, String> _partitionToTaskIDMap;\n+    Map<Integer, String> _taskToInstanceMap;\n+    _taskPartitionSet = new HashSet<>();\n+    _taskPartitionStateMap = new HashMap<>();\n+    _partitionToTaskIDMap = new HashMap<>();\n+    _taskToInstanceMap = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "originalPosition": 216}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a842ab7a1ba49fdcfa59dd1fe37ebb4529b367d2", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/a842ab7a1ba49fdcfa59dd1fe37ebb4529b367d2", "committedDate": "2020-04-02T01:46:46Z", "message": "address comments 2"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDYyNDU0", "url": "https://github.com/apache/helix/pull/923#pullrequestreview-386062454", "createdAt": "2020-04-02T01:59:01Z", "commit": {"oid": "5bee6da006ae40c93fa8bcb6c5009ea2a5dc9bfc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMTo1OTowMVrOF_Yu1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMTo1OTowMVrOF_Yu1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAwOTgxMw==", "bodyText": "Let's be consistent with underscores here as well? some have them, others don't.", "url": "https://github.com/apache/helix/pull/923#discussion_r402009813", "createdAt": "2020-04-02T01:59:01Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "diffHunk": "@@ -0,0 +1,330 @@\n+package org.apache.helix.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.helix.common.caches.TaskDataCache;\n+import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n+import org.apache.helix.controller.stages.BestPossibleStateOutput;\n+import org.apache.helix.controller.stages.CurrentStateOutput;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.InstanceConfig;\n+import org.apache.helix.model.LiveInstance;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestTargetedTaskStateChange {\n+  private static final String CLUSTER_NAME = \"TestCluster\";\n+  private static final String INSTANCE_PREFIX = \"Instance_\";\n+  private static final int NUM_PARTICIPANTS = 3;\n+  private static final String WORKFLOW_NAME = \"TestWorkflow\";\n+  private static final String JOB_NAME = \"TestJob\";\n+  private static final String PARTITION_NAME = \"0\";\n+  private static final String TARGET_RESOURCES = \"TestDB\";\n+  private static final int NUM_TASKS = 1;\n+  private Map<String, LiveInstance> _liveInstances;\n+  private Map<String, InstanceConfig> _instanceConfigs;\n+  private ClusterConfig _clusterConfig;\n+  private AssignableInstanceManager _assignableInstanceManager;\n+\n+  @BeforeClass\n+  public void beforeClass() {\n+    // Populate live instances and their corresponding instance configs\n+    _liveInstances = new HashMap<>();\n+    _instanceConfigs = new HashMap<>();\n+    _clusterConfig = new ClusterConfig(CLUSTER_NAME);\n+    for (int i = 0; i < NUM_PARTICIPANTS; i++) {\n+      String instanceName = INSTANCE_PREFIX + i;\n+      LiveInstance liveInstance = new LiveInstance(instanceName);\n+      InstanceConfig instanceConfig = new InstanceConfig(instanceName);\n+      _liveInstances.put(instanceName, liveInstance);\n+      _instanceConfigs.put(instanceName, instanceConfig);\n+    }\n+    _assignableInstanceManager = new AssignableInstanceManager();\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there are two current states for two\n+   * different instances.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Running\n+   * CurrentState: Instance0: Running, Instance1: Running\n+   * Expected paMap: Instance0 -> Dropped\n+   */\n+  @Test\n+  public void testTwoRunningCurrentStates() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(true);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.DROPPED.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"0\"));\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there is one current state which is\n+   * different from\n+   * Previous Assignment information.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Dropped\n+   * CurrentState: Instance0: Running\n+   * Expected paMap: Instance1 -> Running\n+   */\n+  @Test\n+  public void testOneRunningOneNull() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment2);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(false);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput2, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.RUNNING.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"1\"));\n+  }\n+\n+  private WorkflowConfig prepareWorkflowConfig() {\n+    WorkflowConfig.Builder workflowConfigBuilder = new WorkflowConfig.Builder();\n+    workflowConfigBuilder.setWorkflowId(WORKFLOW_NAME);\n+    workflowConfigBuilder.setTerminable(false);\n+    workflowConfigBuilder.setTargetState(TargetState.START);\n+    workflowConfigBuilder.setJobQueue(true);\n+    JobDag jobDag = new JobDag();\n+    jobDag.addNode(JOB_NAME);\n+    workflowConfigBuilder.setJobDag(jobDag);\n+    return workflowConfigBuilder.build();\n+  }\n+\n+  private JobConfig prepareJobConfig() {\n+    JobConfig.Builder jobConfigBuilder = new JobConfig.Builder();\n+    jobConfigBuilder.setWorkflow(WORKFLOW_NAME);\n+    jobConfigBuilder.setCommand(\"TestCommand\");\n+    jobConfigBuilder.setTargetResource(TARGET_RESOURCES);\n+    jobConfigBuilder.setJobId(JOB_NAME);\n+    List<String> targetPartition = new ArrayList<>();\n+    targetPartition.add(TARGET_RESOURCES + \"_0\");\n+    jobConfigBuilder.setTargetPartitions(targetPartition);\n+    Set<String> targetPartitionStates = new HashSet<>();\n+    targetPartitionStates.add(\"MASTER\");\n+    List<TaskConfig> taskConfigs = new ArrayList<>();\n+    TaskConfig.Builder taskConfigBuilder = new TaskConfig.Builder();\n+    taskConfigBuilder.setTaskId(\"0\");\n+    taskConfigs.add(taskConfigBuilder.build());\n+    jobConfigBuilder.setTargetPartitionStates(targetPartitionStates);\n+    jobConfigBuilder.addTaskConfigs(taskConfigs);\n+    JobConfig jobConfig = jobConfigBuilder.build();\n+    return jobConfig;\n+  }\n+\n+  private WorkflowContext prepareWorkflowContext() {\n+    ZNRecord record = new ZNRecord(WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.StartTime.name(), \"0\");\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.NAME.name(), WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.STATE.name(),\n+        TaskState.IN_PROGRESS.name());\n+    Map<String, String> jobState = new HashMap<>();\n+    jobState.put(JOB_NAME, TaskState.IN_PROGRESS.name());\n+    record.setMapField(WorkflowContext.WorkflowContextProperties.JOB_STATES.name(), jobState);\n+    return new WorkflowContext(record);\n+  }\n+\n+  private JobContext prepareJobContext(String instance) {\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    JobContext jobContext = new JobContext(record);\n+    jobContext.setStartTime(0L);\n+    jobContext.setName(JOB_NAME);\n+    jobContext.setStartTime(0L);\n+    jobContext.setPartitionState(0, TaskPartitionState.RUNNING);\n+    jobContext.setPartitionTarget(0, instance);\n+    jobContext.setPartitionTarget(0, TARGET_RESOURCES + \"_0\");\n+    return jobContext;\n+  }\n+\n+  private Map<String, IdealState> prepareIdealStates(String instance1, String instance2,\n+      String instance3) {\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    record.setSimpleField(IdealState.IdealStateProperty.NUM_PARTITIONS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.EXTERNAL_VIEW_DISABLED.name(), \"true\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"TASK\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"Task\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_FACTORY_NAME.name(), \"DEFAULT\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.task.JobRebalancer\");\n+    record.setMapField(JOB_NAME + \"_\" + PARTITION_NAME, new HashMap<>());\n+    record.setListField(JOB_NAME + \"_\" + PARTITION_NAME, new ArrayList<>());\n+    Map<String, IdealState> idealStates = new HashMap<>();\n+    idealStates.put(JOB_NAME, new IdealState(record));\n+\n+    ZNRecord recordDB = new ZNRecord(TARGET_RESOURCES);\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"3\");\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"FULL_AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO_REBALANCE\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"MasterSlave\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(),\n+        \"org.apache.helix.controller.rebalancer.strategy.CrushEdRebalanceStrategy\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.controller.rebalancer.DelayedAutoRebalancer\");\n+    Map<String, String> mapping = new HashMap<>();\n+    mapping.put(instance1, \"MASTER\");\n+    mapping.put(instance2, \"SLAVE\");\n+    mapping.put(instance3, \"SLAVE\");\n+    recordDB.setMapField(TARGET_RESOURCES + \"_0\", mapping);\n+    List<String> listField = new ArrayList<>();\n+    listField.add(instance1);\n+    listField.add(instance2);\n+    listField.add(instance3);\n+    recordDB.setListField(TARGET_RESOURCES + \"_0\", listField);\n+    idealStates.put(TARGET_RESOURCES, new IdealState(recordDB));\n+\n+    return idealStates;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState(String masterInstance, String slaveInstance,\n+      String masterState, String slaveState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, slaveInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, slaveInstance, slaveState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, slaveInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState2(String masterInstance, String masterState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private ResourceAssignment preparePreviousAssignment(String instance, String state) {\n+    ResourceAssignment prevAssignment = new ResourceAssignment(JOB_NAME);\n+    Map<String, String> replicaMap = new HashMap<>();\n+    replicaMap.put(instance, state);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    prevAssignment.addReplicaMap(taskPartition, replicaMap);\n+    return prevAssignment;\n+  }\n+\n+  private class MockTestInformation {\n+    private String slaveInstance = INSTANCE_PREFIX + \"0\";\n+    private String masterInstance = INSTANCE_PREFIX + \"1\";\n+    private String slaveInstance2 = INSTANCE_PREFIX + \"2\";\n+    private WorkflowControllerDataProvider cache = mock(WorkflowControllerDataProvider.class);\n+    private WorkflowConfig _workflowConfig = prepareWorkflowConfig();\n+    private WorkflowContext _workflowContext = prepareWorkflowContext();\n+    private Map<String, IdealState> _idealStates =\n+        prepareIdealStates(masterInstance, slaveInstance, slaveInstance2);\n+    private JobConfig _jobConfig = prepareJobConfig();\n+    private JobContext _jobContext = prepareJobContext(slaveInstance);\n+    private BestPossibleStateOutput _bestPossibleStateOutput = mock(BestPossibleStateOutput.class);\n+    private CurrentStateOutput _currentStateOutput = prepareCurrentState(masterInstance,\n+        slaveInstance, TaskPartitionState.RUNNING.name(), TaskPartitionState.RUNNING.name());\n+    private CurrentStateOutput _currentStateOutput2 =\n+        prepareCurrentState2(masterInstance, TaskPartitionState.RUNNING.name());\n+    private ResourceAssignment _resourceAssignment =\n+        preparePreviousAssignment(slaveInstance, TaskPartitionState.RUNNING.name());\n+    private ResourceAssignment _resourceAssignment2 =\n+        preparePreviousAssignment(slaveInstance, TaskPartitionState.DROPPED.name());\n+    private TaskDataCache _taskDataCache = mock(TaskDataCache.class);\n+    private RuntimeJobDag _runtimeJobDag = mock(RuntimeJobDag.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bee6da006ae40c93fa8bcb6c5009ea2a5dc9bfc"}, "originalPosition": 325}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2MDYyNDk4", "url": "https://github.com/apache/helix/pull/923#pullrequestreview-386062498", "createdAt": "2020-04-02T01:59:09Z", "commit": {"oid": "5bee6da006ae40c93fa8bcb6c5009ea2a5dc9bfc"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5bee6da006ae40c93fa8bcb6c5009ea2a5dc9bfc", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/5bee6da006ae40c93fa8bcb6c5009ea2a5dc9bfc", "committedDate": "2020-04-02T00:31:07Z", "message": "address comments 2"}, "afterCommit": {"oid": "a842ab7a1ba49fdcfa59dd1fe37ebb4529b367d2", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/a842ab7a1ba49fdcfa59dd1fe37ebb4529b367d2", "committedDate": "2020-04-02T01:46:46Z", "message": "address comments 2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6df37e4e48c0ee66c9d1a54790c86124d2eb3e0f", "author": {"user": {"login": "alirezazamani", "name": "Ali Reza Zamani Zadeh Najari"}}, "url": "https://github.com/apache/helix/commit/6df37e4e48c0ee66c9d1a54790c86124d2eb3e0f", "committedDate": "2020-04-02T02:18:21Z", "message": "fix variables"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4745, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}