{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk2NTEwNjQ0", "number": 923, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxODo0NDo0NlrODtPX_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMTo1OTowMVrODtxKwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzY0NDEzOnYy", "diffSide": "RIGHT", "path": "helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxODo0NDo0NlrOF-jViw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQyMzo1MTo1NlrOF-sL3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTEzNDk4Nw==", "bodyText": "I suggest using  {}-style parameters.", "url": "https://github.com/apache/helix/pull/923#discussion_r401134987", "createdAt": "2020-03-31T18:44:46Z", "author": {"login": "huizhilu"}, "path": "helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java", "diffHunk": "@@ -115,6 +115,12 @@ public void updatePreviousAssignedTasksStatus(\n         TaskPartitionState currState = updateJobContextAndGetTaskCurrentState(currStateOutput,\n             jobResource, pId, pName, instance, jobCtx, jobTgtState);\n \n+        if (!instance.equals(jobCtx.getAssignedParticipant(pId))) {\n+          LOG.warn(String.format(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67f15cfdcd77e2e585d641be8560c8bf10013790"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTI3OTk2Nw==", "bodyText": "Done.", "url": "https://github.com/apache/helix/pull/923#discussion_r401279967", "createdAt": "2020-03-31T23:51:56Z", "author": {"login": "alirezazamani"}, "path": "helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java", "diffHunk": "@@ -115,6 +115,12 @@ public void updatePreviousAssignedTasksStatus(\n         TaskPartitionState currState = updateJobContextAndGetTaskCurrentState(currStateOutput,\n             jobResource, pId, pName, instance, jobCtx, jobTgtState);\n \n+        if (!instance.equals(jobCtx.getAssignedParticipant(pId))) {\n+          LOG.warn(String.format(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTEzNDk4Nw=="}, "originalCommit": {"oid": "67f15cfdcd77e2e585d641be8560c8bf10013790"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzY1NTAwOnYy", "diffSide": "RIGHT", "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxODo0Nzo0MFrOF-jcdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQyMzo1MTo0N1rOF-sLnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTEzNjc1OQ==", "bodyText": "Can we have a more descriptive name for this class?", "url": "https://github.com/apache/helix/pull/923#discussion_r401136759", "createdAt": "2020-03-31T18:47:40Z", "author": {"login": "huizhilu"}, "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "diffHunk": "@@ -0,0 +1,348 @@\n+package org.apache.helix.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.helix.common.caches.TaskDataCache;\n+import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n+import org.apache.helix.controller.stages.BestPossibleStateOutput;\n+import org.apache.helix.controller.stages.CurrentStateOutput;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.InstanceConfig;\n+import org.apache.helix.model.LiveInstance;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestTargetedTaskStateChange {\n+  private static final String CLUSTER_NAME = \"TestCluster\";\n+  private static final String INSTANCE_PREFIX = \"Instance_\";\n+  private static final int NUM_PARTICIPANTS = 3;\n+  private static final String WORKFLOW_NAME = \"TestWorkflow\";\n+  private static final String JOB_NAME = \"TestJob\";\n+  private static final String PARTITION_NAME = \"0\";\n+  private static final String TARGET_RESOURCES = \"TestDB\";\n+  private static final int NUM_TASKS = 1;\n+  private Map<String, LiveInstance> _liveInstances;\n+  private Map<String, InstanceConfig> _instanceConfigs;\n+  private ClusterConfig _clusterConfig;\n+  private AssignableInstanceManager _assignableInstanceManager;\n+\n+  @BeforeClass\n+  public void beforeClass() {\n+    System.out.println(\n+        \"START \" + this.getClass().getSimpleName() + \" at \" + new Date(System.currentTimeMillis()));\n+    // Populate live instances and their corresponding instance configs\n+    _liveInstances = new HashMap<>();\n+    _instanceConfigs = new HashMap<>();\n+    _clusterConfig = new ClusterConfig(CLUSTER_NAME);\n+    for (int i = 0; i < NUM_PARTICIPANTS; i++) {\n+      String instanceName = INSTANCE_PREFIX + i;\n+      LiveInstance liveInstance = new LiveInstance(instanceName);\n+      InstanceConfig instanceConfig = new InstanceConfig(instanceName);\n+      _liveInstances.put(instanceName, liveInstance);\n+      _instanceConfigs.put(instanceName, instanceConfig);\n+    }\n+    _assignableInstanceManager = new AssignableInstanceManager();\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there are two current states for two\n+   * different instances.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Running\n+   * CurrentState: Instance0: Running, Instance1: Running\n+   * Expected paMap: Instance0 -> Dropped\n+   */\n+  @Test\n+  public void testTwoRunningCurrentStates() {\n+    Mock mock = new Mock();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(true);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.DROPPED.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"0\"));\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there is one current state which is\n+   * different from\n+   * Previous Assignment information.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Dropped\n+   * CurrentState: Instance0: Running\n+   * Expected paMap: Instance1 -> Running\n+   */\n+  @Test\n+  public void testOneRunningOneNull() {\n+    Mock mock = new Mock();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment2);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(false);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput2, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.RUNNING.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"1\"));\n+  }\n+\n+  private WorkflowConfig prepareWorkflowConfig() {\n+    WorkflowConfig.Builder workflowConfigBuilder = new WorkflowConfig.Builder();\n+    workflowConfigBuilder.setWorkflowId(WORKFLOW_NAME);\n+    workflowConfigBuilder.setTerminable(false);\n+    workflowConfigBuilder.setTargetState(TargetState.START);\n+    workflowConfigBuilder.setJobQueue(true);\n+    JobDag jobDag = new JobDag();\n+    jobDag.addNode(JOB_NAME);\n+    workflowConfigBuilder.setJobDag(jobDag);\n+    WorkflowConfig workflowConfig = workflowConfigBuilder.build();\n+\n+    return workflowConfig;\n+  }\n+\n+  private JobConfig prepareJobConfig() {\n+    JobConfig.Builder jobConfigBuilder = new JobConfig.Builder();\n+    jobConfigBuilder.setWorkflow(WORKFLOW_NAME);\n+    jobConfigBuilder.setCommand(\"TestCommand\");\n+    jobConfigBuilder.setTargetResource(TARGET_RESOURCES);\n+    jobConfigBuilder.setJobId(JOB_NAME);\n+    List<String> targetPartition = new ArrayList<>();\n+    targetPartition.add(TARGET_RESOURCES + \"_0\");\n+    jobConfigBuilder.setTargetPartitions(targetPartition);\n+    Set<String> targetPartitionStates = new HashSet<>();\n+    targetPartitionStates.add(\"MASTER\");\n+    List<TaskConfig> taskConfigs = new ArrayList<>();\n+    TaskConfig.Builder taskConfigBuilder = new TaskConfig.Builder();\n+    taskConfigBuilder.setTaskId(\"0\");\n+    taskConfigs.add(taskConfigBuilder.build());\n+    jobConfigBuilder.setTargetPartitionStates(targetPartitionStates);\n+    jobConfigBuilder.addTaskConfigs(taskConfigs);\n+    JobConfig jobConfig = jobConfigBuilder.build();\n+    return jobConfig;\n+  }\n+\n+  private WorkflowContext prepareWorkflowContext() {\n+    ZNRecord record = new ZNRecord(WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.StartTime.name(), \"0\");\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.NAME.name(), WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.STATE.name(),\n+        TaskState.IN_PROGRESS.name());\n+    Map<String, String> jobState = new HashMap<>();\n+    jobState.put(JOB_NAME, TaskState.IN_PROGRESS.name());\n+    record.setMapField(WorkflowContext.WorkflowContextProperties.JOB_STATES.name(), jobState);\n+    return new WorkflowContext(record);\n+  }\n+\n+  private JobContext prepareJobContext(String instance) {\n+    Set<Integer> _taskPartitionSet;\n+    Map<Integer, TaskPartitionState> _taskPartitionStateMap;\n+    Map<Integer, String> _partitionToTaskIDMap;\n+    Map<Integer, String> _taskToInstanceMap;\n+    _taskPartitionSet = new HashSet<>();\n+    _taskPartitionStateMap = new HashMap<>();\n+    _partitionToTaskIDMap = new HashMap<>();\n+    _taskToInstanceMap = new HashMap<>();\n+\n+    _taskPartitionSet.add(0);\n+    _taskPartitionStateMap.put(0, TaskPartitionState.RUNNING);\n+    _partitionToTaskIDMap.put(0, \"0\");\n+    String someInstance = INSTANCE_PREFIX + 0;\n+    _taskToInstanceMap.put(0, someInstance);\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    JobContext jobContext = new JobContext(record);\n+    jobContext.setStartTime(0L);\n+    jobContext.setName(JOB_NAME);\n+    jobContext.setStartTime(0L);\n+    jobContext.setPartitionState(0, TaskPartitionState.RUNNING);\n+    jobContext.setPartitionTarget(0, instance);\n+    jobContext.setPartitionTarget(0, TARGET_RESOURCES + \"_0\");\n+    return jobContext;\n+  }\n+\n+  private Map<String, IdealState> prepareIdealStates(String instance1, String instance2,\n+      String instance3) {\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    record.setSimpleField(IdealState.IdealStateProperty.NUM_PARTITIONS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.EXTERNAL_VIEW_DISABLED.name(), \"true\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"TASK\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"Task\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_FACTORY_NAME.name(), \"DEFAULT\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.task.JobRebalancer\");\n+    record.setMapField(JOB_NAME + \"_\" + PARTITION_NAME, new HashMap<>());\n+    record.setListField(JOB_NAME + \"_\" + PARTITION_NAME, new ArrayList<>());\n+    Map<String, IdealState> idealStates = new HashMap<>();\n+    idealStates.put(JOB_NAME, new IdealState(record));\n+\n+    ZNRecord recordDB = new ZNRecord(TARGET_RESOURCES);\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"3\");\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"FULL_AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO_REBALANCE\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"MasterSlave\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(),\n+        \"org.apache.helix.controller.rebalancer.strategy.CrushEdRebalanceStrategy\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.controller.rebalancer.DelayedAutoRebalancer\");\n+    Map<String, String> mapping = new HashMap<>();\n+    mapping.put(instance1, \"MASTER\");\n+    mapping.put(instance2, \"SLAVE\");\n+    mapping.put(instance3, \"SLAVE\");\n+    recordDB.setMapField(TARGET_RESOURCES + \"_0\", mapping);\n+    List<String> listField = new ArrayList<>();\n+    listField.add(instance1);\n+    listField.add(instance2);\n+    listField.add(instance3);\n+    recordDB.setListField(TARGET_RESOURCES + \"_0\", listField);\n+    idealStates.put(TARGET_RESOURCES, new IdealState(recordDB));\n+\n+    return idealStates;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState(String masterInstance, String slaveInstance,\n+      String masterState, String slaveState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, slaveInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, slaveInstance, slaveState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, slaveInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState2(String masterInstance, String masterState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private ResourceAssignment preparePreviousAssignment(String instance, String state) {\n+    ResourceAssignment prevAssignment = new ResourceAssignment(JOB_NAME);\n+    Map<String, String> replicaMap = new HashMap<>();\n+    replicaMap.put(instance, state);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    prevAssignment.addReplicaMap(taskPartition, replicaMap);\n+    return prevAssignment;\n+  }\n+\n+  private class Mock {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67f15cfdcd77e2e585d641be8560c8bf10013790"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTI3OTkwMQ==", "bodyText": "Done.", "url": "https://github.com/apache/helix/pull/923#discussion_r401279901", "createdAt": "2020-03-31T23:51:47Z", "author": {"login": "alirezazamani"}, "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "diffHunk": "@@ -0,0 +1,348 @@\n+package org.apache.helix.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.helix.common.caches.TaskDataCache;\n+import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n+import org.apache.helix.controller.stages.BestPossibleStateOutput;\n+import org.apache.helix.controller.stages.CurrentStateOutput;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.InstanceConfig;\n+import org.apache.helix.model.LiveInstance;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestTargetedTaskStateChange {\n+  private static final String CLUSTER_NAME = \"TestCluster\";\n+  private static final String INSTANCE_PREFIX = \"Instance_\";\n+  private static final int NUM_PARTICIPANTS = 3;\n+  private static final String WORKFLOW_NAME = \"TestWorkflow\";\n+  private static final String JOB_NAME = \"TestJob\";\n+  private static final String PARTITION_NAME = \"0\";\n+  private static final String TARGET_RESOURCES = \"TestDB\";\n+  private static final int NUM_TASKS = 1;\n+  private Map<String, LiveInstance> _liveInstances;\n+  private Map<String, InstanceConfig> _instanceConfigs;\n+  private ClusterConfig _clusterConfig;\n+  private AssignableInstanceManager _assignableInstanceManager;\n+\n+  @BeforeClass\n+  public void beforeClass() {\n+    System.out.println(\n+        \"START \" + this.getClass().getSimpleName() + \" at \" + new Date(System.currentTimeMillis()));\n+    // Populate live instances and their corresponding instance configs\n+    _liveInstances = new HashMap<>();\n+    _instanceConfigs = new HashMap<>();\n+    _clusterConfig = new ClusterConfig(CLUSTER_NAME);\n+    for (int i = 0; i < NUM_PARTICIPANTS; i++) {\n+      String instanceName = INSTANCE_PREFIX + i;\n+      LiveInstance liveInstance = new LiveInstance(instanceName);\n+      InstanceConfig instanceConfig = new InstanceConfig(instanceName);\n+      _liveInstances.put(instanceName, liveInstance);\n+      _instanceConfigs.put(instanceName, instanceConfig);\n+    }\n+    _assignableInstanceManager = new AssignableInstanceManager();\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there are two current states for two\n+   * different instances.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Running\n+   * CurrentState: Instance0: Running, Instance1: Running\n+   * Expected paMap: Instance0 -> Dropped\n+   */\n+  @Test\n+  public void testTwoRunningCurrentStates() {\n+    Mock mock = new Mock();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(true);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.DROPPED.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"0\"));\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there is one current state which is\n+   * different from\n+   * Previous Assignment information.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Dropped\n+   * CurrentState: Instance0: Running\n+   * Expected paMap: Instance1 -> Running\n+   */\n+  @Test\n+  public void testOneRunningOneNull() {\n+    Mock mock = new Mock();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment2);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(false);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput2, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.RUNNING.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"1\"));\n+  }\n+\n+  private WorkflowConfig prepareWorkflowConfig() {\n+    WorkflowConfig.Builder workflowConfigBuilder = new WorkflowConfig.Builder();\n+    workflowConfigBuilder.setWorkflowId(WORKFLOW_NAME);\n+    workflowConfigBuilder.setTerminable(false);\n+    workflowConfigBuilder.setTargetState(TargetState.START);\n+    workflowConfigBuilder.setJobQueue(true);\n+    JobDag jobDag = new JobDag();\n+    jobDag.addNode(JOB_NAME);\n+    workflowConfigBuilder.setJobDag(jobDag);\n+    WorkflowConfig workflowConfig = workflowConfigBuilder.build();\n+\n+    return workflowConfig;\n+  }\n+\n+  private JobConfig prepareJobConfig() {\n+    JobConfig.Builder jobConfigBuilder = new JobConfig.Builder();\n+    jobConfigBuilder.setWorkflow(WORKFLOW_NAME);\n+    jobConfigBuilder.setCommand(\"TestCommand\");\n+    jobConfigBuilder.setTargetResource(TARGET_RESOURCES);\n+    jobConfigBuilder.setJobId(JOB_NAME);\n+    List<String> targetPartition = new ArrayList<>();\n+    targetPartition.add(TARGET_RESOURCES + \"_0\");\n+    jobConfigBuilder.setTargetPartitions(targetPartition);\n+    Set<String> targetPartitionStates = new HashSet<>();\n+    targetPartitionStates.add(\"MASTER\");\n+    List<TaskConfig> taskConfigs = new ArrayList<>();\n+    TaskConfig.Builder taskConfigBuilder = new TaskConfig.Builder();\n+    taskConfigBuilder.setTaskId(\"0\");\n+    taskConfigs.add(taskConfigBuilder.build());\n+    jobConfigBuilder.setTargetPartitionStates(targetPartitionStates);\n+    jobConfigBuilder.addTaskConfigs(taskConfigs);\n+    JobConfig jobConfig = jobConfigBuilder.build();\n+    return jobConfig;\n+  }\n+\n+  private WorkflowContext prepareWorkflowContext() {\n+    ZNRecord record = new ZNRecord(WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.StartTime.name(), \"0\");\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.NAME.name(), WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.STATE.name(),\n+        TaskState.IN_PROGRESS.name());\n+    Map<String, String> jobState = new HashMap<>();\n+    jobState.put(JOB_NAME, TaskState.IN_PROGRESS.name());\n+    record.setMapField(WorkflowContext.WorkflowContextProperties.JOB_STATES.name(), jobState);\n+    return new WorkflowContext(record);\n+  }\n+\n+  private JobContext prepareJobContext(String instance) {\n+    Set<Integer> _taskPartitionSet;\n+    Map<Integer, TaskPartitionState> _taskPartitionStateMap;\n+    Map<Integer, String> _partitionToTaskIDMap;\n+    Map<Integer, String> _taskToInstanceMap;\n+    _taskPartitionSet = new HashSet<>();\n+    _taskPartitionStateMap = new HashMap<>();\n+    _partitionToTaskIDMap = new HashMap<>();\n+    _taskToInstanceMap = new HashMap<>();\n+\n+    _taskPartitionSet.add(0);\n+    _taskPartitionStateMap.put(0, TaskPartitionState.RUNNING);\n+    _partitionToTaskIDMap.put(0, \"0\");\n+    String someInstance = INSTANCE_PREFIX + 0;\n+    _taskToInstanceMap.put(0, someInstance);\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    JobContext jobContext = new JobContext(record);\n+    jobContext.setStartTime(0L);\n+    jobContext.setName(JOB_NAME);\n+    jobContext.setStartTime(0L);\n+    jobContext.setPartitionState(0, TaskPartitionState.RUNNING);\n+    jobContext.setPartitionTarget(0, instance);\n+    jobContext.setPartitionTarget(0, TARGET_RESOURCES + \"_0\");\n+    return jobContext;\n+  }\n+\n+  private Map<String, IdealState> prepareIdealStates(String instance1, String instance2,\n+      String instance3) {\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    record.setSimpleField(IdealState.IdealStateProperty.NUM_PARTITIONS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.EXTERNAL_VIEW_DISABLED.name(), \"true\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"TASK\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"Task\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_FACTORY_NAME.name(), \"DEFAULT\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.task.JobRebalancer\");\n+    record.setMapField(JOB_NAME + \"_\" + PARTITION_NAME, new HashMap<>());\n+    record.setListField(JOB_NAME + \"_\" + PARTITION_NAME, new ArrayList<>());\n+    Map<String, IdealState> idealStates = new HashMap<>();\n+    idealStates.put(JOB_NAME, new IdealState(record));\n+\n+    ZNRecord recordDB = new ZNRecord(TARGET_RESOURCES);\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"3\");\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"FULL_AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO_REBALANCE\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"MasterSlave\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(),\n+        \"org.apache.helix.controller.rebalancer.strategy.CrushEdRebalanceStrategy\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.controller.rebalancer.DelayedAutoRebalancer\");\n+    Map<String, String> mapping = new HashMap<>();\n+    mapping.put(instance1, \"MASTER\");\n+    mapping.put(instance2, \"SLAVE\");\n+    mapping.put(instance3, \"SLAVE\");\n+    recordDB.setMapField(TARGET_RESOURCES + \"_0\", mapping);\n+    List<String> listField = new ArrayList<>();\n+    listField.add(instance1);\n+    listField.add(instance2);\n+    listField.add(instance3);\n+    recordDB.setListField(TARGET_RESOURCES + \"_0\", listField);\n+    idealStates.put(TARGET_RESOURCES, new IdealState(recordDB));\n+\n+    return idealStates;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState(String masterInstance, String slaveInstance,\n+      String masterState, String slaveState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, slaveInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, slaveInstance, slaveState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, slaveInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState2(String masterInstance, String masterState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private ResourceAssignment preparePreviousAssignment(String instance, String state) {\n+    ResourceAssignment prevAssignment = new ResourceAssignment(JOB_NAME);\n+    Map<String, String> replicaMap = new HashMap<>();\n+    replicaMap.put(instance, state);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    prevAssignment.addReplicaMap(taskPartition, replicaMap);\n+    return prevAssignment;\n+  }\n+\n+  private class Mock {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTEzNjc1OQ=="}, "originalCommit": {"oid": "67f15cfdcd77e2e585d641be8560c8bf10013790"}, "originalPosition": 322}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mjk0MDEwOnYy", "diffSide": "RIGHT", "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskSchedulingTwoCurrentStates.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzo0NjoyN1rOF_WiWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjowNTozNFrOF_Y02Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3Mzg0OA==", "bodyText": "\"private static final String\" for constants? Or just use DEFAULT_TGT_DB directly.", "url": "https://github.com/apache/helix/pull/923#discussion_r401973848", "createdAt": "2020-04-01T23:46:27Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskSchedulingTwoCurrentStates.java", "diffHunk": "@@ -0,0 +1,219 @@\n+package org.apache.helix.integration.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import com.google.common.collect.Sets;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.HelixDataAccessor;\n+import org.apache.helix.HelixManagerFactory;\n+import org.apache.helix.InstanceType;\n+import org.apache.helix.PropertyKey;\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.ZkTestHelper;\n+import org.apache.helix.integration.manager.MockParticipantManager;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.CurrentState;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.MasterSlaveSMD;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.participant.StateMachineEngine;\n+import org.apache.helix.task.JobConfig;\n+import org.apache.helix.task.JobContext;\n+import org.apache.helix.task.JobQueue;\n+import org.apache.helix.task.TaskCallbackContext;\n+import org.apache.helix.task.TaskDriver;\n+import org.apache.helix.task.TaskFactory;\n+import org.apache.helix.task.TaskPartitionState;\n+import org.apache.helix.task.TaskState;\n+import org.apache.helix.task.TaskStateModelFactory;\n+import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.apache.helix.zookeeper.impl.client.ZkClient;\n+import org.apache.zookeeper.data.Stat;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Test to check if targeted tasks correctly get assigned and also if cancel messages are not being\n+ * sent when there are two CurrentStates.\n+ */\n+public class TestTaskSchedulingTwoCurrentStates extends TaskTestBase {\n+  private final String DATABASE = WorkflowGenerator.DEFAULT_TGT_DB;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAxMTM1Mw==", "bodyText": "Done.", "url": "https://github.com/apache/helix/pull/923#discussion_r402011353", "createdAt": "2020-04-02T02:05:34Z", "author": {"login": "alirezazamani"}, "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskSchedulingTwoCurrentStates.java", "diffHunk": "@@ -0,0 +1,219 @@\n+package org.apache.helix.integration.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import com.google.common.collect.Sets;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.HelixDataAccessor;\n+import org.apache.helix.HelixManagerFactory;\n+import org.apache.helix.InstanceType;\n+import org.apache.helix.PropertyKey;\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.ZkTestHelper;\n+import org.apache.helix.integration.manager.MockParticipantManager;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.CurrentState;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.MasterSlaveSMD;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.participant.StateMachineEngine;\n+import org.apache.helix.task.JobConfig;\n+import org.apache.helix.task.JobContext;\n+import org.apache.helix.task.JobQueue;\n+import org.apache.helix.task.TaskCallbackContext;\n+import org.apache.helix.task.TaskDriver;\n+import org.apache.helix.task.TaskFactory;\n+import org.apache.helix.task.TaskPartitionState;\n+import org.apache.helix.task.TaskState;\n+import org.apache.helix.task.TaskStateModelFactory;\n+import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.apache.helix.zookeeper.impl.client.ZkClient;\n+import org.apache.zookeeper.data.Stat;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Test to check if targeted tasks correctly get assigned and also if cancel messages are not being\n+ * sent when there are two CurrentStates.\n+ */\n+public class TestTaskSchedulingTwoCurrentStates extends TaskTestBase {\n+  private final String DATABASE = WorkflowGenerator.DEFAULT_TGT_DB;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3Mzg0OA=="}, "originalCommit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mjk0MjA2OnYy", "diffSide": "RIGHT", "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskSchedulingTwoCurrentStates.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzo0NzozMlrOF_Wjgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjowNTo0MFrOF_Y09Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3NDE0Ng==", "bodyText": "Possible to merge these two loops?", "url": "https://github.com/apache/helix/pull/923#discussion_r401974146", "createdAt": "2020-04-01T23:47:32Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskSchedulingTwoCurrentStates.java", "diffHunk": "@@ -0,0 +1,219 @@\n+package org.apache.helix.integration.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import com.google.common.collect.Sets;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.HelixDataAccessor;\n+import org.apache.helix.HelixManagerFactory;\n+import org.apache.helix.InstanceType;\n+import org.apache.helix.PropertyKey;\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.ZkTestHelper;\n+import org.apache.helix.integration.manager.MockParticipantManager;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.CurrentState;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.MasterSlaveSMD;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.participant.StateMachineEngine;\n+import org.apache.helix.task.JobConfig;\n+import org.apache.helix.task.JobContext;\n+import org.apache.helix.task.JobQueue;\n+import org.apache.helix.task.TaskCallbackContext;\n+import org.apache.helix.task.TaskDriver;\n+import org.apache.helix.task.TaskFactory;\n+import org.apache.helix.task.TaskPartitionState;\n+import org.apache.helix.task.TaskState;\n+import org.apache.helix.task.TaskStateModelFactory;\n+import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.apache.helix.zookeeper.impl.client.ZkClient;\n+import org.apache.zookeeper.data.Stat;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Test to check if targeted tasks correctly get assigned and also if cancel messages are not being\n+ * sent when there are two CurrentStates.\n+ */\n+public class TestTaskSchedulingTwoCurrentStates extends TaskTestBase {\n+  private final String DATABASE = WorkflowGenerator.DEFAULT_TGT_DB;\n+  protected HelixDataAccessor _accessor;\n+  private PropertyKey.Builder _keyBuilder;\n+  private static final AtomicInteger CANCEL_COUNT = new AtomicInteger(0);\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception {\n+    _numPartitions = 1;\n+    _numNodes = 3;\n+    super.beforeClass();\n+    _manager = HelixManagerFactory.getZKHelixManager(CLUSTER_NAME, \"Admin\",\n+        InstanceType.ADMINISTRATOR, ZK_ADDR);\n+\n+    // Stop participants that have been started in super class\n+    for (int i = 0; i < _numNodes; i++) {\n+      super.stopParticipant(i);\n+    }\n+\n+    // Check that participants are actually stopped\n+    for (int i = 0; i < _numNodes; i++) {\n+      Assert.assertFalse(_participants[i].isConnected());\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAxMTM4MQ==", "bodyText": "Done.", "url": "https://github.com/apache/helix/pull/923#discussion_r402011381", "createdAt": "2020-04-02T02:05:40Z", "author": {"login": "alirezazamani"}, "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskSchedulingTwoCurrentStates.java", "diffHunk": "@@ -0,0 +1,219 @@\n+package org.apache.helix.integration.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import com.google.common.collect.Sets;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.HelixDataAccessor;\n+import org.apache.helix.HelixManagerFactory;\n+import org.apache.helix.InstanceType;\n+import org.apache.helix.PropertyKey;\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.ZkTestHelper;\n+import org.apache.helix.integration.manager.MockParticipantManager;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.CurrentState;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.MasterSlaveSMD;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.participant.StateMachineEngine;\n+import org.apache.helix.task.JobConfig;\n+import org.apache.helix.task.JobContext;\n+import org.apache.helix.task.JobQueue;\n+import org.apache.helix.task.TaskCallbackContext;\n+import org.apache.helix.task.TaskDriver;\n+import org.apache.helix.task.TaskFactory;\n+import org.apache.helix.task.TaskPartitionState;\n+import org.apache.helix.task.TaskState;\n+import org.apache.helix.task.TaskStateModelFactory;\n+import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.apache.helix.zookeeper.impl.client.ZkClient;\n+import org.apache.zookeeper.data.Stat;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Test to check if targeted tasks correctly get assigned and also if cancel messages are not being\n+ * sent when there are two CurrentStates.\n+ */\n+public class TestTaskSchedulingTwoCurrentStates extends TaskTestBase {\n+  private final String DATABASE = WorkflowGenerator.DEFAULT_TGT_DB;\n+  protected HelixDataAccessor _accessor;\n+  private PropertyKey.Builder _keyBuilder;\n+  private static final AtomicInteger CANCEL_COUNT = new AtomicInteger(0);\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception {\n+    _numPartitions = 1;\n+    _numNodes = 3;\n+    super.beforeClass();\n+    _manager = HelixManagerFactory.getZKHelixManager(CLUSTER_NAME, \"Admin\",\n+        InstanceType.ADMINISTRATOR, ZK_ADDR);\n+\n+    // Stop participants that have been started in super class\n+    for (int i = 0; i < _numNodes; i++) {\n+      super.stopParticipant(i);\n+    }\n+\n+    // Check that participants are actually stopped\n+    for (int i = 0; i < _numNodes; i++) {\n+      Assert.assertFalse(_participants[i].isConnected());\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3NDE0Ng=="}, "originalCommit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5Mjk0NTk5OnYy", "diffSide": "RIGHT", "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQyMzo0OToyM1rOF_Wl2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjowNjowMlrOF_Y1Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3NDc0Nw==", "bodyText": "Why do these local variables have underscores?", "url": "https://github.com/apache/helix/pull/923#discussion_r401974747", "createdAt": "2020-04-01T23:49:23Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "diffHunk": "@@ -0,0 +1,348 @@\n+package org.apache.helix.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.helix.common.caches.TaskDataCache;\n+import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n+import org.apache.helix.controller.stages.BestPossibleStateOutput;\n+import org.apache.helix.controller.stages.CurrentStateOutput;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.InstanceConfig;\n+import org.apache.helix.model.LiveInstance;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestTargetedTaskStateChange {\n+  private static final String CLUSTER_NAME = \"TestCluster\";\n+  private static final String INSTANCE_PREFIX = \"Instance_\";\n+  private static final int NUM_PARTICIPANTS = 3;\n+  private static final String WORKFLOW_NAME = \"TestWorkflow\";\n+  private static final String JOB_NAME = \"TestJob\";\n+  private static final String PARTITION_NAME = \"0\";\n+  private static final String TARGET_RESOURCES = \"TestDB\";\n+  private static final int NUM_TASKS = 1;\n+  private Map<String, LiveInstance> _liveInstances;\n+  private Map<String, InstanceConfig> _instanceConfigs;\n+  private ClusterConfig _clusterConfig;\n+  private AssignableInstanceManager _assignableInstanceManager;\n+\n+  @BeforeClass\n+  public void beforeClass() {\n+    System.out.println(\n+        \"START \" + this.getClass().getSimpleName() + \" at \" + new Date(System.currentTimeMillis()));\n+    // Populate live instances and their corresponding instance configs\n+    _liveInstances = new HashMap<>();\n+    _instanceConfigs = new HashMap<>();\n+    _clusterConfig = new ClusterConfig(CLUSTER_NAME);\n+    for (int i = 0; i < NUM_PARTICIPANTS; i++) {\n+      String instanceName = INSTANCE_PREFIX + i;\n+      LiveInstance liveInstance = new LiveInstance(instanceName);\n+      InstanceConfig instanceConfig = new InstanceConfig(instanceName);\n+      _liveInstances.put(instanceName, liveInstance);\n+      _instanceConfigs.put(instanceName, instanceConfig);\n+    }\n+    _assignableInstanceManager = new AssignableInstanceManager();\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there are two current states for two\n+   * different instances.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Running\n+   * CurrentState: Instance0: Running, Instance1: Running\n+   * Expected paMap: Instance0 -> Dropped\n+   */\n+  @Test\n+  public void testTwoRunningCurrentStates() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(true);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.DROPPED.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"0\"));\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there is one current state which is\n+   * different from\n+   * Previous Assignment information.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Dropped\n+   * CurrentState: Instance0: Running\n+   * Expected paMap: Instance1 -> Running\n+   */\n+  @Test\n+  public void testOneRunningOneNull() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment2);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(false);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput2, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.RUNNING.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"1\"));\n+  }\n+\n+  private WorkflowConfig prepareWorkflowConfig() {\n+    WorkflowConfig.Builder workflowConfigBuilder = new WorkflowConfig.Builder();\n+    workflowConfigBuilder.setWorkflowId(WORKFLOW_NAME);\n+    workflowConfigBuilder.setTerminable(false);\n+    workflowConfigBuilder.setTargetState(TargetState.START);\n+    workflowConfigBuilder.setJobQueue(true);\n+    JobDag jobDag = new JobDag();\n+    jobDag.addNode(JOB_NAME);\n+    workflowConfigBuilder.setJobDag(jobDag);\n+    WorkflowConfig workflowConfig = workflowConfigBuilder.build();\n+\n+    return workflowConfig;\n+  }\n+\n+  private JobConfig prepareJobConfig() {\n+    JobConfig.Builder jobConfigBuilder = new JobConfig.Builder();\n+    jobConfigBuilder.setWorkflow(WORKFLOW_NAME);\n+    jobConfigBuilder.setCommand(\"TestCommand\");\n+    jobConfigBuilder.setTargetResource(TARGET_RESOURCES);\n+    jobConfigBuilder.setJobId(JOB_NAME);\n+    List<String> targetPartition = new ArrayList<>();\n+    targetPartition.add(TARGET_RESOURCES + \"_0\");\n+    jobConfigBuilder.setTargetPartitions(targetPartition);\n+    Set<String> targetPartitionStates = new HashSet<>();\n+    targetPartitionStates.add(\"MASTER\");\n+    List<TaskConfig> taskConfigs = new ArrayList<>();\n+    TaskConfig.Builder taskConfigBuilder = new TaskConfig.Builder();\n+    taskConfigBuilder.setTaskId(\"0\");\n+    taskConfigs.add(taskConfigBuilder.build());\n+    jobConfigBuilder.setTargetPartitionStates(targetPartitionStates);\n+    jobConfigBuilder.addTaskConfigs(taskConfigs);\n+    JobConfig jobConfig = jobConfigBuilder.build();\n+    return jobConfig;\n+  }\n+\n+  private WorkflowContext prepareWorkflowContext() {\n+    ZNRecord record = new ZNRecord(WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.StartTime.name(), \"0\");\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.NAME.name(), WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.STATE.name(),\n+        TaskState.IN_PROGRESS.name());\n+    Map<String, String> jobState = new HashMap<>();\n+    jobState.put(JOB_NAME, TaskState.IN_PROGRESS.name());\n+    record.setMapField(WorkflowContext.WorkflowContextProperties.JOB_STATES.name(), jobState);\n+    return new WorkflowContext(record);\n+  }\n+\n+  private JobContext prepareJobContext(String instance) {\n+    Set<Integer> _taskPartitionSet;\n+    Map<Integer, TaskPartitionState> _taskPartitionStateMap;\n+    Map<Integer, String> _partitionToTaskIDMap;\n+    Map<Integer, String> _taskToInstanceMap;\n+    _taskPartitionSet = new HashSet<>();\n+    _taskPartitionStateMap = new HashMap<>();\n+    _partitionToTaskIDMap = new HashMap<>();\n+    _taskToInstanceMap = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAxMTQ2Mw==", "bodyText": "I removed them. Realized we do not need them.", "url": "https://github.com/apache/helix/pull/923#discussion_r402011463", "createdAt": "2020-04-02T02:06:02Z", "author": {"login": "alirezazamani"}, "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "diffHunk": "@@ -0,0 +1,348 @@\n+package org.apache.helix.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.helix.common.caches.TaskDataCache;\n+import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n+import org.apache.helix.controller.stages.BestPossibleStateOutput;\n+import org.apache.helix.controller.stages.CurrentStateOutput;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.InstanceConfig;\n+import org.apache.helix.model.LiveInstance;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestTargetedTaskStateChange {\n+  private static final String CLUSTER_NAME = \"TestCluster\";\n+  private static final String INSTANCE_PREFIX = \"Instance_\";\n+  private static final int NUM_PARTICIPANTS = 3;\n+  private static final String WORKFLOW_NAME = \"TestWorkflow\";\n+  private static final String JOB_NAME = \"TestJob\";\n+  private static final String PARTITION_NAME = \"0\";\n+  private static final String TARGET_RESOURCES = \"TestDB\";\n+  private static final int NUM_TASKS = 1;\n+  private Map<String, LiveInstance> _liveInstances;\n+  private Map<String, InstanceConfig> _instanceConfigs;\n+  private ClusterConfig _clusterConfig;\n+  private AssignableInstanceManager _assignableInstanceManager;\n+\n+  @BeforeClass\n+  public void beforeClass() {\n+    System.out.println(\n+        \"START \" + this.getClass().getSimpleName() + \" at \" + new Date(System.currentTimeMillis()));\n+    // Populate live instances and their corresponding instance configs\n+    _liveInstances = new HashMap<>();\n+    _instanceConfigs = new HashMap<>();\n+    _clusterConfig = new ClusterConfig(CLUSTER_NAME);\n+    for (int i = 0; i < NUM_PARTICIPANTS; i++) {\n+      String instanceName = INSTANCE_PREFIX + i;\n+      LiveInstance liveInstance = new LiveInstance(instanceName);\n+      InstanceConfig instanceConfig = new InstanceConfig(instanceName);\n+      _liveInstances.put(instanceName, liveInstance);\n+      _instanceConfigs.put(instanceName, instanceConfig);\n+    }\n+    _assignableInstanceManager = new AssignableInstanceManager();\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there are two current states for two\n+   * different instances.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Running\n+   * CurrentState: Instance0: Running, Instance1: Running\n+   * Expected paMap: Instance0 -> Dropped\n+   */\n+  @Test\n+  public void testTwoRunningCurrentStates() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(true);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.DROPPED.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"0\"));\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there is one current state which is\n+   * different from\n+   * Previous Assignment information.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Dropped\n+   * CurrentState: Instance0: Running\n+   * Expected paMap: Instance1 -> Running\n+   */\n+  @Test\n+  public void testOneRunningOneNull() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment2);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(false);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput2, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.RUNNING.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"1\"));\n+  }\n+\n+  private WorkflowConfig prepareWorkflowConfig() {\n+    WorkflowConfig.Builder workflowConfigBuilder = new WorkflowConfig.Builder();\n+    workflowConfigBuilder.setWorkflowId(WORKFLOW_NAME);\n+    workflowConfigBuilder.setTerminable(false);\n+    workflowConfigBuilder.setTargetState(TargetState.START);\n+    workflowConfigBuilder.setJobQueue(true);\n+    JobDag jobDag = new JobDag();\n+    jobDag.addNode(JOB_NAME);\n+    workflowConfigBuilder.setJobDag(jobDag);\n+    WorkflowConfig workflowConfig = workflowConfigBuilder.build();\n+\n+    return workflowConfig;\n+  }\n+\n+  private JobConfig prepareJobConfig() {\n+    JobConfig.Builder jobConfigBuilder = new JobConfig.Builder();\n+    jobConfigBuilder.setWorkflow(WORKFLOW_NAME);\n+    jobConfigBuilder.setCommand(\"TestCommand\");\n+    jobConfigBuilder.setTargetResource(TARGET_RESOURCES);\n+    jobConfigBuilder.setJobId(JOB_NAME);\n+    List<String> targetPartition = new ArrayList<>();\n+    targetPartition.add(TARGET_RESOURCES + \"_0\");\n+    jobConfigBuilder.setTargetPartitions(targetPartition);\n+    Set<String> targetPartitionStates = new HashSet<>();\n+    targetPartitionStates.add(\"MASTER\");\n+    List<TaskConfig> taskConfigs = new ArrayList<>();\n+    TaskConfig.Builder taskConfigBuilder = new TaskConfig.Builder();\n+    taskConfigBuilder.setTaskId(\"0\");\n+    taskConfigs.add(taskConfigBuilder.build());\n+    jobConfigBuilder.setTargetPartitionStates(targetPartitionStates);\n+    jobConfigBuilder.addTaskConfigs(taskConfigs);\n+    JobConfig jobConfig = jobConfigBuilder.build();\n+    return jobConfig;\n+  }\n+\n+  private WorkflowContext prepareWorkflowContext() {\n+    ZNRecord record = new ZNRecord(WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.StartTime.name(), \"0\");\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.NAME.name(), WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.STATE.name(),\n+        TaskState.IN_PROGRESS.name());\n+    Map<String, String> jobState = new HashMap<>();\n+    jobState.put(JOB_NAME, TaskState.IN_PROGRESS.name());\n+    record.setMapField(WorkflowContext.WorkflowContextProperties.JOB_STATES.name(), jobState);\n+    return new WorkflowContext(record);\n+  }\n+\n+  private JobContext prepareJobContext(String instance) {\n+    Set<Integer> _taskPartitionSet;\n+    Map<Integer, TaskPartitionState> _taskPartitionStateMap;\n+    Map<Integer, String> _partitionToTaskIDMap;\n+    Map<Integer, String> _taskToInstanceMap;\n+    _taskPartitionSet = new HashSet<>();\n+    _taskPartitionStateMap = new HashMap<>();\n+    _partitionToTaskIDMap = new HashMap<>();\n+    _taskToInstanceMap = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk3NDc0Nw=="}, "originalCommit": {"oid": "82584289cf6bae1d5c0195f79bbe2c4f910c08bf"}, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzE4MDgwOnYy", "diffSide": "RIGHT", "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMTo1OTowMVrOF_Yu1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjoyMTo1NFrOF_ZE0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAwOTgxMw==", "bodyText": "Let's be consistent with underscores here as well? some have them, others don't.", "url": "https://github.com/apache/helix/pull/923#discussion_r402009813", "createdAt": "2020-04-02T01:59:01Z", "author": {"login": "narendly"}, "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "diffHunk": "@@ -0,0 +1,330 @@\n+package org.apache.helix.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.helix.common.caches.TaskDataCache;\n+import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n+import org.apache.helix.controller.stages.BestPossibleStateOutput;\n+import org.apache.helix.controller.stages.CurrentStateOutput;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.InstanceConfig;\n+import org.apache.helix.model.LiveInstance;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestTargetedTaskStateChange {\n+  private static final String CLUSTER_NAME = \"TestCluster\";\n+  private static final String INSTANCE_PREFIX = \"Instance_\";\n+  private static final int NUM_PARTICIPANTS = 3;\n+  private static final String WORKFLOW_NAME = \"TestWorkflow\";\n+  private static final String JOB_NAME = \"TestJob\";\n+  private static final String PARTITION_NAME = \"0\";\n+  private static final String TARGET_RESOURCES = \"TestDB\";\n+  private static final int NUM_TASKS = 1;\n+  private Map<String, LiveInstance> _liveInstances;\n+  private Map<String, InstanceConfig> _instanceConfigs;\n+  private ClusterConfig _clusterConfig;\n+  private AssignableInstanceManager _assignableInstanceManager;\n+\n+  @BeforeClass\n+  public void beforeClass() {\n+    // Populate live instances and their corresponding instance configs\n+    _liveInstances = new HashMap<>();\n+    _instanceConfigs = new HashMap<>();\n+    _clusterConfig = new ClusterConfig(CLUSTER_NAME);\n+    for (int i = 0; i < NUM_PARTICIPANTS; i++) {\n+      String instanceName = INSTANCE_PREFIX + i;\n+      LiveInstance liveInstance = new LiveInstance(instanceName);\n+      InstanceConfig instanceConfig = new InstanceConfig(instanceName);\n+      _liveInstances.put(instanceName, liveInstance);\n+      _instanceConfigs.put(instanceName, instanceConfig);\n+    }\n+    _assignableInstanceManager = new AssignableInstanceManager();\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there are two current states for two\n+   * different instances.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Running\n+   * CurrentState: Instance0: Running, Instance1: Running\n+   * Expected paMap: Instance0 -> Dropped\n+   */\n+  @Test\n+  public void testTwoRunningCurrentStates() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(true);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.DROPPED.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"0\"));\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there is one current state which is\n+   * different from\n+   * Previous Assignment information.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Dropped\n+   * CurrentState: Instance0: Running\n+   * Expected paMap: Instance1 -> Running\n+   */\n+  @Test\n+  public void testOneRunningOneNull() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment2);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(false);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput2, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.RUNNING.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"1\"));\n+  }\n+\n+  private WorkflowConfig prepareWorkflowConfig() {\n+    WorkflowConfig.Builder workflowConfigBuilder = new WorkflowConfig.Builder();\n+    workflowConfigBuilder.setWorkflowId(WORKFLOW_NAME);\n+    workflowConfigBuilder.setTerminable(false);\n+    workflowConfigBuilder.setTargetState(TargetState.START);\n+    workflowConfigBuilder.setJobQueue(true);\n+    JobDag jobDag = new JobDag();\n+    jobDag.addNode(JOB_NAME);\n+    workflowConfigBuilder.setJobDag(jobDag);\n+    return workflowConfigBuilder.build();\n+  }\n+\n+  private JobConfig prepareJobConfig() {\n+    JobConfig.Builder jobConfigBuilder = new JobConfig.Builder();\n+    jobConfigBuilder.setWorkflow(WORKFLOW_NAME);\n+    jobConfigBuilder.setCommand(\"TestCommand\");\n+    jobConfigBuilder.setTargetResource(TARGET_RESOURCES);\n+    jobConfigBuilder.setJobId(JOB_NAME);\n+    List<String> targetPartition = new ArrayList<>();\n+    targetPartition.add(TARGET_RESOURCES + \"_0\");\n+    jobConfigBuilder.setTargetPartitions(targetPartition);\n+    Set<String> targetPartitionStates = new HashSet<>();\n+    targetPartitionStates.add(\"MASTER\");\n+    List<TaskConfig> taskConfigs = new ArrayList<>();\n+    TaskConfig.Builder taskConfigBuilder = new TaskConfig.Builder();\n+    taskConfigBuilder.setTaskId(\"0\");\n+    taskConfigs.add(taskConfigBuilder.build());\n+    jobConfigBuilder.setTargetPartitionStates(targetPartitionStates);\n+    jobConfigBuilder.addTaskConfigs(taskConfigs);\n+    JobConfig jobConfig = jobConfigBuilder.build();\n+    return jobConfig;\n+  }\n+\n+  private WorkflowContext prepareWorkflowContext() {\n+    ZNRecord record = new ZNRecord(WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.StartTime.name(), \"0\");\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.NAME.name(), WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.STATE.name(),\n+        TaskState.IN_PROGRESS.name());\n+    Map<String, String> jobState = new HashMap<>();\n+    jobState.put(JOB_NAME, TaskState.IN_PROGRESS.name());\n+    record.setMapField(WorkflowContext.WorkflowContextProperties.JOB_STATES.name(), jobState);\n+    return new WorkflowContext(record);\n+  }\n+\n+  private JobContext prepareJobContext(String instance) {\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    JobContext jobContext = new JobContext(record);\n+    jobContext.setStartTime(0L);\n+    jobContext.setName(JOB_NAME);\n+    jobContext.setStartTime(0L);\n+    jobContext.setPartitionState(0, TaskPartitionState.RUNNING);\n+    jobContext.setPartitionTarget(0, instance);\n+    jobContext.setPartitionTarget(0, TARGET_RESOURCES + \"_0\");\n+    return jobContext;\n+  }\n+\n+  private Map<String, IdealState> prepareIdealStates(String instance1, String instance2,\n+      String instance3) {\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    record.setSimpleField(IdealState.IdealStateProperty.NUM_PARTITIONS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.EXTERNAL_VIEW_DISABLED.name(), \"true\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"TASK\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"Task\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_FACTORY_NAME.name(), \"DEFAULT\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.task.JobRebalancer\");\n+    record.setMapField(JOB_NAME + \"_\" + PARTITION_NAME, new HashMap<>());\n+    record.setListField(JOB_NAME + \"_\" + PARTITION_NAME, new ArrayList<>());\n+    Map<String, IdealState> idealStates = new HashMap<>();\n+    idealStates.put(JOB_NAME, new IdealState(record));\n+\n+    ZNRecord recordDB = new ZNRecord(TARGET_RESOURCES);\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"3\");\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"FULL_AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO_REBALANCE\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"MasterSlave\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(),\n+        \"org.apache.helix.controller.rebalancer.strategy.CrushEdRebalanceStrategy\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.controller.rebalancer.DelayedAutoRebalancer\");\n+    Map<String, String> mapping = new HashMap<>();\n+    mapping.put(instance1, \"MASTER\");\n+    mapping.put(instance2, \"SLAVE\");\n+    mapping.put(instance3, \"SLAVE\");\n+    recordDB.setMapField(TARGET_RESOURCES + \"_0\", mapping);\n+    List<String> listField = new ArrayList<>();\n+    listField.add(instance1);\n+    listField.add(instance2);\n+    listField.add(instance3);\n+    recordDB.setListField(TARGET_RESOURCES + \"_0\", listField);\n+    idealStates.put(TARGET_RESOURCES, new IdealState(recordDB));\n+\n+    return idealStates;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState(String masterInstance, String slaveInstance,\n+      String masterState, String slaveState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, slaveInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, slaveInstance, slaveState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, slaveInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState2(String masterInstance, String masterState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private ResourceAssignment preparePreviousAssignment(String instance, String state) {\n+    ResourceAssignment prevAssignment = new ResourceAssignment(JOB_NAME);\n+    Map<String, String> replicaMap = new HashMap<>();\n+    replicaMap.put(instance, state);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    prevAssignment.addReplicaMap(taskPartition, replicaMap);\n+    return prevAssignment;\n+  }\n+\n+  private class MockTestInformation {\n+    private String slaveInstance = INSTANCE_PREFIX + \"0\";\n+    private String masterInstance = INSTANCE_PREFIX + \"1\";\n+    private String slaveInstance2 = INSTANCE_PREFIX + \"2\";\n+    private WorkflowControllerDataProvider cache = mock(WorkflowControllerDataProvider.class);\n+    private WorkflowConfig _workflowConfig = prepareWorkflowConfig();\n+    private WorkflowContext _workflowContext = prepareWorkflowContext();\n+    private Map<String, IdealState> _idealStates =\n+        prepareIdealStates(masterInstance, slaveInstance, slaveInstance2);\n+    private JobConfig _jobConfig = prepareJobConfig();\n+    private JobContext _jobContext = prepareJobContext(slaveInstance);\n+    private BestPossibleStateOutput _bestPossibleStateOutput = mock(BestPossibleStateOutput.class);\n+    private CurrentStateOutput _currentStateOutput = prepareCurrentState(masterInstance,\n+        slaveInstance, TaskPartitionState.RUNNING.name(), TaskPartitionState.RUNNING.name());\n+    private CurrentStateOutput _currentStateOutput2 =\n+        prepareCurrentState2(masterInstance, TaskPartitionState.RUNNING.name());\n+    private ResourceAssignment _resourceAssignment =\n+        preparePreviousAssignment(slaveInstance, TaskPartitionState.RUNNING.name());\n+    private ResourceAssignment _resourceAssignment2 =\n+        preparePreviousAssignment(slaveInstance, TaskPartitionState.DROPPED.name());\n+    private TaskDataCache _taskDataCache = mock(TaskDataCache.class);\n+    private RuntimeJobDag _runtimeJobDag = mock(RuntimeJobDag.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bee6da006ae40c93fa8bcb6c5009ea2a5dc9bfc"}, "originalPosition": 325}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAxNTQ0Mg==", "bodyText": "Good point. Fixed.", "url": "https://github.com/apache/helix/pull/923#discussion_r402015442", "createdAt": "2020-04-02T02:21:54Z", "author": {"login": "alirezazamani"}, "path": "helix-core/src/test/java/org/apache/helix/task/TestTargetedTaskStateChange.java", "diffHunk": "@@ -0,0 +1,330 @@\n+package org.apache.helix.task;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.helix.common.caches.TaskDataCache;\n+import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n+import org.apache.helix.controller.stages.BestPossibleStateOutput;\n+import org.apache.helix.controller.stages.CurrentStateOutput;\n+import org.apache.helix.model.ClusterConfig;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.model.InstanceConfig;\n+import org.apache.helix.model.LiveInstance;\n+import org.apache.helix.model.Partition;\n+import org.apache.helix.model.ResourceAssignment;\n+import org.apache.helix.zookeeper.datamodel.ZNRecord;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestTargetedTaskStateChange {\n+  private static final String CLUSTER_NAME = \"TestCluster\";\n+  private static final String INSTANCE_PREFIX = \"Instance_\";\n+  private static final int NUM_PARTICIPANTS = 3;\n+  private static final String WORKFLOW_NAME = \"TestWorkflow\";\n+  private static final String JOB_NAME = \"TestJob\";\n+  private static final String PARTITION_NAME = \"0\";\n+  private static final String TARGET_RESOURCES = \"TestDB\";\n+  private static final int NUM_TASKS = 1;\n+  private Map<String, LiveInstance> _liveInstances;\n+  private Map<String, InstanceConfig> _instanceConfigs;\n+  private ClusterConfig _clusterConfig;\n+  private AssignableInstanceManager _assignableInstanceManager;\n+\n+  @BeforeClass\n+  public void beforeClass() {\n+    // Populate live instances and their corresponding instance configs\n+    _liveInstances = new HashMap<>();\n+    _instanceConfigs = new HashMap<>();\n+    _clusterConfig = new ClusterConfig(CLUSTER_NAME);\n+    for (int i = 0; i < NUM_PARTICIPANTS; i++) {\n+      String instanceName = INSTANCE_PREFIX + i;\n+      LiveInstance liveInstance = new LiveInstance(instanceName);\n+      InstanceConfig instanceConfig = new InstanceConfig(instanceName);\n+      _liveInstances.put(instanceName, liveInstance);\n+      _instanceConfigs.put(instanceName, instanceConfig);\n+    }\n+    _assignableInstanceManager = new AssignableInstanceManager();\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there are two current states for two\n+   * different instances.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Running\n+   * CurrentState: Instance0: Running, Instance1: Running\n+   * Expected paMap: Instance0 -> Dropped\n+   */\n+  @Test\n+  public void testTwoRunningCurrentStates() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(true);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.DROPPED.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"0\"));\n+  }\n+\n+  /**\n+   * This test checks the behaviour of the controller while there is one current state which is\n+   * different from\n+   * Previous Assignment information.\n+   * Scenario:\n+   * Instance0: Slave, Instance1: Master, Instance2: Slave\n+   * PreviousAssignment of Task: Instance0: Dropped\n+   * CurrentState: Instance0: Running\n+   * Expected paMap: Instance1 -> Running\n+   */\n+  @Test\n+  public void testOneRunningOneNull() {\n+    MockTestInformation mock = new MockTestInformation();\n+    when(mock.cache.getWorkflowConfig(WORKFLOW_NAME)).thenReturn(mock._workflowConfig);\n+    when(mock.cache.getJobConfig(JOB_NAME)).thenReturn(mock._jobConfig);\n+    when(mock.cache.getTaskDataCache()).thenReturn(mock._taskDataCache);\n+    when(mock.cache.getJobContext(JOB_NAME)).thenReturn(mock._jobContext);\n+    when(mock.cache.getIdealStates()).thenReturn(mock._idealStates);\n+    when(mock.cache.getEnabledLiveInstances()).thenReturn(_liveInstances.keySet());\n+    when(mock.cache.getInstanceConfigMap()).thenReturn(_instanceConfigs);\n+    when(mock.cache.getTaskDataCache().getPreviousAssignment(JOB_NAME))\n+        .thenReturn(mock._resourceAssignment2);\n+    when(mock.cache.getClusterConfig()).thenReturn(_clusterConfig);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME)).thenReturn(mock._runtimeJobDag);\n+    _assignableInstanceManager.buildAssignableInstances(_clusterConfig, mock._taskDataCache,\n+        _liveInstances, _instanceConfigs);\n+    when(mock.cache.getAssignableInstanceManager()).thenReturn(_assignableInstanceManager);\n+    when(mock.cache.getExistsLiveInstanceOrCurrentStateChange()).thenReturn(false);\n+    Set<String> inflightJobDag = new HashSet<>();\n+    inflightJobDag.add(JOB_NAME);\n+    when(mock._taskDataCache.getRuntimeJobDag(WORKFLOW_NAME).getInflightJobList())\n+        .thenReturn(inflightJobDag);\n+    BestPossibleStateOutput bestPossibleStateOutput = new BestPossibleStateOutput();\n+    WorkflowDispatcher workflowDispatcher = new WorkflowDispatcher();\n+    workflowDispatcher.updateCache(mock.cache);\n+    workflowDispatcher.updateWorkflowStatus(WORKFLOW_NAME, mock._workflowConfig,\n+        mock._workflowContext, mock._currentStateOutput2, bestPossibleStateOutput);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    Assert.assertEquals(TaskPartitionState.RUNNING.name(), bestPossibleStateOutput\n+        .getPartitionStateMap(JOB_NAME).getPartitionMap(taskPartition).get(INSTANCE_PREFIX + \"1\"));\n+  }\n+\n+  private WorkflowConfig prepareWorkflowConfig() {\n+    WorkflowConfig.Builder workflowConfigBuilder = new WorkflowConfig.Builder();\n+    workflowConfigBuilder.setWorkflowId(WORKFLOW_NAME);\n+    workflowConfigBuilder.setTerminable(false);\n+    workflowConfigBuilder.setTargetState(TargetState.START);\n+    workflowConfigBuilder.setJobQueue(true);\n+    JobDag jobDag = new JobDag();\n+    jobDag.addNode(JOB_NAME);\n+    workflowConfigBuilder.setJobDag(jobDag);\n+    return workflowConfigBuilder.build();\n+  }\n+\n+  private JobConfig prepareJobConfig() {\n+    JobConfig.Builder jobConfigBuilder = new JobConfig.Builder();\n+    jobConfigBuilder.setWorkflow(WORKFLOW_NAME);\n+    jobConfigBuilder.setCommand(\"TestCommand\");\n+    jobConfigBuilder.setTargetResource(TARGET_RESOURCES);\n+    jobConfigBuilder.setJobId(JOB_NAME);\n+    List<String> targetPartition = new ArrayList<>();\n+    targetPartition.add(TARGET_RESOURCES + \"_0\");\n+    jobConfigBuilder.setTargetPartitions(targetPartition);\n+    Set<String> targetPartitionStates = new HashSet<>();\n+    targetPartitionStates.add(\"MASTER\");\n+    List<TaskConfig> taskConfigs = new ArrayList<>();\n+    TaskConfig.Builder taskConfigBuilder = new TaskConfig.Builder();\n+    taskConfigBuilder.setTaskId(\"0\");\n+    taskConfigs.add(taskConfigBuilder.build());\n+    jobConfigBuilder.setTargetPartitionStates(targetPartitionStates);\n+    jobConfigBuilder.addTaskConfigs(taskConfigs);\n+    JobConfig jobConfig = jobConfigBuilder.build();\n+    return jobConfig;\n+  }\n+\n+  private WorkflowContext prepareWorkflowContext() {\n+    ZNRecord record = new ZNRecord(WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.StartTime.name(), \"0\");\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.NAME.name(), WORKFLOW_NAME);\n+    record.setSimpleField(WorkflowContext.WorkflowContextProperties.STATE.name(),\n+        TaskState.IN_PROGRESS.name());\n+    Map<String, String> jobState = new HashMap<>();\n+    jobState.put(JOB_NAME, TaskState.IN_PROGRESS.name());\n+    record.setMapField(WorkflowContext.WorkflowContextProperties.JOB_STATES.name(), jobState);\n+    return new WorkflowContext(record);\n+  }\n+\n+  private JobContext prepareJobContext(String instance) {\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    JobContext jobContext = new JobContext(record);\n+    jobContext.setStartTime(0L);\n+    jobContext.setName(JOB_NAME);\n+    jobContext.setStartTime(0L);\n+    jobContext.setPartitionState(0, TaskPartitionState.RUNNING);\n+    jobContext.setPartitionTarget(0, instance);\n+    jobContext.setPartitionTarget(0, TARGET_RESOURCES + \"_0\");\n+    return jobContext;\n+  }\n+\n+  private Map<String, IdealState> prepareIdealStates(String instance1, String instance2,\n+      String instance3) {\n+    ZNRecord record = new ZNRecord(JOB_NAME);\n+    record.setSimpleField(IdealState.IdealStateProperty.NUM_PARTITIONS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.EXTERNAL_VIEW_DISABLED.name(), \"true\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"TASK\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"1\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"Task\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_FACTORY_NAME.name(), \"DEFAULT\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.task.JobRebalancer\");\n+    record.setMapField(JOB_NAME + \"_\" + PARTITION_NAME, new HashMap<>());\n+    record.setListField(JOB_NAME + \"_\" + PARTITION_NAME, new ArrayList<>());\n+    Map<String, IdealState> idealStates = new HashMap<>();\n+    idealStates.put(JOB_NAME, new IdealState(record));\n+\n+    ZNRecord recordDB = new ZNRecord(TARGET_RESOURCES);\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REPLICAS.name(), \"3\");\n+    recordDB.setSimpleField(IdealState.IdealStateProperty.REBALANCE_MODE.name(), \"FULL_AUTO\");\n+    record.setSimpleField(IdealState.IdealStateProperty.IDEAL_STATE_MODE.name(), \"AUTO_REBALANCE\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(), \"MasterSlave\");\n+    record.setSimpleField(IdealState.IdealStateProperty.STATE_MODEL_DEF_REF.name(),\n+        \"org.apache.helix.controller.rebalancer.strategy.CrushEdRebalanceStrategy\");\n+    record.setSimpleField(IdealState.IdealStateProperty.REBALANCER_CLASS_NAME.name(),\n+        \"org.apache.helix.controller.rebalancer.DelayedAutoRebalancer\");\n+    Map<String, String> mapping = new HashMap<>();\n+    mapping.put(instance1, \"MASTER\");\n+    mapping.put(instance2, \"SLAVE\");\n+    mapping.put(instance3, \"SLAVE\");\n+    recordDB.setMapField(TARGET_RESOURCES + \"_0\", mapping);\n+    List<String> listField = new ArrayList<>();\n+    listField.add(instance1);\n+    listField.add(instance2);\n+    listField.add(instance3);\n+    recordDB.setListField(TARGET_RESOURCES + \"_0\", listField);\n+    idealStates.put(TARGET_RESOURCES, new IdealState(recordDB));\n+\n+    return idealStates;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState(String masterInstance, String slaveInstance,\n+      String masterState, String slaveState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, slaveInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, slaveInstance, slaveState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, slaveInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private CurrentStateOutput prepareCurrentState2(String masterInstance, String masterState) {\n+    CurrentStateOutput currentStateOutput = new CurrentStateOutput();\n+    currentStateOutput.setResourceStateModelDef(JOB_NAME, \"TASK\");\n+    currentStateOutput.setBucketSize(JOB_NAME, 0);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    currentStateOutput.setEndTime(JOB_NAME, taskPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(JOB_NAME, taskPartition, masterInstance, masterState);\n+    currentStateOutput.setInfo(JOB_NAME, taskPartition, masterInstance, \"\");\n+    currentStateOutput.setResourceStateModelDef(TARGET_RESOURCES, \"MasterSlave\");\n+    currentStateOutput.setBucketSize(TARGET_RESOURCES, 0);\n+    Partition dbPartition = new Partition(TARGET_RESOURCES + \"_0\");\n+    currentStateOutput.setEndTime(TARGET_RESOURCES, dbPartition, masterInstance, 0L);\n+    currentStateOutput.setCurrentState(TARGET_RESOURCES, dbPartition, masterInstance, \"MASTER\");\n+    currentStateOutput.setInfo(TARGET_RESOURCES, dbPartition, masterInstance, \"\");\n+    return currentStateOutput;\n+  }\n+\n+  private ResourceAssignment preparePreviousAssignment(String instance, String state) {\n+    ResourceAssignment prevAssignment = new ResourceAssignment(JOB_NAME);\n+    Map<String, String> replicaMap = new HashMap<>();\n+    replicaMap.put(instance, state);\n+    Partition taskPartition = new Partition(JOB_NAME + \"_\" + PARTITION_NAME);\n+    prevAssignment.addReplicaMap(taskPartition, replicaMap);\n+    return prevAssignment;\n+  }\n+\n+  private class MockTestInformation {\n+    private String slaveInstance = INSTANCE_PREFIX + \"0\";\n+    private String masterInstance = INSTANCE_PREFIX + \"1\";\n+    private String slaveInstance2 = INSTANCE_PREFIX + \"2\";\n+    private WorkflowControllerDataProvider cache = mock(WorkflowControllerDataProvider.class);\n+    private WorkflowConfig _workflowConfig = prepareWorkflowConfig();\n+    private WorkflowContext _workflowContext = prepareWorkflowContext();\n+    private Map<String, IdealState> _idealStates =\n+        prepareIdealStates(masterInstance, slaveInstance, slaveInstance2);\n+    private JobConfig _jobConfig = prepareJobConfig();\n+    private JobContext _jobContext = prepareJobContext(slaveInstance);\n+    private BestPossibleStateOutput _bestPossibleStateOutput = mock(BestPossibleStateOutput.class);\n+    private CurrentStateOutput _currentStateOutput = prepareCurrentState(masterInstance,\n+        slaveInstance, TaskPartitionState.RUNNING.name(), TaskPartitionState.RUNNING.name());\n+    private CurrentStateOutput _currentStateOutput2 =\n+        prepareCurrentState2(masterInstance, TaskPartitionState.RUNNING.name());\n+    private ResourceAssignment _resourceAssignment =\n+        preparePreviousAssignment(slaveInstance, TaskPartitionState.RUNNING.name());\n+    private ResourceAssignment _resourceAssignment2 =\n+        preparePreviousAssignment(slaveInstance, TaskPartitionState.DROPPED.name());\n+    private TaskDataCache _taskDataCache = mock(TaskDataCache.class);\n+    private RuntimeJobDag _runtimeJobDag = mock(RuntimeJobDag.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAwOTgxMw=="}, "originalCommit": {"oid": "5bee6da006ae40c93fa8bcb6c5009ea2a5dc9bfc"}, "originalPosition": 325}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1424, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}