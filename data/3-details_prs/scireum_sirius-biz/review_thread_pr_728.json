{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA3MTMwNjcw", "number": 728, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwNzowOTozNVrOECBxDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwNzowOTozNVrOECBxDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwNTYxNTQ5OnYy", "diffSide": "RIGHT", "path": "src/main/java/sirius/biz/mongo/PrefixSearchableEntity.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwNzowOTozNVrOGeOzJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QwODoxMTo1NlrOGeQ4Vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM1MjkzNA==", "bodyText": "W\u00e4rs ned vllt sauberer wenn man da nen Consumer f\u00fcr Strings bekommt, der dann automatisch den Tokenizer daf\u00fcr aufruft? Also einfach damit man ned selbst addContentAsTokens aufrufen muss und vor allem keinen Pfusch mit dem Tokenizer machen kann", "url": "https://github.com/scireum/sirius-biz/pull/728#discussion_r434352934", "createdAt": "2020-06-03T07:09:35Z", "author": {"login": "sabieber"}, "path": "src/main/java/sirius/biz/mongo/PrefixSearchableEntity.java", "diffHunk": "@@ -66,51 +49,52 @@ protected void updateSearchField() {\n \n         getSearchPrefixes().clear();\n \n+        Tokenizer tokenizer = createPrefixTokenizer();\n         this.getDescriptor()\n             .getProperties()\n             .stream()\n             .filter(p -> p.getAnnotation(PrefixSearchContent.class).isPresent())\n             .map(p -> p.tryAs(PrefixSearchableContentConsumer.class).orElse((entity, consumer) -> {\n                 consumer.accept(p.getValue(this));\n             }))\n-            .forEach(consumer -> consumer.accept(this, this::addContentAsTokens));\n+            .forEach(consumer -> consumer.accept(this, value -> addContentAsTokens(tokenizer, value)));\n+\n+        addCustomSearchPrefixes(tokenizer);\n+    }\n+\n+    /**\n+     * Adds custom fields as search prefixes.\n+     * <p>\n+     * This method is empty by default and intended to be overwritten by sub classes.\n+     */\n+    protected void addCustomSearchPrefixes(Tokenizer tokenizer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "334f1181c5dfb8c15cfb7bb8794954686ce1de29"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM4NzAzMA==", "bodyText": "aber dann kann man keinen pfusch mehr mit dem tokenizer machen :-P", "url": "https://github.com/scireum/sirius-biz/pull/728#discussion_r434387030", "createdAt": "2020-06-03T08:11:56Z", "author": {"login": "andyHa"}, "path": "src/main/java/sirius/biz/mongo/PrefixSearchableEntity.java", "diffHunk": "@@ -66,51 +49,52 @@ protected void updateSearchField() {\n \n         getSearchPrefixes().clear();\n \n+        Tokenizer tokenizer = createPrefixTokenizer();\n         this.getDescriptor()\n             .getProperties()\n             .stream()\n             .filter(p -> p.getAnnotation(PrefixSearchContent.class).isPresent())\n             .map(p -> p.tryAs(PrefixSearchableContentConsumer.class).orElse((entity, consumer) -> {\n                 consumer.accept(p.getValue(this));\n             }))\n-            .forEach(consumer -> consumer.accept(this, this::addContentAsTokens));\n+            .forEach(consumer -> consumer.accept(this, value -> addContentAsTokens(tokenizer, value)));\n+\n+        addCustomSearchPrefixes(tokenizer);\n+    }\n+\n+    /**\n+     * Adds custom fields as search prefixes.\n+     * <p>\n+     * This method is empty by default and intended to be overwritten by sub classes.\n+     */\n+    protected void addCustomSearchPrefixes(Tokenizer tokenizer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM1MjkzNA=="}, "originalCommit": {"oid": "334f1181c5dfb8c15cfb7bb8794954686ce1de29"}, "originalPosition": 62}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2052, "cost": 1, "resetAt": "2021-11-12T12:57:47Z"}}}