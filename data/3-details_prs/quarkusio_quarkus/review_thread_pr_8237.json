{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk1MTIwMjA5", "number": 8237, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowMDoxM1rODwsQEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowNjoyOFrODwsWnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMzgzMjUxOnYy", "diffSide": "RIGHT", "path": "integration-tests/kafka/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowMDoxM1rOGD1PPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowMDoxM1rOGD1PPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3MTE2NQ==", "bodyText": "Have you considered using the serializer from the Apicurio project?", "url": "https://github.com/quarkusio/quarkus/pull/8237#discussion_r406671165", "createdAt": "2020-04-10T09:00:13Z", "author": {"login": "gunnarmorling"}, "path": "integration-tests/kafka/pom.xml", "diffHunk": "@@ -54,6 +54,26 @@\n             <artifactId>quarkus-kafka-client</artifactId>\n         </dependency>\n \n+        <!-- Avro -->\n+        <dependency>\n+            <groupId>org.apache.avro</groupId>\n+            <artifactId>avro</artifactId>\n+            <version>1.9.1</version>\n+        </dependency>\n+        <dependency>\n+            <!-- Not in Maven Central -->\n+            <groupId>io.confluent</groupId>\n+            <artifactId>kafka-avro-serializer</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c88d1eb440ce98114a5ca7b0179ce9b8e7492f3"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMzgzOTAwOnYy", "diffSide": "RIGHT", "path": "integration-tests/kafka/src/main/java/io/quarkus/it/kafka/avro/AvroEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowMjozMFrOGD1S1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowMjozMFrOGD1S1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3MjA4Nw==", "bodyText": "Same thought as above: use the Apicurio SerDe?", "url": "https://github.com/quarkusio/quarkus/pull/8237#discussion_r406672087", "createdAt": "2020-04-10T09:02:30Z", "author": {"login": "gunnarmorling"}, "path": "integration-tests/kafka/src/main/java/io/quarkus/it/kafka/avro/AvroEndpoint.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package io.quarkus.it.kafka.avro;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import javax.annotation.PostConstruct;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.IntegerDeserializer;\n+import org.apache.kafka.common.serialization.IntegerSerializer;\n+\n+import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;\n+import io.confluent.kafka.serializers.KafkaAvroDeserializer;\n+import io.confluent.kafka.serializers.KafkaAvroDeserializerConfig;\n+import io.confluent.kafka.serializers.KafkaAvroSerializer;\n+import io.vertx.core.json.JsonObject;\n+\n+/**\n+ * Endpoint to test the Avro support\n+ */\n+@Path(\"/avro\")\n+public class AvroEndpoint {\n+\n+    private KafkaConsumer<Integer, Pet> consumer;\n+    private KafkaProducer<Integer, Pet> producer;\n+\n+    @PostConstruct\n+    public void init() {\n+        String registry = System.getProperty(\"schema.url\");\n+        producer = createProducer(registry);\n+        consumer = createConsumer(registry);\n+    }\n+\n+    @GET\n+    @Produces(MediaType.APPLICATION_JSON)\n+    public JsonObject get() {\n+        final ConsumerRecords<Integer, Pet> records = consumer.poll(Duration.ofMillis(60000));\n+        if (records.isEmpty()) {\n+            return null;\n+        }\n+        Pet p = records.iterator().next().value();\n+        // We cannot serialize the returned Pet directly, it contains non-serializable object such as the schema.\n+        JsonObject result = new JsonObject();\n+        result.put(\"name\", p.getName());\n+        result.put(\"color\", p.getColor());\n+        return result;\n+    }\n+\n+    @POST\n+    public void send(Pet pet) {\n+        producer.send(new ProducerRecord<>(\"test-avro-producer\", 0, pet));\n+        producer.flush();\n+    }\n+\n+    public static KafkaConsumer<Integer, Pet> createConsumer(String registry) {\n+        Properties props = new Properties();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:19092\");\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, \"test-avro-consumer\");\n+        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());\n+        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class.getName());\n+        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n+        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        props.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, registry);\n+        props.put(KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG, true);\n+        KafkaConsumer<Integer, Pet> consumer = new KafkaConsumer<>(props);\n+        consumer.subscribe(Collections.singletonList(\"test-avro-consumer\"));\n+        return consumer;\n+    }\n+\n+    public static KafkaProducer<Integer, Pet> createProducer(String registry) {\n+        Properties props = new Properties();\n+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:19092\");\n+        props.put(ProducerConfig.CLIENT_ID_CONFIG, \"test-avro\");\n+        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class.getName());\n+        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());\n+        props.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, registry);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c88d1eb440ce98114a5ca7b0179ce9b8e7492f3"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMzg0MTU1OnYy", "diffSide": "RIGHT", "path": "integration-tests/kafka/src/main/java/io/quarkus/it/kafka/sasl/SaslKafkaEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowMzozM1rOGD1UUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowMzozM1rOGD1UUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3MjQ2Nw==", "bodyText": "addSsl, to be consistent with other abbreviation casing in this test?", "url": "https://github.com/quarkusio/quarkus/pull/8237#discussion_r406672467", "createdAt": "2020-04-10T09:03:33Z", "author": {"login": "gunnarmorling"}, "path": "integration-tests/kafka/src/main/java/io/quarkus/it/kafka/sasl/SaslKafkaEndpoint.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package io.quarkus.it.kafka.sasl;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import javax.annotation.PostConstruct;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.serialization.IntegerDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+\n+/**\n+ * Endpoint to check the SSL/SASL connection.\n+ */\n+@Path(\"/sasl\")\n+public class SaslKafkaEndpoint {\n+\n+    private Consumer<Integer, String> consumer;\n+\n+    @PostConstruct\n+    public void create() {\n+        consumer = createConsumer();\n+    }\n+\n+    @GET\n+    public String get() {\n+        final ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(60000));\n+        if (records.isEmpty()) {\n+            return null;\n+        }\n+        return records.iterator().next().value();\n+    }\n+\n+    private static void addSSL(Properties props) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c88d1eb440ce98114a5ca7b0179ce9b8e7492f3"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMzg0OTI0OnYy", "diffSide": "RIGHT", "path": "integration-tests/kafka/src/test/java/io/quarkus/it/kafka/SaslKafkaConsumerTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowNjoyOFrOGD1Ywg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowNjoyOFrOGD1Ywg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3MzYwMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static void addSSL(Properties props) {\n          \n          \n            \n                private static void addSsl(Properties props) {", "url": "https://github.com/quarkusio/quarkus/pull/8237#discussion_r406673602", "createdAt": "2020-04-10T09:06:28Z", "author": {"login": "gunnarmorling"}, "path": "integration-tests/kafka/src/test/java/io/quarkus/it/kafka/SaslKafkaConsumerTest.java", "diffHunk": "@@ -0,0 +1,60 @@\n+package io.quarkus.it.kafka;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Properties;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.serialization.IntegerSerializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.Test;\n+\n+import io.quarkus.test.common.QuarkusTestResource;\n+import io.quarkus.test.junit.QuarkusTest;\n+import io.restassured.RestAssured;\n+\n+@QuarkusTest\n+@QuarkusTestResource(KafkaSASLTestResource.class)\n+public class SaslKafkaConsumerTest {\n+\n+    private static void addSSL(Properties props) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c88d1eb440ce98114a5ca7b0179ce9b8e7492f3"}, "originalPosition": 27}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3690, "cost": 1, "resetAt": "2021-11-13T14:23:39Z"}}}