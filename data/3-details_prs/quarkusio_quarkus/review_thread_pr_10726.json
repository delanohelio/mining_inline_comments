{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ5MDE1MTAy", "number": 10726, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODo0MjowMlrOEOli9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwNTo0NTo0N1rOEP-VVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzMwNjc5OnYy", "diffSide": "RIGHT", "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "isResolved": false, "comments": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODo0MjowMlrOGx0QtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxNTo1MToyNlrOGyxWpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw==", "bodyText": "I have no idea what this code is doing but this observer will be notified before similar observers with no priority declared (the default priority is 2500, Priority.LIBRARY_BEFORE + 500 = 1500 and observers with smaller priority values are called first).\nIf that's the intention I have nothing to add ;-).", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r454889653", "createdAt": "2020-07-15T08:42:02Z", "author": {"login": "mkouba"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg5NTA3OA==", "bodyText": "Yeah, I should have been clearer :).\nI'm not totally sure this pattern of doing things with startup events and then returning what's initialized here is a good thing. I'm pretty sure this could lead to weird startup issues.\nBut I'm not a Kafka Streams expect, maybe it's how they do things to avoid waiting for things to be fully started.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r454895078", "createdAt": "2020-07-15T08:50:43Z", "author": {"login": "gsmet"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkwODg0OQ==", "bodyText": "Is this issue specific to Kafka Streams even, or is it something more generic? I'd have expected that the dependency resolver of CDI takes care of this: i.e. if there's an injection point for KafkaStreams (or any type, really), it would make sure the corresponding producer is started up before that?\nAlso it's interesting that an NPE happens, I'd rather have expected some sort of \"UnresolvedDependencyInjection\"?", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r454908849", "createdAt": "2020-07-15T09:13:12Z", "author": {"login": "gunnarmorling"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyNTA2MA==", "bodyText": "@gunnarmorling, dependency injection and CDI events are two different concepts. If there is an injection point of type KafkaStreams then CDI ensures that the corresponding bean is created before the injection point is injected.\n\nAlso it's interesting that an NPE happens, I'd rather have expected some sort of \"UnresolvedDependencyInjection\"?\n\nUnsatisfiedResolutionException is thrown if there is an injection point that cannot be satisfied. Which is not the case here  - the producer method would satisfy such an injection point. However, the KafkaStreamsTopologyManager#streams could be uninitialized and thus the producer method returns null.\nSo the real problem is - when/how to initalize the streams so that a bean may not inject an uninitialized producer method.\nThis morning I sent a PR that describes this \"late init\" problem with extensions:\nhttps://github.com/quarkusio/quarkus/blob/f12c24e4be88fd3d7d077ed9087fe8ffecc83f56/docs/src/main/asciidoc/writing-extensions.adoc#user-content-bean_init\nUnfortunately, I'm no kafka streams expert either so I can't answer your question @gsmet...", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r454925060", "createdAt": "2020-07-15T09:40:56Z", "author": {"login": "mkouba"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkzNzkxNA==", "bodyText": "the producer method would satisfy such an injection point. However, the KafkaStreamsTopologyManager#streams could be uninitialized and thus the producer method returns null.\n\nI see. I think this code is based on the assumpt that if there's a producer method like in this case here, the @observes StartupEvent method of the bean declaring that method is guaranteed to have been run before that producer method is invoked. Seems like that assumption doesn't hold as per what your say.\nIn that light I'm wondering why we don't start the KafkaStreams object simply in the constructor instead of using the start-up observer method.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r454937914", "createdAt": "2020-07-15T10:02:39Z", "author": {"login": "gunnarmorling"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0MDQzMQ==", "bodyText": "StartupEvent method of the bean declaring that method is guaranteed to have been run before that producer method is invoked. Seems like that assumption doesn't hold as per what your say.\n\nYes, completely unfounded assumption.\n\nIn that light I'm wondering why we don't start the KafkaStreams object simply in the constructor instead of using the start-up observer method.\n\nMaybe it has to be started at runtime and some other bean needs to access KafkaStreamsTopologyManager during static init?", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r454940431", "createdAt": "2020-07-15T10:07:11Z", "author": {"login": "mkouba"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAzNTk0OA==", "bodyText": "I think the problem is KafkaStreamsTopologyManager#setRuntimeConfig called by KafkaStreamsRecorder has to happen before KStream can be started (because once a KStreams instance is started it can't be re-configured afterward). And I guess KafkaStreamsRuntimeConfig is not a bean that could be directly injected in the constructor either ?", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455035948", "createdAt": "2020-07-15T13:06:59Z", "author": {"login": "rquinio"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTA0MTI3Nw==", "bodyText": "KafkaStreamsRuntimeConfig can be injected in a bean. However, it is a RUN_TIME config root so it may not be available before the app starts. E.g. if the consuming bean is created during STATIC_INIT you will get CreationException.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455041277", "createdAt": "2020-07-15T13:14:49Z", "author": {"login": "mkouba"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTA0MjM5NA==", "bodyText": "Yes, completely unfounded assumption.\n\nWell, I'd say it's not so far-fetched to assume a bean would be fully initialized and ready to use before any of its methods are invoked by the runtime. But ok, things are as they are.\n\nMaybe it has to be started at runtime\n\nYes, it absolutely must be started at runtime. KafkaStreamsTopologyManager shouldn't be needed at static init IIRC. So can we have it being instantiated at runtime only? Or maybe the suggested priority fix is just fine really :)", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455042394", "createdAt": "2020-07-15T13:16:31Z", "author": {"login": "gunnarmorling"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTA0OTcxMA==", "bodyText": "Yes, completely unfounded assumption.\n\n\n\nWell, I'd say it's not so far-fetched to assume a bean would be fully initialized and ready to use before any of its methods are invoked by the runtime. But ok, things are as they are.\n\n@gunnarmorling The bean itself is fully initialized but its state is not initialized. In this particular case there is a bean that declares a producer method and an obsever. The producer method is backed by a state that is explicitly initialized after the bean is created and has no connection to the observer except that they both are invoked upon the same bean instance. In other words, it is only guaranteed that the KafkaStreamsTopologyManager is created before the producer or the observer is called.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455049710", "createdAt": "2020-07-15T13:26:43Z", "author": {"login": "mkouba"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTM2MTg2Mw==", "bodyText": "Just to add. I did debug the code and it is showing non deterministic behavior. Sometimes KafkaStreamsTopologyManager would be initialized before the bean expecting the KafkaStreams and other times not.\n    @Inject\n    KafkaStreams kafkaStreams;\n\n    void startUp(@Observes StartupEvent ev) {\n        LOG.info(\"Initializing metrics exporter\");\n    }\n\n    @PostConstruct\n    void init() {\n\n        LOG.info(\"My stream as a String: \" + kafkaStreams);\n        // Sometimes it gives a NPE\n        var metrics = kafkaStreams.metrics();\n\n    }\n\nA quick work around was to change the priority to\n    void startUp(@Observes @Priority(Interceptor.Priority.APPLICATION + 600) StartupEvent ev) {\n        LOG.info(\"Initializing metrics exporter\");\n    }\n\nWhich is what brought me to the code in this PR.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455361863", "createdAt": "2020-07-15T21:26:42Z", "author": {"login": "pcasaes"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTU0ODE1MA==", "bodyText": "I did debug the code and it is showing non deterministic behavior.\n\nYes, that's expected. Your StartupEvent observer has also the default priority - if multiple observers define the same priority the ordering is undefined (random).", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455548150", "createdAt": "2020-07-16T06:51:14Z", "author": {"login": "mkouba"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY0MDgxNg==", "bodyText": "@mkouba can't we just move whatever is in the startup event in the @Produces method?", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455640816", "createdAt": "2020-07-16T09:10:26Z", "author": {"login": "gsmet"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY1NjIyMw==", "bodyText": "Well, that could be a solution. However, it could still break things if someone attempts to access the produced bean during STATIC_INIT....\nBut again I have no idea about the \"business logic\" of this bean...", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455656223", "createdAt": "2020-07-16T09:35:33Z", "author": {"login": "mkouba"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY2MzQxMA==", "bodyText": "I think it won't work in all cases, because it's not necessary that an application injects explicitly a KafkaStreams instance into another bean, more over if it is injected in an @applicationScoped bean, it will be created after the application has started, not sure if it's the expected behavior.\nMaybe the best would be to change the scope of the Kafkastreams method to @applicationScoped (it's currently a Singleton) and create a holder class to be sure to access the kafkastreams at runtime.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455663410", "createdAt": "2020-07-16T09:47:24Z", "author": {"login": "vietk"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY3MDExNQ==", "bodyText": "However, it could still break things if someone attempts to access the produced bean during STATIC_INIT...\n\nThe KafkaStreams object is only meant to be used at runtime. It processes data from Kafka topics. You could compare it to creating a database connection which also doesn't make sense at static init.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455670115", "createdAt": "2020-07-16T09:58:53Z", "author": {"login": "gunnarmorling"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY5OTkxMQ==", "bodyText": "The KafkaStreams object is only meant to be used at runtime.\n\nIn that case, we should probably throw an exception if someone attempts to use the bean during STATIC_INIT...", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455699911", "createdAt": "2020-07-16T10:53:49Z", "author": {"login": "mkouba"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTcwMzgwNA==", "bodyText": "In that case, we should probably throw an exception if someone attempts to use the bean during STATIC_INIT...\n\nWell, we don't really do that for all the other beans that shouldn't be accessed at static init, do we? At least I never took care of this.\nIf moving things to the @Produces method is OK, that would have my preference. (And I would like to include it in 1.6.1)", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455703804", "createdAt": "2020-07-16T11:01:23Z", "author": {"login": "gsmet"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg5MDU5OA==", "bodyText": "Just pushed the change. Moved the instantiation to the producer method. As a consequence it no longer will be eager loaded though. Also will throw an exception if the Topology is not defined, not sure if this is the right approach.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r455890598", "createdAt": "2020-07-16T15:51:26Z", "author": {"login": "pcasaes"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,7 +191,7 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n+    void onStart(@Observes @Priority(Interceptor.Priority.LIBRARY_BEFORE + 500) StartupEvent ev) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4OTY1Mw=="}, "originalCommit": {"oid": "6b662865a15f9d3102f78aba308e0af7dd6778a6"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjIzMDEwOnYy", "diffSide": "RIGHT", "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODowMzozM1rOGzJbIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODowMzozM1rOGzJbIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjI4NDk2Mw==", "bodyText": "I would use a @PreDestroy here instead.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r456284963", "createdAt": "2020-07-17T08:03:33Z", "author": {"login": "gsmet"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,56 +188,56 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n-        if (executor == null) {\n-            return;\n+    void onStop(@Observes ShutdownEvent ev) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef4ee7656955449f1273657892d4c8ca1963f7df"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NjI3MzY3OnYy", "diffSide": "RIGHT", "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODoxNzowNlrOGzJ19A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODo1NjozMVrOGzLI6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjI5MTgyOA==", "bodyText": "I checked on a small test, a Singleton bean seems to be not created if the bean is not injected anywhere.\nCan someone confirms this behavior, I searched in CDI/Arc I did not find anything.\nIn our application we are not injecting (yet) a KafkaStreams instance, because we don't need it, so this is not gonna work.\nCan you make sure it's working (or not) in that case : not injecting the bean somewhere ?", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r456291828", "createdAt": "2020-07-17T08:17:06Z", "author": {"login": "vietk"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,56 +188,56 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n-        if (executor == null) {\n-            return;\n+    void onStop(@Observes ShutdownEvent ev) {\n+        if (streams != null) {\n+            LOGGER.debug(\"Stopping Kafka Streams pipeline\");\n+            streams.close();\n         }\n+    }\n \n-        String bootstrapServersConfig = asString(runtimeConfig.bootstrapServers);\n-\n-        Properties streamsProperties = getStreamsProperties(properties, bootstrapServersConfig, runtimeConfig);\n-\n-        if (kafkaClientSupplier.isUnsatisfied()) {\n-            streams = new KafkaStreams(topology.get(), streamsProperties);\n-        } else {\n-            streams = new KafkaStreams(topology.get(), streamsProperties, kafkaClientSupplier.get());\n+    @Produces\n+    @Singleton", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef4ee7656955449f1273657892d4c8ca1963f7df"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMxMzA2NQ==", "bodyText": "I found the doc : https://quarkus.io/guides/cdi-reference#lazy_by_default\n By default, CDI beans are created lazily, when needed.\nA bean with a pseudo-scope (@Dependent and @Singleton ) is created when injected.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r456313065", "createdAt": "2020-07-17T08:56:31Z", "author": {"login": "vietk"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -189,56 +188,56 @@ private static String asString(List<InetSocketAddress> addresses) {\n                 .collect(Collectors.joining(\",\"));\n     }\n \n-    void onStart(@Observes StartupEvent ev) {\n-        if (executor == null) {\n-            return;\n+    void onStop(@Observes ShutdownEvent ev) {\n+        if (streams != null) {\n+            LOGGER.debug(\"Stopping Kafka Streams pipeline\");\n+            streams.close();\n         }\n+    }\n \n-        String bootstrapServersConfig = asString(runtimeConfig.bootstrapServers);\n-\n-        Properties streamsProperties = getStreamsProperties(properties, bootstrapServersConfig, runtimeConfig);\n-\n-        if (kafkaClientSupplier.isUnsatisfied()) {\n-            streams = new KafkaStreams(topology.get(), streamsProperties);\n-        } else {\n-            streams = new KafkaStreams(topology.get(), streamsProperties, kafkaClientSupplier.get());\n+    @Produces\n+    @Singleton", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjI5MTgyOA=="}, "originalCommit": {"oid": "ef4ee7656955449f1273657892d4c8ca1963f7df"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0OTY0ODkyOnYy", "diffSide": "RIGHT", "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsProducer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOFQxNDoxOToyM1rOGzohTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOFQxNDoyMzo0NVrOGzoi1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njc5NDQ0NA==", "bodyText": "This annotation shouldn't be necessary", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r456794444", "createdAt": "2020-07-18T14:19:23Z", "author": {"login": "geoand"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsProducer.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package io.quarkus.kafka.streams.runtime;\n+\n+import java.net.InetSocketAddress;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.PreDestroy;\n+import javax.enterprise.inject.Instance;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import javax.inject.Singleton;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.ListTopicsResult;\n+import org.apache.kafka.common.config.SaslConfigs;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.streams.KafkaClientSupplier;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KafkaStreams.StateListener;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.processor.StateRestoreListener;\n+import org.jboss.logging.Logger;\n+\n+import io.quarkus.arc.Unremovable;\n+import io.quarkus.runtime.Startup;\n+\n+/**\n+ * Manages the lifecycle of a Kafka Streams pipeline. If there's a producer\n+ * method returning a KS {@link Topology}, then this topology will be configured\n+ * and started. Optionally, before starting the pipeline, this manager will wait\n+ * for a given set of topics to be created, as KS itself will fail without all\n+ * input topics being created upfront.\n+ */\n+@Singleton\n+public class KafkaStreamsProducer {\n+\n+    private static final Logger LOGGER = Logger.getLogger(KafkaStreamsProducer.class.getName());\n+\n+    private final ExecutorService executorService;\n+    private final KafkaStreams kafkaStreams;\n+    private final KafkaStreamsTopologyManager kafkaStreamsTopologyManager;\n+\n+    @Inject", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e2ebbb0f08f54d23c4d18d815dab56ee312e6bd"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njc5NDgzNg==", "bodyText": "Yeah, I know it's not. It's purely cosmetic to make me think the parameters are injected :).", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r456794836", "createdAt": "2020-07-18T14:23:45Z", "author": {"login": "gsmet"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsProducer.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package io.quarkus.kafka.streams.runtime;\n+\n+import java.net.InetSocketAddress;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.PreDestroy;\n+import javax.enterprise.inject.Instance;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import javax.inject.Singleton;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.ListTopicsResult;\n+import org.apache.kafka.common.config.SaslConfigs;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.streams.KafkaClientSupplier;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KafkaStreams.StateListener;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.processor.StateRestoreListener;\n+import org.jboss.logging.Logger;\n+\n+import io.quarkus.arc.Unremovable;\n+import io.quarkus.runtime.Startup;\n+\n+/**\n+ * Manages the lifecycle of a Kafka Streams pipeline. If there's a producer\n+ * method returning a KS {@link Topology}, then this topology will be configured\n+ * and started. Optionally, before starting the pipeline, this manager will wait\n+ * for a given set of topics to be created, as KS itself will fail without all\n+ * input topics being created upfront.\n+ */\n+@Singleton\n+public class KafkaStreamsProducer {\n+\n+    private static final Logger LOGGER = Logger.getLogger(KafkaStreamsProducer.class.getName());\n+\n+    private final ExecutorService executorService;\n+    private final KafkaStreams kafkaStreams;\n+    private final KafkaStreamsTopologyManager kafkaStreamsTopologyManager;\n+\n+    @Inject", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njc5NDQ0NA=="}, "originalCommit": {"oid": "8e2ebbb0f08f54d23c4d18d815dab56ee312e6bd"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTgwODc0OnYy", "diffSide": "RIGHT", "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwNTozMjozNFrOGz5GhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwNzo0Mzo1OFrOGz9nTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzA2NjExNg==", "bodyText": "This looks like it can be final now, correct?", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r457066116", "createdAt": "2020-07-20T05:32:34Z", "author": {"login": "geoand"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -1,282 +1,29 @@\n package io.quarkus.kafka.streams.runtime;\n \n-import java.net.InetSocketAddress;\n-import java.time.Duration;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.HashSet;\n-import java.util.List;\n-import java.util.Objects;\n-import java.util.Optional;\n import java.util.Properties;\n import java.util.Set;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.TimeoutException;\n-import java.util.function.Function;\n-import java.util.stream.Collectors;\n \n-import javax.enterprise.context.ApplicationScoped;\n-import javax.enterprise.event.Observes;\n-import javax.enterprise.inject.Instance;\n-import javax.enterprise.inject.Produces;\n-import javax.inject.Inject;\n-import javax.inject.Singleton;\n-\n-import org.apache.kafka.clients.CommonClientConfigs;\n import org.apache.kafka.clients.admin.AdminClient;\n-import org.apache.kafka.clients.admin.AdminClientConfig;\n import org.apache.kafka.clients.admin.ListTopicsResult;\n-import org.apache.kafka.common.config.SaslConfigs;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.kafka.streams.KafkaClientSupplier;\n-import org.apache.kafka.streams.KafkaStreams;\n-import org.apache.kafka.streams.KafkaStreams.StateListener;\n-import org.apache.kafka.streams.StreamsConfig;\n-import org.apache.kafka.streams.Topology;\n-import org.apache.kafka.streams.processor.StateRestoreListener;\n import org.jboss.logging.Logger;\n \n-import io.quarkus.runtime.ShutdownEvent;\n-import io.quarkus.runtime.StartupEvent;\n-\n-/**\n- * Manages the lifecycle of a Kafka Streams pipeline. If there's a producer\n- * method returning a KS {@link Topology}, then this topology will be configured\n- * and started. Optionally, before starting the pipeline, this manager will wait\n- * for a given set of topics to be created, as KS itself will fail without all\n- * input topics being created upfront.\n- */\n-@ApplicationScoped\n public class KafkaStreamsTopologyManager {\n \n     private static final Logger LOGGER = Logger.getLogger(KafkaStreamsTopologyManager.class.getName());\n \n-    private final ExecutorService executor;\n-    private volatile KafkaStreams streams;\n-    private volatile KafkaStreamsRuntimeConfig runtimeConfig;\n-    private volatile Instance<Topology> topology;\n-    private volatile Properties properties;\n     private volatile Properties adminClientConfig;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e2ebbb0f08f54d23c4d18d815dab56ee312e6bd"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEzODEzMA==", "bodyText": "Ah yeah, forgot to remove it.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r457138130", "createdAt": "2020-07-20T07:41:11Z", "author": {"login": "gsmet"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -1,282 +1,29 @@\n package io.quarkus.kafka.streams.runtime;\n \n-import java.net.InetSocketAddress;\n-import java.time.Duration;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.HashSet;\n-import java.util.List;\n-import java.util.Objects;\n-import java.util.Optional;\n import java.util.Properties;\n import java.util.Set;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.TimeoutException;\n-import java.util.function.Function;\n-import java.util.stream.Collectors;\n \n-import javax.enterprise.context.ApplicationScoped;\n-import javax.enterprise.event.Observes;\n-import javax.enterprise.inject.Instance;\n-import javax.enterprise.inject.Produces;\n-import javax.inject.Inject;\n-import javax.inject.Singleton;\n-\n-import org.apache.kafka.clients.CommonClientConfigs;\n import org.apache.kafka.clients.admin.AdminClient;\n-import org.apache.kafka.clients.admin.AdminClientConfig;\n import org.apache.kafka.clients.admin.ListTopicsResult;\n-import org.apache.kafka.common.config.SaslConfigs;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.kafka.streams.KafkaClientSupplier;\n-import org.apache.kafka.streams.KafkaStreams;\n-import org.apache.kafka.streams.KafkaStreams.StateListener;\n-import org.apache.kafka.streams.StreamsConfig;\n-import org.apache.kafka.streams.Topology;\n-import org.apache.kafka.streams.processor.StateRestoreListener;\n import org.jboss.logging.Logger;\n \n-import io.quarkus.runtime.ShutdownEvent;\n-import io.quarkus.runtime.StartupEvent;\n-\n-/**\n- * Manages the lifecycle of a Kafka Streams pipeline. If there's a producer\n- * method returning a KS {@link Topology}, then this topology will be configured\n- * and started. Optionally, before starting the pipeline, this manager will wait\n- * for a given set of topics to be created, as KS itself will fail without all\n- * input topics being created upfront.\n- */\n-@ApplicationScoped\n public class KafkaStreamsTopologyManager {\n \n     private static final Logger LOGGER = Logger.getLogger(KafkaStreamsTopologyManager.class.getName());\n \n-    private final ExecutorService executor;\n-    private volatile KafkaStreams streams;\n-    private volatile KafkaStreamsRuntimeConfig runtimeConfig;\n-    private volatile Instance<Topology> topology;\n-    private volatile Properties properties;\n     private volatile Properties adminClientConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzA2NjExNg=="}, "originalCommit": {"oid": "8e2ebbb0f08f54d23c4d18d815dab56ee312e6bd"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzE0MDA0NA==", "bodyText": "Fixed. Removed volatile and added final.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r457140044", "createdAt": "2020-07-20T07:43:58Z", "author": {"login": "gsmet"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsTopologyManager.java", "diffHunk": "@@ -1,282 +1,29 @@\n package io.quarkus.kafka.streams.runtime;\n \n-import java.net.InetSocketAddress;\n-import java.time.Duration;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.HashSet;\n-import java.util.List;\n-import java.util.Objects;\n-import java.util.Optional;\n import java.util.Properties;\n import java.util.Set;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.TimeoutException;\n-import java.util.function.Function;\n-import java.util.stream.Collectors;\n \n-import javax.enterprise.context.ApplicationScoped;\n-import javax.enterprise.event.Observes;\n-import javax.enterprise.inject.Instance;\n-import javax.enterprise.inject.Produces;\n-import javax.inject.Inject;\n-import javax.inject.Singleton;\n-\n-import org.apache.kafka.clients.CommonClientConfigs;\n import org.apache.kafka.clients.admin.AdminClient;\n-import org.apache.kafka.clients.admin.AdminClientConfig;\n import org.apache.kafka.clients.admin.ListTopicsResult;\n-import org.apache.kafka.common.config.SaslConfigs;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.kafka.streams.KafkaClientSupplier;\n-import org.apache.kafka.streams.KafkaStreams;\n-import org.apache.kafka.streams.KafkaStreams.StateListener;\n-import org.apache.kafka.streams.StreamsConfig;\n-import org.apache.kafka.streams.Topology;\n-import org.apache.kafka.streams.processor.StateRestoreListener;\n import org.jboss.logging.Logger;\n \n-import io.quarkus.runtime.ShutdownEvent;\n-import io.quarkus.runtime.StartupEvent;\n-\n-/**\n- * Manages the lifecycle of a Kafka Streams pipeline. If there's a producer\n- * method returning a KS {@link Topology}, then this topology will be configured\n- * and started. Optionally, before starting the pipeline, this manager will wait\n- * for a given set of topics to be created, as KS itself will fail without all\n- * input topics being created upfront.\n- */\n-@ApplicationScoped\n public class KafkaStreamsTopologyManager {\n \n     private static final Logger LOGGER = Logger.getLogger(KafkaStreamsTopologyManager.class.getName());\n \n-    private final ExecutorService executor;\n-    private volatile KafkaStreams streams;\n-    private volatile KafkaStreamsRuntimeConfig runtimeConfig;\n-    private volatile Instance<Topology> topology;\n-    private volatile Properties properties;\n     private volatile Properties adminClientConfig;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzA2NjExNg=="}, "originalCommit": {"oid": "8e2ebbb0f08f54d23c4d18d815dab56ee312e6bd"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTg1MzQ1OnYy", "diffSide": "RIGHT", "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsProducer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwNTo0NTozOVrOGz5eWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwNTo0NTozOVrOGz5eWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzA3MjIxOQ==", "bodyText": "Is it certain that this needs to be @Unremovable?", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r457072219", "createdAt": "2020-07-20T05:45:39Z", "author": {"login": "geoand"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsProducer.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package io.quarkus.kafka.streams.runtime;\n+\n+import java.net.InetSocketAddress;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.PreDestroy;\n+import javax.enterprise.inject.Instance;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import javax.inject.Singleton;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.ListTopicsResult;\n+import org.apache.kafka.common.config.SaslConfigs;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.streams.KafkaClientSupplier;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KafkaStreams.StateListener;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.processor.StateRestoreListener;\n+import org.jboss.logging.Logger;\n+\n+import io.quarkus.arc.Unremovable;\n+import io.quarkus.runtime.Startup;\n+\n+/**\n+ * Manages the lifecycle of a Kafka Streams pipeline. If there's a producer\n+ * method returning a KS {@link Topology}, then this topology will be configured\n+ * and started. Optionally, before starting the pipeline, this manager will wait\n+ * for a given set of topics to be created, as KS itself will fail without all\n+ * input topics being created upfront.\n+ */\n+@Singleton\n+public class KafkaStreamsProducer {\n+\n+    private static final Logger LOGGER = Logger.getLogger(KafkaStreamsProducer.class.getName());\n+\n+    private final ExecutorService executorService;\n+    private final KafkaStreams kafkaStreams;\n+    private final KafkaStreamsTopologyManager kafkaStreamsTopologyManager;\n+\n+    @Inject\n+    public KafkaStreamsProducer(KafkaStreamsSupport kafkaStreamsSupport, KafkaStreamsRuntimeConfig runtimeConfig,\n+            Instance<Topology> topology, Instance<KafkaClientSupplier> kafkaClientSupplier,\n+            Instance<StateListener> stateListener, Instance<StateRestoreListener> globalStateRestoreListener) {\n+        // No producer for Topology -> nothing to do\n+        if (topology.isUnsatisfied()) {\n+            LOGGER.debug(\"No Topology producer; Kafka Streams will not be started\");\n+            this.executorService = null;\n+            this.kafkaStreams = null;\n+            this.kafkaStreamsTopologyManager = null;\n+            return;\n+        }\n+\n+        Properties buildTimeProperties = kafkaStreamsSupport.getProperties();\n+\n+        String bootstrapServersConfig = asString(runtimeConfig.bootstrapServers);\n+        Properties kafkaStreamsProperties = getStreamsProperties(buildTimeProperties, bootstrapServersConfig, runtimeConfig);\n+        Properties adminClientConfig = getAdminClientConfig(kafkaStreamsProperties);\n+\n+        this.executorService = Executors.newSingleThreadExecutor();\n+\n+        this.kafkaStreams = initializeKafkaStreams(kafkaStreamsProperties, runtimeConfig, adminClientConfig, topology.get(),\n+                kafkaClientSupplier, stateListener, globalStateRestoreListener, executorService);\n+        this.kafkaStreamsTopologyManager = new KafkaStreamsTopologyManager(adminClientConfig);\n+    }\n+\n+    @Produces\n+    @Singleton\n+    @Unremovable", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e2ebbb0f08f54d23c4d18d815dab56ee312e6bd"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1MTg1MzY1OnYy", "diffSide": "RIGHT", "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsProducer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwNTo0NTo0N1rOGz5ehg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQwNzo0MTo1OFrOGz9h0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzA3MjI2Mg==", "bodyText": "Same here", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r457072262", "createdAt": "2020-07-20T05:45:47Z", "author": {"login": "geoand"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsProducer.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package io.quarkus.kafka.streams.runtime;\n+\n+import java.net.InetSocketAddress;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.PreDestroy;\n+import javax.enterprise.inject.Instance;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import javax.inject.Singleton;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.ListTopicsResult;\n+import org.apache.kafka.common.config.SaslConfigs;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.streams.KafkaClientSupplier;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KafkaStreams.StateListener;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.processor.StateRestoreListener;\n+import org.jboss.logging.Logger;\n+\n+import io.quarkus.arc.Unremovable;\n+import io.quarkus.runtime.Startup;\n+\n+/**\n+ * Manages the lifecycle of a Kafka Streams pipeline. If there's a producer\n+ * method returning a KS {@link Topology}, then this topology will be configured\n+ * and started. Optionally, before starting the pipeline, this manager will wait\n+ * for a given set of topics to be created, as KS itself will fail without all\n+ * input topics being created upfront.\n+ */\n+@Singleton\n+public class KafkaStreamsProducer {\n+\n+    private static final Logger LOGGER = Logger.getLogger(KafkaStreamsProducer.class.getName());\n+\n+    private final ExecutorService executorService;\n+    private final KafkaStreams kafkaStreams;\n+    private final KafkaStreamsTopologyManager kafkaStreamsTopologyManager;\n+\n+    @Inject\n+    public KafkaStreamsProducer(KafkaStreamsSupport kafkaStreamsSupport, KafkaStreamsRuntimeConfig runtimeConfig,\n+            Instance<Topology> topology, Instance<KafkaClientSupplier> kafkaClientSupplier,\n+            Instance<StateListener> stateListener, Instance<StateRestoreListener> globalStateRestoreListener) {\n+        // No producer for Topology -> nothing to do\n+        if (topology.isUnsatisfied()) {\n+            LOGGER.debug(\"No Topology producer; Kafka Streams will not be started\");\n+            this.executorService = null;\n+            this.kafkaStreams = null;\n+            this.kafkaStreamsTopologyManager = null;\n+            return;\n+        }\n+\n+        Properties buildTimeProperties = kafkaStreamsSupport.getProperties();\n+\n+        String bootstrapServersConfig = asString(runtimeConfig.bootstrapServers);\n+        Properties kafkaStreamsProperties = getStreamsProperties(buildTimeProperties, bootstrapServersConfig, runtimeConfig);\n+        Properties adminClientConfig = getAdminClientConfig(kafkaStreamsProperties);\n+\n+        this.executorService = Executors.newSingleThreadExecutor();\n+\n+        this.kafkaStreams = initializeKafkaStreams(kafkaStreamsProperties, runtimeConfig, adminClientConfig, topology.get(),\n+                kafkaClientSupplier, stateListener, globalStateRestoreListener, executorService);\n+        this.kafkaStreamsTopologyManager = new KafkaStreamsTopologyManager(adminClientConfig);\n+    }\n+\n+    @Produces\n+    @Singleton\n+    @Unremovable\n+    @Startup\n+    public KafkaStreams getKafkaStreams() {\n+        return kafkaStreams;\n+    }\n+\n+    @Produces\n+    @Singleton\n+    @Unremovable", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e2ebbb0f08f54d23c4d18d815dab56ee312e6bd"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEzODY0MQ==", "bodyText": "It was before so I mimic the existing behavior.", "url": "https://github.com/quarkusio/quarkus/pull/10726#discussion_r457138641", "createdAt": "2020-07-20T07:41:58Z", "author": {"login": "gsmet"}, "path": "extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsProducer.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package io.quarkus.kafka.streams.runtime;\n+\n+import java.net.InetSocketAddress;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.PreDestroy;\n+import javax.enterprise.inject.Instance;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import javax.inject.Singleton;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.ListTopicsResult;\n+import org.apache.kafka.common.config.SaslConfigs;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.streams.KafkaClientSupplier;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KafkaStreams.StateListener;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.processor.StateRestoreListener;\n+import org.jboss.logging.Logger;\n+\n+import io.quarkus.arc.Unremovable;\n+import io.quarkus.runtime.Startup;\n+\n+/**\n+ * Manages the lifecycle of a Kafka Streams pipeline. If there's a producer\n+ * method returning a KS {@link Topology}, then this topology will be configured\n+ * and started. Optionally, before starting the pipeline, this manager will wait\n+ * for a given set of topics to be created, as KS itself will fail without all\n+ * input topics being created upfront.\n+ */\n+@Singleton\n+public class KafkaStreamsProducer {\n+\n+    private static final Logger LOGGER = Logger.getLogger(KafkaStreamsProducer.class.getName());\n+\n+    private final ExecutorService executorService;\n+    private final KafkaStreams kafkaStreams;\n+    private final KafkaStreamsTopologyManager kafkaStreamsTopologyManager;\n+\n+    @Inject\n+    public KafkaStreamsProducer(KafkaStreamsSupport kafkaStreamsSupport, KafkaStreamsRuntimeConfig runtimeConfig,\n+            Instance<Topology> topology, Instance<KafkaClientSupplier> kafkaClientSupplier,\n+            Instance<StateListener> stateListener, Instance<StateRestoreListener> globalStateRestoreListener) {\n+        // No producer for Topology -> nothing to do\n+        if (topology.isUnsatisfied()) {\n+            LOGGER.debug(\"No Topology producer; Kafka Streams will not be started\");\n+            this.executorService = null;\n+            this.kafkaStreams = null;\n+            this.kafkaStreamsTopologyManager = null;\n+            return;\n+        }\n+\n+        Properties buildTimeProperties = kafkaStreamsSupport.getProperties();\n+\n+        String bootstrapServersConfig = asString(runtimeConfig.bootstrapServers);\n+        Properties kafkaStreamsProperties = getStreamsProperties(buildTimeProperties, bootstrapServersConfig, runtimeConfig);\n+        Properties adminClientConfig = getAdminClientConfig(kafkaStreamsProperties);\n+\n+        this.executorService = Executors.newSingleThreadExecutor();\n+\n+        this.kafkaStreams = initializeKafkaStreams(kafkaStreamsProperties, runtimeConfig, adminClientConfig, topology.get(),\n+                kafkaClientSupplier, stateListener, globalStateRestoreListener, executorService);\n+        this.kafkaStreamsTopologyManager = new KafkaStreamsTopologyManager(adminClientConfig);\n+    }\n+\n+    @Produces\n+    @Singleton\n+    @Unremovable\n+    @Startup\n+    public KafkaStreams getKafkaStreams() {\n+        return kafkaStreams;\n+    }\n+\n+    @Produces\n+    @Singleton\n+    @Unremovable", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzA3MjI2Mg=="}, "originalCommit": {"oid": "8e2ebbb0f08f54d23c4d18d815dab56ee312e6bd"}, "originalPosition": 95}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2496, "cost": 1, "resetAt": "2021-11-13T14:23:39Z"}}}