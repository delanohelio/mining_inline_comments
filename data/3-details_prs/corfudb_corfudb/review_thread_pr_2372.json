{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyMDQ5MDg4", "number": 2372, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMjowODoxMlrODd2OTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQyMDoxMDo1MVrOEHUL7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNjIzNjkzOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMjowODoxM1rOFmr6hA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwNjoxOTowOFrOFmzRtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEwOTcwMA==", "bodyText": "Where these functions just moved, or was there any change in logic?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r376109700", "createdAt": "2020-02-06T22:08:13Z", "author": {"login": "vjeko"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "diffHunk": "@@ -598,4 +505,136 @@ private Layout getHighestEpochLayout(Map<String, Layout> layoutMap) {\n                     return true;\n                 });\n     }\n+\n+    public static class ClusterHealth {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "837cb61b3768b6e2f6ea9b35bb2e930e6658a5cf"}, "originalPosition": 505}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjIzMDMyNw==", "bodyText": "Just moved from ManagementView to ClusterHealth", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r376230327", "createdAt": "2020-02-07T06:19:08Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "diffHunk": "@@ -598,4 +505,136 @@ private Layout getHighestEpochLayout(Map<String, Layout> layoutMap) {\n                     return true;\n                 });\n     }\n+\n+    public static class ClusterHealth {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEwOTcwMA=="}, "originalCommit": {"oid": "837cb61b3768b6e2f6ea9b35bb2e930e6658a5cf"}, "originalPosition": 505}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTQ2ODMwOnYy", "diffSide": "RIGHT", "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMToyNTozM1rOFnKvMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMzo0NDo1NVrOFodONQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYxNDcwNg==", "bodyText": "Can you please explain what the test does? What is the expected behavior and why.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r376614706", "createdAt": "2020-02-07T21:25:33Z", "author": {"login": "vjeko"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.ClusterStatusReport.ClusterStatus;\n+import org.corfudb.runtime.view.ManagementView.ClusterHealth;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ClusterHealthTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "837cb61b3768b6e2f6ea9b35bb2e930e6658a5cf"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2NjEzMw==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r377966133", "createdAt": "2020-02-11T23:44:55Z", "author": {"login": "xnull"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.ClusterStatusReport.ClusterStatus;\n+import org.corfudb.runtime.view.ManagementView.ClusterHealth;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ClusterHealthTest {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYxNDcwNg=="}, "originalCommit": {"oid": "837cb61b3768b6e2f6ea9b35bb2e930e6658a5cf"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTQ3MDkxOnYy", "diffSide": "RIGHT", "path": "runtime/src/test/java/org/corfudb/runtime/view/ManagementViewTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMToyNjozNFrOFnKwyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMzo0NDo1OVrOFodOSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYxNTExMg==", "bodyText": "Same here.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r376615112", "createdAt": "2020-02-07T21:26:34Z", "author": {"login": "vjeko"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ManagementViewTest.java", "diffHunk": "@@ -0,0 +1,56 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.ClusterStatusReport.NodeStatus;\n+import org.junit.jupiter.api.Test;\n+import org.mockito.Mockito;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+class ManagementViewTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "837cb61b3768b6e2f6ea9b35bb2e930e6658a5cf"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2NjE1Mw==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r377966153", "createdAt": "2020-02-11T23:44:59Z", "author": {"login": "xnull"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ManagementViewTest.java", "diffHunk": "@@ -0,0 +1,56 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.ClusterStatusReport.NodeStatus;\n+import org.junit.jupiter.api.Test;\n+import org.mockito.Mockito;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+class ManagementViewTest {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYxNTExMg=="}, "originalCommit": {"oid": "837cb61b3768b6e2f6ea9b35bb2e930e6658a5cf"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTczNjA2OnYy", "diffSide": "RIGHT", "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxNzoyNzoxN1rOGmcTmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQwNzoxMToxNlrOGmlNUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk2Mjg0Mw==", "bodyText": "This test is failing in CI. Seems timing related? Can it be made reliable?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r442962843", "createdAt": "2020-06-19T17:27:17Z", "author": {"login": "hisundar"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "diffHunk": "@@ -0,0 +1,36 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.ClusterStatusReport.ClusterStatus;\n+import org.corfudb.runtime.view.ManagementView.ClusterHealth;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ClusterHealthTest {\n+    private final LayoutUtil layoutUtil = new LayoutUtil();\n+\n+    /**\n+     * Get cluster status from a layout with all responsive nodes. Expected result is STABLE status\n+     */\n+    @Test\n+    public void testClusterHealth() {\n+        final String server1 = \"server1\";\n+        final String server2 = \"server2\";\n+        final String server3 = \"server3\";\n+\n+        final List<String> servers = Arrays.asList(server1, server2, server3);\n+        final Layout layout = layoutUtil.getLayout(servers);\n+        layout.setUnresponsiveServers(Arrays.asList(server3));\n+\n+        ClusterHealth clusterHealth = new ClusterHealth();\n+        ClusterStatus status = clusterHealth.getClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk2NzE0NA==", "bodyText": "will do it, thank you", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r442967144", "createdAt": "2020-06-19T17:37:41Z", "author": {"login": "xnull"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "diffHunk": "@@ -0,0 +1,36 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.ClusterStatusReport.ClusterStatus;\n+import org.corfudb.runtime.view.ManagementView.ClusterHealth;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ClusterHealthTest {\n+    private final LayoutUtil layoutUtil = new LayoutUtil();\n+\n+    /**\n+     * Get cluster status from a layout with all responsive nodes. Expected result is STABLE status\n+     */\n+    @Test\n+    public void testClusterHealth() {\n+        final String server1 = \"server1\";\n+        final String server2 = \"server2\";\n+        final String server3 = \"server3\";\n+\n+        final List<String> servers = Arrays.asList(server1, server2, server3);\n+        final Layout layout = layoutUtil.getLayout(servers);\n+        layout.setUnresponsiveServers(Arrays.asList(server3));\n+\n+        ClusterHealth clusterHealth = new ClusterHealth();\n+        ClusterStatus status = clusterHealth.getClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk2Mjg0Mw=="}, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzEwODY5MA==", "bodyText": "Sundar, there couldn't be any timing issues (unit test, no external invocations), my test was failing intentionally, I wanted to add more unit tests (that's why I made it failed) when I created this PR several months ago and then just forgot to add more tests.\nSo, I just added more cases for ClusterHealth, now everything is covered", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443108690", "createdAt": "2020-06-20T07:11:16Z", "author": {"login": "xnull"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "diffHunk": "@@ -0,0 +1,36 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.ClusterStatusReport.ClusterStatus;\n+import org.corfudb.runtime.view.ManagementView.ClusterHealth;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ClusterHealthTest {\n+    private final LayoutUtil layoutUtil = new LayoutUtil();\n+\n+    /**\n+     * Get cluster status from a layout with all responsive nodes. Expected result is STABLE status\n+     */\n+    @Test\n+    public void testClusterHealth() {\n+        final String server1 = \"server1\";\n+        final String server2 = \"server2\";\n+        final String server3 = \"server3\";\n+\n+        final List<String> servers = Arrays.asList(server1, server2, server3);\n+        final Layout layout = layoutUtil.getLayout(servers);\n+        layout.setUnresponsiveServers(Arrays.asList(server3));\n+\n+        ClusterHealth clusterHealth = new ClusterHealth();\n+        ClusterStatus status = clusterHealth.getClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk2Mjg0Mw=="}, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTg2MDA4OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxODoxNTo0MlrOGmdihw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQyMDowNzoxMVrOGmoIAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4MzA0Nw==", "bodyText": "shouldnt the cluster state always be 'unstable' in the absence of a quorum?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r442983047", "createdAt": "2020-06-19T18:15:42Z", "author": {"login": "pankti-m"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "diffHunk": "@@ -133,160 +138,41 @@ public void mergeSegments(@Nonnull String endpointToRestoreRedundancy, int retry\n         new RestoreRedundancyMergeSegments(endpointToRestoreRedundancy, runtime, retry, timeout, pollPeriod).invoke();\n     }\n \n-    /**\n-     * If all the layout servers are responsive the cluster status is STABLE,\n-     * if a minority of them are unresponsive then the status is DEGRADED,\n-     * else the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLayoutServersClusterHealth(Layout layout,\n-                                                        Set<String> peerResponsiveNodes) {\n-        ClusterStatus clusterStatus = ClusterStatus.STABLE;\n-        // A quorum of layout servers need to be responsive for the cluster to be STABLE.\n-        List<String> responsiveLayoutServers = new ArrayList<>(layout.getLayoutServers());\n-        // Retain only the responsive servers.\n-        responsiveLayoutServers.retainAll(peerResponsiveNodes);\n-        if (responsiveLayoutServers.size() != layout.getLayoutServers().size()) {\n-            clusterStatus = ClusterStatus.DEGRADED;\n-            int quorumSize = (layout.getLayoutServers().size() / 2) + 1;\n-            if (responsiveLayoutServers.size() < quorumSize) {\n-                clusterStatus = ClusterStatus.UNAVAILABLE;\n-            }\n-        }\n-        return clusterStatus;\n-    }\n-\n-    /**\n-     * If the primary sequencer is unresponsive then the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getSequencerServersClusterHealth(Layout layout,\n-                                                           Set<String> peerResponsiveNodes) {\n-        // The primary sequencer should be reachable for the cluster to be STABLE.\n-        return !peerResponsiveNodes.contains(layout.getPrimarySequencer())\n-                ? ClusterStatus.UNAVAILABLE : ClusterStatus.STABLE;\n-    }\n-\n-    /**\n-     * Gets the log unit cluster status based on the replication protocol.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLogUnitServersClusterHealth(Layout layout,\n-                                                         Set<String> peerResponsiveNodes) {\n-        // logUnitRedundancyStatus marks the cluster as DB_SYNCING if any of the nodes is performing\n-        // stateTransfer and is in process of achieving full redundancy.\n-        ClusterStatus logUnitRedundancyStatus = peerResponsiveNodes.stream()\n-                .anyMatch(s -> getLogUnitNodeStatusInLayout(layout, s) == NodeStatus.DB_SYNCING)\n-                ? ClusterStatus.DB_SYNCING : ClusterStatus.STABLE;\n-        // Check the availability of the log servers in all segments as reads to all addresses\n-        // should be accessible.\n-        ClusterStatus logunitClusterStatus = layout.getSegments().stream()\n-                .map(segment -> segment.getReplicationMode()\n-                        .getClusterHealthForSegment(segment, peerResponsiveNodes))\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-        // Gets max of cluster status and logUnitRedundancyStatus.\n-        return Stream.of(logunitClusterStatus, logUnitRedundancyStatus)\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Analyzes the health of the cluster based on the views of the cluster of all the\n-     * ManagementAgents.\n-     * STABLE: if all nodes in the layout are responsive.\n-     * DEGRADED: if a minority of Layout servers\n-     * or a minority of LogUnit servers - in QUORUM_REPLICATION mode only are unresponsive.\n-     * UNAVAILABLE: if a majority of Layout servers or the Primary Sequencer\n-     * or a node in the CHAIN_REPLICATION or a majority of nodes in QUORUM_REPLICATION is\n-     * unresponsive.\n-     *\n-     * @param layout              Layout based on which the health is analyzed.\n-     * @param peerResponsiveNodes Responsive nodes according to the management services.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getClusterHealth(Layout layout, Set<String> peerResponsiveNodes) {\n-\n-        return Stream.of(getLayoutServersClusterHealth(layout, peerResponsiveNodes),\n-                getSequencerServersClusterHealth(layout, peerResponsiveNodes),\n-                getLogUnitServersClusterHealth(layout, peerResponsiveNodes))\n-                // Gets cluster status from the layout, sequencer and log unit clusters.\n-                // The status is then aggregated by the max of the 3 statuses acquired.\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Returns a LogUnit Server's status in the layout. It is marked as:\n-     * UP if it is present in all segments or none of the segments and not in the unresponsive list,\n-     * NOTE: A node is UP if its not in any of the segments as it might not be a LogUnit component\n-     * but has only the Layout or the Sequencer (or both) component(s) active.\n-     * DB_SYNCING if it is present in some but not all or none of the segments,\n-     * DOWN if it is present in the unresponsive servers list.\n-     *\n-     * @param layout Layout to check.\n-     * @param server LogUnit Server endpoint.\n-     * @return NodeState with respect to the layout specified.\n-     */\n-    private NodeStatus getLogUnitNodeStatusInLayout(Layout layout, String server) {\n-        if (layout.getUnresponsiveServers().contains(server)) {\n-            return NodeStatus.DOWN;\n-        }\n-        final int segmentsCount = layout.getSegments().size();\n-        int nodeInSegments = 0;\n-        for (LayoutSegment layoutSegment : layout.getSegments()) {\n-            if (layoutSegment.getAllLogServers().contains(server)) {\n-                nodeInSegments++;\n-            }\n-        }\n-        return nodeInSegments == segmentsCount || nodeInSegments == 0\n-                ? NodeStatus.UP : NodeStatus.DB_SYNCING;\n-    }\n-\n     /**\n      * Get the Cluster Status.\n-     *\n+     * <p>\n      * This is reported as follows:\n      * - (1) The status of the cluster itself (regardless of clients connectivity) as reflected in the\n-     *   layout. This information is presented along each node's status (up, down, db_sync).\n-     *\n-     *   It is important to note that as the cluster state is obtained from the layout,\n-     *   when quorum is not available (majority of nodes) there are lower guarantees on the\n-     *   reliability of this state.\n-     *   For example, in the absence of quorum the system might be in an unstable state which\n-     *   cannot converge due to lack of consensus. This is reflected in the\n-     *   cluster status report as clusterStatusReliability.\n-     *\n+     * layout. This information is presented along each node's status (up, down, db_sync).\n+     * <p>\n+     * It is important to note that as the cluster state is obtained from the layout,\n+     * when quorum is not available (majority of nodes) there are lower guarantees on the\n+     * reliability of this state.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzEwODEzNQ==", "bodyText": "As I know, on the client-side it's not possible to know exactly what the cluster state in case of a failure, but if the client can't connect to a server in the cluster it doesn't mean the cluster in the DEGRADED state.\n@annym can explain better than me.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443108135", "createdAt": "2020-06-20T07:01:11Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "diffHunk": "@@ -133,160 +138,41 @@ public void mergeSegments(@Nonnull String endpointToRestoreRedundancy, int retry\n         new RestoreRedundancyMergeSegments(endpointToRestoreRedundancy, runtime, retry, timeout, pollPeriod).invoke();\n     }\n \n-    /**\n-     * If all the layout servers are responsive the cluster status is STABLE,\n-     * if a minority of them are unresponsive then the status is DEGRADED,\n-     * else the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLayoutServersClusterHealth(Layout layout,\n-                                                        Set<String> peerResponsiveNodes) {\n-        ClusterStatus clusterStatus = ClusterStatus.STABLE;\n-        // A quorum of layout servers need to be responsive for the cluster to be STABLE.\n-        List<String> responsiveLayoutServers = new ArrayList<>(layout.getLayoutServers());\n-        // Retain only the responsive servers.\n-        responsiveLayoutServers.retainAll(peerResponsiveNodes);\n-        if (responsiveLayoutServers.size() != layout.getLayoutServers().size()) {\n-            clusterStatus = ClusterStatus.DEGRADED;\n-            int quorumSize = (layout.getLayoutServers().size() / 2) + 1;\n-            if (responsiveLayoutServers.size() < quorumSize) {\n-                clusterStatus = ClusterStatus.UNAVAILABLE;\n-            }\n-        }\n-        return clusterStatus;\n-    }\n-\n-    /**\n-     * If the primary sequencer is unresponsive then the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getSequencerServersClusterHealth(Layout layout,\n-                                                           Set<String> peerResponsiveNodes) {\n-        // The primary sequencer should be reachable for the cluster to be STABLE.\n-        return !peerResponsiveNodes.contains(layout.getPrimarySequencer())\n-                ? ClusterStatus.UNAVAILABLE : ClusterStatus.STABLE;\n-    }\n-\n-    /**\n-     * Gets the log unit cluster status based on the replication protocol.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLogUnitServersClusterHealth(Layout layout,\n-                                                         Set<String> peerResponsiveNodes) {\n-        // logUnitRedundancyStatus marks the cluster as DB_SYNCING if any of the nodes is performing\n-        // stateTransfer and is in process of achieving full redundancy.\n-        ClusterStatus logUnitRedundancyStatus = peerResponsiveNodes.stream()\n-                .anyMatch(s -> getLogUnitNodeStatusInLayout(layout, s) == NodeStatus.DB_SYNCING)\n-                ? ClusterStatus.DB_SYNCING : ClusterStatus.STABLE;\n-        // Check the availability of the log servers in all segments as reads to all addresses\n-        // should be accessible.\n-        ClusterStatus logunitClusterStatus = layout.getSegments().stream()\n-                .map(segment -> segment.getReplicationMode()\n-                        .getClusterHealthForSegment(segment, peerResponsiveNodes))\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-        // Gets max of cluster status and logUnitRedundancyStatus.\n-        return Stream.of(logunitClusterStatus, logUnitRedundancyStatus)\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Analyzes the health of the cluster based on the views of the cluster of all the\n-     * ManagementAgents.\n-     * STABLE: if all nodes in the layout are responsive.\n-     * DEGRADED: if a minority of Layout servers\n-     * or a minority of LogUnit servers - in QUORUM_REPLICATION mode only are unresponsive.\n-     * UNAVAILABLE: if a majority of Layout servers or the Primary Sequencer\n-     * or a node in the CHAIN_REPLICATION or a majority of nodes in QUORUM_REPLICATION is\n-     * unresponsive.\n-     *\n-     * @param layout              Layout based on which the health is analyzed.\n-     * @param peerResponsiveNodes Responsive nodes according to the management services.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getClusterHealth(Layout layout, Set<String> peerResponsiveNodes) {\n-\n-        return Stream.of(getLayoutServersClusterHealth(layout, peerResponsiveNodes),\n-                getSequencerServersClusterHealth(layout, peerResponsiveNodes),\n-                getLogUnitServersClusterHealth(layout, peerResponsiveNodes))\n-                // Gets cluster status from the layout, sequencer and log unit clusters.\n-                // The status is then aggregated by the max of the 3 statuses acquired.\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Returns a LogUnit Server's status in the layout. It is marked as:\n-     * UP if it is present in all segments or none of the segments and not in the unresponsive list,\n-     * NOTE: A node is UP if its not in any of the segments as it might not be a LogUnit component\n-     * but has only the Layout or the Sequencer (or both) component(s) active.\n-     * DB_SYNCING if it is present in some but not all or none of the segments,\n-     * DOWN if it is present in the unresponsive servers list.\n-     *\n-     * @param layout Layout to check.\n-     * @param server LogUnit Server endpoint.\n-     * @return NodeState with respect to the layout specified.\n-     */\n-    private NodeStatus getLogUnitNodeStatusInLayout(Layout layout, String server) {\n-        if (layout.getUnresponsiveServers().contains(server)) {\n-            return NodeStatus.DOWN;\n-        }\n-        final int segmentsCount = layout.getSegments().size();\n-        int nodeInSegments = 0;\n-        for (LayoutSegment layoutSegment : layout.getSegments()) {\n-            if (layoutSegment.getAllLogServers().contains(server)) {\n-                nodeInSegments++;\n-            }\n-        }\n-        return nodeInSegments == segmentsCount || nodeInSegments == 0\n-                ? NodeStatus.UP : NodeStatus.DB_SYNCING;\n-    }\n-\n     /**\n      * Get the Cluster Status.\n-     *\n+     * <p>\n      * This is reported as follows:\n      * - (1) The status of the cluster itself (regardless of clients connectivity) as reflected in the\n-     *   layout. This information is presented along each node's status (up, down, db_sync).\n-     *\n-     *   It is important to note that as the cluster state is obtained from the layout,\n-     *   when quorum is not available (majority of nodes) there are lower guarantees on the\n-     *   reliability of this state.\n-     *   For example, in the absence of quorum the system might be in an unstable state which\n-     *   cannot converge due to lack of consensus. This is reflected in the\n-     *   cluster status report as clusterStatusReliability.\n-     *\n+     * layout. This information is presented along each node's status (up, down, db_sync).\n+     * <p>\n+     * It is important to note that as the cluster state is obtained from the layout,\n+     * when quorum is not available (majority of nodes) there are lower guarantees on the\n+     * reliability of this state.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4MzA0Nw=="}, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1NjQ4MQ==", "bodyText": "exactly, the fact that a client cannot connect to all 3 servers, does not necessarily imply that the Cluster is UNSTABLE, probably it's all up and running, it's just this client who cannot connect to it. That is why reading the cluster status should consider reliability and connection status, to get an overall look.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443156481", "createdAt": "2020-06-20T20:07:11Z", "author": {"login": "annym"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "diffHunk": "@@ -133,160 +138,41 @@ public void mergeSegments(@Nonnull String endpointToRestoreRedundancy, int retry\n         new RestoreRedundancyMergeSegments(endpointToRestoreRedundancy, runtime, retry, timeout, pollPeriod).invoke();\n     }\n \n-    /**\n-     * If all the layout servers are responsive the cluster status is STABLE,\n-     * if a minority of them are unresponsive then the status is DEGRADED,\n-     * else the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLayoutServersClusterHealth(Layout layout,\n-                                                        Set<String> peerResponsiveNodes) {\n-        ClusterStatus clusterStatus = ClusterStatus.STABLE;\n-        // A quorum of layout servers need to be responsive for the cluster to be STABLE.\n-        List<String> responsiveLayoutServers = new ArrayList<>(layout.getLayoutServers());\n-        // Retain only the responsive servers.\n-        responsiveLayoutServers.retainAll(peerResponsiveNodes);\n-        if (responsiveLayoutServers.size() != layout.getLayoutServers().size()) {\n-            clusterStatus = ClusterStatus.DEGRADED;\n-            int quorumSize = (layout.getLayoutServers().size() / 2) + 1;\n-            if (responsiveLayoutServers.size() < quorumSize) {\n-                clusterStatus = ClusterStatus.UNAVAILABLE;\n-            }\n-        }\n-        return clusterStatus;\n-    }\n-\n-    /**\n-     * If the primary sequencer is unresponsive then the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getSequencerServersClusterHealth(Layout layout,\n-                                                           Set<String> peerResponsiveNodes) {\n-        // The primary sequencer should be reachable for the cluster to be STABLE.\n-        return !peerResponsiveNodes.contains(layout.getPrimarySequencer())\n-                ? ClusterStatus.UNAVAILABLE : ClusterStatus.STABLE;\n-    }\n-\n-    /**\n-     * Gets the log unit cluster status based on the replication protocol.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLogUnitServersClusterHealth(Layout layout,\n-                                                         Set<String> peerResponsiveNodes) {\n-        // logUnitRedundancyStatus marks the cluster as DB_SYNCING if any of the nodes is performing\n-        // stateTransfer and is in process of achieving full redundancy.\n-        ClusterStatus logUnitRedundancyStatus = peerResponsiveNodes.stream()\n-                .anyMatch(s -> getLogUnitNodeStatusInLayout(layout, s) == NodeStatus.DB_SYNCING)\n-                ? ClusterStatus.DB_SYNCING : ClusterStatus.STABLE;\n-        // Check the availability of the log servers in all segments as reads to all addresses\n-        // should be accessible.\n-        ClusterStatus logunitClusterStatus = layout.getSegments().stream()\n-                .map(segment -> segment.getReplicationMode()\n-                        .getClusterHealthForSegment(segment, peerResponsiveNodes))\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-        // Gets max of cluster status and logUnitRedundancyStatus.\n-        return Stream.of(logunitClusterStatus, logUnitRedundancyStatus)\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Analyzes the health of the cluster based on the views of the cluster of all the\n-     * ManagementAgents.\n-     * STABLE: if all nodes in the layout are responsive.\n-     * DEGRADED: if a minority of Layout servers\n-     * or a minority of LogUnit servers - in QUORUM_REPLICATION mode only are unresponsive.\n-     * UNAVAILABLE: if a majority of Layout servers or the Primary Sequencer\n-     * or a node in the CHAIN_REPLICATION or a majority of nodes in QUORUM_REPLICATION is\n-     * unresponsive.\n-     *\n-     * @param layout              Layout based on which the health is analyzed.\n-     * @param peerResponsiveNodes Responsive nodes according to the management services.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getClusterHealth(Layout layout, Set<String> peerResponsiveNodes) {\n-\n-        return Stream.of(getLayoutServersClusterHealth(layout, peerResponsiveNodes),\n-                getSequencerServersClusterHealth(layout, peerResponsiveNodes),\n-                getLogUnitServersClusterHealth(layout, peerResponsiveNodes))\n-                // Gets cluster status from the layout, sequencer and log unit clusters.\n-                // The status is then aggregated by the max of the 3 statuses acquired.\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Returns a LogUnit Server's status in the layout. It is marked as:\n-     * UP if it is present in all segments or none of the segments and not in the unresponsive list,\n-     * NOTE: A node is UP if its not in any of the segments as it might not be a LogUnit component\n-     * but has only the Layout or the Sequencer (or both) component(s) active.\n-     * DB_SYNCING if it is present in some but not all or none of the segments,\n-     * DOWN if it is present in the unresponsive servers list.\n-     *\n-     * @param layout Layout to check.\n-     * @param server LogUnit Server endpoint.\n-     * @return NodeState with respect to the layout specified.\n-     */\n-    private NodeStatus getLogUnitNodeStatusInLayout(Layout layout, String server) {\n-        if (layout.getUnresponsiveServers().contains(server)) {\n-            return NodeStatus.DOWN;\n-        }\n-        final int segmentsCount = layout.getSegments().size();\n-        int nodeInSegments = 0;\n-        for (LayoutSegment layoutSegment : layout.getSegments()) {\n-            if (layoutSegment.getAllLogServers().contains(server)) {\n-                nodeInSegments++;\n-            }\n-        }\n-        return nodeInSegments == segmentsCount || nodeInSegments == 0\n-                ? NodeStatus.UP : NodeStatus.DB_SYNCING;\n-    }\n-\n     /**\n      * Get the Cluster Status.\n-     *\n+     * <p>\n      * This is reported as follows:\n      * - (1) The status of the cluster itself (regardless of clients connectivity) as reflected in the\n-     *   layout. This information is presented along each node's status (up, down, db_sync).\n-     *\n-     *   It is important to note that as the cluster state is obtained from the layout,\n-     *   when quorum is not available (majority of nodes) there are lower guarantees on the\n-     *   reliability of this state.\n-     *   For example, in the absence of quorum the system might be in an unstable state which\n-     *   cannot converge due to lack of consensus. This is reflected in the\n-     *   cluster status report as clusterStatusReliability.\n-     *\n+     * layout. This information is presented along each node's status (up, down, db_sync).\n+     * <p>\n+     * It is important to note that as the cluster state is obtained from the layout,\n+     * when quorum is not available (majority of nodes) there are lower guarantees on the\n+     * reliability of this state.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4MzA0Nw=="}, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTg2MzAzOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxODoxNzowNlrOGmdkjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQwNzowMjo1N1rOGmlLpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4MzU2Nw==", "bodyText": "Can you add an example output in the comment?  It is not clear what all info is displayed/collected..", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r442983567", "createdAt": "2020-06-19T18:17:06Z", "author": {"login": "pankti-m"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "diffHunk": "@@ -133,160 +138,41 @@ public void mergeSegments(@Nonnull String endpointToRestoreRedundancy, int retry\n         new RestoreRedundancyMergeSegments(endpointToRestoreRedundancy, runtime, retry, timeout, pollPeriod).invoke();\n     }\n \n-    /**\n-     * If all the layout servers are responsive the cluster status is STABLE,\n-     * if a minority of them are unresponsive then the status is DEGRADED,\n-     * else the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLayoutServersClusterHealth(Layout layout,\n-                                                        Set<String> peerResponsiveNodes) {\n-        ClusterStatus clusterStatus = ClusterStatus.STABLE;\n-        // A quorum of layout servers need to be responsive for the cluster to be STABLE.\n-        List<String> responsiveLayoutServers = new ArrayList<>(layout.getLayoutServers());\n-        // Retain only the responsive servers.\n-        responsiveLayoutServers.retainAll(peerResponsiveNodes);\n-        if (responsiveLayoutServers.size() != layout.getLayoutServers().size()) {\n-            clusterStatus = ClusterStatus.DEGRADED;\n-            int quorumSize = (layout.getLayoutServers().size() / 2) + 1;\n-            if (responsiveLayoutServers.size() < quorumSize) {\n-                clusterStatus = ClusterStatus.UNAVAILABLE;\n-            }\n-        }\n-        return clusterStatus;\n-    }\n-\n-    /**\n-     * If the primary sequencer is unresponsive then the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getSequencerServersClusterHealth(Layout layout,\n-                                                           Set<String> peerResponsiveNodes) {\n-        // The primary sequencer should be reachable for the cluster to be STABLE.\n-        return !peerResponsiveNodes.contains(layout.getPrimarySequencer())\n-                ? ClusterStatus.UNAVAILABLE : ClusterStatus.STABLE;\n-    }\n-\n-    /**\n-     * Gets the log unit cluster status based on the replication protocol.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLogUnitServersClusterHealth(Layout layout,\n-                                                         Set<String> peerResponsiveNodes) {\n-        // logUnitRedundancyStatus marks the cluster as DB_SYNCING if any of the nodes is performing\n-        // stateTransfer and is in process of achieving full redundancy.\n-        ClusterStatus logUnitRedundancyStatus = peerResponsiveNodes.stream()\n-                .anyMatch(s -> getLogUnitNodeStatusInLayout(layout, s) == NodeStatus.DB_SYNCING)\n-                ? ClusterStatus.DB_SYNCING : ClusterStatus.STABLE;\n-        // Check the availability of the log servers in all segments as reads to all addresses\n-        // should be accessible.\n-        ClusterStatus logunitClusterStatus = layout.getSegments().stream()\n-                .map(segment -> segment.getReplicationMode()\n-                        .getClusterHealthForSegment(segment, peerResponsiveNodes))\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-        // Gets max of cluster status and logUnitRedundancyStatus.\n-        return Stream.of(logunitClusterStatus, logUnitRedundancyStatus)\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Analyzes the health of the cluster based on the views of the cluster of all the\n-     * ManagementAgents.\n-     * STABLE: if all nodes in the layout are responsive.\n-     * DEGRADED: if a minority of Layout servers\n-     * or a minority of LogUnit servers - in QUORUM_REPLICATION mode only are unresponsive.\n-     * UNAVAILABLE: if a majority of Layout servers or the Primary Sequencer\n-     * or a node in the CHAIN_REPLICATION or a majority of nodes in QUORUM_REPLICATION is\n-     * unresponsive.\n-     *\n-     * @param layout              Layout based on which the health is analyzed.\n-     * @param peerResponsiveNodes Responsive nodes according to the management services.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getClusterHealth(Layout layout, Set<String> peerResponsiveNodes) {\n-\n-        return Stream.of(getLayoutServersClusterHealth(layout, peerResponsiveNodes),\n-                getSequencerServersClusterHealth(layout, peerResponsiveNodes),\n-                getLogUnitServersClusterHealth(layout, peerResponsiveNodes))\n-                // Gets cluster status from the layout, sequencer and log unit clusters.\n-                // The status is then aggregated by the max of the 3 statuses acquired.\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Returns a LogUnit Server's status in the layout. It is marked as:\n-     * UP if it is present in all segments or none of the segments and not in the unresponsive list,\n-     * NOTE: A node is UP if its not in any of the segments as it might not be a LogUnit component\n-     * but has only the Layout or the Sequencer (or both) component(s) active.\n-     * DB_SYNCING if it is present in some but not all or none of the segments,\n-     * DOWN if it is present in the unresponsive servers list.\n-     *\n-     * @param layout Layout to check.\n-     * @param server LogUnit Server endpoint.\n-     * @return NodeState with respect to the layout specified.\n-     */\n-    private NodeStatus getLogUnitNodeStatusInLayout(Layout layout, String server) {\n-        if (layout.getUnresponsiveServers().contains(server)) {\n-            return NodeStatus.DOWN;\n-        }\n-        final int segmentsCount = layout.getSegments().size();\n-        int nodeInSegments = 0;\n-        for (LayoutSegment layoutSegment : layout.getSegments()) {\n-            if (layoutSegment.getAllLogServers().contains(server)) {\n-                nodeInSegments++;\n-            }\n-        }\n-        return nodeInSegments == segmentsCount || nodeInSegments == 0\n-                ? NodeStatus.UP : NodeStatus.DB_SYNCING;\n-    }\n-\n     /**\n      * Get the Cluster Status.\n-     *\n+     * <p>\n      * This is reported as follows:\n      * - (1) The status of the cluster itself (regardless of clients connectivity) as reflected in the\n-     *   layout. This information is presented along each node's status (up, down, db_sync).\n-     *\n-     *   It is important to note that as the cluster state is obtained from the layout,\n-     *   when quorum is not available (majority of nodes) there are lower guarantees on the\n-     *   reliability of this state.\n-     *   For example, in the absence of quorum the system might be in an unstable state which\n-     *   cannot converge due to lack of consensus. This is reflected in the\n-     *   cluster status report as clusterStatusReliability.\n-     *\n+     * layout. This information is presented along each node's status (up, down, db_sync).\n+     * <p>\n+     * It is important to note that as the cluster state is obtained from the layout,\n+     * when quorum is not available (majority of nodes) there are lower guarantees on the\n+     * reliability of this state.\n+     * For example, in the absence of quorum the system might be in an unstable state which\n+     * cannot converge due to lack of consensus. This is reflected in the\n+     * cluster status report as clusterStatusReliability.\n+     * <p>\n      * - (2) The connectivity status of the client to every node in the cluster,\n-     *   i.e., can the client connect to the cluster. This will be obtained by\n-     *   ping(ing) every node and show as RESPONSIVE, for successful connections or UNRESPONSIVE for\n-     *   clients unable to communicate.\n-     *\n-     *  In this sense a cluster can be STABLE with all nodes UP, while not being available for a\n-     *  client, as all connections from the client to the cluster nodes are down, showing in this\n-     *  case connectivity status to all nodes as UNRESPONSIVE.\n-     *\n-     *  The ClusterStatusReport consists of the following:\n-     *\n-     *  CLUSTER-SPECIFIC STATUS\n-     *  - clusterStatus: the cluster status a perceived by the system's layout.\n-     *  STABLE, DEGRADED, DB_SYNCING or UNAVAILABLE\n-     *  - nodeStatusMap: each node's status as perceived by the system's layout.\n-     *  (UP, DOWN or DB_SYNC)\n-     *  - Cluster Status Reliability: STRONG_QUORUM, WEAK_NO_QUORUM or UNAVAILABLE\n-     *\n-     *  CLIENT-CLUSTER SPECIFIC STATUS:\n-     *  - clientServerConnectivityStatusMap: the connectivity status of this client to the cluster.\n-     *    (RESPONSIVE, UNRESPONSIVE).\n+     * i.e., can the client connect to the cluster. This will be obtained by\n+     * ping(ing) every node and show as RESPONSIVE, for successful connections or UNRESPONSIVE for\n+     * clients unable to communicate.\n+     * <p>\n+     * In this sense a cluster can be STABLE with all nodes UP, while not being available for a\n+     * client, as all connections from the client to the cluster nodes are down, showing in this\n+     * case connectivity status to all nodes as UNRESPONSIVE.\n+     * <p>\n+     * The ClusterStatusReport consists of the following:\n+     * <p>\n+     * CLUSTER-SPECIFIC STATUS\n+     * - clusterStatus: the cluster status a perceived by the system's layout.\n+     * STABLE, DEGRADED, DB_SYNCING or UNAVAILABLE\n+     * - nodeStatusMap: each node's status as perceived by the system's layout.\n+     * (UP, DOWN or DB_SYNC)\n+     * - Cluster Status Reliability: STRONG_QUORUM, WEAK_NO_QUORUM or UNAVAILABLE\n+     * <p>\n+     * CLIENT-CLUSTER SPECIFIC STATUS:\n+     * - clientServerConnectivityStatusMap: the connectivity status of this client to the cluster.\n+     * (RESPONSIVE, UNRESPONSIVE).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzEwODI2Mg==", "bodyText": "Didn't get your question. There could be only one of those two states RESPONSIVE or UNRESPONSIVE", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443108262", "createdAt": "2020-06-20T07:02:57Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/ManagementView.java", "diffHunk": "@@ -133,160 +138,41 @@ public void mergeSegments(@Nonnull String endpointToRestoreRedundancy, int retry\n         new RestoreRedundancyMergeSegments(endpointToRestoreRedundancy, runtime, retry, timeout, pollPeriod).invoke();\n     }\n \n-    /**\n-     * If all the layout servers are responsive the cluster status is STABLE,\n-     * if a minority of them are unresponsive then the status is DEGRADED,\n-     * else the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLayoutServersClusterHealth(Layout layout,\n-                                                        Set<String> peerResponsiveNodes) {\n-        ClusterStatus clusterStatus = ClusterStatus.STABLE;\n-        // A quorum of layout servers need to be responsive for the cluster to be STABLE.\n-        List<String> responsiveLayoutServers = new ArrayList<>(layout.getLayoutServers());\n-        // Retain only the responsive servers.\n-        responsiveLayoutServers.retainAll(peerResponsiveNodes);\n-        if (responsiveLayoutServers.size() != layout.getLayoutServers().size()) {\n-            clusterStatus = ClusterStatus.DEGRADED;\n-            int quorumSize = (layout.getLayoutServers().size() / 2) + 1;\n-            if (responsiveLayoutServers.size() < quorumSize) {\n-                clusterStatus = ClusterStatus.UNAVAILABLE;\n-            }\n-        }\n-        return clusterStatus;\n-    }\n-\n-    /**\n-     * If the primary sequencer is unresponsive then the cluster is UNAVAILABLE.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getSequencerServersClusterHealth(Layout layout,\n-                                                           Set<String> peerResponsiveNodes) {\n-        // The primary sequencer should be reachable for the cluster to be STABLE.\n-        return !peerResponsiveNodes.contains(layout.getPrimarySequencer())\n-                ? ClusterStatus.UNAVAILABLE : ClusterStatus.STABLE;\n-    }\n-\n-    /**\n-     * Gets the log unit cluster status based on the replication protocol.\n-     *\n-     * @param layout              Current layout on which responsiveness was checked.\n-     * @param peerResponsiveNodes responsive nodes in the current layout.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getLogUnitServersClusterHealth(Layout layout,\n-                                                         Set<String> peerResponsiveNodes) {\n-        // logUnitRedundancyStatus marks the cluster as DB_SYNCING if any of the nodes is performing\n-        // stateTransfer and is in process of achieving full redundancy.\n-        ClusterStatus logUnitRedundancyStatus = peerResponsiveNodes.stream()\n-                .anyMatch(s -> getLogUnitNodeStatusInLayout(layout, s) == NodeStatus.DB_SYNCING)\n-                ? ClusterStatus.DB_SYNCING : ClusterStatus.STABLE;\n-        // Check the availability of the log servers in all segments as reads to all addresses\n-        // should be accessible.\n-        ClusterStatus logunitClusterStatus = layout.getSegments().stream()\n-                .map(segment -> segment.getReplicationMode()\n-                        .getClusterHealthForSegment(segment, peerResponsiveNodes))\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-        // Gets max of cluster status and logUnitRedundancyStatus.\n-        return Stream.of(logunitClusterStatus, logUnitRedundancyStatus)\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Analyzes the health of the cluster based on the views of the cluster of all the\n-     * ManagementAgents.\n-     * STABLE: if all nodes in the layout are responsive.\n-     * DEGRADED: if a minority of Layout servers\n-     * or a minority of LogUnit servers - in QUORUM_REPLICATION mode only are unresponsive.\n-     * UNAVAILABLE: if a majority of Layout servers or the Primary Sequencer\n-     * or a node in the CHAIN_REPLICATION or a majority of nodes in QUORUM_REPLICATION is\n-     * unresponsive.\n-     *\n-     * @param layout              Layout based on which the health is analyzed.\n-     * @param peerResponsiveNodes Responsive nodes according to the management services.\n-     * @return ClusterStatus\n-     */\n-    private ClusterStatus getClusterHealth(Layout layout, Set<String> peerResponsiveNodes) {\n-\n-        return Stream.of(getLayoutServersClusterHealth(layout, peerResponsiveNodes),\n-                getSequencerServersClusterHealth(layout, peerResponsiveNodes),\n-                getLogUnitServersClusterHealth(layout, peerResponsiveNodes))\n-                // Gets cluster status from the layout, sequencer and log unit clusters.\n-                // The status is then aggregated by the max of the 3 statuses acquired.\n-                .max(Comparator.comparingInt(ClusterStatus::getHealthValue))\n-                .orElse(ClusterStatus.UNAVAILABLE);\n-    }\n-\n-    /**\n-     * Returns a LogUnit Server's status in the layout. It is marked as:\n-     * UP if it is present in all segments or none of the segments and not in the unresponsive list,\n-     * NOTE: A node is UP if its not in any of the segments as it might not be a LogUnit component\n-     * but has only the Layout or the Sequencer (or both) component(s) active.\n-     * DB_SYNCING if it is present in some but not all or none of the segments,\n-     * DOWN if it is present in the unresponsive servers list.\n-     *\n-     * @param layout Layout to check.\n-     * @param server LogUnit Server endpoint.\n-     * @return NodeState with respect to the layout specified.\n-     */\n-    private NodeStatus getLogUnitNodeStatusInLayout(Layout layout, String server) {\n-        if (layout.getUnresponsiveServers().contains(server)) {\n-            return NodeStatus.DOWN;\n-        }\n-        final int segmentsCount = layout.getSegments().size();\n-        int nodeInSegments = 0;\n-        for (LayoutSegment layoutSegment : layout.getSegments()) {\n-            if (layoutSegment.getAllLogServers().contains(server)) {\n-                nodeInSegments++;\n-            }\n-        }\n-        return nodeInSegments == segmentsCount || nodeInSegments == 0\n-                ? NodeStatus.UP : NodeStatus.DB_SYNCING;\n-    }\n-\n     /**\n      * Get the Cluster Status.\n-     *\n+     * <p>\n      * This is reported as follows:\n      * - (1) The status of the cluster itself (regardless of clients connectivity) as reflected in the\n-     *   layout. This information is presented along each node's status (up, down, db_sync).\n-     *\n-     *   It is important to note that as the cluster state is obtained from the layout,\n-     *   when quorum is not available (majority of nodes) there are lower guarantees on the\n-     *   reliability of this state.\n-     *   For example, in the absence of quorum the system might be in an unstable state which\n-     *   cannot converge due to lack of consensus. This is reflected in the\n-     *   cluster status report as clusterStatusReliability.\n-     *\n+     * layout. This information is presented along each node's status (up, down, db_sync).\n+     * <p>\n+     * It is important to note that as the cluster state is obtained from the layout,\n+     * when quorum is not available (majority of nodes) there are lower guarantees on the\n+     * reliability of this state.\n+     * For example, in the absence of quorum the system might be in an unstable state which\n+     * cannot converge due to lack of consensus. This is reflected in the\n+     * cluster status report as clusterStatusReliability.\n+     * <p>\n      * - (2) The connectivity status of the client to every node in the cluster,\n-     *   i.e., can the client connect to the cluster. This will be obtained by\n-     *   ping(ing) every node and show as RESPONSIVE, for successful connections or UNRESPONSIVE for\n-     *   clients unable to communicate.\n-     *\n-     *  In this sense a cluster can be STABLE with all nodes UP, while not being available for a\n-     *  client, as all connections from the client to the cluster nodes are down, showing in this\n-     *  case connectivity status to all nodes as UNRESPONSIVE.\n-     *\n-     *  The ClusterStatusReport consists of the following:\n-     *\n-     *  CLUSTER-SPECIFIC STATUS\n-     *  - clusterStatus: the cluster status a perceived by the system's layout.\n-     *  STABLE, DEGRADED, DB_SYNCING or UNAVAILABLE\n-     *  - nodeStatusMap: each node's status as perceived by the system's layout.\n-     *  (UP, DOWN or DB_SYNC)\n-     *  - Cluster Status Reliability: STRONG_QUORUM, WEAK_NO_QUORUM or UNAVAILABLE\n-     *\n-     *  CLIENT-CLUSTER SPECIFIC STATUS:\n-     *  - clientServerConnectivityStatusMap: the connectivity status of this client to the cluster.\n-     *    (RESPONSIVE, UNRESPONSIVE).\n+     * i.e., can the client connect to the cluster. This will be obtained by\n+     * ping(ing) every node and show as RESPONSIVE, for successful connections or UNRESPONSIVE for\n+     * clients unable to communicate.\n+     * <p>\n+     * In this sense a cluster can be STABLE with all nodes UP, while not being available for a\n+     * client, as all connections from the client to the cluster nodes are down, showing in this\n+     * case connectivity status to all nodes as UNRESPONSIVE.\n+     * <p>\n+     * The ClusterStatusReport consists of the following:\n+     * <p>\n+     * CLUSTER-SPECIFIC STATUS\n+     * - clusterStatus: the cluster status a perceived by the system's layout.\n+     * STABLE, DEGRADED, DB_SYNCING or UNAVAILABLE\n+     * - nodeStatusMap: each node's status as perceived by the system's layout.\n+     * (UP, DOWN or DB_SYNC)\n+     * - Cluster Status Reliability: STRONG_QUORUM, WEAK_NO_QUORUM or UNAVAILABLE\n+     * <p>\n+     * CLIENT-CLUSTER SPECIFIC STATUS:\n+     * - clientServerConnectivityStatusMap: the connectivity status of this client to the cluster.\n+     * (RESPONSIVE, UNRESPONSIVE).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4MzU2Nw=="}, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1OTg2NDkyOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/view/Layout.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQxODoxNzo1M1rOGmdluA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQwNjo1NzoyOVrOGmlKbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4Mzg2NA==", "bodyText": "what about the degraded state?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r442983864", "createdAt": "2020-06-19T18:17:53Z", "author": {"login": "pankti-m"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/Layout.java", "diffHunk": "@@ -375,10 +375,10 @@ public IReplicationProtocol getReplicationProtocol(CorfuRuntime r) {\n             }\n \n             @Override\n-            public ClusterStatus getClusterHealthForSegment(LayoutSegment layoutSegment,\n-                                                            Set<String> responsiveNodes) {\n-                return !responsiveNodes.containsAll(layoutSegment.getAllLogServers())\n-                        ? ClusterStatus.UNAVAILABLE : ClusterStatus.STABLE;\n+            public ClusterStatus getClusterHealthForSegment(\n+                    LayoutSegment layoutSegment, Set<String> responsiveNodes) {\n+                return responsiveNodes.containsAll(layoutSegment.getAllLogServers())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzEwNzk0OQ==", "bodyText": "it's not possible for a chain replication. If at least one node failed, the status gets UNAVAILABLE", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443107949", "createdAt": "2020-06-20T06:57:29Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/Layout.java", "diffHunk": "@@ -375,10 +375,10 @@ public IReplicationProtocol getReplicationProtocol(CorfuRuntime r) {\n             }\n \n             @Override\n-            public ClusterStatus getClusterHealthForSegment(LayoutSegment layoutSegment,\n-                                                            Set<String> responsiveNodes) {\n-                return !responsiveNodes.containsAll(layoutSegment.getAllLogServers())\n-                        ? ClusterStatus.UNAVAILABLE : ClusterStatus.STABLE;\n+            public ClusterStatus getClusterHealthForSegment(\n+                    LayoutSegment layoutSegment, Set<String> responsiveNodes) {\n+                return responsiveNodes.containsAll(layoutSegment.getAllLogServers())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4Mzg2NA=="}, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MDY2MjIxOnYy", "diffSide": "RIGHT", "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQwNTo0NDowNFrOGmk7oQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQwNzoxMjoxNFrOGmlNiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzEwNDE2MQ==", "bodyText": "Looks like server3 is still in the layout segment, so log unit servers' health is unavailable.\nThe expected overall status should be degraded, right? Since the layout server status is 2/3 active.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443104161", "createdAt": "2020-06-20T05:44:04Z", "author": {"login": "zhangn49"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "diffHunk": "@@ -0,0 +1,36 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.ClusterStatusReport.ClusterStatus;\n+import org.corfudb.runtime.view.ManagementView.ClusterHealth;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ClusterHealthTest {\n+    private final LayoutUtil layoutUtil = new LayoutUtil();\n+\n+    /**\n+     * Get cluster status from a layout with all responsive nodes. Expected result is STABLE status\n+     */\n+    @Test\n+    public void testClusterHealth() {\n+        final String server1 = \"server1\";\n+        final String server2 = \"server2\";\n+        final String server3 = \"server3\";\n+\n+        final List<String> servers = Arrays.asList(server1, server2, server3);\n+        final Layout layout = layoutUtil.getLayout(servers);\n+        layout.setUnresponsiveServers(Arrays.asList(server3));\n+\n+        ClusterHealth clusterHealth = new ClusterHealth();\n+        ClusterStatus status = clusterHealth.getClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzEwODc0NA==", "bodyText": "I just added more tests, your case also covered\n\nThe expected overall status should be degraded, right?\n\nyes", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443108744", "createdAt": "2020-06-20T07:12:14Z", "author": {"login": "xnull"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "diffHunk": "@@ -0,0 +1,36 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.ClusterStatusReport.ClusterStatus;\n+import org.corfudb.runtime.view.ManagementView.ClusterHealth;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ClusterHealthTest {\n+    private final LayoutUtil layoutUtil = new LayoutUtil();\n+\n+    /**\n+     * Get cluster status from a layout with all responsive nodes. Expected result is STABLE status\n+     */\n+    @Test\n+    public void testClusterHealth() {\n+        final String server1 = \"server1\";\n+        final String server2 = \"server2\";\n+        final String server3 = \"server3\";\n+\n+        final List<String> servers = Arrays.asList(server1, server2, server3);\n+        final Layout layout = layoutUtil.getLayout(servers);\n+        layout.setUnresponsiveServers(Arrays.asList(server3));\n+\n+        ClusterHealth clusterHealth = new ClusterHealth();\n+        ClusterStatus status = clusterHealth.getClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzEwNDE2MQ=="}, "originalCommit": {"oid": "4dae49e8b7379f3ad9a6c3c34dd1f47b23fe6bcd"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MTA2MTU2OnYy", "diffSide": "RIGHT", "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQyMDowOToyMlrOGmoIfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMVQwMDo1ODowNFrOGmpCEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1NjYwNg==", "bodyText": "How different is this test from queryClusterStatus in ManagementViewTest ?\nThis test already exists and it actually is a bit more complete...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443156606", "createdAt": "2020-06-20T20:09:22Z", "author": {"login": "annym"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "diffHunk": "@@ -0,0 +1,117 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.ClusterStatusReport.ClusterStatus;\n+import org.corfudb.runtime.view.ManagementView.ClusterHealth;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ClusterHealthTest {\n+    private final LayoutUtil layoutUtil = new LayoutUtil();\n+\n+    private final String server1 = \"server1\";\n+    private final String server2 = \"server2\";\n+    private final String server3 = \"server3\";\n+    private final List<String> servers = Arrays.asList(server1, server2, server3);\n+\n+    private final ClusterHealth clusterHealth = new ClusterHealth();\n+\n+    /**\n+     * Test possible cluster statuses for layout servers\n+     */\n+    @Test\n+    public void testLayoutServersHealth(){\n+        Layout layout = layoutUtil.getLayout(servers);\n+        ClusterStatus status = clusterHealth.getLayoutServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);\n+\n+        layout.setUnresponsiveServers(Collections.singletonList(server3));\n+        status = clusterHealth.getLayoutServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.DEGRADED);\n+\n+        layout.setUnresponsiveServers(Arrays.asList(server2, server3));\n+        status = clusterHealth.getLayoutServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);\n+    }\n+\n+    /**\n+     * Test possible cluster statuses for sequencer servers\n+     */\n+    @Test\n+    public void testSequencerServersHealth(){\n+        Layout layout = layoutUtil.getLayout(servers);\n+        layout.setUnresponsiveServers(Collections.singletonList(server3));\n+\n+        ClusterStatus status = clusterHealth.getSequencerServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);\n+\n+        //Unresponsive sequencer\n+        layout.setUnresponsiveServers(Collections.singletonList(server1));\n+        status = clusterHealth.getSequencerServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);\n+    }\n+\n+    /**\n+     * Test possible cluster statuses for LogUnit servers\n+     */\n+    @Test\n+    public void testLogUnitServersClusterHealth(){\n+        Layout layout = layoutUtil.getLayout(servers);\n+\n+        ClusterStatus status = clusterHealth.getLogUnitServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);\n+\n+        //invalid segment\n+        layout.setUnresponsiveServers(Collections.singletonList(server3));\n+        status = clusterHealth.getLogUnitServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);\n+\n+        //exclude unresponsive server\n+        layout.getFirstSegment().getFirstStripe().getLogServers().remove(server3);\n+        status = clusterHealth.getLogUnitServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);\n+    }\n+\n+    /**\n+     * Get cluster status from a layout with all responsive nodes.\n+     * Expected result is STABLE status\n+     */\n+    @Test\n+    public void testClusterHealth() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af3142f62fd8bed2fbf659758ea590400ee54b44"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE3MTM0Nw==", "bodyText": "That test is more an Integration Test, this one is a unit test.\nNo need to start an entire cluster, no side effects from the environment, the unit test is much simpler.\nI think we need both - integration and unit tests even if some tests are similar.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443171347", "createdAt": "2020-06-21T00:58:04Z", "author": {"login": "xnull"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ClusterHealthTest.java", "diffHunk": "@@ -0,0 +1,117 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.ClusterStatusReport.ClusterStatus;\n+import org.corfudb.runtime.view.ManagementView.ClusterHealth;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ClusterHealthTest {\n+    private final LayoutUtil layoutUtil = new LayoutUtil();\n+\n+    private final String server1 = \"server1\";\n+    private final String server2 = \"server2\";\n+    private final String server3 = \"server3\";\n+    private final List<String> servers = Arrays.asList(server1, server2, server3);\n+\n+    private final ClusterHealth clusterHealth = new ClusterHealth();\n+\n+    /**\n+     * Test possible cluster statuses for layout servers\n+     */\n+    @Test\n+    public void testLayoutServersHealth(){\n+        Layout layout = layoutUtil.getLayout(servers);\n+        ClusterStatus status = clusterHealth.getLayoutServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);\n+\n+        layout.setUnresponsiveServers(Collections.singletonList(server3));\n+        status = clusterHealth.getLayoutServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.DEGRADED);\n+\n+        layout.setUnresponsiveServers(Arrays.asList(server2, server3));\n+        status = clusterHealth.getLayoutServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);\n+    }\n+\n+    /**\n+     * Test possible cluster statuses for sequencer servers\n+     */\n+    @Test\n+    public void testSequencerServersHealth(){\n+        Layout layout = layoutUtil.getLayout(servers);\n+        layout.setUnresponsiveServers(Collections.singletonList(server3));\n+\n+        ClusterStatus status = clusterHealth.getSequencerServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);\n+\n+        //Unresponsive sequencer\n+        layout.setUnresponsiveServers(Collections.singletonList(server1));\n+        status = clusterHealth.getSequencerServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);\n+    }\n+\n+    /**\n+     * Test possible cluster statuses for LogUnit servers\n+     */\n+    @Test\n+    public void testLogUnitServersClusterHealth(){\n+        Layout layout = layoutUtil.getLayout(servers);\n+\n+        ClusterStatus status = clusterHealth.getLogUnitServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);\n+\n+        //invalid segment\n+        layout.setUnresponsiveServers(Collections.singletonList(server3));\n+        status = clusterHealth.getLogUnitServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);\n+\n+        //exclude unresponsive server\n+        layout.getFirstSegment().getFirstStripe().getLogServers().remove(server3);\n+        status = clusterHealth.getLogUnitServersClusterHealth(\n+                layout, layout.getAllActiveServers()\n+        );\n+        assertThat(status).isEqualTo(ClusterStatus.STABLE);\n+    }\n+\n+    /**\n+     * Get cluster status from a layout with all responsive nodes.\n+     * Expected result is STABLE status\n+     */\n+    @Test\n+    public void testClusterHealth() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1NjYwNg=="}, "originalCommit": {"oid": "af3142f62fd8bed2fbf659758ea590400ee54b44"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MTA2MTYyOnYy", "diffSide": "RIGHT", "path": "runtime/src/test/java/org/corfudb/runtime/view/LayoutUtil.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQyMDowOTozOVrOGmoIiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMVQwNDo1NTo1M1rOGmpqrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1NjYxNg==", "bodyText": "Please add class description...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443156616", "createdAt": "2020-06-20T20:09:39Z", "author": {"login": "annym"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/LayoutUtil.java", "diffHunk": "@@ -0,0 +1,30 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.Layout.LayoutSegment;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.UUID;\n+\n+public class LayoutUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af3142f62fd8bed2fbf659758ea590400ee54b44"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE4MTc0MA==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443181740", "createdAt": "2020-06-21T04:55:53Z", "author": {"login": "xnull"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/LayoutUtil.java", "diffHunk": "@@ -0,0 +1,30 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.view.Layout.LayoutSegment;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.UUID;\n+\n+public class LayoutUtil {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1NjYxNg=="}, "originalCommit": {"oid": "af3142f62fd8bed2fbf659758ea590400ee54b44"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2MTA2MjIxOnYy", "diffSide": "RIGHT", "path": "runtime/src/test/java/org/corfudb/runtime/view/ManagementViewTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQyMDoxMDo1MVrOGmoI1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMVQwNDo1NTozNFrOGmpqng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1NjY5Mw==", "bodyText": "This test already exists in queryClusterStatus in this same file.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443156693", "createdAt": "2020-06-20T20:10:51Z", "author": {"login": "annym"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ManagementViewTest.java", "diffHunk": "@@ -0,0 +1,59 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.ClusterStatusReport.NodeStatus;\n+import org.junit.jupiter.api.Test;\n+import org.mockito.Mockito;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+class ManagementViewTest {\n+    private final LayoutUtil layoutUtil = new LayoutUtil();\n+    private final ManagementView managementView = new ManagementView(Mockito.mock(CorfuRuntime.class));\n+\n+    /**\n+     * Check that getting a quorum layout from the list of layouts works as expected\n+     */\n+    @Test\n+    void testGetLayoutForQuorum() {\n+        final String server1 = \"server1\";\n+        final String server2 = \"server2\";\n+        final String server3 = \"server3\";\n+\n+        final List<String> servers = Arrays.asList(server1, server2, server3);\n+        final Layout layout = layoutUtil.getLayout(servers);\n+\n+        Map<String, Layout> layouts = new HashMap<>();\n+\n+        servers.forEach(server -> layouts.put(server, layout));\n+\n+        Optional<Layout> quorumLayout = managementView.getLayoutFromQuorum(layouts, layouts.size() - 1);\n+        assertThat(quorumLayout).isEqualTo(Optional.of(layout));\n+\n+        quorumLayout = managementView.getLayoutFromQuorum(layouts, layouts.size());\n+        assertThat(quorumLayout).isEqualTo(Optional.of(layout));\n+\n+        quorumLayout = managementView.getLayoutFromQuorum(layouts, layouts.size() + 1);\n+        assertThat(quorumLayout).isEqualTo(Optional.empty());\n+    }\n+\n+    @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af3142f62fd8bed2fbf659758ea590400ee54b44"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE4MTcyNg==", "bodyText": "The advantages of the unit test:\n\nno side-effects (no need to start external services - netty, no need for network communication, etc)\nmuch faster\nsimpler to understand, simpler to find what causes the error.\n\nI could delete those checks in queryClusterStatus method if you would like to.\nAlso, I think it's ok to have integration and unit tests even if they check similar parameters.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2372#discussion_r443181726", "createdAt": "2020-06-21T04:55:34Z", "author": {"login": "xnull"}, "path": "runtime/src/test/java/org/corfudb/runtime/view/ManagementViewTest.java", "diffHunk": "@@ -0,0 +1,59 @@\n+package org.corfudb.runtime.view;\n+\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.ClusterStatusReport.NodeStatus;\n+import org.junit.jupiter.api.Test;\n+import org.mockito.Mockito;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+class ManagementViewTest {\n+    private final LayoutUtil layoutUtil = new LayoutUtil();\n+    private final ManagementView managementView = new ManagementView(Mockito.mock(CorfuRuntime.class));\n+\n+    /**\n+     * Check that getting a quorum layout from the list of layouts works as expected\n+     */\n+    @Test\n+    void testGetLayoutForQuorum() {\n+        final String server1 = \"server1\";\n+        final String server2 = \"server2\";\n+        final String server3 = \"server3\";\n+\n+        final List<String> servers = Arrays.asList(server1, server2, server3);\n+        final Layout layout = layoutUtil.getLayout(servers);\n+\n+        Map<String, Layout> layouts = new HashMap<>();\n+\n+        servers.forEach(server -> layouts.put(server, layout));\n+\n+        Optional<Layout> quorumLayout = managementView.getLayoutFromQuorum(layouts, layouts.size() - 1);\n+        assertThat(quorumLayout).isEqualTo(Optional.of(layout));\n+\n+        quorumLayout = managementView.getLayoutFromQuorum(layouts, layouts.size());\n+        assertThat(quorumLayout).isEqualTo(Optional.of(layout));\n+\n+        quorumLayout = managementView.getLayoutFromQuorum(layouts, layouts.size() + 1);\n+        assertThat(quorumLayout).isEqualTo(Optional.empty());\n+    }\n+\n+    @Test", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1NjY5Mw=="}, "originalCommit": {"oid": "af3142f62fd8bed2fbf659758ea590400ee54b44"}, "originalPosition": 46}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2085, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}