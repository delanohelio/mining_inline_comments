{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUyMTg3MTA5", "number": 2641, "reviewThreads": {"totalCount": 54, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjo0OToxM1rOERPusg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQwMToyNzozNlrOEUPfhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTE4OTYyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjo0OToxM1rOG124xA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwNjoxMjozN1rOG19WDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyNjk4MA==", "bodyText": "this TODO was going to be exactly my question. Are you returning 0, 1?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459126980", "createdAt": "2020-07-22T22:49:13Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -648,46 +647,26 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  Writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n-    public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n-        } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-        }\n-    }\n+    public void prepareToBecomeStandby() { }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n     public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            return replicationManager.queryReplicationStatus();\n-        } else {\n-            log.warn(\"Illegal queryReplicationStatus when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-            return INVALID_REPLICATION_STATUS;\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {\n+            return Integer.parseInt(logReplicationMetadataManager.getReplicationStatus());\n         }\n+        // TODO pankti - boolean cannot be parsed to int", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIzMjc4Mw==", "bodyText": "I changed it a bit but I think it will be best to change the metadata schema a bit and not have string for all types...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459232783", "createdAt": "2020-07-23T06:12:37Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -648,46 +647,26 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  Writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n-    public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n-        } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-        }\n-    }\n+    public void prepareToBecomeStandby() { }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n     public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            return replicationManager.queryReplicationStatus();\n-        } else {\n-            log.warn(\"Illegal queryReplicationStatus when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-            return INVALID_REPLICATION_STATUS;\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {\n+            return Integer.parseInt(logReplicationMetadataManager.getReplicationStatus());\n         }\n+        // TODO pankti - boolean cannot be parsed to int", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyNjk4MA=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTE5MjQwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjo1MDoyOFrOG126fA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjo1MDoyOFrOG126fA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyNzQyMA==", "bodyText": "we should probably have an else (localClusterDescriptor.getRole() == ClusterRole.Standby). Because what if the role of that node is INVALID, we probably shouldn't return anything and log an error/warning.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459127420", "createdAt": "2020-07-22T22:50:28Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -648,46 +647,26 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  Writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n-    public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n-        } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-        }\n-    }\n+    public void prepareToBecomeStandby() { }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n     public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            return replicationManager.queryReplicationStatus();\n-        } else {\n-            log.warn(\"Illegal queryReplicationStatus when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-            return INVALID_REPLICATION_STATUS;\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTIwNDAyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjo1NToxNlrOG13BGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjo1NToxNlrOG13BGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyOTExMg==", "bodyText": "this commented code can be removed right? and also please move the comment up to where the runtime is now being created so we keep this reminder around for future references.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459129112", "createdAt": "2020-07-22T22:55:16Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +67,108 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(0);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller = Executors.newSingleThreadScheduledExecutor();\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n+        this.parameters = params;\n \n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n+        this.config = parameters.getReplicationConfig();\n+        if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n+            // Avoid FSM being initialized if there are no streams to replicate\n+            throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n+        }\n \n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n+        DataSender dataSender = new CorfuDataSender(client);\n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTIwNzU1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjo1Njo0N1rOG13DHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwNTowNDo1MFrOG2jOPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyOTYyOQ==", "bodyText": "can we have the poll interval as a static field? we might want to also move this param to be configurable as we might need to adjust according to UI / SM polling frequency.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459129629", "createdAt": "2020-07-22T22:56:47Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +67,108 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(0);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller = Executors.newSingleThreadScheduledExecutor();\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n+        this.parameters = params;\n \n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n+        this.config = parameters.getReplicationConfig();\n+        if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n+            // Avoid FSM being initialized if there are no streams to replicate\n+            throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n+        }\n \n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n+        DataSender dataSender = new CorfuDataSender(client);\n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+\n+        this.logReplicationFSM = new LogReplicationFSM(this.runtime, config, params.getRemoteClusterDescriptor(),\n+                dataSender, readProcessor, logReplicationFSMWorkers);\n+\n+        this.logReplicationFSM.setTopologyConfigId(params.getTopologyConfigId());\n+\n+        this.metadataManager = metadataManager;\n+        lastAckedTsPoller.scheduleWithFixedDelay(new TsPollingTask(), 0, 15, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzMDA0OA==", "bodyText": "Also, it might be nice to give this thread some name that allows us to easily identify it.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459130048", "createdAt": "2020-07-22T22:57:51Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +67,108 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(0);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller = Executors.newSingleThreadScheduledExecutor();\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n+        this.parameters = params;\n \n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n+        this.config = parameters.getReplicationConfig();\n+        if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n+            // Avoid FSM being initialized if there are no streams to replicate\n+            throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n+        }\n \n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n+        DataSender dataSender = new CorfuDataSender(client);\n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+\n+        this.logReplicationFSM = new LogReplicationFSM(this.runtime, config, params.getRemoteClusterDescriptor(),\n+                dataSender, readProcessor, logReplicationFSMWorkers);\n+\n+        this.logReplicationFSM.setTopologyConfigId(params.getTopologyConfigId());\n+\n+        this.metadataManager = metadataManager;\n+        lastAckedTsPoller.scheduleWithFixedDelay(new TsPollingTask(), 0, 15, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyOTYyOQ=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIxNjkyMA==", "bodyText": "to make it configurable, will we have to make it a parameter of the serverContext?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459216920", "createdAt": "2020-07-23T05:08:32Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +67,108 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(0);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller = Executors.newSingleThreadScheduledExecutor();\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n+        this.parameters = params;\n \n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n+        this.config = parameters.getReplicationConfig();\n+        if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n+            // Avoid FSM being initialized if there are no streams to replicate\n+            throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n+        }\n \n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n+        DataSender dataSender = new CorfuDataSender(client);\n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+\n+        this.logReplicationFSM = new LogReplicationFSM(this.runtime, config, params.getRemoteClusterDescriptor(),\n+                dataSender, readProcessor, logReplicationFSMWorkers);\n+\n+        this.logReplicationFSM.setTopologyConfigId(params.getTopologyConfigId());\n+\n+        this.metadataManager = metadataManager;\n+        lastAckedTsPoller.scheduleWithFixedDelay(new TsPollingTask(), 0, 15, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyOTYyOQ=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg1MzM3Mw==", "bodyText": "Yes, if its too late to address in this PR you can add it to our issues list.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459853373", "createdAt": "2020-07-24T05:04:50Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +67,108 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(0);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller = Executors.newSingleThreadScheduledExecutor();\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n+        this.parameters = params;\n \n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n+        this.config = parameters.getReplicationConfig();\n+        if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n+            // Avoid FSM being initialized if there are no streams to replicate\n+            throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n+        }\n \n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n+        DataSender dataSender = new CorfuDataSender(client);\n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+\n+        this.logReplicationFSM = new LogReplicationFSM(this.runtime, config, params.getRemoteClusterDescriptor(),\n+                dataSender, readProcessor, logReplicationFSMWorkers);\n+\n+        this.logReplicationFSM.setTopologyConfigId(params.getTopologyConfigId());\n+\n+        this.metadataManager = metadataManager;\n+        lastAckedTsPoller.scheduleWithFixedDelay(new TsPollingTask(), 0, 15, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyOTYyOQ=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTIxNTM5OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzowMDoxMFrOG13HwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzowMDoxMFrOG13HwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzMDgxNg==", "bodyText": "this code seems to be repeated, right? We can call this(params, metadataManager, new DataSender(client)) from the above constructor and remove the repeated code?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459130816", "createdAt": "2020-07-22T23:00:10Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +67,108 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(0);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller = Executors.newSingleThreadScheduledExecutor();\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n+        this.parameters = params;\n \n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n+        this.config = parameters.getReplicationConfig();\n+        if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n+            // Avoid FSM being initialized if there are no streams to replicate\n+            throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n+        }\n \n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n+        DataSender dataSender = new CorfuDataSender(client);\n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+\n+        this.logReplicationFSM = new LogReplicationFSM(this.runtime, config, params.getRemoteClusterDescriptor(),\n+                dataSender, readProcessor, logReplicationFSMWorkers);\n+\n+        this.logReplicationFSM.setTopologyConfigId(params.getTopologyConfigId());\n+\n+        this.metadataManager = metadataManager;\n+        lastAckedTsPoller.scheduleWithFixedDelay(new TsPollingTask(), 0, 15, TimeUnit.SECONDS);\n     }\n \n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (transformation)\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n+    @VisibleForTesting\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params,\n+                                       LogReplicationMetadataManager metadataManager,\n+                                       DataSender dataSender) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 175}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTIyNDAzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzowNDoyMVrOG13M8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzowNDoyMVrOG13M8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzMjE0NQ==", "bodyText": "missing -> how many entries 'remain' to be...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459132145", "createdAt": "2020-07-22T23:04:21Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,16 +242,58 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long queryStreamTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp, calculate how many entries to be sent for all replicated streams.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 252}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTIyODYxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzowNjozMFrOG13PnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzowNjozMFrOG13PnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzMjgyOA==", "bodyText": "probably this is a good use case to have an API to query the tails of a specific set of streams. Not that we have to do this now or on this PR, but we can keep this in mind!", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459132828", "createdAt": "2020-07-22T23:06:30Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,16 +242,58 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long queryStreamTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 239}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTIzOTQzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzoxMTo1NFrOG13WIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwNTozMDoxNlrOG18rcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzNDQ5Ng==", "bodyText": "maybe the name of this method could be more suggestive, so when reading the calculateRemainingEntriesToSend it's easier to understand the flow, perhaps queryMaxReplicatedStreamsTail? (or something in that line)", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459134496", "createdAt": "2020-07-22T23:11:54Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,16 +242,58 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long queryStreamTail() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIyMTg3Mw==", "bodyText": "I changed it to getMaxReplicatedStreamsTail.  Let me know if it is clearer.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459221873", "createdAt": "2020-07-23T05:30:16Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,16 +242,58 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long queryStreamTail() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzNDQ5Ng=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 238}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTI0ODEyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMzoxNTo1NVrOG13bLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwNTowNjo0NVrOG2jPyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzNTc5MQ==", "bodyText": "Can we add a comment stating that this way of calculating the remaining entries to send might not be accurate...\nAlso, will we include the other precise option we discussed about?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459135791", "createdAt": "2020-07-22T23:15:55Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,16 +242,58 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long queryStreamTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp, calculate how many entries to be sent for all replicated streams.\n+     *\n+     * @param\n+     */\n+    private int calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long timestamp = queryStreamTail();\n+        long remainingEntriesToSend = timestamp - ackedTimestamp;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 258}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIyMzk2NQ==", "bodyText": "yes, I was not sure how to calculate that, but I think it should be in the same way - getAllTails().getStreamTails().filter(.....)", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459223965", "createdAt": "2020-07-23T05:38:48Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,16 +242,58 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long queryStreamTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp, calculate how many entries to be sent for all replicated streams.\n+     *\n+     * @param\n+     */\n+    private int calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long timestamp = queryStreamTail();\n+        long remainingEntriesToSend = timestamp - ackedTimestamp;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzNTc5MQ=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 258}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg1Mzc3MQ==", "bodyText": "Instead of the tails we need to query the address maps for each streams to replicate.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459853771", "createdAt": "2020-07-24T05:06:45Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,16 +242,58 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long queryStreamTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp, calculate how many entries to be sent for all replicated streams.\n+     *\n+     * @param\n+     */\n+    private int calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long timestamp = queryStreamTail();\n+        long remainingEntriesToSend = timestamp - ackedTimestamp;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEzNTc5MQ=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 258}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTM3NDc3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwMDoyMTozN1rOG14k-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwMzozNTozMVrOG37Wkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE1NDY4MA==", "bodyText": "I'm curious, if we update the topologyConfigId, do we always need to reset all other values? Let's say a new standby is added.. is this still needed?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459154680", "createdAt": "2020-07-23T00:21:37Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -91,61 +91,64 @@ public long query(CorfuStoreMetadata.Timestamp timestamp, LogReplicationMetadata\n     }\n \n     public long getTopologyConfigId() {\n-        return query(null, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        return query(null, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n     }\n \n-    public String getVersion() { return queryString(null, LogReplicationMetadataType.VERSION); }\n+    public String getVersion() { return queryString(null, LogReplicationMetadataKey.KeyType.VERSION); }\n \n     public long getLastSnapStartTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_START);\n     }\n \n \n     public long getLastSnapTransferDoneTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_TRANSFERRED);\n     }\n \n     public long getLastSrcBaseSnapshotTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_APPLIED);\n     }\n \n     public long getLastSnapSeqNum() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_SEQ_NUM);\n     }\n \n     public long getLastProcessedLogTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_LOG_PROCESSED);\n+        return query(null, LogReplicationMetadataKey.KeyType.LAST_LOG_ENTRY_PROCESSED);\n     }\n \n-    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, long val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType type, long val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(type).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(Long.toString(val)).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n-    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, String val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType key, String val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(val).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n     public void setupTopologyConfigId(long topologyConfigId) {\n         CorfuStoreMetadata.Timestamp timestamp = corfuStore.getTimestamp();\n-        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n \n         if (topologyConfigId <= persistedTopologyConfigId) {\n             log.warn(\"Skip setupTopologyConfigId. the current topologyConfigId \" + topologyConfigId + \" is not larger than the persistedTopologyConfigID \" + persistedTopologyConfigId);\n-            return;\n         }\n \n         TxBuilder txBuilder = corfuStore.tx(namespace);\n \n-        for (LogReplicationMetadataType key : LogReplicationMetadataType.values()) {\n+        // TODO pankti: Change to set the topology config id and not other fields.  This cannot be changed now as it\n+        // fails later if anything is found not set.\n+        for (LogReplicationMetadataKey.KeyType type : LogReplicationMetadataKey.KeyType.values()) {\n             long val = Address.NON_ADDRESS;\n-            if (key == LogReplicationMetadataType.TOPOLOGY_CONFIG_ID) {\n+            if (type == LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID) {\n                 val = topologyConfigId;\n             }\n-            appendUpdate(txBuilder, key, val);\n+            if (type != LogReplicationMetadataKey.KeyType.UNRECOGNIZED) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIyNTI3Nw==", "bodyText": "good question.  No we should not set everything, but that was being done when I made the change.  I removed it to only set topologyConfigId but later somewhere(I think negotiation response) we have a validation for version field not being empty, where it failed.  We should clean this up and fix it.\nI am thinking version is a valid thing to set in metadata so I can expose it in LogReplicationConfig alongwith streamsToReplicate.  But yes, here we should only set topologyConfigId.\nAlso, afaik topologyConfigId does not change when a standby is added.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459225277", "createdAt": "2020-07-23T05:44:20Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -91,61 +91,64 @@ public long query(CorfuStoreMetadata.Timestamp timestamp, LogReplicationMetadata\n     }\n \n     public long getTopologyConfigId() {\n-        return query(null, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        return query(null, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n     }\n \n-    public String getVersion() { return queryString(null, LogReplicationMetadataType.VERSION); }\n+    public String getVersion() { return queryString(null, LogReplicationMetadataKey.KeyType.VERSION); }\n \n     public long getLastSnapStartTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_START);\n     }\n \n \n     public long getLastSnapTransferDoneTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_TRANSFERRED);\n     }\n \n     public long getLastSrcBaseSnapshotTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_APPLIED);\n     }\n \n     public long getLastSnapSeqNum() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_SEQ_NUM);\n     }\n \n     public long getLastProcessedLogTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_LOG_PROCESSED);\n+        return query(null, LogReplicationMetadataKey.KeyType.LAST_LOG_ENTRY_PROCESSED);\n     }\n \n-    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, long val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType type, long val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(type).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(Long.toString(val)).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n-    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, String val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType key, String val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(val).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n     public void setupTopologyConfigId(long topologyConfigId) {\n         CorfuStoreMetadata.Timestamp timestamp = corfuStore.getTimestamp();\n-        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n \n         if (topologyConfigId <= persistedTopologyConfigId) {\n             log.warn(\"Skip setupTopologyConfigId. the current topologyConfigId \" + topologyConfigId + \" is not larger than the persistedTopologyConfigID \" + persistedTopologyConfigId);\n-            return;\n         }\n \n         TxBuilder txBuilder = corfuStore.tx(namespace);\n \n-        for (LogReplicationMetadataType key : LogReplicationMetadataType.values()) {\n+        // TODO pankti: Change to set the topology config id and not other fields.  This cannot be changed now as it\n+        // fails later if anything is found not set.\n+        for (LogReplicationMetadataKey.KeyType type : LogReplicationMetadataKey.KeyType.values()) {\n             long val = Address.NON_ADDRESS;\n-            if (key == LogReplicationMetadataType.TOPOLOGY_CONFIG_ID) {\n+            if (type == LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID) {\n                 val = topologyConfigId;\n             }\n-            appendUpdate(txBuilder, key, val);\n+            if (type != LogReplicationMetadataKey.KeyType.UNRECOGNIZED) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE1NDY4MA=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE5NDAzOA==", "bodyText": "I think we should not update other values in this function, because it causes more TX conflicts, and discovery service will shutdown. If the version filed is empty, we should initialize version somewhere...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461194038", "createdAt": "2020-07-27T21:57:05Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -91,61 +91,64 @@ public long query(CorfuStoreMetadata.Timestamp timestamp, LogReplicationMetadata\n     }\n \n     public long getTopologyConfigId() {\n-        return query(null, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        return query(null, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n     }\n \n-    public String getVersion() { return queryString(null, LogReplicationMetadataType.VERSION); }\n+    public String getVersion() { return queryString(null, LogReplicationMetadataKey.KeyType.VERSION); }\n \n     public long getLastSnapStartTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_START);\n     }\n \n \n     public long getLastSnapTransferDoneTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_TRANSFERRED);\n     }\n \n     public long getLastSrcBaseSnapshotTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_APPLIED);\n     }\n \n     public long getLastSnapSeqNum() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_SEQ_NUM);\n     }\n \n     public long getLastProcessedLogTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_LOG_PROCESSED);\n+        return query(null, LogReplicationMetadataKey.KeyType.LAST_LOG_ENTRY_PROCESSED);\n     }\n \n-    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, long val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType type, long val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(type).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(Long.toString(val)).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n-    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, String val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType key, String val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(val).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n     public void setupTopologyConfigId(long topologyConfigId) {\n         CorfuStoreMetadata.Timestamp timestamp = corfuStore.getTimestamp();\n-        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n \n         if (topologyConfigId <= persistedTopologyConfigId) {\n             log.warn(\"Skip setupTopologyConfigId. the current topologyConfigId \" + topologyConfigId + \" is not larger than the persistedTopologyConfigID \" + persistedTopologyConfigId);\n-            return;\n         }\n \n         TxBuilder txBuilder = corfuStore.tx(namespace);\n \n-        for (LogReplicationMetadataType key : LogReplicationMetadataType.values()) {\n+        // TODO pankti: Change to set the topology config id and not other fields.  This cannot be changed now as it\n+        // fails later if anything is found not set.\n+        for (LogReplicationMetadataKey.KeyType type : LogReplicationMetadataKey.KeyType.values()) {\n             long val = Address.NON_ADDRESS;\n-            if (key == LogReplicationMetadataType.TOPOLOGY_CONFIG_ID) {\n+            if (type == LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID) {\n                 val = topologyConfigId;\n             }\n-            appendUpdate(txBuilder, key, val);\n+            if (type != LogReplicationMetadataKey.KeyType.UNRECOGNIZED) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE1NDY4MA=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI5NzI5OA==", "bodyText": "If the active cluster doesn't change, the source of data doesn't change, we don't need to reset the log replication metadata. So, we should have two API s:\n\njust  updateTopologyConfigId, if the active cluster doesn't change.\nupdate Topology Id and reset logReplicationMetadata if the active cluster change, as the source of data change.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461297298", "createdAt": "2020-07-28T03:35:31Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -91,61 +91,64 @@ public long query(CorfuStoreMetadata.Timestamp timestamp, LogReplicationMetadata\n     }\n \n     public long getTopologyConfigId() {\n-        return query(null, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        return query(null, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n     }\n \n-    public String getVersion() { return queryString(null, LogReplicationMetadataType.VERSION); }\n+    public String getVersion() { return queryString(null, LogReplicationMetadataKey.KeyType.VERSION); }\n \n     public long getLastSnapStartTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_START);\n     }\n \n \n     public long getLastSnapTransferDoneTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_TRANSFERRED);\n     }\n \n     public long getLastSrcBaseSnapshotTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_APPLIED);\n     }\n \n     public long getLastSnapSeqNum() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_SEQ_NUM);\n     }\n \n     public long getLastProcessedLogTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_LOG_PROCESSED);\n+        return query(null, LogReplicationMetadataKey.KeyType.LAST_LOG_ENTRY_PROCESSED);\n     }\n \n-    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, long val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType type, long val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(type).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(Long.toString(val)).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n-    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, String val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType key, String val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(val).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n     public void setupTopologyConfigId(long topologyConfigId) {\n         CorfuStoreMetadata.Timestamp timestamp = corfuStore.getTimestamp();\n-        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n \n         if (topologyConfigId <= persistedTopologyConfigId) {\n             log.warn(\"Skip setupTopologyConfigId. the current topologyConfigId \" + topologyConfigId + \" is not larger than the persistedTopologyConfigID \" + persistedTopologyConfigId);\n-            return;\n         }\n \n         TxBuilder txBuilder = corfuStore.tx(namespace);\n \n-        for (LogReplicationMetadataType key : LogReplicationMetadataType.values()) {\n+        // TODO pankti: Change to set the topology config id and not other fields.  This cannot be changed now as it\n+        // fails later if anything is found not set.\n+        for (LogReplicationMetadataKey.KeyType type : LogReplicationMetadataKey.KeyType.values()) {\n             long val = Address.NON_ADDRESS;\n-            if (key == LogReplicationMetadataType.TOPOLOGY_CONFIG_ID) {\n+            if (type == LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID) {\n                 val = topologyConfigId;\n             }\n-            appendUpdate(txBuilder, key, val);\n+            if (type != LogReplicationMetadataKey.KeyType.UNRECOGNIZED) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE1NDY4MA=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTM5NDYyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/SinkBufferManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwMDozMzowMVrOG14wdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwMDozMzowMVrOG14wdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE1NzYyMg==", "bodyText": "We can remove this commented code.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459157622", "createdAt": "2020-07-23T00:33:01Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/SinkBufferManager.java", "diffHunk": "@@ -161,6 +161,10 @@ public LogReplicationEntry processMsgAndBuffer(LogReplicationEntry dataMessage)\n         return null;\n     }\n \n+    /*private int calculateRemainingEntriesToReplicate() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTQwMjU3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwMDozNzoyOFrOG1409w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwNTo1MjoxN1rOG19AJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE1ODc3NQ==", "bodyText": "Do we need an executor service for the standby? Cause it would only be updated to true (or 100) once the snapshot is applied, right? so we can just do it directly, instead of having a thread for this every 15 seconds... anyways its not changing.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459158775", "createdAt": "2020-07-23T00:37:28Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -79,6 +84,13 @@\n     @Getter\n     private ObservableValue rxMessageCount = new ObservableValue(rxMessageCounter);\n \n+    /*\n+     * Periodic Thread which reads the sequence number of entries processed\n+     */\n+    private ScheduledExecutorService lastReplicatedEntryPoller = Executors.newSingleThreadScheduledExecutor();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIyNzE3NQ==", "bodyText": "good idea.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459227175", "createdAt": "2020-07-23T05:52:17Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -79,6 +84,13 @@\n     @Getter\n     private ObservableValue rxMessageCount = new ObservableValue(rxMessageCounter);\n \n+    /*\n+     * Periodic Thread which reads the sequence number of entries processed\n+     */\n+    private ScheduledExecutorService lastReplicatedEntryPoller = Executors.newSingleThreadScheduledExecutor();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE1ODc3NQ=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTQxMTc0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwMDo0MzowNVrOG146UQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwMDo0MzowNVrOG146UQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE2MDE0NQ==", "bodyText": "rxState needs to be thread safe right?\nAlso, do we really need this distinction? anyways if it is in LOG_ENTRY_SYNC , data_consistent was set to true (maybe we need to confirm that it is set to true even if on re-instantiation it enters directly in log entry sync)", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459160145", "createdAt": "2020-07-23T00:43:05Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -386,4 +402,24 @@ public void shutdown() {\n         SNAPSHOT_SYNC,\n         LOG_ENTRY_SYNC\n     }\n+\n+    /**\n+     * In Snapshot Sync, if the StreamsSnapshotWriter is in the apply phase, the data is not yet\n+     * consistent and cannot be read by applications.  Data is always consistent during Log Entry Sync,\n+     * so always return true in that case.\n+     * @return boolean\n+     */\n+    private boolean isDataConsistent() {\n+        if (RxState.LOG_ENTRY_SYNC == rxState) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTQxODI3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwMDo0Njo0N1rOG14-Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QwMzo1Njo0OVrOG17eMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE2MTExMQ==", "bodyText": "Pankti, do we have any test?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459161111", "createdAt": "2020-07-23T00:46:47Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -648,46 +647,26 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  Writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n-    public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n-        } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-        }\n-    }\n+    public void prepareToBecomeStandby() { }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n     public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            return replicationManager.queryReplicationStatus();\n-        } else {\n-            log.warn(\"Illegal queryReplicationStatus when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-            return INVALID_REPLICATION_STATUS;\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {\n+            return Integer.parseInt(logReplicationMetadataManager.getReplicationStatus());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIwMjA5OA==", "bodyText": "no.. I did not add any tests for this change", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459202098", "createdAt": "2020-07-23T03:56:49Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -648,46 +647,26 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  Writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n-    public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n-        } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-        }\n-    }\n+    public void prepareToBecomeStandby() { }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n     public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            return replicationManager.queryReplicationStatus();\n-        } else {\n-            log.warn(\"Illegal queryReplicationStatus when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-            return INVALID_REPLICATION_STATUS;\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {\n+            return Integer.parseInt(logReplicationMetadataManager.getReplicationStatus());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTE2MTExMQ=="}, "originalCommit": {"oid": "885eb3bff6b5f8440469a6e1f95049d1d48017f7"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2ODU5MTYwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxODozOTo0MlrOG2W8qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxOTo0NzoyM1rOG27xXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1MjI2Nw==", "bodyText": "Do we still need this function?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459652267", "createdAt": "2020-07-23T18:39:42Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -648,46 +648,29 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  Writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n-    public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n-        } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-        }\n-    }\n+    public void prepareToBecomeStandby() { }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86a7762a977595715cf79214e59c879f74a7a8bf"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2NjcyMA==", "bodyText": "We do not do anything here, but the SiteManager has a workflow for prepareToBecomeStandby().  So the SM adapter calls this function.  We can change the adapter to not invoke and remove this function, but I thought it is better to keep it in case something needs to be added here in future.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459666720", "createdAt": "2020-07-23T19:05:55Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -648,46 +648,29 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  Writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n-    public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n-        } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-        }\n-    }\n+    public void prepareToBecomeStandby() { }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1MjI2Nw=="}, "originalCommit": {"oid": "86a7762a977595715cf79214e59c879f74a7a8bf"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI1NTU4Mw==", "bodyText": "Pankti I was thinking given this, it might be safe to have a logging? .. not that we would do anything, but at least if they claim to have started the workflow we can confirm.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r460255583", "createdAt": "2020-07-24T19:47:23Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -648,46 +648,29 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  Writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n-    public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n-        } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-        }\n-    }\n+    public void prepareToBecomeStandby() { }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1MjI2Nw=="}, "originalCommit": {"oid": "86a7762a977595715cf79214e59c879f74a7a8bf"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2ODYyMzA3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxODo0ODozMVrOG2XQUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxOTowODozMlrOG2X6dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1NzI5Nw==", "bodyText": "Looks like remainingEntriesToSend is not used?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459657297", "createdAt": "2020-07-23T18:48:31Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,16 +221,61 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp\n+     * Note: This method of calculating the remaining entries to send is inaccurate because we consider the tail\n+     * of all streams(replicated and otherwise) in Corfu and compare it with the current entry sent.  It is possible\n+     * that the tail is far ahead but replicated streams have few entries to send.\n+     */\n+    private int calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long timestamp = getMaxReplicatedStreamsTail();\n+        long remainingEntriesToSend = timestamp - ackedTimestamp;\n+        int percentDone = (int) (ackedTimestamp/timestamp * 100);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a7f5abb89e68b88cd5edab548637f916f62a511"}, "originalPosition": 244}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2ODA4Ng==", "bodyText": "right.  I intended to use it somehow to calculate the remaining entries in a more accurate way, but it is not needed now.  Will remove.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459668086", "createdAt": "2020-07-23T19:08:32Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,16 +221,61 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp\n+     * Note: This method of calculating the remaining entries to send is inaccurate because we consider the tail\n+     * of all streams(replicated and otherwise) in Corfu and compare it with the current entry sent.  It is possible\n+     * that the tail is far ahead but replicated streams have few entries to send.\n+     */\n+    private int calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long timestamp = getMaxReplicatedStreamsTail();\n+        long remainingEntriesToSend = timestamp - ackedTimestamp;\n+        int percentDone = (int) (ackedTimestamp/timestamp * 100);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1NzI5Nw=="}, "originalCommit": {"oid": "6a7f5abb89e68b88cd5edab548637f916f62a511"}, "originalPosition": 244}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2ODYzNjgxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxODo1MjozMVrOG2XY3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxOTowOTo0NFrOG2X8uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1OTQ4NA==", "bodyText": "Can we have a short comment on this dataConsistent?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459659484", "createdAt": "2020-07-23T18:52:31Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -79,6 +81,8 @@\n     @Getter\n     private ObservableValue rxMessageCount = new ObservableValue(rxMessageCounter);\n \n+    private AtomicInteger dataConsistent = new AtomicInteger(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a7f5abb89e68b88cd5edab548637f916f62a511"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2ODY2Nw==", "bodyText": "I have it in initCommonParams() where it first gets initialized but can move it here.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459668667", "createdAt": "2020-07-23T19:09:44Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -79,6 +81,8 @@\n     @Getter\n     private ObservableValue rxMessageCount = new ObservableValue(rxMessageCounter);\n \n+    private AtomicInteger dataConsistent = new AtomicInteger(1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1OTQ4NA=="}, "originalCommit": {"oid": "6a7f5abb89e68b88cd5edab548637f916f62a511"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTQ1Mjk0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QyMzo0MDo0OVrOG2fIPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTozNDoxMVrOG2gy9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc4NjMwMQ==", "bodyText": "I am a little confused about why the dataConsistent is initialized as 1.\nIf a SNAPSHOT_MESSAGE comes, dataConsistent is still 1. Is it correct?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459786301", "createdAt": "2020-07-23T23:40:49Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -311,14 +313,17 @@ private void applySnapshotSync(LogReplicationEntry message) {\n         switch (message.getMetadata().getMessageMetadataType()) {\n             case SNAPSHOT_MESSAGE:\n                 snapshotWriter.apply(message);\n-                return;\n+                break;\n             case SNAPSHOT_END:\n+                dataConsistent.set(0);\n+                logReplicationMetadataManager.setDataConsistentOnStandby(String.valueOf(dataConsistent));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ff6b7041f13a0f5ca789ba2f351f3f79153d5f6"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgxMzYyMA==", "bodyText": "Yes, dataConsistent is 1 in any phase other than apply phase of the snapshot sync.  This is because only during apply phase we have an intermediate state where replicated data is being applied and applications can read inconsistent data.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r459813620", "createdAt": "2020-07-24T01:34:11Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -311,14 +313,17 @@ private void applySnapshotSync(LogReplicationEntry message) {\n         switch (message.getMetadata().getMessageMetadataType()) {\n             case SNAPSHOT_MESSAGE:\n                 snapshotWriter.apply(message);\n-                return;\n+                break;\n             case SNAPSHOT_END:\n+                dataConsistent.set(0);\n+                logReplicationMetadataManager.setDataConsistentOnStandby(String.valueOf(dataConsistent));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc4NjMwMQ=="}, "originalCommit": {"oid": "4ff6b7041f13a0f5ca789ba2f351f3f79153d5f6"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3ODYxMTk1OnYy", "diffSide": "LEFT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxOToyNjozMFrOG3wX4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMTo1ODo0OFrOG31GFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNzQxMQ==", "bodyText": "Why don't we return here?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461117411", "createdAt": "2020-07-27T19:26:30Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -95,60 +95,63 @@ public long query(CorfuStoreMetadata.Timestamp timestamp, LogReplicationMetadata\n     }\n \n     public long getTopologyConfigId() {\n-        return query(null, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        return query(null, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n     }\n \n-    public String getVersion() { return queryString(null, LogReplicationMetadataType.VERSION); }\n+    public String getVersion() { return queryString(null, LogReplicationMetadataKey.KeyType.VERSION); }\n \n     public long getLastSnapStartTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_START);\n     }\n \n     public long getLastSnapTransferDoneTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_TRANSFERRED);\n     }\n \n     public long getLastAppliedBaseSnapshotTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_APPLIED);\n     }\n \n     public long getLastSnapSeqNum() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_SEQ_NUM);\n     }\n \n     public long getLastProcessedLogTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_LOG_PROCESSED);\n+        return query(null, LogReplicationMetadataKey.KeyType.LAST_LOG_ENTRY_PROCESSED);\n     }\n \n-    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, long val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType type, long val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(type).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(Long.toString(val)).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n-    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, String val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType key, String val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(val).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n     public void setupTopologyConfigId(long topologyConfigId) {\n         CorfuStoreMetadata.Timestamp timestamp = corfuStore.getTimestamp();\n-        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n \n         if (topologyConfigId <= persistedTopologyConfigId) {\n             log.warn(\"Skip setupTopologyConfigId. the current topologyConfigId \" + topologyConfigId + \" is not larger than the persistedTopologyConfigID \" + persistedTopologyConfigId);\n-            return;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "683566e7eb4d4b694027262a9c7e09c2ab50bbc0"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE5NDc3Mw==", "bodyText": "I think it will bring some concurrent updates to some extent.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461194773", "createdAt": "2020-07-27T21:58:48Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -95,60 +95,63 @@ public long query(CorfuStoreMetadata.Timestamp timestamp, LogReplicationMetadata\n     }\n \n     public long getTopologyConfigId() {\n-        return query(null, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        return query(null, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n     }\n \n-    public String getVersion() { return queryString(null, LogReplicationMetadataType.VERSION); }\n+    public String getVersion() { return queryString(null, LogReplicationMetadataKey.KeyType.VERSION); }\n \n     public long getLastSnapStartTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_START);\n     }\n \n     public long getLastSnapTransferDoneTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_TRANSFERRED);\n     }\n \n     public long getLastAppliedBaseSnapshotTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_APPLIED);\n     }\n \n     public long getLastSnapSeqNum() {\n-        return query(null, LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM);\n+        return query(null, LogReplicationMetadataKey.KeyType.SNAPSHOT_SEQ_NUM);\n     }\n \n     public long getLastProcessedLogTimestamp() {\n-        return query(null, LogReplicationMetadataType.LAST_LOG_PROCESSED);\n+        return query(null, LogReplicationMetadataKey.KeyType.LAST_LOG_ENTRY_PROCESSED);\n     }\n \n-    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, long val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    public void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType type, long val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(type).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(Long.toString(val)).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n-    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataType key, String val) {\n-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();\n+    private void appendUpdate(TxBuilder txBuilder, LogReplicationMetadataKey.KeyType key, String val) {\n+        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key).build();\n         LogReplicationMetadataVal txVal = LogReplicationMetadataVal.newBuilder().setVal(val).build();\n         txBuilder.update(metadataTableName, txKey, txVal, null);\n     }\n \n     public void setupTopologyConfigId(long topologyConfigId) {\n         CorfuStoreMetadata.Timestamp timestamp = corfuStore.getTimestamp();\n-        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataKey.KeyType.TOPOLOGY_CONFIG_ID);\n \n         if (topologyConfigId <= persistedTopologyConfigId) {\n             log.warn(\"Skip setupTopologyConfigId. the current topologyConfigId \" + topologyConfigId + \" is not larger than the persistedTopologyConfigID \" + persistedTopologyConfigId);\n-            return;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNzQxMQ=="}, "originalCommit": {"oid": "683566e7eb4d4b694027262a9c7e09c2ab50bbc0"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzk5NDk2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzozNzowOFrOG4jZ3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo1NTozMlrOG5J00g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1MzUwMg==", "bodyText": "Can we use thread name : last-ackd-ts-reader?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461953502", "createdAt": "2020-07-28T23:37:08Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;\n+\n+    private static int FULL_REPLICATION_REMAINING_PERCENT = 100;\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this(params, metadataManager, new CorfuDataSender(client));\n     }\n \n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    @VisibleForTesting\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params,\n+                                       LogReplicationMetadataManager metadataManager,\n+                                       DataSender dataSender) {\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n-\n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n-\n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (transformation)\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n         this.parameters = params;\n+\n         this.config = parameters.getReplicationConfig();\n         if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n             // Avoid FSM being initialized if there are no streams to replicate\n             throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n         }\n \n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n         // If this runtime has opened other streams, it appends non opaque entries and because\n         // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n         // for log replication exclusively.\n-        this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n-        this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n \n         this.logReplicationFSM = new LogReplicationFSM(this.runtime, config, params.getRemoteClusterDescriptor(),\n                 dataSender, readProcessor, logReplicationFSMWorkers);\n+\n         this.logReplicationFSM.setTopologyConfigId(params.getTopologyConfigId());\n+\n+        this.metadataManager = metadataManager;\n+        lastAckedTsPoller = Executors.newSingleThreadScheduledExecutor(\n+            new ThreadFactoryBuilder().setNameFormat(\"Last Ackd Ts Reader\").build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwOTMyMQ==", "bodyText": "+1 maybe ack-timestamp-poller or ack-timestamp-reader", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462009321", "createdAt": "2020-07-29T03:00:54Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;\n+\n+    private static int FULL_REPLICATION_REMAINING_PERCENT = 100;\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this(params, metadataManager, new CorfuDataSender(client));\n     }\n \n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    @VisibleForTesting\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params,\n+                                       LogReplicationMetadataManager metadataManager,\n+                                       DataSender dataSender) {\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n-\n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n-\n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (transformation)\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n         this.parameters = params;\n+\n         this.config = parameters.getReplicationConfig();\n         if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n             // Avoid FSM being initialized if there are no streams to replicate\n             throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n         }\n \n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n         // If this runtime has opened other streams, it appends non opaque entries and because\n         // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n         // for log replication exclusively.\n-        this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n-        this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n \n         this.logReplicationFSM = new LogReplicationFSM(this.runtime, config, params.getRemoteClusterDescriptor(),\n                 dataSender, readProcessor, logReplicationFSMWorkers);\n+\n         this.logReplicationFSM.setTopologyConfigId(params.getTopologyConfigId());\n+\n+        this.metadataManager = metadataManager;\n+        lastAckedTsPoller = Executors.newSingleThreadScheduledExecutor(\n+            new ThreadFactoryBuilder().setNameFormat(\"Last Ackd Ts Reader\").build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1MzUwMg=="}, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4Mjk5NA==", "bodyText": "done.  changed to ack-timestamp-reader", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462582994", "createdAt": "2020-07-29T20:55:32Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;\n+\n+    private static int FULL_REPLICATION_REMAINING_PERCENT = 100;\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this(params, metadataManager, new CorfuDataSender(client));\n     }\n \n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    @VisibleForTesting\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params,\n+                                       LogReplicationMetadataManager metadataManager,\n+                                       DataSender dataSender) {\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n-\n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n-\n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (transformation)\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n         this.parameters = params;\n+\n         this.config = parameters.getReplicationConfig();\n         if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n             // Avoid FSM being initialized if there are no streams to replicate\n             throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n         }\n \n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n         // If this runtime has opened other streams, it appends non opaque entries and because\n         // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n         // for log replication exclusively.\n-        this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n-        this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n \n         this.logReplicationFSM = new LogReplicationFSM(this.runtime, config, params.getRemoteClusterDescriptor(),\n                 dataSender, readProcessor, logReplicationFSMWorkers);\n+\n         this.logReplicationFSM.setTopologyConfigId(params.getTopologyConfigId());\n+\n+        this.metadataManager = metadataManager;\n+        lastAckedTsPoller = Executors.newSingleThreadScheduledExecutor(\n+            new ThreadFactoryBuilder().setNameFormat(\"Last Ackd Ts Reader\").build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1MzUwMg=="}, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 198}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzk5ODI0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzozODozOVrOG4jbrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo1Mzo0NVrOG5Jw-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1Mzk2Ng==", "bodyText": "Should we remove these lines? as well as the above comments?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461953966", "createdAt": "2020-07-28T23:38:39Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;\n+\n+    private static int FULL_REPLICATION_REMAINING_PERCENT = 100;\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this(params, metadataManager, new CorfuDataSender(client));\n     }\n \n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    @VisibleForTesting\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params,\n+                                       LogReplicationMetadataManager metadataManager,\n+                                       DataSender dataSender) {\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n-\n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n-\n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (transformation)\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n         this.parameters = params;\n+\n         this.config = parameters.getReplicationConfig();\n         if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n             // Avoid FSM being initialized if there are no streams to replicate\n             throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n         }\n \n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n         // If this runtime has opened other streams, it appends non opaque entries and because\n         // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n         // for log replication exclusively.\n-        this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n-        this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwODM2NA==", "bodyText": "+1", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462008364", "createdAt": "2020-07-29T02:57:40Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;\n+\n+    private static int FULL_REPLICATION_REMAINING_PERCENT = 100;\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this(params, metadataManager, new CorfuDataSender(client));\n     }\n \n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    @VisibleForTesting\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params,\n+                                       LogReplicationMetadataManager metadataManager,\n+                                       DataSender dataSender) {\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n-\n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n-\n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (transformation)\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n         this.parameters = params;\n+\n         this.config = parameters.getReplicationConfig();\n         if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n             // Avoid FSM being initialized if there are no streams to replicate\n             throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n         }\n \n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n         // If this runtime has opened other streams, it appends non opaque entries and because\n         // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n         // for log replication exclusively.\n-        this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n-        this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1Mzk2Ng=="}, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4MjAxMQ==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462582011", "createdAt": "2020-07-29T20:53:45Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;\n+\n+    private static int FULL_REPLICATION_REMAINING_PERCENT = 100;\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this(params, metadataManager, new CorfuDataSender(client));\n     }\n \n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    @VisibleForTesting\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params,\n+                                       LogReplicationMetadataManager metadataManager,\n+                                       DataSender dataSender) {\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n-\n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n-\n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (transformation)\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n         this.parameters = params;\n+\n         this.config = parameters.getReplicationConfig();\n         if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n             // Avoid FSM being initialized if there are no streams to replicate\n             throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n         }\n \n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n         // If this runtime has opened other streams, it appends non opaque entries and because\n         // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n         // for log replication exclusively.\n-        this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n-        this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1Mzk2Ng=="}, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 189}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzk5OTEyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzozOTowOVrOG4jcNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo1NDowOVrOG5Jx4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NDEwMg==", "bodyText": "Remove not used code.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461954102", "createdAt": "2020-07-28T23:39:09Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;\n+\n+    private static int FULL_REPLICATION_REMAINING_PERCENT = 100;\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this(params, metadataManager, new CorfuDataSender(client));\n     }\n \n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    @VisibleForTesting\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params,\n+                                       LogReplicationMetadataManager metadataManager,\n+                                       DataSender dataSender) {\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n-\n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n-\n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (transformation)\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n         this.parameters = params;\n+\n         this.config = parameters.getReplicationConfig();\n         if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n             // Avoid FSM being initialized if there are no streams to replicate\n             throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n         }\n \n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n         // If this runtime has opened other streams, it appends non opaque entries and because\n         // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n         // for log replication exclusively.\n-        this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n-        this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4MjI0MQ==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462582241", "createdAt": "2020-07-29T20:54:09Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;\n+\n+    private static int FULL_REPLICATION_REMAINING_PERCENT = 100;\n+\n     @VisibleForTesting\n     private int countACKs = 0;\n \n     @VisibleForTesting\n     private ObservableAckMsg ackMessages = new ObservableAckMsg();\n \n     /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n+     * @param params Log Replication parameters\n+     * @param client LogReplication client, which is a data sender, both snapshot and log entry, this represents\n+     *              the application callback for data transmission\n+     * @param metadataManager Replication Metadata Manager\n      */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params) {\n-\n-        this(runtime, dataSender, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client,\n+                                       LogReplicationMetadataManager metadataManager) {\n+        this(params, metadataManager, new CorfuDataSender(client));\n     }\n \n-    public LogReplicationSourceManager(LogReplicationRuntimeParameters params, LogReplicationClient client) {\n-        this(CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n+    @VisibleForTesting\n+    public LogReplicationSourceManager(LogReplicationRuntimeParameters params,\n+                                       LogReplicationMetadataManager metadataManager,\n+                                       DataSender dataSender) {\n+\n+        // If this runtime has opened other streams, it appends non opaque entries and because\n+        // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n+        // for log replication exclusively.\n+        this.runtime = CorfuRuntime.fromParameters(CorfuRuntimeParameters.builder()\n                 .trustStore(params.getTrustStore())\n                 .tsPasswordFile(params.getTsPasswordFile())\n                 .keyStore(params.getKeyStore())\n                 .ksPasswordFile(params.getKsPasswordFile())\n-                .tlsEnabled(params.isTlsEnabled()).build())\n-        .parseConfigurationString(params.getLocalCorfuEndpoint()).connect(), client, params);\n-    }\n-\n-    /**\n-     * Constructor LogReplicationSourceManager\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param client Log replication client\n-     * @param params Log Replication parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime, LogReplicationClient client, LogReplicationRuntimeParameters params) {\n-        this(runtime, new CorfuDataSender(client), params);\n-    }\n-\n-    /**\n-     * Constructor Source (default)\n-     *\n-     * @param runtime Corfu Runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (data transformation)\n-     * @param params Log Replication Parameters\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params) {\n-        // Default to single dedicated thread for state machine workers (perform state tasks)\n-        this(runtime, dataSender, readProcessor, params, Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n-                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build()));\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n-        this(runtime, dataSender, new DefaultReadProcessor(runtime), params, logReplicationFSMWorkers);\n-    }\n-\n-    /**\n-     * Constructor Source to provide ExecutorServices for FSM\n-     *\n-     * For multi-cluster log replication multiple managers can share a common thread pool.\n-     *\n-     * @param runtime corfu runtime\n-     * @param dataSender implementation of a data sender, both snapshot and log entry, this represents\n-     *                   the application callback for data transmission\n-     * @param readProcessor implementation for reads processor (transformation)\n-     * @param params Log Replication Parameters\n-     * @param logReplicationFSMWorkers worker thread pool (state tasks)\n-     */\n-    public LogReplicationSourceManager(CorfuRuntime runtime,\n-                                       DataSender dataSender,\n-                                       ReadProcessor readProcessor,\n-                                       LogReplicationRuntimeParameters params,\n-                                       ExecutorService logReplicationFSMWorkers) {\n+                .tlsEnabled(params.isTlsEnabled()).build());\n+        runtime.parseConfigurationString(params.getLocalCorfuEndpoint()).connect();\n \n         this.parameters = params;\n+\n         this.config = parameters.getReplicationConfig();\n         if (config.getStreamsToReplicate() == null || config.getStreamsToReplicate().isEmpty()) {\n             // Avoid FSM being initialized if there are no streams to replicate\n             throw new IllegalArgumentException(\"Invalid Log Replication: Streams to replicate is EMPTY\");\n         }\n \n+        ExecutorService logReplicationFSMWorkers = Executors.newFixedThreadPool(DEFAULT_FSM_WORKER_THREADS, new\n+                ThreadFactoryBuilder().setNameFormat(\"state-machine-worker\").build());\n+        ReadProcessor readProcessor = new DefaultReadProcessor(runtime);\n+\n         // If this runtime has opened other streams, it appends non opaque entries and because\n         // the cache is shared we end up doing deserialization. We need guarantees that this runtime is dedicated\n         // for log replication exclusively.\n-        this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n-        this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();\n+        //this.runtime = CorfuRuntime.fromParameters(runtime.getParameters());\n+        //this.runtime.parseConfigurationString(runtime.getLayoutServers().get(0)).connect();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NDEwMg=="}, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 189}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDAwMTkzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzo0MDoyMlrOG4jdyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzo0MDoyMlrOG4jdyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NDUwNA==", "bodyText": "Will we add retry to each tx commit in metadata manager? I think we should have a max retry limit here.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461954504", "createdAt": "2020-07-28T23:40:22Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -137,21 +145,36 @@ public void setupTopologyConfigId(long topologyConfigId) {\n         long persistedTopologyConfigId = query(timestamp, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n \n         if (topologyConfigId <= persistedTopologyConfigId) {\n-            log.warn(\"Skip setupTopologyConfigId. the current topologyConfigId \" + topologyConfigId + \" is not larger than the persistedTopologyConfigID \" + persistedTopologyConfigId);\n+            log.warn(\"Skip setupTopologyConfigId. the current topologyConfigId {} is not larger than the persistedTopologyConfigID {}\",\n+                topologyConfigId, persistedTopologyConfigId);\n             return;\n         }\n \n         TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n \n-        for (LogReplicationMetadataType key : LogReplicationMetadataType.values()) {\n-            long val = Address.NON_ADDRESS;\n-            if (key == LogReplicationMetadataType.TOPOLOGY_CONFIG_ID) {\n-                val = topologyConfigId;\n+        for (LogReplicationMetadataType type : LogReplicationMetadataType.values()) {\n+            if (type == LogReplicationMetadataType.TOPOLOGY_CONFIG_ID) {\n+                appendUpdate(txBuilder, type, topologyConfigId);\n+                try {\n+                    IRetry.build(IntervalRetry.class, () -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDAwMzg0OnYy", "diffSide": "LEFT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzo0MToyMFrOG4je3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToyMjowN1rOG5KrpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NDc4Mg==", "bodyText": "Is this correct to remove?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461954782", "createdAt": "2020-07-28T23:41:20Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -281,7 +304,6 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n         if (siteConfigID != persistSiteConfigID || ts != persistSnapStart || ts != persistSnapTranferDone) {\n             log.warn(\"topologyConfigId \" + siteConfigID + \" != \" + \" persist \" + persistSiteConfigID +  \" ts \" + ts +\n                     \" != \" + \"persistSnapTransferDone \" + persistSnapTranferDone);\n-            return;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NzAyOA==", "bodyText": "no.. dont know how it got removed..", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462597028", "createdAt": "2020-07-29T21:22:07Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -281,7 +304,6 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n         if (siteConfigID != persistSiteConfigID || ts != persistSnapStart || ts != persistSnapTranferDone) {\n             log.warn(\"topologyConfigId \" + siteConfigID + \" != \" + \" persist \" + persistSiteConfigID +  \" ts \" + ts +\n                     \" != \" + \"persistSnapTransferDone \" + persistSnapTranferDone);\n-            return;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NDc4Mg=="}, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 142}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDAwNTIyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzo0MTo1NlrOG4jfqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo1ODozMlrOG5J65A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NDk4Nw==", "bodyText": "For snapshot messages, should it be msgSeqNum? All snapshot messages have the same timestamp.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461954987", "createdAt": "2020-07-28T23:41:56Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4NDU0OA==", "bodyText": "we are going to change this implementation before merging the PR", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462584548", "createdAt": "2020-07-29T20:58:32Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NDk4Nw=="}, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 213}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDAwNTcxOnYy", "diffSide": "LEFT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzo0MjoxMVrOG4jf-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToxOTo1OVrOG5KniQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NTA2NA==", "bodyText": "Is this correct to remove?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461955064", "createdAt": "2020-07-28T23:42:11Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -253,15 +277,14 @@ public void setLastSnapTransferDoneTimestamp(long topologyConfigId, long ts) {\n         if (topologyConfigId != persistedTopologyConfigId || ts <= persistedTopologyConfigId) {\n             log.warn(\"The metadata is older than the persisted one. Set snapshotStart topologyConfigId \" + topologyConfigId + \" ts \" + ts +\n                     \" persisteSiteConfigID \" + persistedTopologyConfigId + \" persistSnapStart \" + persistSnapStart);\n-            return;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NTk3Nw==", "bodyText": "good catch.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462595977", "createdAt": "2020-07-29T21:19:59Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -253,15 +277,14 @@ public void setLastSnapTransferDoneTimestamp(long topologyConfigId, long ts) {\n         if (topologyConfigId != persistedTopologyConfigId || ts <= persistedTopologyConfigId) {\n             log.warn(\"The metadata is older than the persisted one. Set snapshotStart topologyConfigId \" + topologyConfigId + \" ts \" + ts +\n                     \" persisteSiteConfigID \" + persistedTopologyConfigId + \" persistSnapStart \" + persistSnapStart);\n-            return;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NTA2NA=="}, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDAxMTUxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzo0NDo1MlrOG4jjTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTo0MzozOVrOG5LUJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NTkxOA==", "bodyText": "Should we init topologyConfigId in this function?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461955918", "createdAt": "2020-07-28T23:44:52Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -130,31 +128,37 @@ public LogReplicationSinkManager(String localCorfuEndpoint, LogReplicationConfig\n     @VisibleForTesting\n     public LogReplicationSinkManager(String localCorfuEndpoint, LogReplicationConfig config,\n                                      LogReplicationMetadataManager metadataManager, String pluginConfigFilePath) {\n-        this.logReplicationMetadataManager = metadataManager;\n         this.runtime =  CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder().build())\n                 .parseConfigurationString(localCorfuEndpoint).connect();\n         this.pluginConfigFilePath = pluginConfigFilePath;\n+        initCommonParams(metadataManager, config);\n+    }\n \n-        /*\n-         * When the server is up, it will be at LOG_ENTRY_SYNC state by default.\n-         * The sender will query receiver's status and decide what type of replication to start with.\n-         * It will transit to SNAPSHOT_SYNC state if it received a SNAPSHOT_START message from the sender.\n-         */\n-        this.rxState = RxState.LOG_ENTRY_SYNC;\n+    private void initCommonParams(LogReplicationMetadataManager metadataManager, LogReplicationConfig config) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYwNzM5Ng==", "bodyText": "topologyConfigId is not set for the test constructor.  But good catch, it is now not getting set in the first constructor also.  Adding it back.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462607396", "createdAt": "2020-07-29T21:43:39Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -130,31 +128,37 @@ public LogReplicationSinkManager(String localCorfuEndpoint, LogReplicationConfig\n     @VisibleForTesting\n     public LogReplicationSinkManager(String localCorfuEndpoint, LogReplicationConfig config,\n                                      LogReplicationMetadataManager metadataManager, String pluginConfigFilePath) {\n-        this.logReplicationMetadataManager = metadataManager;\n         this.runtime =  CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder().build())\n                 .parseConfigurationString(localCorfuEndpoint).connect();\n         this.pluginConfigFilePath = pluginConfigFilePath;\n+        initCommonParams(metadataManager, config);\n+    }\n \n-        /*\n-         * When the server is up, it will be at LOG_ENTRY_SYNC state by default.\n-         * The sender will query receiver's status and decide what type of replication to start with.\n-         * It will transit to SNAPSHOT_SYNC state if it received a SNAPSHOT_START message from the sender.\n-         */\n-        this.rxState = RxState.LOG_ENTRY_SYNC;\n+    private void initCommonParams(LogReplicationMetadataManager metadataManager, LogReplicationConfig config) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NTkxOA=="}, "originalCommit": {"oid": "70a6226e297abbadcc0a92c03d35d15de8b2f86f"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDI5MTQ4OnYy", "diffSide": "RIGHT", "path": "infrastructure/proto/log_replication_metadata.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoxMzozOFrOG4mDMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoxMzozOFrOG4mDMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5Njg1MA==", "bodyText": "Not sure I understand why this is an enum. Probably having as a key the Cluster UUID would make sense? Because at the active, one active can have multiple standby's, so how do we differentiate? And for the standby its ok to have its own cluster id as key. It would look something like this:\nKey                               |                      Value\nCluster_Standby_Paris_0001        |            ReplicationStatusVal\nCluster_London_002                     |            ReplicationStatusVal", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461996850", "createdAt": "2020-07-29T02:13:38Z", "author": {"login": "annym"}, "path": "infrastructure/proto/log_replication_metadata.proto", "diffHunk": "@@ -25,3 +25,23 @@ message LogReplicationMetadataKey {\n message LogReplicationMetadataVal {\n   string val = 1;\n }\n+\n+/*\n+ * Replication Status Key\n+ */\n+ message ReplicationStatusKey {\n+   enum Status {\n+     REPLICATION_COMPLETION = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDI5Mzk4OnYy", "diffSide": "RIGHT", "path": "infrastructure/proto/log_replication_metadata.proto", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoxNDo1MlrOG4mElg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMzo1MzoxOVrOG5OMEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5NzIwNg==", "bodyText": "should we also add an enum which indicates if we are in LOG_ENTRY (delta) or SNAPSHOT (full) sync? for completeness.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461997206", "createdAt": "2020-07-29T02:14:52Z", "author": {"login": "annym"}, "path": "infrastructure/proto/log_replication_metadata.proto", "diffHunk": "@@ -25,3 +25,23 @@ message LogReplicationMetadataKey {\n message LogReplicationMetadataVal {\n   string val = 1;\n }\n+\n+/*\n+ * Replication Status Key\n+ */\n+ message ReplicationStatusKey {\n+   enum Status {\n+     REPLICATION_COMPLETION = 0;\n+     IS_DATA_CONSISTENT = 1;\n+   }\n+   Status key = 1;\n+ }\n+\n+/*\n+ * Replication Status Value\n+ * Active Site sets the completionPercent, Standby sets the dataConsistent boolean\n+ */\n+message ReplicationStatusVal {\n+  uint64 replicationCompletion = 1;\n+  bool dataConsistent = 2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY1NDQ4Mw==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462654483", "createdAt": "2020-07-29T23:53:19Z", "author": {"login": "pankti-m"}, "path": "infrastructure/proto/log_replication_metadata.proto", "diffHunk": "@@ -25,3 +25,23 @@ message LogReplicationMetadataKey {\n message LogReplicationMetadataVal {\n   string val = 1;\n }\n+\n+/*\n+ * Replication Status Key\n+ */\n+ message ReplicationStatusKey {\n+   enum Status {\n+     REPLICATION_COMPLETION = 0;\n+     IS_DATA_CONSISTENT = 1;\n+   }\n+   Status key = 1;\n+ }\n+\n+/*\n+ * Replication Status Value\n+ * Active Site sets the completionPercent, Standby sets the dataConsistent boolean\n+ */\n+message ReplicationStatusVal {\n+  uint64 replicationCompletion = 1;\n+  bool dataConsistent = 2;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5NzIwNg=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMwNzE4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoyMTo0NFrOG4mMAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxODo1Njo0OVrOG5F28g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5OTEwNw==", "bodyText": "We can leave this for later, but we might need to change this API a bit, because in line with my previous comment, there can be multiple standby's, so we might want to return a map if no cluster Id is specified (so we return the status for all standby's), and accept the cluster Id as argument for another API.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461999107", "createdAt": "2020-07-29T02:21:44Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -660,46 +659,38 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  If in the Active state, writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n     public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {\n+            log.info(\"Received a Request to Become Standby\");\n         } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n+            log.error(\"Received a Request to Become Standby in current role {}\", localClusterDescriptor.getRole());\n         }\n     }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n     public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxODAwMg==", "bodyText": "we will have to do it now if we change the key in the replication status metadata protobuf", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462518002", "createdAt": "2020-07-29T18:56:49Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -660,46 +659,38 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  If in the Active state, writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n     public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {\n+            log.info(\"Received a Request to Become Standby\");\n         } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n+            log.error(\"Received a Request to Become Standby in current role {}\", localClusterDescriptor.getRole());\n         }\n     }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n     public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5OTEwNw=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMwODQzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoyMjozOVrOG4mMwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxOTowNzowOVrOG5GOAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5OTI5OA==", "bodyText": "Should this be returning our proto ReplicationStatusVal?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r461999298", "createdAt": "2020-07-29T02:22:39Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -660,46 +659,38 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  If in the Active state, writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n     public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {\n+            log.info(\"Received a Request to Become Standby\");\n         } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n+            log.error(\"Received a Request to Become Standby in current role {}\", localClusterDescriptor.getRole());\n         }\n     }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n     public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUyMzkwNg==", "bodyText": "ultimately yes.  But we will have to change the Cluster Manager adapter interfaces for that..", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462523906", "createdAt": "2020-07-29T19:07:09Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -660,46 +659,38 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  If in the Active state, writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n     public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {\n+            log.info(\"Received a Request to Become Standby\");\n         } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n+            log.error(\"Received a Request to Become Standby in current role {}\", localClusterDescriptor.getRole());\n         }\n     }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n     public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5OTI5OA=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMxODQzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoyODozOFrOG4mSmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToxNzo0NFrOG5KjGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMDc5NA==", "bodyText": "nit -> Skip update of current version {} to {}, as they are the same.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462000794", "createdAt": "2020-07-29T02:28:38Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -160,7 +173,8 @@ public void updateVersion(String version) {\n         String  persistedVersion = queryString(timestamp, LogReplicationMetadataType.VERSION);\n \n         if (persistedVersion.equals(version)) {\n-            log.warn(\"Skip update the current version {} with new version {} as they are the same\", persistedVersion, version);\n+            log.warn(\"Skip update the current version {} with new version {} as they are the same\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NDg0Mg==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462594842", "createdAt": "2020-07-29T21:17:44Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -160,7 +173,8 @@ public void updateVersion(String version) {\n         String  persistedVersion = queryString(timestamp, LogReplicationMetadataType.VERSION);\n \n         if (persistedVersion.equals(version)) {\n-            log.warn(\"Skip update the current version {} with new version {} as they are the same\", persistedVersion, version);\n+            log.warn(\"Skip update the current version {} with new version {} as they are the same\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMDc5NA=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMxODU1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoyODo1MVrOG4mSww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToxNTo0NFrOG5KfQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMDgzNQ==", "bodyText": "Perhaps we can add some validation that this indeed a correct percent from 0 to 100. We just store it as a string later and then parse back as an integer. If it's incorrect it will throw a NumberFormatException", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462000835", "createdAt": "2020-07-29T02:28:51Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;\n+        }\n+        long remainingEntriesToSend = 0;\n+        for (String stream : config.getStreamsToReplicate()) {\n+            UUID streamId = CorfuRuntime.getStreamID(stream);\n+            StreamAddressRange range = new StreamAddressRange(streamId, maxReplicatedStreamTail, ackedTimestamp);\n+            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n+            Roaring64NavigableMap map = addressSpace.getAddressesInRange(range);\n+            remainingEntriesToSend += map.getLongCardinality();\n+        }\n+        return remainingEntriesToSend;\n+    }\n+\n+    /**\n+     * Task which periodically updates the metadata table with replication completion percentage\n+     */\n+    private class TsPollingTask implements Runnable {\n+        @Override\n+        public void run() {\n+            long remainingReplicationStatus = calculateRemainingEntriesToSend(lastAckedTimestamp.get());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 276}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5Mzg1Ng==", "bodyText": "This protobuf has changed and takes a long now.. so there is no conversion.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462593856", "createdAt": "2020-07-29T21:15:44Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;\n+        }\n+        long remainingEntriesToSend = 0;\n+        for (String stream : config.getStreamsToReplicate()) {\n+            UUID streamId = CorfuRuntime.getStreamID(stream);\n+            StreamAddressRange range = new StreamAddressRange(streamId, maxReplicatedStreamTail, ackedTimestamp);\n+            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n+            Roaring64NavigableMap map = addressSpace.getAddressesInRange(range);\n+            remainingEntriesToSend += map.getLongCardinality();\n+        }\n+        return remainingEntriesToSend;\n+    }\n+\n+    /**\n+     * Task which periodically updates the metadata table with replication completion percentage\n+     */\n+    private class TsPollingTask implements Runnable {\n+        @Override\n+        public void run() {\n+            long remainingReplicationStatus = calculateRemainingEntriesToSend(lastAckedTimestamp.get());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMDgzNQ=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 276}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMyMDUwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoyOTo1NFrOG4mT5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToxODozMlrOG5KkvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMTEyNg==", "bodyText": "typo -> STARTED", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462001126", "createdAt": "2020-07-29T02:29:54Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -217,14 +231,14 @@ public boolean setSrcBaseSnapshotStart(long topologyConfigId, long ts) {\n         // Update the topologyConfigId to fence all other transactions that update the metadata at the same time\n         appendUpdate(txBuilder, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, topologyConfigId);\n \n-        // Setup the LAST_SNAPSHOT_STARTED\n+        // Setup the LAST_LAST_SNAPSHOT_STARTEDED", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NTI2MA==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462595260", "createdAt": "2020-07-29T21:18:32Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -217,14 +231,14 @@ public boolean setSrcBaseSnapshotStart(long topologyConfigId, long ts) {\n         // Update the topologyConfigId to fence all other transactions that update the metadata at the same time\n         appendUpdate(txBuilder, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, topologyConfigId);\n \n-        // Setup the LAST_SNAPSHOT_STARTED\n+        // Setup the LAST_LAST_SNAPSHOT_STARTEDED", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMTEyNg=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMyMTA1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozMDoxMVrOG4mUNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozMDoxMVrOG4mUNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMTIwNA==", "bodyText": "same typo -> STARTED", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462001204", "createdAt": "2020-07-29T02:30:11Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -253,15 +267,14 @@ public void setLastSnapTransferDoneTimestamp(long topologyConfigId, long ts) {\n         if (topologyConfigId != persistedTopologyConfigId || ts <= persistedTopologyConfigId) {\n             log.warn(\"The metadata is older than the persisted one. Set snapshotStart topologyConfigId \" + topologyConfigId + \" ts \" + ts +\n                     \" persisteSiteConfigID \" + persistedTopologyConfigId + \" persistSnapStart \" + persistSnapStart);\n-            return;\n         }\n \n         TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n \n         //Update the topologyConfigId to fence all other transactions that update the metadata at the same time\n         appendUpdate(txBuilder, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, topologyConfigId);\n \n-        //Setup the LAST_SNAPSHOT_STARTED\n+        //Setup the LAST_LAST_SNAPSHOT_STARTEDED", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMyNjgwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozMzoxM1rOG4mXdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToyOTozMlrOG5K6FQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMjAzNg==", "bodyText": "maybe we should add a log here so we know that nothing has been updated to the corfuStore and not that it is complete necessarily.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462002036", "createdAt": "2020-07-29T02:33:13Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -301,21 +313,85 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n     }\n \n+    public void setReplicationRemainingPercent(long percentComplete) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setReplicationCompletion(percentComplete).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public long getReplicationRemainingPercent() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+        if (record == null) {\n+            return 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYwMDcyNQ==", "bodyText": "From here we will only return the protobuf.. will have to add the log message in the adapter", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462600725", "createdAt": "2020-07-29T21:29:32Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -301,21 +313,85 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n     }\n \n+    public void setReplicationRemainingPercent(long percentComplete) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setReplicationCompletion(percentComplete).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public long getReplicationRemainingPercent() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+        if (record == null) {\n+            return 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMjAzNg=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 183}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMzMTE4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozNTozNFrOG4mZ6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTozODozN1rOG5LK3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMjY2NA==", "bodyText": "Also here we can print some warning message or something for us to know its not yet persisted.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462002664", "createdAt": "2020-07-29T02:35:34Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -301,21 +313,85 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n     }\n \n+    public void setReplicationRemainingPercent(long percentComplete) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setReplicationCompletion(percentComplete).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public long getReplicationRemainingPercent() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+        if (record == null) {\n+            return 0;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getReplicationCompletion();\n+    }\n+\n+    public void setDataConsistentOnStandby(boolean isConsistent) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setDataConsistent(isConsistent).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public boolean getDataConsistentOnStandby() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+\n+        // TODO: Initially, snapshot sync is pending so the data is not consistent.  But what if everything was applied and\n+        // the standby rebooted?  In that case it is consistent\n+        if (record == null) {\n+            return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYwNTAyMg==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462605022", "createdAt": "2020-07-29T21:38:37Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -301,21 +313,85 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n     }\n \n+    public void setReplicationRemainingPercent(long percentComplete) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setReplicationCompletion(percentComplete).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public long getReplicationRemainingPercent() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+        if (record == null) {\n+            return 0;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getReplicationCompletion();\n+    }\n+\n+    public void setDataConsistentOnStandby(boolean isConsistent) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setDataConsistent(isConsistent).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public boolean getDataConsistentOnStandby() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+\n+        // TODO: Initially, snapshot sync is pending so the data is not consistent.  But what if everything was applied and\n+        // the standby rebooted?  In that case it is consistent\n+        if (record == null) {\n+            return false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMjY2NA=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 206}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMzMjE2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozNjowOVrOG4madA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozNjowOVrOG4madA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMjgwNA==", "bodyText": "Does not seem to be used", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462002804", "createdAt": "2020-07-29T02:36:09Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -21,12 +21,12 @@\n import java.util.UUID;\n \n /**\n- * This class manages Log Replication for multiple remote (standby) cluster's.\n+ * This class manages Log Replication for multiple remote (standby) clusters.\n  */\n @Slf4j\n public class CorfuReplicationManager {\n \n-    public final static int PERCENTAGE_BASE = 100;\n+    public final static int PERCENTAGE_HUNDRED = 100;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMzMjUwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozNjoyNFrOG4marQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTozNTo0N1rOG5LFzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMjg2MQ==", "bodyText": "Even If the standby rebooted it should be persisted, right? unless it rebooted right before updating this value. (Maybe we should ensure it is atomically updated when the last snapshot entry is written)", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462002861", "createdAt": "2020-07-29T02:36:24Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -301,21 +313,85 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n     }\n \n+    public void setReplicationRemainingPercent(long percentComplete) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setReplicationCompletion(percentComplete).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public long getReplicationRemainingPercent() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+        if (record == null) {\n+            return 0;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getReplicationCompletion();\n+    }\n+\n+    public void setDataConsistentOnStandby(boolean isConsistent) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setDataConsistent(isConsistent).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public boolean getDataConsistentOnStandby() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+\n+        // TODO: Initially, snapshot sync is pending so the data is not consistent.  But what if everything was applied and", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 203}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYwMzcyNg==", "bodyText": "oh yes.. I think the todo is not required.  The last snapshot timestamp will have been set on reboot, unless it stopped just before updating this field.  In that case, will the transfer resume?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462603726", "createdAt": "2020-07-29T21:35:47Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -301,21 +313,85 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n     }\n \n+    public void setReplicationRemainingPercent(long percentComplete) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setReplicationCompletion(percentComplete).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public long getReplicationRemainingPercent() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+        if (record == null) {\n+            return 0;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getReplicationCompletion();\n+    }\n+\n+    public void setDataConsistentOnStandby(boolean isConsistent) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setDataConsistent(isConsistent).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public boolean getDataConsistentOnStandby() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+\n+        // TODO: Initially, snapshot sync is pending so the data is not consistent.  But what if everything was applied and", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMjg2MQ=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 203}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMzNDE1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozNzoyN1rOG4mbnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTo0MDo1MlrOG5LPKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMzEwMw==", "bodyText": "break;", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462003103", "createdAt": "2020-07-29T02:37:27Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -301,21 +313,85 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n     }\n \n+    public void setReplicationRemainingPercent(long percentComplete) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setReplicationCompletion(percentComplete).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public long getReplicationRemainingPercent() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+        if (record == null) {\n+            return 0;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getReplicationCompletion();\n+    }\n+\n+    public void setDataConsistentOnStandby(boolean isConsistent) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setDataConsistent(isConsistent).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public boolean getDataConsistentOnStandby() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+\n+        // TODO: Initially, snapshot sync is pending so the data is not consistent.  But what if everything was applied and\n+        // the standby rebooted?  In that case it is consistent\n+        if (record == null) {\n+            return false;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getDataConsistent();\n+    }\n+\n     @Override\n     public String toString() {\n-        String s = new String();\n-        s.concat(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID.getVal() + \" \" + getTopologyConfigId() +\" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED.getVal() + \" \" + getLastSnapStartTimestamp() +\" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED.getVal() + \" \" + getLastSnapTransferDoneTimestamp() + \" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED.getVal() + \" \" + getLastAppliedBaseSnapshotTimestamp() + \" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM.getVal() + \" \" + getLastSnapSeqNum() + \" \");\n-        s.concat(LogReplicationMetadataType.LAST_LOG_PROCESSED.getVal() + \" \" + getLastProcessedLogTimestamp() + \" \");\n-\n-        return s;\n+        StringBuilder builder = new StringBuilder();\n+        for (LogReplicationMetadataType type : LogReplicationMetadataType.values()) {\n+            builder.append(type).append(\": \");\n+            switch (type) {\n+                case TOPOLOGY_CONFIG_ID:\n+                    builder.append(getTopologyConfigId());\n+                    break;\n+                case LAST_SNAPSHOT_STARTED:\n+                   builder.append(getLastSnapStartTimestamp());\n+                   break;\n+                case LAST_SNAPSHOT_TRANSFERRED:\n+                   builder.append(getLastSnapTransferDoneTimestamp());\n+                   break;\n+                case LAST_SNAPSHOT_APPLIED:\n+                   builder.append(getLastAppliedBaseSnapshotTimestamp());\n+                   break;\n+                case LAST_SNAPSHOT_SEQ_NUM:\n+                   builder.append(getLastSnapSeqNum());\n+                   break;\n+                case LAST_LOG_ENTRY_PROCESSED:\n+                   builder.append(getLastProcessedLogTimestamp());\n+                   break;\n+                case REMAINING_REPLICATION_PERCENT:\n+                    builder.append(getReplicationRemainingPercent());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYwNjEyMQ==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462606121", "createdAt": "2020-07-29T21:40:52Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -301,21 +313,85 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n     }\n \n+    public void setReplicationRemainingPercent(long percentComplete) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setReplicationCompletion(percentComplete).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public long getReplicationRemainingPercent() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+        if (record == null) {\n+            return 0;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getReplicationCompletion();\n+    }\n+\n+    public void setDataConsistentOnStandby(boolean isConsistent) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setDataConsistent(isConsistent).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public boolean getDataConsistentOnStandby() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+\n+        // TODO: Initially, snapshot sync is pending so the data is not consistent.  But what if everything was applied and\n+        // the standby rebooted?  In that case it is consistent\n+        if (record == null) {\n+            return false;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getDataConsistent();\n+    }\n+\n     @Override\n     public String toString() {\n-        String s = new String();\n-        s.concat(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID.getVal() + \" \" + getTopologyConfigId() +\" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED.getVal() + \" \" + getLastSnapStartTimestamp() +\" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED.getVal() + \" \" + getLastSnapTransferDoneTimestamp() + \" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED.getVal() + \" \" + getLastAppliedBaseSnapshotTimestamp() + \" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM.getVal() + \" \" + getLastSnapSeqNum() + \" \");\n-        s.concat(LogReplicationMetadataType.LAST_LOG_PROCESSED.getVal() + \" \" + getLastProcessedLogTimestamp() + \" \");\n-\n-        return s;\n+        StringBuilder builder = new StringBuilder();\n+        for (LogReplicationMetadataType type : LogReplicationMetadataType.values()) {\n+            builder.append(type).append(\": \");\n+            switch (type) {\n+                case TOPOLOGY_CONFIG_ID:\n+                    builder.append(getTopologyConfigId());\n+                    break;\n+                case LAST_SNAPSHOT_STARTED:\n+                   builder.append(getLastSnapStartTimestamp());\n+                   break;\n+                case LAST_SNAPSHOT_TRANSFERRED:\n+                   builder.append(getLastSnapTransferDoneTimestamp());\n+                   break;\n+                case LAST_SNAPSHOT_APPLIED:\n+                   builder.append(getLastAppliedBaseSnapshotTimestamp());\n+                   break;\n+                case LAST_SNAPSHOT_SEQ_NUM:\n+                   builder.append(getLastSnapSeqNum());\n+                   break;\n+                case LAST_LOG_ENTRY_PROCESSED:\n+                   builder.append(getLastProcessedLogTimestamp());\n+                   break;\n+                case REMAINING_REPLICATION_PERCENT:\n+                    builder.append(getReplicationRemainingPercent());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMzEwMw=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 246}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDMzNjA1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozODo0MFrOG4mcwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjozODo0MFrOG4mcwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwMzM5NA==", "bodyText": "missing DATA_CONSISTENT_ON_STANDBY?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462003394", "createdAt": "2020-07-29T02:38:40Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -301,21 +313,85 @@ public void setSnapshotApplied(LogReplicationEntry entry) {\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n     }\n \n+    public void setReplicationRemainingPercent(long percentComplete) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setReplicationCompletion(percentComplete).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public long getReplicationRemainingPercent() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.REPLICATION_COMPLETION).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+        if (record == null) {\n+            return 0;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getReplicationCompletion();\n+    }\n+\n+    public void setDataConsistentOnStandby(boolean isConsistent) {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        ReplicationStatusVal val = ReplicationStatusVal.newBuilder().setDataConsistent(isConsistent).build();\n+        TxBuilder txBuilder = corfuStore.tx(NAMESPACE);\n+        txBuilder.update(REPLICATION_STATUS_TABLE, key, val, null);\n+        txBuilder.commit();\n+    }\n+\n+    public boolean getDataConsistentOnStandby() {\n+        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setKey(\n+                ReplicationStatusKey.Status.IS_DATA_CONSISTENT).build();\n+        CorfuRecord record = corfuStore.query(NAMESPACE).getRecord(REPLICATION_STATUS_TABLE, key);\n+\n+        // TODO: Initially, snapshot sync is pending so the data is not consistent.  But what if everything was applied and\n+        // the standby rebooted?  In that case it is consistent\n+        if (record == null) {\n+            return false;\n+        }\n+        ReplicationStatusVal val = (ReplicationStatusVal)record.getPayload();\n+        return val.getDataConsistent();\n+    }\n+\n     @Override\n     public String toString() {\n-        String s = new String();\n-        s.concat(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID.getVal() + \" \" + getTopologyConfigId() +\" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED.getVal() + \" \" + getLastSnapStartTimestamp() +\" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED.getVal() + \" \" + getLastSnapTransferDoneTimestamp() + \" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED.getVal() + \" \" + getLastAppliedBaseSnapshotTimestamp() + \" \");\n-        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM.getVal() + \" \" + getLastSnapSeqNum() + \" \");\n-        s.concat(LogReplicationMetadataType.LAST_LOG_PROCESSED.getVal() + \" \" + getLastProcessedLogTimestamp() + \" \");\n-\n-        return s;\n+        StringBuilder builder = new StringBuilder();\n+        for (LogReplicationMetadataType type : LogReplicationMetadataType.values()) {\n+            builder.append(type).append(\": \");\n+            switch (type) {\n+                case TOPOLOGY_CONFIG_ID:\n+                    builder.append(getTopologyConfigId());\n+                    break;\n+                case LAST_SNAPSHOT_STARTED:\n+                   builder.append(getLastSnapStartTimestamp());\n+                   break;\n+                case LAST_SNAPSHOT_TRANSFERRED:\n+                   builder.append(getLastSnapTransferDoneTimestamp());\n+                   break;\n+                case LAST_SNAPSHOT_APPLIED:\n+                   builder.append(getLastAppliedBaseSnapshotTimestamp());\n+                   break;\n+                case LAST_SNAPSHOT_SEQ_NUM:\n+                   builder.append(getLastSnapSeqNum());\n+                   break;\n+                case LAST_LOG_ENTRY_PROCESSED:\n+                   builder.append(getLastProcessedLogTimestamp());\n+                   break;\n+                case REMAINING_REPLICATION_PERCENT:\n+                    builder.append(getReplicationRemainingPercent());\n+                default:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 247}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDM0ODE0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjo0NToyNVrOG4mjow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTo1NTo1M1rOG5LpXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwNTE1NQ==", "bodyText": "This class has a receive method where we first receive messages. And there we have some logic to process a SNAPSHOT_START marker, so I think we should set dataConsistent to false in processSnapshotStart. As we now we're starting the transfer of a snapshot sync, so from that point until the snapshot_end is received and applied is when we'll set to true.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462005155", "createdAt": "2020-07-29T02:45:25Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -398,14 +401,17 @@ private void processSnapshotMessage(LogReplicationEntry message) {\n         switch (message.getMetadata().getMessageMetadataType()) {\n             case SNAPSHOT_MESSAGE:\n                 snapshotWriter.apply(message);\n-                return;\n+                break;\n             case SNAPSHOT_END:\n+                dataConsistent.set(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwNjcyOA==", "bodyText": "So we can remove it from here and set it on the reception of the start marker.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462006728", "createdAt": "2020-07-29T02:51:40Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -398,14 +401,17 @@ private void processSnapshotMessage(LogReplicationEntry message) {\n         switch (message.getMetadata().getMessageMetadataType()) {\n             case SNAPSHOT_MESSAGE:\n                 snapshotWriter.apply(message);\n-                return;\n+                break;\n             case SNAPSHOT_END:\n+                dataConsistent.set(false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwNTE1NQ=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYxMjgyOQ==", "bodyText": "but the data will be consistent and can be read during the transfer, right?  Only when it is being applied, it is not consistent.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462612829", "createdAt": "2020-07-29T21:55:53Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -398,14 +401,17 @@ private void processSnapshotMessage(LogReplicationEntry message) {\n         switch (message.getMetadata().getMessageMetadataType()) {\n             case SNAPSHOT_MESSAGE:\n                 snapshotWriter.apply(message);\n-                return;\n+                break;\n             case SNAPSHOT_END:\n+                dataConsistent.set(false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwNTE1NQ=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDM1MDYyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjo0NzowMFrOG4mlGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMjowMzo1N1rOG5L3TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwNTUzMQ==", "bodyText": "To keep a sense of atomicity maybe we can have a private method setDataConsistency(boolean consistent) something like that where we update the local variable and the persisted...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462005531", "createdAt": "2020-07-29T02:47:00Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -398,14 +401,17 @@ private void processSnapshotMessage(LogReplicationEntry message) {\n         switch (message.getMetadata().getMessageMetadataType()) {\n             case SNAPSHOT_MESSAGE:\n                 snapshotWriter.apply(message);\n-                return;\n+                break;\n             case SNAPSHOT_END:\n+                dataConsistent.set(false);\n+                logReplicationMetadataManager.setDataConsistentOnStandby(dataConsistent.get());\n                 snapshotWriter.snapshotTransferDone(message);\n                 completeSnapshotApply(message);\n-                return;\n+                dataConsistent.set(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYxNjM5Ng==", "bodyText": "sure", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462616396", "createdAt": "2020-07-29T22:03:57Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -398,14 +401,17 @@ private void processSnapshotMessage(LogReplicationEntry message) {\n         switch (message.getMetadata().getMessageMetadataType()) {\n             case SNAPSHOT_MESSAGE:\n                 snapshotWriter.apply(message);\n-                return;\n+                break;\n             case SNAPSHOT_END:\n+                dataConsistent.set(false);\n+                logReplicationMetadataManager.setDataConsistentOnStandby(dataConsistent.get());\n                 snapshotWriter.snapshotTransferDone(message);\n                 completeSnapshotApply(message);\n-                return;\n+                dataConsistent.set(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwNTUzMQ=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDM2OTgyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjo1Nzo0OFrOG4mwXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToxMTowM1rOG5KWDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwODQxMg==", "bodyText": "I just want to clarify. ackedTimestamp is the last timestamp acked by the receiver that we receive when the entry is replicated, so it should be smaller than the maxReplicatedStreamTail, for the range to be valid right?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462008412", "createdAt": "2020-07-29T02:57:48Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;\n+        }\n+        long remainingEntriesToSend = 0;\n+        for (String stream : config.getStreamsToReplicate()) {\n+            UUID streamId = CorfuRuntime.getStreamID(stream);\n+            StreamAddressRange range = new StreamAddressRange(streamId, maxReplicatedStreamTail, ackedTimestamp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 262}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5MTUwMw==", "bodyText": "good question.  This range is used in StreamAddressSpace.getAddressesInRange() below on line 284.  That function takes a range where start>end.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462591503", "createdAt": "2020-07-29T21:11:03Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;\n+        }\n+        long remainingEntriesToSend = 0;\n+        for (String stream : config.getStreamsToReplicate()) {\n+            UUID streamId = CorfuRuntime.getStreamID(stream);\n+            StreamAddressRange range = new StreamAddressRange(streamId, maxReplicatedStreamTail, ackedTimestamp);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwODQxMg=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 262}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDM3OTAwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMzowMjozOFrOG4m1qQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo1MTo0MVrOG5Jsog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwOTc2OQ==", "bodyText": "no need to do this for this review, but we might add an issue to track the fact that we should move this configuration out to the config file.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462009769", "createdAt": "2020-07-29T03:02:38Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4MDg5OA==", "bodyText": "I will add it in the follow up PR #2657", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462580898", "createdAt": "2020-07-29T20:51:41Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -61,119 +70,89 @@\n      */\n     private final LogReplicationConfig config;\n \n+    /*\n+     * Log Replication MetadataManager.\n+     */\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    /*\n+     * Last ack'd timestamp from Receiver\n+     */\n+    private AtomicLong lastAckedTimestamp = new AtomicLong(Address.NON_ADDRESS);\n+\n+    /*\n+     * Periodic Thread which reads the last Acked Timestamp and writes it to the metadata table\n+     */\n+    ScheduledExecutorService lastAckedTsPoller;\n+\n+    /*\n+     * Interval at which the thread reads the last Acked Timestamp\n+     */\n+    private static int ACKED_TS_READ_INTERVAL_SECONDS = 15;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAwOTc2OQ=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDM4NzcxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMzowNzozNVrOG4m6gA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMzoxMjozOFrOG4m_Pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxMTAwOA==", "bodyText": "Actually, this is a bit weird. But I realized it the other day while looking at other things. This method for the Source is not really never called. All the logic for processing ACKs is taken care in the SnapshotSender and LogEntrySender respectively, so it is there where we should be setting this lastAckedTimestamp.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462011008", "createdAt": "2020-07-29T03:07:35Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxMjIyMg==", "bodyText": "Actually, I think we have a major concern here and its that SnapshotSender does not really accumulate intermediate SNAPSHOT_REPLICATED, so it only updates at the end.. But you can bypass that (for now) by updating when you send something...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462012222", "createdAt": "2020-07-29T03:12:38Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxMTAwOA=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 208}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDM5ODIwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMzoxNDowOVrOG4nAoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo1OTo0N1rOG5J-HQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxMjU3Nw==", "bodyText": "s -> streamName", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462012577", "createdAt": "2020-07-29T03:14:09Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4NTM3Mw==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462585373", "createdAt": "2020-07-29T20:59:47Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxMjU3Nw=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 232}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDM5OTU0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMzoxNDo0NVrOG4nBYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTowMjowNVrOG5KC5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxMjc2OA==", "bodyText": "if tailMap.contains(streamUuid)?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462012768", "createdAt": "2020-07-29T03:14:45Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 234}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4NjU5Nw==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462586597", "createdAt": "2020-07-29T21:02:05Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxMjc2OA=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 234}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDQyNDM0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMzoyOToxMlrOG4nPzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTowODoxMlrOG5KQDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNjQ2Mw==", "bodyText": "Is this true? what if the maxReplicatedStreamTail is -1, that means there is no data so remaining is 0%, right?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462016463", "createdAt": "2020-07-29T03:29:12Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 257}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNjU3Ng==", "bodyText": "We should add tests to cover all these cases!", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462016576", "createdAt": "2020-07-29T03:29:40Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNjQ2Mw=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 257}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4OTk2NA==", "bodyText": "Added the case for maxTail = -1.\nYes for tests.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462589964", "createdAt": "2020-07-29T21:08:12Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNjQ2Mw=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 257}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDQzMDI5OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMzozMjo1OVrOG4nTRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToxMjo0MVrOG5KZXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNzM1MA==", "bodyText": "No need, the address map you requested is already confined to that range, you can directly: addressSpace.getAddressMap().getLongCardinality()", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462017350", "createdAt": "2020-07-29T03:32:59Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;\n+        }\n+        long remainingEntriesToSend = 0;\n+        for (String stream : config.getStreamsToReplicate()) {\n+            UUID streamId = CorfuRuntime.getStreamID(stream);\n+            StreamAddressRange range = new StreamAddressRange(streamId, maxReplicatedStreamTail, ackedTimestamp);\n+            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n+            Roaring64NavigableMap map = addressSpace.getAddressesInRange(range);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5MjM0OQ==", "bodyText": "done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462592349", "createdAt": "2020-07-29T21:12:41Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;\n+        }\n+        long remainingEntriesToSend = 0;\n+        for (String stream : config.getStreamsToReplicate()) {\n+            UUID streamId = CorfuRuntime.getStreamID(stream);\n+            StreamAddressRange range = new StreamAddressRange(streamId, maxReplicatedStreamTail, ackedTimestamp);\n+            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n+            Roaring64NavigableMap map = addressSpace.getAddressesInRange(range);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNzM1MA=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 264}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDQzMTE1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMzozMzozNVrOG4nTxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToxNDozMFrOG5KcqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNzQ3Nw==", "bodyText": "should we add a logging before returning?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462017477", "createdAt": "2020-07-29T03:33:35Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;\n+        }\n+        long remainingEntriesToSend = 0;\n+        for (String stream : config.getStreamsToReplicate()) {\n+            UUID streamId = CorfuRuntime.getStreamID(stream);\n+            StreamAddressRange range = new StreamAddressRange(streamId, maxReplicatedStreamTail, ackedTimestamp);\n+            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n+            Roaring64NavigableMap map = addressSpace.getAddressesInRange(range);\n+            remainingEntriesToSend += map.getLongCardinality();\n+        }\n+        return remainingEntriesToSend;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 267}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5MzE5Mw==", "bodyText": "we can add a trace.. because this thread runs every 15seconds right now and other levels will flood the log.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462593193", "createdAt": "2020-07-29T21:14:30Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationSourceManager.java", "diffHunk": "@@ -247,17 +226,75 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         // Process ACKs from Application, for both, log entry and snapshot sync.\n         if(message.getMetadata().getMessageMetadataType() == MessageType.LOG_ENTRY_REPLICATED) {\n             log.debug(\"Log entry sync ACK received on timestamp {}\", message.getMetadata().getTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.LOG_ENTRY_SYNC_REPLICATED,\n                 new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp())));\n         } else if (message.getMetadata().getMessageMetadataType() == MessageType.SNAPSHOT_REPLICATED) {\n             log.debug(\"Snapshot sync ACK received on base timestamp {}\", message.getMetadata().getSnapshotTimestamp());\n+            lastAckedTimestamp.set(message.getMetadata().getTimestamp());\n             logReplicationFSM.input(new LogReplicationEvent(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE,\n                     new LogReplicationEventMetadata(message.getMetadata().getSyncRequestId(), message.getMetadata().getTimestamp(),\n                             message.getMetadata().getTimestamp())));\n         } else {\n             log.debug(\"Received data message of type {} not an ACK\", message.getMetadata().getMessageMetadataType());\n         }\n-\n         return null;\n     }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail() {\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(s);\n+            if (tailMap.get(streamUuid) != null) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp acked by the receiver, calculate how many entries remain to be sent for all replicated streams.\n+     *\n+     * @param ackedTimestamp Timestamp ack'd by the receiver\n+     *\n+     * For Log Entry Sync, this function returns the total number of entries remaining to be sent across all replicated\n+     * streams.\n+     * For Snapshot Sync, each entry sent is a snapshot.  So this function returns the total number of snapshots\n+     * remaining to be sent.\n+     * If the ack'd timestamp is uninitialized, it returns 100%, which means no replication has been done.\n+     */\n+    private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+\n+        if (ackedTimestamp == Address.NON_ADDRESS) {\n+            return FULL_REPLICATION_REMAINING_PERCENT;\n+        }\n+        long remainingEntriesToSend = 0;\n+        for (String stream : config.getStreamsToReplicate()) {\n+            UUID streamId = CorfuRuntime.getStreamID(stream);\n+            StreamAddressRange range = new StreamAddressRange(streamId, maxReplicatedStreamTail, ackedTimestamp);\n+            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n+            Roaring64NavigableMap map = addressSpace.getAddressesInRange(range);\n+            remainingEntriesToSend += map.getLongCardinality();\n+        }\n+        return remainingEntriesToSend;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNzQ3Nw=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 267}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NDQzMjg1OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/LogReplicationIT.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMzozNDozOVrOG4nU0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMjowNDozNFrOG5L4Tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNzc0Nw==", "bodyText": "Where is this being used?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462017747", "createdAt": "2020-07-29T03:34:39Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/LogReplicationIT.java", "diffHunk": "@@ -1380,6 +1377,11 @@ private void verifyPersistedLogEntryMetadata() {\n         assertThat(expectedAckTimestamp == lastLogProcessed).isTrue();\n     }\n \n+    private void verifyRemainingReplicationPercent(long remainingPercent) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYxNjY1NA==", "bodyText": "I did not remove so that it can be used later when we add tests", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r462616654", "createdAt": "2020-07-29T22:04:34Z", "author": {"login": "pankti-m"}, "path": "test/src/test/java/org/corfudb/integration/LogReplicationIT.java", "diffHunk": "@@ -1380,6 +1377,11 @@ private void verifyPersistedLogEntryMetadata() {\n         assertThat(expectedAckTimestamp == lastLogProcessed).isTrue();\n     }\n \n+    private void verifyRemainingReplicationPercent(long remainingPercent) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNzc0Nw=="}, "originalCommit": {"oid": "3b5a84dac4f787ac072b979e2843c94450b85682"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NjYwNDg3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerBaseAdapter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQwMToyNDoxM1rOG6aZEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQwMToyNDoxM1rOG6aZEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkwMjk5Mg==", "bodyText": "It's not guaranteed to always place the local cluster in the 0th index position right?\nAm I mistaken?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r463902992", "createdAt": "2020-08-01T01:24:13Z", "author": {"login": "hisundar"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerBaseAdapter.java", "diffHunk": "@@ -45,7 +46,8 @@ public void prepareToBecomeStandby() {\n         corfuReplicationDiscoveryService.prepareToBecomeStandby();\n     }\n \n-    public int queryReplicationStatus() {\n-        return corfuReplicationDiscoveryService.queryReplicationStatus();\n+    public LogReplicationMetadata.ReplicationStatusVal queryReplicationStatus() {\n+        return corfuReplicationDiscoveryService.queryReplicationStatus(\n+            topologyConfig.getClusters(0).getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b3c2c042cebde1c55ccbc7969989adc597b21df"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NjYwODA3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQwMToyNzozNlrOG6aaog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQwMToyNzozNlrOG6aaog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkwMzM5NA==", "bodyText": "I only see one type - is it possible to overload the queryReplicationStatus to return the full map?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2641#discussion_r463903394", "createdAt": "2020-08-01T01:27:36Z", "author": {"login": "hisundar"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -660,46 +664,36 @@ public void updateTopology(LogReplicationClusterInfo.TopologyConfigurationMsg to\n     }\n \n     /**\n-     * Query all replicated stream log tails and remember the max\n-     * and query each standbySite information according to the ackInformation decide all manay total\n-     * msg needs to send out.\n+     * No work needs to be done here.  If in the Active state, writes to all replicated streams have stopped at this time.\n+     * Following this, the ClusterManagerAdapter can query the status of ongoing snapshot sync on the\n+     * local(active) cluster.\n      */\n     @Override\n     public void prepareToBecomeStandby() {\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE && replicationManager != null) {\n-            replicationManager.prepareClusterRoleChange();\n+        if (ClusterRole.ACTIVE == localClusterDescriptor.getRole()) {\n+            log.info(\"Received a Request to Become Standby\");\n         } else {\n-            log.warn(\"Illegal prepareToBecomeStandby when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n+            log.error(\"Received a Request to Become Standby in current role {}\", localClusterDescriptor.getRole());\n         }\n     }\n \n     /**\n-     * Query all replicated stream log tails and calculate the number of messages to be sent.\n-     * If the max tail has changed, return 0%.\n+     * Active Cluster - Read the shared metadata table to find the status of any ongoing snapshot or log entry sync\n+     * and return a completion percentage.\n+     * Standby Cluster - Read the shared metadata table and find if data is consistent(returns false if\n+     * snapshot sync is in the apply phase)\n      */\n     @Override\n-    public int queryReplicationStatus() {\n-        //TODO make sure caller should query all nodes in the cluster and pick the max of these 3 values\n-        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n-            if (!isLeader.get()) {\n-                log.warn(\"Illegal queryReplicationStatus when node is not a leader \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            if (replicationManager == null) {\n-                log.warn(\"Illegal queryReplicationStatus when replication manager is null \" +\n-                        \"in an ACTIVE Cluster{} \", localClusterDescriptor.getClusterId());\n-                return 0;\n-            }\n-\n-            return replicationManager.queryReplicationStatus();\n-        } else {\n-            log.warn(\"Illegal queryReplicationStatus when cluster{} with role {}\",\n-                    localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n-            return INVALID_REPLICATION_STATUS;\n+    public LogReplicationMetadata.ReplicationStatusVal queryReplicationStatus(String clusterId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4b3c2c042cebde1c55ccbc7969989adc597b21df"}, "originalPosition": 89}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1864, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}