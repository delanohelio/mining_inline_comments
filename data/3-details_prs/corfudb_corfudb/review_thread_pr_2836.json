{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI5ODcwMzQy", "number": 2836, "reviewThreads": {"totalCount": 78, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMjo0NTowM1rOFFSpwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMDozODoyNVrOFTRdkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMDkyODAwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMjo0NTowM1rOIFvZhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQyMTo1MDowMVrOIGhgtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjg5MDM3Mw==", "bodyText": "nit: should be equal to the epoch in request header", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r542890373", "createdAt": "2020-12-14T22:45:03Z", "author": {"login": "hisundar"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@Slf4j\n+public class BatchProcessorTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+    private BatchProcessor batchProcessor;\n+    private StreamLog mockStreamLog;\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final long DEFAULT_SEAL_EPOCH = 1L;\n+    private final long LARGER_SEAL_EPOCH = 5L;\n+\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should equal to the epoch in request header.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a8a79b1a4e8a3c67d46ecef77c46d73be17432"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzcxMTQxNA==", "bodyText": "Added, thanks!", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r543711414", "createdAt": "2020-12-15T21:50:01Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@Slf4j\n+public class BatchProcessorTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+    private BatchProcessor batchProcessor;\n+    private StreamLog mockStreamLog;\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final long DEFAULT_SEAL_EPOCH = 1L;\n+    private final long LARGER_SEAL_EPOCH = 5L;\n+\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should equal to the epoch in request header.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjg5MDM3Mw=="}, "originalCommit": {"oid": "04a8a79b1a4e8a3c67d46ecef77c46d73be17432"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMDkzMDM1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMjo0NToyNVrOIFva2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQyMTo1MDowOFrOIGhg_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjg5MDcxMw==", "bodyText": "nit: should be equal to the epoch in request header", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r542890713", "createdAt": "2020-12-14T22:45:25Z", "author": {"login": "hisundar"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@Slf4j\n+public class BatchProcessorTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+    private BatchProcessor batchProcessor;\n+    private StreamLog mockStreamLog;\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final long DEFAULT_SEAL_EPOCH = 1L;\n+    private final long LARGER_SEAL_EPOCH = 5L;\n+\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getBasicHeader(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should equal to the epoch in request header.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a8a79b1a4e8a3c67d46ecef77c46d73be17432"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzcxMTQ4Nw==", "bodyText": "Added, thanks!", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r543711487", "createdAt": "2020-12-15T21:50:08Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@Slf4j\n+public class BatchProcessorTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+    private BatchProcessor batchProcessor;\n+    private StreamLog mockStreamLog;\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final long DEFAULT_SEAL_EPOCH = 1L;\n+    private final long LARGER_SEAL_EPOCH = 5L;\n+\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getBasicHeader(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should equal to the epoch in request header.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjg5MDcxMw=="}, "originalCommit": {"oid": "04a8a79b1a4e8a3c67d46ecef77c46d73be17432"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMDk0MjI1OnYy", "diffSide": "RIGHT", "path": "test/src/test/resources/logback-test.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMjo0NzoxOFrOIFvijw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMjo0NzoxOFrOIFvijw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjg5MjY4Nw==", "bodyText": "Can the test log level still be left as INFO?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r542892687", "createdAt": "2020-12-14T22:47:18Z", "author": {"login": "hisundar"}, "path": "test/src/test/resources/logback-test.xml", "diffHunk": "@@ -62,9 +62,9 @@\n     <logger name=\"org.corfudb.runtime.object\" level=\"INFO\"/>\n     <logger name=\"org.corfudb.runtime.clients\" level=\"INFO\"/>\n     <logger name=\"org.corfudb.infrastructure\" level=\"INFO\"/>\n-    <logger name=\"io.netty.util\" level=\"INFO\"/>\n-    <logger name=\"io.netty.util.internal\" level=\"INFO\"/>\n-    <logger name=\"io.netty.buffer\" level=\"INFO\"/>\n+    <logger name=\"io.netty.util\" level=\"WARN\"/>\n+    <logger name=\"io.netty.util.internal\" level=\"WARN\"/>\n+    <logger name=\"io.netty.buffer\" level=\"WARN\"/>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a8a79b1a4e8a3c67d46ecef77c46d73be17432"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMDk0MjU0OnYy", "diffSide": "RIGHT", "path": "test/src/test/resources/logback-test.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMjo0NzoyMVrOIFvivw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMjo0NzoyMVrOIFvivw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjg5MjczNQ==", "bodyText": "Do you want to check this in with the default appender set to STDOUT?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r542892735", "createdAt": "2020-12-14T22:47:21Z", "author": {"login": "hisundar"}, "path": "test/src/test/resources/logback-test.xml", "diffHunk": "@@ -77,7 +77,7 @@\n \n     <root level=\"INFO\">\n         <!--<appender-ref ref=\"FILE\" />-->\n-        <!--<appender-ref ref=\"STDOUT\" />-->\n+        <appender-ref ref=\"STDOUT\" />", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a8a79b1a4e8a3c67d46ecef77c46d73be17432"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzg4ODE0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwNDoxMzo0OFrOIGuPxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwNDoxMzo0OFrOIGuPxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzkyMDA2OA==", "bodyText": "Could be final?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r543920068", "createdAt": "2020-12-16T04:13:48Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -12,50 +12,48 @@\n import java.util.concurrent.Executors;\n import java.util.concurrent.LinkedBlockingQueue;\n import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n import javax.annotation.Nonnull;\n-\n-import io.micrometer.core.instrument.DistributionSummary;\n-import io.micrometer.core.instrument.Timer;\n import lombok.extern.slf4j.Slf4j;\n import org.corfudb.common.metrics.micrometer.MeterRegistryProvider;\n import org.corfudb.infrastructure.BatchWriterOperation.Type;\n import org.corfudb.infrastructure.log.StreamLog;\n-import org.corfudb.protocols.wireprotocol.CorfuPayloadMsg;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.CorfuProtocolLogData;\n import org.corfudb.protocols.wireprotocol.LogData;\n-import org.corfudb.protocols.wireprotocol.PriorityLevel;\n-import org.corfudb.protocols.wireprotocol.RangeWriteMsg;\n import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n-import org.corfudb.protocols.wireprotocol.TailsRequest;\n import org.corfudb.protocols.wireprotocol.TailsResponse;\n-import org.corfudb.protocols.wireprotocol.TrimRequest;\n-import org.corfudb.protocols.wireprotocol.WriteRequest;\n+import org.corfudb.runtime.proto.service.CorfuMessage;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestPayloadMsg;\n import org.corfudb.runtime.exceptions.QuotaExceededException;\n import org.corfudb.runtime.exceptions.WrongEpochException;\n import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n \n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogData;\n+\n /**\n  * This class manages access for operations that need ordering while executing against\n  * the backing storage.\n  */\n @Slf4j\n public class BatchProcessor implements AutoCloseable {\n \n-    final private int BATCH_SIZE = 50;\n-\n-    final private boolean sync;\n-\n-    final private StreamLog streamLog;\n-\n-    final private BlockingQueue<BatchWriterOperation> operationsQueue;\n+    private final int BATCH_SIZE = 50;\n+    private final boolean sync;\n+    private final StreamLog streamLog;\n+    private final BlockingQueue<BatchWriterOperation> operationsQueue;\n \n     private ExecutorService processorService = Executors\n             .newSingleThreadExecutor(new ThreadFactoryBuilder()\n                     .setDaemon(false)\n                     .setNameFormat(\"LogUnit-BatchProcessor-%d\")\n                     .build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b575c10406e3da944f3ed8e91ada0806cf553d5b"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzg5NTk1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwNDoxNToyN1rOIGuUwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwMTowODoyNVrOIPbqMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzkyMTM0NQ==", "bodyText": "looks like we can remove the writeRecordTimer and queueSizeDist?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r543921345", "createdAt": "2020-12-16T04:15:27Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -12,50 +12,48 @@\n import java.util.concurrent.Executors;\n import java.util.concurrent.LinkedBlockingQueue;\n import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n import javax.annotation.Nonnull;\n-\n-import io.micrometer.core.instrument.DistributionSummary;\n-import io.micrometer.core.instrument.Timer;\n import lombok.extern.slf4j.Slf4j;\n import org.corfudb.common.metrics.micrometer.MeterRegistryProvider;\n import org.corfudb.infrastructure.BatchWriterOperation.Type;\n import org.corfudb.infrastructure.log.StreamLog;\n-import org.corfudb.protocols.wireprotocol.CorfuPayloadMsg;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.CorfuProtocolLogData;\n import org.corfudb.protocols.wireprotocol.LogData;\n-import org.corfudb.protocols.wireprotocol.PriorityLevel;\n-import org.corfudb.protocols.wireprotocol.RangeWriteMsg;\n import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n-import org.corfudb.protocols.wireprotocol.TailsRequest;\n import org.corfudb.protocols.wireprotocol.TailsResponse;\n-import org.corfudb.protocols.wireprotocol.TrimRequest;\n-import org.corfudb.protocols.wireprotocol.WriteRequest;\n+import org.corfudb.runtime.proto.service.CorfuMessage;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestPayloadMsg;\n import org.corfudb.runtime.exceptions.QuotaExceededException;\n import org.corfudb.runtime.exceptions.WrongEpochException;\n import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n \n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogData;\n+\n /**\n  * This class manages access for operations that need ordering while executing against\n  * the backing storage.\n  */\n @Slf4j\n public class BatchProcessor implements AutoCloseable {\n \n-    final private int BATCH_SIZE = 50;\n-\n-    final private boolean sync;\n-\n-    final private StreamLog streamLog;\n-\n-    final private BlockingQueue<BatchWriterOperation> operationsQueue;\n+    private final int BATCH_SIZE = 50;\n+    private final boolean sync;\n+    private final StreamLog streamLog;\n+    private final BlockingQueue<BatchWriterOperation> operationsQueue;\n \n     private ExecutorService processorService = Executors\n             .newSingleThreadExecutor(new ThreadFactoryBuilder()\n                     .setDaemon(false)\n                     .setNameFormat(\"LogUnit-BatchProcessor-%d\")\n                     .build());\n+\n     private final Optional<Timer> writeRecordTimer;\n     private final Optional<Timer> writeRecordsTimer;\n     private final Optional<DistributionSummary> queueSizeDist;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b575c10406e3da944f3ed8e91ada0806cf553d5b"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzA1MjcyMQ==", "bodyText": "These appeared unused because the metrics were accidentally removed. See https://github.com/CorfuDB/CorfuDB/pull/2836/files#r547489298.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r553052721", "createdAt": "2021-01-07T01:08:25Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -12,50 +12,48 @@\n import java.util.concurrent.Executors;\n import java.util.concurrent.LinkedBlockingQueue;\n import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n import javax.annotation.Nonnull;\n-\n-import io.micrometer.core.instrument.DistributionSummary;\n-import io.micrometer.core.instrument.Timer;\n import lombok.extern.slf4j.Slf4j;\n import org.corfudb.common.metrics.micrometer.MeterRegistryProvider;\n import org.corfudb.infrastructure.BatchWriterOperation.Type;\n import org.corfudb.infrastructure.log.StreamLog;\n-import org.corfudb.protocols.wireprotocol.CorfuPayloadMsg;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.CorfuProtocolLogData;\n import org.corfudb.protocols.wireprotocol.LogData;\n-import org.corfudb.protocols.wireprotocol.PriorityLevel;\n-import org.corfudb.protocols.wireprotocol.RangeWriteMsg;\n import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n-import org.corfudb.protocols.wireprotocol.TailsRequest;\n import org.corfudb.protocols.wireprotocol.TailsResponse;\n-import org.corfudb.protocols.wireprotocol.TrimRequest;\n-import org.corfudb.protocols.wireprotocol.WriteRequest;\n+import org.corfudb.runtime.proto.service.CorfuMessage;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestPayloadMsg;\n import org.corfudb.runtime.exceptions.QuotaExceededException;\n import org.corfudb.runtime.exceptions.WrongEpochException;\n import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n \n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogData;\n+\n /**\n  * This class manages access for operations that need ordering while executing against\n  * the backing storage.\n  */\n @Slf4j\n public class BatchProcessor implements AutoCloseable {\n \n-    final private int BATCH_SIZE = 50;\n-\n-    final private boolean sync;\n-\n-    final private StreamLog streamLog;\n-\n-    final private BlockingQueue<BatchWriterOperation> operationsQueue;\n+    private final int BATCH_SIZE = 50;\n+    private final boolean sync;\n+    private final StreamLog streamLog;\n+    private final BlockingQueue<BatchWriterOperation> operationsQueue;\n \n     private ExecutorService processorService = Executors\n             .newSingleThreadExecutor(new ThreadFactoryBuilder()\n                     .setDaemon(false)\n                     .setNameFormat(\"LogUnit-BatchProcessor-%d\")\n                     .build());\n+\n     private final Optional<Timer> writeRecordTimer;\n     private final Optional<Timer> writeRecordsTimer;\n     private final Optional<DistributionSummary> queueSizeDist;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzkyMTM0NQ=="}, "originalCommit": {"oid": "b575c10406e3da944f3ed8e91ada0806cf553d5b"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxODA3NTQ2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwNDo1Mzo1MFrOIGwESw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNzozOTowNFrOIIsVIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzk0OTg5OQ==", "bodyText": "It seems like we are using different logging levels among those request handlers, should we make them consistent? Also, @Maithem previously pointed out that it could be better to wrap the log.trace with log.isTraceEnabled().", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r543949899", "createdAt": "2020-12-16T04:53:50Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +184,256 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b575c10406e3da944f3ed8e91ada0806cf553d5b"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTk4NTgyNg==", "bodyText": "It isn't clear to me that all RPCs should have the same logging level. In any case, I've wrapped these with log.isTraceEnabled().", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r545985826", "createdAt": "2020-12-18T17:39:04Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +184,256 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzk0OTg5OQ=="}, "originalCommit": {"oid": "b575c10406e3da944f3ed8e91ada0806cf553d5b"}, "originalPosition": 217}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxODE0OTM4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwNTowODo0NlrOIGwx7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNzozNzo1NFrOIIsSjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzk2MTU4Mw==", "bodyText": "Will it be better to keep the naming style for those handlers consistent? like handleWrite, handleRangeWrite, etc", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r543961583", "createdAt": "2020-12-16T05:08:46Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +184,256 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp -> {\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx);\n+                }).exceptionally(ex -> {\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleCommittedTailRequest: received a \"\n+                + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void write(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"log write: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b575c10406e3da944f3ed8e91ada0806cf553d5b"}, "originalPosition": 341}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTk4NTE2Ng==", "bodyText": "Fixed.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r545985166", "createdAt": "2020-12-18T17:37:54Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +184,256 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp -> {\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx);\n+                }).exceptionally(ex -> {\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleCommittedTailRequest: received a \"\n+                + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void write(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"log write: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzk2MTU4Mw=="}, "originalCommit": {"oid": "b575c10406e3da944f3ed8e91ada0806cf553d5b"}, "originalPosition": 341}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNzM1OTkwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxODo1OToxMFrOIIERnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxODo1OToxMFrOIIERnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTMyOTU2NQ==", "bodyText": "Note: this should be fReq.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r545329565", "createdAt": "2020-12-17T18:59:10Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +185,256 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp -> {\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx);\n+                }).exceptionally(ex -> {\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleCommittedTailRequest: received a \"\n+                + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void write(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"log write: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());\n         }\n \n-        batchWriter\n-                .addTask(WRITE, msg)\n+        final RequestMsg fReq = req;\n+        batchWriter.addTask(BatchWriterOperation.Type.WRITE, req)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5941ed5facb051c53b77c2005926b438608c0781"}, "originalPosition": 356}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNzM4NTk5OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxOTowNTozNFrOIIEg8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxOTowNTozNFrOIIEg8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTMzMzQ4OQ==", "bodyText": "Note: fix the order.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r545333489", "createdAt": "2020-12-17T19:05:34Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +185,256 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp -> {\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx);\n+                }).exceptionally(ex -> {\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleCommittedTailRequest: received a \"\n+                + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void write(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"log write: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());\n         }\n \n-        batchWriter\n-                .addTask(WRITE, msg)\n+        final RequestMsg fReq = req;\n+        batchWriter.addTask(BatchWriterOperation.Type.WRITE, req)\n                 .thenRunAsync(() -> {\n-                    dataCache.put(msg.getPayload().getGlobalAddress(), logData);\n-                    r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg());\n-                }, executor)\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n-                    return null;\n-                });\n+                    dataCache.put(logData.getGlobalAddress(), logData);\n+                    r.sendResponse(getResponseMsg(fReq.getHeader(), getWriteLogResponseMsg()), ctx);\n+                }, executor).exceptionally(ex -> {\n+            handleException(ex, ctx, fReq, r);\n+            return null;\n+        });\n     }\n \n     /**\n      * Services incoming range write calls.\n      */\n-    @ServerHandler(type = CorfuMsgType.RANGE_WRITE)\n-    public void rangeWrite(CorfuPayloadMsg<RangeWriteMsg> msg,\n-                           ChannelHandlerContext ctx, IServerRouter r) {\n-        List<LogData> range = msg.getPayload().getEntries();\n+    @RequestHandler(type = PayloadCase.RANGE_WRITE_LOG_REQUEST)\n+    public void rangeWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        List<LogData> range = req.getPayload().getRangeWriteLogRequest().getLogDataList()\n+                .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+\n         log.debug(\"rangeWrite: Writing {} entries [{}-{}]\", range.size(),\n                 range.get(0).getGlobalAddress(), range.get(range.size() - 1).getGlobalAddress());\n \n-        batchWriter\n-                .addTask(RANGE_WRITE, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg()))\n+        batchWriter.addTask(BatchWriterOperation.Type.RANGE_WRITE, req)\n+                .thenRun(() -> r.sendResponse(getResponseMsg(req.getHeader(), getRangeWriteLogResponseMsg()), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n-     * Perform a prefix trim.\n+     * Perform a prefix trim (trim log).\n      * Here the token is not used to perform the trim as the epoch at which the checkpoint was completed\n      * might be old. Hence, we use the msg epoch to perform the trim. This should be safe provided that the\n      * trim is performed only on the token provided by the CheckpointWriter which ensures that the checkpoint\n      * was persisted. Using any other address to perform a trim can cause data loss.\n      */\n-    @ServerHandler(type = CorfuMsgType.PREFIX_TRIM)\n-    private void prefixTrim(CorfuPayloadMsg<TrimRequest> msg, ChannelHandlerContext ctx,\n-                            IServerRouter r) {\n-        log.debug(\"prefixTrim: trimming prefix to {}\", msg.getPayload().getAddress());\n-        batchWriter\n-                .addTask(PREFIX_TRIM, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg()))\n+    @RequestHandler(type = PayloadCase.TRIM_LOG_REQUEST)\n+    private void handleTrimLog(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.debug(\"handleTrimLog[{}]: trimming prefix to {}\", req.getHeader().getRequestId(),\n+                TextFormat.shortDebugString(req.getPayload().getTrimLogRequest().getAddress()));\n+\n+        batchWriter.addTask(BatchWriterOperation.Type.PREFIX_TRIM, req)\n+                .thenRun(() -> {\n+                    HeaderMsg header = getHeaderMsg(req.getHeader(), false, true);\n+                    r.sendResponse(getResponseMsg(header, getTrimLogResponseMsg()), ctx);\n+                })\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n-  @ServerHandler(type = CorfuMsgType.READ_REQUEST)\n-  public void read(CorfuPayloadMsg<ReadRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-    boolean cacheable = msg.getPayload().isCacheReadResult();\n-    if (log.isTraceEnabled()) {\n-      log.trace(\"read: {}, cacheable: {}\", msg.getPayload().getAddresses(), cacheable);\n-    }\n+    @RequestHandler(type = PayloadCase.READ_LOG_REQUEST)\n+    public void read(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        final boolean cacheable = req.getPayload().getReadLogRequest().getCacheResults();\n+        final List<Long> addressList = req.getPayload().getReadLogRequest().getAddressList();\n \n-    ReadResponse rr = new ReadResponse();\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"read: {}, cacheable: {}\", cacheable, addressList);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5941ed5facb051c53b77c2005926b438608c0781"}, "originalPosition": 445}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMjA0NDgxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxODo1MDo0OVrOIIup8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQxOTozNzoyMFrOIPTv6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAyMzkyMA==", "bodyText": "I don't think these work as expected for LogData types, as they are considered equal if the clientId and threadId are equal.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r546023920", "createdAt": "2020-12-18T18:50:49Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@Slf4j\n+public class BatchProcessorTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+    private BatchProcessor batchProcessor;\n+    private StreamLog mockStreamLog;\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final long DEFAULT_SEAL_EPOCH = 1L;\n+    private final long LARGER_SEAL_EPOCH = 5L;\n+\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should be equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getBasicHeader(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should be equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getHeaderHighPriority(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.HIGH, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+\n+    /**\n+     * A helper method that creates a message header populated with\n+     * default values and larger epoch than default header. Note that\n+     * this header is only used to construct RESET request, which is just\n+     * took for convenience in some exceptional cases.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getResetHeaderLargerEpoch() {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, LARGER_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), false, true);\n+    }\n+\n+    /**\n+     * A helper method that creates a sample LogData object with default values.\n+     *\n+     * @param address LogData's global address (global tail)\n+     * @return        the corresponding HeaderMsg\n+     */\n+    private LogData getDefaultLogData(long address) {\n+        ByteBuf b = Unpooled.buffer();\n+        byte[] streamEntry = \"Payload\".getBytes();\n+        Serializers.CORFU.serialize(streamEntry, b);\n+        LogData ld = new LogData(DataType.DATA, b);\n+        ld.setGlobalAddress(address);\n+        ld.setEpoch(0L);\n+        return ld;\n+    }\n+\n+    /**\n+     * Perform the required preparation before running individual tests.\n+     */\n+    @Before\n+    public void setup() {\n+        mockStreamLog = mock(StreamLog.class);\n+        batchProcessor = new BatchProcessor(mockStreamLog, DEFAULT_SEAL_EPOCH, true);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a PREFIX_TRIM request.\n+     */\n+    @Test\n+    public void testPrefixTrim() {\n+        long epoch = 0L;\n+        long sequence = 5L;\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getTrimLogRequestMsg(new Token(epoch, sequence)));\n+\n+        batchProcessor.addTask(BatchWriterOperation.Type.PREFIX_TRIM, request).join();\n+        verify(mockStreamLog).prefixTrim(sequence);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a WRITE request.\n+     */\n+    @Test\n+    public void testWrite() {\n+        LogData logData = getDefaultLogData(0L);\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getWriteLogRequestMsg(logData));\n+\n+        batchProcessor.addTask(BatchWriterOperation.Type.WRITE, request).join();\n+        verify(mockStreamLog).append(0L, logData);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4de5c3d3b3cc5f15034bcd20286d15eb11af33fe"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjkyMzExNA==", "bodyText": "This has been resolved in an offline discussion with @xcchang", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r552923114", "createdAt": "2021-01-06T19:37:20Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@Slf4j\n+public class BatchProcessorTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+    private BatchProcessor batchProcessor;\n+    private StreamLog mockStreamLog;\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final long DEFAULT_SEAL_EPOCH = 1L;\n+    private final long LARGER_SEAL_EPOCH = 5L;\n+\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should be equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getBasicHeader(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should be equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getHeaderHighPriority(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.HIGH, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+\n+    /**\n+     * A helper method that creates a message header populated with\n+     * default values and larger epoch than default header. Note that\n+     * this header is only used to construct RESET request, which is just\n+     * took for convenience in some exceptional cases.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getResetHeaderLargerEpoch() {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, LARGER_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), false, true);\n+    }\n+\n+    /**\n+     * A helper method that creates a sample LogData object with default values.\n+     *\n+     * @param address LogData's global address (global tail)\n+     * @return        the corresponding HeaderMsg\n+     */\n+    private LogData getDefaultLogData(long address) {\n+        ByteBuf b = Unpooled.buffer();\n+        byte[] streamEntry = \"Payload\".getBytes();\n+        Serializers.CORFU.serialize(streamEntry, b);\n+        LogData ld = new LogData(DataType.DATA, b);\n+        ld.setGlobalAddress(address);\n+        ld.setEpoch(0L);\n+        return ld;\n+    }\n+\n+    /**\n+     * Perform the required preparation before running individual tests.\n+     */\n+    @Before\n+    public void setup() {\n+        mockStreamLog = mock(StreamLog.class);\n+        batchProcessor = new BatchProcessor(mockStreamLog, DEFAULT_SEAL_EPOCH, true);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a PREFIX_TRIM request.\n+     */\n+    @Test\n+    public void testPrefixTrim() {\n+        long epoch = 0L;\n+        long sequence = 5L;\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getTrimLogRequestMsg(new Token(epoch, sequence)));\n+\n+        batchProcessor.addTask(BatchWriterOperation.Type.PREFIX_TRIM, request).join();\n+        verify(mockStreamLog).prefixTrim(sequence);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a WRITE request.\n+     */\n+    @Test\n+    public void testWrite() {\n+        LogData logData = getDefaultLogData(0L);\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getWriteLogRequestMsg(logData));\n+\n+        batchProcessor.addTask(BatchWriterOperation.Type.WRITE, request).join();\n+        verify(mockStreamLog).append(0L, logData);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAyMzkyMA=="}, "originalCommit": {"oid": "4de5c3d3b3cc5f15034bcd20286d15eb11af33fe"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0MjM3MDM1OnYy", "diffSide": "LEFT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMDoxOTo1M1rOIKIGEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQxNzozODo0MFrOIPO-pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ4OTI5OA==", "bodyText": "Why the metrics are removed?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547489298", "createdAt": "2020-12-22T20:19:53Z", "author": {"login": "WenbinZhu"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +101,149 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n-                queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjg0NDk2Ng==", "bodyText": "Good catch. This was accidental.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r552844966", "createdAt": "2021-01-06T17:38:40Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +101,149 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n-                queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ4OTI5OA=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 159}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0MjM3MzE2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMDoyMToxMlrOIKIH4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMDoyMToxMlrOIKIH4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ4OTc2Mw==", "bodyText": "Better to wrapped this in an if condition:\nif (log.isTraceEnabled) {\n    log.trace(...);\n}", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547489763", "createdAt": "2020-12-22T20:21:12Z", "author": {"login": "WenbinZhu"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +101,149 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n-                queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+                BatchWriterOperation currentOp;\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n+                        log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 174}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0MjYyMjQ1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMjowMDoyMlrOIKKbhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQxNzoyNTowMFrOIQas0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzUyNzU1OQ==", "bodyText": "Here you call it Intializer, but in Chetan's seqeuncer patch it is called FactoryHelper, can you help make them consistent? I think \"initializer\" sounds like a better name.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547527559", "createdAt": "2020-12-22T22:00:22Z", "author": {"login": "WenbinZhu"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -111,20 +117,27 @@\n     private final StreamLogCompaction logCleaner;\n     private final BatchProcessor batchWriter;\n \n-    private ExecutorService executor;\n+    private final ExecutorService executor;\n \n     /**\n      * Returns a new LogUnitServer.\n      *\n      * @param serverContext context object providing settings and objects\n      */\n     public LogUnitServer(ServerContext serverContext) {\n+        this(serverContext, new LogUnitServerInitializer());\n+    }\n+\n+    /**\n+     * Returns a new LogUnitServer.\n+     *\n+     * @param serverContext      context object providing settings and objects\n+     * @param serverInitializer  a LogUnitServerInitializer object\n+     */\n+    public LogUnitServer(ServerContext serverContext, LogUnitServerInitializer serverInitializer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDA4NTU4Ng==", "bodyText": "Changed in the other PR, thanks!", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r554085586", "createdAt": "2021-01-08T17:25:00Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -111,20 +117,27 @@\n     private final StreamLogCompaction logCleaner;\n     private final BatchProcessor batchWriter;\n \n-    private ExecutorService executor;\n+    private final ExecutorService executor;\n \n     /**\n      * Returns a new LogUnitServer.\n      *\n      * @param serverContext context object providing settings and objects\n      */\n     public LogUnitServer(ServerContext serverContext) {\n+        this(serverContext, new LogUnitServerInitializer());\n+    }\n+\n+    /**\n+     * Returns a new LogUnitServer.\n+     *\n+     * @param serverContext      context object providing settings and objects\n+     * @param serverInitializer  a LogUnitServerInitializer object\n+     */\n+    public LogUnitServer(ServerContext serverContext, LogUnitServerInitializer serverInitializer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzUyNzU1OQ=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0MjYyNTg4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMjowMTo0OFrOIKKdkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQwMDowNToxOFrOIOFhww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzUyODA4MA==", "bodyText": "Better to have a more explanatory comment for the serverInitializer parameter.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547528080", "createdAt": "2020-12-22T22:01:48Z", "author": {"login": "WenbinZhu"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -111,20 +117,27 @@\n     private final StreamLogCompaction logCleaner;\n     private final BatchProcessor batchWriter;\n \n-    private ExecutorService executor;\n+    private final ExecutorService executor;\n \n     /**\n      * Returns a new LogUnitServer.\n      *\n      * @param serverContext context object providing settings and objects\n      */\n     public LogUnitServer(ServerContext serverContext) {\n+        this(serverContext, new LogUnitServerInitializer());\n+    }\n+\n+    /**\n+     * Returns a new LogUnitServer.\n+     *\n+     * @param serverContext      context object providing settings and objects\n+     * @param serverInitializer  a LogUnitServerInitializer object", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0MTUzOQ==", "bodyText": "Added additional details.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r551641539", "createdAt": "2021-01-05T00:05:18Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -111,20 +117,27 @@\n     private final StreamLogCompaction logCleaner;\n     private final BatchProcessor batchWriter;\n \n-    private ExecutorService executor;\n+    private final ExecutorService executor;\n \n     /**\n      * Returns a new LogUnitServer.\n      *\n      * @param serverContext context object providing settings and objects\n      */\n     public LogUnitServer(ServerContext serverContext) {\n+        this(serverContext, new LogUnitServerInitializer());\n+    }\n+\n+    /**\n+     * Returns a new LogUnitServer.\n+     *\n+     * @param serverContext      context object providing settings and objects\n+     * @param serverInitializer  a LogUnitServerInitializer object", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzUyODA4MA=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mjc2MTA2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzowMjowOFrOIKLrYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzowMjowOFrOIKLrYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU0ODAwMA==", "bodyText": "NIT: Format the .exceptionally() block to align with .thenRunAsync() as it was.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547548000", "createdAt": "2020-12-22T23:02:08Z", "author": {"login": "WenbinZhu"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +185,270 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp -> {\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx);\n+                }).exceptionally(ex -> {\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());\n         }\n \n-        batchWriter\n-                .addTask(WRITE, msg)\n+        final RequestMsg fReq = req;\n+        batchWriter.addTask(BatchWriterOperation.Type.WRITE, fReq)\n                 .thenRunAsync(() -> {\n-                    dataCache.put(msg.getPayload().getGlobalAddress(), logData);\n-                    r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg());\n-                }, executor)\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n-                    return null;\n-                });\n+                    dataCache.put(logData.getGlobalAddress(), logData);\n+                    r.sendResponse(getResponseMsg(fReq.getHeader(), getWriteLogResponseMsg()), ctx);\n+                }, executor).exceptionally(ex -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 377}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mjc2MzczOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzowMzozMFrOIKLs2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzowMzozMFrOIKLs2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU0ODM3Nw==", "bodyText": "Format the if block to wrap in curly brackets on new lines.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547548377", "createdAt": "2020-12-22T23:03:30Z", "author": {"login": "WenbinZhu"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +185,270 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp -> {\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx);\n+                }).exceptionally(ex -> {\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());\n         }\n \n-        batchWriter\n-                .addTask(WRITE, msg)\n+        final RequestMsg fReq = req;\n+        batchWriter.addTask(BatchWriterOperation.Type.WRITE, fReq)\n                 .thenRunAsync(() -> {\n-                    dataCache.put(msg.getPayload().getGlobalAddress(), logData);\n-                    r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg());\n-                }, executor)\n-                .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n-                    return null;\n-                });\n+                    dataCache.put(logData.getGlobalAddress(), logData);\n+                    r.sendResponse(getResponseMsg(fReq.getHeader(), getWriteLogResponseMsg()), ctx);\n+                }, executor).exceptionally(ex -> {\n+            handleException(ex, ctx, fReq, r);\n+            return null;\n+        });\n     }\n \n     /**\n      * Services incoming range write calls.\n      */\n-    @ServerHandler(type = CorfuMsgType.RANGE_WRITE)\n-    public void rangeWrite(CorfuPayloadMsg<RangeWriteMsg> msg,\n-                           ChannelHandlerContext ctx, IServerRouter r) {\n-        List<LogData> range = msg.getPayload().getEntries();\n-        log.debug(\"rangeWrite: Writing {} entries [{}-{}]\", range.size(),\n+    @RequestHandler(type = PayloadCase.RANGE_WRITE_LOG_REQUEST)\n+    public void handleRangeWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        List<LogData> range = req.getPayload().getRangeWriteLogRequest().getLogDataList()\n+                .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+\n+        log.debug(\"handleRangeWrite: Writing {} entries [{}-{}]\", range.size(),\n                 range.get(0).getGlobalAddress(), range.get(range.size() - 1).getGlobalAddress());\n \n-        batchWriter\n-                .addTask(RANGE_WRITE, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg()))\n+        batchWriter.addTask(BatchWriterOperation.Type.RANGE_WRITE, req)\n+                .thenRun(() -> r.sendResponse(getResponseMsg(req.getHeader(), getRangeWriteLogResponseMsg()), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n-     * Perform a prefix trim.\n+     * Perform a prefix trim (trim log).\n      * Here the token is not used to perform the trim as the epoch at which the checkpoint was completed\n      * might be old. Hence, we use the msg epoch to perform the trim. This should be safe provided that the\n      * trim is performed only on the token provided by the CheckpointWriter which ensures that the checkpoint\n      * was persisted. Using any other address to perform a trim can cause data loss.\n      */\n-    @ServerHandler(type = CorfuMsgType.PREFIX_TRIM)\n-    private void prefixTrim(CorfuPayloadMsg<TrimRequest> msg, ChannelHandlerContext ctx,\n-                            IServerRouter r) {\n-        log.debug(\"prefixTrim: trimming prefix to {}\", msg.getPayload().getAddress());\n-        batchWriter\n-                .addTask(PREFIX_TRIM, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg()))\n+    @RequestHandler(type = PayloadCase.TRIM_LOG_REQUEST)\n+    private void handleTrimLog(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.debug(\"handleTrimLog[{}]: trimming prefix to {}\", req.getHeader().getRequestId(),\n+                TextFormat.shortDebugString(req.getPayload().getTrimLogRequest().getAddress()));\n+\n+        batchWriter.addTask(BatchWriterOperation.Type.PREFIX_TRIM, req)\n+                .thenRun(() -> {\n+                    HeaderMsg header = getHeaderMsg(req.getHeader(), false, true);\n+                    r.sendResponse(getResponseMsg(header, getTrimLogResponseMsg()), ctx);\n+                })\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n-  @ServerHandler(type = CorfuMsgType.READ_REQUEST)\n-  public void read(CorfuPayloadMsg<ReadRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-    boolean cacheable = msg.getPayload().isCacheReadResult();\n-    if (log.isTraceEnabled()) {\n-      log.trace(\"read: {}, cacheable: {}\", msg.getPayload().getAddresses(), cacheable);\n-    }\n+    @RequestHandler(type = PayloadCase.READ_LOG_REQUEST)\n+    public void handleRead(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        final boolean cacheable = req.getPayload().getReadLogRequest().getCacheResults();\n+        final List<Long> addressList = req.getPayload().getReadLogRequest().getAddressList();\n \n-    ReadResponse rr = new ReadResponse();\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleRead: {}, cacheable: {}\", addressList, cacheable);\n+        }\n \n-    for (long address : msg.getPayload().getAddresses()) {\n-      try {\n-        ILogData logData = dataCache.get(address, cacheable);\n-        if (logData == null) {\n-          rr.put(address, LogData.getEmpty(address));\n-        } else {\n-          rr.put(address, (LogData) logData);\n+        ReadResponse rr = new ReadResponse();\n+\n+        for (long address : addressList) {\n+            try {\n+                ILogData logData = dataCache.get(address, cacheable);\n+                if (logData == null) {\n+                    rr.put(address, LogData.getEmpty(address));\n+                } else {\n+                    rr.put(address, (LogData) logData);\n+                }\n+            } catch (DataCorruptionException dce) {\n+                log.error(\"handleRead: Data corruption exception while reading addresses {}\", addressList, dce);\n+                r.sendResponse(getResponseMsg(req.getHeader(), getDataCorruptionErrorMsg(address)), ctx);\n+                return;\n+            }\n         }\n-      } catch (DataCorruptionException e) {\n-        log.error(\n-            \"Data corruption exception while reading addresses {}\",\n-            msg.getPayload().getAddresses(),\n-            e);\n-        r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_CORRUPTION.payloadMsg(address));\n-        return;\n-      }\n+\n+        r.sendResponse(getResponseMsg(req.getHeader(), getReadLogResponseMsg(rr.getAddresses())), ctx);\n     }\n-    r.sendResponse(ctx, msg, CorfuMsgType.READ_RESPONSE.payloadMsg(rr));\n-  }\n-\n-  @ServerHandler(type = CorfuMsgType.INSPECT_ADDRESSES_REQUEST)\n-  public void inspectAddresses(\n-      CorfuPayloadMsg<InspectAddressesRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-    List<Long> addresses = msg.getPayload().getAddresses();\n-    log.trace(\"inspectAddresses: {}\", addresses);\n-    InspectAddressesResponse inspectResponse = new InspectAddressesResponse();\n-\n-    for (long address : addresses) {\n-      try {\n-        if (!streamLog.contains(address)) {\n-          inspectResponse.add(address);\n+\n+    @RequestHandler(type = PayloadCase.INSPECT_ADDRESSES_REQUEST)\n+    public void handleInspectAddressesRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        final List<Long> addresses = req.getPayload().getInspectAddressesRequest().getAddressList();\n+        List<Long> emptyAddresses = new ArrayList<>();\n+\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleInspectAddressesRequest[{}]: \" +\n+                    \"addresses {}\", req.getHeader().getRequestId(), addresses);\n+        }\n+\n+\n+        for (long address : addresses) {\n+            try {\n+                if (!streamLog.contains(address)) emptyAddresses.add(address);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 521}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mjc3NDQ4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzowODoyMFrOIKLyzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQwMDowNTo1M1rOIOFibw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU0OTkwMA==", "bodyText": "I guess this class is for testing purpose only? If true, please mention this in the Javadoc.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547549900", "createdAt": "2020-12-22T23:08:20Z", "author": {"login": "WenbinZhu"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -550,10 +598,39 @@ public static LogUnitServerConfig parse(Map<String, Object> opts) {\n             return LogUnitServerConfig.builder()\n                     .cacheSizeHeapRatio(cacheSizeHeapRatio)\n                     .maxCacheSize((long) (Runtime.getRuntime().maxMemory() * cacheSizeHeapRatio))\n-                    .memoryMode(Boolean.valueOf(opts.get(\"--memory\").toString()))\n+                    .memoryMode(Boolean.parseBoolean(opts.get(\"--memory\").toString()))\n                     .noVerify((Boolean) opts.get(\"--no-verify\"))\n                     .noSync((Boolean) opts.get(\"--no-sync\"))\n                     .build();\n         }\n     }\n+\n+    /**\n+     * Utility class used by the LogUnit server.\n+     */\n+    public static class LogUnitServerInitializer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 721}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzcyMDM3Mw==", "bodyText": "Have a look at the Javadoc of SequencerInitializer (previously SequencerFactoryHelper) in SequencerServer.java. You can copy the relevant info if required.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547720373", "createdAt": "2020-12-23T06:47:47Z", "author": {"login": "chetangudisagar"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -550,10 +598,39 @@ public static LogUnitServerConfig parse(Map<String, Object> opts) {\n             return LogUnitServerConfig.builder()\n                     .cacheSizeHeapRatio(cacheSizeHeapRatio)\n                     .maxCacheSize((long) (Runtime.getRuntime().maxMemory() * cacheSizeHeapRatio))\n-                    .memoryMode(Boolean.valueOf(opts.get(\"--memory\").toString()))\n+                    .memoryMode(Boolean.parseBoolean(opts.get(\"--memory\").toString()))\n                     .noVerify((Boolean) opts.get(\"--no-verify\"))\n                     .noSync((Boolean) opts.get(\"--no-sync\"))\n                     .build();\n         }\n     }\n+\n+    /**\n+     * Utility class used by the LogUnit server.\n+     */\n+    public static class LogUnitServerInitializer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU0OTkwMA=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 721}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0MTcxMQ==", "bodyText": "Expanded the Javadoc to include this information.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r551641711", "createdAt": "2021-01-05T00:05:53Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -550,10 +598,39 @@ public static LogUnitServerConfig parse(Map<String, Object> opts) {\n             return LogUnitServerConfig.builder()\n                     .cacheSizeHeapRatio(cacheSizeHeapRatio)\n                     .maxCacheSize((long) (Runtime.getRuntime().maxMemory() * cacheSizeHeapRatio))\n-                    .memoryMode(Boolean.valueOf(opts.get(\"--memory\").toString()))\n+                    .memoryMode(Boolean.parseBoolean(opts.get(\"--memory\").toString()))\n                     .noVerify((Boolean) opts.get(\"--no-verify\"))\n                     .noSync((Boolean) opts.get(\"--no-sync\"))\n                     .build();\n         }\n     }\n+\n+    /**\n+     * Utility class used by the LogUnit server.\n+     */\n+    public static class LogUnitServerInitializer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU0OTkwMA=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 721}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mjc4MDIxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzoxMTozNlrOIKL2Iw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQxNzoyNzoxOFrOIQaxtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU1MDc1NQ==", "bodyText": "I think we usually use this in unit tests:  assertThat(ret).isInstanceOf(TailsResponse.class);", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547550755", "createdAt": "2020-12-22T23:11:36Z", "author": {"login": "WenbinZhu"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@Slf4j\n+public class BatchProcessorTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+    private BatchProcessor batchProcessor;\n+    private StreamLog mockStreamLog;\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final long DEFAULT_SEAL_EPOCH = 1L;\n+    private final long LARGER_SEAL_EPOCH = 5L;\n+\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should be equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getBasicHeader(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should be equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getHeaderHighPriority(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.HIGH, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+\n+    /**\n+     * A helper method that creates a message header populated with\n+     * default values and larger epoch than default header. Note that\n+     * this header is only used to construct RESET request, which is just\n+     * took for convenience in some exceptional cases.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getResetHeaderLargerEpoch() {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, LARGER_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), false, true);\n+    }\n+\n+    /**\n+     * A helper method that creates a sample LogData object with default values.\n+     *\n+     * @param address LogData's global address (global tail)\n+     * @return        the corresponding HeaderMsg\n+     */\n+    private LogData getDefaultLogData(long address) {\n+        ByteBuf b = Unpooled.buffer();\n+        byte[] streamEntry = \"Payload\".getBytes();\n+        Serializers.CORFU.serialize(streamEntry, b);\n+        LogData ld = new LogData(DataType.DATA, b);\n+        ld.setGlobalAddress(address);\n+        ld.setEpoch(0L);\n+        return ld;\n+    }\n+\n+    /**\n+     * Perform the required preparation before running individual tests.\n+     */\n+    @Before\n+    public void setup() {\n+        mockStreamLog = mock(StreamLog.class);\n+        batchProcessor = new BatchProcessor(mockStreamLog, DEFAULT_SEAL_EPOCH, true);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a PREFIX_TRIM request.\n+     */\n+    @Test\n+    public void testPrefixTrim() {\n+        long epoch = 0L;\n+        long sequence = 5L;\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getTrimLogRequestMsg(new Token(epoch, sequence)));\n+\n+        batchProcessor.addTask(BatchWriterOperation.Type.PREFIX_TRIM, request).join();\n+        verify(mockStreamLog).prefixTrim(sequence);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a WRITE request.\n+     */\n+    @Test\n+    public void testWrite() {\n+        LogData logData = getDefaultLogData(0L);\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getWriteLogRequestMsg(logData));\n+\n+        batchProcessor.addTask(BatchWriterOperation.Type.WRITE, request).join();\n+        verify(mockStreamLog).append(0L, logData);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a RANGE_WRITE request.\n+     */\n+    @Test\n+    public void testRangeWrite() {\n+        final int numIter = 100;\n+        List<LogData> entries = new ArrayList<>();\n+        for (int x = 0; x < numIter; x++) {\n+            LogData ld = getDefaultLogData(x);\n+            entries.add(ld);\n+        }\n+\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getRangeWriteLogRequestMsg(entries));\n+        batchProcessor.addTask(BatchWriterOperation.Type.RANGE_WRITE, request).join();\n+        verify(mockStreamLog).append(entries);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a RESET request.\n+     */\n+    @Test\n+    public void testReset() {\n+        long epochWaterMark = 100L;\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, true),\n+                getResetLogUnitRequestMsg(epochWaterMark));\n+        batchProcessor.addTask(BatchWriterOperation.Type.RESET, request).join();\n+        verify(mockStreamLog).reset();\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a TAILS_QUERY request for LOG_TAIL.\n+     */\n+    @Test\n+    public void testTailsQueryLogTail() {\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getTailRequestMsg(LogUnit.TailRequestMsg.Type.LOG_TAIL));\n+\n+        Object ret = batchProcessor.addTask(BatchWriterOperation.Type.TAILS_QUERY, request).join();\n+        verify(mockStreamLog).getLogTail();\n+        assertTrue(ret instanceof TailsResponse);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a TAILS_QUERY request for STREAMS_TAILS.\n+     */\n+    @Test\n+    public void testTailsQueryStreamsTail() {\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getTailRequestMsg(LogUnit.TailRequestMsg.Type.STREAMS_TAILS));\n+        List<UUID> list = request.getPayload()\n+                .getTailRequest()\n+                .getStreamList()\n+                .stream()\n+                .map(CorfuProtocolCommon::getUUID)\n+                .collect(Collectors.toList());\n+\n+        when(mockStreamLog.getTails(any())).thenReturn(new TailsResponse(0L));\n+        Object ret = batchProcessor.addTask(BatchWriterOperation.Type.TAILS_QUERY, request).join();\n+        verify(mockStreamLog).getTails(list);\n+        assertTrue(ret instanceof TailsResponse);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 214}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDA4NjgzNw==", "bodyText": "Done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r554086837", "createdAt": "2021-01-08T17:27:18Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@Slf4j\n+public class BatchProcessorTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+    private BatchProcessor batchProcessor;\n+    private StreamLog mockStreamLog;\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final long DEFAULT_SEAL_EPOCH = 1L;\n+    private final long LARGER_SEAL_EPOCH = 5L;\n+\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should be equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getBasicHeader(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values. Note that the sealEpoch in BatchProcessor\n+     * should be equal to the epoch in request header.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getHeaderHighPriority(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.HIGH, DEFAULT_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+\n+\n+    /**\n+     * A helper method that creates a message header populated with\n+     * default values and larger epoch than default header. Note that\n+     * this header is only used to construct RESET request, which is just\n+     * took for convenience in some exceptional cases.\n+     *\n+     * @return   the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getResetHeaderLargerEpoch() {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, LARGER_SEAL_EPOCH,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), false, true);\n+    }\n+\n+    /**\n+     * A helper method that creates a sample LogData object with default values.\n+     *\n+     * @param address LogData's global address (global tail)\n+     * @return        the corresponding HeaderMsg\n+     */\n+    private LogData getDefaultLogData(long address) {\n+        ByteBuf b = Unpooled.buffer();\n+        byte[] streamEntry = \"Payload\".getBytes();\n+        Serializers.CORFU.serialize(streamEntry, b);\n+        LogData ld = new LogData(DataType.DATA, b);\n+        ld.setGlobalAddress(address);\n+        ld.setEpoch(0L);\n+        return ld;\n+    }\n+\n+    /**\n+     * Perform the required preparation before running individual tests.\n+     */\n+    @Before\n+    public void setup() {\n+        mockStreamLog = mock(StreamLog.class);\n+        batchProcessor = new BatchProcessor(mockStreamLog, DEFAULT_SEAL_EPOCH, true);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a PREFIX_TRIM request.\n+     */\n+    @Test\n+    public void testPrefixTrim() {\n+        long epoch = 0L;\n+        long sequence = 5L;\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getTrimLogRequestMsg(new Token(epoch, sequence)));\n+\n+        batchProcessor.addTask(BatchWriterOperation.Type.PREFIX_TRIM, request).join();\n+        verify(mockStreamLog).prefixTrim(sequence);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a WRITE request.\n+     */\n+    @Test\n+    public void testWrite() {\n+        LogData logData = getDefaultLogData(0L);\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getWriteLogRequestMsg(logData));\n+\n+        batchProcessor.addTask(BatchWriterOperation.Type.WRITE, request).join();\n+        verify(mockStreamLog).append(0L, logData);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a RANGE_WRITE request.\n+     */\n+    @Test\n+    public void testRangeWrite() {\n+        final int numIter = 100;\n+        List<LogData> entries = new ArrayList<>();\n+        for (int x = 0; x < numIter; x++) {\n+            LogData ld = getDefaultLogData(x);\n+            entries.add(ld);\n+        }\n+\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getRangeWriteLogRequestMsg(entries));\n+        batchProcessor.addTask(BatchWriterOperation.Type.RANGE_WRITE, request).join();\n+        verify(mockStreamLog).append(entries);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a RESET request.\n+     */\n+    @Test\n+    public void testReset() {\n+        long epochWaterMark = 100L;\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, true),\n+                getResetLogUnitRequestMsg(epochWaterMark));\n+        batchProcessor.addTask(BatchWriterOperation.Type.RESET, request).join();\n+        verify(mockStreamLog).reset();\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a TAILS_QUERY request for LOG_TAIL.\n+     */\n+    @Test\n+    public void testTailsQueryLogTail() {\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getTailRequestMsg(LogUnit.TailRequestMsg.Type.LOG_TAIL));\n+\n+        Object ret = batchProcessor.addTask(BatchWriterOperation.Type.TAILS_QUERY, request).join();\n+        verify(mockStreamLog).getLogTail();\n+        assertTrue(ret instanceof TailsResponse);\n+    }\n+\n+    /**\n+     * Test that the BatchProcessor successfully handles a TAILS_QUERY request for STREAMS_TAILS.\n+     */\n+    @Test\n+    public void testTailsQueryStreamsTail() {\n+        RequestMsg request = getRequestMsg(getBasicHeader(false, false),\n+                getTailRequestMsg(LogUnit.TailRequestMsg.Type.STREAMS_TAILS));\n+        List<UUID> list = request.getPayload()\n+                .getTailRequest()\n+                .getStreamList()\n+                .stream()\n+                .map(CorfuProtocolCommon::getUUID)\n+                .collect(Collectors.toList());\n+\n+        when(mockStreamLog.getTails(any())).thenReturn(new TailsResponse(0L));\n+        Object ret = batchProcessor.addTask(BatchWriterOperation.Type.TAILS_QUERY, request).join();\n+        verify(mockStreamLog).getTails(list);\n+        assertTrue(ret instanceof TailsResponse);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU1MDc1NQ=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 214}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mjc4MzI4OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzoxMzoxOFrOIKL35g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzoxMzoxOFrOIKL35g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU1MTIwNg==", "bodyText": "Expand imports.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547551206", "createdAt": "2020-12-22T23:13:18Z", "author": {"login": "WenbinZhu"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import com.google.protobuf.Int32Value;\n+import com.google.protobuf.Int64Value;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry.CheckpointEntryType;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.ICorfuPayload;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.IMetadata.DataRank;\n+import org.corfudb.protocols.wireprotocol.IMetadata.LogUnitMetadataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.LogData.DataRankMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEmptyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEntryMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataHoleMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataRankOnlyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataTrimmedMsg;\n+import org.corfudb.runtime.proto.LogData.LogUnitMetadataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import java.nio.ByteBuffer;\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0MjgzODcwOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzo0MDoyOVrOIKMW5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQxODoyNDoyOFrOIQcjIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU1OTE0Mg==", "bodyText": "Are these TODO comments still relevant and need to be addressed?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547559142", "createdAt": "2020-12-22T23:40:29Z", "author": {"login": "WenbinZhu"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import com.google.protobuf.Int32Value;\n+import com.google.protobuf.Int64Value;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry.CheckpointEntryType;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.ICorfuPayload;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.IMetadata.DataRank;\n+import org.corfudb.protocols.wireprotocol.IMetadata.LogUnitMetadataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.LogData.DataRankMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEmptyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEntryMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataHoleMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataRankOnlyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataTrimmedMsg;\n+import org.corfudb.runtime.proto.LogData.LogUnitMetadataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import java.nio.ByteBuffer;\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.*;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a DataRank object.\n+     */\n+    private static DataRankMsg getDataRankMsg(DataRank dataRank) {\n+        return DataRankMsg.newBuilder()\n+                .setId(getUuidMsg(dataRank.getUuid()))\n+                .setRank(dataRank.getRank())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a DataRank object from its Protobuf representation.\n+     */\n+    private static DataRank getDataRank(DataRankMsg msg) {\n+        return new DataRank(msg.getRank(), getUUID(msg.getId()));\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData's\n+     * metadata map.\n+     */\n+    private static LogUnitMetadataMsg getLogUnitMetadataMsg(EnumMap<LogUnitMetadataType, Object> metadata) {\n+        LogUnitMetadataMsg.Builder metadataMsgBuilder = LogUnitMetadataMsg.newBuilder();\n+\n+        metadata.forEach((type, obj)  -> {\n+            switch (type) {\n+                case RANK:\n+                    metadataMsgBuilder.setDataRank(getDataRankMsg((DataRank)obj));\n+                    break;\n+                case BACKPOINTER_MAP:\n+                    metadataMsgBuilder.addAllBackpointerMap(\n+                            ((Map<UUID, Long>)obj).entrySet()\n+                                    .stream()\n+                                    .map(e -> UuidToLongPairMsg.newBuilder()\n+                                            .setKey(getUuidMsg(e.getKey()))\n+                                            .setValue(e.getValue())\n+                                            .build())\n+                                    .collect(Collectors.toList()));\n+                    break;\n+                case GLOBAL_ADDRESS:\n+                    metadataMsgBuilder.setGlobalAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CHECKPOINT_TYPE:\n+                    metadataMsgBuilder.setCheckpointType(Int32Value.of(((CheckpointEntryType)obj).asByte()));\n+                    break;\n+                case CHECKPOINT_ID:\n+                    metadataMsgBuilder.setCheckpointId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_ID:\n+                    metadataMsgBuilder.setCheckpointedStreamId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_START_LOG_ADDRESS:\n+                    metadataMsgBuilder.setCheckpointedStreamStartLogAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CLIENT_ID:\n+                    metadataMsgBuilder.setClientId(getUuidMsg((UUID)obj));\n+                    break;\n+                case THREAD_ID:\n+                    metadataMsgBuilder.setThreadId(Int64Value.of((Long)obj));\n+                    break;\n+                case EPOCH:\n+                    metadataMsgBuilder.setEpoch(Int64Value.of((Long)obj));\n+                    break;\n+                default:\n+                    metadataMsgBuilder.setCodecTypeId(Int32Value.of(((Codec.Type)obj).getId()));\n+            }});\n+\n+        return metadataMsgBuilder.build();\n+    }\n+\n+    /**\n+     * Populates the LogData's metadata from the provided Protobuf\n+     * LogUnitMetadata message.\n+     */\n+    private static void addLogUnitMetadata(ILogData data, LogUnitMetadataMsg msg) {\n+        if (msg.hasDataRank()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.RANK, getDataRank(msg.getDataRank()));\n+        }\n+\n+        if (msg.getBackpointerMapCount() > 0) {\n+            data.getMetadataMap().put(LogUnitMetadataType.BACKPOINTER_MAP,\n+                    msg.getBackpointerMapList().stream()\n+                            .collect(Collectors.<UuidToLongPairMsg, UUID, Long>toMap(\n+                                    e -> getUUID(e.getKey()),\n+                                    UuidToLongPairMsg::getValue\n+                            )));\n+        }\n+\n+        if (msg.hasGlobalAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.GLOBAL_ADDRESS, msg.getGlobalAddress().getValue());\n+        }\n+\n+        if (msg.hasCheckpointType()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_TYPE,\n+                    CheckpointEntryType.typeMap.get((byte)msg.getCheckpointType().getValue()));\n+        }\n+\n+        if (msg.hasCheckpointId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_ID, getUUID(msg.getCheckpointId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_ID, getUUID(msg.getCheckpointedStreamId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamStartLogAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_START_LOG_ADDRESS,\n+                    msg.getCheckpointedStreamStartLogAddress().getValue());\n+        }\n+\n+        if (msg.hasClientId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CLIENT_ID, getUUID(msg.getClientId()));\n+        }\n+\n+        if (msg.hasThreadId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.THREAD_ID, msg.getThreadId().getValue());\n+        }\n+\n+        if (msg.hasEpoch()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.EPOCH, msg.getEpoch().getValue());\n+        }\n+\n+        if (msg.hasCodecTypeId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.PAYLOAD_CODEC,\n+                    Codec.getCodecTypeById(msg.getCodecTypeId().getValue()));\n+        }\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData object\n+     * of type DATA.\n+     */\n+    private static LogDataMsg getLogDataEntryMsg(LogData logData) {\n+        if (!logData.isData()) {\n+            throw new IllegalArgumentException(\"Incorrect LogData type provided: \" + logData.getType().toString());\n+        }\n+\n+        LogDataEntryMsg.Builder entryMsgBuilder = LogDataEntryMsg.newBuilder();\n+\n+        //TODO(Zach): Optimize and cleanup -- Concurrency bug?\n+        //TODO(Zach): Reduce number of buffer copies", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQ0NTg0Mw==", "bodyText": "Yes they are. This whole class is still under adjustments.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r551445843", "createdAt": "2021-01-04T17:04:36Z", "author": {"login": "zfrenette"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import com.google.protobuf.Int32Value;\n+import com.google.protobuf.Int64Value;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry.CheckpointEntryType;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.ICorfuPayload;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.IMetadata.DataRank;\n+import org.corfudb.protocols.wireprotocol.IMetadata.LogUnitMetadataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.LogData.DataRankMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEmptyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEntryMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataHoleMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataRankOnlyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataTrimmedMsg;\n+import org.corfudb.runtime.proto.LogData.LogUnitMetadataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import java.nio.ByteBuffer;\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.*;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a DataRank object.\n+     */\n+    private static DataRankMsg getDataRankMsg(DataRank dataRank) {\n+        return DataRankMsg.newBuilder()\n+                .setId(getUuidMsg(dataRank.getUuid()))\n+                .setRank(dataRank.getRank())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a DataRank object from its Protobuf representation.\n+     */\n+    private static DataRank getDataRank(DataRankMsg msg) {\n+        return new DataRank(msg.getRank(), getUUID(msg.getId()));\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData's\n+     * metadata map.\n+     */\n+    private static LogUnitMetadataMsg getLogUnitMetadataMsg(EnumMap<LogUnitMetadataType, Object> metadata) {\n+        LogUnitMetadataMsg.Builder metadataMsgBuilder = LogUnitMetadataMsg.newBuilder();\n+\n+        metadata.forEach((type, obj)  -> {\n+            switch (type) {\n+                case RANK:\n+                    metadataMsgBuilder.setDataRank(getDataRankMsg((DataRank)obj));\n+                    break;\n+                case BACKPOINTER_MAP:\n+                    metadataMsgBuilder.addAllBackpointerMap(\n+                            ((Map<UUID, Long>)obj).entrySet()\n+                                    .stream()\n+                                    .map(e -> UuidToLongPairMsg.newBuilder()\n+                                            .setKey(getUuidMsg(e.getKey()))\n+                                            .setValue(e.getValue())\n+                                            .build())\n+                                    .collect(Collectors.toList()));\n+                    break;\n+                case GLOBAL_ADDRESS:\n+                    metadataMsgBuilder.setGlobalAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CHECKPOINT_TYPE:\n+                    metadataMsgBuilder.setCheckpointType(Int32Value.of(((CheckpointEntryType)obj).asByte()));\n+                    break;\n+                case CHECKPOINT_ID:\n+                    metadataMsgBuilder.setCheckpointId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_ID:\n+                    metadataMsgBuilder.setCheckpointedStreamId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_START_LOG_ADDRESS:\n+                    metadataMsgBuilder.setCheckpointedStreamStartLogAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CLIENT_ID:\n+                    metadataMsgBuilder.setClientId(getUuidMsg((UUID)obj));\n+                    break;\n+                case THREAD_ID:\n+                    metadataMsgBuilder.setThreadId(Int64Value.of((Long)obj));\n+                    break;\n+                case EPOCH:\n+                    metadataMsgBuilder.setEpoch(Int64Value.of((Long)obj));\n+                    break;\n+                default:\n+                    metadataMsgBuilder.setCodecTypeId(Int32Value.of(((Codec.Type)obj).getId()));\n+            }});\n+\n+        return metadataMsgBuilder.build();\n+    }\n+\n+    /**\n+     * Populates the LogData's metadata from the provided Protobuf\n+     * LogUnitMetadata message.\n+     */\n+    private static void addLogUnitMetadata(ILogData data, LogUnitMetadataMsg msg) {\n+        if (msg.hasDataRank()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.RANK, getDataRank(msg.getDataRank()));\n+        }\n+\n+        if (msg.getBackpointerMapCount() > 0) {\n+            data.getMetadataMap().put(LogUnitMetadataType.BACKPOINTER_MAP,\n+                    msg.getBackpointerMapList().stream()\n+                            .collect(Collectors.<UuidToLongPairMsg, UUID, Long>toMap(\n+                                    e -> getUUID(e.getKey()),\n+                                    UuidToLongPairMsg::getValue\n+                            )));\n+        }\n+\n+        if (msg.hasGlobalAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.GLOBAL_ADDRESS, msg.getGlobalAddress().getValue());\n+        }\n+\n+        if (msg.hasCheckpointType()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_TYPE,\n+                    CheckpointEntryType.typeMap.get((byte)msg.getCheckpointType().getValue()));\n+        }\n+\n+        if (msg.hasCheckpointId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_ID, getUUID(msg.getCheckpointId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_ID, getUUID(msg.getCheckpointedStreamId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamStartLogAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_START_LOG_ADDRESS,\n+                    msg.getCheckpointedStreamStartLogAddress().getValue());\n+        }\n+\n+        if (msg.hasClientId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CLIENT_ID, getUUID(msg.getClientId()));\n+        }\n+\n+        if (msg.hasThreadId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.THREAD_ID, msg.getThreadId().getValue());\n+        }\n+\n+        if (msg.hasEpoch()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.EPOCH, msg.getEpoch().getValue());\n+        }\n+\n+        if (msg.hasCodecTypeId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.PAYLOAD_CODEC,\n+                    Codec.getCodecTypeById(msg.getCodecTypeId().getValue()));\n+        }\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData object\n+     * of type DATA.\n+     */\n+    private static LogDataMsg getLogDataEntryMsg(LogData logData) {\n+        if (!logData.isData()) {\n+            throw new IllegalArgumentException(\"Incorrect LogData type provided: \" + logData.getType().toString());\n+        }\n+\n+        LogDataEntryMsg.Builder entryMsgBuilder = LogDataEntryMsg.newBuilder();\n+\n+        //TODO(Zach): Optimize and cleanup -- Concurrency bug?\n+        //TODO(Zach): Reduce number of buffer copies", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU1OTE0Mg=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDExNTg3NQ==", "bodyText": "These have all been updated.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r554115875", "createdAt": "2021-01-08T18:24:28Z", "author": {"login": "zfrenette"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import com.google.protobuf.Int32Value;\n+import com.google.protobuf.Int64Value;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry.CheckpointEntryType;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.ICorfuPayload;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.IMetadata.DataRank;\n+import org.corfudb.protocols.wireprotocol.IMetadata.LogUnitMetadataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.LogData.DataRankMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEmptyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEntryMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataHoleMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataRankOnlyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataTrimmedMsg;\n+import org.corfudb.runtime.proto.LogData.LogUnitMetadataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import java.nio.ByteBuffer;\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.*;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a DataRank object.\n+     */\n+    private static DataRankMsg getDataRankMsg(DataRank dataRank) {\n+        return DataRankMsg.newBuilder()\n+                .setId(getUuidMsg(dataRank.getUuid()))\n+                .setRank(dataRank.getRank())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a DataRank object from its Protobuf representation.\n+     */\n+    private static DataRank getDataRank(DataRankMsg msg) {\n+        return new DataRank(msg.getRank(), getUUID(msg.getId()));\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData's\n+     * metadata map.\n+     */\n+    private static LogUnitMetadataMsg getLogUnitMetadataMsg(EnumMap<LogUnitMetadataType, Object> metadata) {\n+        LogUnitMetadataMsg.Builder metadataMsgBuilder = LogUnitMetadataMsg.newBuilder();\n+\n+        metadata.forEach((type, obj)  -> {\n+            switch (type) {\n+                case RANK:\n+                    metadataMsgBuilder.setDataRank(getDataRankMsg((DataRank)obj));\n+                    break;\n+                case BACKPOINTER_MAP:\n+                    metadataMsgBuilder.addAllBackpointerMap(\n+                            ((Map<UUID, Long>)obj).entrySet()\n+                                    .stream()\n+                                    .map(e -> UuidToLongPairMsg.newBuilder()\n+                                            .setKey(getUuidMsg(e.getKey()))\n+                                            .setValue(e.getValue())\n+                                            .build())\n+                                    .collect(Collectors.toList()));\n+                    break;\n+                case GLOBAL_ADDRESS:\n+                    metadataMsgBuilder.setGlobalAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CHECKPOINT_TYPE:\n+                    metadataMsgBuilder.setCheckpointType(Int32Value.of(((CheckpointEntryType)obj).asByte()));\n+                    break;\n+                case CHECKPOINT_ID:\n+                    metadataMsgBuilder.setCheckpointId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_ID:\n+                    metadataMsgBuilder.setCheckpointedStreamId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_START_LOG_ADDRESS:\n+                    metadataMsgBuilder.setCheckpointedStreamStartLogAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CLIENT_ID:\n+                    metadataMsgBuilder.setClientId(getUuidMsg((UUID)obj));\n+                    break;\n+                case THREAD_ID:\n+                    metadataMsgBuilder.setThreadId(Int64Value.of((Long)obj));\n+                    break;\n+                case EPOCH:\n+                    metadataMsgBuilder.setEpoch(Int64Value.of((Long)obj));\n+                    break;\n+                default:\n+                    metadataMsgBuilder.setCodecTypeId(Int32Value.of(((Codec.Type)obj).getId()));\n+            }});\n+\n+        return metadataMsgBuilder.build();\n+    }\n+\n+    /**\n+     * Populates the LogData's metadata from the provided Protobuf\n+     * LogUnitMetadata message.\n+     */\n+    private static void addLogUnitMetadata(ILogData data, LogUnitMetadataMsg msg) {\n+        if (msg.hasDataRank()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.RANK, getDataRank(msg.getDataRank()));\n+        }\n+\n+        if (msg.getBackpointerMapCount() > 0) {\n+            data.getMetadataMap().put(LogUnitMetadataType.BACKPOINTER_MAP,\n+                    msg.getBackpointerMapList().stream()\n+                            .collect(Collectors.<UuidToLongPairMsg, UUID, Long>toMap(\n+                                    e -> getUUID(e.getKey()),\n+                                    UuidToLongPairMsg::getValue\n+                            )));\n+        }\n+\n+        if (msg.hasGlobalAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.GLOBAL_ADDRESS, msg.getGlobalAddress().getValue());\n+        }\n+\n+        if (msg.hasCheckpointType()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_TYPE,\n+                    CheckpointEntryType.typeMap.get((byte)msg.getCheckpointType().getValue()));\n+        }\n+\n+        if (msg.hasCheckpointId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_ID, getUUID(msg.getCheckpointId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_ID, getUUID(msg.getCheckpointedStreamId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamStartLogAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_START_LOG_ADDRESS,\n+                    msg.getCheckpointedStreamStartLogAddress().getValue());\n+        }\n+\n+        if (msg.hasClientId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CLIENT_ID, getUUID(msg.getClientId()));\n+        }\n+\n+        if (msg.hasThreadId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.THREAD_ID, msg.getThreadId().getValue());\n+        }\n+\n+        if (msg.hasEpoch()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.EPOCH, msg.getEpoch().getValue());\n+        }\n+\n+        if (msg.hasCodecTypeId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.PAYLOAD_CODEC,\n+                    Codec.getCodecTypeById(msg.getCodecTypeId().getValue()));\n+        }\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData object\n+     * of type DATA.\n+     */\n+    private static LogDataMsg getLogDataEntryMsg(LogData logData) {\n+        if (!logData.isData()) {\n+            throw new IllegalArgumentException(\"Incorrect LogData type provided: \" + logData.getType().toString());\n+        }\n+\n+        LogDataEntryMsg.Builder entryMsgBuilder = LogDataEntryMsg.newBuilder();\n+\n+        //TODO(Zach): Optimize and cleanup -- Concurrency bug?\n+        //TODO(Zach): Reduce number of buffer copies", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU1OTE0Mg=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mjg0MTE4OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzo0MjowNFrOIKMYZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzo0MjowNFrOIKMYZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU1OTUyNA==", "bodyText": "Are these TODO comments still relevant and need to be addressed?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547559524", "createdAt": "2020-12-22T23:42:04Z", "author": {"login": "WenbinZhu"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import com.google.protobuf.Int32Value;\n+import com.google.protobuf.Int64Value;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry.CheckpointEntryType;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.ICorfuPayload;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.IMetadata.DataRank;\n+import org.corfudb.protocols.wireprotocol.IMetadata.LogUnitMetadataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.LogData.DataRankMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEmptyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEntryMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataHoleMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataRankOnlyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataTrimmedMsg;\n+import org.corfudb.runtime.proto.LogData.LogUnitMetadataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import java.nio.ByteBuffer;\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.*;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a DataRank object.\n+     */\n+    private static DataRankMsg getDataRankMsg(DataRank dataRank) {\n+        return DataRankMsg.newBuilder()\n+                .setId(getUuidMsg(dataRank.getUuid()))\n+                .setRank(dataRank.getRank())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a DataRank object from its Protobuf representation.\n+     */\n+    private static DataRank getDataRank(DataRankMsg msg) {\n+        return new DataRank(msg.getRank(), getUUID(msg.getId()));\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData's\n+     * metadata map.\n+     */\n+    private static LogUnitMetadataMsg getLogUnitMetadataMsg(EnumMap<LogUnitMetadataType, Object> metadata) {\n+        LogUnitMetadataMsg.Builder metadataMsgBuilder = LogUnitMetadataMsg.newBuilder();\n+\n+        metadata.forEach((type, obj)  -> {\n+            switch (type) {\n+                case RANK:\n+                    metadataMsgBuilder.setDataRank(getDataRankMsg((DataRank)obj));\n+                    break;\n+                case BACKPOINTER_MAP:\n+                    metadataMsgBuilder.addAllBackpointerMap(\n+                            ((Map<UUID, Long>)obj).entrySet()\n+                                    .stream()\n+                                    .map(e -> UuidToLongPairMsg.newBuilder()\n+                                            .setKey(getUuidMsg(e.getKey()))\n+                                            .setValue(e.getValue())\n+                                            .build())\n+                                    .collect(Collectors.toList()));\n+                    break;\n+                case GLOBAL_ADDRESS:\n+                    metadataMsgBuilder.setGlobalAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CHECKPOINT_TYPE:\n+                    metadataMsgBuilder.setCheckpointType(Int32Value.of(((CheckpointEntryType)obj).asByte()));\n+                    break;\n+                case CHECKPOINT_ID:\n+                    metadataMsgBuilder.setCheckpointId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_ID:\n+                    metadataMsgBuilder.setCheckpointedStreamId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_START_LOG_ADDRESS:\n+                    metadataMsgBuilder.setCheckpointedStreamStartLogAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CLIENT_ID:\n+                    metadataMsgBuilder.setClientId(getUuidMsg((UUID)obj));\n+                    break;\n+                case THREAD_ID:\n+                    metadataMsgBuilder.setThreadId(Int64Value.of((Long)obj));\n+                    break;\n+                case EPOCH:\n+                    metadataMsgBuilder.setEpoch(Int64Value.of((Long)obj));\n+                    break;\n+                default:\n+                    metadataMsgBuilder.setCodecTypeId(Int32Value.of(((Codec.Type)obj).getId()));\n+            }});\n+\n+        return metadataMsgBuilder.build();\n+    }\n+\n+    /**\n+     * Populates the LogData's metadata from the provided Protobuf\n+     * LogUnitMetadata message.\n+     */\n+    private static void addLogUnitMetadata(ILogData data, LogUnitMetadataMsg msg) {\n+        if (msg.hasDataRank()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.RANK, getDataRank(msg.getDataRank()));\n+        }\n+\n+        if (msg.getBackpointerMapCount() > 0) {\n+            data.getMetadataMap().put(LogUnitMetadataType.BACKPOINTER_MAP,\n+                    msg.getBackpointerMapList().stream()\n+                            .collect(Collectors.<UuidToLongPairMsg, UUID, Long>toMap(\n+                                    e -> getUUID(e.getKey()),\n+                                    UuidToLongPairMsg::getValue\n+                            )));\n+        }\n+\n+        if (msg.hasGlobalAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.GLOBAL_ADDRESS, msg.getGlobalAddress().getValue());\n+        }\n+\n+        if (msg.hasCheckpointType()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_TYPE,\n+                    CheckpointEntryType.typeMap.get((byte)msg.getCheckpointType().getValue()));\n+        }\n+\n+        if (msg.hasCheckpointId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_ID, getUUID(msg.getCheckpointId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_ID, getUUID(msg.getCheckpointedStreamId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamStartLogAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_START_LOG_ADDRESS,\n+                    msg.getCheckpointedStreamStartLogAddress().getValue());\n+        }\n+\n+        if (msg.hasClientId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CLIENT_ID, getUUID(msg.getClientId()));\n+        }\n+\n+        if (msg.hasThreadId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.THREAD_ID, msg.getThreadId().getValue());\n+        }\n+\n+        if (msg.hasEpoch()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.EPOCH, msg.getEpoch().getValue());\n+        }\n+\n+        if (msg.hasCodecTypeId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.PAYLOAD_CODEC,\n+                    Codec.getCodecTypeById(msg.getCodecTypeId().getValue()));\n+        }\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData object\n+     * of type DATA.\n+     */\n+    private static LogDataMsg getLogDataEntryMsg(LogData logData) {\n+        if (!logData.isData()) {\n+            throw new IllegalArgumentException(\"Incorrect LogData type provided: \" + logData.getType().toString());\n+        }\n+\n+        LogDataEntryMsg.Builder entryMsgBuilder = LogDataEntryMsg.newBuilder();\n+\n+        //TODO(Zach): Optimize and cleanup -- Concurrency bug?\n+        //TODO(Zach): Reduce number of buffer copies\n+\n+        if (logData.getData() != null) {\n+            entryMsgBuilder.setData(ByteString.copyFrom(logData.getData()));\n+        } else {\n+            ByteBuf serializedBuf = Unpooled.buffer();\n+            Serializers.CORFU.serialize(logData.getPayload(null), serializedBuf);\n+            ByteBuffer wrappedByteBuf = ByteBuffer.wrap(serializedBuf.array(), 0, serializedBuf.readableBytes());\n+\n+            //TODO(Zach): Do we need to consider LogData's lastKnownSize here?\n+            if (logData.hasPayloadCodec()) {\n+                ByteBuf buffer = Unpooled.buffer();\n+                ByteBuffer compressedBuf = logData.getPayloadCodecType().getInstance().compress(wrappedByteBuf);\n+\n+                //TODO(Zach): Don't use ICorfuPayload", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 201}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mjg3MzQ1OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQyMzo1OToxM1rOIKMqLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQxNzoyOTozOFrOIQa2sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NDA3OA==", "bodyText": "I think there are inefficiencies here. From client side, before the LogData is transformed to protobuf, it was already seralized, and the serailized data is cached in LogData's serializedCache(see StreamsView::append and LogData code). Here you get the payload and serialize the payload object directly, this bypassed the serializedCache, causing extra serialization. Also I think there is another problem here. logData.getPayload(null) returns the original object which is uncompressed, so I guess the compression feature is broken if you serialize the payload directly.\nIf this is a problem and you later change it to use LogData's serialization methods, be aware that by default LogData serailizes metadata and payload together, but in your protobuf definition there are separate.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547564078", "createdAt": "2020-12-22T23:59:13Z", "author": {"login": "WenbinZhu"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import com.google.protobuf.Int32Value;\n+import com.google.protobuf.Int64Value;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry.CheckpointEntryType;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.ICorfuPayload;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.IMetadata.DataRank;\n+import org.corfudb.protocols.wireprotocol.IMetadata.LogUnitMetadataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.LogData.DataRankMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEmptyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEntryMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataHoleMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataRankOnlyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataTrimmedMsg;\n+import org.corfudb.runtime.proto.LogData.LogUnitMetadataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import java.nio.ByteBuffer;\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.*;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a DataRank object.\n+     */\n+    private static DataRankMsg getDataRankMsg(DataRank dataRank) {\n+        return DataRankMsg.newBuilder()\n+                .setId(getUuidMsg(dataRank.getUuid()))\n+                .setRank(dataRank.getRank())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a DataRank object from its Protobuf representation.\n+     */\n+    private static DataRank getDataRank(DataRankMsg msg) {\n+        return new DataRank(msg.getRank(), getUUID(msg.getId()));\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData's\n+     * metadata map.\n+     */\n+    private static LogUnitMetadataMsg getLogUnitMetadataMsg(EnumMap<LogUnitMetadataType, Object> metadata) {\n+        LogUnitMetadataMsg.Builder metadataMsgBuilder = LogUnitMetadataMsg.newBuilder();\n+\n+        metadata.forEach((type, obj)  -> {\n+            switch (type) {\n+                case RANK:\n+                    metadataMsgBuilder.setDataRank(getDataRankMsg((DataRank)obj));\n+                    break;\n+                case BACKPOINTER_MAP:\n+                    metadataMsgBuilder.addAllBackpointerMap(\n+                            ((Map<UUID, Long>)obj).entrySet()\n+                                    .stream()\n+                                    .map(e -> UuidToLongPairMsg.newBuilder()\n+                                            .setKey(getUuidMsg(e.getKey()))\n+                                            .setValue(e.getValue())\n+                                            .build())\n+                                    .collect(Collectors.toList()));\n+                    break;\n+                case GLOBAL_ADDRESS:\n+                    metadataMsgBuilder.setGlobalAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CHECKPOINT_TYPE:\n+                    metadataMsgBuilder.setCheckpointType(Int32Value.of(((CheckpointEntryType)obj).asByte()));\n+                    break;\n+                case CHECKPOINT_ID:\n+                    metadataMsgBuilder.setCheckpointId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_ID:\n+                    metadataMsgBuilder.setCheckpointedStreamId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_START_LOG_ADDRESS:\n+                    metadataMsgBuilder.setCheckpointedStreamStartLogAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CLIENT_ID:\n+                    metadataMsgBuilder.setClientId(getUuidMsg((UUID)obj));\n+                    break;\n+                case THREAD_ID:\n+                    metadataMsgBuilder.setThreadId(Int64Value.of((Long)obj));\n+                    break;\n+                case EPOCH:\n+                    metadataMsgBuilder.setEpoch(Int64Value.of((Long)obj));\n+                    break;\n+                default:\n+                    metadataMsgBuilder.setCodecTypeId(Int32Value.of(((Codec.Type)obj).getId()));\n+            }});\n+\n+        return metadataMsgBuilder.build();\n+    }\n+\n+    /**\n+     * Populates the LogData's metadata from the provided Protobuf\n+     * LogUnitMetadata message.\n+     */\n+    private static void addLogUnitMetadata(ILogData data, LogUnitMetadataMsg msg) {\n+        if (msg.hasDataRank()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.RANK, getDataRank(msg.getDataRank()));\n+        }\n+\n+        if (msg.getBackpointerMapCount() > 0) {\n+            data.getMetadataMap().put(LogUnitMetadataType.BACKPOINTER_MAP,\n+                    msg.getBackpointerMapList().stream()\n+                            .collect(Collectors.<UuidToLongPairMsg, UUID, Long>toMap(\n+                                    e -> getUUID(e.getKey()),\n+                                    UuidToLongPairMsg::getValue\n+                            )));\n+        }\n+\n+        if (msg.hasGlobalAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.GLOBAL_ADDRESS, msg.getGlobalAddress().getValue());\n+        }\n+\n+        if (msg.hasCheckpointType()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_TYPE,\n+                    CheckpointEntryType.typeMap.get((byte)msg.getCheckpointType().getValue()));\n+        }\n+\n+        if (msg.hasCheckpointId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_ID, getUUID(msg.getCheckpointId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_ID, getUUID(msg.getCheckpointedStreamId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamStartLogAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_START_LOG_ADDRESS,\n+                    msg.getCheckpointedStreamStartLogAddress().getValue());\n+        }\n+\n+        if (msg.hasClientId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CLIENT_ID, getUUID(msg.getClientId()));\n+        }\n+\n+        if (msg.hasThreadId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.THREAD_ID, msg.getThreadId().getValue());\n+        }\n+\n+        if (msg.hasEpoch()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.EPOCH, msg.getEpoch().getValue());\n+        }\n+\n+        if (msg.hasCodecTypeId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.PAYLOAD_CODEC,\n+                    Codec.getCodecTypeById(msg.getCodecTypeId().getValue()));\n+        }\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData object\n+     * of type DATA.\n+     */\n+    private static LogDataMsg getLogDataEntryMsg(LogData logData) {\n+        if (!logData.isData()) {\n+            throw new IllegalArgumentException(\"Incorrect LogData type provided: \" + logData.getType().toString());\n+        }\n+\n+        LogDataEntryMsg.Builder entryMsgBuilder = LogDataEntryMsg.newBuilder();\n+\n+        //TODO(Zach): Optimize and cleanup -- Concurrency bug?\n+        //TODO(Zach): Reduce number of buffer copies\n+\n+        if (logData.getData() != null) {\n+            entryMsgBuilder.setData(ByteString.copyFrom(logData.getData()));\n+        } else {\n+            ByteBuf serializedBuf = Unpooled.buffer();\n+            Serializers.CORFU.serialize(logData.getPayload(null), serializedBuf);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 193}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzY0MTczOQ==", "bodyText": "LogData objects are usually long lived and should probably be lightweight, using a protobuf representation will probably increase memory overhead. I think a protobuf representation would be much more \"bloated\", so I suggest keeping the current representation.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r553641739", "createdAt": "2021-01-07T22:57:40Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import com.google.protobuf.Int32Value;\n+import com.google.protobuf.Int64Value;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry.CheckpointEntryType;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.ICorfuPayload;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.IMetadata.DataRank;\n+import org.corfudb.protocols.wireprotocol.IMetadata.LogUnitMetadataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.LogData.DataRankMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEmptyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEntryMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataHoleMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataRankOnlyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataTrimmedMsg;\n+import org.corfudb.runtime.proto.LogData.LogUnitMetadataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import java.nio.ByteBuffer;\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.*;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a DataRank object.\n+     */\n+    private static DataRankMsg getDataRankMsg(DataRank dataRank) {\n+        return DataRankMsg.newBuilder()\n+                .setId(getUuidMsg(dataRank.getUuid()))\n+                .setRank(dataRank.getRank())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a DataRank object from its Protobuf representation.\n+     */\n+    private static DataRank getDataRank(DataRankMsg msg) {\n+        return new DataRank(msg.getRank(), getUUID(msg.getId()));\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData's\n+     * metadata map.\n+     */\n+    private static LogUnitMetadataMsg getLogUnitMetadataMsg(EnumMap<LogUnitMetadataType, Object> metadata) {\n+        LogUnitMetadataMsg.Builder metadataMsgBuilder = LogUnitMetadataMsg.newBuilder();\n+\n+        metadata.forEach((type, obj)  -> {\n+            switch (type) {\n+                case RANK:\n+                    metadataMsgBuilder.setDataRank(getDataRankMsg((DataRank)obj));\n+                    break;\n+                case BACKPOINTER_MAP:\n+                    metadataMsgBuilder.addAllBackpointerMap(\n+                            ((Map<UUID, Long>)obj).entrySet()\n+                                    .stream()\n+                                    .map(e -> UuidToLongPairMsg.newBuilder()\n+                                            .setKey(getUuidMsg(e.getKey()))\n+                                            .setValue(e.getValue())\n+                                            .build())\n+                                    .collect(Collectors.toList()));\n+                    break;\n+                case GLOBAL_ADDRESS:\n+                    metadataMsgBuilder.setGlobalAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CHECKPOINT_TYPE:\n+                    metadataMsgBuilder.setCheckpointType(Int32Value.of(((CheckpointEntryType)obj).asByte()));\n+                    break;\n+                case CHECKPOINT_ID:\n+                    metadataMsgBuilder.setCheckpointId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_ID:\n+                    metadataMsgBuilder.setCheckpointedStreamId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_START_LOG_ADDRESS:\n+                    metadataMsgBuilder.setCheckpointedStreamStartLogAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CLIENT_ID:\n+                    metadataMsgBuilder.setClientId(getUuidMsg((UUID)obj));\n+                    break;\n+                case THREAD_ID:\n+                    metadataMsgBuilder.setThreadId(Int64Value.of((Long)obj));\n+                    break;\n+                case EPOCH:\n+                    metadataMsgBuilder.setEpoch(Int64Value.of((Long)obj));\n+                    break;\n+                default:\n+                    metadataMsgBuilder.setCodecTypeId(Int32Value.of(((Codec.Type)obj).getId()));\n+            }});\n+\n+        return metadataMsgBuilder.build();\n+    }\n+\n+    /**\n+     * Populates the LogData's metadata from the provided Protobuf\n+     * LogUnitMetadata message.\n+     */\n+    private static void addLogUnitMetadata(ILogData data, LogUnitMetadataMsg msg) {\n+        if (msg.hasDataRank()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.RANK, getDataRank(msg.getDataRank()));\n+        }\n+\n+        if (msg.getBackpointerMapCount() > 0) {\n+            data.getMetadataMap().put(LogUnitMetadataType.BACKPOINTER_MAP,\n+                    msg.getBackpointerMapList().stream()\n+                            .collect(Collectors.<UuidToLongPairMsg, UUID, Long>toMap(\n+                                    e -> getUUID(e.getKey()),\n+                                    UuidToLongPairMsg::getValue\n+                            )));\n+        }\n+\n+        if (msg.hasGlobalAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.GLOBAL_ADDRESS, msg.getGlobalAddress().getValue());\n+        }\n+\n+        if (msg.hasCheckpointType()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_TYPE,\n+                    CheckpointEntryType.typeMap.get((byte)msg.getCheckpointType().getValue()));\n+        }\n+\n+        if (msg.hasCheckpointId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_ID, getUUID(msg.getCheckpointId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_ID, getUUID(msg.getCheckpointedStreamId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamStartLogAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_START_LOG_ADDRESS,\n+                    msg.getCheckpointedStreamStartLogAddress().getValue());\n+        }\n+\n+        if (msg.hasClientId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CLIENT_ID, getUUID(msg.getClientId()));\n+        }\n+\n+        if (msg.hasThreadId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.THREAD_ID, msg.getThreadId().getValue());\n+        }\n+\n+        if (msg.hasEpoch()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.EPOCH, msg.getEpoch().getValue());\n+        }\n+\n+        if (msg.hasCodecTypeId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.PAYLOAD_CODEC,\n+                    Codec.getCodecTypeById(msg.getCodecTypeId().getValue()));\n+        }\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData object\n+     * of type DATA.\n+     */\n+    private static LogDataMsg getLogDataEntryMsg(LogData logData) {\n+        if (!logData.isData()) {\n+            throw new IllegalArgumentException(\"Incorrect LogData type provided: \" + logData.getType().toString());\n+        }\n+\n+        LogDataEntryMsg.Builder entryMsgBuilder = LogDataEntryMsg.newBuilder();\n+\n+        //TODO(Zach): Optimize and cleanup -- Concurrency bug?\n+        //TODO(Zach): Reduce number of buffer copies\n+\n+        if (logData.getData() != null) {\n+            entryMsgBuilder.setData(ByteString.copyFrom(logData.getData()));\n+        } else {\n+            ByteBuf serializedBuf = Unpooled.buffer();\n+            Serializers.CORFU.serialize(logData.getPayload(null), serializedBuf);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NDA3OA=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 193}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDA4ODExNA==", "bodyText": "Thank you both for your comments and suggestions. I've gone with the latter approach, and no longer have separate definitions for the metadata. The entire entry is now obtained from LogData's serialization methods.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r554088114", "createdAt": "2021-01-08T17:29:38Z", "author": {"login": "zfrenette"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import com.google.protobuf.Int32Value;\n+import com.google.protobuf.Int64Value;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry.CheckpointEntryType;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.ICorfuPayload;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.IMetadata.DataRank;\n+import org.corfudb.protocols.wireprotocol.IMetadata.LogUnitMetadataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.LogData.DataRankMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEmptyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEntryMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataHoleMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataRankOnlyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataTrimmedMsg;\n+import org.corfudb.runtime.proto.LogData.LogUnitMetadataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import java.nio.ByteBuffer;\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.*;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a DataRank object.\n+     */\n+    private static DataRankMsg getDataRankMsg(DataRank dataRank) {\n+        return DataRankMsg.newBuilder()\n+                .setId(getUuidMsg(dataRank.getUuid()))\n+                .setRank(dataRank.getRank())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a DataRank object from its Protobuf representation.\n+     */\n+    private static DataRank getDataRank(DataRankMsg msg) {\n+        return new DataRank(msg.getRank(), getUUID(msg.getId()));\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData's\n+     * metadata map.\n+     */\n+    private static LogUnitMetadataMsg getLogUnitMetadataMsg(EnumMap<LogUnitMetadataType, Object> metadata) {\n+        LogUnitMetadataMsg.Builder metadataMsgBuilder = LogUnitMetadataMsg.newBuilder();\n+\n+        metadata.forEach((type, obj)  -> {\n+            switch (type) {\n+                case RANK:\n+                    metadataMsgBuilder.setDataRank(getDataRankMsg((DataRank)obj));\n+                    break;\n+                case BACKPOINTER_MAP:\n+                    metadataMsgBuilder.addAllBackpointerMap(\n+                            ((Map<UUID, Long>)obj).entrySet()\n+                                    .stream()\n+                                    .map(e -> UuidToLongPairMsg.newBuilder()\n+                                            .setKey(getUuidMsg(e.getKey()))\n+                                            .setValue(e.getValue())\n+                                            .build())\n+                                    .collect(Collectors.toList()));\n+                    break;\n+                case GLOBAL_ADDRESS:\n+                    metadataMsgBuilder.setGlobalAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CHECKPOINT_TYPE:\n+                    metadataMsgBuilder.setCheckpointType(Int32Value.of(((CheckpointEntryType)obj).asByte()));\n+                    break;\n+                case CHECKPOINT_ID:\n+                    metadataMsgBuilder.setCheckpointId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_ID:\n+                    metadataMsgBuilder.setCheckpointedStreamId(getUuidMsg((UUID)obj));\n+                    break;\n+                case CHECKPOINTED_STREAM_START_LOG_ADDRESS:\n+                    metadataMsgBuilder.setCheckpointedStreamStartLogAddress(Int64Value.of((Long)obj));\n+                    break;\n+                case CLIENT_ID:\n+                    metadataMsgBuilder.setClientId(getUuidMsg((UUID)obj));\n+                    break;\n+                case THREAD_ID:\n+                    metadataMsgBuilder.setThreadId(Int64Value.of((Long)obj));\n+                    break;\n+                case EPOCH:\n+                    metadataMsgBuilder.setEpoch(Int64Value.of((Long)obj));\n+                    break;\n+                default:\n+                    metadataMsgBuilder.setCodecTypeId(Int32Value.of(((Codec.Type)obj).getId()));\n+            }});\n+\n+        return metadataMsgBuilder.build();\n+    }\n+\n+    /**\n+     * Populates the LogData's metadata from the provided Protobuf\n+     * LogUnitMetadata message.\n+     */\n+    private static void addLogUnitMetadata(ILogData data, LogUnitMetadataMsg msg) {\n+        if (msg.hasDataRank()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.RANK, getDataRank(msg.getDataRank()));\n+        }\n+\n+        if (msg.getBackpointerMapCount() > 0) {\n+            data.getMetadataMap().put(LogUnitMetadataType.BACKPOINTER_MAP,\n+                    msg.getBackpointerMapList().stream()\n+                            .collect(Collectors.<UuidToLongPairMsg, UUID, Long>toMap(\n+                                    e -> getUUID(e.getKey()),\n+                                    UuidToLongPairMsg::getValue\n+                            )));\n+        }\n+\n+        if (msg.hasGlobalAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.GLOBAL_ADDRESS, msg.getGlobalAddress().getValue());\n+        }\n+\n+        if (msg.hasCheckpointType()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_TYPE,\n+                    CheckpointEntryType.typeMap.get((byte)msg.getCheckpointType().getValue()));\n+        }\n+\n+        if (msg.hasCheckpointId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINT_ID, getUUID(msg.getCheckpointId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_ID, getUUID(msg.getCheckpointedStreamId()));\n+        }\n+\n+        if (msg.hasCheckpointedStreamStartLogAddress()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CHECKPOINTED_STREAM_START_LOG_ADDRESS,\n+                    msg.getCheckpointedStreamStartLogAddress().getValue());\n+        }\n+\n+        if (msg.hasClientId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.CLIENT_ID, getUUID(msg.getClientId()));\n+        }\n+\n+        if (msg.hasThreadId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.THREAD_ID, msg.getThreadId().getValue());\n+        }\n+\n+        if (msg.hasEpoch()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.EPOCH, msg.getEpoch().getValue());\n+        }\n+\n+        if (msg.hasCodecTypeId()) {\n+            data.getMetadataMap().put(LogUnitMetadataType.PAYLOAD_CODEC,\n+                    Codec.getCodecTypeById(msg.getCodecTypeId().getValue()));\n+        }\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData object\n+     * of type DATA.\n+     */\n+    private static LogDataMsg getLogDataEntryMsg(LogData logData) {\n+        if (!logData.isData()) {\n+            throw new IllegalArgumentException(\"Incorrect LogData type provided: \" + logData.getType().toString());\n+        }\n+\n+        LogDataEntryMsg.Builder entryMsgBuilder = LogDataEntryMsg.newBuilder();\n+\n+        //TODO(Zach): Optimize and cleanup -- Concurrency bug?\n+        //TODO(Zach): Reduce number of buffer copies\n+\n+        if (logData.getData() != null) {\n+            entryMsgBuilder.setData(ByteString.copyFrom(logData.getData()));\n+        } else {\n+            ByteBuf serializedBuf = Unpooled.buffer();\n+            Serializers.CORFU.serialize(logData.getPayload(null), serializedBuf);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NDA3OA=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 193}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mjg4MDIyOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QwMDowMzo0NVrOIKMuGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QwMDowMzo0NVrOIKMuGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NTA4MA==", "bodyText": "NIT: extra space before \"->\"", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547565080", "createdAt": "2020-12-23T00:03:45Z", "author": {"login": "WenbinZhu"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import com.google.protobuf.Int32Value;\n+import com.google.protobuf.Int64Value;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry.CheckpointEntryType;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.ICorfuPayload;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.IMetadata.DataRank;\n+import org.corfudb.protocols.wireprotocol.IMetadata.LogUnitMetadataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.LogData.DataRankMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEmptyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataEntryMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataHoleMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataRankOnlyMsg;\n+import org.corfudb.runtime.proto.LogData.LogDataTrimmedMsg;\n+import org.corfudb.runtime.proto.LogData.LogUnitMetadataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import java.nio.ByteBuffer;\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.*;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a DataRank object.\n+     */\n+    private static DataRankMsg getDataRankMsg(DataRank dataRank) {\n+        return DataRankMsg.newBuilder()\n+                .setId(getUuidMsg(dataRank.getUuid()))\n+                .setRank(dataRank.getRank())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a DataRank object from its Protobuf representation.\n+     */\n+    private static DataRank getDataRank(DataRankMsg msg) {\n+        return new DataRank(msg.getRank(), getUUID(msg.getId()));\n+    }\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData's\n+     * metadata map.\n+     */\n+    private static LogUnitMetadataMsg getLogUnitMetadataMsg(EnumMap<LogUnitMetadataType, Object> metadata) {\n+        LogUnitMetadataMsg.Builder metadataMsgBuilder = LogUnitMetadataMsg.newBuilder();\n+\n+        metadata.forEach((type, obj)  -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mjg5NTA3OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/service/CorfuProtocolLogUnit.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QwMDoxMjoyNFrOIKM2Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQyMjoyNDozNVrOIXV5qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NzE5MQ==", "bodyText": "Where is this method being used? Looks like only the one above this one, i.e. getTailRequestMsg with the type as parameter is being used. I think you can remove this one.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547567191", "createdAt": "2020-12-23T00:12:24Z", "author": {"login": "WenbinZhu"}, "path": "runtime/src/main/java/org/corfudb/protocols/service/CorfuProtocolLogUnit.java", "diffHunk": "@@ -0,0 +1,539 @@\n+package org.corfudb.protocols.service;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.CorfuProtocolLogData;\n+import org.corfudb.protocols.wireprotocol.InspectAddressesResponse;\n+import org.corfudb.protocols.wireprotocol.KnownAddressResponse;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.ReadResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToStreamAddressSpacePairMsg;\n+import org.corfudb.runtime.proto.ServerErrors.ValueAdoptedErrorMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestPayloadMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.ResponsePayloadMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CompactRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CompactResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CommittedTailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CommittedTailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.FlushCacheRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.FlushCacheResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.InspectAddressesRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.InspectAddressesResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.KnownAddressRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.KnownAddressResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.LogAddressSpaceRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.LogAddressSpaceResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.RangeWriteLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.RangeWriteLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ReadLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ReadLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ResetLogUnitRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ResetLogUnitResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimMarkRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimMarkResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.UpdateCommittedTailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.UpdateCommittedTailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.WriteLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.WriteLogResponseMsg;\n+import org.corfudb.runtime.view.stream.StreamAddressSpace;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.getStreamAddressSpaceMsg;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getTokenMsg;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogData;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogDataMsg;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getReadResponseMsg;\n+\n+/**\n+ * This class provides methods for creating the Protobuf objects defined\n+ * in log_unit.proto. These provide the interface for performing the RPCs\n+ * handled by the LogUnit server.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogUnit {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogUnit() {}\n+\n+    /**\n+     * Returns a READ request that can be sent by the client.\n+     *\n+     * @param addresses  a list of addresses to read from\n+     * @param cacheable  true if the read result should be cached on the LogUnit server\n+     * @return           a RequestPayloadMsg containing the READ request\n+     */\n+    public static RequestPayloadMsg getReadLogRequestMsg(List<Long> addresses, boolean cacheable) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setReadLogRequest(ReadLogRequestMsg.newBuilder()\n+                        .setCacheResults(cacheable)\n+                        .addAllAddress(addresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a READ response that can be sent by the server.\n+     *\n+     * @param addresses  a map containing the log data from the addresses read\n+     * @return           a ResponsePayloadMsg containing the READ response\n+     */\n+    public static ResponsePayloadMsg getReadLogResponseMsg(Map<Long, LogData> addresses) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setReadLogResponse(ReadLogResponseMsg.newBuilder()\n+                        .addAllResponse(addresses.entrySet()\n+                                .stream()\n+                                .map(e -> getReadResponseMsg(e.getKey(), e.getValue()))\n+                                .collect(Collectors.toList()))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a ReadResponse from its Protobuf representation.\n+     *\n+     * @param msg  the desired Protobuf ReadLogResponse message\n+     * @return     an equivalent ReadResponse object\n+     */\n+    public static ReadResponse getReadResponse(ReadLogResponseMsg msg) {\n+        ReadResponse rr = new ReadResponse();\n+        msg.getResponseList().forEach(e -> rr.put(e.getAddress(), getLogData(e.getLogData())));\n+\n+        return rr;\n+    }\n+\n+    /**\n+     * Returns a ReadResponse from a VALUE_ADOPTED error.\n+     *\n+     * @param msg  the desired Protobuf ValueAdoptedError message\n+     * @return     a corresponding ReadResponse object\n+     */\n+    public static ReadResponse getReadResponse(ValueAdoptedErrorMsg msg) {\n+        ReadResponse rr = new ReadResponse();\n+        msg.getResponseList().forEach(e -> rr.put(e.getAddress(), getLogData(e.getLogData())));\n+\n+        return rr;\n+    }\n+\n+    /**\n+     * Returns a WRITE request that can be sent by the client.\n+     *\n+     * @param data  the log data to write to the LogUnit\n+     * @return      a RequestPayloadMsg containing the WRITE request\n+     */\n+    public static RequestPayloadMsg getWriteLogRequestMsg(LogData data) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setWriteLogRequest(WriteLogRequestMsg.newBuilder()\n+                        .setLogData(getLogDataMsg(data))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a WRITE response that can be sent by the server.\n+     *\n+     * @return  a ResponsePayloadMsg containing the WRITE response\n+     */\n+    public static ResponsePayloadMsg getWriteLogResponseMsg() {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setWriteLogResponse(WriteLogResponseMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a RANGE_WRITE request that can be sent by the client.\n+     *\n+     * @param range  the list of log data to write to the LogUnit\n+     * @return       a RequestPayloadMsg containing the RANGE_WRITE request\n+     */\n+    public static RequestPayloadMsg getRangeWriteLogRequestMsg(List<LogData> range) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setRangeWriteLogRequest(RangeWriteLogRequestMsg.newBuilder()\n+                        .addAllLogData(range.stream()\n+                                .map(CorfuProtocolLogData::getLogDataMsg)\n+                                .collect(Collectors.toList()))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a RANGE_WRITE response that can be sent by the server.\n+     *\n+     * @return  a ResponsePayloadMsg containing the RANGE_WRITE response\n+     */\n+    public static ResponsePayloadMsg getRangeWriteLogResponseMsg() {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setRangeWriteLogResponse(RangeWriteLogResponseMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns an INSPECT_ADDRESSES request that can be sent by the client.\n+     *\n+     * @param addresses  a list of global addresses to inspect\n+     * @return           a RequestPayloadMsg containing the INSPECT_ADDRESSES request\n+     */\n+    public static RequestPayloadMsg getInspectAddressesRequestMsg(List<Long> addresses) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setInspectAddressesRequest(InspectAddressesRequestMsg.newBuilder()\n+                        .addAllAddress(addresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns an INSPECT_ADDRESSES response that can be sent by the server.\n+     *\n+     * @param emptyAddresses  the list of empty addresses\n+     * @return                a ResponsePayloadMsg containing the INSPECT_ADDRESSES response\n+     */\n+    public static ResponsePayloadMsg getInspectAddressesResponseMsg(List<Long> emptyAddresses) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setInspectAddressesResponse(InspectAddressesResponseMsg.newBuilder()\n+                        .addAllEmptyAddress(emptyAddresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns an InspectAddressesResponse from its Protobuf representation.\n+     *\n+     * @param msg  the desired Protobuf InspectAddressesResponse message\n+     * @return     an equivalent InspectAddressesResponse object\n+     */\n+    public static InspectAddressesResponse getInspectAddressesResponse(InspectAddressesResponseMsg msg) {\n+        return new InspectAddressesResponse(msg.getEmptyAddressList());\n+    }\n+\n+    /**\n+     * Returns a TRIM_LOG (PREFIX_TRIM) request that can be sent by\n+     * the client.\n+     *\n+     * @param address  an address to trim up to (i.e. [0, address))\n+     * @return         a RequestPayloadMsg containing the TRIM_LOG request\n+     */\n+    public static RequestPayloadMsg getTrimLogRequestMsg(Token address) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setTrimLogRequest(TrimLogRequestMsg.newBuilder()\n+                        .setAddress(getTokenMsg(address))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TRIM_LOG (PREFIX_TRIM) response that can be sent\n+     * by the server.\n+     *\n+     * @return  a ResponsePayloadMsg containing the TRIM_LOG response\n+     */\n+    public static ResponsePayloadMsg getTrimLogResponseMsg() {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setTrimLogResponse(TrimLogResponseMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TRIM_MARK request that can be sent by the client.\n+     *\n+     * @return  a RequestPayloadMsg containing the TRIM_MARK request\n+     */\n+    public static RequestPayloadMsg getTrimMarkRequestMsg() {\n+        return RequestPayloadMsg.newBuilder()\n+                .setTrimMarkRequest(TrimMarkRequestMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TRIM_MARK response that can be sent by the server.\n+     *\n+     * @param trimMark  the first untrimmed address in the address space\n+     * @return          a ResponsePayloadMsg containing the TRIM_MARK response\n+     */\n+    public static ResponsePayloadMsg getTrimMarkResponseMsg(long trimMark) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setTrimMarkResponse(TrimMarkResponseMsg.newBuilder()\n+                        .setTrimMark(trimMark)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TAILS request of the specified type that can be sent by the client.\n+     *\n+     * @param type  the type of the TAILS request\n+     * @return      a RequestPayloadMsg containing the TAILS request\n+     */\n+    public static RequestPayloadMsg getTailRequestMsg(TailRequestMsg.Type type) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setTailRequest(TailRequestMsg.newBuilder()\n+                        .setReqType(type)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TAILS request of type STREAM_TAILS that can be sent by the client.\n+     *\n+     * @param streamIds  the list of stream IDs\n+     * @return           a RequestPayloadMsg containing the TAILS request\n+     */\n+    public static RequestPayloadMsg getTailRequestMsg(List<UUID> streamIds) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 292}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI3ODUwMg==", "bodyText": "It's only being used in some of the unit tests.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r554278502", "createdAt": "2021-01-09T02:35:44Z", "author": {"login": "zfrenette"}, "path": "runtime/src/main/java/org/corfudb/protocols/service/CorfuProtocolLogUnit.java", "diffHunk": "@@ -0,0 +1,539 @@\n+package org.corfudb.protocols.service;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.CorfuProtocolLogData;\n+import org.corfudb.protocols.wireprotocol.InspectAddressesResponse;\n+import org.corfudb.protocols.wireprotocol.KnownAddressResponse;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.ReadResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToStreamAddressSpacePairMsg;\n+import org.corfudb.runtime.proto.ServerErrors.ValueAdoptedErrorMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestPayloadMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.ResponsePayloadMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CompactRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CompactResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CommittedTailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CommittedTailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.FlushCacheRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.FlushCacheResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.InspectAddressesRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.InspectAddressesResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.KnownAddressRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.KnownAddressResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.LogAddressSpaceRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.LogAddressSpaceResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.RangeWriteLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.RangeWriteLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ReadLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ReadLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ResetLogUnitRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ResetLogUnitResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimMarkRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimMarkResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.UpdateCommittedTailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.UpdateCommittedTailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.WriteLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.WriteLogResponseMsg;\n+import org.corfudb.runtime.view.stream.StreamAddressSpace;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.getStreamAddressSpaceMsg;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getTokenMsg;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogData;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogDataMsg;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getReadResponseMsg;\n+\n+/**\n+ * This class provides methods for creating the Protobuf objects defined\n+ * in log_unit.proto. These provide the interface for performing the RPCs\n+ * handled by the LogUnit server.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogUnit {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogUnit() {}\n+\n+    /**\n+     * Returns a READ request that can be sent by the client.\n+     *\n+     * @param addresses  a list of addresses to read from\n+     * @param cacheable  true if the read result should be cached on the LogUnit server\n+     * @return           a RequestPayloadMsg containing the READ request\n+     */\n+    public static RequestPayloadMsg getReadLogRequestMsg(List<Long> addresses, boolean cacheable) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setReadLogRequest(ReadLogRequestMsg.newBuilder()\n+                        .setCacheResults(cacheable)\n+                        .addAllAddress(addresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a READ response that can be sent by the server.\n+     *\n+     * @param addresses  a map containing the log data from the addresses read\n+     * @return           a ResponsePayloadMsg containing the READ response\n+     */\n+    public static ResponsePayloadMsg getReadLogResponseMsg(Map<Long, LogData> addresses) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setReadLogResponse(ReadLogResponseMsg.newBuilder()\n+                        .addAllResponse(addresses.entrySet()\n+                                .stream()\n+                                .map(e -> getReadResponseMsg(e.getKey(), e.getValue()))\n+                                .collect(Collectors.toList()))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a ReadResponse from its Protobuf representation.\n+     *\n+     * @param msg  the desired Protobuf ReadLogResponse message\n+     * @return     an equivalent ReadResponse object\n+     */\n+    public static ReadResponse getReadResponse(ReadLogResponseMsg msg) {\n+        ReadResponse rr = new ReadResponse();\n+        msg.getResponseList().forEach(e -> rr.put(e.getAddress(), getLogData(e.getLogData())));\n+\n+        return rr;\n+    }\n+\n+    /**\n+     * Returns a ReadResponse from a VALUE_ADOPTED error.\n+     *\n+     * @param msg  the desired Protobuf ValueAdoptedError message\n+     * @return     a corresponding ReadResponse object\n+     */\n+    public static ReadResponse getReadResponse(ValueAdoptedErrorMsg msg) {\n+        ReadResponse rr = new ReadResponse();\n+        msg.getResponseList().forEach(e -> rr.put(e.getAddress(), getLogData(e.getLogData())));\n+\n+        return rr;\n+    }\n+\n+    /**\n+     * Returns a WRITE request that can be sent by the client.\n+     *\n+     * @param data  the log data to write to the LogUnit\n+     * @return      a RequestPayloadMsg containing the WRITE request\n+     */\n+    public static RequestPayloadMsg getWriteLogRequestMsg(LogData data) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setWriteLogRequest(WriteLogRequestMsg.newBuilder()\n+                        .setLogData(getLogDataMsg(data))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a WRITE response that can be sent by the server.\n+     *\n+     * @return  a ResponsePayloadMsg containing the WRITE response\n+     */\n+    public static ResponsePayloadMsg getWriteLogResponseMsg() {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setWriteLogResponse(WriteLogResponseMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a RANGE_WRITE request that can be sent by the client.\n+     *\n+     * @param range  the list of log data to write to the LogUnit\n+     * @return       a RequestPayloadMsg containing the RANGE_WRITE request\n+     */\n+    public static RequestPayloadMsg getRangeWriteLogRequestMsg(List<LogData> range) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setRangeWriteLogRequest(RangeWriteLogRequestMsg.newBuilder()\n+                        .addAllLogData(range.stream()\n+                                .map(CorfuProtocolLogData::getLogDataMsg)\n+                                .collect(Collectors.toList()))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a RANGE_WRITE response that can be sent by the server.\n+     *\n+     * @return  a ResponsePayloadMsg containing the RANGE_WRITE response\n+     */\n+    public static ResponsePayloadMsg getRangeWriteLogResponseMsg() {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setRangeWriteLogResponse(RangeWriteLogResponseMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns an INSPECT_ADDRESSES request that can be sent by the client.\n+     *\n+     * @param addresses  a list of global addresses to inspect\n+     * @return           a RequestPayloadMsg containing the INSPECT_ADDRESSES request\n+     */\n+    public static RequestPayloadMsg getInspectAddressesRequestMsg(List<Long> addresses) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setInspectAddressesRequest(InspectAddressesRequestMsg.newBuilder()\n+                        .addAllAddress(addresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns an INSPECT_ADDRESSES response that can be sent by the server.\n+     *\n+     * @param emptyAddresses  the list of empty addresses\n+     * @return                a ResponsePayloadMsg containing the INSPECT_ADDRESSES response\n+     */\n+    public static ResponsePayloadMsg getInspectAddressesResponseMsg(List<Long> emptyAddresses) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setInspectAddressesResponse(InspectAddressesResponseMsg.newBuilder()\n+                        .addAllEmptyAddress(emptyAddresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns an InspectAddressesResponse from its Protobuf representation.\n+     *\n+     * @param msg  the desired Protobuf InspectAddressesResponse message\n+     * @return     an equivalent InspectAddressesResponse object\n+     */\n+    public static InspectAddressesResponse getInspectAddressesResponse(InspectAddressesResponseMsg msg) {\n+        return new InspectAddressesResponse(msg.getEmptyAddressList());\n+    }\n+\n+    /**\n+     * Returns a TRIM_LOG (PREFIX_TRIM) request that can be sent by\n+     * the client.\n+     *\n+     * @param address  an address to trim up to (i.e. [0, address))\n+     * @return         a RequestPayloadMsg containing the TRIM_LOG request\n+     */\n+    public static RequestPayloadMsg getTrimLogRequestMsg(Token address) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setTrimLogRequest(TrimLogRequestMsg.newBuilder()\n+                        .setAddress(getTokenMsg(address))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TRIM_LOG (PREFIX_TRIM) response that can be sent\n+     * by the server.\n+     *\n+     * @return  a ResponsePayloadMsg containing the TRIM_LOG response\n+     */\n+    public static ResponsePayloadMsg getTrimLogResponseMsg() {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setTrimLogResponse(TrimLogResponseMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TRIM_MARK request that can be sent by the client.\n+     *\n+     * @return  a RequestPayloadMsg containing the TRIM_MARK request\n+     */\n+    public static RequestPayloadMsg getTrimMarkRequestMsg() {\n+        return RequestPayloadMsg.newBuilder()\n+                .setTrimMarkRequest(TrimMarkRequestMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TRIM_MARK response that can be sent by the server.\n+     *\n+     * @param trimMark  the first untrimmed address in the address space\n+     * @return          a ResponsePayloadMsg containing the TRIM_MARK response\n+     */\n+    public static ResponsePayloadMsg getTrimMarkResponseMsg(long trimMark) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setTrimMarkResponse(TrimMarkResponseMsg.newBuilder()\n+                        .setTrimMark(trimMark)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TAILS request of the specified type that can be sent by the client.\n+     *\n+     * @param type  the type of the TAILS request\n+     * @return      a RequestPayloadMsg containing the TAILS request\n+     */\n+    public static RequestPayloadMsg getTailRequestMsg(TailRequestMsg.Type type) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setTailRequest(TailRequestMsg.newBuilder()\n+                        .setReqType(type)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TAILS request of type STREAM_TAILS that can be sent by the client.\n+     *\n+     * @param streamIds  the list of stream IDs\n+     * @return           a RequestPayloadMsg containing the TAILS request\n+     */\n+    public static RequestPayloadMsg getTailRequestMsg(List<UUID> streamIds) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NzE5MQ=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 292}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTM0Njk4Ng==", "bodyText": "Note: this has been removed.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r561346986", "createdAt": "2021-01-20T22:24:35Z", "author": {"login": "zfrenette"}, "path": "runtime/src/main/java/org/corfudb/protocols/service/CorfuProtocolLogUnit.java", "diffHunk": "@@ -0,0 +1,539 @@\n+package org.corfudb.protocols.service;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.CorfuProtocolLogData;\n+import org.corfudb.protocols.wireprotocol.InspectAddressesResponse;\n+import org.corfudb.protocols.wireprotocol.KnownAddressResponse;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.ReadResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToStreamAddressSpacePairMsg;\n+import org.corfudb.runtime.proto.ServerErrors.ValueAdoptedErrorMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestPayloadMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.ResponsePayloadMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CompactRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CompactResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CommittedTailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CommittedTailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.FlushCacheRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.FlushCacheResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.InspectAddressesRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.InspectAddressesResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.KnownAddressRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.KnownAddressResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.LogAddressSpaceRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.LogAddressSpaceResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.RangeWriteLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.RangeWriteLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ReadLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ReadLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ResetLogUnitRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ResetLogUnitResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimMarkRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimMarkResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.UpdateCommittedTailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.UpdateCommittedTailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.WriteLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.WriteLogResponseMsg;\n+import org.corfudb.runtime.view.stream.StreamAddressSpace;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.getStreamAddressSpaceMsg;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getTokenMsg;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogData;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogDataMsg;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getReadResponseMsg;\n+\n+/**\n+ * This class provides methods for creating the Protobuf objects defined\n+ * in log_unit.proto. These provide the interface for performing the RPCs\n+ * handled by the LogUnit server.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogUnit {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogUnit() {}\n+\n+    /**\n+     * Returns a READ request that can be sent by the client.\n+     *\n+     * @param addresses  a list of addresses to read from\n+     * @param cacheable  true if the read result should be cached on the LogUnit server\n+     * @return           a RequestPayloadMsg containing the READ request\n+     */\n+    public static RequestPayloadMsg getReadLogRequestMsg(List<Long> addresses, boolean cacheable) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setReadLogRequest(ReadLogRequestMsg.newBuilder()\n+                        .setCacheResults(cacheable)\n+                        .addAllAddress(addresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a READ response that can be sent by the server.\n+     *\n+     * @param addresses  a map containing the log data from the addresses read\n+     * @return           a ResponsePayloadMsg containing the READ response\n+     */\n+    public static ResponsePayloadMsg getReadLogResponseMsg(Map<Long, LogData> addresses) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setReadLogResponse(ReadLogResponseMsg.newBuilder()\n+                        .addAllResponse(addresses.entrySet()\n+                                .stream()\n+                                .map(e -> getReadResponseMsg(e.getKey(), e.getValue()))\n+                                .collect(Collectors.toList()))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a ReadResponse from its Protobuf representation.\n+     *\n+     * @param msg  the desired Protobuf ReadLogResponse message\n+     * @return     an equivalent ReadResponse object\n+     */\n+    public static ReadResponse getReadResponse(ReadLogResponseMsg msg) {\n+        ReadResponse rr = new ReadResponse();\n+        msg.getResponseList().forEach(e -> rr.put(e.getAddress(), getLogData(e.getLogData())));\n+\n+        return rr;\n+    }\n+\n+    /**\n+     * Returns a ReadResponse from a VALUE_ADOPTED error.\n+     *\n+     * @param msg  the desired Protobuf ValueAdoptedError message\n+     * @return     a corresponding ReadResponse object\n+     */\n+    public static ReadResponse getReadResponse(ValueAdoptedErrorMsg msg) {\n+        ReadResponse rr = new ReadResponse();\n+        msg.getResponseList().forEach(e -> rr.put(e.getAddress(), getLogData(e.getLogData())));\n+\n+        return rr;\n+    }\n+\n+    /**\n+     * Returns a WRITE request that can be sent by the client.\n+     *\n+     * @param data  the log data to write to the LogUnit\n+     * @return      a RequestPayloadMsg containing the WRITE request\n+     */\n+    public static RequestPayloadMsg getWriteLogRequestMsg(LogData data) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setWriteLogRequest(WriteLogRequestMsg.newBuilder()\n+                        .setLogData(getLogDataMsg(data))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a WRITE response that can be sent by the server.\n+     *\n+     * @return  a ResponsePayloadMsg containing the WRITE response\n+     */\n+    public static ResponsePayloadMsg getWriteLogResponseMsg() {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setWriteLogResponse(WriteLogResponseMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a RANGE_WRITE request that can be sent by the client.\n+     *\n+     * @param range  the list of log data to write to the LogUnit\n+     * @return       a RequestPayloadMsg containing the RANGE_WRITE request\n+     */\n+    public static RequestPayloadMsg getRangeWriteLogRequestMsg(List<LogData> range) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setRangeWriteLogRequest(RangeWriteLogRequestMsg.newBuilder()\n+                        .addAllLogData(range.stream()\n+                                .map(CorfuProtocolLogData::getLogDataMsg)\n+                                .collect(Collectors.toList()))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a RANGE_WRITE response that can be sent by the server.\n+     *\n+     * @return  a ResponsePayloadMsg containing the RANGE_WRITE response\n+     */\n+    public static ResponsePayloadMsg getRangeWriteLogResponseMsg() {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setRangeWriteLogResponse(RangeWriteLogResponseMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns an INSPECT_ADDRESSES request that can be sent by the client.\n+     *\n+     * @param addresses  a list of global addresses to inspect\n+     * @return           a RequestPayloadMsg containing the INSPECT_ADDRESSES request\n+     */\n+    public static RequestPayloadMsg getInspectAddressesRequestMsg(List<Long> addresses) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setInspectAddressesRequest(InspectAddressesRequestMsg.newBuilder()\n+                        .addAllAddress(addresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns an INSPECT_ADDRESSES response that can be sent by the server.\n+     *\n+     * @param emptyAddresses  the list of empty addresses\n+     * @return                a ResponsePayloadMsg containing the INSPECT_ADDRESSES response\n+     */\n+    public static ResponsePayloadMsg getInspectAddressesResponseMsg(List<Long> emptyAddresses) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setInspectAddressesResponse(InspectAddressesResponseMsg.newBuilder()\n+                        .addAllEmptyAddress(emptyAddresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns an InspectAddressesResponse from its Protobuf representation.\n+     *\n+     * @param msg  the desired Protobuf InspectAddressesResponse message\n+     * @return     an equivalent InspectAddressesResponse object\n+     */\n+    public static InspectAddressesResponse getInspectAddressesResponse(InspectAddressesResponseMsg msg) {\n+        return new InspectAddressesResponse(msg.getEmptyAddressList());\n+    }\n+\n+    /**\n+     * Returns a TRIM_LOG (PREFIX_TRIM) request that can be sent by\n+     * the client.\n+     *\n+     * @param address  an address to trim up to (i.e. [0, address))\n+     * @return         a RequestPayloadMsg containing the TRIM_LOG request\n+     */\n+    public static RequestPayloadMsg getTrimLogRequestMsg(Token address) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setTrimLogRequest(TrimLogRequestMsg.newBuilder()\n+                        .setAddress(getTokenMsg(address))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TRIM_LOG (PREFIX_TRIM) response that can be sent\n+     * by the server.\n+     *\n+     * @return  a ResponsePayloadMsg containing the TRIM_LOG response\n+     */\n+    public static ResponsePayloadMsg getTrimLogResponseMsg() {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setTrimLogResponse(TrimLogResponseMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TRIM_MARK request that can be sent by the client.\n+     *\n+     * @return  a RequestPayloadMsg containing the TRIM_MARK request\n+     */\n+    public static RequestPayloadMsg getTrimMarkRequestMsg() {\n+        return RequestPayloadMsg.newBuilder()\n+                .setTrimMarkRequest(TrimMarkRequestMsg.getDefaultInstance())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TRIM_MARK response that can be sent by the server.\n+     *\n+     * @param trimMark  the first untrimmed address in the address space\n+     * @return          a ResponsePayloadMsg containing the TRIM_MARK response\n+     */\n+    public static ResponsePayloadMsg getTrimMarkResponseMsg(long trimMark) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setTrimMarkResponse(TrimMarkResponseMsg.newBuilder()\n+                        .setTrimMark(trimMark)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TAILS request of the specified type that can be sent by the client.\n+     *\n+     * @param type  the type of the TAILS request\n+     * @return      a RequestPayloadMsg containing the TAILS request\n+     */\n+    public static RequestPayloadMsg getTailRequestMsg(TailRequestMsg.Type type) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setTailRequest(TailRequestMsg.newBuilder()\n+                        .setReqType(type)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a TAILS request of type STREAM_TAILS that can be sent by the client.\n+     *\n+     * @param streamIds  the list of stream IDs\n+     * @return           a RequestPayloadMsg containing the TAILS request\n+     */\n+    public static RequestPayloadMsg getTailRequestMsg(List<UUID> streamIds) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NzE5MQ=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 292}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0Mzg5MDQ0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QwNjo1MToxNFrOIKWWSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQxNzozMTo1NVrOIQa7Tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzcyMjgyNQ==", "bodyText": "NIT: This unused import can be removed I think.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547722825", "createdAt": "2020-12-23T06:51:14Z", "author": {"login": "chetangudisagar"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI5NzcyOQ==", "bodyText": "Which one was unused?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r548297729", "createdAt": "2020-12-23T22:30:28Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzcyMjgyNQ=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM3NTE4NA==", "bodyText": "import static org.corfudb.runtime.proto.service.CorfuMessage.*;\nthis one?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r548375184", "createdAt": "2020-12-24T04:17:54Z", "author": {"login": "chetangudisagar"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzcyMjgyNQ=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDA4OTI5NQ==", "bodyText": "Done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r554089295", "createdAt": "2021-01-08T17:31:55Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/batchprocessor/BatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+package org.corfudb.infrastructure.batchprocessor;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.BatchProcessor;\n+import org.corfudb.infrastructure.BatchWriterOperation;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.QuotaExceededException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.proto.service.LogUnit;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolBase.getSealRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.corfudb.runtime.proto.service.CorfuMessage.*;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzcyMjgyNQ=="}, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ0MzkwMzU0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QwNjo1NDowMFrOIKWezA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QwNjo1NDowMFrOIKWezA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzcyNTAwNA==", "bodyText": "NIT: Can we add an on-demand import statement for CorfuMessage.PriorityLevel?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r547725004", "createdAt": "2020-12-23T06:54:00Z", "author": {"login": "chetangudisagar"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +101,149 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n-                queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+                BatchWriterOperation currentOp;\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n+                        log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n \n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != CorfuMessage.PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d32de0d80235b0667cce34ff692ea4a4a1d16ef"}, "originalPosition": 226}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MTgwMzA0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwMjozOToxOVrOIQ-EcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxOTozNzoyNFrOIRkSxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY2NTA3Mg==", "bodyText": "Seems like the first Timer is still unused?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r554665072", "createdAt": "2021-01-11T02:39:19Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -40,22 +41,21 @@\n @Slf4j\n public class BatchProcessor implements AutoCloseable {\n \n-    final private int BATCH_SIZE = 50;\n-\n-    final private boolean sync;\n-\n-    final private StreamLog streamLog;\n+    private final int BATCH_SIZE = 50;\n+    private final boolean sync;\n+    private final StreamLog streamLog;\n+    private final BlockingQueue<BatchWriterOperation> operationsQueue;\n \n-    final private BlockingQueue<BatchWriterOperation> operationsQueue;\n-\n-    private ExecutorService processorService = Executors\n+    private final ExecutorService processorService = Executors\n             .newSingleThreadExecutor(new ThreadFactoryBuilder()\n                     .setDaemon(false)\n                     .setNameFormat(\"LogUnit-BatchProcessor-%d\")\n                     .build());\n+\n     private final Optional<Timer> writeRecordTimer;\n     private final Optional<Timer> writeRecordsTimer;\n     private final Optional<DistributionSummary> queueSizeDist;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTI5MTMzNQ==", "bodyText": "The first timer is meant to be used for regular writes, while the second for range writes. @PavelZaytsev is in the process of addressing this in another patch.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555291335", "createdAt": "2021-01-11T19:37:24Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -40,22 +41,21 @@\n @Slf4j\n public class BatchProcessor implements AutoCloseable {\n \n-    final private int BATCH_SIZE = 50;\n-\n-    final private boolean sync;\n-\n-    final private StreamLog streamLog;\n+    private final int BATCH_SIZE = 50;\n+    private final boolean sync;\n+    private final StreamLog streamLog;\n+    private final BlockingQueue<BatchWriterOperation> operationsQueue;\n \n-    final private BlockingQueue<BatchWriterOperation> operationsQueue;\n-\n-    private ExecutorService processorService = Executors\n+    private final ExecutorService processorService = Executors\n             .newSingleThreadExecutor(new ThreadFactoryBuilder()\n                     .setDaemon(false)\n                     .setNameFormat(\"LogUnit-BatchProcessor-%d\")\n                     .build());\n+\n     private final Optional<Timer> writeRecordTimer;\n     private final Optional<Timer> writeRecordsTimer;\n     private final Optional<DistributionSummary> queueSizeDist;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY2NTA3Mg=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MTgwNTI2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwMjo0MToxMlrOIQ-Fiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMTo1MzozNlrOIRul9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY2NTM1NQ==", "bodyText": "nit: Will it be better if we also initialize BATCH_SIZE and processorService in the constructor to have a consistent declaration and initialization style?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r554665355", "createdAt": "2021-01-11T02:41:12Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -40,22 +41,21 @@\n @Slf4j\n public class BatchProcessor implements AutoCloseable {\n \n-    final private int BATCH_SIZE = 50;\n-\n-    final private boolean sync;\n-\n-    final private StreamLog streamLog;\n+    private final int BATCH_SIZE = 50;\n+    private final boolean sync;\n+    private final StreamLog streamLog;\n+    private final BlockingQueue<BatchWriterOperation> operationsQueue;\n \n-    final private BlockingQueue<BatchWriterOperation> operationsQueue;\n-\n-    private ExecutorService processorService = Executors\n+    private final ExecutorService processorService = Executors", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ2MDA4Ng==", "bodyText": "Done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555460086", "createdAt": "2021-01-12T01:53:36Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -40,22 +41,21 @@\n @Slf4j\n public class BatchProcessor implements AutoCloseable {\n \n-    final private int BATCH_SIZE = 50;\n-\n-    final private boolean sync;\n-\n-    final private StreamLog streamLog;\n+    private final int BATCH_SIZE = 50;\n+    private final boolean sync;\n+    private final StreamLog streamLog;\n+    private final BlockingQueue<BatchWriterOperation> operationsQueue;\n \n-    final private BlockingQueue<BatchWriterOperation> operationsQueue;\n-\n-    private ExecutorService processorService = Executors\n+    private final ExecutorService processorService = Executors", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY2NTM1NQ=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5MTg4NzU4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwMzo0NjozN1rOIQ-wKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QxNzo0ODo1N1rOIS7OjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY3NjI2NQ==", "bodyText": "Just a question, and I remember we talked about this before: it seems like STREAMS_TAILS isn't used anywhere. Should we treat this as dead code or put a note here?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r554676265", "createdAt": "2021-01-11T03:46:37Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n                 } else {\n                     try {\n-                        switch (currOp.getType()) {\n+                        RequestPayloadMsg payload =  currentOp.getRequest().getPayload();\n+                        switch (currentOp.getType()) {\n                             case PREFIX_TRIM:\n-                                TrimRequest prefixTrim = (TrimRequest) currOp.getMsg().getPayload();\n-                                streamLog.prefixTrim(prefixTrim.getAddress().getSequence());\n+                                final long addr = payload.getTrimLogRequest().getAddress().getSequence();\n+                                streamLog.prefixTrim(addr);\n                                 break;\n                             case WRITE:\n-                                WriteRequest write = (WriteRequest) currOp.getMsg().getPayload();\n-                                Runnable append =\n-                                        () -> streamLog.append(write.getGlobalAddress(), (LogData) write.getData());\n+                                LogData logData = getLogData(payload.getWriteLogRequest().getLogData());\n+                                Runnable append = () -> streamLog.append(logData.getGlobalAddress(), logData);\n                                 recordRunnable(append, writeRecordsTimer);\n                                 break;\n                             case RANGE_WRITE:\n-                                RangeWriteMsg writeRange = (RangeWriteMsg) currOp.getMsg().getPayload();\n-                                Runnable appendMultiple = () -> streamLog.append(writeRange.getEntries());\n+                                List<LogData> range = payload.getRangeWriteLogRequest().getLogDataList()\n+                                        .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+                                Runnable appendMultiple = () -> streamLog.append(range);\n                                 recordRunnable(appendMultiple, writeRecordsTimer);\n                                 break;\n                             case RESET:\n                                 streamLog.reset();\n                                 break;\n                             case TAILS_QUERY:\n-                                TailsRequest tailsRequest = (TailsRequest)currOp.getMsg().getPayload();\n-                                TailsResponse tails;\n+                                final TailsResponse tails;\n \n-                                switch (tailsRequest.getReqType()) {\n-                                    case TailsRequest.LOG_TAIL:\n+                                switch (payload.getTailRequest().getReqType()) {\n+                                    case LOG_TAIL:\n                                         tails = new TailsResponse(streamLog.getLogTail());\n                                         break;\n-\n-                                    case TailsRequest.STREAMS_TAILS:\n-                                        tails = streamLog.getTails(tailsRequest.getStreams());\n+                                    case STREAMS_TAILS:\n+                                        tails = streamLog.getTails(currentOp.getRequest()\n+                                                .getPayload()\n+                                                .getTailRequest()\n+                                                .getStreamList()\n+                                                .stream()\n+                                                .map(CorfuProtocolCommon::getUUID)\n+                                                .collect(Collectors.toList()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 303}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ4NjU3NA==", "bodyText": "Good catch. It seems like this should be ALL_STREAMS_TAIL. This should be a bug, not sure how the tests are not failing. On reconfiguration, the sequencer won't be configured unless LogUnitClient::getAllTails is called, and that won't construct a STREAMS_TAILS type.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555486574", "createdAt": "2021-01-12T03:25:18Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n                 } else {\n                     try {\n-                        switch (currOp.getType()) {\n+                        RequestPayloadMsg payload =  currentOp.getRequest().getPayload();\n+                        switch (currentOp.getType()) {\n                             case PREFIX_TRIM:\n-                                TrimRequest prefixTrim = (TrimRequest) currOp.getMsg().getPayload();\n-                                streamLog.prefixTrim(prefixTrim.getAddress().getSequence());\n+                                final long addr = payload.getTrimLogRequest().getAddress().getSequence();\n+                                streamLog.prefixTrim(addr);\n                                 break;\n                             case WRITE:\n-                                WriteRequest write = (WriteRequest) currOp.getMsg().getPayload();\n-                                Runnable append =\n-                                        () -> streamLog.append(write.getGlobalAddress(), (LogData) write.getData());\n+                                LogData logData = getLogData(payload.getWriteLogRequest().getLogData());\n+                                Runnable append = () -> streamLog.append(logData.getGlobalAddress(), logData);\n                                 recordRunnable(append, writeRecordsTimer);\n                                 break;\n                             case RANGE_WRITE:\n-                                RangeWriteMsg writeRange = (RangeWriteMsg) currOp.getMsg().getPayload();\n-                                Runnable appendMultiple = () -> streamLog.append(writeRange.getEntries());\n+                                List<LogData> range = payload.getRangeWriteLogRequest().getLogDataList()\n+                                        .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+                                Runnable appendMultiple = () -> streamLog.append(range);\n                                 recordRunnable(appendMultiple, writeRecordsTimer);\n                                 break;\n                             case RESET:\n                                 streamLog.reset();\n                                 break;\n                             case TAILS_QUERY:\n-                                TailsRequest tailsRequest = (TailsRequest)currOp.getMsg().getPayload();\n-                                TailsResponse tails;\n+                                final TailsResponse tails;\n \n-                                switch (tailsRequest.getReqType()) {\n-                                    case TailsRequest.LOG_TAIL:\n+                                switch (payload.getTailRequest().getReqType()) {\n+                                    case LOG_TAIL:\n                                         tails = new TailsResponse(streamLog.getLogTail());\n                                         break;\n-\n-                                    case TailsRequest.STREAMS_TAILS:\n-                                        tails = streamLog.getTails(tailsRequest.getStreams());\n+                                    case STREAMS_TAILS:\n+                                        tails = streamLog.getTails(currentOp.getRequest()\n+                                                .getPayload()\n+                                                .getTailRequest()\n+                                                .getStreamList()\n+                                                .stream()\n+                                                .map(CorfuProtocolCommon::getUUID)\n+                                                .collect(Collectors.toList()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY3NjI2NQ=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 303}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ4Njk1OA==", "bodyText": "I see. Its not failing because its hitting the default cause which returns all stream tails. I would recommend throwing an exception in the default case and explicitly specifying ALL_STREAMS_TAIL", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555486958", "createdAt": "2021-01-12T03:26:23Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n                 } else {\n                     try {\n-                        switch (currOp.getType()) {\n+                        RequestPayloadMsg payload =  currentOp.getRequest().getPayload();\n+                        switch (currentOp.getType()) {\n                             case PREFIX_TRIM:\n-                                TrimRequest prefixTrim = (TrimRequest) currOp.getMsg().getPayload();\n-                                streamLog.prefixTrim(prefixTrim.getAddress().getSequence());\n+                                final long addr = payload.getTrimLogRequest().getAddress().getSequence();\n+                                streamLog.prefixTrim(addr);\n                                 break;\n                             case WRITE:\n-                                WriteRequest write = (WriteRequest) currOp.getMsg().getPayload();\n-                                Runnable append =\n-                                        () -> streamLog.append(write.getGlobalAddress(), (LogData) write.getData());\n+                                LogData logData = getLogData(payload.getWriteLogRequest().getLogData());\n+                                Runnable append = () -> streamLog.append(logData.getGlobalAddress(), logData);\n                                 recordRunnable(append, writeRecordsTimer);\n                                 break;\n                             case RANGE_WRITE:\n-                                RangeWriteMsg writeRange = (RangeWriteMsg) currOp.getMsg().getPayload();\n-                                Runnable appendMultiple = () -> streamLog.append(writeRange.getEntries());\n+                                List<LogData> range = payload.getRangeWriteLogRequest().getLogDataList()\n+                                        .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+                                Runnable appendMultiple = () -> streamLog.append(range);\n                                 recordRunnable(appendMultiple, writeRecordsTimer);\n                                 break;\n                             case RESET:\n                                 streamLog.reset();\n                                 break;\n                             case TAILS_QUERY:\n-                                TailsRequest tailsRequest = (TailsRequest)currOp.getMsg().getPayload();\n-                                TailsResponse tails;\n+                                final TailsResponse tails;\n \n-                                switch (tailsRequest.getReqType()) {\n-                                    case TailsRequest.LOG_TAIL:\n+                                switch (payload.getTailRequest().getReqType()) {\n+                                    case LOG_TAIL:\n                                         tails = new TailsResponse(streamLog.getLogTail());\n                                         break;\n-\n-                                    case TailsRequest.STREAMS_TAILS:\n-                                        tails = streamLog.getTails(tailsRequest.getStreams());\n+                                    case STREAMS_TAILS:\n+                                        tails = streamLog.getTails(currentOp.getRequest()\n+                                                .getPayload()\n+                                                .getTailRequest()\n+                                                .getStreamList()\n+                                                .stream()\n+                                                .map(CorfuProtocolCommon::getUUID)\n+                                                .collect(Collectors.toList()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY3NjI2NQ=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 303}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkzMTc2NQ==", "bodyText": "I think that this means we can remove the STREAMS_TAILS case entirely, since this is the only place where it's referenced, and the client never sends this type of message.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555931765", "createdAt": "2021-01-12T17:04:12Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n                 } else {\n                     try {\n-                        switch (currOp.getType()) {\n+                        RequestPayloadMsg payload =  currentOp.getRequest().getPayload();\n+                        switch (currentOp.getType()) {\n                             case PREFIX_TRIM:\n-                                TrimRequest prefixTrim = (TrimRequest) currOp.getMsg().getPayload();\n-                                streamLog.prefixTrim(prefixTrim.getAddress().getSequence());\n+                                final long addr = payload.getTrimLogRequest().getAddress().getSequence();\n+                                streamLog.prefixTrim(addr);\n                                 break;\n                             case WRITE:\n-                                WriteRequest write = (WriteRequest) currOp.getMsg().getPayload();\n-                                Runnable append =\n-                                        () -> streamLog.append(write.getGlobalAddress(), (LogData) write.getData());\n+                                LogData logData = getLogData(payload.getWriteLogRequest().getLogData());\n+                                Runnable append = () -> streamLog.append(logData.getGlobalAddress(), logData);\n                                 recordRunnable(append, writeRecordsTimer);\n                                 break;\n                             case RANGE_WRITE:\n-                                RangeWriteMsg writeRange = (RangeWriteMsg) currOp.getMsg().getPayload();\n-                                Runnable appendMultiple = () -> streamLog.append(writeRange.getEntries());\n+                                List<LogData> range = payload.getRangeWriteLogRequest().getLogDataList()\n+                                        .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+                                Runnable appendMultiple = () -> streamLog.append(range);\n                                 recordRunnable(appendMultiple, writeRecordsTimer);\n                                 break;\n                             case RESET:\n                                 streamLog.reset();\n                                 break;\n                             case TAILS_QUERY:\n-                                TailsRequest tailsRequest = (TailsRequest)currOp.getMsg().getPayload();\n-                                TailsResponse tails;\n+                                final TailsResponse tails;\n \n-                                switch (tailsRequest.getReqType()) {\n-                                    case TailsRequest.LOG_TAIL:\n+                                switch (payload.getTailRequest().getReqType()) {\n+                                    case LOG_TAIL:\n                                         tails = new TailsResponse(streamLog.getLogTail());\n                                         break;\n-\n-                                    case TailsRequest.STREAMS_TAILS:\n-                                        tails = streamLog.getTails(tailsRequest.getStreams());\n+                                    case STREAMS_TAILS:\n+                                        tails = streamLog.getTails(currentOp.getRequest()\n+                                                .getPayload()\n+                                                .getTailRequest()\n+                                                .getStreamList()\n+                                                .stream()\n+                                                .map(CorfuProtocolCommon::getUUID)\n+                                                .collect(Collectors.toList()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY3NjI2NQ=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 303}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjcxNTY2MA==", "bodyText": "Removed STREAMS_TAILS and related codes, thanks!", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r556715660", "createdAt": "2021-01-13T17:48:57Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n                 } else {\n                     try {\n-                        switch (currOp.getType()) {\n+                        RequestPayloadMsg payload =  currentOp.getRequest().getPayload();\n+                        switch (currentOp.getType()) {\n                             case PREFIX_TRIM:\n-                                TrimRequest prefixTrim = (TrimRequest) currOp.getMsg().getPayload();\n-                                streamLog.prefixTrim(prefixTrim.getAddress().getSequence());\n+                                final long addr = payload.getTrimLogRequest().getAddress().getSequence();\n+                                streamLog.prefixTrim(addr);\n                                 break;\n                             case WRITE:\n-                                WriteRequest write = (WriteRequest) currOp.getMsg().getPayload();\n-                                Runnable append =\n-                                        () -> streamLog.append(write.getGlobalAddress(), (LogData) write.getData());\n+                                LogData logData = getLogData(payload.getWriteLogRequest().getLogData());\n+                                Runnable append = () -> streamLog.append(logData.getGlobalAddress(), logData);\n                                 recordRunnable(append, writeRecordsTimer);\n                                 break;\n                             case RANGE_WRITE:\n-                                RangeWriteMsg writeRange = (RangeWriteMsg) currOp.getMsg().getPayload();\n-                                Runnable appendMultiple = () -> streamLog.append(writeRange.getEntries());\n+                                List<LogData> range = payload.getRangeWriteLogRequest().getLogDataList()\n+                                        .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+                                Runnable appendMultiple = () -> streamLog.append(range);\n                                 recordRunnable(appendMultiple, writeRecordsTimer);\n                                 break;\n                             case RESET:\n                                 streamLog.reset();\n                                 break;\n                             case TAILS_QUERY:\n-                                TailsRequest tailsRequest = (TailsRequest)currOp.getMsg().getPayload();\n-                                TailsResponse tails;\n+                                final TailsResponse tails;\n \n-                                switch (tailsRequest.getReqType()) {\n-                                    case TailsRequest.LOG_TAIL:\n+                                switch (payload.getTailRequest().getReqType()) {\n+                                    case LOG_TAIL:\n                                         tails = new TailsResponse(streamLog.getLogTail());\n                                         break;\n-\n-                                    case TailsRequest.STREAMS_TAILS:\n-                                        tails = streamLog.getTails(tailsRequest.getStreams());\n+                                    case STREAMS_TAILS:\n+                                        tails = streamLog.getTails(currentOp.getRequest()\n+                                                .getPayload()\n+                                                .getTailRequest()\n+                                                .getStreamList()\n+                                                .stream()\n+                                                .map(CorfuProtocolCommon::getUUID)\n+                                                .collect(Collectors.toList()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY3NjI2NQ=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 303}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDYzNjQ1OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogDataSerializerUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNToxMDowM1rOIRZczQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxOTo0OTo0NFrOISR8gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTExMzY3Nw==", "bodyText": "nit: Since this method is switching over many types, will it better if we try to avoid using lots of if/else clauses? I thought the dispatcher pattern mentioned in this  post is a good alternative. https://stackoverflow.com/questions/29570767/switch-over-type-in-java\nIt will also make the code neater when we are adding more cases.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555113677", "createdAt": "2021-01-11T15:10:03Z", "author": {"login": "xcchang"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogDataSerializerUtils.java", "diffHunk": "@@ -0,0 +1,197 @@\n+package org.corfudb.protocols.wireprotocol;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.reflect.TypeToken;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * Utility class used by LogData to help serialize its contents.\n+ */\n+public class LogDataSerializerUtils {\n+    // Prevent class from being instantiated\n+    private LogDataSerializerUtils() {}\n+\n+    @FunctionalInterface\n+    interface PayloadConstructor<T> {\n+        T construct(ByteBuf buf);\n+    }\n+\n+    static ConcurrentHashMap<Class<?>, PayloadConstructor<?>> constructorMap = new ConcurrentHashMap<>(\n+            ImmutableMap.<Class<?>, PayloadConstructor<?>>builder()\n+                    .put(Byte.class, ByteBuf::readByte)\n+                    .put(Integer.class, ByteBuf::readInt)\n+                    .put(Long.class, ByteBuf::readLong)\n+                    .put(IMetadata.DataRank.class, x -> new IMetadata.DataRank(x.readLong(), new UUID(x.readLong(), x.readLong())))\n+                    .put(CheckpointEntry.CheckpointEntryType.class, x -> CheckpointEntry.CheckpointEntryType.typeMap.get(x.readByte()))\n+                    .put(Codec.Type.class, x -> Codec.getCodecTypeById(x.readInt()))\n+                    .put(UUID.class, x -> new UUID(x.readLong(), x.readLong()))\n+                    .put(byte[].class, x -> {\n+                        int length = x.readInt();\n+                        byte[] bytes = new byte[length];\n+                        x.readBytes(bytes);\n+                        return bytes;\n+                    })\n+                    .put(ByteBuf.class, x -> {\n+                        int bytes = x.readInt();\n+                        ByteBuf b = x.retainedSlice(x.readerIndex(), bytes);\n+                        x.readerIndex(x.readerIndex() + bytes);\n+                        return b;\n+                    })\n+                    .build()\n+    );\n+\n+    static ByteBuf byteBufFromBuffer(byte[] data) {\n+        ByteBuf buffer = Unpooled.wrappedBuffer(data);\n+        return fromBuffer(buffer, ByteBuf.class);\n+    }\n+\n+    /**\n+     * Build payload from Buffer\n+     *\n+     * @param buf The buffer to deserialize.\n+     * @param cls The class of the payload.\n+     * @param <T> The type of the payload.\n+     * @return payload\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <T> T fromBuffer(ByteBuf buf, Class<T> cls) {\n+        if (constructorMap.containsKey(cls)) {\n+            return (T) constructorMap.get(cls).construct(buf);\n+        } else if (cls.isEnum()) {\n+            // We only know how to deal with enums with a type map\n+            try {\n+                Map<Byte, T> typeMap = (Map<Byte, T>) cls.getDeclaredField(\"typeMap\").get(null);\n+                constructorMap.put(cls, x -> typeMap.get(x.readByte()));\n+                return (T) constructorMap.get(cls).construct(buf);\n+            } catch (NoSuchFieldException e) {\n+                throw new RuntimeException(\"Only enums with a typeMap are supported!\");\n+            } catch (IllegalAccessException e) {\n+                throw new RuntimeException(e);\n+            }\n+        } else {\n+            throw new RuntimeException(\"Unknown class \" + cls + \" for deserialization\");\n+        }\n+    }\n+\n+    /**\n+     * Build payload from Buffer.\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <T> T fromBuffer(ByteBuf buf, TypeToken<T> token) {\n+        Class<?> rawType = token.getRawType();\n+\n+        if (rawType.isAssignableFrom(Map.class)) {\n+            return (T) mapFromBuffer(\n+                    buf,\n+                    token.resolveType(Map.class.getTypeParameters()[0]).getRawType(),\n+                    token.resolveType(Map.class.getTypeParameters()[1]).getRawType()\n+            );\n+        }\n+\n+        return (T) fromBuffer(buf, rawType);\n+    }\n+\n+    /**\n+     * A really simple flat map implementation. The first entry is the size of the map as an int,\n+     * and the next entries are each key followed by its value.\n+     * Maps of maps are currently not supported.\n+     *\n+     * @param buf        The buffer to deserialize.\n+     * @param keyClass   The class of the keys.\n+     * @param valueClass The class of the values.\n+     * @param <K>        The type of the keys.\n+     * @param <V>        The type of the values.\n+     * @return Map\n+     */\n+    static <K, V> Map<K, V> mapFromBuffer(ByteBuf buf, Class<K> keyClass, Class<V> valueClass) {\n+        int numEntries = buf.readInt();\n+        ImmutableMap.Builder<K, V> builder = ImmutableMap.builder();\n+        for (int i = 0; i < numEntries; i++) {\n+            builder.put(fromBuffer(buf, keyClass), fromBuffer(buf, valueClass));\n+        }\n+        return builder.build();\n+    }\n+\n+    /**\n+     * A really simple flat map implementation. The first entry is the size of the map as an int,\n+     * and the next entries are each value.\n+     *\n+     * @param buf      The buffer to deserialize.\n+     * @param keyClass The class of the keys.\n+     * @param <K>      The type of the keys\n+     * @param <V>      The type of the values.\n+     * @return Map for use with enum type keys\n+     */\n+    static <K extends Enum<K> & ITypedEnum<K>, V> EnumMap<K, V> enumMapFromBuffer(\n+            ByteBuf buf, Class<K> keyClass) {\n+\n+        EnumMap<K, V> metadataMap = new EnumMap<>(keyClass);\n+        byte numEntries = buf.readByte();\n+        while (numEntries > 0 && buf.isReadable()) {\n+            K type = fromBuffer(buf, keyClass);\n+            V value = (V) fromBuffer(buf, type.getComponentType());\n+            metadataMap.put(type, value);\n+            numEntries--;\n+        }\n+        return metadataMap;\n+    }\n+\n+    /**\n+     * Serialize an object into a given byte buffer.\n+     *\n+     * @param buffer  The buffer to serialize it into.\n+     * @param payload The object to serialize.\n+     */\n+    static void serialize(ByteBuf buffer, Object payload) {\n+        if (payload instanceof Byte) {\n+            buffer.writeByte((Byte) payload);\n+        } else if (payload instanceof Long) {\n+            buffer.writeLong((Long) payload);\n+        } else if (payload instanceof byte[]) {\n+            buffer.writeInt(((byte[]) payload).length);\n+            buffer.writeBytes((byte[]) payload);\n+        } else if (payload instanceof UUID) {\n+            serialize(buffer, ((UUID) payload).getMostSignificantBits());\n+            serialize(buffer, ((UUID) payload).getLeastSignificantBits());\n+        } else if (payload instanceof EnumMap) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjAzOTI5Nw==", "bodyText": "We had an offline discussion and decide to keep the current implementation.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r556039297", "createdAt": "2021-01-12T19:49:44Z", "author": {"login": "xcchang"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogDataSerializerUtils.java", "diffHunk": "@@ -0,0 +1,197 @@\n+package org.corfudb.protocols.wireprotocol;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.reflect.TypeToken;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * Utility class used by LogData to help serialize its contents.\n+ */\n+public class LogDataSerializerUtils {\n+    // Prevent class from being instantiated\n+    private LogDataSerializerUtils() {}\n+\n+    @FunctionalInterface\n+    interface PayloadConstructor<T> {\n+        T construct(ByteBuf buf);\n+    }\n+\n+    static ConcurrentHashMap<Class<?>, PayloadConstructor<?>> constructorMap = new ConcurrentHashMap<>(\n+            ImmutableMap.<Class<?>, PayloadConstructor<?>>builder()\n+                    .put(Byte.class, ByteBuf::readByte)\n+                    .put(Integer.class, ByteBuf::readInt)\n+                    .put(Long.class, ByteBuf::readLong)\n+                    .put(IMetadata.DataRank.class, x -> new IMetadata.DataRank(x.readLong(), new UUID(x.readLong(), x.readLong())))\n+                    .put(CheckpointEntry.CheckpointEntryType.class, x -> CheckpointEntry.CheckpointEntryType.typeMap.get(x.readByte()))\n+                    .put(Codec.Type.class, x -> Codec.getCodecTypeById(x.readInt()))\n+                    .put(UUID.class, x -> new UUID(x.readLong(), x.readLong()))\n+                    .put(byte[].class, x -> {\n+                        int length = x.readInt();\n+                        byte[] bytes = new byte[length];\n+                        x.readBytes(bytes);\n+                        return bytes;\n+                    })\n+                    .put(ByteBuf.class, x -> {\n+                        int bytes = x.readInt();\n+                        ByteBuf b = x.retainedSlice(x.readerIndex(), bytes);\n+                        x.readerIndex(x.readerIndex() + bytes);\n+                        return b;\n+                    })\n+                    .build()\n+    );\n+\n+    static ByteBuf byteBufFromBuffer(byte[] data) {\n+        ByteBuf buffer = Unpooled.wrappedBuffer(data);\n+        return fromBuffer(buffer, ByteBuf.class);\n+    }\n+\n+    /**\n+     * Build payload from Buffer\n+     *\n+     * @param buf The buffer to deserialize.\n+     * @param cls The class of the payload.\n+     * @param <T> The type of the payload.\n+     * @return payload\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <T> T fromBuffer(ByteBuf buf, Class<T> cls) {\n+        if (constructorMap.containsKey(cls)) {\n+            return (T) constructorMap.get(cls).construct(buf);\n+        } else if (cls.isEnum()) {\n+            // We only know how to deal with enums with a type map\n+            try {\n+                Map<Byte, T> typeMap = (Map<Byte, T>) cls.getDeclaredField(\"typeMap\").get(null);\n+                constructorMap.put(cls, x -> typeMap.get(x.readByte()));\n+                return (T) constructorMap.get(cls).construct(buf);\n+            } catch (NoSuchFieldException e) {\n+                throw new RuntimeException(\"Only enums with a typeMap are supported!\");\n+            } catch (IllegalAccessException e) {\n+                throw new RuntimeException(e);\n+            }\n+        } else {\n+            throw new RuntimeException(\"Unknown class \" + cls + \" for deserialization\");\n+        }\n+    }\n+\n+    /**\n+     * Build payload from Buffer.\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <T> T fromBuffer(ByteBuf buf, TypeToken<T> token) {\n+        Class<?> rawType = token.getRawType();\n+\n+        if (rawType.isAssignableFrom(Map.class)) {\n+            return (T) mapFromBuffer(\n+                    buf,\n+                    token.resolveType(Map.class.getTypeParameters()[0]).getRawType(),\n+                    token.resolveType(Map.class.getTypeParameters()[1]).getRawType()\n+            );\n+        }\n+\n+        return (T) fromBuffer(buf, rawType);\n+    }\n+\n+    /**\n+     * A really simple flat map implementation. The first entry is the size of the map as an int,\n+     * and the next entries are each key followed by its value.\n+     * Maps of maps are currently not supported.\n+     *\n+     * @param buf        The buffer to deserialize.\n+     * @param keyClass   The class of the keys.\n+     * @param valueClass The class of the values.\n+     * @param <K>        The type of the keys.\n+     * @param <V>        The type of the values.\n+     * @return Map\n+     */\n+    static <K, V> Map<K, V> mapFromBuffer(ByteBuf buf, Class<K> keyClass, Class<V> valueClass) {\n+        int numEntries = buf.readInt();\n+        ImmutableMap.Builder<K, V> builder = ImmutableMap.builder();\n+        for (int i = 0; i < numEntries; i++) {\n+            builder.put(fromBuffer(buf, keyClass), fromBuffer(buf, valueClass));\n+        }\n+        return builder.build();\n+    }\n+\n+    /**\n+     * A really simple flat map implementation. The first entry is the size of the map as an int,\n+     * and the next entries are each value.\n+     *\n+     * @param buf      The buffer to deserialize.\n+     * @param keyClass The class of the keys.\n+     * @param <K>      The type of the keys\n+     * @param <V>      The type of the values.\n+     * @return Map for use with enum type keys\n+     */\n+    static <K extends Enum<K> & ITypedEnum<K>, V> EnumMap<K, V> enumMapFromBuffer(\n+            ByteBuf buf, Class<K> keyClass) {\n+\n+        EnumMap<K, V> metadataMap = new EnumMap<>(keyClass);\n+        byte numEntries = buf.readByte();\n+        while (numEntries > 0 && buf.isReadable()) {\n+            K type = fromBuffer(buf, keyClass);\n+            V value = (V) fromBuffer(buf, type.getComponentType());\n+            metadataMap.put(type, value);\n+            numEntries--;\n+        }\n+        return metadataMap;\n+    }\n+\n+    /**\n+     * Serialize an object into a given byte buffer.\n+     *\n+     * @param buffer  The buffer to serialize it into.\n+     * @param payload The object to serialize.\n+     */\n+    static void serialize(ByteBuf buffer, Object payload) {\n+        if (payload instanceof Byte) {\n+            buffer.writeByte((Byte) payload);\n+        } else if (payload instanceof Long) {\n+            buffer.writeLong((Long) payload);\n+        } else if (payload instanceof byte[]) {\n+            buffer.writeInt(((byte[]) payload).length);\n+            buffer.writeBytes((byte[]) payload);\n+        } else if (payload instanceof UUID) {\n+            serialize(buffer, ((UUID) payload).getMostSignificantBits());\n+            serialize(buffer, ((UUID) payload).getLeastSignificantBits());\n+        } else if (payload instanceof EnumMap) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTExMzY3Nw=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDc2MzM4OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/CorfuMsgType.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNTozNzo0MVrOIRaqCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDozMzo0NlrOIRsygw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEzMzQ0OA==", "bodyText": "I think the handleNoBootstrap in LayoutHandler could be removed now? but not sure is this a good time to remove this MsgType here since we may need to deprecate a lot of related methods then.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555133448", "createdAt": "2021-01-11T15:37:41Z", "author": {"login": "xcchang"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/CorfuMsgType.java", "diffHunk": "@@ -31,42 +31,6 @@\n     // Layout Messages\n     LAYOUT_NOBOOTSTRAP(19, TypeToken.of(CorfuMsg.class), true, false),\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzMDUzMQ==", "bodyText": "It might not worth the effort to remove this type at this time, might be better to remove when the LR is supported in Protobuf (i.e. at the time we don't need CorfuMsg at all)", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555430531", "createdAt": "2021-01-12T00:33:46Z", "author": {"login": "xcchang"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/CorfuMsgType.java", "diffHunk": "@@ -31,42 +31,6 @@\n     // Layout Messages\n     LAYOUT_NOBOOTSTRAP(19, TypeToken.of(CorfuMsg.class), true, false),\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEzMzQ0OA=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDkzMDk0OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNjowNzo0N1rOIRcYCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMTo1MzoxOFrOIRuldA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTE2MTYxMA==", "bodyText": "nit: Please align the indent for r here and the methods above in the javadoc.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555161610", "createdAt": "2021-01-11T16:07:47Z", "author": {"login": "xcchang"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "diffHunk": "@@ -45,233 +48,265 @@ public LogUnitClient getClient(long epoch, UUID clusterID) {\n      * The handler and handlers which implement this client.\n      */\n     @Getter\n-    public ClientMsgHandler msgHandler = new ClientMsgHandler(this)\n-            .generateHandlers(MethodHandles.lookup(), this);\n-\n-    /**\n-     * For old CorfuMsg, use {@link #msgHandler}\n-     * The handler and handlers which implement this client.\n-     */\n-    @Getter\n     public ClientResponseHandler responseHandler = new ClientResponseHandler(this)\n             .generateHandlers(MethodHandles.lookup(), this)\n             .generateErrorHandlers(MethodHandles.lookup(), this);\n \n     /**\n-     * Handle an WRITE_OK message.\n+     * Handle a write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @return True, since this indicates success.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.WRITE_OK)\n-    private static Object handleOk(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+    @ResponseHandler(type = PayloadCase.WRITE_LOG_RESPONSE)\n+    private static Object handleWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n         return true;\n     }\n \n     /**\n-     * Handle an ERROR_TRIMMED message.\n+     * Handle a range write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws TrimmedException if address has already been trimmed.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the range write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_TRIMMED)\n-    private static Object handleTrimmed(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new TrimmedException();\n+    @ResponseHandler(type = PayloadCase.RANGE_WRITE_LOG_RESPONSE)\n+    private static Object handleRangeWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle an ERROR_OVERWRITE message.\n+     * Handle a read log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OverwriteException Throws OverwriteException if address has already been written to.\n+     * @param msg The read log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return {@link ReadResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_OVERWRITE)\n-    private static Object handleOverwrite(CorfuPayloadMsg<Integer> msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new OverwriteException(OverwriteCause.fromId(msg.getPayload()));\n+    @ResponseHandler(type = PayloadCase.READ_LOG_RESPONSE)\n+    private static Object handleReadLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getReadResponse(msg.getPayload().getReadLogResponse());\n     }\n \n     /**\n-     * Handle an ERROR_DATA_OUTRANKED message.\n+     * Handle a inspect addresses response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OverwriteException Throws OverwriteException if write has been outranked.\n+     * @param msg The inspect addresses response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return {@link InspectAddressesResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_DATA_OUTRANKED)\n-    private static Object handleDataOutranked(CorfuMsg msg,\n-                                              ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new DataOutrankedException();\n+    @ResponseHandler(type = PayloadCase.INSPECT_ADDRESSES_RESPONSE)\n+    private static Object handleInspectResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getInspectAddressesResponse(msg.getPayload().getInspectAddressesResponse());\n     }\n \n+    /**\n+     * Handle a trim log response from the server.\n+     *\n+     * @param msg The trim log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the trim log was successful.\n+     */\n+    @ResponseHandler(type = PayloadCase.TRIM_LOG_RESPONSE)\n+    private static Object handleTrimLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n+    }\n \n     /**\n-     * Handle an ERROR_VALUE_ADOPTED message.\n+     * Handle a trim mark response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The trim mark response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return The trim_mark value.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_VALUE_ADOPTED)\n-    private static Object handleValueAdoptedResponse(CorfuPayloadMsg<ReadResponse> msg,\n-                                                     ChannelHandlerContext ctx, IClientRouter r) {\n-        throw new ValueAdoptedException(msg.getPayload());\n+    @ResponseHandler(type = PayloadCase.TRIM_MARK_RESPONSE)\n+    private static Object handleTrimMarkResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return msg.getPayload().getTrimMarkResponse().getTrimMark();\n     }\n \n     /**\n-     * Handle an ERROR_OOS message.\n+     * Handle a tail response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OutOfSpaceException Throws OutOfSpaceException if log unit out of space.\n+     * @param msg The tail response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return {@link TailsResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_OOS)\n-    private static Object handleOos(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new OutOfSpaceException();\n+    @ResponseHandler(type = PayloadCase.TAIL_RESPONSE)\n+    private static Object handleTailResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getTailsResponse(msg.getPayload().getTailResponse());\n     }\n \n     /**\n-     * Handle an ERROR_RANK message.\n+     * Handle a compact response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws Exception if write has been outranked.\n+     * @param msg The compact response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the compact was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_RANK)\n-    private static Object handleOutranked(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new Exception(\"rank\");\n+    @ResponseHandler(type = PayloadCase.COMPACT_RESPONSE)\n+    private static Object handleCompactResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle an ERROR_NOENTRY message.\n+     * Handle a flush cache response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws exception if write is performed to a non-existent entry.\n+     * @param msg The flush cache response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the flush was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_NOENTRY)\n-    private static Object handleNoEntry(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new Exception(\"Tried to write commit on a non-existent entry\");\n+    @ResponseHandler(type = PayloadCase.FLUSH_CACHE_RESPONSE)\n+    private static Object handleFlushCacheResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle a READ_RESPONSE message.\n+     * Handle a log address space response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The log address space response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return {@link StreamsAddressResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.READ_RESPONSE)\n-    private static Object handleReadResponse(CorfuPayloadMsg<ReadResponse> msg,\n-                                             ChannelHandlerContext ctx, IClientRouter r) {\n-        return msg.getPayload();\n+    @ResponseHandler(type = PayloadCase.LOG_ADDRESS_SPACE_RESPONSE)\n+    private static Object handleLogAddressSpaceResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        LogAddressSpaceResponseMsg responseMsg = msg.getPayload().getLogAddressSpaceResponse();\n+        return getStreamsAddressResponse(\n+                responseMsg.getLogTail(),\n+                responseMsg.getEpoch(),\n+                responseMsg.getAddressMapList()\n+        );\n     }\n \n     /**\n-     * Handle a ERROR_DATA_CORRUPTION message.\n+     * Handle a known address response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The known address space response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return The known_address value sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_DATA_CORRUPTION)\n-    private static Object handleReadDataCorruption(CorfuPayloadMsg<Long> msg,\n-                                                   ChannelHandlerContext ctx, IClientRouter r) {\n-        long read = msg.getPayload().longValue();\n-        throw new DataCorruptionException(String.format(\"Encountered corrupted data while reading %s\", read));\n+    @ResponseHandler(type = PayloadCase.KNOWN_ADDRESS_RESPONSE)\n+    private static Object handleKnownAddressResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getKnownAddressResponse(msg.getPayload().getKnownAddressResponse());\n     }\n \n     /**\n-     * Handle a INSPECT_ADDRESSES_RESPONSE message.\n+     * Handle a committed tail response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The committed tail response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return The committed_tail value sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.INSPECT_ADDRESSES_RESPONSE)\n-    private static Object handleInspectAddressResponse(CorfuPayloadMsg<InspectAddressesResponse> msg,\n-                                                       ChannelHandlerContext ctx, IClientRouter r) {\n-        return msg.getPayload();\n+    @ResponseHandler(type = PayloadCase.COMMITTED_TAIL_RESPONSE)\n+    private static Object handleCommittedTailResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return  msg.getPayload().getCommittedTailResponse().getCommittedTail();\n     }\n \n     /**\n-     * Handle a TAIL_RESPONSE message.\n+     * Handle a update committed tail response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The update committed tail response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the update committed tail was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.TAIL_RESPONSE)\n-    private static Object handleTailResponse(CorfuPayloadMsg<TailsResponse> msg,\n-                                             ChannelHandlerContext ctx, IClientRouter r) {\n-        return msg.getPayload();\n+    @ResponseHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_RESPONSE)\n+    private static Object handleUpdateCommittedTailResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle a LOG_ADDRESS_SPACE_RESPONSE message.\n+     * Handle a reset log unit response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The reset log unit response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the reset log unit was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE)\n-    private static Object handleStreamsAddressResponse(CorfuPayloadMsg<TailsResponse> msg,\n-                                             ChannelHandlerContext ctx, IClientRouter r) {\n-        return msg.getPayload();\n+    @ResponseHandler(type = PayloadCase.RESET_LOG_UNIT_RESPONSE)\n+    private static Object handleResetLogUnitResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 350}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1OTk1Ng==", "bodyText": "Done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555459956", "createdAt": "2021-01-12T01:53:18Z", "author": {"login": "xcchang"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "diffHunk": "@@ -45,233 +48,265 @@ public LogUnitClient getClient(long epoch, UUID clusterID) {\n      * The handler and handlers which implement this client.\n      */\n     @Getter\n-    public ClientMsgHandler msgHandler = new ClientMsgHandler(this)\n-            .generateHandlers(MethodHandles.lookup(), this);\n-\n-    /**\n-     * For old CorfuMsg, use {@link #msgHandler}\n-     * The handler and handlers which implement this client.\n-     */\n-    @Getter\n     public ClientResponseHandler responseHandler = new ClientResponseHandler(this)\n             .generateHandlers(MethodHandles.lookup(), this)\n             .generateErrorHandlers(MethodHandles.lookup(), this);\n \n     /**\n-     * Handle an WRITE_OK message.\n+     * Handle a write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @return True, since this indicates success.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.WRITE_OK)\n-    private static Object handleOk(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+    @ResponseHandler(type = PayloadCase.WRITE_LOG_RESPONSE)\n+    private static Object handleWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n         return true;\n     }\n \n     /**\n-     * Handle an ERROR_TRIMMED message.\n+     * Handle a range write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws TrimmedException if address has already been trimmed.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the range write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_TRIMMED)\n-    private static Object handleTrimmed(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new TrimmedException();\n+    @ResponseHandler(type = PayloadCase.RANGE_WRITE_LOG_RESPONSE)\n+    private static Object handleRangeWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle an ERROR_OVERWRITE message.\n+     * Handle a read log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OverwriteException Throws OverwriteException if address has already been written to.\n+     * @param msg The read log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return {@link ReadResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_OVERWRITE)\n-    private static Object handleOverwrite(CorfuPayloadMsg<Integer> msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new OverwriteException(OverwriteCause.fromId(msg.getPayload()));\n+    @ResponseHandler(type = PayloadCase.READ_LOG_RESPONSE)\n+    private static Object handleReadLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getReadResponse(msg.getPayload().getReadLogResponse());\n     }\n \n     /**\n-     * Handle an ERROR_DATA_OUTRANKED message.\n+     * Handle a inspect addresses response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OverwriteException Throws OverwriteException if write has been outranked.\n+     * @param msg The inspect addresses response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return {@link InspectAddressesResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_DATA_OUTRANKED)\n-    private static Object handleDataOutranked(CorfuMsg msg,\n-                                              ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new DataOutrankedException();\n+    @ResponseHandler(type = PayloadCase.INSPECT_ADDRESSES_RESPONSE)\n+    private static Object handleInspectResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getInspectAddressesResponse(msg.getPayload().getInspectAddressesResponse());\n     }\n \n+    /**\n+     * Handle a trim log response from the server.\n+     *\n+     * @param msg The trim log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the trim log was successful.\n+     */\n+    @ResponseHandler(type = PayloadCase.TRIM_LOG_RESPONSE)\n+    private static Object handleTrimLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n+    }\n \n     /**\n-     * Handle an ERROR_VALUE_ADOPTED message.\n+     * Handle a trim mark response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The trim mark response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return The trim_mark value.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_VALUE_ADOPTED)\n-    private static Object handleValueAdoptedResponse(CorfuPayloadMsg<ReadResponse> msg,\n-                                                     ChannelHandlerContext ctx, IClientRouter r) {\n-        throw new ValueAdoptedException(msg.getPayload());\n+    @ResponseHandler(type = PayloadCase.TRIM_MARK_RESPONSE)\n+    private static Object handleTrimMarkResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return msg.getPayload().getTrimMarkResponse().getTrimMark();\n     }\n \n     /**\n-     * Handle an ERROR_OOS message.\n+     * Handle a tail response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OutOfSpaceException Throws OutOfSpaceException if log unit out of space.\n+     * @param msg The tail response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return {@link TailsResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_OOS)\n-    private static Object handleOos(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new OutOfSpaceException();\n+    @ResponseHandler(type = PayloadCase.TAIL_RESPONSE)\n+    private static Object handleTailResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getTailsResponse(msg.getPayload().getTailResponse());\n     }\n \n     /**\n-     * Handle an ERROR_RANK message.\n+     * Handle a compact response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws Exception if write has been outranked.\n+     * @param msg The compact response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the compact was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_RANK)\n-    private static Object handleOutranked(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new Exception(\"rank\");\n+    @ResponseHandler(type = PayloadCase.COMPACT_RESPONSE)\n+    private static Object handleCompactResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle an ERROR_NOENTRY message.\n+     * Handle a flush cache response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws exception if write is performed to a non-existent entry.\n+     * @param msg The flush cache response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the flush was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_NOENTRY)\n-    private static Object handleNoEntry(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new Exception(\"Tried to write commit on a non-existent entry\");\n+    @ResponseHandler(type = PayloadCase.FLUSH_CACHE_RESPONSE)\n+    private static Object handleFlushCacheResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle a READ_RESPONSE message.\n+     * Handle a log address space response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The log address space response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return {@link StreamsAddressResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.READ_RESPONSE)\n-    private static Object handleReadResponse(CorfuPayloadMsg<ReadResponse> msg,\n-                                             ChannelHandlerContext ctx, IClientRouter r) {\n-        return msg.getPayload();\n+    @ResponseHandler(type = PayloadCase.LOG_ADDRESS_SPACE_RESPONSE)\n+    private static Object handleLogAddressSpaceResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        LogAddressSpaceResponseMsg responseMsg = msg.getPayload().getLogAddressSpaceResponse();\n+        return getStreamsAddressResponse(\n+                responseMsg.getLogTail(),\n+                responseMsg.getEpoch(),\n+                responseMsg.getAddressMapList()\n+        );\n     }\n \n     /**\n-     * Handle a ERROR_DATA_CORRUPTION message.\n+     * Handle a known address response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The known address space response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return The known_address value sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_DATA_CORRUPTION)\n-    private static Object handleReadDataCorruption(CorfuPayloadMsg<Long> msg,\n-                                                   ChannelHandlerContext ctx, IClientRouter r) {\n-        long read = msg.getPayload().longValue();\n-        throw new DataCorruptionException(String.format(\"Encountered corrupted data while reading %s\", read));\n+    @ResponseHandler(type = PayloadCase.KNOWN_ADDRESS_RESPONSE)\n+    private static Object handleKnownAddressResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getKnownAddressResponse(msg.getPayload().getKnownAddressResponse());\n     }\n \n     /**\n-     * Handle a INSPECT_ADDRESSES_RESPONSE message.\n+     * Handle a committed tail response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The committed tail response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return The committed_tail value sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.INSPECT_ADDRESSES_RESPONSE)\n-    private static Object handleInspectAddressResponse(CorfuPayloadMsg<InspectAddressesResponse> msg,\n-                                                       ChannelHandlerContext ctx, IClientRouter r) {\n-        return msg.getPayload();\n+    @ResponseHandler(type = PayloadCase.COMMITTED_TAIL_RESPONSE)\n+    private static Object handleCommittedTailResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return  msg.getPayload().getCommittedTailResponse().getCommittedTail();\n     }\n \n     /**\n-     * Handle a TAIL_RESPONSE message.\n+     * Handle a update committed tail response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The update committed tail response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the update committed tail was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.TAIL_RESPONSE)\n-    private static Object handleTailResponse(CorfuPayloadMsg<TailsResponse> msg,\n-                                             ChannelHandlerContext ctx, IClientRouter r) {\n-        return msg.getPayload();\n+    @ResponseHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_RESPONSE)\n+    private static Object handleUpdateCommittedTailResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle a LOG_ADDRESS_SPACE_RESPONSE message.\n+     * Handle a reset log unit response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n+     * @param msg The reset log unit response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r A reference to the router.\n+     * @return Always True, since the reset log unit was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE)\n-    private static Object handleStreamsAddressResponse(CorfuPayloadMsg<TailsResponse> msg,\n-                                             ChannelHandlerContext ctx, IClientRouter r) {\n-        return msg.getPayload();\n+    @ResponseHandler(type = PayloadCase.RESET_LOG_UNIT_RESPONSE)\n+    private static Object handleResetLogUnitResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTE2MTYxMA=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 350}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NDk1MjM2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/test/java/org/corfudb/infrastructure/LogUnitServerTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNjoxMjo0NFrOIRclfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMTo1MzowOVrOIRulQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTE2NTA1NA==", "bodyText": "nit: Adding an empty line between the description and params? Same for the other methods in this file I thought.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555165054", "createdAt": "2021-01-11T16:12:44Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/LogUnitServerTest.java", "diffHunk": "@@ -0,0 +1,814 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.util.concurrent.MoreExecutors;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import io.netty.channel.ChannelHandlerContext;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.stream.LongStream;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.infrastructure.log.StreamLogCompaction;\n+import org.corfudb.infrastructure.LogUnitServer.LogUnitServerConfig;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.IMetadata;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.ReadResponse;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.DataCorruptionException;\n+import org.corfudb.runtime.exceptions.DataOutrankedException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.proto.service.CorfuMessage.HeaderMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.PriorityLevel;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.ResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailRequestMsg;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.runtime.view.stream.StreamAddressSpace;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+import org.roaringbitmap.longlong.Roaring64NavigableMap;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getStreamsAddressResponse;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getCommittedTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getCompactRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getFlushCacheRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getInspectAddressesRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getKnownAddressRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getReadLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getReadResponse;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailsResponse;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimMarkRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getUpdateCommittedTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyInt;\n+import static org.mockito.ArgumentMatchers.anyString;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.never;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+\n+@Slf4j\n+public class LogUnitServerTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+\n+    // The LogUnitServer instance used for testing.\n+    private LogUnitServer logUnitServer;\n+\n+    // Objects that need to be mocked.\n+    private ServerContext mServerContext;\n+    private IServerRouter mServerRouter;\n+    private ChannelHandlerContext mChannelHandlerContext;\n+    private BatchProcessor mBatchProcessor;\n+    private StreamLog mStreamLog;\n+    private LogUnitServerCache mCache;\n+\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final String PAYLOAD_DATA = \"PAYLOAD\";\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values.\n+     * @param ignoreClusterId   indicates if the message is clusterId aware\n+     * @param ignoreEpoch       indicates if the message is epoch aware\n+     * @return                  the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getBasicHeader(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, 1L,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1OTkwNg==", "bodyText": "Done", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555459906", "createdAt": "2021-01-12T01:53:09Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/test/java/org/corfudb/infrastructure/LogUnitServerTest.java", "diffHunk": "@@ -0,0 +1,814 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.util.concurrent.MoreExecutors;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import io.netty.channel.ChannelHandlerContext;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.stream.LongStream;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.log.StreamLog;\n+import org.corfudb.infrastructure.log.StreamLogCompaction;\n+import org.corfudb.infrastructure.LogUnitServer.LogUnitServerConfig;\n+import org.corfudb.protocols.wireprotocol.DataType;\n+import org.corfudb.protocols.wireprotocol.IMetadata;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.ReadResponse;\n+import org.corfudb.protocols.wireprotocol.StreamsAddressResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.exceptions.DataCorruptionException;\n+import org.corfudb.runtime.exceptions.DataOutrankedException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.proto.service.CorfuMessage.HeaderMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.PriorityLevel;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.ResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailRequestMsg;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.runtime.view.stream.StreamAddressSpace;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+import org.roaringbitmap.longlong.Roaring64NavigableMap;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.DEFAULT_UUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getStreamsAddressResponse;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getCommittedTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getCompactRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getFlushCacheRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getInspectAddressesRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getKnownAddressRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getLogAddressSpaceRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getRangeWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getReadLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getReadResponse;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getResetLogUnitRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTailsResponse;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getTrimMarkRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getUpdateCommittedTailRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolLogUnit.getWriteLogRequestMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getHeaderMsg;\n+import static org.corfudb.protocols.service.CorfuProtocolMessage.getRequestMsg;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyInt;\n+import static org.mockito.ArgumentMatchers.anyString;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.never;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+\n+@Slf4j\n+public class LogUnitServerTest {\n+\n+    @Rule\n+    public MockitoRule mockito = MockitoJUnit.rule();\n+\n+    // The LogUnitServer instance used for testing.\n+    private LogUnitServer logUnitServer;\n+\n+    // Objects that need to be mocked.\n+    private ServerContext mServerContext;\n+    private IServerRouter mServerRouter;\n+    private ChannelHandlerContext mChannelHandlerContext;\n+    private BatchProcessor mBatchProcessor;\n+    private StreamLog mStreamLog;\n+    private LogUnitServerCache mCache;\n+\n+    private final AtomicInteger requestCounter = new AtomicInteger();\n+    private final String PAYLOAD_DATA = \"PAYLOAD\";\n+\n+    /**\n+     * A helper method that creates a basic message header populated\n+     * with default values.\n+     * @param ignoreClusterId   indicates if the message is clusterId aware\n+     * @param ignoreEpoch       indicates if the message is epoch aware\n+     * @return                  the corresponding HeaderMsg\n+     */\n+    private HeaderMsg getBasicHeader(boolean ignoreClusterId, boolean ignoreEpoch) {\n+        return getHeaderMsg(requestCounter.incrementAndGet(), PriorityLevel.NORMAL, 1L,\n+                getUuidMsg(DEFAULT_UUID), getUuidMsg(DEFAULT_UUID), ignoreClusterId, ignoreEpoch);\n+    }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTE2NTA1NA=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 114}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjU3MDQ2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQyMzo1OTo0NVrOIRr4Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQyMjoyNzoxM1rOIXV-xA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQxNTU2Mw==", "bodyText": "This loop is really messy and probably should be improved in another PR.\nThe performance of this loop can be improved by using ArrayList instead of LinkedList. It produces less garbage and should reduce gc pressure.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555415563", "createdAt": "2021-01-11T23:59:45Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQxNjE5OQ==", "bodyText": "numProcessed can also be removed and replaced with list.size()", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555416199", "createdAt": "2021-01-12T00:01:38Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQxNTU2Mw=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTM0ODI5Mg==", "bodyText": "I've replaced the LinkedList by an ArrayList and have removed numProcessed.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r561348292", "createdAt": "2021-01-20T22:27:13Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQxNTU2Mw=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 197}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjU5MjU3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDowOTozMlrOIRsElg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDoxMDozN1rOIRsF_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQxODc3NA==", "bodyText": "I think we can remove BatchWriterOperation.Type since all the message types map to an operation in this processor, except for shutdown, which can be encoded as a variable instead of a message in the work queue.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555418774", "createdAt": "2021-01-12T00:09:32Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQxOTEzMg==", "bodyText": "Then you can check and map the message type directly. For example, if (currentOp.getRequest().getPayload().hasSealRequest())", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555419132", "createdAt": "2021-01-12T00:10:37Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQxODc3NA=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 235}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjYxNDcxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDoxNDo1OVrOIRsSgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQyMjoyNzo1MVrOIXWAOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQyMjMzNg==", "bodyText": "The point of batch writing is to amortize the cost of the fsync, but in this case the request is rejected and doesn't produce any io and thus shouldn't contribute to the batch size.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555422336", "createdAt": "2021-01-12T00:14:59Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTM0ODY2NQ==", "bodyText": "Done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r561348665", "createdAt": "2021-01-20T22:27:51Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQyMjMzNg=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 251}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjYzODgzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDoyMDoyMFrOIRsh7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDoyMDoyMFrOIRsh7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQyNjI4Nw==", "bodyText": "Can WriteLogRequestMsg and RangeWriteLogRequestMsg be collapsed ?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555426287", "createdAt": "2021-01-12T00:20:20Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n                 } else {\n                     try {\n-                        switch (currOp.getType()) {\n+                        RequestPayloadMsg payload =  currentOp.getRequest().getPayload();\n+                        switch (currentOp.getType()) {\n                             case PREFIX_TRIM:\n-                                TrimRequest prefixTrim = (TrimRequest) currOp.getMsg().getPayload();\n-                                streamLog.prefixTrim(prefixTrim.getAddress().getSequence());\n+                                final long addr = payload.getTrimLogRequest().getAddress().getSequence();\n+                                streamLog.prefixTrim(addr);\n                                 break;\n                             case WRITE:\n-                                WriteRequest write = (WriteRequest) currOp.getMsg().getPayload();\n-                                Runnable append =\n-                                        () -> streamLog.append(write.getGlobalAddress(), (LogData) write.getData());\n+                                LogData logData = getLogData(payload.getWriteLogRequest().getLogData());\n+                                Runnable append = () -> streamLog.append(logData.getGlobalAddress(), logData);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 268}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjY0OTEzOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDoyNToxMFrOIRsnww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQyMzo1OTowOVrOISaOSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQyNzc3OQ==", "bodyText": "A WriteRequest is constructed, but its not being used when the message is sent. I would recommend eliminating that type and directly using the LogData object.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555427779", "createdAt": "2021-01-12T00:25:10Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitClient.java", "diffHunk": "@@ -90,7 +94,9 @@ public Integer getPort() {\n         wr.setRank(rank);\n         wr.setBackpointerMap(backpointerMap);\n         wr.setGlobalAddress(address);\n-        CompletableFuture<Boolean> cf = sendMessageWithFuture(CorfuMsgType.WRITE.payloadMsg(wr));\n+        CompletableFuture<Boolean> cf = sendRequestWithFuture(\n+                getWriteLogRequestMsg((LogData) wr.getData()), false, false);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjE3NDkyMg==", "bodyText": "Done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r556174922", "createdAt": "2021-01-12T23:59:09Z", "author": {"login": "zfrenette"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitClient.java", "diffHunk": "@@ -90,7 +94,9 @@ public Integer getPort() {\n         wr.setRank(rank);\n         wr.setBackpointerMap(backpointerMap);\n         wr.setGlobalAddress(address);\n-        CompletableFuture<Boolean> cf = sendMessageWithFuture(CorfuMsgType.WRITE.payloadMsg(wr));\n+        CompletableFuture<Boolean> cf = sendRequestWithFuture(\n+                getWriteLogRequestMsg((LogData) wr.getData()), false, false);\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQyNzc3OQ=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjY2NTY0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDozMjo0NlrOIRsxTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDozMzozMVrOIRsyJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzMDIyMw==", "bodyText": "Error handling logic here is not correct. If an exception happens within a batch then all requests should be errored out because the write/fsync won't guarantee any boundaries.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555430223", "createdAt": "2021-01-12T00:32:46Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n                 } else {\n                     try {\n-                        switch (currOp.getType()) {\n+                        RequestPayloadMsg payload =  currentOp.getRequest().getPayload();\n+                        switch (currentOp.getType()) {\n                             case PREFIX_TRIM:\n-                                TrimRequest prefixTrim = (TrimRequest) currOp.getMsg().getPayload();\n-                                streamLog.prefixTrim(prefixTrim.getAddress().getSequence());\n+                                final long addr = payload.getTrimLogRequest().getAddress().getSequence();\n+                                streamLog.prefixTrim(addr);\n                                 break;\n                             case WRITE:\n-                                WriteRequest write = (WriteRequest) currOp.getMsg().getPayload();\n-                                Runnable append =\n-                                        () -> streamLog.append(write.getGlobalAddress(), (LogData) write.getData());\n+                                LogData logData = getLogData(payload.getWriteLogRequest().getLogData());\n+                                Runnable append = () -> streamLog.append(logData.getGlobalAddress(), logData);\n                                 recordRunnable(append, writeRecordsTimer);\n                                 break;\n                             case RANGE_WRITE:\n-                                RangeWriteMsg writeRange = (RangeWriteMsg) currOp.getMsg().getPayload();\n-                                Runnable appendMultiple = () -> streamLog.append(writeRange.getEntries());\n+                                List<LogData> range = payload.getRangeWriteLogRequest().getLogDataList()\n+                                        .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+                                Runnable appendMultiple = () -> streamLog.append(range);\n                                 recordRunnable(appendMultiple, writeRecordsTimer);\n                                 break;\n                             case RESET:\n                                 streamLog.reset();\n                                 break;\n                             case TAILS_QUERY:\n-                                TailsRequest tailsRequest = (TailsRequest)currOp.getMsg().getPayload();\n-                                TailsResponse tails;\n+                                final TailsResponse tails;\n \n-                                switch (tailsRequest.getReqType()) {\n-                                    case TailsRequest.LOG_TAIL:\n+                                switch (payload.getTailRequest().getReqType()) {\n+                                    case LOG_TAIL:\n                                         tails = new TailsResponse(streamLog.getLogTail());\n                                         break;\n-\n-                                    case TailsRequest.STREAMS_TAILS:\n-                                        tails = streamLog.getTails(tailsRequest.getStreams());\n+                                    case STREAMS_TAILS:\n+                                        tails = streamLog.getTails(currentOp.getRequest()\n+                                                .getPayload()\n+                                                .getTailRequest()\n+                                                .getStreamList()\n+                                                .stream()\n+                                                .map(CorfuProtocolCommon::getUUID)\n+                                                .collect(Collectors.toList()));\n                                         break;\n-\n                                     default:\n                                         tails = streamLog.getAllTails();\n                                         break;\n                                 }\n \n                                 tails.setEpoch(sealEpoch);\n-                                currOp.setResultValue(tails);\n+                                currentOp.setResultValue(tails);\n                                 break;\n                             case LOG_ADDRESS_SPACE_QUERY:\n                                 // Retrieve the address space for every stream in the log.\n                                 StreamsAddressResponse resp = streamLog.getStreamsAddressSpace();\n                                 resp.setEpoch(sealEpoch);\n-                                currOp.setResultValue(resp);\n+                                currentOp.setResultValue(resp);\n                                 break;\n                             default:\n-                                log.warn(\"Unknown BatchWriterOperation {}\", currOp);\n+                                log.warn(\"batchWriteProcessor: unknown operation {}\", currentOp);\n                         }\n                     } catch (Exception e) {\n-                        log.error(\"Stream log error. Batch [queue size={}]. StreamLog: [trim mark: {}].\",\n-                                operationsQueue.size(), streamLog.getTrimMark(), e);\n-                        currOp.getFutureResult().completeExceptionally(e);\n+                        log.error(\"batchWriteProcessor: stream log error. Batch: [queue size={}]. \" +\n+                                \"StreamLog: [trim mark={}].\", operationsQueue.size(), streamLog.getTrimMark(), e);\n+\n+                        currentOp.getFutureResult().completeExceptionally(e);\n                     }\n-                    res.add(currOp);\n \n-                    processed++;\n-                    lastOp = currOp;\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 341}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzMDQzNg==", "bodyText": "Actually, IO errors are fatal in this cause and the whole LogUnit should be re-initialized.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555430436", "createdAt": "2021-01-12T00:33:31Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -114,127 +102,152 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n             List<BatchWriterOperation> res = new LinkedList<>();\n+            int numProcessed = 0;\n \n             while (true) {\n-                BatchWriterOperation currOp;\n+                BatchWriterOperation currentOp;\n                 queueSizeDist.ifPresent(dist -> dist.record(operationsQueue.size()));\n+\n                 if (lastOp == null) {\n-                    currOp = operationsQueue.take();\n+                    currentOp = operationsQueue.take();\n                 } else {\n-                    currOp = operationsQueue.poll();\n+                    currentOp = operationsQueue.poll();\n \n-                    if (currOp == null || processed == BATCH_SIZE\n-                            || currOp == BatchWriterOperation.SHUTDOWN) {\n+                    if (currentOp == null || numProcessed == BATCH_SIZE || currentOp == BatchWriterOperation.SHUTDOWN) {\n                         streamLog.sync(sync);\n-                        log.trace(\"Completed {} operations\", processed);\n-\n-                        for (BatchWriterOperation operation : res) {\n-                            if (!operation.getFutureResult().isCompletedExceptionally()\n-                            && !operation.getFutureResult().isCancelled()) {\n-                                // At this point we need to complete the requests\n-                                // that completed successfully (i.e. haven't failed)\n-                                operation.getFutureResult().complete(operation.getResultValue());\n+                        if (log.isTraceEnabled()) {\n+                            log.trace(\"batchWriteProcessor: completed {} operations\", numProcessed);\n+                        }\n+                        // At this point we need to complete the requests\n+                        // that completed successfully (i.e. haven't failed)\n+                        for (BatchWriterOperation op : res) {\n+                            if (!op.getFutureResult().isCompletedExceptionally()\n+                                    && !op.getFutureResult().isCancelled()) {\n+                                op.getFutureResult().complete(op.getResultValue());\n                             }\n                         }\n+\n                         res.clear();\n-                        processed = 0;\n+                        numProcessed = 0;\n                     }\n                 }\n \n-                if (currOp == null) {\n+                if (currentOp == null) {\n                     lastOp = null;\n-                } else if (currOp == BatchWriterOperation.SHUTDOWN) {\n-                    log.warn(\"Shutting down the write processor\");\n+                } else if (currentOp == BatchWriterOperation.SHUTDOWN) {\n+                    log.warn(\"batchWriteProcessor: shutting down the write processor\");\n                     streamLog.sync(true);\n                     break;\n-                } else if (streamLog.quotaExceeded() && currOp.getMsg().getPriorityLevel() != PriorityLevel.HIGH) {\n-                    currOp.getFutureResult().completeExceptionally(\n-                            new QuotaExceededException(\"Quota of \"\n-                                    + streamLog.quotaLimitInBytes() + \" bytes\"));\n-                    log.warn(\"batchprocessor: quota exceeded, dropping msg {}\", currOp.getMsg());\n-                } else if (currOp.getType() == Type.SEAL && currOp.getMsg().getEpoch() >= sealEpoch) {\n-                    log.info(\"batchWriteProcessor: updating from {} to {}\", sealEpoch, currOp.getMsg().getEpoch());\n-                    sealEpoch = currOp.getMsg().getEpoch();\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n-                } else if (currOp.getMsg().getEpoch() != sealEpoch) {\n-                    log.warn(\"batchWriteProcessor: wrong epoch on {} msg, seal epoch is {}, and msg epoch is {}\",\n-                            currOp.getType(), sealEpoch, currOp.getMsg().getEpoch());\n-                    currOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n-                    res.add(currOp);\n-                    processed++;\n-                    lastOp = currOp;\n+                } else if (streamLog.quotaExceeded() &&\n+                        (currentOp.getRequest().getHeader().getPriority() != PriorityLevel.HIGH)) {\n+                    currentOp.getFutureResult().completeExceptionally(\n+                            new QuotaExceededException(\"Quota of \" + streamLog.quotaLimitInBytes() + \" bytes\"));\n+\n+                    log.warn(\"batchWriteProcessor: quota exceeded, dropping request {}\",\n+                            TextFormat.shortDebugString(currentOp.getRequest()));\n+                } else if (currentOp.getType() == BatchWriterOperation.Type.SEAL &&\n+                        (currentOp.getRequest().getPayload().getSealRequest().getEpoch() >= sealEpoch)) {\n+                    log.info(\"batchWriteProcessor: updating epoch from {} to {}\",\n+                            sealEpoch, currentOp.getRequest().getPayload().getSealRequest().getEpoch());\n+\n+                    sealEpoch = currentOp.getRequest().getPayload().getSealRequest().getEpoch();\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n+                } else if (currentOp.getRequest().getHeader().getEpoch() != sealEpoch) {\n+                    log.warn(\"batchWriteProcessor: wrong epoch on {} request, seal epoch is {}, and request epoch is {}\",\n+                            currentOp.getType(), sealEpoch, currentOp.getRequest().getHeader().getEpoch());\n+\n+                    currentOp.getFutureResult().completeExceptionally(new WrongEpochException(sealEpoch));\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;\n                 } else {\n                     try {\n-                        switch (currOp.getType()) {\n+                        RequestPayloadMsg payload =  currentOp.getRequest().getPayload();\n+                        switch (currentOp.getType()) {\n                             case PREFIX_TRIM:\n-                                TrimRequest prefixTrim = (TrimRequest) currOp.getMsg().getPayload();\n-                                streamLog.prefixTrim(prefixTrim.getAddress().getSequence());\n+                                final long addr = payload.getTrimLogRequest().getAddress().getSequence();\n+                                streamLog.prefixTrim(addr);\n                                 break;\n                             case WRITE:\n-                                WriteRequest write = (WriteRequest) currOp.getMsg().getPayload();\n-                                Runnable append =\n-                                        () -> streamLog.append(write.getGlobalAddress(), (LogData) write.getData());\n+                                LogData logData = getLogData(payload.getWriteLogRequest().getLogData());\n+                                Runnable append = () -> streamLog.append(logData.getGlobalAddress(), logData);\n                                 recordRunnable(append, writeRecordsTimer);\n                                 break;\n                             case RANGE_WRITE:\n-                                RangeWriteMsg writeRange = (RangeWriteMsg) currOp.getMsg().getPayload();\n-                                Runnable appendMultiple = () -> streamLog.append(writeRange.getEntries());\n+                                List<LogData> range = payload.getRangeWriteLogRequest().getLogDataList()\n+                                        .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+                                Runnable appendMultiple = () -> streamLog.append(range);\n                                 recordRunnable(appendMultiple, writeRecordsTimer);\n                                 break;\n                             case RESET:\n                                 streamLog.reset();\n                                 break;\n                             case TAILS_QUERY:\n-                                TailsRequest tailsRequest = (TailsRequest)currOp.getMsg().getPayload();\n-                                TailsResponse tails;\n+                                final TailsResponse tails;\n \n-                                switch (tailsRequest.getReqType()) {\n-                                    case TailsRequest.LOG_TAIL:\n+                                switch (payload.getTailRequest().getReqType()) {\n+                                    case LOG_TAIL:\n                                         tails = new TailsResponse(streamLog.getLogTail());\n                                         break;\n-\n-                                    case TailsRequest.STREAMS_TAILS:\n-                                        tails = streamLog.getTails(tailsRequest.getStreams());\n+                                    case STREAMS_TAILS:\n+                                        tails = streamLog.getTails(currentOp.getRequest()\n+                                                .getPayload()\n+                                                .getTailRequest()\n+                                                .getStreamList()\n+                                                .stream()\n+                                                .map(CorfuProtocolCommon::getUUID)\n+                                                .collect(Collectors.toList()));\n                                         break;\n-\n                                     default:\n                                         tails = streamLog.getAllTails();\n                                         break;\n                                 }\n \n                                 tails.setEpoch(sealEpoch);\n-                                currOp.setResultValue(tails);\n+                                currentOp.setResultValue(tails);\n                                 break;\n                             case LOG_ADDRESS_SPACE_QUERY:\n                                 // Retrieve the address space for every stream in the log.\n                                 StreamsAddressResponse resp = streamLog.getStreamsAddressSpace();\n                                 resp.setEpoch(sealEpoch);\n-                                currOp.setResultValue(resp);\n+                                currentOp.setResultValue(resp);\n                                 break;\n                             default:\n-                                log.warn(\"Unknown BatchWriterOperation {}\", currOp);\n+                                log.warn(\"batchWriteProcessor: unknown operation {}\", currentOp);\n                         }\n                     } catch (Exception e) {\n-                        log.error(\"Stream log error. Batch [queue size={}]. StreamLog: [trim mark: {}].\",\n-                                operationsQueue.size(), streamLog.getTrimMark(), e);\n-                        currOp.getFutureResult().completeExceptionally(e);\n+                        log.error(\"batchWriteProcessor: stream log error. Batch: [queue size={}]. \" +\n+                                \"StreamLog: [trim mark={}].\", operationsQueue.size(), streamLog.getTrimMark(), e);\n+\n+                        currentOp.getFutureResult().completeExceptionally(e);\n                     }\n-                    res.add(currOp);\n \n-                    processed++;\n-                    lastOp = currOp;\n+                    res.add(currentOp);\n+                    numProcessed++;\n+                    lastOp = currentOp;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzMDIyMw=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 341}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjcwMDM2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDo0ODoyNFrOIRtFLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDo0ODoyNFrOIRtFLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzNTMwOQ==", "bodyText": "the naming can be improved here, consider renaming it to buildInMemoryStreamLog", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555435309", "createdAt": "2021-01-12T00:48:24Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -550,10 +596,41 @@ public static LogUnitServerConfig parse(Map<String, Object> opts) {\n             return LogUnitServerConfig.builder()\n                     .cacheSizeHeapRatio(cacheSizeHeapRatio)\n                     .maxCacheSize((long) (Runtime.getRuntime().maxMemory() * cacheSizeHeapRatio))\n-                    .memoryMode(Boolean.valueOf(opts.get(\"--memory\").toString()))\n+                    .memoryMode(Boolean.parseBoolean(opts.get(\"--memory\").toString()))\n                     .noVerify((Boolean) opts.get(\"--no-verify\"))\n                     .noSync((Boolean) opts.get(\"--no-sync\"))\n                     .build();\n         }\n     }\n+\n+    /**\n+     * Utility class used by the LogUnit server to initialize its components,\n+     * including the StreamLog, LogUnitServerCache, BatchProcessor and StreamLogCompaction.\n+     * This facilitates the injection of mocked objects during unit tests.\n+     */\n+    public static class LogUnitServerInitializer {\n+        StreamLog buildStreamLog() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 742}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjcxMTQ1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDo1Mzo1NFrOIRtLvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMDo1Mzo1NFrOIRtLvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzNjk4OQ==", "bodyText": "This is incorrect. You can get receive a message on epoch 1, then by the time you reply the server is on epoch 2. The client should be able to detect that. The message can be queued internally while the epoch of the router changes.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555436989", "createdAt": "2021-01-12T00:53:54Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -158,15 +165,19 @@ protected void processRequest(RequestMsg req, ChannelHandlerContext ctx, IServer\n     /**\n      * Service an incoming request for maximum global address the log unit server has written.\n      */\n-    @ServerHandler(type = CorfuMsgType.TAIL_REQUEST)\n-    public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.debug(\"handleTailRequest: received a tail request {}\", msg);\n-        batchWriter.<TailsResponse>addTask(TAILS_QUERY, msg)\n-                .thenAccept(tailsResp -> {\n-                    r.sendResponse(ctx, msg, CorfuMsgType.TAIL_RESPONSE.payloadMsg(tailsResp));\n-                })\n+    @RequestHandler(type = PayloadCase.TAIL_REQUEST)\n+    public void handleTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.debug(\"handleTailRequest[{}]: received a tail request {}\",\n+                req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+\n+        batchWriter.<TailsResponse>addTask(BatchWriterOperation.Type.TAILS_QUERY, req)\n+                .thenAccept(tailsResp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 201}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NjcyNzkzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMTowMjowMlrOIRtVfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxNTozOTo1OVrOIWUSZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzOTQ4Ng==", "bodyText": "Since the same request header is used for the response header these checks won't make a  lot of sense, right?\nImagine the client is on epoch 1 and sends a message to the server and the server transitions to epoch 2 just before it sends out the response. When the client receives the response it will be on epoch 1, but ignoreEpoch=false would mean that the client should have raised an exception. In this case it wont.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555439486", "createdAt": "2021-01-12T01:02:02Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +186,272 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 331}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ0MDA5OQ==", "bodyText": "It's a semantic change from the current code base. There is an difference between sending back the wrong epoch and saying that the return epoch value has no effect on the final result. That difference should be explicitly encoded.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555440099", "createdAt": "2021-01-12T01:04:05Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +186,272 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzOTQ4Ng=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 331}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI3MTk3Mg==", "bodyText": "With PR 2855, this message type is no longer needed and has been removed.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r560271972", "createdAt": "2021-01-19T15:39:59Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +186,272 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQzOTQ4Ng=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 331}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5Njc0MjMwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMTowOTowM1rOIRtd2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMTowOTowM1rOIRtd2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ0MTYyNA==", "bodyText": "Not sure if there is a convention about verb/noun naming these types.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555441624", "createdAt": "2021-01-12T01:09:03Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +186,272 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 361}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5Njc0NzQyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMToxMTo0NVrOIRtg_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQxOTo1ODoyMlrOISSWZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ0MjQyOA==", "bodyText": "This is strange, why is it needed?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555442428", "createdAt": "2021-01-12T01:11:45Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +186,272 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());\n         }\n \n-        batchWriter\n-                .addTask(WRITE, msg)\n+        final RequestMsg fReq = req;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 373}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjA0NTkyNg==", "bodyText": "I thought it's the effectively final constraint enforced in the lambda expressions.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r556045926", "createdAt": "2021-01-12T19:58:22Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +186,272 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());\n         }\n \n-        batchWriter\n-                .addTask(WRITE, msg)\n+        final RequestMsg fReq = req;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ0MjQyOA=="}, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 373}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5Njc2Mjg0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMToxODoxNlrOIRtpwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMToxODoxNlrOIRtpwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ0NDY3NA==", "bodyText": "This is not needed, you just unwrap it to List<LogData> addresses  and then construct a protobuf from that. Since a lot of quorum replication relies on that type, it would be more work to remove the ReadResponse class .", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555444674", "createdAt": "2021-01-12T01:18:16Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +186,272 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());\n         }\n \n-        batchWriter\n-                .addTask(WRITE, msg)\n+        final RequestMsg fReq = req;\n+        batchWriter.addTask(BatchWriterOperation.Type.WRITE, fReq)\n                 .thenRunAsync(() -> {\n-                    dataCache.put(msg.getPayload().getGlobalAddress(), logData);\n-                    r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg());\n+                    dataCache.put(logData.getGlobalAddress(), logData);\n+                    r.sendResponse(getResponseMsg(fReq.getHeader(), getWriteLogResponseMsg()), ctx);\n                 }, executor)\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, fReq, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Services incoming range write calls.\n      */\n-    @ServerHandler(type = CorfuMsgType.RANGE_WRITE)\n-    public void rangeWrite(CorfuPayloadMsg<RangeWriteMsg> msg,\n-                           ChannelHandlerContext ctx, IServerRouter r) {\n-        List<LogData> range = msg.getPayload().getEntries();\n-        log.debug(\"rangeWrite: Writing {} entries [{}-{}]\", range.size(),\n+    @RequestHandler(type = PayloadCase.RANGE_WRITE_LOG_REQUEST)\n+    public void handleRangeWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        List<LogData> range = req.getPayload().getRangeWriteLogRequest().getLogDataList()\n+                .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+\n+        log.debug(\"handleRangeWrite: Writing {} entries [{}-{}]\", range.size(),\n                 range.get(0).getGlobalAddress(), range.get(range.size() - 1).getGlobalAddress());\n \n-        batchWriter\n-                .addTask(RANGE_WRITE, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg()))\n+        batchWriter.addTask(BatchWriterOperation.Type.RANGE_WRITE, req)\n+                .thenRun(() -> r.sendResponse(getResponseMsg(req.getHeader(), getRangeWriteLogResponseMsg()), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n-     * Perform a prefix trim.\n+     * Perform a prefix trim (trim log).\n      * Here the token is not used to perform the trim as the epoch at which the checkpoint was completed\n      * might be old. Hence, we use the msg epoch to perform the trim. This should be safe provided that the\n      * trim is performed only on the token provided by the CheckpointWriter which ensures that the checkpoint\n      * was persisted. Using any other address to perform a trim can cause data loss.\n      */\n-    @ServerHandler(type = CorfuMsgType.PREFIX_TRIM)\n-    private void prefixTrim(CorfuPayloadMsg<TrimRequest> msg, ChannelHandlerContext ctx,\n-                            IServerRouter r) {\n-        log.debug(\"prefixTrim: trimming prefix to {}\", msg.getPayload().getAddress());\n-        batchWriter\n-                .addTask(PREFIX_TRIM, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg()))\n+    @RequestHandler(type = PayloadCase.TRIM_LOG_REQUEST)\n+    private void handleTrimLog(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.debug(\"handleTrimLog[{}]: trimming prefix to {}\", req.getHeader().getRequestId(),\n+                TextFormat.shortDebugString(req.getPayload().getTrimLogRequest().getAddress()));\n+\n+        batchWriter.addTask(BatchWriterOperation.Type.PREFIX_TRIM, req)\n+                .thenRun(() -> {\n+                    HeaderMsg header = getHeaderMsg(req.getHeader(), false, true);\n+                    r.sendResponse(getResponseMsg(header, getTrimLogResponseMsg()), ctx);\n+                })\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n-  @ServerHandler(type = CorfuMsgType.READ_REQUEST)\n-  public void read(CorfuPayloadMsg<ReadRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-    boolean cacheable = msg.getPayload().isCacheReadResult();\n-    if (log.isTraceEnabled()) {\n-      log.trace(\"read: {}, cacheable: {}\", msg.getPayload().getAddresses(), cacheable);\n-    }\n+    @RequestHandler(type = PayloadCase.READ_LOG_REQUEST)\n+    public void handleRead(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        final boolean cacheable = req.getPayload().getReadLogRequest().getCacheResults();\n+        final List<Long> addressList = req.getPayload().getReadLogRequest().getAddressList();\n \n-    ReadResponse rr = new ReadResponse();\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleRead: {}, cacheable: {}\", addressList, cacheable);\n+        }\n \n-    for (long address : msg.getPayload().getAddresses()) {\n-      try {\n-        ILogData logData = dataCache.get(address, cacheable);\n-        if (logData == null) {\n-          rr.put(address, LogData.getEmpty(address));\n-        } else {\n-          rr.put(address, (LogData) logData);\n+        ReadResponse rr = new ReadResponse();\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 472}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5Njc4MzAyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMToyNjo0OFrOIRt09A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMToyNjo0OFrOIRt09A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ0NzU0MA==", "bodyText": "This handler and handleInspectAddressesRequest seem to be redundant. We should remove one of them.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555447540", "createdAt": "2021-01-12T01:26:48Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -175,231 +186,272 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n-        } else if (ex.getCause() instanceof DataOutrankedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_OUTRANKED.msg());\n-        } else if (ex.getCause() instanceof ValueAdoptedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n+        } else if (ex.getCause() instanceof  DataOutrankedException) {\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getDataOutrankedErrorMsg()), ctx);\n+        } else if (ex.getCause() instanceof  ValueAdoptedException) {\n             ValueAdoptedException vae = (ValueAdoptedException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_VALUE_ADOPTED.payloadMsg(vae.getReadResponse()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getValueAdoptedErrorMsg(vae.getReadResponse())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());\n         }\n \n-        batchWriter\n-                .addTask(WRITE, msg)\n+        final RequestMsg fReq = req;\n+        batchWriter.addTask(BatchWriterOperation.Type.WRITE, fReq)\n                 .thenRunAsync(() -> {\n-                    dataCache.put(msg.getPayload().getGlobalAddress(), logData);\n-                    r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg());\n+                    dataCache.put(logData.getGlobalAddress(), logData);\n+                    r.sendResponse(getResponseMsg(fReq.getHeader(), getWriteLogResponseMsg()), ctx);\n                 }, executor)\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, fReq, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Services incoming range write calls.\n      */\n-    @ServerHandler(type = CorfuMsgType.RANGE_WRITE)\n-    public void rangeWrite(CorfuPayloadMsg<RangeWriteMsg> msg,\n-                           ChannelHandlerContext ctx, IServerRouter r) {\n-        List<LogData> range = msg.getPayload().getEntries();\n-        log.debug(\"rangeWrite: Writing {} entries [{}-{}]\", range.size(),\n+    @RequestHandler(type = PayloadCase.RANGE_WRITE_LOG_REQUEST)\n+    public void handleRangeWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        List<LogData> range = req.getPayload().getRangeWriteLogRequest().getLogDataList()\n+                .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+\n+        log.debug(\"handleRangeWrite: Writing {} entries [{}-{}]\", range.size(),\n                 range.get(0).getGlobalAddress(), range.get(range.size() - 1).getGlobalAddress());\n \n-        batchWriter\n-                .addTask(RANGE_WRITE, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg()))\n+        batchWriter.addTask(BatchWriterOperation.Type.RANGE_WRITE, req)\n+                .thenRun(() -> r.sendResponse(getResponseMsg(req.getHeader(), getRangeWriteLogResponseMsg()), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n-     * Perform a prefix trim.\n+     * Perform a prefix trim (trim log).\n      * Here the token is not used to perform the trim as the epoch at which the checkpoint was completed\n      * might be old. Hence, we use the msg epoch to perform the trim. This should be safe provided that the\n      * trim is performed only on the token provided by the CheckpointWriter which ensures that the checkpoint\n      * was persisted. Using any other address to perform a trim can cause data loss.\n      */\n-    @ServerHandler(type = CorfuMsgType.PREFIX_TRIM)\n-    private void prefixTrim(CorfuPayloadMsg<TrimRequest> msg, ChannelHandlerContext ctx,\n-                            IServerRouter r) {\n-        log.debug(\"prefixTrim: trimming prefix to {}\", msg.getPayload().getAddress());\n-        batchWriter\n-                .addTask(PREFIX_TRIM, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg()))\n+    @RequestHandler(type = PayloadCase.TRIM_LOG_REQUEST)\n+    private void handleTrimLog(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.debug(\"handleTrimLog[{}]: trimming prefix to {}\", req.getHeader().getRequestId(),\n+                TextFormat.shortDebugString(req.getPayload().getTrimLogRequest().getAddress()));\n+\n+        batchWriter.addTask(BatchWriterOperation.Type.PREFIX_TRIM, req)\n+                .thenRun(() -> {\n+                    HeaderMsg header = getHeaderMsg(req.getHeader(), false, true);\n+                    r.sendResponse(getResponseMsg(header, getTrimLogResponseMsg()), ctx);\n+                })\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n-  @ServerHandler(type = CorfuMsgType.READ_REQUEST)\n-  public void read(CorfuPayloadMsg<ReadRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-    boolean cacheable = msg.getPayload().isCacheReadResult();\n-    if (log.isTraceEnabled()) {\n-      log.trace(\"read: {}, cacheable: {}\", msg.getPayload().getAddresses(), cacheable);\n-    }\n+    @RequestHandler(type = PayloadCase.READ_LOG_REQUEST)\n+    public void handleRead(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        final boolean cacheable = req.getPayload().getReadLogRequest().getCacheResults();\n+        final List<Long> addressList = req.getPayload().getReadLogRequest().getAddressList();\n \n-    ReadResponse rr = new ReadResponse();\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleRead: {}, cacheable: {}\", addressList, cacheable);\n+        }\n \n-    for (long address : msg.getPayload().getAddresses()) {\n-      try {\n-        ILogData logData = dataCache.get(address, cacheable);\n-        if (logData == null) {\n-          rr.put(address, LogData.getEmpty(address));\n-        } else {\n-          rr.put(address, (LogData) logData);\n+        ReadResponse rr = new ReadResponse();\n+\n+        for (long address : addressList) {\n+            try {\n+                ILogData logData = dataCache.get(address, cacheable);\n+                if (logData == null) {\n+                    rr.put(address, LogData.getEmpty(address));\n+                } else {\n+                    rr.put(address, (LogData) logData);\n+                }\n+            } catch (DataCorruptionException dce) {\n+                log.error(\"handleRead: Data corruption exception while reading addresses {}\", addressList, dce);\n+                r.sendResponse(getResponseMsg(req.getHeader(), getDataCorruptionErrorMsg(address)), ctx);\n+                return;\n+            }\n         }\n-      } catch (DataCorruptionException e) {\n-        log.error(\n-            \"Data corruption exception while reading addresses {}\",\n-            msg.getPayload().getAddresses(),\n-            e);\n-        r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_CORRUPTION.payloadMsg(address));\n-        return;\n-      }\n+\n+        r.sendResponse(getResponseMsg(req.getHeader(), getReadLogResponseMsg(rr.getAddresses())), ctx);\n     }\n-    r.sendResponse(ctx, msg, CorfuMsgType.READ_RESPONSE.payloadMsg(rr));\n-  }\n-\n-  @ServerHandler(type = CorfuMsgType.INSPECT_ADDRESSES_REQUEST)\n-  public void inspectAddresses(\n-      CorfuPayloadMsg<InspectAddressesRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-    List<Long> addresses = msg.getPayload().getAddresses();\n-    log.trace(\"inspectAddresses: {}\", addresses);\n-    InspectAddressesResponse inspectResponse = new InspectAddressesResponse();\n-\n-    for (long address : addresses) {\n-      try {\n-        if (!streamLog.contains(address)) {\n-          inspectResponse.add(address);\n+\n+    @RequestHandler(type = PayloadCase.INSPECT_ADDRESSES_REQUEST)\n+    public void handleInspectAddressesRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        final List<Long> addresses = req.getPayload().getInspectAddressesRequest().getAddressList();\n+        List<Long> emptyAddresses = new ArrayList<>();\n+\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleInspectAddressesRequest[{}]: \" +\n+                    \"addresses {}\", req.getHeader().getRequestId(), addresses);\n+        }\n+\n+        for (long address : addresses) {\n+            try {\n+                if (!streamLog.contains(address)) {\n+                    emptyAddresses.add(address);\n+                }\n+            } catch (TrimmedException te) {\n+                r.sendResponse(getResponseMsg(req.getHeader(), getTrimmedErrorMsg()), ctx);\n+                return;\n+            } catch (DataCorruptionException dce) {\n+                r.sendResponse(getResponseMsg(req.getHeader(), getDataCorruptionErrorMsg(address)), ctx);\n+                return;\n+            }\n         }\n-      } catch (TrimmedException te) {\n-        r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n-        return;\n-      } catch (DataCorruptionException dce) {\n-        r.sendResponse(ctx, msg, CorfuMsgType.ERROR_DATA_CORRUPTION.payloadMsg(address));\n-        return;\n-      }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getInspectAddressesResponseMsg(emptyAddresses)), ctx);\n     }\n-    r.sendResponse(ctx, msg, CorfuMsgType.INSPECT_ADDRESSES_RESPONSE.payloadMsg(inspectResponse));\n-  }\n \n     /**\n      * Handles requests for known entries in specified range.\n      * This is used by state transfer to catch up only the remainder of the segment.\n      */\n-    @ServerHandler(type = CorfuMsgType.KNOWN_ADDRESS_REQUEST)\n-    private void getKnownAddressesInRange(CorfuPayloadMsg<KnownAddressRequest> msg,\n-                                          ChannelHandlerContext ctx, IServerRouter r) {\n-\n-        KnownAddressRequest request = msg.getPayload();\n+    @RequestHandler(type = PayloadCase.KNOWN_ADDRESS_REQUEST)\n+    private void handleKnownAddressRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 561}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5Njc4NzM3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMToyODo0NFrOIRt3cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMToyODo0NFrOIRt3cw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ0ODE3OQ==", "bodyText": "We should have a uniform way to propagate these requests. For example sealServerWithEpoch should be invoked with a seal message instead of only a long.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555448179", "createdAt": "2021-01-12T01:28:44Z", "author": {"login": "Maithem"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -411,23 +463,26 @@ private void handleFlushCacheRequest(CorfuMsg msg, ChannelHandlerContext ctx, IS\n      */\n     @Override\n     public void sealServerWithEpoch(long epoch) {\n-        CorfuPayloadMsg<Long> msg = new CorfuPayloadMsg<>();\n-        msg.setEpoch(epoch);\n-        msg.setPriorityLevel(PriorityLevel.HIGH);\n+        RequestMsg batchProcessorMsg = getRequestMsg(\n+                getHighPriorityHeaderMsg(HeaderMsg.newBuilder().setEpoch(epoch).build()),\n+                getSealRequestMsg(epoch)\n+        );\n+\n         try {\n-            batchWriter.addTask(SEAL, msg).join();\n+            batchWriter.addTask(BatchWriterOperation.Type.SEAL, batchProcessorMsg).join();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6dfbfadc57b6175a802d9698c28da67d855683f"}, "originalPosition": 628}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5Njk0MzQwOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/service/CorfuProtocolLogUnit.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMjozMjo1N1rOIRvT0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMjozMjo1N1rOIRvT0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ3MTgyNw==", "bodyText": "Why does the response return another response? It should unwrap the resulted LogData and return that. No point in propagated the wrappers.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555471827", "createdAt": "2021-01-12T02:32:57Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/service/CorfuProtocolLogUnit.java", "diffHunk": "@@ -0,0 +1,539 @@\n+package org.corfudb.protocols.service;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.CorfuProtocolCommon;\n+import org.corfudb.protocols.CorfuProtocolLogData;\n+import org.corfudb.protocols.wireprotocol.InspectAddressesResponse;\n+import org.corfudb.protocols.wireprotocol.KnownAddressResponse;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.ReadResponse;\n+import org.corfudb.protocols.wireprotocol.TailsResponse;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToLongPairMsg;\n+import org.corfudb.runtime.proto.RpcCommon.UuidToStreamAddressSpacePairMsg;\n+import org.corfudb.runtime.proto.ServerErrors.ValueAdoptedErrorMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.RequestPayloadMsg;\n+import org.corfudb.runtime.proto.service.CorfuMessage.ResponsePayloadMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CompactRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CompactResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CommittedTailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.CommittedTailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.FlushCacheRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.FlushCacheResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.InspectAddressesRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.InspectAddressesResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.KnownAddressRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.KnownAddressResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.LogAddressSpaceRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.LogAddressSpaceResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.RangeWriteLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.RangeWriteLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ReadLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ReadLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ResetLogUnitRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.ResetLogUnitResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimLogResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimMarkRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.TrimMarkResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.UpdateCommittedTailRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.UpdateCommittedTailResponseMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.WriteLogRequestMsg;\n+import org.corfudb.runtime.proto.service.LogUnit.WriteLogResponseMsg;\n+import org.corfudb.runtime.view.stream.StreamAddressSpace;\n+\n+import static org.corfudb.protocols.CorfuProtocolCommon.getStreamAddressSpaceMsg;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getTokenMsg;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUUID;\n+import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogData;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getLogDataMsg;\n+import static org.corfudb.protocols.CorfuProtocolLogData.getReadResponseMsg;\n+\n+/**\n+ * This class provides methods for creating the Protobuf objects defined\n+ * in log_unit.proto. These provide the interface for performing the RPCs\n+ * handled by the LogUnit server.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogUnit {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogUnit() {}\n+\n+    /**\n+     * Returns a READ request that can be sent by the client.\n+     *\n+     * @param addresses  a list of addresses to read from\n+     * @param cacheable  true if the read result should be cached on the LogUnit server\n+     * @return           a RequestPayloadMsg containing the READ request\n+     */\n+    public static RequestPayloadMsg getReadLogRequestMsg(List<Long> addresses, boolean cacheable) {\n+        return RequestPayloadMsg.newBuilder()\n+                .setReadLogRequest(ReadLogRequestMsg.newBuilder()\n+                        .setCacheResults(cacheable)\n+                        .addAllAddress(addresses)\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a READ response that can be sent by the server.\n+     *\n+     * @param addresses  a map containing the log data from the addresses read\n+     * @return           a ResponsePayloadMsg containing the READ response\n+     */\n+    public static ResponsePayloadMsg getReadLogResponseMsg(Map<Long, LogData> addresses) {\n+        return ResponsePayloadMsg.newBuilder()\n+                .setReadLogResponse(ReadLogResponseMsg.newBuilder()\n+                        .addAllResponse(addresses.entrySet()\n+                                .stream()\n+                                .map(e -> getReadResponseMsg(e.getKey(), e.getValue()))\n+                                .collect(Collectors.toList()))\n+                        .build())\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a ReadResponse from its Protobuf representation.\n+     *\n+     * @param msg  the desired Protobuf ReadLogResponse message\n+     * @return     an equivalent ReadResponse object\n+     */\n+    public static ReadResponse getReadResponse(ReadLogResponseMsg msg) {\n+        ReadResponse rr = new ReadResponse();\n+        msg.getResponseList().forEach(e -> rr.put(e.getAddress(), getLogData(e.getLogData())));\n+\n+        return rr;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NzAyODIxOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMzoxNTo0MVrOIRwDiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMzoxNTo0MVrOIRwDiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ4NDA0Mw==", "bodyText": "Most of these handlers should return the actual value, not the wrapped values. That is, LogData and not ReadResponse (which wraps LogData) etc.,", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555484043", "createdAt": "2021-01-12T03:15:41Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "diffHunk": "@@ -45,233 +48,265 @@ public LogUnitClient getClient(long epoch, UUID clusterID) {\n      * The handler and handlers which implement this client.\n      */\n     @Getter\n-    public ClientMsgHandler msgHandler = new ClientMsgHandler(this)\n-            .generateHandlers(MethodHandles.lookup(), this);\n-\n-    /**\n-     * For old CorfuMsg, use {@link #msgHandler}\n-     * The handler and handlers which implement this client.\n-     */\n-    @Getter\n     public ClientResponseHandler responseHandler = new ClientResponseHandler(this)\n             .generateHandlers(MethodHandles.lookup(), this)\n             .generateErrorHandlers(MethodHandles.lookup(), this);\n \n     /**\n-     * Handle an WRITE_OK message.\n+     * Handle a write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @return True, since this indicates success.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return Always True, since the write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.WRITE_OK)\n-    private static Object handleOk(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+    @ResponseHandler(type = PayloadCase.WRITE_LOG_RESPONSE)\n+    private static Object handleWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n         return true;\n     }\n \n     /**\n-     * Handle an ERROR_TRIMMED message.\n+     * Handle a range write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws TrimmedException if address has already been trimmed.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return Always True, since the range write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_TRIMMED)\n-    private static Object handleTrimmed(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new TrimmedException();\n+    @ResponseHandler(type = PayloadCase.RANGE_WRITE_LOG_RESPONSE)\n+    private static Object handleRangeWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle an ERROR_OVERWRITE message.\n+     * Handle a read log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OverwriteException Throws OverwriteException if address has already been written to.\n+     * @param msg The read log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return {@link ReadResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_OVERWRITE)\n-    private static Object handleOverwrite(CorfuPayloadMsg<Integer> msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new OverwriteException(OverwriteCause.fromId(msg.getPayload()));\n+    @ResponseHandler(type = PayloadCase.READ_LOG_RESPONSE)\n+    private static Object handleReadLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getReadResponse(msg.getPayload().getReadLogResponse());\n     }\n \n     /**\n-     * Handle an ERROR_DATA_OUTRANKED message.\n+     * Handle a inspect addresses response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OverwriteException Throws OverwriteException if write has been outranked.\n+     * @param msg The inspect addresses response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return {@link InspectAddressesResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_DATA_OUTRANKED)\n-    private static Object handleDataOutranked(CorfuMsg msg,\n-                                              ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new DataOutrankedException();\n+    @ResponseHandler(type = PayloadCase.INSPECT_ADDRESSES_RESPONSE)\n+    private static Object handleInspectResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getInspectAddressesResponse(msg.getPayload().getInspectAddressesResponse());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NzA5OTQ0OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMzo0NzozNlrOIRwsvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QxNzo0NToxNlrOIS7Elg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ5NDU5MQ==", "bodyText": "You can mark the class as final to prevent it from being inherited as well since its just a utils class.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555494591", "createdAt": "2021-01-12T03:47:36Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,59 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjA0OTg5NQ==", "bodyText": "Looks like we should mark all the CorfuProtocol*.java files to be final?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r556049895", "createdAt": "2021-01-12T20:04:21Z", "author": {"login": "xcchang"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,59 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ5NDU5MQ=="}, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjcxMzExMA==", "bodyText": "Done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r556713110", "createdAt": "2021-01-13T17:45:16Z", "author": {"login": "xcchang"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,59 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ5NDU5MQ=="}, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NzEyNjYxOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMzo1NzoxNVrOIRw9aQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwMzo1NzoxNVrOIRw9aQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ5ODg1Nw==", "bodyText": "Too many array copies :p. Maybe we should use pooling. I think we need to address some possible performance issues in subsequent patches.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555498857", "createdAt": "2021-01-12T03:57:15Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,59 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData object.\n+     *\n+     * @param logData  the desired LogData object\n+     * @return         an equivalent Protobuf LogData message\n+     */\n+    public static LogDataMsg getLogDataMsg(LogData logData) {\n+        ByteBuf buf = Unpooled.buffer();\n+        logData.doSerialize(buf);\n+\n+        return LogDataMsg.newBuilder()\n+                .setEntry(ByteString.copyFrom(buf.resetReaderIndex().array()))\n+                .build();\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NzEzNTQ3OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwNDowMjo0NlrOIRxCgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwNDowMjo0NlrOIRxCgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTUwMDE2MQ==", "bodyText": "I think new LogData(Unpooled.wrappedBuffer(msg.getEntry().asReadOnlyByteBuffer())); is cheaper than toByteArray since it will eliminate one allocation and one copy.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555500161", "createdAt": "2021-01-12T04:02:46Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolLogData.java", "diffHunk": "@@ -0,0 +1,59 @@\n+package org.corfudb.protocols;\n+\n+import com.google.protobuf.ByteString;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.runtime.proto.LogData.LogDataMsg;\n+import org.corfudb.runtime.proto.LogData.ReadResponseMsg;\n+\n+/**\n+ * This class provides methods for creating and converting between the Protobuf\n+ * objects defined in log_data.proto and their Java counterparts. Used by the\n+ * LogUnit RPCs.\n+ */\n+@Slf4j\n+public class CorfuProtocolLogData {\n+    // Prevent class from being instantiated\n+    private CorfuProtocolLogData() {}\n+\n+    /**\n+     * Returns the Protobuf representation of a LogData object.\n+     *\n+     * @param logData  the desired LogData object\n+     * @return         an equivalent Protobuf LogData message\n+     */\n+    public static LogDataMsg getLogDataMsg(LogData logData) {\n+        ByteBuf buf = Unpooled.buffer();\n+        logData.doSerialize(buf);\n+\n+        return LogDataMsg.newBuilder()\n+                .setEntry(ByteString.copyFrom(buf.resetReaderIndex().array()))\n+                .build();\n+    }\n+\n+    /**\n+     * Returns a LogData object from its Protobuf representation.\n+     *\n+     * @param msg  the desired Protobuf LogData message\n+     * @return     a equivalent LogData object\n+     */\n+    public static LogData getLogData(LogDataMsg msg) {\n+        return new LogData(Unpooled.wrappedBuffer(msg.getEntry().toByteArray()));\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NzE3MTE2OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogDataSerializerUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwNDoyMzoxMFrOIRxW3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwNDoyMzoxMFrOIRxW3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTUwNTM3NA==", "bodyText": "Shouldn't this be an immutable map that is created once? Why do we add more types at runtime?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555505374", "createdAt": "2021-01-12T04:23:10Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogDataSerializerUtils.java", "diffHunk": "@@ -0,0 +1,211 @@\n+package org.corfudb.protocols.wireprotocol;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.reflect.TypeToken;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * Utility class used by LogData to help serialize its contents.\n+ */\n+public class LogDataSerializerUtils {\n+    // Prevent class from being instantiated\n+    private LogDataSerializerUtils() {}\n+\n+    @FunctionalInterface\n+    interface PayloadConstructor<T> {\n+        T construct(ByteBuf buf);\n+    }\n+\n+    @FunctionalInterface\n+    interface Serializer {\n+        void serialize(ByteBuf buffer, Object payload);\n+    }\n+\n+    static ConcurrentHashMap<Class<?>, PayloadConstructor<?>> constructorMap = new ConcurrentHashMap<>(\n+            ImmutableMap.<Class<?>, PayloadConstructor<?>>builder()\n+                    .put(Byte.class, ByteBuf::readByte)\n+                    .put(Integer.class, ByteBuf::readInt)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NzE3NDAzOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogDataSerializerUtils.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwNDoyNDo1OVrOIRxYkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwNDoyNDo1OVrOIRxYkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTUwNTgxMQ==", "bodyText": "All this reflection is expensive to do per LogData. I think we need to revisit this later and just inline the metadata into the protobuf type.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555505811", "createdAt": "2021-01-12T04:24:59Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogDataSerializerUtils.java", "diffHunk": "@@ -0,0 +1,211 @@\n+package org.corfudb.protocols.wireprotocol;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.reflect.TypeToken;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.Unpooled;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.protocols.logprotocol.CheckpointEntry;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * Utility class used by LogData to help serialize its contents.\n+ */\n+public class LogDataSerializerUtils {\n+    // Prevent class from being instantiated\n+    private LogDataSerializerUtils() {}\n+\n+    @FunctionalInterface\n+    interface PayloadConstructor<T> {\n+        T construct(ByteBuf buf);\n+    }\n+\n+    @FunctionalInterface\n+    interface Serializer {\n+        void serialize(ByteBuf buffer, Object payload);\n+    }\n+\n+    static ConcurrentHashMap<Class<?>, PayloadConstructor<?>> constructorMap = new ConcurrentHashMap<>(\n+            ImmutableMap.<Class<?>, PayloadConstructor<?>>builder()\n+                    .put(Byte.class, ByteBuf::readByte)\n+                    .put(Integer.class, ByteBuf::readInt)\n+                    .put(Long.class, ByteBuf::readLong)\n+                    .put(IMetadata.DataRank.class, x -> new IMetadata.DataRank(x.readLong(), new UUID(x.readLong(), x.readLong())))\n+                    .put(CheckpointEntry.CheckpointEntryType.class, x -> CheckpointEntry.CheckpointEntryType.typeMap.get(x.readByte()))\n+                    .put(Codec.Type.class, x -> Codec.getCodecTypeById(x.readInt()))\n+                    .put(UUID.class, x -> new UUID(x.readLong(), x.readLong()))\n+                    .put(byte[].class, x -> {\n+                        int length = x.readInt();\n+                        byte[] bytes = new byte[length];\n+                        x.readBytes(bytes);\n+                        return bytes;\n+                    })\n+                    .put(ByteBuf.class, x -> {\n+                        int bytes = x.readInt();\n+                        ByteBuf b = x.retainedSlice(x.readerIndex(), bytes);\n+                        x.readerIndex(x.readerIndex() + bytes);\n+                        return b;\n+                    })\n+                    .build()\n+    );\n+\n+    static ConcurrentHashMap<Class<?>, Serializer> serializerMap = new ConcurrentHashMap<>(\n+            ImmutableMap.<Class<?>, Serializer>builder()\n+                    .put(Byte.class, (buffer, payload) -> buffer.writeByte((Byte) payload))\n+                    .put(Long.class, (buffer, payload) -> buffer.writeLong((Long) payload))\n+                    .put(byte[].class, (buffer, payload) -> {\n+                        buffer.writeInt(((byte[]) payload).length);\n+                        buffer.writeBytes((byte[]) payload);\n+                    })\n+                    .put(UUID.class, (buffer, payload) -> {\n+                        serialize(buffer, ((UUID) payload).getMostSignificantBits());\n+                        serialize(buffer, ((UUID) payload).getLeastSignificantBits());\n+                    })\n+                    .put(EnumMap.class, (buffer, payload) -> {\n+                        EnumMap<?, ?> map = (EnumMap<?, ?>) payload;\n+                        buffer.writeByte(map.size());\n+                        map.forEach((key, value) -> {\n+                            serialize(buffer, key);\n+                            serialize(buffer, value);\n+                        });\n+                    })\n+                    .put(Map.class, (buffer, payload) -> {\n+                        Map<?, ?> map = (Map<?, ?>) payload;\n+                        buffer.writeInt(map.size());\n+                        map.forEach((key, value) -> {\n+                            serialize(buffer, key);\n+                            serialize(buffer, value);\n+                        });\n+                    })\n+                    .put(ByteBuf.class, (buffer, payload) -> {\n+                        ByteBuf b = ((ByteBuf) payload).slice();\n+                        b.resetReaderIndex();\n+                        int bytes = b.readableBytes();\n+                        buffer.writeInt(bytes);\n+                        buffer.writeBytes(b, bytes);\n+                    })\n+                    .put(IMetadata.DataRank.class, (buffer, payload) -> {\n+                        serialize(buffer, ((IMetadata.DataRank) payload).getRank());\n+                        serialize(buffer, ((IMetadata.DataRank) payload).getUuid());\n+                    })\n+                    .put(IMetadata.LogUnitMetadataType.class, (buffer, payload) ->\n+                            serialize(buffer, ((IMetadata.LogUnitMetadataType) payload).asByte()))\n+                    .put(CheckpointEntry.CheckpointEntryType.class, (buffer, payload) ->\n+                            serialize(buffer, ((CheckpointEntry.CheckpointEntryType) payload).asByte()))\n+                    .put(Codec.Type.class, (buffer, payload) -> buffer.writeInt(((Codec.Type) payload).getId()))\n+                    .build()\n+    );\n+\n+    static ByteBuf byteBufFromBuffer(byte[] data) {\n+        ByteBuf buffer = Unpooled.wrappedBuffer(data);\n+        return fromBuffer(buffer, ByteBuf.class);\n+    }\n+\n+    /**\n+     * Build payload from Buffer\n+     *\n+     * @param buf The buffer to deserialize.\n+     * @param cls The class of the payload.\n+     * @param <T> The type of the payload.\n+     * @return payload\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <T> T fromBuffer(ByteBuf buf, Class<T> cls) {\n+        if (constructorMap.containsKey(cls)) {\n+            return (T) constructorMap.get(cls).construct(buf);\n+        } else if (cls.isEnum()) {\n+            // We only know how to deal with enums with a type map\n+            try {\n+                Map<Byte, T> typeMap = (Map<Byte, T>) cls.getDeclaredField(\"typeMap\").get(null);\n+                constructorMap.put(cls, x -> typeMap.get(x.readByte()));\n+                return (T) constructorMap.get(cls).construct(buf);\n+            } catch (NoSuchFieldException e) {\n+                throw new RuntimeException(\"Only enums with a typeMap are supported!\");\n+            } catch (IllegalAccessException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 128}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ5NzE4NDA2OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/WriteRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQwNDozMDoxNlrOIRxeFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMlQyMzo1OToyN1rOISaOnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTUwNzIyMg==", "bodyText": "You can just eliminate this class and Just use the LogData object directly.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r555507222", "createdAt": "2021-01-12T04:30:16Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/WriteRequest.java", "diffHunk": "@@ -12,25 +12,15 @@\n  */\n @Builder\n @AllArgsConstructor\n-public class WriteRequest implements ICorfuPayload<WriteRequest>, IMetadata {\n+public class WriteRequest implements IMetadata {\n \n     @Getter", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjE3NTAwNA==", "bodyText": "Done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r556175004", "createdAt": "2021-01-12T23:59:27Z", "author": {"login": "zfrenette"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/WriteRequest.java", "diffHunk": "@@ -12,25 +12,15 @@\n  */\n @Builder\n @AllArgsConstructor\n-public class WriteRequest implements ICorfuPayload<WriteRequest>, IMetadata {\n+public class WriteRequest implements IMetadata {\n \n     @Getter", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTUwNzIyMg=="}, "originalCommit": {"oid": "01cffae0ece1c5129a44ff6a19aa59f6ed855f6f"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxMDMzOTE3OnYy", "diffSide": "LEFT", "path": "test/src/test/java/org/corfudb/infrastructure/LogUnitServerTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyMToxOFrOITu7Tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyMToxOFrOITu7Tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2MjcwMg==", "bodyText": "Should we just remove this test since we don't have Rank now?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r557562702", "createdAt": "2021-01-14T17:21:18Z", "author": {"login": "xcchang"}, "path": "test/src/test/java/org/corfudb/infrastructure/LogUnitServerTest.java", "diffHunk": "@@ -524,77 +524,6 @@ public void testVerifyWithNoVerifyLog() throws Exception {\n         LogUnitServer logunit = new LogUnitServer(context);\n     }\n \n-    @Test\n-    public void checkOverwriteExceptionIsNotThrownWhenTheRankIsHigher() {\n-        String serviceDir = PARAMETERS.TEST_TEMP_DIR;\n-\n-        ServerContext sc = new ServerContextBuilder()\n-                .setLogPath(serviceDir)\n-                .setSingle(true)\n-                .setMemory(false)\n-                .build();\n-\n-        sc.installSingleNodeLayoutIfAbsent();\n-        sc.setServerRouter(router);\n-        sc.setServerEpoch(sc.getCurrentLayout().getEpoch(), router);\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d1f1beffdd890eb4264fe6a273d07ca1cbed251"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MjExOTEyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxOTowMzozN1rOIZ2Fnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxOTowMzozN1rOIZ2Fnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzk3MTQ4Nw==", "bodyText": "You might want to consider being more explicit about your type parameters and use the unbounded wildcard type.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r563971487", "createdAt": "2021-01-25T19:03:37Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/BatchProcessor.java", "diffHunk": "@@ -118,127 +107,140 @@ private void recordRunnable(Runnable fsyncRunnable, Optional<Timer> fsyncTimer)\n         }\n     }\n \n-    private void processor() {\n+    /**\n+     * Add a task to the processor.\n+     *\n+     * @param type The request type\n+     * @param req  The request message\n+     * @return     returns a future result for the request, if it expects one\n+     */\n+    public <T> CompletableFuture<T> addTask(@Nonnull Type type, @Nonnull RequestMsg req) {\n+        BatchWriterOperation<T> op = new BatchWriterOperation<>(type, req);\n+        operationsQueue.add(op);\n+        return op.getFutureResult();\n+    }\n \n+    private void process() {\n         if (!sync) {\n             log.warn(\"batchWriteProcessor: writes configured to not sync with secondary storage\");\n         }\n \n         try {\n             BatchWriterOperation lastOp = null;\n-            int processed = 0;\n-            List<BatchWriterOperation> res = new LinkedList<>();\n+            List<BatchWriterOperation> res = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 162}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MjIwMjkxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxOToyNToxM1rOIZ25LQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMjo1MjozNFrOIauISQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzk4NDY4NQ==", "bodyText": "Please rename r into router. Out of context, r could mean anything.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r563984685", "createdAt": "2021-01-25T19:25:13Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -156,15 +161,19 @@ protected void processRequest(RequestMsg req, ChannelHandlerContext ctx, IServer\n     /**\n      * Service an incoming request for maximum global address the log unit server has written.\n      */\n-    @ServerHandler(type = CorfuMsgType.TAIL_REQUEST)\n-    public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.debug(\"handleTailRequest: received a tail request {}\", msg);\n-        batchWriter.<TailsResponse>addTask(TAILS_QUERY, msg)\n-                .thenAccept(tailsResp -> {\n-                    r.sendResponse(ctx, msg, CorfuMsgType.TAIL_RESPONSE.payloadMsg(tailsResp));\n-                })\n+    @RequestHandler(type = PayloadCase.TAIL_REQUEST)\n+    public void handleTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg4OTY3Mw==", "bodyText": "I have updated this here and in other related locations.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564889673", "createdAt": "2021-01-26T22:52:34Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -156,15 +161,19 @@ protected void processRequest(RequestMsg req, ChannelHandlerContext ctx, IServer\n     /**\n      * Service an incoming request for maximum global address the log unit server has written.\n      */\n-    @ServerHandler(type = CorfuMsgType.TAIL_REQUEST)\n-    public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.debug(\"handleTailRequest: received a tail request {}\", msg);\n-        batchWriter.<TailsResponse>addTask(TAILS_QUERY, msg)\n-                .thenAccept(tailsResp -> {\n-                    r.sendResponse(ctx, msg, CorfuMsgType.TAIL_RESPONSE.payloadMsg(tailsResp));\n-                })\n+    @RequestHandler(type = PayloadCase.TAIL_REQUEST)\n+    public void handleTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzk4NDY4NQ=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 200}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MjIwODQ5OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxOToyNjozNVrOIZ28kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxOToyNjozNVrOIZ28kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzk4NTU1NA==", "bodyText": "Same. More descriptive argument names please.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r563985554", "createdAt": "2021-01-25T19:26:35Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 230}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MjM3NjgzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMDoxMTo0NVrOIZ4l8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMDoxMzoyN1rOIaozwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDAxMjUzMA==", "bodyText": "Instead of introducing an if statement, you can simply emulate lazy-evaluation:\n    interface LazyString {\n        String toString();\n\n        static LazyString create(MessageOrBuilder message) {\n            return new LazyString() {\n                @Override\n                public String toString() {\n                    return TextFormat.shortDebugString(message);\n                }\n            };\n        }\n    }\n\nWhich will enable you to do:\nlog.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n        \"address space request {}\", req.getHeader().getRequestId(), LazyString.create(req));\n\nAlternatively, we can upgrade slf4j to include the fluent API, which would allow you to pass a Supplier. However, that is a riskier change.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564012530", "createdAt": "2021-01-25T20:11:45Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 298}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDgwMjQ5OA==", "bodyText": "Although this emulates lazy-evaluation, it does not guard against the allocation of an additional object like the if statement would when trace/debug is disabled. I think keeping the if statement is slightly better since it provides both benefits.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564802498", "createdAt": "2021-01-26T20:13:27Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDAxMjUzMA=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 298}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MjM4MjczOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMDoxMzozN1rOIZ4pqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMDoxMzozN1rOIZ4pqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDAxMzQ4MQ==", "bodyText": "I assume you wanted to guard this statement as well.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564013481", "createdAt": "2021-01-25T20:13:37Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -156,15 +161,19 @@ protected void processRequest(RequestMsg req, ChannelHandlerContext ctx, IServer\n     /**\n      * Service an incoming request for maximum global address the log unit server has written.\n      */\n-    @ServerHandler(type = CorfuMsgType.TAIL_REQUEST)\n-    public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.debug(\"handleTailRequest: received a tail request {}\", msg);\n-        batchWriter.<TailsResponse>addTask(TAILS_QUERY, msg)\n-                .thenAccept(tailsResp -> {\n-                    r.sendResponse(ctx, msg, CorfuMsgType.TAIL_RESPONSE.payloadMsg(tailsResp));\n-                })\n+    @RequestHandler(type = PayloadCase.TAIL_REQUEST)\n+    public void handleTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.debug(\"handleTailRequest[{}]: received a tail request {}\",\n+                req.getHeader().getRequestId(), TextFormat.shortDebugString(req));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 202}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MjQzNDUwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMDoyODoyMVrOIZ5JKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQxODo1OToxN1rOIal_VA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDAyMTU0NQ==", "bodyText": "I actually think that this method does nor provide much value. The problem I have with it is that arguments two and three are not type safe, so it is pretty easy to mess us the ordering. When using the Builder directly, it is much harder, since the parameter names are referenced explicitly.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564021545", "createdAt": "2021-01-25T20:28:21Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 304}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDAzODYxMw==", "bodyText": "Alternatively, you can defines types for each of the paramets:\n    public enum ClusterId {\n        CHECK,\n        IGNORE\n    }\n    \n    public enum Epoch {\n        CHECK,\n        IGNORE\n    }\n\nAnd change you method implementation:\n    public static HeaderMsg getHeaderMsg(HeaderMsg header, ClusterId ignoreClusterId, Epoch ignoreEpoch) {\n        return HeaderMsg.newBuilder()\n                .mergeFrom(header)\n                .setIgnoreClusterId(ignoreClusterId == ClusterId.IGNORE)\n                .setIgnoreEpoch(ignoreEpoch == Epoch.IGNORE)\n                .build();\n    }\n\nSo a call to that function would become: getHeaderMsg(req.getHeader(), ClusterId.IGNORE, Epoch.IGNORE);", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564038613", "createdAt": "2021-01-25T20:58:26Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDAyMTU0NQ=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 304}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDc1NjMwOA==", "bodyText": "I like this approach, but as discussed, changing the getHeaderMsg method signatures requires updates to all of the servers, clients and corresponding tests. I'll address this in a different PR.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564756308", "createdAt": "2021-01-26T18:59:17Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDAyMTU0NQ=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 304}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MjU0OTEwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMDo1ODo1MVrOIZ6MtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMDo1ODo1MVrOIZ6MtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDAzODgzNg==", "bodyText": "Same here, argument names could be impoved.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564038836", "createdAt": "2021-01-25T20:58:51Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 314}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MjU5MTA0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMToxMDozMlrOIZ6mMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMjo0OToyNlrOIauCSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDA0NTM2MA==", "bodyText": "I think it would be much cleaner to user the Builder directly. Also, you should avoid shadowing req` argument. How about this?\n        HeaderMsg.Builder responseHeader = HeaderMsg.newBuilder().mergeFrom(req.getHeader());\n\n        // Its not clear that making all holes high priority is the right thing to do, but since\n        // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n        // because the requirement is to allow reads, but only block writes once the quota is exhausted\n        if (logData.isHole()) {\n            responseHeader.setPriority(CorfuMessage.PriorityLevel.HIGH);\n        }\n\n        batchWriter.addTask(BatchWriterOperation.Type.WRITE, req)\n                .thenRunAsync(() -> {\n                    dataCache.put(logData.getGlobalAddress(), logData);\n                    r.sendResponse(getResponseMsg(responseHeader.build(), getWriteLogResponseMsg()), ctx);\n                }, executor)\n                .exceptionally(ex -> {\n                    handleException(ex, ctx, req, r);\n                    return null;\n                });", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564045360", "createdAt": "2021-01-25T21:10:32Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 363}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDc5MzAwMw==", "bodyText": "The issue here is that the message given to BatchProcessor when adding the task is expected to have PriorityLevel.HIGH when the corresponding logData is a hole. In this snippet, we are changing the priority of the response instead. Although this is fine, it still seems like the request needs to be updated in order to use this new header.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564793003", "createdAt": "2021-01-26T19:57:40Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDA0NTM2MA=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 363}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg4ODEzOQ==", "bodyText": "I have used the Builder directly to set PriorityLevel.HIGH, but still modify the request message to use this new header.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564888139", "createdAt": "2021-01-26T22:49:26Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDA0NTM2MA=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 363}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MjY4MjYwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMTozNjoxM1rOIZ7dcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQyMTozNjoxM1rOIZ7dcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDA1OTUwNg==", "bodyText": "A more descriptive variable name please.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564059506", "createdAt": "2021-01-25T21:36:13Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -173,226 +182,265 @@ public void handleTailRequest(CorfuPayloadMsg<TailsRequest> msg, ChannelHandlerC\n      * Service an incoming request for log address space, i.e., the map of addresses for every stream in the log.\n      * This is used on sequencer bootstrap to provide the address maps for initialization.\n      */\n-    @ServerHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_REQUEST)\n-    public void handleLogAddressSpaceRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        CorfuPayloadMsg<Void> payloadMsg = new CorfuPayloadMsg<>();\n-        payloadMsg.copyBaseFields(msg);\n-        log.trace(\"handleLogAddressSpaceRequest: received a log address space request {}\", msg);\n-        batchWriter.<StreamsAddressResponse>addTask(LOG_ADDRESS_SPACE_QUERY, payloadMsg)\n-                .thenAccept(tailsResp -> r.sendResponse(ctx, msg,\n-                        CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE.payloadMsg(tailsResp))\n-                )\n+    @RequestHandler(type = PayloadCase.LOG_ADDRESS_SPACE_REQUEST)\n+    public void handleLogAddressSpaceRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleLogAddressSpaceRequest[{}]: received a log \" +\n+                    \"address space request {}\", req.getHeader().getRequestId(), TextFormat.shortDebugString(req));\n+        }\n+\n+        batchWriter.<StreamsAddressResponse>addTask(BatchWriterOperation.Type.LOG_ADDRESS_SPACE_QUERY, req)\n+                .thenAccept(resp ->\n+                    // Note: we reuse the request header as the ignore_cluster_id and\n+                    // ignore_epoch fields are the same in both cases.\n+                    r.sendResponse(getResponseMsg(req.getHeader(), getLogAddressSpaceResponseMsg(\n+                            resp.getLogTail(), resp.getEpoch(), resp.getAddressMap())), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, payloadMsg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Service an incoming request to retrieve the starting address of this logging unit.\n      */\n-    @ServerHandler(type = CorfuMsgType.TRIM_MARK_REQUEST)\n-    public void handleTrimMarkRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.TRIM_MARK_RESPONSE.payloadMsg(streamLog.getTrimMark()));\n+    @RequestHandler(type = PayloadCase.TRIM_MARK_REQUEST)\n+    public void handleTrimMarkRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleTrimMarkRequest: received a trim mark request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(), getTrimMarkResponseMsg(streamLog.getTrimMark())), ctx);\n     }\n \n     /**\n      * Service an incoming query for the committed tail on this log unit server.\n      */\n-    @ServerHandler(type = CorfuMsgType.COMMITTED_TAIL_REQUEST)\n-    public void handleCommittedTailRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"handleCommittedTailRequest: received a committed log tail request {}\", msg);\n-        r.sendResponse(ctx, msg, CorfuMsgType.COMMITTED_TAIL_RESPONSE.payloadMsg(streamLog.getCommittedTail()));\n+    @RequestHandler(type = PayloadCase.COMMITTED_TAIL_REQUEST)\n+    public void handleCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleCommittedTailRequest: received a \"\n+                    + \"committed log tail request {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        // Note: we reuse the request header as the ignore_cluster_id and\n+        // ignore_epoch fields are the same in both cases.\n+        r.sendResponse(getResponseMsg(req.getHeader(),\n+                getCommittedTailResponseMsg(streamLog.getCommittedTail())), ctx);\n     }\n \n     /**\n      * Service an incoming request to update the current committed tail.\n      */\n-    @ServerHandler(type = CorfuMsgType.UPDATE_COMMITTED_TAIL)\n-    public void updateCommittedTail(CorfuPayloadMsg<Long> msg,\n-                                    ChannelHandlerContext ctx, IServerRouter r) {\n-        log.trace(\"updateCommittedTail: received request to update committed tail {}\", msg);\n-        streamLog.updateCommittedTail(msg.getPayload());\n-        r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n+    @RequestHandler(type = PayloadCase.UPDATE_COMMITTED_TAIL_REQUEST)\n+    public void handleUpdateCommittedTailRequest(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleUpdateCommittedTailRequest: received request to \"\n+                    + \"update committed tail {}\", TextFormat.shortDebugString(req));\n+        }\n+\n+        streamLog.updateCommittedTail(req.getPayload().getUpdateCommittedTailRequest().getCommittedTail());\n+        HeaderMsg responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+        ResponseMsg response = getResponseMsg(responseHeader, getUpdateCommittedTailResponseMsg());\n+        r.sendResponse(response, ctx);\n     }\n \n     /**\n      * A helper function that maps an exception to the appropriate response message.\n      */\n-    private void handleException(Throwable ex, ChannelHandlerContext ctx, CorfuPayloadMsg msg, IServerRouter r) {\n-        log.trace(\"handleException: handling exception {} for {}\", ex, msg);\n+    private void handleException(Throwable ex, ChannelHandlerContext ctx, RequestMsg req, IServerRouter r) {\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleException: handling exception {} for {}\", ex, TextFormat.shortDebugString(req));\n+        }\n+\n+        HeaderMsg responseHeader;\n+\n         if (ex.getCause() instanceof WrongEpochException) {\n             WrongEpochException wee = (WrongEpochException) ex.getCause();\n-            r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, wee.getCorrectEpoch()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getWrongEpochErrorMsg(wee.getCorrectEpoch())), ctx);\n         } else if (ex.getCause() instanceof OverwriteException) {\n             OverwriteException owe = (OverwriteException) ex.getCause();\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_OVERWRITE\n-                    .payloadMsg(owe.getOverWriteCause().getId()));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getOverwriteErrorMsg(owe.getOverWriteCause().getId())), ctx);\n         } else if (ex.getCause() instanceof TrimmedException) {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_TRIMMED.msg());\n+            responseHeader = getHeaderMsg(req.getHeader(), false, false);\n+            r.sendResponse(getResponseMsg(responseHeader, getTrimmedErrorMsg()), ctx);\n         } else {\n-            r.sendResponse(ctx, msg, CorfuMsgType.ERROR_SERVER_EXCEPTION.payloadMsg(new ExceptionMsg(ex)));\n+            responseHeader = getHeaderMsg(req.getHeader(), false, true);\n+            r.sendResponse(getResponseMsg(responseHeader, getUnknownErrorMsg(ex)), ctx);\n             throw new LogUnitException(ex);\n         }\n     }\n \n     /**\n      * Service an incoming write request.\n      */\n-    @ServerHandler(type = CorfuMsgType.WRITE)\n-    public void write(CorfuPayloadMsg<WriteRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        LogData logData = (LogData) msg.getPayload().getData();\n-        log.debug(\"log write: type: {}, address: {}, streams: {}\", logData.getType(),\n-                logData.getToken(), logData.getBackpointerMap());\n+    @RequestHandler(type = PayloadCase.WRITE_LOG_REQUEST)\n+    public void handleWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        LogData logData = getLogData(req.getPayload().getWriteLogRequest().getLogData());\n+        log.debug(\"handleWrite: type: {}, address: {}, streams: {}\",\n+                logData.getType(), logData.getToken(), logData.getBackpointerMap());\n \n         // Its not clear that making all holes high priority is the right thing to do, but since\n         // some reads will block until a hole is filled this is required (i.e. bypass quota checks)\n         // because the requirement is to allow reads, but only block writes once the quota is exhausted\n         if (logData.isHole()) {\n-            msg.setPriorityLevel(PriorityLevel.HIGH);\n+            req = getRequestMsg(getHighPriorityHeaderMsg(req.getHeader()), req.getPayload());\n         }\n \n-        batchWriter\n-                .addTask(WRITE, msg)\n+        final RequestMsg fReq = req;\n+        batchWriter.addTask(BatchWriterOperation.Type.WRITE, fReq)\n                 .thenRunAsync(() -> {\n-                    dataCache.put(msg.getPayload().getGlobalAddress(), logData);\n-                    r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg());\n+                    dataCache.put(logData.getGlobalAddress(), logData);\n+                    r.sendResponse(getResponseMsg(fReq.getHeader(), getWriteLogResponseMsg()), ctx);\n                 }, executor)\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, fReq, r);\n                     return null;\n                 });\n     }\n \n     /**\n      * Services incoming range write calls.\n      */\n-    @ServerHandler(type = CorfuMsgType.RANGE_WRITE)\n-    public void rangeWrite(CorfuPayloadMsg<RangeWriteMsg> msg,\n-                           ChannelHandlerContext ctx, IServerRouter r) {\n-        List<LogData> range = msg.getPayload().getEntries();\n-        log.debug(\"rangeWrite: Writing {} entries [{}-{}]\", range.size(),\n+    @RequestHandler(type = PayloadCase.RANGE_WRITE_LOG_REQUEST)\n+    public void handleRangeWrite(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        List<LogData> range = req.getPayload().getRangeWriteLogRequest().getLogDataList()\n+                .stream().map(CorfuProtocolLogData::getLogData).collect(Collectors.toList());\n+\n+        log.debug(\"handleRangeWrite: Writing {} entries [{}-{}]\", range.size(),\n                 range.get(0).getGlobalAddress(), range.get(range.size() - 1).getGlobalAddress());\n \n-        batchWriter\n-                .addTask(RANGE_WRITE, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.WRITE_OK.msg()))\n+        batchWriter.addTask(BatchWriterOperation.Type.RANGE_WRITE, req)\n+                .thenRun(() -> r.sendResponse(getResponseMsg(req.getHeader(), getRangeWriteLogResponseMsg()), ctx))\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n     /**\n-     * Perform a prefix trim.\n+     * Perform a prefix trim (trim log).\n      * Here the token is not used to perform the trim as the epoch at which the checkpoint was completed\n      * might be old. Hence, we use the msg epoch to perform the trim. This should be safe provided that the\n      * trim is performed only on the token provided by the CheckpointWriter which ensures that the checkpoint\n      * was persisted. Using any other address to perform a trim can cause data loss.\n      */\n-    @ServerHandler(type = CorfuMsgType.PREFIX_TRIM)\n-    private void prefixTrim(CorfuPayloadMsg<TrimRequest> msg, ChannelHandlerContext ctx,\n-                            IServerRouter r) {\n-        log.debug(\"prefixTrim: trimming prefix to {}\", msg.getPayload().getAddress());\n-        batchWriter\n-                .addTask(PREFIX_TRIM, msg)\n-                .thenRun(() -> r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg()))\n+    @RequestHandler(type = PayloadCase.TRIM_LOG_REQUEST)\n+    private void handleTrimLog(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        log.debug(\"handleTrimLog[{}]: trimming prefix to {}\", req.getHeader().getRequestId(),\n+                TextFormat.shortDebugString(req.getPayload().getTrimLogRequest().getAddress()));\n+\n+        batchWriter.addTask(BatchWriterOperation.Type.PREFIX_TRIM, req)\n+                .thenRun(() -> {\n+                    HeaderMsg header = getHeaderMsg(req.getHeader(), false, true);\n+                    r.sendResponse(getResponseMsg(header, getTrimLogResponseMsg()), ctx);\n+                })\n                 .exceptionally(ex -> {\n-                    handleException(ex, ctx, msg, r);\n+                    handleException(ex, ctx, req, r);\n                     return null;\n                 });\n     }\n \n-  @ServerHandler(type = CorfuMsgType.READ_REQUEST)\n-  public void read(CorfuPayloadMsg<ReadRequest> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-    boolean cacheable = msg.getPayload().isCacheReadResult();\n-    if (log.isTraceEnabled()) {\n-      log.trace(\"read: {}, cacheable: {}\", msg.getPayload().getAddresses(), cacheable);\n-    }\n+    @RequestHandler(type = PayloadCase.READ_LOG_REQUEST)\n+    public void handleRead(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n+        final boolean cacheable = req.getPayload().getReadLogRequest().getCacheResults();\n+        final List<Long> addressList = req.getPayload().getReadLogRequest().getAddressList();\n \n-    ReadResponse rr = new ReadResponse();\n+        if (log.isTraceEnabled()) {\n+            log.trace(\"handleRead: {}, cacheable: {}\", addressList, cacheable);\n+        }\n \n-    for (long address : msg.getPayload().getAddresses()) {\n-      try {\n-        ILogData logData = dataCache.get(address, cacheable);\n-        if (logData == null) {\n-          rr.put(address, LogData.getEmpty(address));\n-        } else {\n-          rr.put(address, (LogData) logData);\n+        ReadResponse rr = new ReadResponse();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 466}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzM1NjI1OnYy", "diffSide": "LEFT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo0ODowNlrOIaBpWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMjowNjo0NlrOIasuNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MDg1OQ==", "bodyText": "I feel that the original logic was easier to understand, since you were doing error handling at the beginning of the function. Rest of the function then is a non-edge-case scenario. Also, it reduces the amount of nesting.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564160859", "createdAt": "2021-01-26T01:48:06Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -433,36 +484,33 @@ public boolean isServerReadyToHandleMsg(CorfuMsg msg) {\n      * - After this the reset operation is inserted which resets and clears all data.\n      * - Finally the cache is invalidated to purge the existing entries.\n      */\n-    @ServerHandler(type = CorfuMsgType.RESET_LOGUNIT)\n-    private synchronized void resetLogUnit(CorfuPayloadMsg<Long> msg,\n-                                           ChannelHandlerContext ctx, IServerRouter r) {\n-\n+    @RequestHandler(type = PayloadCase.RESET_LOG_UNIT_REQUEST)\n+    private synchronized void handleResetLogUnit(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n         // Check if the reset request is with an epoch greater than the last reset epoch seen to\n-        // prevent multiple reset in the same epoch and should be equal to the current router\n+        // prevent multiple reset in the same epoch. and should be equal to the current router\n         // epoch to prevent stale reset requests from wiping out the data.\n-        if (msg.getPayload() <= serverContext.getLogUnitEpochWaterMark()\n-                || msg.getPayload() != serverContext.getServerEpoch()) {\n-            log.info(\"LogUnit Server Reset request received but reset already done.\");\n-            r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n-            return;\n-        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 660}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2NjYxMw==", "bodyText": "Done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564866613", "createdAt": "2021-01-26T22:06:46Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -433,36 +484,33 @@ public boolean isServerReadyToHandleMsg(CorfuMsg msg) {\n      * - After this the reset operation is inserted which resets and clears all data.\n      * - Finally the cache is invalidated to purge the existing entries.\n      */\n-    @ServerHandler(type = CorfuMsgType.RESET_LOGUNIT)\n-    private synchronized void resetLogUnit(CorfuPayloadMsg<Long> msg,\n-                                           ChannelHandlerContext ctx, IServerRouter r) {\n-\n+    @RequestHandler(type = PayloadCase.RESET_LOG_UNIT_REQUEST)\n+    private synchronized void handleResetLogUnit(RequestMsg req, ChannelHandlerContext ctx, IServerRouter r) {\n         // Check if the reset request is with an epoch greater than the last reset epoch seen to\n-        // prevent multiple reset in the same epoch and should be equal to the current router\n+        // prevent multiple reset in the same epoch. and should be equal to the current router\n         // epoch to prevent stale reset requests from wiping out the data.\n-        if (msg.getPayload() <= serverContext.getLogUnitEpochWaterMark()\n-                || msg.getPayload() != serverContext.getServerEpoch()) {\n-            log.info(\"LogUnit Server Reset request received but reset already done.\");\n-            r.sendResponse(ctx, msg, CorfuMsgType.ACK.msg());\n-            return;\n-        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MDg1OQ=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 660}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzM1OTc4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/NettyServerRouter.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo0OTo0N1rOIaBrgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMTo1Njo1NFrOIasY4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MTQwOQ==", "bodyText": "I don't think this is necessary. None of the arguments are expensive to compute, nor do we run into this code path.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564161409", "createdAt": "2021-01-26T01:49:47Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/NettyServerRouter.java", "diffHunk": "@@ -76,7 +76,9 @@ public NettyServerRouter(ImmutableList<AbstractServer> servers, ServerContext se\n             try {\n                 server.getHandler().getHandledTypes().forEach(handledType -> handlerMap.put(handledType, server));\n             } catch (UnsupportedOperationException ex) {\n-                log.error(\"No registered CorfuMsg handler for server {}\", server, ex);\n+                if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDY0MTczNA==", "bodyText": "This was originally from one of Maithem's comments, (#2838 (comment)). I'm a little inclined to keep current way to make it consistent, and since this happens in a lot of places, it might be worth adding this check?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564641734", "createdAt": "2021-01-26T16:17:36Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/NettyServerRouter.java", "diffHunk": "@@ -76,7 +76,9 @@ public NettyServerRouter(ImmutableList<AbstractServer> servers, ServerContext se\n             try {\n                 server.getHandler().getHandledTypes().forEach(handledType -> handlerMap.put(handledType, server));\n             } catch (UnsupportedOperationException ex) {\n-                log.error(\"No registered CorfuMsg handler for server {}\", server, ex);\n+                if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MTQwOQ=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDY1MDc3Ng==", "bodyText": "@xcchang In Maithem's comment, I think the concern was the computation of TextFormat.shortDebugString. In this particular instance, we don't have this problem.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564650776", "createdAt": "2021-01-26T16:28:57Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/NettyServerRouter.java", "diffHunk": "@@ -76,7 +76,9 @@ public NettyServerRouter(ImmutableList<AbstractServer> servers, ServerContext se\n             try {\n                 server.getHandler().getHandledTypes().forEach(handledType -> handlerMap.put(handledType, server));\n             } catch (UnsupportedOperationException ex) {\n-                log.error(\"No registered CorfuMsg handler for server {}\", server, ex);\n+                if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MTQwOQ=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDY1MjI3Mg==", "bodyText": "Oh I see now, thanks!", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564652272", "createdAt": "2021-01-26T16:30:45Z", "author": {"login": "xcchang"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/NettyServerRouter.java", "diffHunk": "@@ -76,7 +76,9 @@ public NettyServerRouter(ImmutableList<AbstractServer> servers, ServerContext se\n             try {\n                 server.getHandler().getHandledTypes().forEach(handledType -> handlerMap.put(handledType, server));\n             } catch (UnsupportedOperationException ex) {\n-                log.error(\"No registered CorfuMsg handler for server {}\", server, ex);\n+                if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MTQwOQ=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2MTE1NA==", "bodyText": "I have removed this check from this and other routers.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564861154", "createdAt": "2021-01-26T21:56:54Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/NettyServerRouter.java", "diffHunk": "@@ -76,7 +76,9 @@ public NettyServerRouter(ImmutableList<AbstractServer> servers, ServerContext se\n             try {\n                 server.getHandler().getHandledTypes().forEach(handledType -> handlerMap.put(handledType, server));\n             } catch (UnsupportedOperationException ex) {\n-                log.error(\"No registered CorfuMsg handler for server {}\", server, ex);\n+                if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MTQwOQ=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzM2MDEyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/LogReplicationClientRouter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo0OTo1OFrOIaBrtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo0OTo1OFrOIaBrtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MTQ2Mw==", "bodyText": "Same here.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564161463", "createdAt": "2021-01-26T01:49:58Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/LogReplicationClientRouter.java", "diffHunk": "@@ -151,7 +151,9 @@ public IClientRouter addClient(IClient client) {\n                         log.info(\"Registered client to handle messages of type {}\", x);\n                     });\n         } catch (UnsupportedOperationException ex) {\n-            log.error(\"No registered CorfuMsg handler for client {}\", client, ex);\n+            if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzM2MDY1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/LogReplicationServerRouter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo1MDoxMlrOIaBsBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo1MDoxMlrOIaBsBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MTU0MQ==", "bodyText": "Same here.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564161541", "createdAt": "2021-01-26T01:50:12Z", "author": {"login": "vjeko"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/LogReplicationServerRouter.java", "diffHunk": "@@ -71,7 +71,9 @@ public LogReplicationServerRouter(List<AbstractServer> servers) {\n             try {\n                 server.getHandler().getHandledTypes().forEach(x -> handlerMap.put(x, server));\n             } catch (UnsupportedOperationException ex) {\n-                log.error(\"No registered CorfuMsg handler for server {}\", server, ex);\n+                if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzM2MzY1OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolCommon.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo1MTo0N1rOIaBtxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQxNjozNzozM1rOIaf9cQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MTk4OA==", "bodyText": "I don't think this should go in CorfuProtocolCommon. It is logic that is specific to Log Unit API.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564161988", "createdAt": "2021-01-26T01:51:47Z", "author": {"login": "vjeko"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolCommon.java", "diffHunk": "@@ -255,6 +257,28 @@ public static StreamAddressRangeMsg getStreamAddressRangeMsg(StreamAddressRange\n                 .build();\n     }\n \n+    /**\n+     * Returns a StreamAddressResponse object from its log tail, epoch, and List\n+     * of address map entries, each consisting of a UUID and a StreamAddressSpace,\n+     * represented in Protobuf.\n+     *\n+     * @param tail   the log tail\n+     * @param epoch  the epoch the response was sealed with\n+     * @param map    a list of address map entries represented in Protobuf\n+     * @return       an equivalent StreamsAddressResponse object\n+     */\n+    public static StreamsAddressResponse getStreamsAddressResponse(long tail, long epoch,\n+                                                                   List<UuidToStreamAddressSpacePairMsg> map) {\n+        StreamsAddressResponse response = new StreamsAddressResponse(tail,\n+                map.stream().collect(Collectors.<UuidToStreamAddressSpacePairMsg, UUID, StreamAddressSpace>toMap(\n+                        entry -> getUUID(entry.getStreamUuid()),\n+                        entry -> getStreamAddressSpace(entry.getAddressSpace())\n+                )));\n+\n+        response.setEpoch(epoch);\n+        return response;\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDY1NzUyMQ==", "bodyText": "There's actually an identical method in CorfuProtocolSequencer. My original intent was to place this method in CorfuProtocolCommon since it is used by both the Sequencer and LogUnit, but I must have missed this. Given that this can be used by both servers, I think it would be better to leave the implementation in CorfuProtocolCommon and remove the references to the one in CorfuProtocolSequencer. This would avoid duplication.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564657521", "createdAt": "2021-01-26T16:37:33Z", "author": {"login": "zfrenette"}, "path": "runtime/src/main/java/org/corfudb/protocols/CorfuProtocolCommon.java", "diffHunk": "@@ -255,6 +257,28 @@ public static StreamAddressRangeMsg getStreamAddressRangeMsg(StreamAddressRange\n                 .build();\n     }\n \n+    /**\n+     * Returns a StreamAddressResponse object from its log tail, epoch, and List\n+     * of address map entries, each consisting of a UUID and a StreamAddressSpace,\n+     * represented in Protobuf.\n+     *\n+     * @param tail   the log tail\n+     * @param epoch  the epoch the response was sealed with\n+     * @param map    a list of address map entries represented in Protobuf\n+     * @return       an equivalent StreamsAddressResponse object\n+     */\n+    public static StreamsAddressResponse getStreamsAddressResponse(long tail, long epoch,\n+                                                                   List<UuidToStreamAddressSpacePairMsg> map) {\n+        StreamsAddressResponse response = new StreamsAddressResponse(tail,\n+                map.stream().collect(Collectors.<UuidToStreamAddressSpacePairMsg, UUID, StreamAddressSpace>toMap(\n+                        entry -> getUUID(entry.getStreamUuid()),\n+                        entry -> getStreamAddressSpace(entry.getAddressSpace())\n+                )));\n+\n+        response.setEpoch(epoch);\n+        return response;\n+    }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2MTk4OA=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzM4Mzk1OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitClient.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo1OToyNVrOIaB4xQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo1OToyNVrOIaB4xQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2NDgwNQ==", "bodyText": "Please use more descriptive variable names.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564164805", "createdAt": "2021-01-26T01:59:25Z", "author": {"login": "vjeko"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitClient.java", "diffHunk": "@@ -79,10 +86,12 @@ public Integer getPort() {\n         Timer.Context context = getTimerContext(\"writeObject\");\n         ByteBuf payload = Unpooled.buffer();\n         Serializers.CORFU.serialize(writeObject, payload);\n-        WriteRequest wr = new WriteRequest(DataType.DATA, payload);\n-        wr.setBackpointerMap(backpointerMap);\n-        wr.setGlobalAddress(address);\n-        CompletableFuture<Boolean> cf = sendMessageWithFuture(CorfuMsgType.WRITE.payloadMsg(wr));\n+        LogData ld = new LogData(DataType.DATA, payload);\n+        ld.setBackpointerMap(backpointerMap);\n+        ld.setGlobalAddress(address);\n+        CompletableFuture<Boolean> cf = sendRequestWithFuture(\n+                getWriteLogRequestMsg(ld), false, false);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzM4NTA5OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMTo1OTo1OFrOIaB5Yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMToxNDoxNFrOIaq7Dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2NDk2Mg==", "bodyText": "Same comment here -- passing false, false here is very error prone.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564164962", "createdAt": "2021-01-26T01:59:58Z", "author": {"login": "vjeko"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitClient.java", "diffHunk": "@@ -79,10 +86,12 @@ public Integer getPort() {\n         Timer.Context context = getTimerContext(\"writeObject\");\n         ByteBuf payload = Unpooled.buffer();\n         Serializers.CORFU.serialize(writeObject, payload);\n-        WriteRequest wr = new WriteRequest(DataType.DATA, payload);\n-        wr.setBackpointerMap(backpointerMap);\n-        wr.setGlobalAddress(address);\n-        CompletableFuture<Boolean> cf = sendMessageWithFuture(CorfuMsgType.WRITE.payloadMsg(wr));\n+        LogData ld = new LogData(DataType.DATA, payload);\n+        ld.setBackpointerMap(backpointerMap);\n+        ld.setGlobalAddress(address);\n+        CompletableFuture<Boolean> cf = sendRequestWithFuture(\n+                getWriteLogRequestMsg(ld), false, false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDgzNzEzNQ==", "bodyText": "For similar reasons as mentioned here #2836 (comment), I'll address this in another PR.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564837135", "createdAt": "2021-01-26T21:14:14Z", "author": {"login": "zfrenette"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitClient.java", "diffHunk": "@@ -79,10 +86,12 @@ public Integer getPort() {\n         Timer.Context context = getTimerContext(\"writeObject\");\n         ByteBuf payload = Unpooled.buffer();\n         Serializers.CORFU.serialize(writeObject, payload);\n-        WriteRequest wr = new WriteRequest(DataType.DATA, payload);\n-        wr.setBackpointerMap(backpointerMap);\n-        wr.setGlobalAddress(address);\n-        CompletableFuture<Boolean> cf = sendMessageWithFuture(CorfuMsgType.WRITE.payloadMsg(wr));\n+        LogData ld = new LogData(DataType.DATA, payload);\n+        ld.setBackpointerMap(backpointerMap);\n+        ld.setGlobalAddress(address);\n+        CompletableFuture<Boolean> cf = sendRequestWithFuture(\n+                getWriteLogRequestMsg(ld), false, false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE2NDk2Mg=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzQyNTEzOnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMjoxNzo1OFrOIaCPVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQxNTo1MDozMFrOIadnvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE3MDU4Mg==", "bodyText": "Can't the handler be of return type void?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564170582", "createdAt": "2021-01-26T02:17:58Z", "author": {"login": "vjeko"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "diffHunk": "@@ -40,204 +46,237 @@ public LogUnitClient getClient(long epoch, UUID clusterID) {\n      * The handler and handlers which implement this client.\n      */\n     @Getter\n-    public ClientMsgHandler msgHandler = new ClientMsgHandler(this)\n-            .generateHandlers(MethodHandles.lookup(), this);\n-\n-    /**\n-     * For old CorfuMsg, use {@link #msgHandler}\n-     * The handler and handlers which implement this client.\n-     */\n-    @Getter\n     public ClientResponseHandler responseHandler = new ClientResponseHandler(this)\n             .generateHandlers(MethodHandles.lookup(), this)\n             .generateErrorHandlers(MethodHandles.lookup(), this);\n \n     /**\n-     * Handle an WRITE_OK message.\n+     * Handle a write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @return True, since this indicates success.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return Always True, since the write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.WRITE_OK)\n-    private static Object handleOk(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+    @ResponseHandler(type = PayloadCase.WRITE_LOG_RESPONSE)\n+    private static Object handleWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n         return true;\n     }\n \n     /**\n-     * Handle an ERROR_TRIMMED message.\n+     * Handle a range write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws TrimmedException if address has already been trimmed.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return Always True, since the range write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_TRIMMED)\n-    private static Object handleTrimmed(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new TrimmedException();\n+    @ResponseHandler(type = PayloadCase.RANGE_WRITE_LOG_RESPONSE)\n+    private static Object handleRangeWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle an ERROR_OVERWRITE message.\n+     * Handle a read log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OverwriteException Throws OverwriteException if address has already been written to.\n+     * @param msg The read log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return {@link ReadResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_OVERWRITE)\n-    private static Object handleOverwrite(CorfuPayloadMsg<Integer> msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new OverwriteException(OverwriteCause.fromId(msg.getPayload()));\n+    @ResponseHandler(type = PayloadCase.READ_LOG_RESPONSE)\n+    private static Object handleReadLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getReadResponse(msg.getPayload().getReadLogResponse());\n     }\n \n     /**\n-     * Handle an ERROR_OOS message.\n+     * Handle a inspect addresses response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OutOfSpaceException Throws OutOfSpaceException if log unit out of space.\n+     * @param msg The inspect addresses response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return {@link InspectAddressesResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_OOS)\n-    private static Object handleOos(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new OutOfSpaceException();\n+    @ResponseHandler(type = PayloadCase.INSPECT_ADDRESSES_RESPONSE)\n+    private static Object handleInspectResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getInspectAddressesResponse(msg.getPayload().getInspectAddressesResponse());\n     }\n \n     /**\n-     * Handle an ERROR_RANK message.\n+     * Handle a trim log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws Exception if write has been outranked.\n+     * @param msg The trim log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return Always True, since the trim log was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_RANK)\n-    private static Object handleOutranked(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new Exception(\"rank\");\n+    @ResponseHandler(type = PayloadCase.TRIM_LOG_RESPONSE)\n+    private static Object handleTrimLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDYxOTE5Ng==", "bodyText": "No, they are supposed to match the FunctionalInterface specified in ClientResponseHandler", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564619196", "createdAt": "2021-01-26T15:50:30Z", "author": {"login": "xcchang"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "diffHunk": "@@ -40,204 +46,237 @@ public LogUnitClient getClient(long epoch, UUID clusterID) {\n      * The handler and handlers which implement this client.\n      */\n     @Getter\n-    public ClientMsgHandler msgHandler = new ClientMsgHandler(this)\n-            .generateHandlers(MethodHandles.lookup(), this);\n-\n-    /**\n-     * For old CorfuMsg, use {@link #msgHandler}\n-     * The handler and handlers which implement this client.\n-     */\n-    @Getter\n     public ClientResponseHandler responseHandler = new ClientResponseHandler(this)\n             .generateHandlers(MethodHandles.lookup(), this)\n             .generateErrorHandlers(MethodHandles.lookup(), this);\n \n     /**\n-     * Handle an WRITE_OK message.\n+     * Handle a write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @return True, since this indicates success.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return Always True, since the write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.WRITE_OK)\n-    private static Object handleOk(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+    @ResponseHandler(type = PayloadCase.WRITE_LOG_RESPONSE)\n+    private static Object handleWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n         return true;\n     }\n \n     /**\n-     * Handle an ERROR_TRIMMED message.\n+     * Handle a range write log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws TrimmedException if address has already been trimmed.\n+     * @param msg The write log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return Always True, since the range write was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_TRIMMED)\n-    private static Object handleTrimmed(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new TrimmedException();\n+    @ResponseHandler(type = PayloadCase.RANGE_WRITE_LOG_RESPONSE)\n+    private static Object handleRangeWriteLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }\n \n     /**\n-     * Handle an ERROR_OVERWRITE message.\n+     * Handle a read log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OverwriteException Throws OverwriteException if address has already been written to.\n+     * @param msg The read log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return {@link ReadResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_OVERWRITE)\n-    private static Object handleOverwrite(CorfuPayloadMsg<Integer> msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new OverwriteException(OverwriteCause.fromId(msg.getPayload()));\n+    @ResponseHandler(type = PayloadCase.READ_LOG_RESPONSE)\n+    private static Object handleReadLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getReadResponse(msg.getPayload().getReadLogResponse());\n     }\n \n     /**\n-     * Handle an ERROR_OOS message.\n+     * Handle a inspect addresses response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws OutOfSpaceException Throws OutOfSpaceException if log unit out of space.\n+     * @param msg The inspect addresses response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return {@link InspectAddressesResponse} sent back from server.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_OOS)\n-    private static Object handleOos(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new OutOfSpaceException();\n+    @ResponseHandler(type = PayloadCase.INSPECT_ADDRESSES_RESPONSE)\n+    private static Object handleInspectResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return getInspectAddressesResponse(msg.getPayload().getInspectAddressesResponse());\n     }\n \n     /**\n-     * Handle an ERROR_RANK message.\n+     * Handle a trim log response from the server.\n      *\n-     * @param msg Incoming Message\n-     * @param ctx Context\n-     * @param r   Router\n-     * @throws Exception Throws Exception if write has been outranked.\n+     * @param msg The trim log response message.\n+     * @param ctx The context the message was sent under.\n+     * @param r   A reference to the router.\n+     * @return Always True, since the trim log was successful.\n      */\n-    @ClientHandler(type = CorfuMsgType.ERROR_RANK)\n-    private static Object handleOutranked(CorfuMsg msg, ChannelHandlerContext ctx, IClientRouter r)\n-            throws Exception {\n-        throw new Exception(\"rank\");\n+    @ResponseHandler(type = PayloadCase.TRIM_LOG_RESPONSE)\n+    private static Object handleTrimLogResponse(ResponseMsg msg, ChannelHandlerContext ctx, IClientRouter r) {\n+        return true;\n     }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE3MDU4Mg=="}, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzQzNDY1OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/clients/NettyClientRouter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMjoyMjowNFrOIaCUjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMjoyMjowNFrOIaCUjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE3MTkxNw==", "bodyText": "No need for it.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564171917", "createdAt": "2021-01-26T02:22:04Z", "author": {"login": "vjeko"}, "path": "runtime/src/main/java/org/corfudb/runtime/clients/NettyClientRouter.java", "diffHunk": "@@ -292,7 +292,9 @@ public IClientRouter addClient(IClient client) {\n                         log.trace(\"Registered {} to handle messages of type {}\", client, x);\n                     });\n         } catch (UnsupportedOperationException ex) {\n-            log.error(\"No registered CorfuMsg handler for client {}\", client, ex);\n+            if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzQzNTU4OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/runtime/clients/TestClientRouter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMjoyMjozMFrOIaCVFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMjoyMjozMFrOIaCVFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE3MjA1Mw==", "bodyText": "Not needed.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564172053", "createdAt": "2021-01-26T02:22:30Z", "author": {"login": "vjeko"}, "path": "test/src/test/java/org/corfudb/runtime/clients/TestClientRouter.java", "diffHunk": "@@ -203,10 +203,11 @@ public IClientRouter addClient(IClient client) {\n                         log.trace(\"Registered {} to handle messages of type {}\", client, x);\n                     });\n         } catch (UnsupportedOperationException ex) {\n-            log.error(\"No registered CorfuMsg handler for client {}\", client, ex);\n+            if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1MzQzNTcyOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/infrastructure/TestServerRouter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMjoyMjozN1rOIaCVLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQwMjoyMjozN1rOIaCVLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDE3MjA3OQ==", "bodyText": "Not needed.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564172079", "createdAt": "2021-01-26T02:22:37Z", "author": {"login": "vjeko"}, "path": "test/src/test/java/org/corfudb/infrastructure/TestServerRouter.java", "diffHunk": "@@ -127,10 +134,11 @@ public void addServer(AbstractServer server) {\n                 log.trace(\"Registered {} to handle messages of type {}\", server, x);\n             });\n         } catch (UnsupportedOperationException ex) {\n-            log.error(\"No registered CorfuMsg handler for server {}\", server, ex);\n+            if (log.isTraceEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1NzUzMzYxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMDozODoyNVrOIapsEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMDozODoyNVrOIapsEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDgxNjkxMg==", "bodyText": "Note: this method can be removed since this is the default behaviour of AbstractServer.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2836#discussion_r564816912", "createdAt": "2021-01-26T20:38:25Z", "author": {"login": "zfrenette"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -404,23 +452,26 @@ private void handleFlushCacheRequest(CorfuMsg msg, ChannelHandlerContext ctx, IS\n      */\n     @Override\n     public void sealServerWithEpoch(long epoch) {\n-        CorfuPayloadMsg<Long> msg = new CorfuPayloadMsg<>();\n-        msg.setEpoch(epoch);\n-        msg.setPriorityLevel(PriorityLevel.HIGH);\n+        RequestMsg batchProcessorMsg = getRequestMsg(\n+                getHighPriorityHeaderMsg(HeaderMsg.newBuilder().setEpoch(epoch).build()),\n+                getSealRequestMsg(epoch)\n+        );\n+\n         try {\n-            batchWriter.addTask(SEAL, msg).join();\n+            batchWriter.addTask(BatchWriterOperation.Type.SEAL, batchProcessorMsg).join();\n         } catch (CompletionException ce) {\n             if (ce.getCause() instanceof WrongEpochException) {\n                 // The BaseServer expects to observe this exception,\n                 // when it happens, so it needs to be unwrapped\n                 throw (WrongEpochException) ce.getCause();\n             }\n         }\n+\n         log.info(\"LogUnit sealServerWithEpoch: sealed and flushed with epoch {}\", epoch);\n     }\n \n     @Override\n-    public boolean isServerReadyToHandleMsg(CorfuMsg msg) {\n+    public boolean isServerReadyToHandleMsg(RequestMsg request) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db8734fa293797e78b1b57b8e73b5aaf122e398a"}, "originalPosition": 637}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1809, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}