{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ5MjEwMzA4", "number": 2635, "reviewThreads": {"totalCount": 28, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQwNToyNjoyNFrOEWauhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoyMVrOEWf0yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxOTQyMDIzOnYy", "diffSide": "RIGHT", "path": "common/src/main/java/org/corfudb/common/util/ObservableValue.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQwNToyNjoyNFrOG9tr1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQwNToyNjoyNFrOG9tr1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2NDgyMw==", "bodyText": "Code reformat please", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467364823", "createdAt": "2020-08-08T05:26:24Z", "author": {"login": "xnull"}, "path": "common/src/main/java/org/corfudb/common/util/ObservableValue.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package org.corfudb.common.util;\n+\n+import java.util.Observable;\n+\n+/**\n+ * This class represents an observable value of type int, i.e.,\n+ * an object that the application will mark as observable, in order\n+ * to receive notifications on change.\n+ *\n+ * This is used to block and control tests.\n+ */\n+public class ObservableValue extends Observable\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94a897597b66a4bd6c119313244c71eabd88af9d"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxOTQyMTMzOnYy", "diffSide": "RIGHT", "path": "infrastructure/proto/log_replication_cluster_info.proto", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQwNToyODoyNlrOG9tsUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQwNToyODoyNlrOG9tsUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2NDk0NQ==", "bodyText": "TODO seems not completed", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467364945", "createdAt": "2020-08-08T05:28:26Z", "author": {"login": "xnull"}, "path": "infrastructure/proto/log_replication_cluster_info.proto", "diffHunk": "@@ -0,0 +1,36 @@\n+syntax = \"proto3\";\n+\n+package org.corfudb.infrastructure.logreplication.proto;\n+\n+// Multi-Cluster Topology configuration\n+message TopologyConfigurationMsg {\n+  uint64 topologyConfigID = 1;   // This ID tracks changes in the topology configuration\n+  uint64 version = 2;            // The version of ... (TODO: @maxi, can you add description?)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94a897597b66a4bd6c119313244c71eabd88af9d"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxOTQyMzk0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationRuntimeParameters.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQwNTozMjowOVrOG9tthw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQwNTozMjowOVrOG9tthw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2NTI1NQ==", "bodyText": "Is this delombok-ed? Please use @builder instead", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467365255", "createdAt": "2020-08-08T05:32:09Z", "author": {"login": "xnull"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationRuntimeParameters.java", "diffHunk": "@@ -0,0 +1,270 @@\n+package org.corfudb.infrastructure;\n+\n+import io.netty.channel.ChannelOption;\n+import io.netty.channel.EventLoopGroup;\n+import lombok.Data;\n+import org.corfudb.comm.ChannelImplementation;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.transport.IChannelContext;\n+import org.corfudb.protocols.wireprotocol.MsgHandlingFilter;\n+\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.runtime.RuntimeParameters;\n+import org.corfudb.runtime.RuntimeParametersBuilder;\n+import org.corfudb.util.MetricsUtils;\n+\n+import java.lang.Thread.UncaughtExceptionHandler;\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Log Replication Runtime Parameters (a runtime is specific per remote cluster)\n+ */\n+@Data\n+public class LogReplicationRuntimeParameters extends RuntimeParameters {\n+\n+    // Remote Cluster Descriptor\n+    private ClusterDescriptor remoteClusterDescriptor;\n+\n+    // Local Corfu Endpoint (used for database access)\n+    private String localCorfuEndpoint;\n+\n+    // Local Cluster Identifier\n+    private String localClusterId;\n+\n+    // Log Replication Configuration (streams to replicate)\n+    private LogReplicationConfig replicationConfig;\n+\n+    // Plugin File Path (file with plugin configurations - absolute paths of JAR and canonical name of classes)\n+    private String pluginFilePath;\n+\n+    // Topology Configuration Identifier (configuration epoch)\n+    private long topologyConfigId;\n+\n+    // Log Replication Channel Context\n+    private IChannelContext channelContext;\n+\n+    public static LogReplicationRuntimeParametersBuilder builder() {\n+        return new LogReplicationRuntimeParametersBuilder();\n+    }\n+\n+    public static class LogReplicationRuntimeParametersBuilder extends RuntimeParametersBuilder {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94a897597b66a4bd6c119313244c71eabd88af9d"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NDkxOnYy", "diffSide": "RIGHT", "path": "scripts/corfu_replication_server.sh", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMjo1N1rOG90-Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMjo1N1rOG90-Dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE3NQ==", "bodyText": "Codacy found an issue: Use $(...) notation instead of legacy backticked ....", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484175", "createdAt": "2020-08-08T17:02:57Z", "author": {"login": "corfudb-bot"}, "path": "scripts/corfu_replication_server.sh", "diffHunk": "@@ -0,0 +1,50 @@\n+#!/usr/bin/env bash\n+\n+if [ \"$JAVA_HOME\" != \"\" ]; then\n+  JAVA=\"$JAVA_HOME/bin/java\"\n+else\n+  JAVA=java\n+fi\n+\n+CORFUDBBINDIR=\"${CORFUDBBINDIR:-/usr/bin}\"\n+CORFUDB_PREFIX=\"${CORFUDBBINDIR}/..\"\n+\n+SOURCE=\"${BASH_SOURCE[0]}\"\n+while [ -h \"$SOURCE\" ]; do # resolve $SOURCE until the file is no longer a symlink\n+  DIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\"\n+  SOURCE=\"$(readlink \"$SOURCE\")\"\n+  [[ $SOURCE != /* ]] && SOURCE=\"$DIR/$SOURCE\" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located\n+done\n+DIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\"\n+\n+if ls \"${DIR}\"/../target/*.jar > /dev/null 2>&1; then\n+  # echo \"Running from development source\"\n+  CLASSPATH=(\"${DIR}\"/../infrastructure/target/infrastructure-*-shaded.jar)\n+else\n+  CLASSPATH=(\"${CORFUDB_PREFIX}\"/share/corfu/lib/*.jar)\n+fi\n+\n+# Windows (cygwin) support\n+case \"`uname`\" in\n+    CYGWIN*) cygwin=true ;;\n+    *) cygwin=false ;;\n+esac\n+\n+if $cygwin\n+then\n+    CLASSPATH=`cygpath -wp \"$CLASSPATH\"`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NDkzOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMjo1OFrOG90-Eg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMjo1OFrOG90-Eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE3OA==", "bodyText": "Codacy found an issue: Use equals() to compare object references.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484178", "createdAt": "2020-08-08T17:02:58Z", "author": {"login": "corfudb-bot"}, "path": "test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java", "diffHunk": "@@ -0,0 +1,588 @@\n+package org.corfudb.infrastructure.logreplication;\n+\n+import com.google.common.reflect.TypeToken;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.EmptyDataSender;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.EmptySnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.InSnapshotSyncState;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationFSM;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationState;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationStateType;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestDataSender;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestLogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestReaderConfiguration;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestSnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.DefaultReadProcessor;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.LogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsSnapshotReader;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.SnapshotReader;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent.LogReplicationEventType;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.view.AbstractViewTest;\n+import org.corfudb.runtime.view.Address;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Observable;\n+import java.util.Observer;\n+import java.util.Queue;\n+import java.util.UUID;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Semaphore;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Slf4j\n+/**\n+ * Test Log Replication FSM.\n+ */\n+public class LogReplicationFSMTest extends AbstractViewTest implements Observer {\n+\n+    // Parameters for writes\n+    private static final int NUM_ENTRIES = 10;\n+    private static final int LARGE_NUM_ENTRIES = 100;\n+    private static final String PAYLOAD_FORMAT = \"%s hello world\";\n+    private static final String TEST_STREAM_NAME = \"StreamA\";\n+    private static final int BATCH_SIZE = 2;\n+    private static final int WAIT_TIME = 100;\n+    private static final int CORFU_PORT = 9000;\n+    private static final int TEST_TOPOLOGY_CONFIG_ID = 1;\n+    private static final String TEST_LOCAL_CLUSTER_ID = \"local_cluster\";\n+\n+    // This semaphore is used to block until the triggering event causes the transition to a new state\n+    private final Semaphore transitionAvailable = new Semaphore(1, true);\n+    // We observe the transition counter to know that a transition occurred.\n+    private ObservableValue transitionObservable;\n+\n+    // Flag indicating if we should observer a snapshot sync, this is to interrupt it at any given stage\n+    private boolean observeSnapshotSync = false;\n+    private int limitSnapshotMessages = 0;\n+    private ObservableValue snapshotMessageCounterObservable;\n+\n+    private LogReplicationFSM fsm;\n+    private CorfuRuntime runtime;\n+    private DataSender dataSender;\n+    private SnapshotReader snapshotReader;\n+    private LogEntryReader logEntryReader;\n+    private LogReplicationAckReader ackReader;\n+\n+    @Before\n+    public void setRuntime() {\n+        runtime = getDefaultRuntime();\n+        runtime.getParameters().setCodecType(Codec.Type.NONE);\n+    }\n+\n+    @After\n+    public void stopAckReader() {\n+        ackReader.shutdown();\n+    }\n+\n+    /**\n+     * Verify state machine behavior in the most simple (no error) path.\n+     *\n+     * This is the sequence of events triggered and expected state change:\n+     *\n+     * (1) None -> verify FSM initial state is INITIALIZED\n+     * (2) Replication Stop -> verify it stays in the INITIALIZED state as replication has not been started\n+     * (3) Replication Start -> IN_LOG_ENTRY_SYNC state\n+     * (4) Snapshot Sync Request -> IN_SNAPSHOT_SYNC state\n+     * (5) Snapshot Sync Complete -> IN_LOG_ENTRY_SYNC state\n+     * (6) Replication Stop -> back to INITIALIZED state\n+     *\n+     */\n+    @Test\n+    public void testLogReplicationFSMTransitions() throws Exception {\n+\n+        initLogReplicationFSM(ReaderImplementation.EMPTY);\n+\n+        // Initial state: Initialized\n+        LogReplicationState initState = fsm.getState();\n+        assertThat(initState.getType()).isEqualTo(LogReplicationStateType.INITIALIZED);\n+\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Replication Stop (without any replication having started)\n+        transition(LogReplicationEventType.REPLICATION_STOP, LogReplicationStateType.INITIALIZED);\n+\n+        // Transition #2: Replication Start\n+        transition(LogReplicationEventType.REPLICATION_START, LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        // Transition #3: Snapshot Sync Request\n+        UUID snapshotSyncId = transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC, true);\n+\n+        // Transition #4: Snapshot Sync Complete\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE, LogReplicationStateType.IN_LOG_ENTRY_SYNC, snapshotSyncId, false);\n+\n+        // Transition #5: Stop Replication\n+        // Next transition might not be to INITIALIZED, as IN_LOG_ENTRY_SYNC state might have enqueued\n+        // a continuation before the stop is enqueued.\n+        transition(LogReplicationEventType.REPLICATION_STOP, LogReplicationStateType.INITIALIZED, true);\n+    }\n+\n+    /**\n+     * Test Trim Exception Events for Log Replication FSM\n+     *\n+     * This is the sequence of events triggered and expected state change:\n+     *\n+     * (1) Snapshot Sync Request => IN_SNAPSHOT_SYNC state\n+     * (2) Trimmed Exception (incorrect id) => IN_LOG_ENTRY_SYNC\n+     * (3) Trimmed Exception (for state in (5)) => IN_REQUIRE_SNAPSHOT_SYNC\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testTrimExceptionFSM() throws Exception {\n+        initLogReplicationFSM(ReaderImplementation.EMPTY);\n+\n+        // Initial acquire of the semaphore, so the occurrence of the transition releases it for the transition itself.\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Snapshot Sync Request\n+        transition(LogReplicationEventType.REPLICATION_START, LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        // A SYNC_CANCEL due to a trimmed exception, is an internal event generated during read in the log entry or\n+        // snapshot sync state, to ensure it is triggered during the state, and not before the task is\n+        // actually started on the worker thread, let's insert a delay.\n+        insertDelay(WAIT_TIME);\n+\n+        // Transition #2: Trimmed Exception on Log Entry Sync for an invalid event id, this should not be taken as\n+        // a valid trimmed exception for the current state, hence it remains in the same state\n+        transition(LogReplicationEventType.SYNC_CANCEL, LogReplicationStateType.IN_LOG_ENTRY_SYNC, UUID.randomUUID(), false);\n+\n+        // Transition #3: Trimmed Exception\n+        // Because this is an internal state, we need to capture the actual event id internally generated\n+        UUID logEntrySyncID = fsm.getStates().get(LogReplicationStateType.IN_LOG_ENTRY_SYNC).getTransitionEventId();\n+        transition(LogReplicationEventType.SYNC_CANCEL, LogReplicationStateType.IN_SNAPSHOT_SYNC, logEntrySyncID, true);\n+    }\n+\n+    private void insertDelay(int timeMilliseconds) throws InterruptedException {\n+        sleep(timeMilliseconds);\n+    }\n+\n+    /**\n+     * Test SnapshotSender through dummy implementations of the SnapshotReader and DataSender.\n+     *\n+     * (1) Initiate the Log Replication State Machine (which defaults to the INITIALIZED State)\n+     * (2) Write NUM_ENTRIES to the database in a consecutive address space for a given stream.\n+     * (3) Enforce event to initialize SNAPSHOT_SYNC.\n+     * (4) When SNAPSHOT_SYNC is completed the FSM should transition to a new state IN_LOG_ENTRY_SYNC. Block until\n+     * this transition occurs.\n+     * (5) Once this transition occurs verify that the Listener has received the same data written in (2).\n+     *\n+     * In this test we assume the SnapshotReader reads all NUM_ENTRIES in a single call (no batching)\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testLogReplicationSnapshotTransmitterNoBatch() throws Exception {\n+        testSnapshotSender(NUM_ENTRIES);\n+    }\n+\n+    /**\n+     * Test SnapshotSender through dummy implementations of the SnapshotReader and DataSender.\n+     *\n+     * (1) Initiate the Log Replication State Machine (which defaults to the INITIALIZED State)\n+     * (2) Write NUM_ENTRIES to the database in a consecutive address space for a given stream.\n+     * (3) Enforce event to initialize SNAPSHOT_SYNC.\n+     * (4) When SNAPSHOT_SYNC is completed the FSM should transition to a new state IN_LOG_ENTRY_SYNC. Block until\n+     * this transition occurs.\n+     * (5) Once this transition occurs verify that the Listener has received the same data written in (2).\n+     *\n+     * In this test we assume the SnapshotReader reads NUM_ENTRIES in batches, and confirm all NUM_ENTRIES are\n+     * received by the listener.\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testLogReplicationSnapshotTransmitterBatch() throws Exception {\n+        testSnapshotSender(BATCH_SIZE);\n+    }\n+\n+    private void testSnapshotSender(int batchSize) throws Exception {\n+\n+        // Initialize State Machine\n+        initLogReplicationFSM(ReaderImplementation.TEST);\n+\n+        // Modify test configuration to the specified batch size\n+        ((TestSnapshotReader)snapshotReader).setBatchSize(batchSize);\n+\n+        // Write NUM_ENTRIES to streamA\n+        List<TokenResponse> writeTokens = writeToStream();\n+\n+        List<Long> seqNums = new ArrayList<>();\n+        writeTokens.forEach(token -> seqNums.add(token.getSequence()));\n+\n+        // Write to Stream will write to some addresses.  SnapshotReader should only read from those addresses\n+        ((TestSnapshotReader) snapshotReader).setSeqNumsToRead(seqNums);\n+\n+        // Initial acquire of semaphore, the transition method will block until a transition occurs\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Snapshot Sync Request\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC);\n+\n+        // Block until the snapshot sync completes and next transition occurs.\n+        // The transition should happen to IN_LOG_ENTRY_SYNC state.\n+        Queue<LogReplicationEntry> listenerQueue = ((TestDataSender) dataSender).getEntryQueue();\n+\n+        while(!fsm.getState().getType().equals(LogReplicationStateType.IN_LOG_ENTRY_SYNC)) {\n+            transitionAvailable.acquire();\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+        assertThat(listenerQueue.size()).isEqualTo(NUM_ENTRIES);\n+\n+        for (int i = 0; i < NUM_ENTRIES; i++) {\n+            assertThat(listenerQueue.poll().getPayload())\n+                    .isEqualTo( String.format(PAYLOAD_FORMAT, i).getBytes());\n+        }\n+    }\n+\n+    /**\n+     * This test verifies that canceling a snapshot sync which is in progress, takes log replication\n+     * back to the INITIALIZED state and that snapshot sync can be retried and completed successfully.\n+     *\n+     * (1) Write NUM_ENTRIES to StreamA\n+     * (2) Trigger start of SNAPSHOT_SYNC\n+     * (3) Interrupt/Stop snapshot sync when 2 messages have been sent to the remote site.\n+     * (4) Re-trigger SNAPSHOT_SYNC\n+     * (5) Check for completeness, i.e., that state has changed to IN_LOG_ENTRY_SYNC\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void cancelSnapshotSyncInProgressAndRetry() throws Exception {\n+        // This test needs to observe the number of messages generated during snapshot sync to interrupt/stop it,\n+        // before it completes.\n+        observeSnapshotSync = true;\n+\n+        // Initialize State Machine\n+        initLogReplicationFSM(ReaderImplementation.TEST);\n+\n+        // Modify test configuration to the specified batch size (since we write NUM_ENTRIES = 10) and we send in\n+        // batches of BATCH_SIZE = 2, we will stop snapshot sync at 2 sent messages.\n+        ((TestSnapshotReader)snapshotReader).setBatchSize(BATCH_SIZE);\n+        limitSnapshotMessages = 2;\n+\n+        // Write NUM_ENTRIES to streamA\n+        List<TokenResponse> writeTokens = writeToStream();\n+\n+        List<Long> seqNums = new ArrayList<>();\n+        writeTokens.forEach(token -> seqNums.add(token.getSequence()));\n+\n+        // Write to Stream will write to some addresses.  SnapshotReader should only read from those addresses\n+        ((TestSnapshotReader) snapshotReader).setSeqNumsToRead(seqNums);\n+\n+        // Initial acquire of semaphore, the transition method will block until a transition occurs\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Snapshot Sync Request\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC);\n+\n+        // We observe the number of transmitted messages and force a REPLICATION_STOP, when 2 messages have been sent\n+        // so we verify the state moves to INITIALIZED again.\n+        transitionAvailable.acquire();\n+        fsm.input(new LogReplicationEvent(LogReplicationEventType.REPLICATION_STOP));\n+\n+        transitionAvailable.acquire();\n+\n+        while (fsm.getState().getType() != LogReplicationStateType.INITIALIZED) {\n+            // Wait on a FSM transition to occur\n+            transitionAvailable.acquire();\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(LogReplicationStateType.INITIALIZED);\n+\n+        ((TestDataSender) dataSender).reset();\n+\n+        // Stop observing number of messages in snapshot sync, so this time it completes\n+        observeSnapshotSync = false;\n+\n+        // Transition #2: This time the snapshot sync completes\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC, true);\n+\n+        while (fsm.getState().getType() != LogReplicationStateType.IN_LOG_ENTRY_SYNC) {\n+            // Block until FSM moves back to in log entry (delta) sync state\n+            transitionAvailable.acquire();\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        Queue<LogReplicationEntry> listenerQueue = ((TestDataSender) dataSender).getEntryQueue();\n+\n+        assertThat(listenerQueue.size()).isEqualTo(NUM_ENTRIES);\n+\n+        for (int i=0; i<NUM_ENTRIES; i++) {\n+            assertThat(listenerQueue.poll().getPayload())\n+                    .isEqualTo( String.format(PAYLOAD_FORMAT, i).getBytes());\n+        }\n+    }\n+\n+\n+    /**\n+     * Test Snapshot Sync for Default Stream-based implementations.\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testSnapshotSyncStreamImplementation() throws Exception {\n+\n+        // Initialize State Machine\n+        initLogReplicationFSM(ReaderImplementation.STREAMS);\n+\n+        // Write LARGE_NUM_ENTRIES to streamA\n+        writeToMap();\n+\n+        // Initial acquire of semaphore, the transition method will block until a transition occurs\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Replication Start\n+        // transition(LogReplicationEventType.REPLICATION_START, LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        // Transition #2: Snapshot Sync Request\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC, true);\n+\n+        // Block until the snapshot sync completes and next transition occurs.\n+        // The transition should happen to IN_LOG_ENTRY_SYNC state.\n+        System.out.println(\"**** Wait for snapshot sync to complete\");\n+\n+        // Block until the snapshot sync completes and next transition occurs.\n+        while (fsm.getState().getType() != LogReplicationStateType.IN_LOG_ENTRY_SYNC) {\n+            log.trace(\"stateType {} expected type {}\", fsm.getState().getType(), LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        Queue<LogReplicationEntry> listenerQueue = ((TestDataSender) dataSender).getEntryQueue();\n+\n+        // Transactional puts into the stream (incremental updates)\n+        writeTxIncrementalUpdates();\n+\n+        int incrementalUpdates = 0;\n+\n+        while(incrementalUpdates < NUM_ENTRIES) {\n+           ((TestDataSender)dataSender).getEntryQueue().poll();\n+           incrementalUpdates++;\n+        }\n+\n+        assertThat(incrementalUpdates).isEqualTo(NUM_ENTRIES);\n+    }\n+\n+    private void writeTxIncrementalUpdates() {\n+        CorfuTable<String, String> map = runtime.getObjectsView()\n+                .build()\n+                .setStreamName(TEST_STREAM_NAME)\n+                .setTypeToken(new TypeToken<CorfuTable<String, String>>() {})\n+                .open();\n+\n+        for(int i=0; i<NUM_ENTRIES; i++) {\n+            runtime.getObjectsView().TXBegin();\n+            map.put(String.valueOf(i), String.valueOf(i));\n+            runtime.getObjectsView().TXEnd();\n+        }\n+    }\n+\n+    private List<TokenResponse> writeToStream() {\n+        UUID streamA = UUID.nameUUIDFromBytes(TEST_STREAM_NAME.getBytes());\n+        List<TokenResponse> writeTokens = new ArrayList<>();\n+        // Write\n+        for (int i=0; i < NUM_ENTRIES; i++) {\n+            TokenResponse response = runtime.getSequencerView().next(streamA);\n+            writeTokens.add(response);\n+            runtime.getAddressSpaceView().write(response, String.format(PAYLOAD_FORMAT, i).getBytes());\n+        }\n+\n+        // Read to verify data is there\n+        int index = 0;\n+        for (TokenResponse token : writeTokens) {\n+            assertThat(runtime.getAddressSpaceView().read((long)token.getSequence()).getPayload(getRuntime()))\n+                    .isEqualTo( String.format(PAYLOAD_FORMAT, index).getBytes());\n+            index++;\n+        }\n+        return writeTokens;\n+    }\n+\n+    private void writeToMap() {\n+        CorfuTable<String, String> map = runtime.getObjectsView()\n+                .build()\n+                .setStreamName(TEST_STREAM_NAME)\n+                .setTypeToken(new TypeToken<CorfuTable<String, String>>() {})\n+                .open();\n+\n+        for (int i=0; i<LARGE_NUM_ENTRIES; i++) {\n+            map.put(String.valueOf(i), String.valueOf(i));\n+        }\n+    }\n+\n+    /**\n+     * Initialize Log Replication FSM\n+     *\n+     * Use empty implementations for those cases where you want to verify the behavior of the state machine.\n+     *\n+     * @param readerImpl implementation to use for readers.\n+     */\n+    private void initLogReplicationFSM(ReaderImplementation readerImpl) {\n+\n+        logEntryReader = new TestLogEntryReader();\n+\n+        switch(readerImpl) {\n+            case EMPTY:\n+                // Empty implementations of log reader and listener - used for testing transitions\n+                snapshotReader = new EmptySnapshotReader();\n+                dataSender = new EmptyDataSender();\n+                break;\n+            case TEST:\n+                // Dummy implementations of log reader and listener for testing\n+                // The log reader queries the log for the config provided (stream name, number of entries)\n+                // The listener inserts what it receives into a queue\n+                TestReaderConfiguration testConfig = TestReaderConfiguration.builder()\n+                        .endpoint(getDefaultEndpoint())\n+                        .numEntries(NUM_ENTRIES)\n+                        .payloadFormat(PAYLOAD_FORMAT)\n+                        .streamName(TEST_STREAM_NAME)\n+                        .batchSize(BATCH_SIZE).build();\n+\n+                snapshotReader = new TestSnapshotReader(testConfig);\n+                dataSender = new TestDataSender();\n+                break;\n+            case STREAMS:\n+                // Default implementation used for Log Replication (stream-based)\n+                LogReplicationConfig logReplicationConfig = new LogReplicationConfig(Collections.singleton(TEST_STREAM_NAME));\n+                snapshotReader = new StreamsSnapshotReader(getNewRuntime(getDefaultNode()).connect(),\n+                        logReplicationConfig);\n+                dataSender = new TestDataSender();\n+                break;\n+            default:\n+                break;\n+        }\n+\n+        LogReplicationMetadataManager metadataManager = new LogReplicationMetadataManager(runtime, TEST_TOPOLOGY_CONFIG_ID,\n+                TEST_LOCAL_CLUSTER_ID);\n+        LogReplicationConfig config = new LogReplicationConfig(new HashSet<>(Arrays.asList(TEST_STREAM_NAME)));\n+        ackReader = new LogReplicationAckReader(metadataManager, config, runtime, TEST_LOCAL_CLUSTER_ID);\n+        fsm = new LogReplicationFSM(runtime, snapshotReader, dataSender, logEntryReader,\n+                new DefaultReadProcessor(runtime), config, new ClusterDescriptor(\"Cluster-Local\",\n+                LogReplicationClusterInfo.ClusterRole.ACTIVE, CORFU_PORT),\n+                Executors.newSingleThreadExecutor(new ThreadFactoryBuilder().setNameFormat(\"fsm-worker\").build()),\n+                ackReader);\n+        transitionObservable = fsm.getNumTransitions();\n+        transitionObservable.addObserver(this);\n+\n+        if (observeSnapshotSync) {\n+            System.out.println(\"Observe snapshot sync\");\n+            snapshotMessageCounterObservable = ((InSnapshotSyncState) fsm.getStates()\n+                    .get(LogReplicationStateType.IN_SNAPSHOT_SYNC)).getSnapshotSender().getObservedCounter();\n+            snapshotMessageCounterObservable.addObserver(this);\n+        }\n+    }\n+\n+    /**\n+     * It performs a transition, based on the given event type and asserts the FSM has moved to the expected state\n+     *\n+     * @param eventType log replication event.\n+     * @param expectedState expected state after transition is completed.\n+     * @param eventId identifier of the event.\n+     */\n+    private UUID transition(LogReplicationEventType eventType,\n+                            LogReplicationStateType expectedState,\n+                            UUID eventId, boolean waitUntilExpected)\n+            throws InterruptedException {\n+\n+        System.out.println(\"Insert event: \" + eventType);\n+\n+        LogReplicationEvent event;\n+\n+        if (eventId != null) {\n+            // For testing we are enforcing internal events (like Trimmed Exception or Snapshot Complete),\n+            // for this reason we must set the id of the event that preceded it, so it corresponds to the same state.\n+            event = new LogReplicationEvent(eventType, new LogReplicationEventMetadata(eventId));\n+        } else {\n+            event = new LogReplicationEvent(eventType);\n+        }\n+\n+        fsm.input(event);\n+\n+        transitionAvailable.acquire();\n+\n+        // Wait until the expected state\n+        while (waitUntilExpected) {\n+            if (fsm.getState().getType() == expectedState) {\n+                return event.getEventID();\n+            } else {\n+                transitionAvailable.acquire();\n+            }\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(expectedState);\n+\n+        return event.getEventID();\n+    }\n+\n+    /**\n+     * Insert an event of eventType into the Log Replication FSM and assert on the expected state.\n+     *\n+     * This method blocks until an actual transition occurs in the FSM.\n+     *\n+     * @param eventType the type of the event to input into the state machine\n+     * @param expectedState the expected state to transition to\n+     *\n+     * @return UUID of the input event\n+     *\n+     * @throws InterruptedException\n+     */\n+    private UUID transition(LogReplicationEventType eventType,\n+                            LogReplicationStateType expectedState, boolean waitUntilExpected) throws InterruptedException {\n+        return transition(eventType, expectedState, null, waitUntilExpected);\n+    }\n+\n+    private UUID transition(LogReplicationEventType eventType,\n+                            LogReplicationStateType expectedState) throws InterruptedException {\n+        return transition(eventType, expectedState, null, false);\n+    }\n+\n+    /**\n+     * Observer callback, will be called on every transition of the log replication FSM.\n+     */\n+    @Override\n+    public void update(Observable obs, Object arg) {\n+        if (obs == transitionObservable)\n+        {\n+            while (!transitionAvailable.hasQueuedThreads()) {\n+                // Wait until some thread is waiting to acquire...\n+            }\n+            transitionAvailable.release();\n+            // System.out.println(\"Transition::#\"  + transitionObservable.getValue() + \"::\" + fsm.getState().getType());\n+        } else if (obs == snapshotMessageCounterObservable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 574}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NDk0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/DiscoveryServiceEvent.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMjo1OVrOG90-FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMjo1OVrOG90-FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4MA==", "bodyText": "Codacy found an issue: Use explicit scoping instead of the default package private level", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484180", "createdAt": "2020-08-08T17:02:59Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/DiscoveryServiceEvent.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+\n+public class DiscoveryServiceEvent {\n+    DiscoveryServiceEventType type;\n+\n+    @Getter", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NDk1OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/ReplicationReaderWriterIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowMFrOG90-FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowMFrOG90-FQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4MQ==", "bodyText": "Codacy found an issue: Avoid reassigning parameters such as 'blockOnce'", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484181", "createdAt": "2020-08-08T17:03:00Z", "author": {"login": "corfudb-bot"}, "path": "test/src/test/java/org/corfudb/integration/ReplicationReaderWriterIT.java", "diffHunk": "@@ -0,0 +1,752 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogEntryWriter;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.StreamsSnapshotWriter;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.SnapshotReadMessage;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsLogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsSnapshotReader;\n+import org.corfudb.protocols.logprotocol.OpaqueEntry;\n+import org.corfudb.protocols.logprotocol.SMREntry;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.MultiCheckpointWriter;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.exceptions.SerializerException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.ObjectsView;\n+import org.corfudb.runtime.view.StreamOptions;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+import org.corfudb.util.serializer.ISerializer;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.Semaphore;\n+import java.util.stream.Stream;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Slf4j\n+public class ReplicationReaderWriterIT extends AbstractIT {\n+    private static final String DEFAULT_ENDPOINT = DEFAULT_HOST + \":\" + DEFAULT_PORT;\n+    private static final int WRITER_PORT = DEFAULT_PORT + 1;\n+    private static final String WRITER_ENDPOINT = DEFAULT_HOST + \":\" + WRITER_PORT;\n+    private static final int START_VAL = 11;\n+    private static final int NUM_KEYS = 10;\n+    private static final int NUM_STREAMS = 2;\n+    public static final int NUM_TRANSACTIONS = 20;\n+    public static final String PRIMARY_SITE_ID = \"Cluster-Paris\";\n+    public static final int BATCH_SIZE = 2;\n+\n+    // Enforce to read each entry for each message\n+    // each log entry size is 62, there are 2 log entry per dataMsg\n+    // each snapshot entry is 33, there are 4 snapshot entry per dataMsg\n+    public static final int MAX_MSG_SIZE = 160;\n+\n+    private static Semaphore waitSem = new Semaphore(1);\n+\n+    private static UUID snapshotSyncId = UUID.randomUUID();\n+\n+    private Process server1;\n+    private Process server2;\n+\n+    // Connect with server1 to generate data\n+    private CorfuRuntime srcDataRuntime = null;\n+\n+    // Connect with server1 to read snapshot data\n+    private CorfuRuntime readerRuntime = null;\n+\n+    // Connect with server2 to write snapshot data\n+    private CorfuRuntime writerRuntime = null;\n+\n+    // Connect with server2 to verify data\n+    private CorfuRuntime dstDataRuntime = null;\n+\n+    private HashMap<String, CorfuTable<Long, Long>> srcTables = new HashMap<>();\n+    private HashMap<String, CorfuTable<Long, Long>> dstTables = new HashMap<>();\n+    private HashMap<String, CorfuTable<Long, Long>> shadowTables = new HashMap<>();\n+\n+    private CorfuRuntime srcTestRuntime;\n+\n+    private CorfuRuntime dstTestRuntime;\n+\n+    /*\n+     * the in-memory data for corfu tables for verification.\n+     */\n+    private HashMap<String, HashMap<Long, Long>> srcHashMap = new HashMap<>();\n+    private HashMap<String, HashMap<Long, Long>> dstHashMap = new HashMap<>();\n+\n+    /*\n+     * store message generated by stream snapshot reader and will play it at the writer side.\n+     */\n+    private List<LogReplicationEntry> msgQ = new ArrayList<>();\n+\n+    private void setupEnv() throws IOException {\n+        // Start node one and populate it with data\n+        server1 = new CorfuServerRunner()\n+                .setHost(DEFAULT_HOST)\n+                .setPort(DEFAULT_PORT)\n+                .setSingle(true)\n+                .runServer();\n+\n+        server2 = new CorfuServerRunner()\n+                .setHost(DEFAULT_HOST)\n+                .setPort(WRITER_PORT)\n+                .setSingle(true)\n+                .runServer();\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        srcDataRuntime = CorfuRuntime.fromParameters(params);\n+        srcDataRuntime.parseConfigurationString(DEFAULT_ENDPOINT);\n+        srcDataRuntime.setTransactionLogging(true).connect();\n+\n+        srcTestRuntime = CorfuRuntime.fromParameters(params);\n+        srcTestRuntime.parseConfigurationString(DEFAULT_ENDPOINT);\n+        srcTestRuntime.setTransactionLogging(true).connect();\n+\n+        readerRuntime = CorfuRuntime.fromParameters(params);\n+        readerRuntime.parseConfigurationString(DEFAULT_ENDPOINT);\n+        readerRuntime.setTransactionLogging(true).connect();\n+\n+        writerRuntime = CorfuRuntime.fromParameters(params);\n+        writerRuntime.parseConfigurationString(WRITER_ENDPOINT);\n+        writerRuntime.setTransactionLogging(true).connect();\n+\n+        dstDataRuntime = CorfuRuntime.fromParameters(params);\n+        dstDataRuntime.parseConfigurationString(WRITER_ENDPOINT);\n+        dstDataRuntime.setTransactionLogging(true).connect();\n+\n+        dstTestRuntime = CorfuRuntime.fromParameters(params);\n+        dstTestRuntime.parseConfigurationString(WRITER_ENDPOINT);\n+        dstTestRuntime.setTransactionLogging(true).connect();\n+    }\n+\n+    public static void openStreams(HashMap<String, CorfuTable<Long, Long>> tables, CorfuRuntime rt) {\n+        openStreams(tables, rt, NUM_STREAMS, Serializers.PRIMITIVE, false);\n+    }\n+\n+    public static void openStreams(HashMap<String, CorfuTable<Long, Long>> tables, CorfuRuntime rt, int num_streams) {\n+        openStreams(tables, rt, num_streams, Serializers.PRIMITIVE);\n+    }\n+\n+    public static void openStreams(HashMap<String, CorfuTable<Long, Long>> tables, CorfuRuntime rt, int num_streams,\n+                                   ISerializer serializer, boolean shadow) {\n+        for (int i = 0; i < num_streams; i++) {\n+            String name = \"test\" + i;\n+            if (shadow) {\n+                name = name + \"_shadow\";\n+            }\n+            CorfuTable<Long, Long> table = rt.getObjectsView()\n+                    .build()\n+                    .setStreamName(name)\n+                    .setTypeToken(new TypeToken<CorfuTable<Long, Long>>() {\n+                    })\n+                    .setSerializer(serializer)\n+                    .open();\n+            tables.put(name, table);\n+        }\n+    }\n+\n+    public static void openStreams(HashMap<String, CorfuTable<Long, Long>> tables, CorfuRuntime rt, int num_streams,\n+                                                 ISerializer serializer) {\n+        openStreams(tables, rt, num_streams, serializer, false);\n+    }\n+\n+\n+    public static void generateData(HashMap<String, CorfuTable<Long, Long>> tables,\n+                      HashMap<String, HashMap<Long, Long>> hashMap,\n+                      int numKeys, CorfuRuntime rt, long startVal) {\n+        for (int i = 0; i < numKeys; i++) {\n+            for (String name : tables.keySet()) {\n+                hashMap.putIfAbsent(name, new HashMap<>());\n+                long key = i + startVal;\n+                rt.getObjectsView().TXBegin();\n+                tables.get(name).put(key, key);\n+                rt.getObjectsView().TXEnd();\n+                log.trace(\"tail \" + rt.getAddressSpaceView().getLogTail() + \" seq \" + rt.getSequencerView().query().getSequence());\n+                hashMap.get(name).put(key, key);\n+            }\n+        }\n+    }\n+\n+    // Generate data with transactions and the same time push the data to the hashtable\n+    public static void generateTransactions(HashMap<String, CorfuTable<Long, Long>> tables,\n+                      HashMap<String, HashMap<Long, Long>> hashMap,\n+                      int numT, CorfuRuntime rt, long startval) {\n+        int j = 0;\n+        for (int i = 0; i < numT; i++) {\n+            rt.getObjectsView().TXBegin();\n+            for (String name : tables.keySet()) {\n+                hashMap.putIfAbsent(name, new HashMap<>());\n+                long key = j + startval;\n+                tables.get(name).put(key, key);\n+                log.trace(\"tail \" + rt.getAddressSpaceView().getLogTail() + \" seq \" + rt.getSequencerView().query().getSequence());\n+                hashMap.get(name).put(key, key);\n+                j++;\n+            }\n+            rt.getObjectsView().TXEnd();\n+        }\n+        System.out.println(\"\\ngenerate transactions num \" + numT);\n+    }\n+\n+    public static void verifyData(String tag, HashMap<String, CorfuTable<Long, Long>> tables, HashMap<String, HashMap<Long, Long>> hashMap) {\n+        System.out.println(\"\\n\" + tag);\n+        for (String name : hashMap.keySet()) {\n+            CorfuTable<Long, Long> table = tables.get(name);\n+            HashMap<Long, Long> mapKeys = hashMap.get(name);\n+            System.out.println(\"table \" + name + \" key size \" + table.keySet().size() +\n+                    \" hashMap size \" + mapKeys.size());\n+\n+            assertThat(mapKeys.keySet().containsAll(table.keySet())).isTrue();\n+            assertThat(table.keySet().containsAll(mapKeys.keySet())).isTrue();\n+            assertThat(table.keySet().size() == mapKeys.keySet().size()).isTrue();\n+\n+            for (Long key : mapKeys.keySet()) {\n+                assertThat(table.get(key)).isEqualTo(mapKeys.get(key));\n+            }\n+        }\n+    }\n+\n+    public static void verifyTable(String tag, HashMap<String, CorfuTable<Long, Long>> tables, HashMap<String, CorfuTable<Long, Long>> hashMap) {\n+        System.out.println(\"\\n\" + tag);\n+        for (String name : hashMap.keySet()) {\n+            CorfuTable<Long, Long> table = tables.get(name);\n+            CorfuTable<Long, Long> mapKeys = hashMap.get(name);\n+            System.out.println(\"table \" + name + \" key size \" + table.keySet().size() +\n+                    \" hashMap size \" + mapKeys.size());\n+\n+            assertThat(mapKeys.keySet().containsAll(table.keySet())).isTrue();\n+            assertThat(table.keySet().containsAll(mapKeys.keySet())).isTrue();\n+            assertThat(table.keySet().size() == mapKeys.keySet().size()).isTrue();\n+\n+            for (Long key : mapKeys.keySet()) {\n+                assertThat(table.get(key)).isEqualTo(mapKeys.get(key));\n+            }\n+        }\n+    }\n+\n+    public static void verifyNoData(HashMap<String, CorfuTable<Long, Long>> tables) {\n+        for (CorfuTable table : tables.values()) {\n+            assertThat(table.keySet().isEmpty()).isTrue();\n+        }\n+    }\n+\n+\n+    void verifyTxStream(CorfuRuntime rt) {\n+        StreamOptions options = StreamOptions.builder()\n+                .cacheEntries(false)\n+                .build();\n+\n+        IStreamView txStream = rt.getStreamsView().getUnsafe(ObjectsView.TRANSACTION_STREAM_ID, options);\n+        List<ILogData> dataList = txStream.remaining();\n+        System.out.println(\"\\ndataList size \" + dataList.size());\n+        for (ILogData data : txStream.remaining()) {\n+            System.out.println(data);\n+        }\n+    }\n+\n+    public static void printTails(String tag, CorfuRuntime rt0, CorfuRuntime rt1) {\n+        System.out.println(\"\\n\" + tag);\n+        System.out.println(\"src dataTail \" + rt0.getAddressSpaceView().getLogTail());\n+        System.out.println(\"dst dataTail \" + rt1.getAddressSpaceView().getLogTail());\n+\n+    }\n+\n+    public static void readSnapLogMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt) {\n+        readSnapLogMsgs(msgQ, streams, rt, false);\n+    }\n+\n+    public static void readSnapLogMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt, boolean blockOnSem)  {\n+        int cnt = 0;\n+        LogReplicationConfig config = new LogReplicationConfig(streams, BATCH_SIZE, MAX_MSG_SIZE);\n+        StreamsSnapshotReader reader = new StreamsSnapshotReader(rt, config);\n+\n+        reader.reset(rt.getAddressSpaceView().getLogTail());\n+        while (true) {\n+            cnt++;\n+\n+            SnapshotReadMessage snapshotReadMessage = reader.read(snapshotSyncId);\n+            for (LogReplicationEntry data : snapshotReadMessage.getMessages()) {\n+                msgQ.add(data);\n+                System.out.println(\"generate msg \" + cnt);\n+            }\n+\n+            if (snapshotReadMessage.isEndRead()) {\n+                break;\n+            }\n+\n+            if  (blockOnSem) {\n+                try {\n+                    waitSem.acquire();\n+                } catch (InterruptedException e) {\n+                    log.info(\"Caught an interrupted exception \", e);\n+                }\n+                blockOnSem = false;\n+            }\n+        }\n+    }\n+\n+    public static void writeSnapLogMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt) {\n+        LogReplicationConfig config = new LogReplicationConfig(streams, BATCH_SIZE, MAX_MSG_SIZE);\n+        LogReplicationMetadataManager logReplicationMetadataManager = new LogReplicationMetadataManager(rt, 0, PRIMARY_SITE_ID);\n+        StreamsSnapshotWriter writer = new StreamsSnapshotWriter(rt, config, logReplicationMetadataManager);\n+\n+        if (msgQ.isEmpty()) {\n+            System.out.println(\"msgQ is empty\");\n+        }\n+\n+        long topologyConfigId = msgQ.get(0).getMetadata().getTopologyConfigId();\n+        long snapshot = msgQ.get(0).getMetadata().getSnapshotTimestamp();\n+        logReplicationMetadataManager.setSrcBaseSnapshotStart(topologyConfigId, snapshot);\n+        writer.reset(topologyConfigId, snapshot);\n+\n+        for (LogReplicationEntry msg : msgQ) {\n+            writer.apply(msg);\n+        }\n+\n+        Long seq = writer.getLogReplicationMetadataManager().getLastSnapSeqNum() + 1;\n+        writer.applyShadowStreams(seq);\n+    }\n+\n+    public static void readLogEntryMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt) throws TrimmedException {\n+        readLogEntryMsgs(msgQ, streams, rt, false);\n+    }\n+\n+    public static void readLogEntryMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt, boolean blockOnce) throws", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 335}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NDk2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowMVrOG90-Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowMVrOG90-Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4Mw==", "bodyText": "Codacy found an issue: Avoid throwing raw exception types.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484183", "createdAt": "2020-08-08T17:03:01Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -0,0 +1,393 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure.plugins;\n+\n+import lombok.Getter;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.infrastructure.NodeDescriptor;\n+import org.corfudb.infrastructure.logreplication.infrastructure.TopologyDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.CorfuStoreMetadata;\n+import org.corfudb.runtime.Messages;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuStreamEntries;\n+import org.corfudb.runtime.collections.CorfuStreamEntry;\n+import org.corfudb.runtime.collections.StreamListener;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.collections.TableSchema;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class extends CorfuReplicationClusterManagerAdapter, provides topology config API\n+ * for integration tests. The initial topology config should be valid, which means it has only\n+ * one active cluster, and one or more standby clusters.\n+ */\n+@Slf4j\n+public class DefaultClusterManager extends CorfuReplicationClusterManagerBaseAdapter {\n+    public static final String CONFIG_FILE_PATH = \"src/test/resources/corfu_replication_config.properties\";\n+    private static final String DEFAULT_ACTIVE_CLUSTER_NAME = \"primary_site\";\n+    private static final String DEFAULT_STANDBY_CLUSTER_NAME = \"standby_site\";\n+\n+    private static final int NUM_NODES_PER_CLUSTER = 3;\n+\n+    private static final String ACTIVE_CLUSTER_NAME = \"primary_site\";\n+    private static final String STANDBY_CLUSTER_NAME = \"standby_site\";\n+    private static final String ACTIVE_CLUSTER_CORFU_PORT = \"primary_site_corfu_portnumber\";\n+    private static final String STANDBY_CLUSTER_CORFU_PORT = \"standby_site_corfu_portnumber\";\n+    private static final String LOG_REPLICATION_SERVICE_ACTIVE_PORT_NUM = \"primary_site_portnumber\";\n+    private static final String LOG_REPLICATION_SERVICE_STANDBY_PORT_NUM = \"standby_site_portnumber\";\n+\n+    private static final String ACTIVE_CLUSTER_NODE = \"primary_site_node\";\n+    private static final String STANDBY_CLUSTER_NODE = \"standby_site_node\";\n+\n+\n+    public static final String CONFIG_NAMESPACE = \"ns_lr_config_it\";\n+    public static final String CONFIG_TABLE_NAME = \"lr_config_it\";\n+    public static final CommonTypes.Uuid OP_RESUME = CommonTypes.Uuid.newBuilder().setLsb(0L).setMsb(0L).build();\n+    public static final CommonTypes.Uuid OP_SWITCH = CommonTypes.Uuid.newBuilder().setLsb(1L).setMsb(1L).build();\n+    public static final CommonTypes.Uuid OP_TWO_ACTIVE = CommonTypes.Uuid.newBuilder().setLsb(2L).setMsb(2L).build();\n+    public static final CommonTypes.Uuid OP_ALL_STANDBY = CommonTypes.Uuid.newBuilder().setLsb(3L).setMsb(3L).build();\n+    public static final CommonTypes.Uuid OP_INVALID = CommonTypes.Uuid.newBuilder().setLsb(4L).setMsb(4L).build();\n+\n+    @Getter\n+    private long configId;\n+\n+    @Getter\n+    private boolean shutdown;\n+\n+    @Getter\n+    public ClusterManagerCallback clusterManagerCallback;\n+\n+    private Thread thread;\n+\n+    private CorfuRuntime corfuRuntime;\n+\n+    private CorfuStore corfuStore;\n+\n+    private ConfigStreamListener configStreamListener;\n+\n+    public void start() {\n+        configId = 0L;\n+        shutdown = false;\n+        topologyConfig = constructTopologyConfigMsg();\n+        clusterManagerCallback = new ClusterManagerCallback(this);\n+        corfuRuntime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder().build())\n+                .parseConfigurationString(\"localhost:9000\")\n+                .setTransactionLogging(true)\n+                .connect();\n+        corfuStore = new CorfuStore(corfuRuntime);\n+        CorfuStoreMetadata.Timestamp ts = corfuStore.getTimestamp();\n+        try {\n+            Table<Messages.Uuid, Messages.Uuid, Messages.Uuid> table = corfuStore.openTable(\n+                    CONFIG_NAMESPACE, CONFIG_TABLE_NAME,\n+                    Messages.Uuid.class, Messages.Uuid.class, Messages.Uuid.class,\n+                    TableOptions.builder().build()\n+            );\n+            table.clear();\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NDk4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/transport/client/IClientChannelAdapter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowMlrOG90-Gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowMlrOG90-Gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4Ng==", "bodyText": "Codacy found an issue: Document empty method body", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484186", "createdAt": "2020-08-08T17:03:02Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/transport/client/IClientChannelAdapter.java", "diffHunk": "@@ -0,0 +1,143 @@\n+package org.corfudb.infrastructure.logreplication.transport.client;\n+\n+import lombok.Getter;\n+\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.transport.IChannelContext;\n+import org.corfudb.runtime.Messages.CorfuMessage;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationClientRouter;\n+\n+import javax.annotation.Nonnull;\n+import java.util.Optional;\n+\n+\n+/**\n+ * Client Transport Adapter.\n+ *\n+ * Log Replication allows the definition of a custom transport layer for communication across clusters.\n+ * This interface must be extended by the client-side adapter to implement a custom channel.\n+ *\n+ * @author annym 05/15/2020\n+ */\n+public abstract class IClientChannelAdapter {\n+\n+\n+    @Getter\n+    private final String localClusterId;\n+\n+    @Getter\n+    private final ClusterDescriptor remoteClusterDescriptor;\n+\n+    @Getter\n+    private final LogReplicationClientRouter router;\n+\n+    @Getter\n+    private IChannelContext channelContext;\n+\n+    /**\n+     * Default Constructor\n+     *\n+     * @param localClusterId local cluster unique identifier\n+     * @param remoteClusterDescriptor descriptor of the remote cluster (standby)\n+     * @param router interface to forward\n+     */\n+    public IClientChannelAdapter(@Nonnull String localClusterId,\n+                                 @Nonnull ClusterDescriptor remoteClusterDescriptor,\n+                                 @Nonnull LogReplicationClientRouter router) {\n+        this.localClusterId = localClusterId;\n+        this.remoteClusterDescriptor = remoteClusterDescriptor;\n+        this.router = router;\n+    }\n+\n+    /**\n+     * Connect Asynchronously to all endpoints specified in the Cluster Descriptor.\n+     */\n+    public void connectAsync() {}\n+\n+    /**\n+     * If connection is lost to a specific endpoint, attempt to reconnect to the specific endpoint.\n+     */\n+    public void connectAsync(String endpoint) {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTAwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/utils/LogReplicationStreamNameTableManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowM1rOG90-HQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowM1rOG90-HQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4OQ==", "bodyText": "Codacy found an issue: Avoid unnecessary if..then..else statements when returning booleans", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484189", "createdAt": "2020-08-08T17:03:03Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/utils/LogReplicationStreamNameTableManager.java", "diffHunk": "@@ -0,0 +1,187 @@\n+package org.corfudb.infrastructure.logreplication.utils;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.ILogReplicationConfigAdapter;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.LogReplicationPluginConfig;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.Query;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.collections.TxBuilder;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.utils.CommonTypes;\n+import org.corfudb.utils.LogReplicationStreams;\n+\n+import java.io.File;\n+import java.lang.reflect.InvocationTargetException;\n+import java.net.URL;\n+import java.net.URLClassLoader;\n+import java.util.*;\n+\n+import static org.corfudb.runtime.view.TableRegistry.CORFU_SYSTEM_NAMESPACE;\n+\n+/**\n+ * Handle creation and maintenance of the Corfu table/s containing names of tables\n+ * to be replicated.\n+ * @author pankti-m\n+ */\n+@Slf4j\n+public class LogReplicationStreamNameTableManager {\n+\n+    public static final String LOG_REPLICATION_STREAMS_NAME_TABLE = \"LogReplicationStreams\";\n+    public static final String LOG_REPLICATION_PLUGIN_VERSION_TABLE = \"LogReplicationPluginVersion\";\n+\n+    private ILogReplicationConfigAdapter logReplicationConfigAdapter;\n+\n+    private CorfuRuntime corfuRuntime;\n+\n+    private String pluginConfigFilePath;\n+\n+    public LogReplicationStreamNameTableManager(CorfuRuntime runtime, String pluginConfigFilePath) {\n+        this.pluginConfigFilePath = pluginConfigFilePath;\n+        this.corfuRuntime = runtime;\n+\n+        initStreamNameFetcherPlugin();\n+    }\n+\n+    public Set<String> getStreamsToReplicate() {\n+        // Initialize the streamsToReplicate\n+        if (verifyTableExists(LOG_REPLICATION_PLUGIN_VERSION_TABLE) &&\n+            verifyTableExists(LOG_REPLICATION_STREAMS_NAME_TABLE)) {\n+            // The tables exist but may have been created by another runtime in which case they have to be opened with\n+            // key/value/metadata type info\n+            openExistingTable(LOG_REPLICATION_PLUGIN_VERSION_TABLE);\n+            openExistingTable(LOG_REPLICATION_STREAMS_NAME_TABLE);\n+            if (!tableVersionMatchesPlugin()) {\n+                // delete the tables and recreate them\n+                deleteExistingStreamNameAndVersionTables();\n+                createStreamNameAndVersionTables(\n+                    logReplicationConfigAdapter.fetchStreamsToReplicate());\n+            }\n+        } else {\n+            // If any 1 of the 2 tables does not exist, delete and recreate them both as they may have been corrupted.\n+            deleteExistingStreamNameAndVersionTables();\n+            createStreamNameAndVersionTables(\n+                logReplicationConfigAdapter.fetchStreamsToReplicate());\n+        }\n+        return readStreamsToReplicateFromTable();\n+    }\n+\n+    public boolean isUpgraded() {\n+        if (verifyTableExists(LOG_REPLICATION_PLUGIN_VERSION_TABLE)) {\n+            openExistingTable(LOG_REPLICATION_PLUGIN_VERSION_TABLE);\n+            if (tableVersionMatchesPlugin()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTAxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterConfig.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowNFrOG90-Hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowNFrOG90-Hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5MA==", "bodyText": "Codacy found an issue: Class cannot be instantiated and does not provide any static methods or fields", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484190", "createdAt": "2020-08-08T17:03:04Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterConfig.java", "diffHunk": "@@ -0,0 +1,70 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure.plugins;\n+\n+import lombok.Getter;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public final class DefaultClusterConfig {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTAzOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/LogReplicationIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowNVrOG90-IA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowNVrOG90-IA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5Mg==", "bodyText": "Codacy found an issue: Avoid unused private fields such as 'MSG_SIZE'.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484192", "createdAt": "2020-08-08T17:03:05Z", "author": {"login": "corfudb-bot"}, "path": "test/src/test/java/org/corfudb/integration/LogReplicationIT.java", "diffHunk": "@@ -0,0 +1,1369 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.Data;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationFSM;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationStateType;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.ObservableAckMsg;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.view.ObjectsView;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.*;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.Semaphore;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import static org.corfudb.integration.ReplicationReaderWriterIT.ckStreamsAndTrim;\n+\n+/**\n+ * Test the core components of log replication, namely, Snapshot Sync and Log Entry Sync,\n+ * i.e., the ability to transfer a full view (snapshot) or incremental view of the datastore\n+ * from a source to a destination. In these tests we disregard communication channels between\n+ * clusters (sites) or CorfuLogReplicationServer.\n+ *\n+ * We emulate the channel by implementing a test data plane which directly forwards the data\n+ * to the SinkManager. Overall, these tests bring up two CorfuServers (datastore components),\n+ * one performing as the active and the other as the standby. We write different patterns of data\n+ * on the source (transactional and non transactional, as well as polluted and non-polluted transactions, i.e.,\n+ * transactions containing federated and non-federated streams) and verify that complete data\n+ * reaches the destination after initiating log replication.\n+ */\n+@Slf4j\n+public class LogReplicationIT extends AbstractIT implements Observer {\n+\n+    public final static String nettyConfig = \"src/test/resources/transport/nettyConfig.properties\";\n+\n+    private static final String SOURCE_ENDPOINT = DEFAULT_HOST + \":\" + DEFAULT_PORT;\n+    private static final int WRITER_PORT = DEFAULT_PORT + 1;\n+    private static final String DESTINATION_ENDPOINT = DEFAULT_HOST + \":\" + WRITER_PORT;\n+\n+    private static final String ACTIVE_CLUSTER_ID = UUID.randomUUID().toString();\n+    private static final String REMOTE_CLUSTER_ID = UUID.randomUUID().toString();\n+    private static final int CORFU_PORT = 9000;\n+    private static final String TABLE_PREFIX = \"test\";\n+\n+    static private final int NUM_KEYS = 10;\n+\n+    static private final int NUM_KEYS_LARGE = 1000;\n+    static private final int NUM_KEYS_VERY_LARGE = 20000;\n+\n+    static private final int NUM_STREAMS = 1;\n+    static private final int TOTAL_STREAM_COUNT = 3;\n+    static private final int WRITE_CYCLES = 4;\n+\n+    static private final int STATE_CHANGE_CHECKS = 20;\n+    static private final int WAIT_STATE_CHANGE = 300;\n+\n+    // If testConfig set deleteOp enabled, will have one delete operation for four put operations.\n+    static private final int DELETE_PACE = 4;\n+\n+    // Number of messages per batch\n+    static private final int BATCH_SIZE = 4;\n+\n+    // each snapshot entry is 33 bytes\n+    // log entry size is 66 bytes or more according to how many streams in one transactions\n+    static private final int MSG_SIZE = 524288;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTA0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/LogReplicationState.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowNlrOG90-IQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowNlrOG90-IQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5Mw==", "bodyText": "Codacy found an issue: Document empty method body", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484193", "createdAt": "2020-08-08T17:03:06Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/LogReplicationState.java", "diffHunk": "@@ -0,0 +1,57 @@\n+package org.corfudb.infrastructure.logreplication.replication.fsm;\n+\n+import java.util.UUID;\n+\n+/**\n+ * An interface for log replication state classes.\n+ *\n+ * All log replication states implement this interface.\n+ */\n+public interface LogReplicationState {\n+\n+    /**\n+     * Get LogReplicationState type.\n+     */\n+    LogReplicationStateType getType();\n+\n+    /**\n+     * Method to process a log replication event.\n+     *\n+     * @return next LogReplicationState to transition to.\n+     */\n+    LogReplicationState processEvent(LogReplicationEvent event) throws IllegalTransitionException;\n+\n+    /**\n+     * On Entry\n+     *\n+     * @param from  LogReplicationState transitioning from.\n+     */\n+    default void onEntry(LogReplicationState from) {}\n+\n+    /**\n+     * On Exit\n+     *\n+     * @param to  LogReplicationState transitioning to.\n+     */\n+    default void onExit(LogReplicationState to) {}\n+\n+    /**\n+     * Provides capability to clear/clean state information onEntry.\n+     */\n+    default void clear() {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTA3OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/TestSerializer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowN1rOG90-JQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowN1rOG90-JQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5Nw==", "bodyText": "Codacy found an issue: Avoid unused private fields such as 'delegate'.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484197", "createdAt": "2020-08-08T17:03:07Z", "author": {"login": "corfudb-bot"}, "path": "test/src/test/java/org/corfudb/integration/TestSerializer.java", "diffHunk": "@@ -0,0 +1,42 @@\n+package org.corfudb.integration;\n+\n+import io.netty.buffer.ByteBuf;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.util.serializer.ISerializer;\n+\n+public class TestSerializer implements ISerializer {\n+\n+    private byte typeIdentifier;\n+    private ISerializer delegate = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTA4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/SinkBufferManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowOFrOG90-Jg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowOFrOG90-Jg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5OA==", "bodyText": "Codacy found an issue: Unnecessary use of fully qualified name 'java.lang.System.currentTimeMillis' due to existing implicit import 'java.lang.*'", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484198", "createdAt": "2020-08-08T17:03:08Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/SinkBufferManager.java", "diffHunk": "@@ -0,0 +1,184 @@\n+package org.corfudb.infrastructure.logreplication.replication.receive;\n+\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntryMetadata;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+\n+import java.util.HashMap;\n+\n+@Slf4j\n+/**\n+ * For snapshot sync and log entry sync, it is possible that the messages generated by the primary cluster will\n+ * be delivered out of order due to message loss due to network connect loss or congestion.\n+ * At the backup/receiver cluster we keep a buffer to store the out of order messages and apply them in order.\n+ * For snapshot sync, the message will be applied according to the message's snapshotSeqNumber.\n+ * For log entry sync, each message has a pre pointer that is a timestamp of the previous message, this guarantees that\n+ * the messages will be applied in order.\n+ *\n+ * At the same time, it eill send an ACK to the primary cluster to notify any possible data loss.\n+ */\n+public abstract class SinkBufferManager {\n+\n+    /*\n+     * The buffer is implemented as a hashmap.\n+     * For logEntry buffer, the key is the entry's previousTimeStamp\n+     * For Snapshot buffer, the key is the previous entry's snapshotSeqNumber\n+     */\n+    public HashMap<Long, LogReplicationEntry> buffer;\n+\n+    /*\n+     * While processing a message in the buffer, it will call\n+     * sinkManager to handle it.\n+     */\n+    public LogReplicationSinkManager sinkManager;\n+\n+    /*\n+     * Could be LOG_ENTRY or SNAPSHOT\n+     */\n+    public MessageType type;\n+\n+    /*\n+     * The max number of entries in the buffer.\n+     */\n+    public int maxSize;\n+\n+    /*\n+     * How frequent in time, the ack will be sent.\n+     */\n+    private int ackCycleTime;\n+\n+    /*\n+     * How frequent in number of messages it has received.\n+     */\n+    private int ackCycleCnt;\n+\n+    /*\n+     * Count the number of messages it has received since last sent ACK.\n+     */\n+    public int ackCnt = 0;\n+\n+    /*\n+     * Time last ack sent.\n+     */\n+    public long ackTime = 0;\n+\n+    /*\n+     * The lastProcessedSeq message's ack value.\n+     * For snapshot, it is the entry's seqNumber.\n+     * For log entry, it is the entry's timestamp.\n+     */\n+    public long lastProcessedSeq;\n+\n+    /**\n+     *\n+     * @param type\n+     * @param ackCycleTime\n+     * @param ackCycleCnt\n+     * @param size\n+     * @param lastProcessedSeq\n+     * @param sinkManager\n+     */\n+    public SinkBufferManager(MessageType type, int ackCycleTime, int ackCycleCnt, int size, long lastProcessedSeq, LogReplicationSinkManager sinkManager) {\n+        this.type = type;\n+        this.ackCycleTime = ackCycleTime;\n+        this.ackCycleCnt = ackCycleCnt;\n+        this.maxSize = size;\n+        this.sinkManager = sinkManager;\n+        this.lastProcessedSeq = lastProcessedSeq;\n+        buffer = new HashMap<>();\n+    }\n+\n+    /**\n+     * After receiving a message, it will decide to send an Ack or not\n+     * according to the predefined metrics.\n+     *\n+     * @return\n+     */\n+    public boolean shouldAck() {\n+        long currentTime = java.lang.System.currentTimeMillis();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTA5OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/runtime/CorfuRuntime.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowOVrOG90-Jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzowOVrOG90-Jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5OQ==", "bodyText": "Codacy found an issue: Fields should be declared at the top of the class, before any method declarations, constructors, initializers or inner classes.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484199", "createdAt": "2020-08-08T17:03:09Z", "author": {"login": "corfudb-bot"}, "path": "runtime/src/main/java/org/corfudb/runtime/CorfuRuntime.java", "diffHunk": "@@ -77,254 +74,154 @@\n     /**\n      * A class which holds parameters and settings for the {@link CorfuRuntime}.\n      */\n-    @Builder\n     @Data\n     @ToString\n-    public static class CorfuRuntimeParameters {\n-        @Default\n-        private final long nettyShutdownQuitePeriod = 100;\n-        @Default\n-        private final long nettyShutdownTimeout = 300;\n+    public static class CorfuRuntimeParameters extends RuntimeParameters {\n \n-        // region Object Layer Parameters\n+        public static CorfuRuntimeParametersBuilder builder() {\n+            return new CorfuRuntimeParametersBuilder();\n+        }\n \n-        /**\n+        /*\n          * Max size for a write request.\n          */\n-        @Default\n+\n         int maxWriteSize = 0;\n \n-        /**\n+        /*\n          * Set the bulk read size.\n          */\n-        @Default\n+        //@Default\n         int bulkReadSize = 10;\n \n-        /**\n+        /*\n          * How much time the Fast Loader has to get the maps up to date.\n          *\n          * <p>Once the timeout is reached, the Fast Loader gives up. Every map that is\n          * not up to date will be loaded through normal path.\n          */\n-        @Default\n+        //@Default\n         Duration fastLoaderTimeout = Duration.ofMinutes(30);\n         // endregion\n \n         // region Address Space Parameters\n-        /**\n+        /*\n          * Number of times to attempt to read before hole filling.\n          * @deprecated This is a no-op. Use holeFillWait\n-         * */\n+         */\n         @Deprecated\n-        @Default int holeFillRetry = 10;\n+        //@Default\n+        int holeFillRetry = 10;\n \n-        /** Time to wait between read requests reattempts before hole filling. */\n-        @Default Duration holeFillRetryThreshold = Duration.ofSeconds(1L);\n+        /* Time to wait between read requests reattempts before hole filling. */\n+        //@Default\n+        Duration holeFillRetryThreshold = Duration.ofSeconds(1L);\n \n-        /**\n+       /*\n          * Time limit after which the reader gives up and fills the hole.\n          */\n-        @Default Duration holeFillTimeout = Duration.ofSeconds(10);\n+        //@Default\n+        Duration holeFillTimeout = Duration.ofSeconds(10);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTExOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/LogReplicationState.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxMFrOG90-KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxMFrOG90-KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwMQ==", "bodyText": "Codacy found an issue: Document empty method body", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484201", "createdAt": "2020-08-08T17:03:10Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/LogReplicationState.java", "diffHunk": "@@ -0,0 +1,57 @@\n+package org.corfudb.infrastructure.logreplication.replication.fsm;\n+\n+import java.util.UUID;\n+\n+/**\n+ * An interface for log replication state classes.\n+ *\n+ * All log replication states implement this interface.\n+ */\n+public interface LogReplicationState {\n+\n+    /**\n+     * Get LogReplicationState type.\n+     */\n+    LogReplicationStateType getType();\n+\n+    /**\n+     * Method to process a log replication event.\n+     *\n+     * @return next LogReplicationState to transition to.\n+     */\n+    LogReplicationState processEvent(LogReplicationEvent event) throws IllegalTransitionException;\n+\n+    /**\n+     * On Entry\n+     *\n+     * @param from  LogReplicationState transitioning from.\n+     */\n+    default void onEntry(LogReplicationState from) {}\n+\n+    /**\n+     * On Exit\n+     *\n+     * @param to  LogReplicationState transitioning to.\n+     */\n+    default void onExit(LogReplicationState to) {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTEyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/LogReplicationFSM.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxMVrOG90-Kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxMVrOG90-Kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwMg==", "bodyText": "Codacy found an issue: Avoid unused private fields such as 'remoteCluster'.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484202", "createdAt": "2020-08-08T17:03:11Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/LogReplicationFSM.java", "diffHunk": "@@ -0,0 +1,383 @@\n+package org.corfudb.infrastructure.logreplication.replication.fsm;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.logreplication.DataSender;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent.LogReplicationEventType;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.LogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogEntrySender;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.ReadProcessor;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.SnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.SnapshotSender;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsLogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsSnapshotReader;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Address;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+\n+/**\n+ * This class implements the Log Replication Finite State Machine.\n+ *\n+ * CorfuDB provides a Log Replication functionality, which allows logs to be automatically replicated from a primary\n+ * to a remote cluster. This feature is particularly useful in the event of failure or data corruption, so the system\n+ * can failover to the standby/secondary data-store.\n+ *\n+ * This functionality is initiated by the application through the LogReplicationSourceManager on the primary cluster and handled\n+ * through the LogReplicationSinkManager on the destination cluster. This implementation assumes that the application provides its own\n+ * communication channels.\n+ *\n+ * Log Replication on the source cluster is defined by an event-driven finite state machine, with 5 states\n+ * and 8 events/messages---which can trigger the transition between states.\n+ *\n+ * States:\n+ * ------\n+ *  - Initialized (initial state)\n+ *  - In_Log_Entry_Sync\n+ *  - In_Snapshot_Sync\n+ *  - Snapshot_Sync_Required\n+ *  - Stopped\n+ *\n+ * Events:\n+ * ------\n+ *  - replication_start\n+ *  - replication_stop\n+ *  - snapshot_sync_request\n+ *  - snapshot_sync_complete\n+ *  - snapshot_sync_continue\n+ *  - sync_cancel\n+ *  - log_entry_sync_replicated\n+ *  - replication_shutdown\n+ *\n+ *\n+ * The following diagram illustrates the Log Replication FSM state transition:\n+ *\n+ *\n+ *                                       replication_stop\n+ *                      +-------------------------------------------------+\n+ *    replication_stop  |                                                 |\n+ *             +-----+  |              replication_stop                   |\n+ *             |     |  v      v-----------------------------+            |\n+ *             |    ++--+---------+                          |        +---+--------------------+\n+ *             +--->+ INITIALIZED +------------------------+ |        | SNAPSHOT_SYNC_REQUIRED +<---+\n+ *                  +---+----+----+ snapshot_sync_request  | |        +---+---------------+----+    |\n+ *                      ^    |                             | |            |               ^         |\n+ *                      |    |                             | |   snapshot |               |         |\n+ *                      |    |                             | |    sync    |               |         |\n+ *     replication_stop |    | replication_start           | |    request |               |         |\n+ *                      |    |                             | |            |               |         |\n+ *                      |    v                             v |            v               |         |\n+ *               +------+----+-------+  snapshot_sync    +-+-+------------+-+             |         |\n+ *         +-----| IN_LOG_ENTRY_SYNC |     request       | IN_SNAPSHOT_SYNC +             |         |\n+ *         |     |                   +------------------>+                  |             |         |\n+ *         |     +----+----+---------+                   +---+---+----------+-------------+         |\n+ *         |       ^  |   ^                                 |    |        ^        sync             |\n+ *         |       |  |   +---------------------------------+    |        |       cancel            |\n+ *         + ----- +  |                snapshot_sync             + -------+                         |\n+ *  log_entry_sync    |                  complete               snapshot_sync                       |\n+ *    continue        |                                           continue                          |\n+ *                    +-----------------------------------------------------------------------------+\n+ *                                                     sync_cancel\n+ *               replication\n+ * +---------+    shutdown    +------------+\n+ * | STOPPED +<---------------+ ALL_STATES |\n+ * +---------+                +------------+\n+ *\n+ *\n+ */\n+// TODO(Anny): insert new state to comply with SNAPSHOT_WAIT_COMPLETE event\n+@Slf4j\n+public class LogReplicationFSM {\n+\n+    @Getter\n+    private long topologyConfigId;\n+\n+    /**\n+     * Current state of the FSM.\n+     */\n+    @Getter\n+    private volatile LogReplicationState state;\n+\n+    /**\n+     * Map of all Log Replication FSM States (reuse single instance for each state)\n+     */\n+    @Getter\n+    private Map<LogReplicationStateType, LogReplicationState> states = new HashMap<>();\n+\n+    /**\n+     * Executor service for FSM state tasks (it can be shared across several LogReplicationFSMs)\n+     */\n+    @Getter\n+    private ExecutorService logReplicationFSMWorkers;\n+\n+    /**\n+     * Executor service for FSM event queue consume\n+     */\n+    private ExecutorService logReplicationFSMConsumer;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<LogReplicationEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    /**\n+     * An observable object on the number of transitions of this state machine (for testing & visibility)\n+     */\n+    @VisibleForTesting\n+    @Getter\n+    private ObservableValue numTransitions = new ObservableValue(0);\n+\n+    /**\n+     * Log Entry Reader (read incremental updated from Corfu Datatore)\n+     */\n+    private LogEntryReader logEntryReader;\n+\n+    /**\n+     * Snapshot Reader (read data from Corfu Datastore)\n+     */\n+    private SnapshotReader snapshotReader;\n+\n+    /**\n+     * Version on which snapshot sync is based on.\n+     */\n+    @Getter\n+    private long baseSnapshot = Address.NON_ADDRESS;\n+\n+    /**\n+     * Acknowledged timestamp\n+     */\n+    @Getter\n+    private long ackedTimestamp = Address.NON_ADDRESS;\n+\n+    /**\n+     * Log Entry Sender (send incremental updates to remote cluster)\n+     */\n+    private LogEntrySender logEntrySender;\n+\n+    /**\n+     * Snapshot Sender (send snapshot cut to remote cluster)\n+     */\n+    private SnapshotSender snapshotSender;\n+\n+    /**\n+     * Remote Cluster Descriptor to which this FSM drives the log replication\n+     */\n+    private final ClusterDescriptor remoteCluster;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTEzOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/LogReplicationIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxMlrOG90-Kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxMlrOG90-Kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwMw==", "bodyText": "Codacy found an issue: Avoid unused private fields such as 'sourceServer'.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484203", "createdAt": "2020-08-08T17:03:12Z", "author": {"login": "corfudb-bot"}, "path": "test/src/test/java/org/corfudb/integration/LogReplicationIT.java", "diffHunk": "@@ -0,0 +1,1369 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.Data;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationFSM;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationStateType;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.ObservableAckMsg;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.view.ObjectsView;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.*;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.Semaphore;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import static org.corfudb.integration.ReplicationReaderWriterIT.ckStreamsAndTrim;\n+\n+/**\n+ * Test the core components of log replication, namely, Snapshot Sync and Log Entry Sync,\n+ * i.e., the ability to transfer a full view (snapshot) or incremental view of the datastore\n+ * from a source to a destination. In these tests we disregard communication channels between\n+ * clusters (sites) or CorfuLogReplicationServer.\n+ *\n+ * We emulate the channel by implementing a test data plane which directly forwards the data\n+ * to the SinkManager. Overall, these tests bring up two CorfuServers (datastore components),\n+ * one performing as the active and the other as the standby. We write different patterns of data\n+ * on the source (transactional and non transactional, as well as polluted and non-polluted transactions, i.e.,\n+ * transactions containing federated and non-federated streams) and verify that complete data\n+ * reaches the destination after initiating log replication.\n+ */\n+@Slf4j\n+public class LogReplicationIT extends AbstractIT implements Observer {\n+\n+    public final static String nettyConfig = \"src/test/resources/transport/nettyConfig.properties\";\n+\n+    private static final String SOURCE_ENDPOINT = DEFAULT_HOST + \":\" + DEFAULT_PORT;\n+    private static final int WRITER_PORT = DEFAULT_PORT + 1;\n+    private static final String DESTINATION_ENDPOINT = DEFAULT_HOST + \":\" + WRITER_PORT;\n+\n+    private static final String ACTIVE_CLUSTER_ID = UUID.randomUUID().toString();\n+    private static final String REMOTE_CLUSTER_ID = UUID.randomUUID().toString();\n+    private static final int CORFU_PORT = 9000;\n+    private static final String TABLE_PREFIX = \"test\";\n+\n+    static private final int NUM_KEYS = 10;\n+\n+    static private final int NUM_KEYS_LARGE = 1000;\n+    static private final int NUM_KEYS_VERY_LARGE = 20000;\n+\n+    static private final int NUM_STREAMS = 1;\n+    static private final int TOTAL_STREAM_COUNT = 3;\n+    static private final int WRITE_CYCLES = 4;\n+\n+    static private final int STATE_CHANGE_CHECKS = 20;\n+    static private final int WAIT_STATE_CHANGE = 300;\n+\n+    // If testConfig set deleteOp enabled, will have one delete operation for four put operations.\n+    static private final int DELETE_PACE = 4;\n+\n+    // Number of messages per batch\n+    static private final int BATCH_SIZE = 4;\n+\n+    // each snapshot entry is 33 bytes\n+    // log entry size is 66 bytes or more according to how many streams in one transactions\n+    static private final int MSG_SIZE = 524288;\n+\n+    static private final int SMALL_MSG_SIZE = 200;\n+\n+    static private TestConfig testConfig = new TestConfig();\n+\n+    private Process sourceServer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTE0OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxM1rOG90-LA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxM1rOG90-LA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwNA==", "bodyText": "Codacy found an issue: JUnit tests should include assert() or fail()", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484204", "createdAt": "2020-08-08T17:03:13Z", "author": {"login": "corfudb-bot"}, "path": "test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java", "diffHunk": "@@ -0,0 +1,588 @@\n+package org.corfudb.infrastructure.logreplication;\n+\n+import com.google.common.reflect.TypeToken;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.EmptyDataSender;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.EmptySnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.InSnapshotSyncState;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationFSM;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationState;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationStateType;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestDataSender;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestLogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestReaderConfiguration;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestSnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.DefaultReadProcessor;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.LogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsSnapshotReader;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.SnapshotReader;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent.LogReplicationEventType;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.view.AbstractViewTest;\n+import org.corfudb.runtime.view.Address;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Observable;\n+import java.util.Observer;\n+import java.util.Queue;\n+import java.util.UUID;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Semaphore;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Slf4j\n+/**\n+ * Test Log Replication FSM.\n+ */\n+public class LogReplicationFSMTest extends AbstractViewTest implements Observer {\n+\n+    // Parameters for writes\n+    private static final int NUM_ENTRIES = 10;\n+    private static final int LARGE_NUM_ENTRIES = 100;\n+    private static final String PAYLOAD_FORMAT = \"%s hello world\";\n+    private static final String TEST_STREAM_NAME = \"StreamA\";\n+    private static final int BATCH_SIZE = 2;\n+    private static final int WAIT_TIME = 100;\n+    private static final int CORFU_PORT = 9000;\n+    private static final int TEST_TOPOLOGY_CONFIG_ID = 1;\n+    private static final String TEST_LOCAL_CLUSTER_ID = \"local_cluster\";\n+\n+    // This semaphore is used to block until the triggering event causes the transition to a new state\n+    private final Semaphore transitionAvailable = new Semaphore(1, true);\n+    // We observe the transition counter to know that a transition occurred.\n+    private ObservableValue transitionObservable;\n+\n+    // Flag indicating if we should observer a snapshot sync, this is to interrupt it at any given stage\n+    private boolean observeSnapshotSync = false;\n+    private int limitSnapshotMessages = 0;\n+    private ObservableValue snapshotMessageCounterObservable;\n+\n+    private LogReplicationFSM fsm;\n+    private CorfuRuntime runtime;\n+    private DataSender dataSender;\n+    private SnapshotReader snapshotReader;\n+    private LogEntryReader logEntryReader;\n+    private LogReplicationAckReader ackReader;\n+\n+    @Before\n+    public void setRuntime() {\n+        runtime = getDefaultRuntime();\n+        runtime.getParameters().setCodecType(Codec.Type.NONE);\n+    }\n+\n+    @After\n+    public void stopAckReader() {\n+        ackReader.shutdown();\n+    }\n+\n+    /**\n+     * Verify state machine behavior in the most simple (no error) path.\n+     *\n+     * This is the sequence of events triggered and expected state change:\n+     *\n+     * (1) None -> verify FSM initial state is INITIALIZED\n+     * (2) Replication Stop -> verify it stays in the INITIALIZED state as replication has not been started\n+     * (3) Replication Start -> IN_LOG_ENTRY_SYNC state\n+     * (4) Snapshot Sync Request -> IN_SNAPSHOT_SYNC state\n+     * (5) Snapshot Sync Complete -> IN_LOG_ENTRY_SYNC state\n+     * (6) Replication Stop -> back to INITIALIZED state\n+     *\n+     */\n+    @Test\n+    public void testLogReplicationFSMTransitions() throws Exception {\n+\n+        initLogReplicationFSM(ReaderImplementation.EMPTY);\n+\n+        // Initial state: Initialized\n+        LogReplicationState initState = fsm.getState();\n+        assertThat(initState.getType()).isEqualTo(LogReplicationStateType.INITIALIZED);\n+\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Replication Stop (without any replication having started)\n+        transition(LogReplicationEventType.REPLICATION_STOP, LogReplicationStateType.INITIALIZED);\n+\n+        // Transition #2: Replication Start\n+        transition(LogReplicationEventType.REPLICATION_START, LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        // Transition #3: Snapshot Sync Request\n+        UUID snapshotSyncId = transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC, true);\n+\n+        // Transition #4: Snapshot Sync Complete\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE, LogReplicationStateType.IN_LOG_ENTRY_SYNC, snapshotSyncId, false);\n+\n+        // Transition #5: Stop Replication\n+        // Next transition might not be to INITIALIZED, as IN_LOG_ENTRY_SYNC state might have enqueued\n+        // a continuation before the stop is enqueued.\n+        transition(LogReplicationEventType.REPLICATION_STOP, LogReplicationStateType.INITIALIZED, true);\n+    }\n+\n+    /**\n+     * Test Trim Exception Events for Log Replication FSM\n+     *\n+     * This is the sequence of events triggered and expected state change:\n+     *\n+     * (1) Snapshot Sync Request => IN_SNAPSHOT_SYNC state\n+     * (2) Trimmed Exception (incorrect id) => IN_LOG_ENTRY_SYNC\n+     * (3) Trimmed Exception (for state in (5)) => IN_REQUIRE_SNAPSHOT_SYNC\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testTrimExceptionFSM() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 153}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTE2OnYy", "diffSide": "RIGHT", "path": "runtime/src/main/java/org/corfudb/protocols/logprotocol/SMREntry.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxNFrOG90-Lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxNFrOG90-Lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwNg==", "bodyText": "Codacy found an issue: Avoid unused private methods such as 'calculateOpaqueSMREntrySerializedSize()'.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484206", "createdAt": "2020-08-08T17:03:14Z", "author": {"login": "corfudb-bot"}, "path": "runtime/src/main/java/org/corfudb/protocols/logprotocol/SMREntry.java", "diffHunk": "@@ -103,26 +112,64 @@ public SMREntry(String smrMethod, @NonNull Object[] smrArguments, ISerializer se\n      */\n     @Override\n     void deserializeBuffer(ByteBuf b, CorfuRuntime rt) {\n+        int readIndex = b.readerIndex();\n+\n         super.deserializeBuffer(b, rt);\n         short methodLength = b.readShort();\n         byte[] methodBytes = new byte[methodLength];\n         b.readBytes(methodBytes, 0, methodLength);\n         SMRMethod = new String(methodBytes);\n-        serializerType = Serializers.getSerializer(b.readByte());\n+        byte serializerId = b.readByte();\n         byte numArguments = b.readByte();\n         Object[] arguments = new Object[numArguments];\n+\n+        if (!opaque) {\n+            serializerType = Serializers.getSerializer(serializerId);\n+        } else {\n+            this.serializerId = serializerId;\n+        }\n+\n         for (byte arg = 0; arg < numArguments; arg++) {\n             int len = b.readInt();\n             ByteBuf objBuf = b.slice(b.readerIndex(), len);\n-            arguments[arg] = serializerType.deserialize(objBuf, rt);\n+            if (opaque) {\n+                byte[] argBytes = new byte[len];\n+                objBuf.readBytes(argBytes);\n+                arguments[arg] = argBytes;\n+            } else {\n+                arguments[arg] = serializerType.deserialize(objBuf, rt);\n+            }\n             b.skipBytes(len);\n         }\n         SMRArguments = arguments;\n+        serializedSize = b.readerIndex() - readIndex + 1;\n+    }\n+\n+\n+    /**\n+     * Calculate an Opaque SMR entry's serialized size.\n+     * @throws IllegalAccessException\n+     */\n+    private int calculateOpaqueSMREntrySerializedSize() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTE3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxNVrOG90-Lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxNVrOG90-Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwNw==", "bodyText": "Codacy found an issue: Avoid unused private methods such as 'handleLogReplicationEntry(CorfuPayloadMsg,ChannelHandlerContext,IServerRouter)'.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484207", "createdAt": "2020-08-08T17:03:15Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.corfudb.infrastructure;\n+\n+import io.netty.channel.ChannelHandlerContext;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationSinkManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.CorfuPayloadMsg;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationLeadershipLoss;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationQueryLeaderShipResponse;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+\n+import javax.annotation.Nonnull;\n+import java.lang.invoke.MethodHandles;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * This class represents the Log Replication Server, which is\n+ * responsible of providing Log Replication across sites.\n+ *\n+ * The Log Replication Server, handles log replication entries--which\n+ * represent parts of a Snapshot (full) sync or a Log Entry (delta) sync\n+ * and also handles negotiation messages, which allows the Source Replicator\n+ * to get a view of the last synchronized point at the remote cluster.\n+ */\n+@Slf4j\n+public class LogReplicationServer extends AbstractServer {\n+\n+    private final ServerContext serverContext;\n+\n+    private final ExecutorService executor;\n+\n+    @Getter\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    @Getter\n+    private final LogReplicationSinkManager sinkManager;\n+\n+    private final AtomicBoolean isLeader = new AtomicBoolean(false);\n+\n+    private final AtomicBoolean isActive = new AtomicBoolean(false);\n+\n+    @Getter\n+    private final HandlerMethods handler = HandlerMethods.generateHandler(MethodHandles.lookup(), this);\n+\n+    public LogReplicationServer(@Nonnull ServerContext context, @Nonnull  LogReplicationConfig logReplicationConfig,\n+                                @Nonnull LogReplicationMetadataManager metadataManager, String corfuEndpoint,\n+                                long topologyConfigId) {\n+        this.serverContext = context;\n+        this.metadataManager = metadataManager;\n+        this.sinkManager = new LogReplicationSinkManager(corfuEndpoint, logReplicationConfig, metadataManager, serverContext, topologyConfigId);\n+\n+        this.executor = Executors.newFixedThreadPool(1,\n+                new ServerThreadFactory(\"LogReplicationServer-\", new ServerThreadFactory.ExceptionHandler()));\n+    }\n+\n+    /* ************ Override Methods ************ */\n+\n+    @Override\n+    public boolean isServerReadyToHandleMsg(CorfuMsg msg) {\n+        return getState() == ServerState.READY;\n+    }\n+\n+    @Override\n+    protected void processRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n+        executor.submit(() -> getHandler().handle(msg, ctx, r));\n+    }\n+\n+    @Override\n+    public void shutdown() {\n+        super.shutdown();\n+        executor.shutdown();\n+    }\n+\n+    /* ************ Server Handlers ************ */\n+\n+    @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_ENTRY)\n+    private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTE4OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/runtime/view/stream/OpaqueStreamTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxNlrOG90-MA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxNlrOG90-MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwOA==", "bodyText": "Codacy found an issue: JUnit tests should include assert() or fail()", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484208", "createdAt": "2020-08-08T17:03:16Z", "author": {"login": "corfudb-bot"}, "path": "test/src/test/java/org/corfudb/runtime/view/stream/OpaqueStreamTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+package org.corfudb.runtime.view.stream;\n+\n+import com.google.common.reflect.TypeToken;\n+import org.corfudb.CustomSerializer;\n+import org.corfudb.protocols.logprotocol.MultiSMREntry;\n+import org.corfudb.protocols.logprotocol.OpaqueEntry;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.MultiCheckpointWriter;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.exceptions.SerializerException;\n+import org.corfudb.runtime.view.AbstractViewTest;\n+import org.corfudb.util.serializer.ISerializer;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import org.junit.Test;\n+\n+import java.util.UUID;\n+import java.util.stream.Stream;\n+\n+public class OpaqueStreamTest extends AbstractViewTest {\n+\n+    @Test\n+    public void testMagicByte() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTI0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxN1rOG90-Ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxN1rOG90-Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIxNA==", "bodyText": "Codacy found an issue: Avoid unused method parameters such as 'ctx'.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484214", "createdAt": "2020-08-08T17:03:17Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.corfudb.infrastructure;\n+\n+import io.netty.channel.ChannelHandlerContext;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationSinkManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.CorfuPayloadMsg;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationLeadershipLoss;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationQueryLeaderShipResponse;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+\n+import javax.annotation.Nonnull;\n+import java.lang.invoke.MethodHandles;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * This class represents the Log Replication Server, which is\n+ * responsible of providing Log Replication across sites.\n+ *\n+ * The Log Replication Server, handles log replication entries--which\n+ * represent parts of a Snapshot (full) sync or a Log Entry (delta) sync\n+ * and also handles negotiation messages, which allows the Source Replicator\n+ * to get a view of the last synchronized point at the remote cluster.\n+ */\n+@Slf4j\n+public class LogReplicationServer extends AbstractServer {\n+\n+    private final ServerContext serverContext;\n+\n+    private final ExecutorService executor;\n+\n+    @Getter\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    @Getter\n+    private final LogReplicationSinkManager sinkManager;\n+\n+    private final AtomicBoolean isLeader = new AtomicBoolean(false);\n+\n+    private final AtomicBoolean isActive = new AtomicBoolean(false);\n+\n+    @Getter\n+    private final HandlerMethods handler = HandlerMethods.generateHandler(MethodHandles.lookup(), this);\n+\n+    public LogReplicationServer(@Nonnull ServerContext context, @Nonnull  LogReplicationConfig logReplicationConfig,\n+                                @Nonnull LogReplicationMetadataManager metadataManager, String corfuEndpoint,\n+                                long topologyConfigId) {\n+        this.serverContext = context;\n+        this.metadataManager = metadataManager;\n+        this.sinkManager = new LogReplicationSinkManager(corfuEndpoint, logReplicationConfig, metadataManager, serverContext, topologyConfigId);\n+\n+        this.executor = Executors.newFixedThreadPool(1,\n+                new ServerThreadFactory(\"LogReplicationServer-\", new ServerThreadFactory.ExceptionHandler()));\n+    }\n+\n+    /* ************ Override Methods ************ */\n+\n+    @Override\n+    public boolean isServerReadyToHandleMsg(CorfuMsg msg) {\n+        return getState() == ServerState.READY;\n+    }\n+\n+    @Override\n+    protected void processRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n+        executor.submit(() -> getHandler().handle(msg, ctx, r));\n+    }\n+\n+    @Override\n+    public void shutdown() {\n+        super.shutdown();\n+        executor.shutdown();\n+    }\n+\n+    /* ************ Server Handlers ************ */\n+\n+    @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_ENTRY)\n+    private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTMyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/LogReplicationClientRouter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxOFrOG90-Pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxOFrOG90-Pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIyMg==", "bodyText": "Codacy found an issue: Document empty method body", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484222", "createdAt": "2020-08-08T17:03:18Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/LogReplicationClientRouter.java", "diffHunk": "@@ -0,0 +1,436 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.LogReplicationPluginConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.infrastructure.logreplication.utils.CorfuMessageConverterUtils;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.runtime.Messages.CorfuMessage;\n+import org.corfudb.runtime.clients.IClient;\n+import org.corfudb.runtime.clients.IClientRouter;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.infrastructure.logreplication.transport.client.ChannelAdapterException;\n+import org.corfudb.infrastructure.logreplication.transport.client.IClientChannelAdapter;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.utils.common.CorfuMessageProtoBufException;\n+\n+import java.io.File;\n+import java.net.URL;\n+import java.net.URLClassLoader;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+/**\n+ * This Client Router is used when a custom (client-defined) transport layer is specified for\n+ * Log Replication Server communication.\n+ *\n+ */\n+@Slf4j\n+public class LogReplicationClientRouter implements IClientRouter {\n+\n+    @Getter\n+    private LogReplicationRuntimeParameters parameters;\n+\n+    /**\n+     * The handlers registered to this router.\n+     */\n+    private final Map<CorfuMsgType, IClient> handlerMap;\n+\n+    /**\n+     * The clients registered to this router.\n+     */\n+    public final List<IClient> clientList;\n+\n+    /**\n+     * Whether or not this router is shutdown.\n+     */\n+    public volatile boolean shutdown;\n+\n+    /**\n+     * A {@link CompletableFuture} which is completed when a connection,\n+     * including a successful handshake completes and messages can be sent\n+     * to the remote node.\n+     */\n+    @Getter\n+    private volatile CompletableFuture<Void> remoteLeaderConnectionFuture;\n+\n+    /**\n+     * The current request ID.\n+     */\n+    @Getter\n+    @SuppressWarnings(\"checkstyle:abbreviation\")\n+    public AtomicLong requestID;\n+\n+    /**\n+     * Sync call response timeout (milliseconds).\n+     */\n+    @Getter\n+    @Setter\n+    public long timeoutResponse;\n+\n+    /**\n+     * The outstanding requests on this router.\n+     */\n+    public final Map<Long, CompletableFuture> outstandingRequests;\n+\n+    /**\n+     * Adapter to the channel implementation\n+     */\n+    private IClientChannelAdapter channelAdapter;\n+\n+    /**\n+     * Remote Cluster/Site Full Descriptor\n+     */\n+    private ClusterDescriptor remoteClusterDescriptor;\n+\n+    /**\n+     * Remote Cluster/Site unique identifier\n+     */\n+    private String remoteClusterId;\n+\n+    /**\n+     * Runtime FSM, to insert connectivity events\n+     */\n+    private CorfuLogReplicationRuntime runtimeFSM;\n+\n+    /**\n+     * Log Replication Client Constructor\n+     *\n+     * @param parameters runtime parameters (including connection settings)\n+     * @param runtimeFSM runtime state machine, insert connection related events\n+     */\n+    public LogReplicationClientRouter(LogReplicationRuntimeParameters parameters,\n+                                      CorfuLogReplicationRuntime runtimeFSM) {\n+        this.remoteClusterDescriptor = parameters.getRemoteClusterDescriptor();\n+        this.remoteClusterId = remoteClusterDescriptor.getClusterId();\n+        this.parameters = parameters;\n+        this.timeoutResponse = parameters.getRequestTimeout().toMillis();\n+        this.runtimeFSM = runtimeFSM;\n+\n+        this.handlerMap = new ConcurrentHashMap<>();\n+        this.clientList = new ArrayList<>();\n+        this.requestID = new AtomicLong();\n+        this.outstandingRequests = new ConcurrentHashMap<>();\n+        this.remoteLeaderConnectionFuture = new CompletableFuture<>();\n+    }\n+\n+    // ------------------- IClientRouter Interface ----------------------\n+\n+    @Override\n+    public IClientRouter addClient(IClient client) {\n+        // Set the client's router to this instance.\n+        client.setRouter(this);\n+\n+        // Iterate through all types of CorfuMsgType, registering the handler\n+        client.getHandledTypes().stream()\n+                .forEach(x -> {\n+                    handlerMap.put(x, client);\n+                    log.info(\"Registered {} to handle messages of type {}\", client, x);\n+                });\n+\n+        // Register this type\n+        clientList.add(client);\n+        return this;\n+    }\n+\n+    @Override\n+    public <T> CompletableFuture<T> sendMessageAndGetCompletable(CorfuMsg message) {\n+        return sendMessageAndGetCompletable(message, null);\n+    }\n+\n+    public <T> CompletableFuture<T> sendMessageAndGetCompletable(CorfuMsg message, String endpoint) {\n+        if (isValidMessage(message)) {\n+            // Get the next request ID.\n+            final long requestId = requestID.getAndIncrement();\n+\n+            // Generate a future and put it in the completion table.\n+            final CompletableFuture<T> cf = new CompletableFuture<>();\n+            outstandingRequests.put(requestId, cf);\n+\n+            try {\n+                message.setClientID(parameters.getClientId());\n+                message.setRequestID(requestId);\n+\n+                // If no endpoint is specified, the message is to be sent to the remote leader node.\n+                // We should block until a connection to the leader is established.\n+                if (endpoint == null || endpoint.length() == 0) {\n+                    // Check the connection future. If connected, continue with sending the message.\n+                    // If timed out, return a exceptionally completed with the timeout.\n+                    // Because in Log Replication, messages are sent to the leader node, the connection future\n+                    // represents a connection to the leader.\n+                    try {\n+                        remoteLeaderConnectionFuture\n+                                .get(getParameters().getConnectionTimeout().toMillis(), TimeUnit.MILLISECONDS);\n+                    } catch (InterruptedException e) {\n+                        throw new UnrecoverableCorfuInterruptedError(e);\n+                    } catch (TimeoutException | ExecutionException te) {\n+                        cf.completeExceptionally(te);\n+                        return cf;\n+                    }\n+\n+                    // Get Remote Leader\n+                    if(runtimeFSM.getRemoteLeader().isPresent()) {\n+                        endpoint = runtimeFSM.getRemoteLeader().get();\n+                    } else {\n+                        log.error(\"Leader not found to remote cluster {}\", remoteClusterId);\n+                        runtimeFSM.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+                        throw new ChannelAdapterException(\n+                                String.format(\"Leader not found to remote cluster %s\", remoteClusterDescriptor.getClusterId()));\n+                    }\n+                }\n+\n+                // In the case the message is intended for a specific endpoint, we do not\n+                // block on connection future, this is the case of leader verification.\n+                log.info(\"Send message to {}, type={}\", endpoint, message.getMsgType());\n+                channelAdapter.send(endpoint, CorfuMessageConverterUtils.toProtoBuf(message));\n+\n+            } catch (NetworkException ne) {\n+                log.error(\"Caught Network Exception while trying to send message to remote leader {}\", endpoint);\n+                runtimeFSM.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.ON_CONNECTION_DOWN,\n+                        endpoint));\n+                throw ne;\n+            } catch (Exception e) {\n+                outstandingRequests.remove(requestId);\n+                log.error(\"sendMessageAndGetCompletable: Remove request {} to {} due to exception! Message:{}\",\n+                        requestId, remoteClusterId, message, e);\n+                cf.completeExceptionally(e);\n+                return cf;\n+            }\n+\n+            // Generate a timeout future, which will complete exceptionally\n+            // if the main future is not completed.\n+            final CompletableFuture<T> cfTimeout =\n+                    CFUtils.within(cf, Duration.ofMillis(timeoutResponse));\n+            cfTimeout.exceptionally(e -> {\n+                if (e.getCause() instanceof TimeoutException) {\n+                    outstandingRequests.remove(requestId);\n+                    log.debug(\"sendMessageAndGetCompletable: Remove request {} to {} due to timeout! Message:{}\",\n+                            requestId, remoteClusterId, message);\n+                }\n+                return null;\n+            });\n+\n+            return cfTimeout;\n+        }\n+\n+        log.error(\"Invalid message type {}. Currently only log replication messages are processed.\");\n+        CompletableFuture<T> f = new CompletableFuture<>();\n+        f.completeExceptionally(new Throwable(\"Invalid message type\"));\n+        return f;\n+    }\n+\n+    /**\n+     * Send a one way message, without adding a completable future.\n+     *\n+     * @param message The message to send.\n+     */\n+    @Override\n+    public void sendMessage(CorfuMsg message) {\n+        // Get the next request ID.\n+        message.setRequestID(requestID.getAndIncrement());\n+        // Get Remote Leader\n+        if(runtimeFSM.getRemoteLeader().isPresent()) {\n+            String remoteLeader = runtimeFSM.getRemoteLeader().get();\n+            channelAdapter.send(remoteLeader, CorfuMessageConverterUtils.toProtoBuf(message));\n+            log.trace(\"Sent one-way message: {}\", message);\n+        } else {\n+            log.error(\"Leader not found to remote cluster {}, dropping {}\", remoteClusterId, message.getMsgType());\n+            runtimeFSM.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+        }\n+    }\n+\n+    @Override\n+    public <T> void completeRequest(long requestID, T completion) {\n+        log.trace(\"Complete request: {}\", requestID);\n+        CompletableFuture<T> cf;\n+        if ((cf = (CompletableFuture<T>) outstandingRequests.remove(requestID)) != null) {\n+            cf.complete(completion);\n+        } else {\n+            log.warn(\"Attempted to complete request {}, but request not outstanding!\", requestID);\n+        }\n+    }\n+\n+    @Override\n+    public void completeExceptionally(long requestID, Throwable cause) {\n+        CompletableFuture cf;\n+        if ((cf = outstandingRequests.remove(requestID)) != null) {\n+            cf.completeExceptionally(cause);\n+            log.debug(\"completeExceptionally: Remove request {} to {} due to {}.\", requestID, remoteClusterId,\n+                    cause.getClass().getSimpleName(), cause);\n+        } else {\n+            log.warn(\"Attempted to exceptionally complete request {}, but request not outstanding!\",\n+                    requestID);\n+        }\n+    }\n+\n+    @Override\n+    public void stop() {\n+        log.debug(\"stop: Shutting down router for {}\", remoteClusterId);\n+        shutdown = true;\n+        channelAdapter.stop();\n+        remoteLeaderConnectionFuture = new CompletableFuture<>();\n+        remoteLeaderConnectionFuture.completeExceptionally(new NetworkException(\"Router stopped\", remoteClusterId));\n+    }\n+\n+    @Override\n+    public Integer getPort() {\n+        // For logging purposes return one port (as this abstraction does not make sense for a Log Replication\n+        // Client Router) as it is a router to an entire cluster/site.\n+        return Integer.valueOf(remoteClusterDescriptor.getNodesDescriptors().iterator().next().getPort());\n+    }\n+\n+    @Override\n+    public String getHost() {\n+        String host = \"\";\n+        // For logging purposes return all remote cluster nodes host in a concatenated form\n+        remoteClusterDescriptor.getNodesDescriptors().forEach(node -> host.concat(node.getHost() + \":\"));\n+        return host;\n+    }\n+\n+    @Override\n+    public void setTimeoutConnect(long timeoutConnect) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 308}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTM3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/transport/server/IServerChannelAdapter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxOVrOG90-Qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoxOVrOG90-Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIyNw==", "bodyText": "Codacy found an issue: Document empty method body", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484227", "createdAt": "2020-08-08T17:03:19Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/transport/server/IServerChannelAdapter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+package org.corfudb.infrastructure.logreplication.transport.server;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.transport.IChannelContext;\n+import org.corfudb.runtime.Messages.CorfuMessage;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationServerRouter;\n+\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * Server Transport Adapter.\n+ *\n+ * If Log Replication relies on a custom transport protocol for communication across servers,\n+ * this interface must be extended by the server-side adapter to implement a custom channel.\n+ *\n+ * @author annym 05/15/2020\n+ */\n+public abstract class IServerChannelAdapter {\n+\n+    @Getter\n+    private final LogReplicationServerRouter router;\n+\n+    @Getter\n+    private final ServerContext serverContext;\n+\n+    @Getter\n+    @Setter\n+    private IChannelContext channelContext;\n+\n+    public IServerChannelAdapter(ServerContext serverContext, LogReplicationServerRouter adapter) {\n+        this.serverContext = serverContext;\n+        this.router = adapter;\n+    }\n+\n+    /**\n+     * Send message across channel.\n+     *\n+     * @param msg corfu message (protoBuf definition)\n+     */\n+    public abstract void send(CorfuMessage msg);\n+\n+    /**\n+     * Receive a message from Client.\n+     *\n+     * @param msg received corfu message\n+     */\n+    public void receive(CorfuMessage msg) {\n+        getRouter().receive(msg);\n+    }\n+\n+    /**\n+     * Initialize adapter.\n+     *\n+     * @return Completable Future on connection start\n+     */\n+    public abstract CompletableFuture<Boolean> start();\n+\n+    /**\n+     * Close connections or gracefully shutdown the channel.\n+     */\n+    public void stop() {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTQzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/LogReplicationRuntimeState.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoyMFrOG90-SQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoyMFrOG90-SQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIzMw==", "bodyText": "Codacy found an issue: Document empty method body", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484233", "createdAt": "2020-08-08T17:03:20Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/LogReplicationRuntimeState.java", "diffHunk": "@@ -0,0 +1,43 @@\n+package org.corfudb.infrastructure.logreplication.runtime.fsm;\n+\n+/**\n+ * An interface for log replication runtime state classes.\n+ *\n+ * All log replication runtime states implement this interface.\n+ *\n+ * @author amartinezman\n+ */\n+public interface LogReplicationRuntimeState {\n+\n+    /**\n+     * Get LogReplicationRuntimeState type.\n+     */\n+    LogReplicationRuntimeStateType getType();\n+\n+    /**\n+     * Method to process a communication event.\n+     *\n+     * @return next LogReplicationState to transition to.\n+     */\n+    LogReplicationRuntimeState processEvent(LogReplicationRuntimeEvent event) throws IllegalTransitionException;\n+\n+    /**\n+     * On Entry\n+     *\n+     * @param from  LogReplicationRuntimeState transitioning from.\n+     */\n+    default void onEntry(LogReplicationRuntimeState from) {}\n+\n+    /**\n+     * On Exit\n+     *\n+     * @param to  LogReplicationRuntimeState transitioning to.\n+     */\n+    default void onExit(LogReplicationRuntimeState to) {}\n+\n+    /**\n+     * Provides capability to clear/clean state information onEntry.\n+     */\n+    default void clear() {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMDI1NTQ2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsLogEntryReader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoyMVrOG90-TA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOFQxNzowMzoyMVrOG90-TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIzNg==", "bodyText": "Codacy found an issue: Perhaps 'rt' could be replaced by a local variable.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484236", "createdAt": "2020-08-08T17:03:21Z", "author": {"login": "corfudb-bot"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsLogEntryReader.java", "diffHunk": "@@ -0,0 +1,305 @@\n+package org.corfudb.infrastructure.logreplication.replication.send.logreader;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import lombok.Getter;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.protocols.logprotocol.OpaqueEntry;\n+import org.corfudb.protocols.logprotocol.SMREntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.ObjectsView;\n+import org.corfudb.runtime.view.stream.OpaqueStream;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.infrastructure.logreplication.LogReplicationConfig.MAX_DATA_MSG_SIZE_SUPPORTED;\n+\n+@Slf4j\n+@NotThreadSafe\n+/**\n+ * Reading transaction log changes after a snapshot transfer for a specific set of streams.\n+ */\n+public class StreamsLogEntryReader implements LogEntryReader {\n+\n+    private CorfuRuntime rt;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b"}, "originalPosition": 37}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1851, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}