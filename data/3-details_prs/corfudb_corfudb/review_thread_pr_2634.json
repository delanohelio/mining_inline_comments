{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ5MTU1NjI1", "number": 2634, "reviewThreads": {"totalCount": 45, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOToxOTo0NlrOEPRLZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDo1NTo1NlrOERqiVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDQ1NTQwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOToxOTo0NlrOGy5Cwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOTo1NzowOFrOGy6mCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxNjU3OA==", "bodyText": "Even if current node's role did not change, it does not guarantee that others' role or config id is not changed...\nSo updating sender/receiver's config id is necessary here.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456016578", "createdAt": "2020-07-16T19:19:46Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -578,15 +581,18 @@ private void onStandbyClusterAddRemove(TopologyDescriptor discoveredTopology) {\n         log.debug(\"Standby Cluster has been added or removed from topology={}\", discoveredTopology);\n \n         // We only need to process new standby's if your role is of an ACTIVE cluster\n-        if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {\n-            return;\n-        }\n-\n-        if (replicationManager != null && isLeader.get()) {\n-            replicationManager.processStandbyChange(discoveredTopology);\n+        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n+            if (replicationManager != null && isLeader.get()) {\n+                replicationManager.processStandbyChange(discoveredTopology);\n+            }\n         }\n \n         updateLocalTopology(discoveredTopology);\n+        updateReplicationManagerTopology(discoveredTopology);\n+        // Update topology config id in metadata manager\n+        logReplicationMetadataManager.setupTopologyConfigId(topologyDescriptor.getTopologyConfigId());\n+        log.debug(\"Persist new topologyConfigId {}, cluster id={}, status={}\", topologyDescriptor.getTopologyConfigId(),\n+                localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c8d92fda4514da535e4abc56cc01dca1b15f059"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA0MTk5Mw==", "bodyText": "We have three update*** functions here, can you add comments about what they are doing? We keep the topologyConfigID at SinkManager and also for each logReplication Runtime. Is it possible to just keep one reference instead of multi like handling leaderShip?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456041993", "createdAt": "2020-07-16T19:57:08Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -578,15 +581,18 @@ private void onStandbyClusterAddRemove(TopologyDescriptor discoveredTopology) {\n         log.debug(\"Standby Cluster has been added or removed from topology={}\", discoveredTopology);\n \n         // We only need to process new standby's if your role is of an ACTIVE cluster\n-        if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {\n-            return;\n-        }\n-\n-        if (replicationManager != null && isLeader.get()) {\n-            replicationManager.processStandbyChange(discoveredTopology);\n+        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n+            if (replicationManager != null && isLeader.get()) {\n+                replicationManager.processStandbyChange(discoveredTopology);\n+            }\n         }\n \n         updateLocalTopology(discoveredTopology);\n+        updateReplicationManagerTopology(discoveredTopology);\n+        // Update topology config id in metadata manager\n+        logReplicationMetadataManager.setupTopologyConfigId(topologyDescriptor.getTopologyConfigId());\n+        log.debug(\"Persist new topologyConfigId {}, cluster id={}, status={}\", topologyDescriptor.getTopologyConfigId(),\n+                localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxNjU3OA=="}, "originalCommit": {"oid": "8c8d92fda4514da535e4abc56cc01dca1b15f059"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDQ2Mjg5OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOToyMTozOVrOGy5HYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMToxNToyOFrOG2gjng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxNzc2Mw==", "bodyText": "We do not assume that config id change implies a role change, so it is possible that we have a higher config id.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456017763", "createdAt": "2020-07-16T19:21:39Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -177,35 +179,41 @@ private void stopLogReplicationRuntime(String remoteClusterId) {\n         }\n     }\n \n+    /**\n+     * Update Log Replication Runtime config id.\n+     */\n+    public void updateRuntimeConfigId(TopologyDescriptor newConfig) {\n+        runtimeToRemoteCluster.values().forEach(runtime -> runtime.updateFSMConfigId(newConfig));\n+    }\n+\n     /**\n      * The notification of change of adding/removing standby's without epoch change.\n      *\n      * @param newConfig has the same topologyConfigId as the current config\n      */\n     public void processStandbyChange(TopologyDescriptor newConfig) {\n         if (newConfig.getTopologyConfigId() != topology.getTopologyConfigId()) {\n-            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+            log.warn(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c8d92fda4514da535e4abc56cc01dca1b15f059"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA1MDExNg==", "bodyText": "We may add more comments to the function to explain in what conditions this function will be called.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456050116", "createdAt": "2020-07-16T20:13:16Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -177,35 +179,41 @@ private void stopLogReplicationRuntime(String remoteClusterId) {\n         }\n     }\n \n+    /**\n+     * Update Log Replication Runtime config id.\n+     */\n+    public void updateRuntimeConfigId(TopologyDescriptor newConfig) {\n+        runtimeToRemoteCluster.values().forEach(runtime -> runtime.updateFSMConfigId(newConfig));\n+    }\n+\n     /**\n      * The notification of change of adding/removing standby's without epoch change.\n      *\n      * @param newConfig has the same topologyConfigId as the current config\n      */\n     public void processStandbyChange(TopologyDescriptor newConfig) {\n         if (newConfig.getTopologyConfigId() != topology.getTopologyConfigId()) {\n-            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+            log.warn(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxNzc2Mw=="}, "originalCommit": {"oid": "8c8d92fda4514da535e4abc56cc01dca1b15f059"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc4NjU1NA==", "bodyText": "if the topologyId can change on a standby change, why are we logging it as a warning?  Yes, it will be good to add comments stating any assumptions/expectations", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459786554", "createdAt": "2020-07-23T23:41:26Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -177,35 +179,41 @@ private void stopLogReplicationRuntime(String remoteClusterId) {\n         }\n     }\n \n+    /**\n+     * Update Log Replication Runtime config id.\n+     */\n+    public void updateRuntimeConfigId(TopologyDescriptor newConfig) {\n+        runtimeToRemoteCluster.values().forEach(runtime -> runtime.updateFSMConfigId(newConfig));\n+    }\n+\n     /**\n      * The notification of change of adding/removing standby's without epoch change.\n      *\n      * @param newConfig has the same topologyConfigId as the current config\n      */\n     public void processStandbyChange(TopologyDescriptor newConfig) {\n         if (newConfig.getTopologyConfigId() != topology.getTopologyConfigId()) {\n-            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+            log.warn(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxNzc2Mw=="}, "originalCommit": {"oid": "8c8d92fda4514da535e4abc56cc01dca1b15f059"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwOTY5NA==", "bodyText": "Ideally, there is no config id change when we only processStandbyChange. I will add a short comment.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459809694", "createdAt": "2020-07-24T01:15:28Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -177,35 +179,41 @@ private void stopLogReplicationRuntime(String remoteClusterId) {\n         }\n     }\n \n+    /**\n+     * Update Log Replication Runtime config id.\n+     */\n+    public void updateRuntimeConfigId(TopologyDescriptor newConfig) {\n+        runtimeToRemoteCluster.values().forEach(runtime -> runtime.updateFSMConfigId(newConfig));\n+    }\n+\n     /**\n      * The notification of change of adding/removing standby's without epoch change.\n      *\n      * @param newConfig has the same topologyConfigId as the current config\n      */\n     public void processStandbyChange(TopologyDescriptor newConfig) {\n         if (newConfig.getTopologyConfigId() != topology.getTopologyConfigId()) {\n-            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+            log.warn(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxNzc2Mw=="}, "originalCommit": {"oid": "8c8d92fda4514da535e4abc56cc01dca1b15f059"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDQ5NDQwOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOToyODozOFrOGy5a-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQxOToyODozOFrOGy5a-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAyMjc3OQ==", "bodyText": "Since there is no way to make sure apply completes before the writer reset, we do not support DuringTransferPhase & DuringApplyPhase now.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456022779", "createdAt": "2020-07-16T19:28:38Z", "author": {"login": "zhangn49"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -93,104 +91,520 @@ public void testLogReplicationRoleFlip() throws Exception {\n         assertThat(mapActive.size()).isZero();\n         assertThat(mapStandby.size()).isZero();\n \n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n         // Write 10 entry to active map\n         for (int i = 0; i < firstBatch; i++) {\n             activeRuntime.getObjectsView().TXBegin();\n             mapActive.put(String.valueOf(i), i);\n             activeRuntime.getObjectsView().TXEnd();\n         }\n         assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n \n-        System.out.println(\"First batch size is \" + firstBatch + \", current standby tail is \" +\n-                standbyRuntime.getAddressSpaceView().getLogTail() + \", and active tail is \" +\n-                activeRuntime.getAddressSpaceView().getLogTail());\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n \n-        ExecutorService executorService = Executors.newFixedThreadPool(2);\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8683374605c376a5d2b2372c1ac090e903703a4b"}, "originalPosition": 241}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDY2MjU0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMDoxMjoyMFrOGy7ECA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzoxNjo0MFrOGy_8tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA0OTY3Mg==", "bodyText": "If the topologyConfigId has been change, it will overrule the processStandbyChange. processStandbyChange only is called when the topologyConfigId doesn't change and the list of standbys have been changed.\nIs the logic correct that processStandbyChange called before updating the localTopology?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456049672", "createdAt": "2020-07-16T20:12:20Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -578,15 +581,18 @@ private void onStandbyClusterAddRemove(TopologyDescriptor discoveredTopology) {\n         log.debug(\"Standby Cluster has been added or removed from topology={}\", discoveredTopology);\n \n         // We only need to process new standby's if your role is of an ACTIVE cluster\n-        if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {\n-            return;\n-        }\n-\n-        if (replicationManager != null && isLeader.get()) {\n-            replicationManager.processStandbyChange(discoveredTopology);\n+        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n+            if (replicationManager != null && isLeader.get()) {\n+                replicationManager.processStandbyChange(discoveredTopology);\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0844c5736f25bc52d186178fb5d5099fb711d097"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyOTcxOA==", "bodyText": "Since we don't assume that config id change implies a role change anymore, processStandbyChange won't be overruled. Now we only detect if local node role changes or not, then perform onClusterRoleChange  or onStandbyClusterAddRemove\n\nIs the logic correct that processStandbyChange called before updating the localTopology?\n\nI think the logic is correct, since stopping old replication relies on old config.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456129718", "createdAt": "2020-07-16T23:16:40Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -578,15 +581,18 @@ private void onStandbyClusterAddRemove(TopologyDescriptor discoveredTopology) {\n         log.debug(\"Standby Cluster has been added or removed from topology={}\", discoveredTopology);\n \n         // We only need to process new standby's if your role is of an ACTIVE cluster\n-        if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {\n-            return;\n-        }\n-\n-        if (replicationManager != null && isLeader.get()) {\n-            replicationManager.processStandbyChange(discoveredTopology);\n+        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n+            if (replicationManager != null && isLeader.get()) {\n+                replicationManager.processStandbyChange(discoveredTopology);\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA0OTY3Mg=="}, "originalCommit": {"oid": "0844c5736f25bc52d186178fb5d5099fb711d097"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NDY3MzU4OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMDoxNTo0NlrOGy7Ksg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQyMzoyMDo1OFrOGzABpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA1MTM3OA==", "bodyText": "Can we also add a check of the log replication metadata at the standby side. It should indicate a status of snapshot full sync has finished and the timestamp for the snapshot full sync should agree with the current active log tail.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456051378", "createdAt": "2020-07-16T20:15:46Z", "author": {"login": "xiaoqin2012"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -93,104 +91,520 @@ public void testLogReplicationRoleFlip() throws Exception {\n         assertThat(mapActive.size()).isZero();\n         assertThat(mapStandby.size()).isZero();\n \n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n         // Write 10 entry to active map\n         for (int i = 0; i < firstBatch; i++) {\n             activeRuntime.getObjectsView().TXBegin();\n             mapActive.put(String.valueOf(i), i);\n             activeRuntime.getObjectsView().TXEnd();\n         }\n         assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0844c5736f25bc52d186178fb5d5099fb711d097"}, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzMDk4Mg==", "bodyText": "Yeah, it makes sense to check metadata. I need to add helper functions to do some Corfu table queries...\nI will make sure this PR's logic is correct, then I will have a look at metadata tables and add extra checks.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456130982", "createdAt": "2020-07-16T23:20:58Z", "author": {"login": "zhangn49"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -93,104 +91,520 @@ public void testLogReplicationRoleFlip() throws Exception {\n         assertThat(mapActive.size()).isZero();\n         assertThat(mapStandby.size()).isZero();\n \n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n         // Write 10 entry to active map\n         for (int i = 0; i < firstBatch; i++) {\n             activeRuntime.getObjectsView().TXBegin();\n             mapActive.put(String.valueOf(i), i);\n             activeRuntime.getObjectsView().TXEnd();\n         }\n         assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA1MTM3OA=="}, "originalCommit": {"oid": "0844c5736f25bc52d186178fb5d5099fb711d097"}, "originalPosition": 172}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTk3Nzc0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/TopologyDescriptor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNjozNDo1MlrOGzHD9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNjozNDo1MlrOGzHD9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjI0NjI2MA==", "bodyText": "Replace with:\nthis(topologyConfigId, activeClusters, standbyClusters); invalidClusters.forEach(invalidCluster -> this.invalidClusters.put(invalidCluster.getClusterId(), invalidCluster));", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456246260", "createdAt": "2020-07-17T06:34:52Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/TopologyDescriptor.java", "diffHunk": "@@ -89,13 +90,28 @@ public TopologyDescriptor(long topologyConfigId, @NonNull List<ClusterDescriptor\n         this.standbyClusters = new HashMap<>();\n         this.invalidClusters = new HashMap<>();\n \n-        if(activeClusters != null) {\n-            activeClusters.forEach(activeCluster -> this.activeClusters.put(activeCluster.getClusterId(), activeCluster));\n-        }\n+        activeClusters.forEach(activeCluster -> this.activeClusters.put(activeCluster.getClusterId(), activeCluster));\n+        standbyClusters.forEach(standbyCluster -> this.standbyClusters.put(standbyCluster.getClusterId(), standbyCluster));\n+    }\n \n-        if(standbyClusters != null) {\n-            standbyClusters.forEach(standbyCluster -> this.standbyClusters.put(standbyCluster.getClusterId(), standbyCluster));\n-        }\n+    /**\n+     * Constructor\n+     *\n+     * @param topologyConfigId topology configuration identifier (epoch)\n+     * @param activeClusters active cluster's\n+     * @param standbyClusters standby cluster's\n+     * @param invalidClusters invalid cluster's\n+     */\n+    public TopologyDescriptor(long topologyConfigId, @NonNull List<ClusterDescriptor> activeClusters,\n+                              @NonNull List<ClusterDescriptor> standbyClusters, @NonNull List<ClusterDescriptor> invalidClusters) {\n+        this.topologyConfigId = topologyConfigId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0844c5736f25bc52d186178fb5d5099fb711d097"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NTk4MjAyOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNjozNjoyOVrOGzHGRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwNjozNjoyOVrOGzHGRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjI0Njg1NQ==", "bodyText": "We should fix this path to point something local in the project repo.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r456246855", "createdAt": "2020-07-17T06:36:29Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -1,33 +1,49 @@\n package org.corfudb.infrastructure.logreplication.infrastructure.plugins;\n \n import lombok.Getter;\n+import lombok.NonNull;\n import lombok.extern.slf4j.Slf4j;\n import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n import org.corfudb.infrastructure.logreplication.infrastructure.NodeDescriptor;\n import org.corfudb.infrastructure.logreplication.infrastructure.TopologyDescriptor;\n-import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.CorfuStoreMetadata;\n+import org.corfudb.runtime.Messages;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuStreamEntries;\n+import org.corfudb.runtime.collections.CorfuStreamEntry;\n+import org.corfudb.runtime.collections.StreamListener;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.collections.TableSchema;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n \n import java.io.File;\n-import java.io.FileNotFoundException;\n import java.io.FileReader;\n import java.io.IOException;\n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Properties;\n import java.util.Set;\n import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n \n-import static java.lang.Thread.sleep;\n-\n+/**\n+ * This class extends CorfuReplicationClusterManagerAdapter, provides topology config API\n+ * for integration tests. The initial topology config should be valid, which means it has only\n+ * one active cluster, and one or more standby clusters.\n+ */\n @Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n public class DefaultClusterManager extends CorfuReplicationClusterManagerBaseAdapter {\n-    public static long epoch = 0;\n-    public static final int changeInterval = 5000;\n-    public static final String config_file = \"/config/corfu/corfu_replication_config.properties\";\n+    public static final String CONFIG_FILE_PATH = \"/config/corfu/corfu_replication_config.properties\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0844c5736f25bc52d186178fb5d5099fb711d097"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjcyMTg2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMjoyMzo0NFrOG0lvfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMjoyMzo0NFrOG0lvfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc5NzUwMA==", "bodyText": "Just for completeness, can you please remove the TODO at the beginning of this method and also add a comment describing that cluster change from active to standby is a two step process. We first confirm that we are ready to do the cluster role change, so by the time we receive that change of cluster notification, nothing needs to be done, other than stop.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r457797500", "createdAt": "2020-07-21T02:23:44Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -510,6 +510,9 @@ public void onClusterRoleChange(TopologyDescriptor newTopology) {\n         log.debug(\"Persist new topologyConfigId {}, cluster id={}, status={}\", topologyDescriptor.getTopologyConfigId(),\n                 localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n \n+        // Update replication manager", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4e49b58949ad335573f1110ea7246f8c79a8822"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjcyMzE4OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMjoyNDozMFrOG0lwUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMjoyNDozMFrOG0lwUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc5NzcxNA==", "bodyText": "status -> role", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r457797714", "createdAt": "2020-07-21T02:24:30Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -510,6 +510,9 @@ public void onClusterRoleChange(TopologyDescriptor newTopology) {\n         log.debug(\"Persist new topologyConfigId {}, cluster id={}, status={}\", topologyDescriptor.getTopologyConfigId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4e49b58949ad335573f1110ea7246f8c79a8822"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjcyNjUzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMjoyNjowMVrOG0lyLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNToyNTo1MlrOG2PyLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc5ODE4OA==", "bodyText": "Just curious, if we change from active to standby, or we're a standby cluster, there is no need of updating the replication manager topology?...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r457798188", "createdAt": "2020-07-21T02:26:01Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -510,6 +510,9 @@ public void onClusterRoleChange(TopologyDescriptor newTopology) {\n         log.debug(\"Persist new topologyConfigId {}, cluster id={}, status={}\", topologyDescriptor.getTopologyConfigId(),\n                 localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n \n+        // Update replication manager\n+        updateReplicationManagerTopology(newTopology);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4e49b58949ad335573f1110ea7246f8c79a8822"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTUzNDg5Mw==", "bodyText": "Let's assume that we start with topology[0]: {active: A, standby:B}, then update with topology[1]:{standby: A, B}. If we do not update replication manager topology, cluster B will have outdated epoch 0.\nNext time a new active C comes in, topology is [2]{active C, standby:A, B}. For cluster B, its role never changed, and it won't update replication manager topology.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459534893", "createdAt": "2020-07-23T15:25:52Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -510,6 +510,9 @@ public void onClusterRoleChange(TopologyDescriptor newTopology) {\n         log.debug(\"Persist new topologyConfigId {}, cluster id={}, status={}\", topologyDescriptor.getTopologyConfigId(),\n                 localClusterDescriptor.getClusterId(), localClusterDescriptor.getRole());\n \n+        // Update replication manager\n+        updateReplicationManagerTopology(newTopology);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc5ODE4OA=="}, "originalCommit": {"oid": "e4e49b58949ad335573f1110ea7246f8c79a8822"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1Njc0NDY2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMjozNTo0N1rOG0l8kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMToxMzo1NlrOG2giHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzgwMDg1MA==", "bodyText": "Can't this be updated at the end of processStandbyChange.\nAlso, we only want this to run if we are active right? it would also run for standby.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r457800850", "createdAt": "2020-07-21T02:35:47Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -578,15 +581,18 @@ private void onStandbyClusterAddRemove(TopologyDescriptor discoveredTopology) {\n         log.debug(\"Standby Cluster has been added or removed from topology={}\", discoveredTopology);\n \n         // We only need to process new standby's if your role is of an ACTIVE cluster\n-        if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {\n-            return;\n-        }\n-\n-        if (replicationManager != null && isLeader.get()) {\n-            replicationManager.processStandbyChange(discoveredTopology);\n+        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n+            if (replicationManager != null && isLeader.get()) {\n+                replicationManager.processStandbyChange(discoveredTopology);\n+            }\n         }\n \n         updateLocalTopology(discoveredTopology);\n+        updateReplicationManagerTopology(discoveredTopology);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4e49b58949ad335573f1110ea7246f8c79a8822"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTUzNjE3Nw==", "bodyText": "Just like my example above, we need to keep replication manager's topology epoch updated.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459536177", "createdAt": "2020-07-23T15:27:40Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -578,15 +581,18 @@ private void onStandbyClusterAddRemove(TopologyDescriptor discoveredTopology) {\n         log.debug(\"Standby Cluster has been added or removed from topology={}\", discoveredTopology);\n \n         // We only need to process new standby's if your role is of an ACTIVE cluster\n-        if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {\n-            return;\n-        }\n-\n-        if (replicationManager != null && isLeader.get()) {\n-            replicationManager.processStandbyChange(discoveredTopology);\n+        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n+            if (replicationManager != null && isLeader.get()) {\n+                replicationManager.processStandbyChange(discoveredTopology);\n+            }\n         }\n \n         updateLocalTopology(discoveredTopology);\n+        updateReplicationManagerTopology(discoveredTopology);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzgwMDg1MA=="}, "originalCommit": {"oid": "e4e49b58949ad335573f1110ea7246f8c79a8822"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc4NTIzMw==", "bodyText": "earlier we invoked updateLocalTopology() and updateReplicationManagerTopology() only on the active but now it will be invoked on standby also.  Is it the intended behavior?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459785233", "createdAt": "2020-07-23T23:37:17Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -578,15 +581,18 @@ private void onStandbyClusterAddRemove(TopologyDescriptor discoveredTopology) {\n         log.debug(\"Standby Cluster has been added or removed from topology={}\", discoveredTopology);\n \n         // We only need to process new standby's if your role is of an ACTIVE cluster\n-        if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {\n-            return;\n-        }\n-\n-        if (replicationManager != null && isLeader.get()) {\n-            replicationManager.processStandbyChange(discoveredTopology);\n+        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n+            if (replicationManager != null && isLeader.get()) {\n+                replicationManager.processStandbyChange(discoveredTopology);\n+            }\n         }\n \n         updateLocalTopology(discoveredTopology);\n+        updateReplicationManagerTopology(discoveredTopology);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzgwMDg1MA=="}, "originalCommit": {"oid": "e4e49b58949ad335573f1110ea7246f8c79a8822"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwOTMwOQ==", "bodyText": "@pankti-m  Yes, please see my example at line 515", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459809309", "createdAt": "2020-07-24T01:13:56Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -578,15 +581,18 @@ private void onStandbyClusterAddRemove(TopologyDescriptor discoveredTopology) {\n         log.debug(\"Standby Cluster has been added or removed from topology={}\", discoveredTopology);\n \n         // We only need to process new standby's if your role is of an ACTIVE cluster\n-        if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {\n-            return;\n-        }\n-\n-        if (replicationManager != null && isLeader.get()) {\n-            replicationManager.processStandbyChange(discoveredTopology);\n+        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n+            if (replicationManager != null && isLeader.get()) {\n+                replicationManager.processStandbyChange(discoveredTopology);\n+            }\n         }\n \n         updateLocalTopology(discoveredTopology);\n+        updateReplicationManagerTopology(discoveredTopology);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzgwMDg1MA=="}, "originalCommit": {"oid": "e4e49b58949ad335573f1110ea7246f8c79a8822"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1Njc0NTc2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMjozNjoyNVrOG0l9QQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMjozNjoyNVrOG0l9QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzgwMTAyNQ==", "bodyText": "status -> role", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r457801025", "createdAt": "2020-07-21T02:36:25Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -578,15 +581,18 @@ private void onStandbyClusterAddRemove(TopologyDescriptor discoveredTopology) {\n         log.debug(\"Standby Cluster has been added or removed from topology={}\", discoveredTopology);\n \n         // We only need to process new standby's if your role is of an ACTIVE cluster\n-        if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {\n-            return;\n-        }\n-\n-        if (replicationManager != null && isLeader.get()) {\n-            replicationManager.processStandbyChange(discoveredTopology);\n+        if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {\n+            if (replicationManager != null && isLeader.get()) {\n+                replicationManager.processStandbyChange(discoveredTopology);\n+            }\n         }\n \n         updateLocalTopology(discoveredTopology);\n+        updateReplicationManagerTopology(discoveredTopology);\n+        // Update topology config id in metadata manager\n+        logReplicationMetadataManager.setupTopologyConfigId(topologyDescriptor.getTopologyConfigId());\n+        log.debug(\"Persist new topologyConfigId {}, cluster id={}, status={}\", topologyDescriptor.getTopologyConfigId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4e49b58949ad335573f1110ea7246f8c79a8822"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2MDUxODU0OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQyMToyMDo0MVrOG1KNhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNjoxOToxNFrOG2R9wA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODM5NTAxNQ==", "bodyText": "What are these OP? can we have a general description?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r458395015", "createdAt": "2020-07-21T21:20:41Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -41,28 +57,72 @@\n \n     private static final String ACTIVE_CLUSTER_NODE = \"primary_site_node\";\n     private static final String STANDBY_CLUSTER_NODE = \"standby_site_node\";\n-    private boolean ifShutdown = false;\n+\n+\n+    public static final String CONFIG_NAMESPACE = \"ns_lr_config_it\";\n+    public static final String CONFIG_TABLE_NAME = \"lr_config_it\";\n+    public static final CommonTypes.Uuid OP_RESUME = CommonTypes.Uuid.newBuilder().setLsb(0L).setMsb(0L).build();\n+    public static final CommonTypes.Uuid OP_SWITCH = CommonTypes.Uuid.newBuilder().setLsb(1L).setMsb(1L).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd6336ceced3b28d43c705b2576499358c0773e9"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3MDYyNA==", "bodyText": "It is operations. I think it is kind of ugly to hardcode it and I will try to directly write new config to tables.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459570624", "createdAt": "2020-07-23T16:19:14Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -41,28 +57,72 @@\n \n     private static final String ACTIVE_CLUSTER_NODE = \"primary_site_node\";\n     private static final String STANDBY_CLUSTER_NODE = \"standby_site_node\";\n-    private boolean ifShutdown = false;\n+\n+\n+    public static final String CONFIG_NAMESPACE = \"ns_lr_config_it\";\n+    public static final String CONFIG_TABLE_NAME = \"lr_config_it\";\n+    public static final CommonTypes.Uuid OP_RESUME = CommonTypes.Uuid.newBuilder().setLsb(0L).setMsb(0L).build();\n+    public static final CommonTypes.Uuid OP_SWITCH = CommonTypes.Uuid.newBuilder().setLsb(1L).setMsb(1L).build();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODM5NTAxNQ=="}, "originalCommit": {"oid": "fd6336ceced3b28d43c705b2576499358c0773e9"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDU0OTg3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxOToxODowOFrOG1wuGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxOToxODowOFrOG1wuGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTAyNTk0NA==", "bodyText": "we can remove this commented code.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459025944", "createdAt": "2020-07-22T19:18:08Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -177,35 +179,41 @@ private void stopLogReplicationRuntime(String remoteClusterId) {\n         }\n     }\n \n+    /**\n+     * Update Log Replication Runtime config id.\n+     */\n+    public void updateRuntimeConfigId(TopologyDescriptor newConfig) {\n+        runtimeToRemoteCluster.values().forEach(runtime -> runtime.updateFSMConfigId(newConfig));\n+    }\n+\n     /**\n      * The notification of change of adding/removing standby's without epoch change.\n      *\n      * @param newConfig has the same topologyConfigId as the current config\n      */\n     public void processStandbyChange(TopologyDescriptor newConfig) {\n         if (newConfig.getTopologyConfigId() != topology.getTopologyConfigId()) {\n-            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+            log.warn(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n                     \"topologyConfigId as the current one {}\", newConfig, topology);\n-            return;\n         }\n \n-        Map<String, ClusterDescriptor> newStandbys = newConfig.getStandbyClusters();\n-        Map<String, ClusterDescriptor> currentStandbys = topology.getStandbyClusters();\n-        newStandbys.keySet().retainAll(currentStandbys.keySet());\n-        Set<String> standbysToRemove = currentStandbys.keySet();\n-        standbysToRemove.removeAll(newStandbys.keySet());\n+        Set<String> currentStandbys = new HashSet<>(topology.getStandbyClusters().keySet());\n+        Set<String> newStandbys = new HashSet<>(newConfig.getStandbyClusters().keySet());\n+        Set<String> intersection = Sets.intersection(currentStandbys, newStandbys);\n \n-        /*\n-         * Remove standbys that are not in the new config\n-         */\n+        //standbysToRemove = currentStandbys - intersection", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDU2NDA3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxOToyMjoxNVrOG1w3LQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNTozMToxMFrOG2QAxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTAyODI2OQ==", "bodyText": "is this the corfu epoch or topologyConfigId?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459028269", "createdAt": "2020-07-22T19:22:15Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -41,28 +57,72 @@\n \n     private static final String ACTIVE_CLUSTER_NODE = \"primary_site_node\";\n     private static final String STANDBY_CLUSTER_NODE = \"standby_site_node\";\n-    private boolean ifShutdown = false;\n+\n+\n+    public static final String CONFIG_NAMESPACE = \"ns_lr_config_it\";\n+    public static final String CONFIG_TABLE_NAME = \"lr_config_it\";\n+    public static final CommonTypes.Uuid OP_RESUME = CommonTypes.Uuid.newBuilder().setLsb(0L).setMsb(0L).build();\n+    public static final CommonTypes.Uuid OP_SWITCH = CommonTypes.Uuid.newBuilder().setLsb(1L).setMsb(1L).build();\n+    public static final CommonTypes.Uuid OP_TWO_ACTIVE = CommonTypes.Uuid.newBuilder().setLsb(2L).setMsb(2L).build();\n+    public static final CommonTypes.Uuid OP_ALL_STANDBY = CommonTypes.Uuid.newBuilder().setLsb(3L).setMsb(3L).build();\n+    public static final CommonTypes.Uuid OP_INVALID = CommonTypes.Uuid.newBuilder().setLsb(4L).setMsb(4L).build();\n+\n+    @Getter\n+    private long epoch;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTUzODYyOA==", "bodyText": "It is configId. Renamed.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459538628", "createdAt": "2020-07-23T15:31:10Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -41,28 +57,72 @@\n \n     private static final String ACTIVE_CLUSTER_NODE = \"primary_site_node\";\n     private static final String STANDBY_CLUSTER_NODE = \"standby_site_node\";\n-    private boolean ifShutdown = false;\n+\n+\n+    public static final String CONFIG_NAMESPACE = \"ns_lr_config_it\";\n+    public static final String CONFIG_TABLE_NAME = \"lr_config_it\";\n+    public static final CommonTypes.Uuid OP_RESUME = CommonTypes.Uuid.newBuilder().setLsb(0L).setMsb(0L).build();\n+    public static final CommonTypes.Uuid OP_SWITCH = CommonTypes.Uuid.newBuilder().setLsb(1L).setMsb(1L).build();\n+    public static final CommonTypes.Uuid OP_TWO_ACTIVE = CommonTypes.Uuid.newBuilder().setLsb(2L).setMsb(2L).build();\n+    public static final CommonTypes.Uuid OP_ALL_STANDBY = CommonTypes.Uuid.newBuilder().setLsb(3L).setMsb(3L).build();\n+    public static final CommonTypes.Uuid OP_INVALID = CommonTypes.Uuid.newBuilder().setLsb(4L).setMsb(4L).build();\n+\n+    @Getter\n+    private long epoch;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTAyODI2OQ=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDU3MDQ3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxOToyNDoyMVrOG1w7Ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNTozNzozNFrOG2QSNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTAyOTMwNw==", "bodyText": "Should this exception be thrown so the test fails? or can we proceed without this table being opened in the right way?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459029307", "createdAt": "2020-07-22T19:24:21Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -41,28 +57,72 @@\n \n     private static final String ACTIVE_CLUSTER_NODE = \"primary_site_node\";\n     private static final String STANDBY_CLUSTER_NODE = \"standby_site_node\";\n-    private boolean ifShutdown = false;\n+\n+\n+    public static final String CONFIG_NAMESPACE = \"ns_lr_config_it\";\n+    public static final String CONFIG_TABLE_NAME = \"lr_config_it\";\n+    public static final CommonTypes.Uuid OP_RESUME = CommonTypes.Uuid.newBuilder().setLsb(0L).setMsb(0L).build();\n+    public static final CommonTypes.Uuid OP_SWITCH = CommonTypes.Uuid.newBuilder().setLsb(1L).setMsb(1L).build();\n+    public static final CommonTypes.Uuid OP_TWO_ACTIVE = CommonTypes.Uuid.newBuilder().setLsb(2L).setMsb(2L).build();\n+    public static final CommonTypes.Uuid OP_ALL_STANDBY = CommonTypes.Uuid.newBuilder().setLsb(3L).setMsb(3L).build();\n+    public static final CommonTypes.Uuid OP_INVALID = CommonTypes.Uuid.newBuilder().setLsb(4L).setMsb(4L).build();\n+\n+    @Getter\n+    private long epoch;\n+\n+    @Getter\n+    private boolean shutdown;\n \n     @Getter\n-    public SiteManagerCallback siteManagerCallback;\n+    public ClusterManagerCallback clusterManagerCallback;\n \n     private Thread thread;\n \n+    private CorfuRuntime corfuRuntime;\n \n+    private CorfuStore corfuStore;\n \n     public void start() {\n-        siteManagerCallback = new SiteManagerCallback(this);\n-        thread = new Thread(siteManagerCallback);\n+        epoch = 0L;\n+        shutdown = false;\n+        topologyConfig = constructTopologyConfigMsg();\n+        clusterManagerCallback = new ClusterManagerCallback(this);\n+        corfuRuntime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder().build())\n+                .parseConfigurationString(\"localhost:9000\")\n+                .setTransactionLogging(true)\n+                .connect();\n+        corfuStore = new CorfuStore(corfuRuntime);\n+        CorfuStoreMetadata.Timestamp ts = corfuStore.getTimestamp();\n+        try {\n+            Table<Messages.Uuid, Messages.Uuid, Messages.Uuid> table = corfuStore.openTable(\n+                    CONFIG_NAMESPACE, CONFIG_TABLE_NAME,\n+                    Messages.Uuid.class, Messages.Uuid.class, Messages.Uuid.class,\n+                    TableOptions.builder().build()\n+            );\n+            table.clear();\n+        } catch (Exception e) {\n+            // Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU0MzA5NQ==", "bodyText": "Yes, it should be thrown and discovery service will timeout and fail the test.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459543095", "createdAt": "2020-07-23T15:37:34Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -41,28 +57,72 @@\n \n     private static final String ACTIVE_CLUSTER_NODE = \"primary_site_node\";\n     private static final String STANDBY_CLUSTER_NODE = \"standby_site_node\";\n-    private boolean ifShutdown = false;\n+\n+\n+    public static final String CONFIG_NAMESPACE = \"ns_lr_config_it\";\n+    public static final String CONFIG_TABLE_NAME = \"lr_config_it\";\n+    public static final CommonTypes.Uuid OP_RESUME = CommonTypes.Uuid.newBuilder().setLsb(0L).setMsb(0L).build();\n+    public static final CommonTypes.Uuid OP_SWITCH = CommonTypes.Uuid.newBuilder().setLsb(1L).setMsb(1L).build();\n+    public static final CommonTypes.Uuid OP_TWO_ACTIVE = CommonTypes.Uuid.newBuilder().setLsb(2L).setMsb(2L).build();\n+    public static final CommonTypes.Uuid OP_ALL_STANDBY = CommonTypes.Uuid.newBuilder().setLsb(3L).setMsb(3L).build();\n+    public static final CommonTypes.Uuid OP_INVALID = CommonTypes.Uuid.newBuilder().setLsb(4L).setMsb(4L).build();\n+\n+    @Getter\n+    private long epoch;\n+\n+    @Getter\n+    private boolean shutdown;\n \n     @Getter\n-    public SiteManagerCallback siteManagerCallback;\n+    public ClusterManagerCallback clusterManagerCallback;\n \n     private Thread thread;\n \n+    private CorfuRuntime corfuRuntime;\n \n+    private CorfuStore corfuStore;\n \n     public void start() {\n-        siteManagerCallback = new SiteManagerCallback(this);\n-        thread = new Thread(siteManagerCallback);\n+        epoch = 0L;\n+        shutdown = false;\n+        topologyConfig = constructTopologyConfigMsg();\n+        clusterManagerCallback = new ClusterManagerCallback(this);\n+        corfuRuntime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder().build())\n+                .parseConfigurationString(\"localhost:9000\")\n+                .setTransactionLogging(true)\n+                .connect();\n+        corfuStore = new CorfuStore(corfuRuntime);\n+        CorfuStoreMetadata.Timestamp ts = corfuStore.getTimestamp();\n+        try {\n+            Table<Messages.Uuid, Messages.Uuid, Messages.Uuid> table = corfuStore.openTable(\n+                    CONFIG_NAMESPACE, CONFIG_TABLE_NAME,\n+                    Messages.Uuid.class, Messages.Uuid.class, Messages.Uuid.class,\n+                    TableOptions.builder().build()\n+            );\n+            table.clear();\n+        } catch (Exception e) {\n+            // Ignore", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTAyOTMwNw=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDYxNDk5OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxOTozNzoyN1rOG1xWkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNTo1Nzo0MFrOG2RILA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTAzNjMwNg==", "bodyText": "I think we wouldn't support several actives.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459036306", "createdAt": "2020-07-22T19:37:27Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU1NjkwOA==", "bodyText": "Yes, done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459556908", "createdAt": "2020-07-23T15:57:40Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTAzNjMwNg=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 204}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDY5NjkwOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDowMjowMFrOG1yKNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMToyNDo0OVrOG2grSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA0OTUyNQ==", "bodyText": "If I understand correctly, you are using this Listener, to determine changes in the topology if ever it is changed in the table, correct?\nIf that is true, then the ClusterManagerCallback is not really required, correct? you can just call clusterManager.updateTopologyConfig directly on the streamListener.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459049525", "createdAt": "2020-07-22T20:02:00Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n \n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n+        return new TopologyDescriptor(++epoch, newActiveClusters, newStandbyClusters);\n+    }\n \n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n-            } else {\n-                standbyClusters.add(standbyCluster);\n-            }\n-        }\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>());\n+    }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++epoch, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>(currentConfig.getActiveClusters().values());\n+        List<ClusterDescriptor> newInvalidClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newInvalidClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.INVALID)));\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>(), newInvalidClusters);\n+    }\n+\n+    /**\n+     * Bring topology config back to default valid config.\n+     **/\n+    public TopologyDescriptor generateDefaultValidConfig() {\n+        TopologyDescriptor defaultTopology = new TopologyDescriptor(constructTopologyConfigMsg());\n+        List<ClusterDescriptor> activeClusters = new ArrayList<>(defaultTopology.getActiveClusters().values());\n+        List<ClusterDescriptor> standbyClusters = new ArrayList<>(defaultTopology.getStandbyClusters().values());\n+\n+        return new TopologyDescriptor(++epoch, activeClusters, standbyClusters);\n     }\n \n     /**\n      * Testing purpose to generate cluster role change.\n      */\n-    public static class SiteManagerCallback implements Runnable {\n-        public boolean clusterRoleChange = false;\n-        DefaultClusterManager clusterManager;\n+    public static class ClusterManagerCallback implements Runnable {\n+        private final DefaultClusterManager clusterManager;\n+        private final LinkedBlockingQueue<TopologyDescriptor> queue;\n \n-        SiteManagerCallback(DefaultClusterManager clusterManager) {\n+        public ClusterManagerCallback(DefaultClusterManager clusterManager) {\n             this.clusterManager = clusterManager;\n+            queue = new LinkedBlockingQueue<>();\n+        }\n+\n+        public void applyNewTopologyConfig(@NonNull TopologyDescriptor descriptor) {\n+            log.info(\"Applying a new config {}\", descriptor);\n+            queue.add(descriptor);\n         }\n \n         @Override\n         public void run() {\n-            while (!clusterManager.ifShutdown) {\n+            while (!clusterManager.isShutdown()) {\n                 try {\n-                    sleep(changeInterval);\n-                    if (clusterRoleChange) {\n-                        TopologyDescriptor newConfig = changeActiveCluster(clusterManager.getTopologyConfig());\n-                        clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n-                        log.warn(\"Change the cluster config\");\n-                        clusterRoleChange = false;\n-                    }\n-                } catch (Exception e) {\n-                    log.error(\"Caught an exception\",e);\n+                    TopologyDescriptor newConfig = queue.take();\n+                    clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n+                    log.warn(\"change the cluster config\");\n+                } catch (InterruptedException ie) {\n+                    throw new UnrecoverableCorfuInterruptedError(ie);\n                 }\n             }\n         }\n     }\n \n+    public static class ConfigStreamListener implements StreamListener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU1OTE0MQ==", "bodyText": "Yes, it is not required.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459559141", "createdAt": "2020-07-23T16:01:02Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n \n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n+        return new TopologyDescriptor(++epoch, newActiveClusters, newStandbyClusters);\n+    }\n \n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n-            } else {\n-                standbyClusters.add(standbyCluster);\n-            }\n-        }\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>());\n+    }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++epoch, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>(currentConfig.getActiveClusters().values());\n+        List<ClusterDescriptor> newInvalidClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newInvalidClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.INVALID)));\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>(), newInvalidClusters);\n+    }\n+\n+    /**\n+     * Bring topology config back to default valid config.\n+     **/\n+    public TopologyDescriptor generateDefaultValidConfig() {\n+        TopologyDescriptor defaultTopology = new TopologyDescriptor(constructTopologyConfigMsg());\n+        List<ClusterDescriptor> activeClusters = new ArrayList<>(defaultTopology.getActiveClusters().values());\n+        List<ClusterDescriptor> standbyClusters = new ArrayList<>(defaultTopology.getStandbyClusters().values());\n+\n+        return new TopologyDescriptor(++epoch, activeClusters, standbyClusters);\n     }\n \n     /**\n      * Testing purpose to generate cluster role change.\n      */\n-    public static class SiteManagerCallback implements Runnable {\n-        public boolean clusterRoleChange = false;\n-        DefaultClusterManager clusterManager;\n+    public static class ClusterManagerCallback implements Runnable {\n+        private final DefaultClusterManager clusterManager;\n+        private final LinkedBlockingQueue<TopologyDescriptor> queue;\n \n-        SiteManagerCallback(DefaultClusterManager clusterManager) {\n+        public ClusterManagerCallback(DefaultClusterManager clusterManager) {\n             this.clusterManager = clusterManager;\n+            queue = new LinkedBlockingQueue<>();\n+        }\n+\n+        public void applyNewTopologyConfig(@NonNull TopologyDescriptor descriptor) {\n+            log.info(\"Applying a new config {}\", descriptor);\n+            queue.add(descriptor);\n         }\n \n         @Override\n         public void run() {\n-            while (!clusterManager.ifShutdown) {\n+            while (!clusterManager.isShutdown()) {\n                 try {\n-                    sleep(changeInterval);\n-                    if (clusterRoleChange) {\n-                        TopologyDescriptor newConfig = changeActiveCluster(clusterManager.getTopologyConfig());\n-                        clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n-                        log.warn(\"Change the cluster config\");\n-                        clusterRoleChange = false;\n-                    }\n-                } catch (Exception e) {\n-                    log.error(\"Caught an exception\",e);\n+                    TopologyDescriptor newConfig = queue.take();\n+                    clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n+                    log.warn(\"change the cluster config\");\n+                } catch (InterruptedException ie) {\n+                    throw new UnrecoverableCorfuInterruptedError(ie);\n                 }\n             }\n         }\n     }\n \n+    public static class ConfigStreamListener implements StreamListener {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA0OTUyNQ=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5ODk5OA==", "bodyText": "why do we need to use the table and a listener on it?  The test can just iterate thru all cases and inject different topologies right?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459798998", "createdAt": "2020-07-24T00:28:29Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n \n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n+        return new TopologyDescriptor(++epoch, newActiveClusters, newStandbyClusters);\n+    }\n \n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n-            } else {\n-                standbyClusters.add(standbyCluster);\n-            }\n-        }\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>());\n+    }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++epoch, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>(currentConfig.getActiveClusters().values());\n+        List<ClusterDescriptor> newInvalidClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newInvalidClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.INVALID)));\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>(), newInvalidClusters);\n+    }\n+\n+    /**\n+     * Bring topology config back to default valid config.\n+     **/\n+    public TopologyDescriptor generateDefaultValidConfig() {\n+        TopologyDescriptor defaultTopology = new TopologyDescriptor(constructTopologyConfigMsg());\n+        List<ClusterDescriptor> activeClusters = new ArrayList<>(defaultTopology.getActiveClusters().values());\n+        List<ClusterDescriptor> standbyClusters = new ArrayList<>(defaultTopology.getStandbyClusters().values());\n+\n+        return new TopologyDescriptor(++epoch, activeClusters, standbyClusters);\n     }\n \n     /**\n      * Testing purpose to generate cluster role change.\n      */\n-    public static class SiteManagerCallback implements Runnable {\n-        public boolean clusterRoleChange = false;\n-        DefaultClusterManager clusterManager;\n+    public static class ClusterManagerCallback implements Runnable {\n+        private final DefaultClusterManager clusterManager;\n+        private final LinkedBlockingQueue<TopologyDescriptor> queue;\n \n-        SiteManagerCallback(DefaultClusterManager clusterManager) {\n+        public ClusterManagerCallback(DefaultClusterManager clusterManager) {\n             this.clusterManager = clusterManager;\n+            queue = new LinkedBlockingQueue<>();\n+        }\n+\n+        public void applyNewTopologyConfig(@NonNull TopologyDescriptor descriptor) {\n+            log.info(\"Applying a new config {}\", descriptor);\n+            queue.add(descriptor);\n         }\n \n         @Override\n         public void run() {\n-            while (!clusterManager.ifShutdown) {\n+            while (!clusterManager.isShutdown()) {\n                 try {\n-                    sleep(changeInterval);\n-                    if (clusterRoleChange) {\n-                        TopologyDescriptor newConfig = changeActiveCluster(clusterManager.getTopologyConfig());\n-                        clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n-                        log.warn(\"Change the cluster config\");\n-                        clusterRoleChange = false;\n-                    }\n-                } catch (Exception e) {\n-                    log.error(\"Caught an exception\",e);\n+                    TopologyDescriptor newConfig = queue.take();\n+                    clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n+                    log.warn(\"change the cluster config\");\n+                } catch (InterruptedException ie) {\n+                    throw new UnrecoverableCorfuInterruptedError(ie);\n                 }\n             }\n         }\n     }\n \n+    public static class ConfigStreamListener implements StreamListener {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA0OTUyNQ=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgxMDU3Mw==", "bodyText": "@pankti-m Listener enables us not to busy-wait.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459810573", "createdAt": "2020-07-24T01:19:29Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n \n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n+        return new TopologyDescriptor(++epoch, newActiveClusters, newStandbyClusters);\n+    }\n \n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n-            } else {\n-                standbyClusters.add(standbyCluster);\n-            }\n-        }\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>());\n+    }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++epoch, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>(currentConfig.getActiveClusters().values());\n+        List<ClusterDescriptor> newInvalidClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newInvalidClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.INVALID)));\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>(), newInvalidClusters);\n+    }\n+\n+    /**\n+     * Bring topology config back to default valid config.\n+     **/\n+    public TopologyDescriptor generateDefaultValidConfig() {\n+        TopologyDescriptor defaultTopology = new TopologyDescriptor(constructTopologyConfigMsg());\n+        List<ClusterDescriptor> activeClusters = new ArrayList<>(defaultTopology.getActiveClusters().values());\n+        List<ClusterDescriptor> standbyClusters = new ArrayList<>(defaultTopology.getStandbyClusters().values());\n+\n+        return new TopologyDescriptor(++epoch, activeClusters, standbyClusters);\n     }\n \n     /**\n      * Testing purpose to generate cluster role change.\n      */\n-    public static class SiteManagerCallback implements Runnable {\n-        public boolean clusterRoleChange = false;\n-        DefaultClusterManager clusterManager;\n+    public static class ClusterManagerCallback implements Runnable {\n+        private final DefaultClusterManager clusterManager;\n+        private final LinkedBlockingQueue<TopologyDescriptor> queue;\n \n-        SiteManagerCallback(DefaultClusterManager clusterManager) {\n+        public ClusterManagerCallback(DefaultClusterManager clusterManager) {\n             this.clusterManager = clusterManager;\n+            queue = new LinkedBlockingQueue<>();\n+        }\n+\n+        public void applyNewTopologyConfig(@NonNull TopologyDescriptor descriptor) {\n+            log.info(\"Applying a new config {}\", descriptor);\n+            queue.add(descriptor);\n         }\n \n         @Override\n         public void run() {\n-            while (!clusterManager.ifShutdown) {\n+            while (!clusterManager.isShutdown()) {\n                 try {\n-                    sleep(changeInterval);\n-                    if (clusterRoleChange) {\n-                        TopologyDescriptor newConfig = changeActiveCluster(clusterManager.getTopologyConfig());\n-                        clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n-                        log.warn(\"Change the cluster config\");\n-                        clusterRoleChange = false;\n-                    }\n-                } catch (Exception e) {\n-                    log.error(\"Caught an exception\",e);\n+                    TopologyDescriptor newConfig = queue.take();\n+                    clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n+                    log.warn(\"change the cluster config\");\n+                } catch (InterruptedException ie) {\n+                    throw new UnrecoverableCorfuInterruptedError(ie);\n                 }\n             }\n         }\n     }\n \n+    public static class ConfigStreamListener implements StreamListener {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA0OTUyNQ=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgxMTY1Nw==", "bodyText": "... not sure if I understand, but we can discuss this offline.  It is not a functional issue.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459811657", "createdAt": "2020-07-24T01:24:49Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n \n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n+        return new TopologyDescriptor(++epoch, newActiveClusters, newStandbyClusters);\n+    }\n \n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n-            } else {\n-                standbyClusters.add(standbyCluster);\n-            }\n-        }\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>());\n+    }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++epoch, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>(currentConfig.getActiveClusters().values());\n+        List<ClusterDescriptor> newInvalidClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newInvalidClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.INVALID)));\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>(), newInvalidClusters);\n+    }\n+\n+    /**\n+     * Bring topology config back to default valid config.\n+     **/\n+    public TopologyDescriptor generateDefaultValidConfig() {\n+        TopologyDescriptor defaultTopology = new TopologyDescriptor(constructTopologyConfigMsg());\n+        List<ClusterDescriptor> activeClusters = new ArrayList<>(defaultTopology.getActiveClusters().values());\n+        List<ClusterDescriptor> standbyClusters = new ArrayList<>(defaultTopology.getStandbyClusters().values());\n+\n+        return new TopologyDescriptor(++epoch, activeClusters, standbyClusters);\n     }\n \n     /**\n      * Testing purpose to generate cluster role change.\n      */\n-    public static class SiteManagerCallback implements Runnable {\n-        public boolean clusterRoleChange = false;\n-        DefaultClusterManager clusterManager;\n+    public static class ClusterManagerCallback implements Runnable {\n+        private final DefaultClusterManager clusterManager;\n+        private final LinkedBlockingQueue<TopologyDescriptor> queue;\n \n-        SiteManagerCallback(DefaultClusterManager clusterManager) {\n+        public ClusterManagerCallback(DefaultClusterManager clusterManager) {\n             this.clusterManager = clusterManager;\n+            queue = new LinkedBlockingQueue<>();\n+        }\n+\n+        public void applyNewTopologyConfig(@NonNull TopologyDescriptor descriptor) {\n+            log.info(\"Applying a new config {}\", descriptor);\n+            queue.add(descriptor);\n         }\n \n         @Override\n         public void run() {\n-            while (!clusterManager.ifShutdown) {\n+            while (!clusterManager.isShutdown()) {\n                 try {\n-                    sleep(changeInterval);\n-                    if (clusterRoleChange) {\n-                        TopologyDescriptor newConfig = changeActiveCluster(clusterManager.getTopologyConfig());\n-                        clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n-                        log.warn(\"Change the cluster config\");\n-                        clusterRoleChange = false;\n-                    }\n-                } catch (Exception e) {\n-                    log.error(\"Caught an exception\",e);\n+                    TopologyDescriptor newConfig = queue.take();\n+                    clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n+                    log.warn(\"change the cluster config\");\n+                } catch (InterruptedException ie) {\n+                    throw new UnrecoverableCorfuInterruptedError(ie);\n                 }\n             }\n         }\n     }\n \n+    public static class ConfigStreamListener implements StreamListener {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA0OTUyNQ=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 322}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDcwMDQ2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDowMzowNlrOG1yMaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNjowMDo1NFrOG2RQlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA1MDA4OA==", "bodyText": "Can we add a short description to this class?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459050088", "createdAt": "2020-07-22T20:03:06Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n \n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n+        return new TopologyDescriptor(++epoch, newActiveClusters, newStandbyClusters);\n+    }\n \n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n-            } else {\n-                standbyClusters.add(standbyCluster);\n-            }\n-        }\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>());\n+    }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++epoch, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>(currentConfig.getActiveClusters().values());\n+        List<ClusterDescriptor> newInvalidClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newInvalidClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.INVALID)));\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>(), newInvalidClusters);\n+    }\n+\n+    /**\n+     * Bring topology config back to default valid config.\n+     **/\n+    public TopologyDescriptor generateDefaultValidConfig() {\n+        TopologyDescriptor defaultTopology = new TopologyDescriptor(constructTopologyConfigMsg());\n+        List<ClusterDescriptor> activeClusters = new ArrayList<>(defaultTopology.getActiveClusters().values());\n+        List<ClusterDescriptor> standbyClusters = new ArrayList<>(defaultTopology.getStandbyClusters().values());\n+\n+        return new TopologyDescriptor(++epoch, activeClusters, standbyClusters);\n     }\n \n     /**\n      * Testing purpose to generate cluster role change.\n      */\n-    public static class SiteManagerCallback implements Runnable {\n-        public boolean clusterRoleChange = false;\n-        DefaultClusterManager clusterManager;\n+    public static class ClusterManagerCallback implements Runnable {\n+        private final DefaultClusterManager clusterManager;\n+        private final LinkedBlockingQueue<TopologyDescriptor> queue;\n \n-        SiteManagerCallback(DefaultClusterManager clusterManager) {\n+        public ClusterManagerCallback(DefaultClusterManager clusterManager) {\n             this.clusterManager = clusterManager;\n+            queue = new LinkedBlockingQueue<>();\n+        }\n+\n+        public void applyNewTopologyConfig(@NonNull TopologyDescriptor descriptor) {\n+            log.info(\"Applying a new config {}\", descriptor);\n+            queue.add(descriptor);\n         }\n \n         @Override\n         public void run() {\n-            while (!clusterManager.ifShutdown) {\n+            while (!clusterManager.isShutdown()) {\n                 try {\n-                    sleep(changeInterval);\n-                    if (clusterRoleChange) {\n-                        TopologyDescriptor newConfig = changeActiveCluster(clusterManager.getTopologyConfig());\n-                        clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n-                        log.warn(\"Change the cluster config\");\n-                        clusterRoleChange = false;\n-                    }\n-                } catch (Exception e) {\n-                    log.error(\"Caught an exception\",e);\n+                    TopologyDescriptor newConfig = queue.take();\n+                    clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n+                    log.warn(\"change the cluster config\");\n+                } catch (InterruptedException ie) {\n+                    throw new UnrecoverableCorfuInterruptedError(ie);\n                 }\n             }\n         }\n     }\n \n+    public static class ConfigStreamListener implements StreamListener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU1OTA2Mg==", "bodyText": "Done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459559062", "createdAt": "2020-07-23T16:00:54Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n \n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n+        return new TopologyDescriptor(++epoch, newActiveClusters, newStandbyClusters);\n+    }\n \n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n-            } else {\n-                standbyClusters.add(standbyCluster);\n-            }\n-        }\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>());\n+    }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++epoch, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>(currentConfig.getActiveClusters().values());\n+        List<ClusterDescriptor> newInvalidClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newInvalidClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.INVALID)));\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>(), newInvalidClusters);\n+    }\n+\n+    /**\n+     * Bring topology config back to default valid config.\n+     **/\n+    public TopologyDescriptor generateDefaultValidConfig() {\n+        TopologyDescriptor defaultTopology = new TopologyDescriptor(constructTopologyConfigMsg());\n+        List<ClusterDescriptor> activeClusters = new ArrayList<>(defaultTopology.getActiveClusters().values());\n+        List<ClusterDescriptor> standbyClusters = new ArrayList<>(defaultTopology.getStandbyClusters().values());\n+\n+        return new TopologyDescriptor(++epoch, activeClusters, standbyClusters);\n     }\n \n     /**\n      * Testing purpose to generate cluster role change.\n      */\n-    public static class SiteManagerCallback implements Runnable {\n-        public boolean clusterRoleChange = false;\n-        DefaultClusterManager clusterManager;\n+    public static class ClusterManagerCallback implements Runnable {\n+        private final DefaultClusterManager clusterManager;\n+        private final LinkedBlockingQueue<TopologyDescriptor> queue;\n \n-        SiteManagerCallback(DefaultClusterManager clusterManager) {\n+        public ClusterManagerCallback(DefaultClusterManager clusterManager) {\n             this.clusterManager = clusterManager;\n+            queue = new LinkedBlockingQueue<>();\n+        }\n+\n+        public void applyNewTopologyConfig(@NonNull TopologyDescriptor descriptor) {\n+            log.info(\"Applying a new config {}\", descriptor);\n+            queue.add(descriptor);\n         }\n \n         @Override\n         public void run() {\n-            while (!clusterManager.ifShutdown) {\n+            while (!clusterManager.isShutdown()) {\n                 try {\n-                    sleep(changeInterval);\n-                    if (clusterRoleChange) {\n-                        TopologyDescriptor newConfig = changeActiveCluster(clusterManager.getTopologyConfig());\n-                        clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n-                        log.warn(\"Change the cluster config\");\n-                        clusterRoleChange = false;\n-                    }\n-                } catch (Exception e) {\n-                    log.error(\"Caught an exception\",e);\n+                    TopologyDescriptor newConfig = queue.take();\n+                    clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n+                    log.warn(\"change the cluster config\");\n+                } catch (InterruptedException ie) {\n+                    throw new UnrecoverableCorfuInterruptedError(ie);\n                 }\n             }\n         }\n     }\n \n+    public static class ConfigStreamListener implements StreamListener {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA1MDA4OA=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 322}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDcwOTAzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDowNTozNlrOG1yR8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDowNTozNlrOG1yR8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA1MTUwNQ==", "bodyText": "maybe moving the types of configurations to an enum, and having a switch would make it easier to follow? this I'm not that picky about, just a suggestion.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459051505", "createdAt": "2020-07-22T20:05:36Z", "author": {"login": "annym"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,151 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n \n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n \n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n+        return new TopologyDescriptor(++epoch, newActiveClusters, newStandbyClusters);\n+    }\n \n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n-            } else {\n-                standbyClusters.add(standbyCluster);\n-            }\n-        }\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>());\n+    }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++epoch, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>(currentConfig.getActiveClusters().values());\n+        List<ClusterDescriptor> newInvalidClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newInvalidClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.INVALID)));\n+\n+        return new TopologyDescriptor(++epoch, newActiveClusters, new ArrayList<>(), newInvalidClusters);\n+    }\n+\n+    /**\n+     * Bring topology config back to default valid config.\n+     **/\n+    public TopologyDescriptor generateDefaultValidConfig() {\n+        TopologyDescriptor defaultTopology = new TopologyDescriptor(constructTopologyConfigMsg());\n+        List<ClusterDescriptor> activeClusters = new ArrayList<>(defaultTopology.getActiveClusters().values());\n+        List<ClusterDescriptor> standbyClusters = new ArrayList<>(defaultTopology.getStandbyClusters().values());\n+\n+        return new TopologyDescriptor(++epoch, activeClusters, standbyClusters);\n     }\n \n     /**\n      * Testing purpose to generate cluster role change.\n      */\n-    public static class SiteManagerCallback implements Runnable {\n-        public boolean clusterRoleChange = false;\n-        DefaultClusterManager clusterManager;\n+    public static class ClusterManagerCallback implements Runnable {\n+        private final DefaultClusterManager clusterManager;\n+        private final LinkedBlockingQueue<TopologyDescriptor> queue;\n \n-        SiteManagerCallback(DefaultClusterManager clusterManager) {\n+        public ClusterManagerCallback(DefaultClusterManager clusterManager) {\n             this.clusterManager = clusterManager;\n+            queue = new LinkedBlockingQueue<>();\n+        }\n+\n+        public void applyNewTopologyConfig(@NonNull TopologyDescriptor descriptor) {\n+            log.info(\"Applying a new config {}\", descriptor);\n+            queue.add(descriptor);\n         }\n \n         @Override\n         public void run() {\n-            while (!clusterManager.ifShutdown) {\n+            while (!clusterManager.isShutdown()) {\n                 try {\n-                    sleep(changeInterval);\n-                    if (clusterRoleChange) {\n-                        TopologyDescriptor newConfig = changeActiveCluster(clusterManager.getTopologyConfig());\n-                        clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n-                        log.warn(\"Change the cluster config\");\n-                        clusterRoleChange = false;\n-                    }\n-                } catch (Exception e) {\n-                    log.error(\"Caught an exception\",e);\n+                    TopologyDescriptor newConfig = queue.take();\n+                    clusterManager.updateTopologyConfig(newConfig.convertToMessage());\n+                    log.warn(\"change the cluster config\");\n+                } catch (InterruptedException ie) {\n+                    throw new UnrecoverableCorfuInterruptedError(ie);\n                 }\n             }\n         }\n     }\n \n+    public static class ConfigStreamListener implements StreamListener {\n+\n+        private final DefaultClusterManager clusterManager;\n+\n+        public ConfigStreamListener(DefaultClusterManager clusterManager) {\n+            this.clusterManager = clusterManager;\n+        }\n+\n+        @Override\n+        public void onNext(CorfuStreamEntries results) {\n+            log.info(\"ConfigStreamListener onNext {} with entry size {}\", results, results.getEntries().size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 332}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDcxOTg2OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDowOTowNFrOG1yY3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDowOTowNFrOG1yY3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA1MzI3OQ==", "bodyText": "typo -> suit -> suite", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459053279", "createdAt": "2020-07-22T20:09:04Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDc0NDc2OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDoxNjo0M1rOG1yoOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDoxNjo0M1rOG1yoOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA1NzIxMQ==", "bodyText": "typo -> verifies", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459057211", "createdAt": "2020-07-22T20:16:43Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 120}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDgyODk4OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo0MjoxNlrOG1zc6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo0MjoxNlrOG1zc6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3MDY5OQ==", "bodyText": "entry -> entries", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459070699", "createdAt": "2020-07-22T20:42:16Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 133}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg0NjQ2OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo0NzoyNVrOG1znsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNTo1MDo1MlrOG2Q1ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3MzQ1Ng==", "bodyText": "You can change this for:             mapStandby.keySet().containsAll(mapActive.keySet());", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459073456", "createdAt": "2020-07-22T20:47:25Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU1MjE4Ng==", "bodyText": "Yeah, it is cleaner. I think for loop can make sure all entries exist and help understand how many entries should be there.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459552186", "createdAt": "2020-07-23T15:50:52Z", "author": {"login": "zhangn49"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3MzQ1Ng=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 174}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg1MzY2OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo0OTo0NVrOG1zsWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNTo0ODoxOFrOG2Qu7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3NDY1MA==", "bodyText": "was this commented because it did not work? Cause technically the previous line already verified it was transferred so it should work right?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459074650", "createdAt": "2020-07-22T20:49:45Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 203}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU1MDQ0NA==", "bodyText": "Yes, it works now. Forgot to bring it back after debugging.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459550444", "createdAt": "2020-07-23T15:48:18Z", "author": {"login": "zhangn49"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3NDY1MA=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 203}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg1NTQ0OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1MDoxOFrOG1ztfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1MDoxOFrOG1ztfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3NDk0MQ==", "bodyText": "verify -> verifies", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459074941", "createdAt": "2020-07-22T20:50:18Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 209}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg2Mzk1OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1MzowM1rOG1zy0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1MzowM1rOG1zy0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3NjMwNg==", "bodyText": "verify -> verifies", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459076306", "createdAt": "2020-07-22T20:53:03Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two active clusters", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 322}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg2OTU4OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NDo1MlrOG1z2Rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NDo1MlrOG1z2Rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3NzE5MA==", "bodyText": "to mapActive", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459077190", "createdAt": "2020-07-22T20:54:52Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two active clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-active config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are active\n+     */\n+    @Test\n+    public void testNewConfigWithTwoActive() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with two active\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_TWO_ACTIVE,\n+                        DefaultClusterManager.OP_TWO_ACTIVE, DefaultClusterManager.OP_TWO_ACTIVE)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapStandby", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 390}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg3MDYxOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NTowN1rOG1z23g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NTowN1rOG1z23g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3NzM0Mg==", "bodyText": "have -> has", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459077342", "createdAt": "2020-07-22T20:55:07Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two active clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-active config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are active\n+     */\n+    @Test\n+    public void testNewConfigWithTwoActive() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with two active\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_TWO_ACTIVE,\n+                        DefaultClusterManager.OP_TWO_ACTIVE, DefaultClusterManager.OP_TWO_ACTIVE)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 397}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg3MTkxOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NTozMlrOG1z3sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NTozMlrOG1z3sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3NzU1NQ==", "bodyText": "verify -> verifies", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459077555", "createdAt": "2020-07-22T20:55:32Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two active clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-active config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are active\n+     */\n+    @Test\n+    public void testNewConfigWithTwoActive() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with two active\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_TWO_ACTIVE,\n+                        DefaultClusterManager.OP_TWO_ACTIVE, DefaultClusterManager.OP_TWO_ACTIVE)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two standby clusters", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 410}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg3NDMzOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NjoxN1rOG1z5LA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NjoxN1rOG1z5LA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3NzkzMg==", "bodyText": "verify -> verifies", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459077932", "createdAt": "2020-07-22T20:56:17Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two active clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-active config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are active\n+     */\n+    @Test\n+    public void testNewConfigWithTwoActive() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with two active\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_TWO_ACTIVE,\n+                        DefaultClusterManager.OP_TWO_ACTIVE, DefaultClusterManager.OP_TWO_ACTIVE)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two standby clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-standby config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are standby\n+     */\n+    @Test\n+    public void testNewConfigWithAllStandby() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with all standby\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_ALL_STANDBY,\n+                        DefaultClusterManager.OP_ALL_STANDBY, DefaultClusterManager.OP_ALL_STANDBY)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with one active and one invalid", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 497}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg3NzczOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NzoxNVrOG1z7RA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMDo1NzoxNVrOG1z7RA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA3ODQ2OA==", "bodyText": "Good test!", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459078468", "createdAt": "2020-07-22T20:57:15Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two active clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-active config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are active\n+     */\n+    @Test\n+    public void testNewConfigWithTwoActive() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with two active\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_TWO_ACTIVE,\n+                        DefaultClusterManager.OP_TWO_ACTIVE, DefaultClusterManager.OP_TWO_ACTIVE)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two standby clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-standby config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are standby\n+     */\n+    @Test\n+    public void testNewConfigWithAllStandby() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with all standby\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_ALL_STANDBY,\n+                        DefaultClusterManager.OP_ALL_STANDBY, DefaultClusterManager.OP_ALL_STANDBY)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with one active and one invalid\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a active-invalid config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since standby is invalid\n+     * 9. Resume to standby and verify data is fully replicated again.\n+     */\n+    @Test\n+    public void testNewConfigWithInvalidClusters() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with invalid state\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_INVALID,\n+                        DefaultClusterManager.OP_INVALID, DefaultClusterManager.OP_INVALID)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapActive\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+        log.info(\"After {} seconds sleep, double check passed\", mediumInterval);\n+\n+        // Change to default active standby config\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 584}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg4ODM0OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMTowMDoyNFrOG10B5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDo1Mzo1MlrOG2gQZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4MDE2NA==", "bodyText": "If you take a look at PR #2640 I broke all these functions of writing to active/standby maps/ stopping into generic utilities available in LogReplicationAbstractIT, which would reduce a lot of the code here (just a suggestion)", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459080164", "createdAt": "2020-07-22T21:00:24Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two active clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-active config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are active\n+     */\n+    @Test\n+    public void testNewConfigWithTwoActive() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with two active\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_TWO_ACTIVE,\n+                        DefaultClusterManager.OP_TWO_ACTIVE, DefaultClusterManager.OP_TWO_ACTIVE)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two standby clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-standby config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are standby\n+     */\n+    @Test\n+    public void testNewConfigWithAllStandby() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with all standby\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_ALL_STANDBY,\n+                        DefaultClusterManager.OP_ALL_STANDBY, DefaultClusterManager.OP_ALL_STANDBY)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with one active and one invalid\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a active-invalid config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since standby is invalid\n+     * 9. Resume to standby and verify data is fully replicated again.\n+     */\n+    @Test\n+    public void testNewConfigWithInvalidClusters() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 510}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNDc3NQ==", "bodyText": "A similar suggestion is to move the common code from all tests to a common place in this file so the tests themselves are smaller", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459804775", "createdAt": "2020-07-24T00:53:52Z", "author": {"login": "pankti-m"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        //assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two active clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-active config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are active\n+     */\n+    @Test\n+    public void testNewConfigWithTwoActive() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with two active\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_TWO_ACTIVE,\n+                        DefaultClusterManager.OP_TWO_ACTIVE, DefaultClusterManager.OP_TWO_ACTIVE)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with two standby clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-standby config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are standby\n+     */\n+    @Test\n+    public void testNewConfigWithAllStandby() throws Exception {\n+        // Write 10 entry to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with all standby\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_ALL_STANDBY,\n+                        DefaultClusterManager.OP_ALL_STANDBY, DefaultClusterManager.OP_ALL_STANDBY)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map have {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verify config change with one active and one invalid\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a active-invalid config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since standby is invalid\n+     * 9. Resume to standby and verify data is fully replicated again.\n+     */\n+    @Test\n+    public void testNewConfigWithInvalidClusters() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4MDE2NA=="}, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 510}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDg5NTg2OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMTowMjozOFrOG10Gkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMTowMjozOFrOG10Gkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4MTM2Mw==", "bodyText": "These tests are good! I think one that we might be missing and could be interesting is:\n\nSnapshot and Log Entry (check it completes)\nStop both LRs\nEnforce Role Switch\nBring them back\n\nThis way we can verify it performs correctly the site flip even when coming back up after with a new config.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459081363", "createdAt": "2020-07-22T21:02:38Z", "author": {"login": "annym"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,619 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suit exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verify config change with a role switch.\n+     * <p>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "946999817492aa9fca1f041c7d76ba6815974ab2"}, "originalPosition": 121}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTQyNjk1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QyMzoyNzo0MFrOG2e5Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMToxMzowN1rOG2ghZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc4MjQxMQ==", "bodyText": "how do we confirm this?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459782411", "createdAt": "2020-07-23T23:27:40Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -489,11 +489,12 @@ public void processLockRelease() {\n      *   - Higher config id\n      *   - Potential cluster role change\n      *\n+     * Cluster change from active to standby is a two step process, we first confirm that\n+     * we are ready to do the cluster role change, so by the time we receive cluster change", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwOTEyNQ==", "bodyText": "I guess we confirm it by query replication status.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459809125", "createdAt": "2020-07-24T01:13:07Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -489,11 +489,12 @@ public void processLockRelease() {\n      *   - Higher config id\n      *   - Potential cluster role change\n      *\n+     * Cluster change from active to standby is a two step process, we first confirm that\n+     * we are ready to do the cluster role change, so by the time we receive cluster change", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc4MjQxMQ=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTQ4NzE5OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QyMzo1ODoxMlrOG2fb3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMToxODoxMVrOG2glyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5MTMyNQ==", "bodyText": "remove before merging?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459791325", "createdAt": "2020-07-23T23:58:12Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -1,33 +1,49 @@\n package org.corfudb.infrastructure.logreplication.infrastructure.plugins;\n \n import lombok.Getter;\n+import lombok.NonNull;\n import lombok.extern.slf4j.Slf4j;\n import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n import org.corfudb.infrastructure.logreplication.infrastructure.NodeDescriptor;\n import org.corfudb.infrastructure.logreplication.infrastructure.TopologyDescriptor;\n-import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.CorfuStoreMetadata;\n+import org.corfudb.runtime.Messages;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuStreamEntries;\n+import org.corfudb.runtime.collections.CorfuStreamEntry;\n+import org.corfudb.runtime.collections.StreamListener;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.collections.TableSchema;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n \n import java.io.File;\n-import java.io.FileNotFoundException;\n import java.io.FileReader;\n import java.io.IOException;\n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Properties;\n import java.util.Set;\n import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n \n-import static java.lang.Thread.sleep;\n-\n+/**\n+ * This class extends CorfuReplicationClusterManagerAdapter, provides topology config API\n+ * for integration tests. The initial topology config should be valid, which means it has only\n+ * one active cluster, and one or more standby clusters.\n+ */\n @Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgxMDI0OQ==", "bodyText": "Removed.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459810249", "createdAt": "2020-07-24T01:18:11Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -1,33 +1,49 @@\n package org.corfudb.infrastructure.logreplication.infrastructure.plugins;\n \n import lombok.Getter;\n+import lombok.NonNull;\n import lombok.extern.slf4j.Slf4j;\n import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n import org.corfudb.infrastructure.logreplication.infrastructure.NodeDescriptor;\n import org.corfudb.infrastructure.logreplication.infrastructure.TopologyDescriptor;\n-import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.CorfuStoreMetadata;\n+import org.corfudb.runtime.Messages;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuStreamEntries;\n+import org.corfudb.runtime.collections.CorfuStreamEntry;\n+import org.corfudb.runtime.collections.StreamListener;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.collections.TableSchema;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n \n import java.io.File;\n-import java.io.FileNotFoundException;\n import java.io.FileReader;\n import java.io.IOException;\n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Properties;\n import java.util.Set;\n import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n \n-import static java.lang.Thread.sleep;\n-\n+/**\n+ * This class extends CorfuReplicationClusterManagerAdapter, provides topology config API\n+ * for integration tests. The initial topology config should be valid, which means it has only\n+ * one active cluster, and one or more standby clusters.\n+ */\n @Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5MTMyNQ=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTQ5OTUzOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDowNDo0OVrOG2fi5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMToxMTozNFrOG2ggJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5MzEyNQ==", "bodyText": "this can be an inaccurate error message if the exception was not FileNotFound.  Why was the exception type changed?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459793125", "createdAt": "2020-07-24T00:04:49Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -112,9 +171,8 @@ public static TopologyDescriptor readConfig() throws IOException {\n             }\n             // TODO: add reading of node id (which is the APH node uuid)\n \n-            reader.close();\n-        } catch (FileNotFoundException e) {\n-            log.warn(\"Plugin Config File {} does not exist. Using default configs\", config_file);\n+        } catch (IOException e) {\n+            log.warn(\"Plugin Config File {} does not exist. Using default configs\", CONFIG_FILE_PATH);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwODgwNg==", "bodyText": "Auto close will throw IOException. I think it is fine, since the entire default cluster manager is test only.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459808806", "createdAt": "2020-07-24T01:11:34Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -112,9 +171,8 @@ public static TopologyDescriptor readConfig() throws IOException {\n             }\n             // TODO: add reading of node id (which is the APH node uuid)\n \n-            reader.close();\n-        } catch (FileNotFoundException e) {\n-            log.warn(\"Plugin Config File {} does not exist. Using default configs\", config_file);\n+        } catch (IOException e) {\n+            log.warn(\"Plugin Config File {} does not exist. Using default configs\", CONFIG_FILE_PATH);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5MzEyNQ=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 157}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTUyMzk1OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDoxODo1NVrOG2fxJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTowNTo0NlrOG2gbIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5Njc3Mw==", "bodyText": "can you annotate it with @testonly or add it in the comment that this is only used by tests?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459796773", "createdAt": "2020-07-24T00:18:55Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,161 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNzUyMA==", "bodyText": "Actually the entire DefaultClusterManager is test-only.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459807520", "createdAt": "2020-07-24T01:05:46Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,161 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5Njc3Mw=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 189}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTUyNTIxOnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDoxOTozNVrOG2fx2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTowNjo0MFrOG2gcBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5Njk1Mg==", "bodyText": "can you add an annotation or comment that this in only for testing?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459796952", "createdAt": "2020-07-24T00:19:35Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,161 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n-\n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n-\n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n-\n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        for (ClusterDescriptor standbyCluster : currentConfig.getStandbyClusters().values()) {\n+            if (newActiveClusters.isEmpty()) {\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE));\n             } else {\n-                standbyClusters.add(standbyCluster);\n+                newStandbyClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.STANDBY));\n             }\n         }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+        return new TopologyDescriptor(++configId, newActiveClusters, newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNzc0OA==", "bodyText": "The same. I think I will refactor this part in the next PR.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459807748", "createdAt": "2020-07-24T01:06:40Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,161 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n-\n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n-\n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n-\n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        for (ClusterDescriptor standbyCluster : currentConfig.getStandbyClusters().values()) {\n+            if (newActiveClusters.isEmpty()) {\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE));\n             } else {\n-                standbyClusters.add(standbyCluster);\n+                newStandbyClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.STANDBY));\n             }\n         }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+        return new TopologyDescriptor(++configId, newActiveClusters, newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5Njk1Mg=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 229}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTUzMDg3OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDoyMzowNFrOG2f05w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTowOToxNlrOG2geAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5NzczNQ==", "bodyText": "maybe we should also add a case with active also as invalid", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459797735", "createdAt": "2020-07-24T00:23:04Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,161 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n-\n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n-\n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n-\n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        for (ClusterDescriptor standbyCluster : currentConfig.getStandbyClusters().values()) {\n+            if (newActiveClusters.isEmpty()) {\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE));\n             } else {\n-                standbyClusters.add(standbyCluster);\n+                newStandbyClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.STANDBY));\n             }\n         }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+        return new TopologyDescriptor(++configId, newActiveClusters, newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++configId, newActiveClusters, new ArrayList<>());\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++configId, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 260}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwODI1OQ==", "bodyText": "Sounds good, will add it in the next PR.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459808259", "createdAt": "2020-07-24T01:09:16Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -181,57 +229,161 @@ public TopologyConfigurationMsg queryTopologyConfig(boolean useCached) {\n     }\n \n     /**\n-     * Enforce one of the standby Cluster's to become the new active cluster and current active to become standby\n+     * Create a new topology config, which changes one of the standby as the active,\n+     * and active as standby. Data should flow in the reverse direction.\n      **/\n-    public static TopologyDescriptor changeActiveCluster(TopologyConfigurationMsg topologyConfig) {\n-        TopologyDescriptor topologyDescriptor = new TopologyDescriptor(topologyConfig);\n-\n-        // Convert the current active to standby\n-        ClusterDescriptor oldActive = topologyDescriptor.getActiveClusters().values().iterator().next();\n-        ClusterDescriptor newStandby = new ClusterDescriptor(oldActive, ClusterRole.STANDBY);\n-\n-        List<ClusterDescriptor> standbyClusters = Arrays.asList(newStandby);\n-        ClusterDescriptor newPrimary = null;\n-\n-        for (ClusterDescriptor standbyCluster : topologyDescriptor.getStandbyClusters().values()) {\n-            if (newPrimary == null) {\n-                newPrimary = new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE);\n+    public TopologyDescriptor generateConfigWithRoleSwitch() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>();\n+        currentConfig.getActiveClusters().values().forEach(activeCluster ->\n+                newStandbyClusters.add(new ClusterDescriptor(activeCluster, ClusterRole.STANDBY)));\n+        for (ClusterDescriptor standbyCluster : currentConfig.getStandbyClusters().values()) {\n+            if (newActiveClusters.isEmpty()) {\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE));\n             } else {\n-                standbyClusters.add(standbyCluster);\n+                newStandbyClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.STANDBY));\n             }\n         }\n \n-        TopologyDescriptor newSiteConf = new TopologyDescriptor(1L, Arrays.asList(newPrimary), standbyClusters);\n-        return newSiteConf;\n+        return new TopologyDescriptor(++configId, newActiveClusters, newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as active on purpose.\n+     * System should drop messages between any two active clusters.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllActive() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newActiveClusters = new ArrayList<>();\n+        currentConfig.getStandbyClusters().values().forEach(standbyCluster ->\n+                newActiveClusters.add(new ClusterDescriptor(standbyCluster, ClusterRole.ACTIVE)));\n+        newActiveClusters.add(currentActive);\n+\n+        return new TopologyDescriptor(++configId, newActiveClusters, new ArrayList<>());\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all cluster as standby on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithAllStandby() {\n+        TopologyDescriptor currentConfig = new TopologyDescriptor(topologyConfig);\n+        ClusterDescriptor currentActive = currentConfig.getActiveClusters().values().iterator().next();\n+\n+        List<ClusterDescriptor> newStandbyClusters = new ArrayList<>(currentConfig.getStandbyClusters().values());\n+        ClusterDescriptor newStandby = new ClusterDescriptor(currentActive, ClusterRole.STANDBY);\n+        newStandbyClusters.add(newStandby);\n+\n+        return new TopologyDescriptor(++configId, new ArrayList<>(), newStandbyClusters);\n+    }\n+\n+    /**\n+     * Create a new topology config, which marks all standby cluster as invalid on purpose.\n+     * System should not send messages in this case.\n+     **/\n+    public TopologyDescriptor generateConfigWithInvalid() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5NzczNQ=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 260}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTU0MDQ2OnYy", "diffSide": "RIGHT", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/StreamsSnapshotWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDoyOToxOVrOG2f6fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTowMjozN1rOG2gYNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5OTE2Nw==", "bodyText": "is this import needed?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459799167", "createdAt": "2020-07-24T00:29:19Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/StreamsSnapshotWriter.java", "diffHunk": "@@ -4,6 +4,7 @@\n import lombok.Getter;\n import lombok.extern.slf4j.Slf4j;\n import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationMetadataVal;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNjc3Mw==", "bodyText": "Done.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459806773", "createdAt": "2020-07-24T01:02:37Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/StreamsSnapshotWriter.java", "diffHunk": "@@ -4,6 +4,7 @@\n import lombok.Getter;\n import lombok.extern.slf4j.Slf4j;\n import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationMetadataVal;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5OTE2Nw=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTU0MzU2OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDozMToxNVrOG2f8UQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTowNzoxOVrOG2gcgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5OTYzMw==", "bodyText": "do you plan to remove this?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459799633", "createdAt": "2020-07-24T00:31:15Z", "author": {"login": "pankti-m"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,618 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suite exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNzg3NQ==", "bodyText": "I will keep this one, since it is an IT class.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459807875", "createdAt": "2020-07-24T01:07:19Z", "author": {"login": "zhangn49"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,618 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suite exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5OTYzMw=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTU1OTIwOnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDo0MTowOVrOG2gFTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTowODoxMVrOG2gdLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwMTkzMw==", "bodyText": "Actually, role is not expected to change when in transfer phase.  Only when we report transfer as 100%, the flip happens.  Will have to decide how we want to handle this case.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459801933", "createdAt": "2020-07-24T00:41:09Z", "author": {"login": "pankti-m"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,618 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suite exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entries to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 214}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwODA0NQ==", "bodyText": "Yeah, these two cases are not very clear right now. We did know much about workflow when designed these two cases.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459808045", "createdAt": "2020-07-24T01:08:11Z", "author": {"login": "zhangn49"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,618 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suite exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entries to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwMTkzMw=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 214}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTU3NzA3OnYy", "diffSide": "RIGHT", "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDo1Mjo1M1rOG2gPjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMToyMTozNFrOG2go3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNDU1Nw==", "bodyText": "actually, writes do not happen on the standby.  Technically they can, but we should decide if from Corfu we want to allow them", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459804557", "createdAt": "2020-07-24T00:52:53Z", "author": {"login": "pankti-m"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,618 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suite exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entries to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verifies config change with two active clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-active config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are active\n+     */\n+    @Test\n+    public void testNewConfigWithTwoActive() throws Exception {\n+        // Write 10 entries to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with two active\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_TWO_ACTIVE,\n+                        DefaultClusterManager.OP_TWO_ACTIVE, DefaultClusterManager.OP_TWO_ACTIVE)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapActive\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map has {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verifies config change with two standby clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-standby config update with corfu store\n+     * 7. Write 5 more entries to active map", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 417}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgxMTAzNw==", "bodyText": "Good to know it", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459811037", "createdAt": "2020-07-24T01:21:34Z", "author": {"login": "zhangn49"}, "path": "test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java", "diffHunk": "@@ -0,0 +1,618 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+/**\n+ * This test suite exercises some topology config change scenarios.\n+ * Each test will start with two single node corfu servers, and two single node log replicators.\n+ */\n+@Slf4j\n+@SuppressWarnings(\"checkstyle:magicnumber\")\n+public class CorfuReplicationClusterConfigIT extends AbstractIT {\n+    public final static String nettyPluginPath = \"src/test/resources/transport/nettyConfig.properties\";\n+    private final static String streamName = \"Table001\";\n+\n+    private final static long shortInterval = 1L;\n+    private final static long mediumInterval = 10L;\n+    private final static int firstBatch = 10;\n+    private final static int secondBatch = 15;\n+    private final static int thirdBatch = 20;\n+    private final static int largeBatch = 50;\n+\n+    private final static int activeClusterCorfuPort = 9000;\n+    private final static int standbyClusterCorfuPort = 9001;\n+    private final static int activeReplicationServerPort = 9010;\n+    private final static int standbyReplicationServerPort = 9020;\n+    private final static String activeCorfuEndpoint = DEFAULT_HOST + \":\" + activeClusterCorfuPort;\n+    private final static String standbyCorfuEndpoint = DEFAULT_HOST + \":\" + standbyClusterCorfuPort;\n+\n+    private Process activeCorfuServer = null;\n+    private Process standbyCorfuServer = null;\n+    private Process activeReplicationServer = null;\n+    private Process standbyReplicationServer = null;\n+\n+    private CorfuRuntime activeRuntime;\n+    private CorfuRuntime standbyRuntime;\n+    private CorfuTable<String, Integer> mapActive;\n+    private CorfuTable<String, Integer> mapStandby;\n+\n+    private CorfuStore corfuStore;\n+    private Table<CommonTypes.Uuid, CommonTypes.Uuid, CommonTypes.Uuid> configTable;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        activeCorfuServer = runServer(activeClusterCorfuPort, true);\n+        standbyCorfuServer = runServer(standbyClusterCorfuPort, true);\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        activeRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        activeRuntime.parseConfigurationString(activeCorfuEndpoint).connect();\n+\n+        standbyRuntime = CorfuRuntime.fromParameters(params).setTransactionLogging(true);\n+        standbyRuntime.parseConfigurationString(standbyCorfuEndpoint).connect();\n+\n+        mapActive = activeRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        mapStandby = standbyRuntime.getObjectsView()\n+                .build()\n+                .setStreamName(streamName)\n+                .setTypeToken(new TypeToken<CorfuTable<String, Integer>>() {\n+                })\n+                .open();\n+\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+\n+        corfuStore = new CorfuStore(activeRuntime);\n+\n+        configTable = corfuStore.openTable(\n+                DefaultClusterManager.CONFIG_NAMESPACE, DefaultClusterManager.CONFIG_TABLE_NAME,\n+                CommonTypes.Uuid.class, CommonTypes.Uuid.class, CommonTypes.Uuid.class,\n+                TableOptions.builder().build()\n+        );\n+    }\n+\n+    @After\n+    public void tearDown() throws IOException, InterruptedException {\n+        if (activeRuntime != null) {\n+            activeRuntime.shutdown();\n+        }\n+\n+        if (standbyRuntime != null) {\n+            standbyRuntime.shutdown();\n+        }\n+\n+        shutdownCorfuServer(activeCorfuServer);\n+        shutdownCorfuServer(standbyCorfuServer);\n+        shutdownCorfuServer(activeReplicationServer);\n+        shutdownCorfuServer(standbyReplicationServer);\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a role switch with corfu store\n+     * 7. Write 5 more entries to standby map, which becomes source right now.\n+     * 8. Verify data will be replicated in reverse direction.\n+     */\n+    @Test\n+    public void testNewConfigWithSwitchRole() throws Exception {\n+        // Write 10 entries to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Write 5 more entries to mapStandby\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            standbyRuntime.getObjectsView().TXBegin();\n+            mapStandby.put(String.valueOf(i), i);\n+            standbyRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);\n+        log.info(\"Data is fully replicated again after role switch, both maps have size {}. \" +\n+                        \"Current active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                thirdBatch, activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(thirdBatch);\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch during a snapshot sync transfer phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Perform a role switch with corfu store\n+     * 5. Standby will drop messages and keep size 0\n+     * 6. Verify active map becomes size 0, since source size is 0\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringTransferPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+        TimeUnit.SECONDS.sleep(shortInterval);\n+\n+        // Perform a role switch during transfer\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        assertThat(mapStandby.size()).isEqualTo(0);\n+\n+        // Wait until active map size becomes 0\n+        waitForReplication(size -> size == 0, mapActive, 0);\n+        log.info(\"After role switch during transfer phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isZero();\n+        assertThat(mapStandby.size()).isZero();\n+    }\n+\n+    /**\n+     * This test verifies config change with a role switch during a snapshot sync apply phase.\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 50 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync goes to apply phase\n+     * 5. Perform a role switch with corfu store\n+     * 6. Standby will continue apply and have size 50\n+     * 7. Verify both maps have size 50\n+     */\n+    //@Test\n+    public void testNewConfigWithSwitchRoleDuringApplyPhase() throws Exception {\n+        // Write 50 entry to active map\n+        for (int i = 0; i < largeBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", largeBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until apply phase\n+        UUID standbyStream = CorfuRuntime.getStreamID(streamName);\n+        while (!standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().containsKey(standbyStream)) {\n+            TimeUnit.MILLISECONDS.sleep(100L);\n+        }\n+\n+        log.info(\"======standby tail is : \" + standbyRuntime.getAddressSpaceView().getAllTails().getStreamTails().get(standbyStream));\n+\n+        // Perform a role switch\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_SWITCH,\n+                        DefaultClusterManager.OP_SWITCH, DefaultClusterManager.OP_SWITCH)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+\n+        // Should finish apply\n+        waitForReplication(size -> size == largeBatch, mapStandby, largeBatch);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        log.info(\"After role switch during apply phase, both maps have size {}. Current \" +\n+                        \"active corfu[{}] log tail is {}, standby corfu[{}] log tail is {}\",\n+                mapActive.size(), activeClusterCorfuPort, activeRuntime.getAddressSpaceView().getLogTail(),\n+                standbyClusterCorfuPort, standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(largeBatch);\n+        assertThat(mapStandby.size()).isEqualTo(largeBatch);\n+    }\n+\n+    /**\n+     * This test verifies config change with two active clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-active config update with corfu store\n+     * 7. Write 5 more entries to active map\n+     * 8. Verify data will not be replicated, since both are active\n+     */\n+    @Test\n+    public void testNewConfigWithTwoActive() throws Exception {\n+        // Write 10 entries to active map\n+        for (int i = 0; i < firstBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(firstBatch);\n+        assertThat(mapStandby.size()).isZero();\n+\n+        log.info(\"Before log replication, append {} entries to active map. Current active corfu\" +\n+                        \"[{}] log tail is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        activeReplicationServer = runReplicationServer(activeReplicationServerPort, nettyPluginPath);\n+        standbyReplicationServer = runReplicationServer(standbyReplicationServerPort, nettyPluginPath);\n+        log.info(\"Replication servers started, and replication is in progress...\");\n+\n+        // Wait until data is fully replicated\n+        waitForReplication(size -> size == firstBatch, mapStandby, firstBatch);\n+        log.info(\"After full sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", firstBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Write 5 entries to active map\n+        for (int i = firstBatch; i < secondBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(secondBatch);\n+\n+        // Wait until data is fully replicated again\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+        log.info(\"After delta sync, both maps have size {}. Current active corfu[{}] log tail \" +\n+                        \"is {}, standby corfu[{}] log tail is {}\", secondBatch, activeClusterCorfuPort,\n+                activeRuntime.getAddressSpaceView().getLogTail(), standbyClusterCorfuPort,\n+                standbyRuntime.getAddressSpaceView().getLogTail());\n+\n+        // Verify data\n+        for (int i = 0; i < secondBatch; i++) {\n+            assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();\n+        }\n+        log.info(\"Log replication succeeds without config change!\");\n+\n+        // Perform a config update with two active\n+        corfuStore.tx(DefaultClusterManager.CONFIG_NAMESPACE)\n+                .update(DefaultClusterManager.CONFIG_TABLE_NAME, DefaultClusterManager.OP_TWO_ACTIVE,\n+                        DefaultClusterManager.OP_TWO_ACTIVE, DefaultClusterManager.OP_TWO_ACTIVE)\n+                .commit();\n+        assertThat(configTable.count()).isOne();\n+        log.info(\"New topology config applied!\");\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+\n+        // Append to mapActive\n+        for (int i = secondBatch; i < thirdBatch; i++) {\n+            activeRuntime.getObjectsView().TXBegin();\n+            mapActive.put(String.valueOf(i), i);\n+            activeRuntime.getObjectsView().TXEnd();\n+        }\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        log.info(\"Active map has {} entries now!\", thirdBatch);\n+\n+        // Standby map should still have secondBatch size\n+        log.info(\"Standby map should still have {} size\", secondBatch);\n+        waitForReplication(size -> size == secondBatch, mapStandby, secondBatch);\n+\n+        // Double check after 10 seconds\n+        TimeUnit.SECONDS.sleep(mediumInterval);\n+        assertThat(mapActive.size()).isEqualTo(thirdBatch);\n+        assertThat(mapStandby.size()).isEqualTo(secondBatch);\n+    }\n+\n+    /**\n+     * This test verifies config change with two standby clusters\n+     * <p>\n+     * 1. Init with corfu 9000 active and 9001 standby\n+     * 2. Write 10 entries to active map\n+     * 3. Start log replication: Node 9010 - active, Node 9020 - standby\n+     * 4. Wait for Snapshot Sync, both maps have size 10\n+     * 5. Write 5 more entries to active map, to verify Log Entry Sync\n+     * 6. Perform a two-standby config update with corfu store\n+     * 7. Write 5 more entries to active map", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNDU1Nw=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 417}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTU4MTY3OnYy", "diffSide": "LEFT", "path": "test/src/test/resources/logback-test.xml", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDo1NTo1NlrOG2gSQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTowMTo0NVrOG2gXlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTI0OQ==", "bodyText": "do you plan to revert this before merging?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459805249", "createdAt": "2020-07-24T00:55:56Z", "author": {"login": "pankti-m"}, "path": "test/src/test/resources/logback-test.xml", "diffHunk": "@@ -44,8 +44,8 @@\n     </logger>\n \n     <!--<root level=\"DEBUG\">-->\n-        <!--&lt;!&ndash;<appender-ref ref=\"FILE\" />&ndash;&gt;-->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNjYxMw==", "bodyText": "I think the old one is double '<!--'. The new one is cleaner.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2634#discussion_r459806613", "createdAt": "2020-07-24T01:01:45Z", "author": {"login": "zhangn49"}, "path": "test/src/test/resources/logback-test.xml", "diffHunk": "@@ -44,8 +44,8 @@\n     </logger>\n \n     <!--<root level=\"DEBUG\">-->\n-        <!--&lt;!&ndash;<appender-ref ref=\"FILE\" />&ndash;&gt;-->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTI0OQ=="}, "originalCommit": {"oid": "cb5ea7d22d7c8707897f92595c0d5fd7a6a5a8e6"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1847, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}