{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDgzNDAzMDEz", "number": 2767, "title": "Calculate Remaining Replicated Entries based on TxStream", "bodyText": "Overview\nDescription:\n\nCalculate replicated remaining entries based on the txStream\nto avoid the issue of holes enforced on regular streams by the checkpointer.\nMinor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\nAdd some valuable logging for debugging\n\nWhy should this be merged: bug found in setups running checkpointing\nChecklist (Definition of Done):\n\n There are no TODOs left in the code\n Coding conventions (e.g. for logging, unit tests) have been followed\n Change is covered by automated tests\n Public API has Javadoc", "createdAt": "2020-09-10T05:27:35Z", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767", "merged": true, "mergeCommit": {"oid": "b7171a431b5c968c06a216e7306cc5551e727a13"}, "closed": true, "closedAt": "2020-09-10T20:44:39Z", "author": {"login": "annym"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdHanZSAFqTQ4NTYwMTE2NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdHm9AcAFqTQ4NjI5MTk4Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1NjAxMTY1", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#pullrequestreview-485601165", "createdAt": "2020-09-10T05:52:46Z", "commit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwNTo1Mjo0N1rOHPkEug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwNjowOToyOFrOHPkaMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4MTcyMg==", "bodyText": "when can this happen?  Does it mean no data is present on the sender?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486081722", "createdAt": "2020-09-10T05:52:47Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NDE2MA==", "bodyText": "Can we add a small comment explaining the role of this param?  It can be a bit confusing..", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486084160", "createdAt": "2020-09-10T06:00:16Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NDU1NQ==", "bodyText": "nit - tx stream's", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486084555", "createdAt": "2020-09-10T06:01:30Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 219}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NDg0NA==", "bodyText": "in case of holes, Tx stream's tail will not be above the stream tail, right?  It will be the other way round", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486084844", "createdAt": "2020-09-10T06:02:27Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,\n+        // but in the case of ongoing replication or holes, it might be above.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NTM5Mw==", "bodyText": "remove?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486085393", "createdAt": "2020-09-10T06:04:06Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,\n+        // but in the case of ongoing replication or holes, it might be above.\n+        // We can't do much other than report that we're up to date (as it might continue moving)\n+        if (txStreamTail <= currentTxStreamProcessedTs.getTimestamp()) {\n+            // (Case 2 from description)\n+            // If the current processed tx stream entry has data to replicate,\n+            // we need to ensure we have received an ACK it, otherwise,\n+            // we might be signalling completion when there is still an entry for which\n+            // we haven't received confirmation of the recipient.\n+            if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+                if (lastAckedTs == currentTxStreamProcessedTs.getTimestamp()) {\n+                    log.trace(\"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 230}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NjY1NQ==", "bodyText": "where are we ignoring the invalid entry?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486086655", "createdAt": "2020-09-10T06:07:46Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,\n+        // but in the case of ongoing replication or holes, it might be above.\n+        // We can't do much other than report that we're up to date (as it might continue moving)\n+        if (txStreamTail <= currentTxStreamProcessedTs.getTimestamp()) {\n+            // (Case 2 from description)\n+            // If the current processed tx stream entry has data to replicate,\n+            // we need to ensure we have received an ACK it, otherwise,\n+            // we might be signalling completion when there is still an entry for which\n+            // we haven't received confirmation of the recipient.\n+            if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+                if (lastAckedTs == currentTxStreamProcessedTs.getTimestamp()) {\n+                    log.trace(\"\");\n+                    // (Case 2.0)\n+                    return noRemainingEntriesToSend;\n+                }\n+\n+                // (Case 2.2)\n+                // Last ack'ed timestamp should match the last processed tx stream timestamp.\n+                // Calculate how many entries are missing, based on the tx stream's address map\n+                return getTxStreamTotalEntries(lastAckedTs, currentTxStreamProcessedTs.getTimestamp());\n+            }\n+\n+            // (Case 2.1)\n+            // Since last tx stream processed timestamp is not intended to be replicated\n+            // and we're at or beyond the last known tail, no entries remaining to be sent\n+            // at this point.\n+            return noRemainingEntriesToSend;\n         }\n-        return remainingEntriesToSend;\n+\n+        // (Case 1 from description)\n+        if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+            // (Case 1.0)\n+            return getTxStreamTotalEntries(lastAckedTs, txStreamTail);\n+        }\n+\n+        // Case (1.1)\n+        return getTxStreamTotalEntries(currentTxStreamProcessedTs.getTimestamp(), txStreamTail);\n+    }\n+\n+    private long getTxStreamTotalEntries(long lowerBoundary, long upperBoundary) {\n+        long totalEntries = 0;\n+\n+        if (upperBoundary > lowerBoundary) {\n+            StreamAddressRange range = new StreamAddressRange(TRANSACTION_STREAM_ID, upperBoundary, lowerBoundary);\n+            StreamAddressSpace txStreamAddressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n+            // Count how many entries are present in the Tx Stream (this can include holes,\n+            // valid entries and invalid entries), but we count them all (equal weight).\n+            // An invalid entry, is a transactional entry with no streams to replicate (which will be ignored)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 267}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4Njg4OA==", "bodyText": "why do we start this later?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486086888", "createdAt": "2020-09-10T06:08:28Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -74,13 +80,18 @@ public void setAckedTsAndSyncType(long ackedTs, LogReplicationMetadata.Replicati\n         }\n     }\n \n+    public void startAckReader(LogEntryReader logEntryReader) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NzIxOQ==", "bodyText": "can you move it below along with the other getTail function?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486087219", "createdAt": "2020-09-10T06:09:28Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -74,13 +80,18 @@ public void setAckedTsAndSyncType(long ackedTs, LogReplicationMetadata.Replicati\n         }\n     }\n \n+    public void startAckReader(LogEntryReader logEntryReader) {\n+        this.logEntryReader = logEntryReader;\n+        lastAckedTsPoller.scheduleWithFixedDelay(new TsPollingTask(), 0,\n+                ACKED_TS_READ_INTERVAL_SECONDS, TimeUnit.SECONDS);\n+    }\n+\n     /**\n      * For the given replication runtime, query max stream tail for all streams to be replicated.\n      *\n      * @return max tail of all streams to be replicated for the given runtime\n      */\n-    private long getMaxReplicatedStreamsTail() {\n-        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+    private long getMaxReplicatedStreamsTail(Map<UUID, Long> tailMap) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1NjE2NzYz", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#pullrequestreview-485616763", "createdAt": "2020-09-10T06:27:52Z", "commit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwNjoyNzo1MlrOHPk21Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwNjoyNzo1MlrOHPk21Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA5NDU0OQ==", "bodyText": "empty log", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486094549", "createdAt": "2020-09-10T06:27:52Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,\n+        // but in the case of ongoing replication or holes, it might be above.\n+        // We can't do much other than report that we're up to date (as it might continue moving)\n+        if (txStreamTail <= currentTxStreamProcessedTs.getTimestamp()) {\n+            // (Case 2 from description)\n+            // If the current processed tx stream entry has data to replicate,\n+            // we need to ensure we have received an ACK it, otherwise,\n+            // we might be signalling completion when there is still an entry for which\n+            // we haven't received confirmation of the recipient.\n+            if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+                if (lastAckedTs == currentTxStreamProcessedTs.getTimestamp()) {\n+                    log.trace(\"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 230}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1NjE4Nzcz", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#pullrequestreview-485618773", "createdAt": "2020-09-10T06:32:01Z", "commit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "committedDate": "2020-09-10T05:23:09Z", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging"}, "afterCommit": {"oid": "285e07a3489c1d96ec23661cdd86c7604cb8c2be", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/285e07a3489c1d96ec23661cdd86c7604cb8c2be", "committedDate": "2020-09-10T06:44:37Z", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "285e07a3489c1d96ec23661cdd86c7604cb8c2be", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/285e07a3489c1d96ec23661cdd86c7604cb8c2be", "committedDate": "2020-09-10T06:44:37Z", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging"}, "afterCommit": {"oid": "b6699dc56934b55782b150e9e8a439713324c34f", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/b6699dc56934b55782b150e9e8a439713324c34f", "committedDate": "2020-09-10T06:50:59Z", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b6699dc56934b55782b150e9e8a439713324c34f", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/b6699dc56934b55782b150e9e8a439713324c34f", "committedDate": "2020-09-10T06:50:59Z", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging"}, "afterCommit": {"oid": "9ee82197f9fb07373d4acf3df9e892e2526a8a32", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/9ee82197f9fb07373d4acf3df9e892e2526a8a32", "committedDate": "2020-09-10T07:02:32Z", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4146661ef07957fd59411b53a46e6fe323b4d430", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/4146661ef07957fd59411b53a46e6fe323b4d430", "committedDate": "2020-09-10T08:04:00Z", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9ee82197f9fb07373d4acf3df9e892e2526a8a32", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/9ee82197f9fb07373d4acf3df9e892e2526a8a32", "committedDate": "2020-09-10T07:02:32Z", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging"}, "afterCommit": {"oid": "4146661ef07957fd59411b53a46e6fe323b4d430", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/4146661ef07957fd59411b53a46e6fe323b4d430", "committedDate": "2020-09-10T08:04:00Z", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2MjY3NDQx", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#pullrequestreview-486267441", "createdAt": "2020-09-10T20:00:23Z", "commit": {"oid": "4146661ef07957fd59411b53a46e6fe323b4d430"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMDowMDoyM1rOHQDtkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMDoyMTo0MVrOHQEXNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYwMDA4MA==", "bodyText": "shouldnt this be '... entries between txStreamTail and currentTxStreamProcessed'?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486600080", "createdAt": "2020-09-10T20:00:23Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +114,199 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n \n-        // No data to send on the Active, so no replication remaining\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n+\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n+        }\n+\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n+        }\n+\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n+    }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail(Map<UUID, Long> tailMap) {\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String streamName : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(streamName);\n+            if (tailMap.containsKey(streamUuid)) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp: last timestamp of entry for which we've received an ACK\n+     * - txStreamTail: transaction stream tail\n+     * - currentTxStreamProcessedTs: metadata of current entry being processed by the StreamsLogEntryReader,\n+     *           it contains the timestamp and a boolean indicating if that entry has data to replicate or not,\n+     *           this will give an indication whether if an ACK is expected or not.\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     * (despite the current processed not requiring ACk, there might be entries between lastAcked and currentProcessed", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4146661ef07957fd59411b53a46e6fe323b4d430"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYwNDU5Mg==", "bodyText": "that entry will not get replicated but will get counted here, right?  We may want to update the comment if so?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486604592", "createdAt": "2020-09-10T20:09:36Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,\n+        // but in the case of ongoing replication or holes, it might be above.\n+        // We can't do much other than report that we're up to date (as it might continue moving)\n+        if (txStreamTail <= currentTxStreamProcessedTs.getTimestamp()) {\n+            // (Case 2 from description)\n+            // If the current processed tx stream entry has data to replicate,\n+            // we need to ensure we have received an ACK it, otherwise,\n+            // we might be signalling completion when there is still an entry for which\n+            // we haven't received confirmation of the recipient.\n+            if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+                if (lastAckedTs == currentTxStreamProcessedTs.getTimestamp()) {\n+                    log.trace(\"\");\n+                    // (Case 2.0)\n+                    return noRemainingEntriesToSend;\n+                }\n+\n+                // (Case 2.2)\n+                // Last ack'ed timestamp should match the last processed tx stream timestamp.\n+                // Calculate how many entries are missing, based on the tx stream's address map\n+                return getTxStreamTotalEntries(lastAckedTs, currentTxStreamProcessedTs.getTimestamp());\n+            }\n+\n+            // (Case 2.1)\n+            // Since last tx stream processed timestamp is not intended to be replicated\n+            // and we're at or beyond the last known tail, no entries remaining to be sent\n+            // at this point.\n+            return noRemainingEntriesToSend;\n         }\n-        return remainingEntriesToSend;\n+\n+        // (Case 1 from description)\n+        if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+            // (Case 1.0)\n+            return getTxStreamTotalEntries(lastAckedTs, txStreamTail);\n+        }\n+\n+        // Case (1.1)\n+        return getTxStreamTotalEntries(currentTxStreamProcessedTs.getTimestamp(), txStreamTail);\n+    }\n+\n+    private long getTxStreamTotalEntries(long lowerBoundary, long upperBoundary) {\n+        long totalEntries = 0;\n+\n+        if (upperBoundary > lowerBoundary) {\n+            StreamAddressRange range = new StreamAddressRange(TRANSACTION_STREAM_ID, upperBoundary, lowerBoundary);\n+            StreamAddressSpace txStreamAddressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n+            // Count how many entries are present in the Tx Stream (this can include holes,\n+            // valid entries and invalid entries), but we count them all (equal weight).\n+            // An invalid entry, is a transactional entry with no streams to replicate (which will be ignored)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NjY1NQ=="}, "originalCommit": {"oid": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40"}, "originalPosition": 267}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYxMDc0Mg==", "bodyText": "why do we need to set the state here?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486610742", "createdAt": "2020-09-10T20:21:41Z", "author": {"login": "pankti-m"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/InLogEntrySyncState.java", "diffHunk": "@@ -134,6 +135,9 @@ public void onEntry(LogReplicationState from) {\n             // address and send incremental updates from this point onwards.\n             if (from.getType() == LogReplicationStateType.WAIT_SNAPSHOT_APPLY\n                     || from.getType() == LogReplicationStateType.INITIALIZED) {\n+                // Set LogEntryAckReader to Log Entry Sync state, to compute remaining entries based\n+                // on the tx stream, regardless of ACKs or updates being processed for the tx stream\n+                fsm.getAckReader().setSyncType(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4146661ef07957fd59411b53a46e6fe323b4d430"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2MjkxOTg3", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#pullrequestreview-486291987", "createdAt": "2020-09-10T20:37:44Z", "commit": {"oid": "4146661ef07957fd59411b53a46e6fe323b4d430"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4048, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}