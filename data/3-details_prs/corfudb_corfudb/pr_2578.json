{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2MjkwOTU5", "number": 2578, "title": "Log Replication Design Redefinition", "bodyText": "Overview\nDescription:\n\nSingle CorfuLogReplicationRuntime per Cluster\nLeadership Verification as integrated part of Corfu\nCluster/Site Discovery/Changes managed through Corfu\nRename site -> cluster (Corfu terminology)\nCleanup", "createdAt": "2020-06-18T07:45:34Z", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578", "merged": true, "mergeCommit": {"oid": "63c11cb38b96022aa54345156beaaa4c662c0223"}, "closed": true, "closedAt": "2020-07-01T06:34:23Z", "author": {"login": "annym"}, "timelineItems": {"totalCount": 39, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcsZn-_gBqjM0NTY4MzEwNDQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcwkTZcgH2gAyNDM2MjkwOTU5OjAyOTQ1MmY4ZjAzZjhhYzM2ZGIwOWU4OGU1OTZhOTRmYjljNmQ0MmI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "22f0b866e417b386ff40d72af5a71b412f38814c", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/22f0b866e417b386ff40d72af5a71b412f38814c", "committedDate": "2020-06-18T07:42:04Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}, "afterCommit": {"oid": "968f21405fff58a517d62dda1e0ba64ac9ebe1c9", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/968f21405fff58a517d62dda1e0ba64ac9ebe1c9", "committedDate": "2020-06-18T07:49:52Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "968f21405fff58a517d62dda1e0ba64ac9ebe1c9", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/968f21405fff58a517d62dda1e0ba64ac9ebe1c9", "committedDate": "2020-06-18T07:49:52Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}, "afterCommit": {"oid": "8b944960b18d7cdc262e0351db81a84c36d637d0", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/8b944960b18d7cdc262e0351db81a84c36d637d0", "committedDate": "2020-06-18T07:51:42Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8b944960b18d7cdc262e0351db81a84c36d637d0", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/8b944960b18d7cdc262e0351db81a84c36d637d0", "committedDate": "2020-06-18T07:51:42Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}, "afterCommit": {"oid": "9714b6f5482a7ceacacc1ebaccb2513fb774ae94", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/9714b6f5482a7ceacacc1ebaccb2513fb774ae94", "committedDate": "2020-06-18T07:53:24Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9714b6f5482a7ceacacc1ebaccb2513fb774ae94", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/9714b6f5482a7ceacacc1ebaccb2513fb774ae94", "committedDate": "2020-06-18T07:53:24Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}, "afterCommit": {"oid": "cee6722bb0f4d77a3d808d9322a605c51603984d", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/cee6722bb0f4d77a3d808d9322a605c51603984d", "committedDate": "2020-06-18T07:58:44Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cee6722bb0f4d77a3d808d9322a605c51603984d", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/cee6722bb0f4d77a3d808d9322a605c51603984d", "committedDate": "2020-06-18T07:58:44Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}, "afterCommit": {"oid": "c5f05cc53d1a3409873ed9a09ffbaf5d9784b308", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/c5f05cc53d1a3409873ed9a09ffbaf5d9784b308", "committedDate": "2020-06-18T08:01:17Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c5f05cc53d1a3409873ed9a09ffbaf5d9784b308", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/c5f05cc53d1a3409873ed9a09ffbaf5d9784b308", "committedDate": "2020-06-18T08:01:17Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}, "afterCommit": {"oid": "219d3e551a8d8a000e6354d5d3cdf041b810ee78", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/219d3e551a8d8a000e6354d5d3cdf041b810ee78", "committedDate": "2020-06-19T00:35:07Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "219d3e551a8d8a000e6354d5d3cdf041b810ee78", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/219d3e551a8d8a000e6354d5d3cdf041b810ee78", "committedDate": "2020-06-19T00:35:07Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}, "afterCommit": {"oid": "746779fb17684f8c8c07865d532a7bd89d49dc8c", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/746779fb17684f8c8c07865d532a7bd89d49dc8c", "committedDate": "2020-06-23T19:57:58Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "431a31062f5ae1b6cfb49e413fbed088bd4143d5", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/431a31062f5ae1b6cfb49e413fbed088bd4143d5", "committedDate": "2020-06-24T23:22:52Z", "message": "Log Replication Design Redefinition\n\n- Single CorfuLogReplicationRuntime per Cluster\n- Leadership Verification as integrated part of Corfu\n- Cluster/Site Discovery/Changes managed through Corfu\n- Rename site -> cluster (Corfu terminology)\n- Cleanup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5c670f2d33048a5945911be148e730e8778ac071", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/5c670f2d33048a5945911be148e730e8778ac071", "committedDate": "2020-06-24T23:10:22Z", "message": "Move Log-Replication and Transport Package\n\n- Move LR and Transport to Infrastructure Package\n- Re-organize code structure within package infrastructure/logreplication"}, "afterCommit": {"oid": "952bccd9bec5f4d34279bc84b48c7642e386fdd6", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/952bccd9bec5f4d34279bc84b48c7642e386fdd6", "committedDate": "2020-06-24T23:25:40Z", "message": "Move Log-Replication and Transport Package\n\n- Move LR and Transport to Infrastructure Package\n- Re-organize code structure within package infrastructure/logreplication"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "952bccd9bec5f4d34279bc84b48c7642e386fdd6", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/952bccd9bec5f4d34279bc84b48c7642e386fdd6", "committedDate": "2020-06-24T23:25:40Z", "message": "Move Log-Replication and Transport Package\n\n- Move LR and Transport to Infrastructure Package\n- Re-organize code structure within package infrastructure/logreplication"}, "afterCommit": {"oid": "0c0ddf332d01806d149ef4354c87828260ac874c", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/0c0ddf332d01806d149ef4354c87828260ac874c", "committedDate": "2020-06-24T23:29:23Z", "message": "Move Log-Replication and Transport Package\n\n- Move LR and Transport to Infrastructure Package\n- Re-organize code structure within package infrastructure/logreplication"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "366113a642098877c92eb1039fb6c61cc07983b6", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/366113a642098877c92eb1039fb6c61cc07983b6", "committedDate": "2020-06-24T23:32:23Z", "message": "Move Log-Replication and Transport Package\n\n- Move LR and Transport to Infrastructure Package\n- Re-organize code structure within package infrastructure/logreplication"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0c0ddf332d01806d149ef4354c87828260ac874c", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/0c0ddf332d01806d149ef4354c87828260ac874c", "committedDate": "2020-06-24T23:29:23Z", "message": "Move Log-Replication and Transport Package\n\n- Move LR and Transport to Infrastructure Package\n- Re-organize code structure within package infrastructure/logreplication"}, "afterCommit": {"oid": "366113a642098877c92eb1039fb6c61cc07983b6", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/366113a642098877c92eb1039fb6c61cc07983b6", "committedDate": "2020-06-24T23:32:23Z", "message": "Move Log-Replication and Transport Package\n\n- Move LR and Transport to Infrastructure Package\n- Re-organize code structure within package infrastructure/logreplication"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5231068e72bb2efbe40edbc6571281c30e23704b", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/5231068e72bb2efbe40edbc6571281c30e23704b", "committedDate": "2020-06-25T07:30:46Z", "message": "Model Log Replication Runtime as FSM"}, "afterCommit": {"oid": "200a8de0b1cb6f18b9fcd5bf55e96d185b70f4a8", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/200a8de0b1cb6f18b9fcd5bf55e96d185b70f4a8", "committedDate": "2020-06-25T07:34:35Z", "message": "Model Log Replication Runtime as FSM"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "200a8de0b1cb6f18b9fcd5bf55e96d185b70f4a8", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/200a8de0b1cb6f18b9fcd5bf55e96d185b70f4a8", "committedDate": "2020-06-25T07:34:35Z", "message": "Model Log Replication Runtime as FSM"}, "afterCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/0e30f73af9eff4a1315c637a3be0e5b91ba42225", "committedDate": "2020-06-25T20:30:38Z", "message": "Model Log Replication Runtime as FSM"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3ODczNTk0", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-437873594", "createdAt": "2020-06-25T21:31:27Z", "commit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQyMTozMToyN1rOGpMhZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQyMTozMToyN1rOGpMhZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg0OTk1OA==", "bodyText": "It seems like LOCAL_LEADER_LOSS event can not stop log replication, so discovery service is not able to be shut down.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r445849958", "createdAt": "2020-06-25T21:31:27Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java", "diffHunk": "@@ -0,0 +1,296 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeStateType;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.StoppingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.UnrecoverableState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.WaitingForConnectionsState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.IllegalTransitionException;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.NegotiatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.ReplicatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.VerifyingRemoteLeaderState;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * Runtime to connect to a remote Corfu Log Replication Cluster.\n+ *\n+ * This class represents the Log Replication Runtime Finite State Machine, which defines\n+ * all states in which the leader node on the active cluster can be.\n+ *\n+ *\n+ *                                                      R-LEADER_LOSS\n+ *                                             +-------------------------------+\n+ *                              ON_CONNECTION  |                               |    ON_CONNECTION_DOWN\n+ *                                    UP       |       ON_CONNECTION_DOWN      |       (NON_LEADER)\n+ *                                    +----+   |          (R-LEADER)           |\n+ *                                    |    |   |   +-----------------------+   |        +-----+\n+ *                                    |    |   |   |                       |   |        |     |\n+ * +---------------+  ON_CONNECTION  ++----v---v---v--+                  +-+---+--------+-+   |\n+ * |               |       UP        |                |  R-REMOTE_LEADER_FOUND  |                <---+\n+ * |    WAITING    +---------------->+    VERIFYING   +------------------>                +---+\n+ * |      FOR      |                 |     REMOTE     |                  |   NEGOTIATING  |   | NEGOTIATION_FAILED\n+ * |  CONNECTIONS  +<----------------+     LEADER     |                  |                <---+\n+ * |               |  ON_CONNECTION  |                +<-----------+     |                +----+\n+ * +---------------+      DOWN       +-^----+---^----++            |     +-------+-----^--+    |\n+ *                       (ALL)         |    |   |    |             |             |     |       |\n+ *                                     |    |   |    |        R-LEADER_LOSS      |     +-------+\n+ *                                     +----+   +----+             |             |  ON_CONNECTION_UP\n+ *                              ON_CONNECTION     R-LEADER_NOT     |             |    (NON-LEADER)\n+ *                                  DOWN              FOUND        |             |\n+ *                                (NOT ALL)                        |     NEGOTIATION_COMPLETE\n+ *                                                                 |             |\n+ *                                                           ON_CONNECTION       |   ON_CONNECTION_UP\n+ *                                                               DOWN            |     (NON-LEADER)\n+ *                                                             (R-LEADER)        |      +-----+\n+ *                                                                 |             |      |     |\n+ *                                                                 |     +-------v------+-+   |\n+ *            +---------------+      ALL STATES                    +-----+                <---+\n+ *            |               |                                          |                |\n+ *            |   STOPPING    <---- L-LEADER_LOSS                        |  REPLICATING   |\n+ *            |               |                                          |                |\n+ *            |               |                                          |                +----+\n+ *            +---------------+                                          +--------------^-+    |\n+ *                                                                                      |      |\n+ *                                                                                      +------+\n+ *            +---------------+     ALL STATES\n+ *            |               |                                                     ON_CONNECTION_DOWN\n+ *            | UNRECOVERABLE <---- ON_ERROR                                           (NON-LEADER)\n+ *            |    STATE      |\n+ *            |               |\n+ *            +---------------+\n+ *\n+ *\n+ *\n+ *\n+ * States:\n+ * ------\n+ *\n+ * - WAITING_FOR_CONNECTIVITY    :: initial state, waiting for any connection to remote cluster to be established.\n+ * - VERIFYING_REMOTE_LEADER     :: verifying the leader endpoint on remote cluster (querying all connected nodes)\n+ * - NEGOTIATING                 :: negotiating against the leader endpoint\n+ * - REPLICATING                 :: replicating data to remote cluster through the leader endpoint\n+ * - STOPPING                    :: stop state machine, no error, just lost leadership so replication stops from this node\n+ * - UNRECOVERABLE_STATE         :: error state, unrecoverable error reported by replication, transport or cluster manager, despite\n+ *                                  being the leader node.\n+ *\n+ *\n+ * Events / Transitions:\n+ * --------------------\n+ *\n+ * - ON_CONNECTION_UP           :: connection to a remote endpoint comes UP\n+ * - ON_CONNECTION_DOWN         :: connection to a remote endpoint comes DOWN\n+ * - REMOTE_LEADER_NOT_FOUND,   :: remote leader not found\n+ * - REMOTE_LEADER_FOUND,       :: remote leader found\n+ * - REMOTE_LEADER_LOSS,        :: remote Leader Lost (remote node reports it is no longer the leader)\n+ * - LOCAL_LEADER_LOSS          :: local node looses leadership\n+ * - NEGOTIATION_COMPLETE,      :: negotiation succeeded and completed\n+ * - NEGOTIATION_FAILED,        :: negotiation failed\n+ * - STOPPING                   :: stop log replication server (fatal state)\n+ *\n+ * @author amartinezman\n+ *\n+ *\n+ */\n+@Slf4j\n+public class CorfuLogReplicationRuntime {\n+\n+    public static final int DEFAULT_TIMEOUT = 5000;\n+\n+    /**\n+     * Current state of the FSM.\n+     */\n+    private volatile LogReplicationRuntimeState state;\n+\n+    /**\n+     * Map of all Log Replication Communication FSM States (reuse single instance for each state)\n+     */\n+    @Getter\n+    private Map<LogReplicationRuntimeStateType, LogReplicationRuntimeState> states = new HashMap<>();\n+\n+    /**\n+     * Executor service for FSM state tasks\n+     */\n+    private ExecutorService communicationFSMWorkers;\n+\n+    /**\n+     * Executor service for FSM event queue consume\n+     */\n+    private ExecutorService communicationFSMConsumer;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<LogReplicationRuntimeEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private final LogReplicationClientRouter router;\n+    private final LogReplicationMetadataManager metadataManager;\n+    private final LogReplicationSourceManager sourceManager;\n+    private volatile Set<String> connectedEndpoints = ConcurrentHashMap.newKeySet();\n+    private volatile Optional<String> leaderEndpoint = Optional.empty();\n+    public final String remoteClusterId;\n+\n+    /**\n+     * Default Constructor\n+     */\n+    public CorfuLogReplicationRuntime(LogReplicationRuntimeParameters parameters, LogReplicationMetadataManager metadataManager) {\n+        this.remoteClusterId = parameters.getRemoteClusterDescriptor().getClusterId();\n+        this.metadataManager = metadataManager;\n+        this.router = new LogReplicationClientRouter(parameters, this);\n+        this.router.addClient(new LogReplicationHandler());\n+        this.sourceManager = new LogReplicationSourceManager(parameters.getLocalCorfuEndpoint(),\n+                new LogReplicationClient(router, remoteClusterId), parameters.getReplicationConfig());\n+        this.communicationFSMWorkers = Executors.newSingleThreadExecutor(new\n+                ThreadFactoryBuilder().setNameFormat(\"runtime-fsm-worker\").build());\n+        this.communicationFSMConsumer = Executors.newSingleThreadExecutor(new\n+                ThreadFactoryBuilder().setNameFormat(\"runtime-fsm-consumer\").build());\n+\n+        initializeStates();\n+        this.state = states.get(LogReplicationRuntimeStateType.WAITING_FOR_CONNECTIVITY);\n+\n+        log.info(\"Log Replication Runtime State Machine initialized\");\n+    }\n+\n+    /**\n+     * Start Log Replication Communication FSM\n+     */\n+    public void start() {\n+        communicationFSMConsumer.submit(this::consume);\n+        router.connect();\n+    }\n+\n+    /**\n+     * Initialize all states for the Log Replication Runtime FSM.\n+     */\n+    private void initializeStates() {\n+        /*\n+         * Log Replication Runtime State instances are kept in a map to be reused in transitions, avoid creating one\n+         * per every transition (reduce GC cycles).\n+         */\n+        states.put(LogReplicationRuntimeStateType.WAITING_FOR_CONNECTIVITY, new WaitingForConnectionsState(this));\n+        states.put(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER, new VerifyingRemoteLeaderState(this, communicationFSMWorkers, router));\n+        states.put(LogReplicationRuntimeStateType.NEGOTIATING, new NegotiatingState(this, communicationFSMWorkers, router, metadataManager));\n+        states.put(LogReplicationRuntimeStateType.REPLICATING, new ReplicatingState(this, sourceManager));\n+        states.put(LogReplicationRuntimeStateType.STOPPING, new StoppingState(sourceManager));\n+        states.put(LogReplicationRuntimeStateType.UNRECOVERABLE, new UnrecoverableState());\n+    }\n+\n+    /**\n+     * Input function of the FSM.\n+     *\n+     * This method enqueues runtime events for further processing.\n+     *\n+     * @param event LogReplicationRuntimeEvent to process.\n+     */\n+    public synchronized void input(LogReplicationRuntimeEvent event) {\n+        try {\n+            if (state.getType().equals(LogReplicationRuntimeStateType.STOPPING)) {\n+                // Not accepting events, in stopped state\n+                return;\n+            }\n+            eventQueue.put(event);\n+        } catch (InterruptedException ex) {\n+            log.error(\"Log Replication interrupted Exception: \", ex);\n+        }\n+    }\n+\n+    /**\n+     * Consumer of the eventQueue.\n+     * <p>\n+     * This method consumes the log replication events and does the state transition.\n+     */\n+    private void consume() {\n+        try {\n+            if (state.getType() == LogReplicationRuntimeStateType.STOPPING) {\n+                log.info(\"Log Replication Communication State Machine has been stopped. No more events will be processed.\");\n+                return;\n+            }\n+\n+            //  Block until an event shows up in the queue.\n+            LogReplicationRuntimeEvent event = eventQueue.take();\n+\n+            try {\n+                LogReplicationRuntimeState newState = state.processEvent(event);\n+                transition(state, newState);\n+                state = newState;\n+            } catch (IllegalTransitionException illegalState) {\n+                log.error(\"Illegal log replication event {} when in state {}\", event.getType(), state.getType());\n+            }\n+\n+            communicationFSMConsumer.submit(this::consume);\n+\n+        } catch (Throwable t) {\n+            log.error(\"Error on event consumer: \", t);\n+        }\n+    }\n+\n+    /**\n+     * Perform transition between states.\n+     *\n+     * @param from initial state\n+     * @param to   final state\n+     */\n+    private void transition(LogReplicationRuntimeState from, LogReplicationRuntimeState to) {\n+        log.trace(\"Transition from {} to {}\", from, to);\n+        from.onExit(to);\n+        to.clear();\n+        to.onEntry(from);\n+    }\n+\n+    public synchronized void updateConnectedEndpoints(String endpoint) {\n+        connectedEndpoints.add(endpoint);\n+    }\n+\n+    public synchronized void updateDisconnectedEndpoints(String endpoint) {\n+        connectedEndpoints.remove(endpoint);\n+    }\n+\n+    public synchronized void setLeaderEndpoint(String leader) {\n+        leaderEndpoint = Optional.ofNullable(leader);\n+    }\n+\n+    public synchronized Optional<String> getLeader() {\n+        return leaderEndpoint;\n+    }\n+\n+    public synchronized Set<String> getConnectedEndpoints() {\n+        return connectedEndpoints;\n+    }\n+\n+    /**\n+     * Retrieve total number of entries to be sent based on a given timestamp.\n+     *\n+     * This is required for progress status reporting.\n+     *\n+     * @param ts base (reference) timestamp\n+     *\n+     * @return pending number of entries to send\n+     */\n+    public long getNumEntriesToSend(long ts) {\n+        long ackTS = sourceManager.getLogReplicationFSM().getAckedTimestamp();\n+        return ts - ackTS;\n+    }\n+\n+    /**\n+     * Stop Log Replication, regardless of current state.\n+     */\n+    public void stop() {\n+        log.info(\"Local leadership lost. Log Replication will immediately stop.\");\n+        input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.LOCAL_LEADER_LOSS));\n+    }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "originalPosition": 296}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3OTQ0Mjcw", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-437944270", "createdAt": "2020-06-26T00:31:02Z", "commit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwMDozMTowMlrOGpQGVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwMDozNjowNFrOGpQLVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwODU2NA==", "bodyText": "return here. Otherwise, it will trigger more than one event.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r445908564", "createdAt": "2020-06-26T00:31:02Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.corfudb.infrastructure.logreplication.runtime.fsm;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.LogReplicationNegotiationException;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationClientRouter;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+@Slf4j\n+public class NegotiatingState implements LogReplicationRuntimeState {\n+\n+    private CorfuLogReplicationRuntime fsm;\n+\n+    private Optional<String> leaderEndpoint;\n+\n+    private volatile AtomicBoolean inProgress = new AtomicBoolean(false);\n+\n+    private ExecutorService worker;\n+\n+    private LogReplicationClientRouter router;\n+\n+    private LogReplicationMetadataManager metadataManager;\n+\n+    public NegotiatingState(CorfuLogReplicationRuntime fsm, ExecutorService worker, LogReplicationClientRouter router,\n+                            LogReplicationMetadataManager metadataManager) {\n+        this.fsm = fsm;\n+        this.metadataManager = metadataManager;\n+        this.worker = worker;\n+        this.router = router;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeStateType getType() {\n+        return LogReplicationRuntimeStateType.NEGOTIATING;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeState processEvent(LogReplicationRuntimeEvent event) throws IllegalTransitionException {\n+        switch (event.getType()) {\n+            case ON_CONNECTION_DOWN:\n+                String endpointDown = event.getEndpoint();\n+                // Update list of valid connections.\n+                fsm.updateDisconnectedEndpoints(endpointDown);\n+\n+                // If the leader is the node that become unavailable, verify new leader and attempt to reconnect.\n+                if (leaderEndpoint.equals(endpointDown)) {\n+                    leaderEndpoint = Optional.empty();\n+                    return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+                } else {\n+                    // Router will attempt reconnection of non-leader endpoint\n+                    return this;\n+                }\n+            case ON_CONNECTION_UP:\n+                // Some node got connected, update connected endpoints\n+                fsm.updateConnectedEndpoints(event.getEndpoint());\n+                return this;\n+            case NEGOTIATION_COMPLETE:\n+                ((ReplicatingState)fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING)).setReplicationEvent(event.getNegotiationResult());\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING);\n+            case NEGOTIATION_FAILED:\n+                return this;\n+            case REMOTE_LEADER_NOT_FOUND:\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+            case ERROR:\n+                ((UnrecoverableState)fsm.getStates().get(LogReplicationRuntimeStateType.UNRECOVERABLE)).setThrowableCause(event.getT().getCause());\n+            default: {\n+                log.warn(\"Unexpected communication event {} when in init state.\", event.getType());\n+                throw new IllegalTransitionException(event.getType(), getType());\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void onEntry(LogReplicationRuntimeState from) {\n+        // Start Negotiation (check if ongoing negotiation is in progress)\n+        if(!inProgress.get()) {\n+            // Start Negotiation\n+            worker.submit(this::negotiate);\n+        }\n+    }\n+\n+    private void negotiate() {\n+        try {\n+            if(fsm.getLeader().isPresent()) {\n+                String remoteLeader = fsm.getLeader().get();\n+                CompletableFuture<LogReplicationNegotiationResponse> cf = router.sendMessageAndGetCompletable(\n+                        new CorfuMsg(CorfuMsgType.LOG_REPLICATION_NEGOTIATION_REQUEST).setEpoch(0), remoteLeader);\n+                LogReplicationNegotiationResponse response = cf.get(CorfuLogReplicationRuntime.DEFAULT_TIMEOUT, TimeUnit.MILLISECONDS);\n+\n+                // Process Negotiation Response, and determine if we start replication and which type type to start\n+                // (snapshot or log entry sync). This will be carried along the negotiation_complete event.\n+                processNegotiationResponse(response);\n+\n+                // Negotiation to leader node completed, unblock channel in the router.\n+                router.getConnectionFuture().complete(null);\n+\n+                // Negotiation completed\n+                inProgress.set(false);\n+            } else {\n+                // No leader found at the time of negotiation\n+                fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+            }\n+        } catch (LogReplicationNegotiationException ne) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", ne);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.ERROR));\n+        } catch (TimeoutException te) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", te);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        } catch (Exception e) {\n+            log.error(\"Unexpected exception during negotiation, retry.\", e);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        }\n+    }\n+\n+    /**\n+     * Set Leader Endpoint, determined during the transition from VERIFYING_REMOTE_LEADER\n+     * to NEGOTIATING state.\n+     *\n+     * @param endpoint leader node on remote cluster\n+     */\n+    public void setLeaderEndpoint(String endpoint) {\n+        this.leaderEndpoint = Optional.of(endpoint);\n+    }\n+\n+    /**\n+     * It will decide to do a full snapshot sync or log entry sync according to the metadata received from the standby site.\n+     *\n+     * @param negotiationResponse\n+     * @return\n+     * @throws LogReplicationNegotiationException\n+     */\n+    private void processNegotiationResponse(LogReplicationNegotiationResponse negotiationResponse)\n+            throws LogReplicationNegotiationException {\n+        /*\n+         * If the version are different, report an error.\n+         */\n+        if (!negotiationResponse.getVersion().equals(metadataManager.getVersion())) {\n+            log.error(\"The active site version {} is different from standby site version {}\",\n+                    metadataManager.getVersion(), negotiationResponse.getVersion());\n+            throw new LogReplicationNegotiationException(\" Mismatch of version number\");\n+        }\n+\n+        /*\n+         * The standby site has a smaller config ID, redo the discovery for this standby site when\n+         * getting a new notification of the site config change if this standby is in the new config.\n+         */\n+        if (negotiationResponse.getSiteConfigID() < negotiationResponse.getSiteConfigID()) {\n+            log.error(\"The active site configID {} is bigger than the standby configID {} \",\n+                    metadataManager.getSiteConfigID(), negotiationResponse.getSiteConfigID());\n+            throw new LogReplicationNegotiationException(\"Mismatch of configID\");\n+        }\n+\n+        /*\n+         * The standby site has larger config ID, redo the whole discovery for the active site\n+         * it will be triggered by a notification of the site config change.\n+         */\n+        if (negotiationResponse.getSiteConfigID() > negotiationResponse.getSiteConfigID()) {\n+            log.error(\"The active site configID {} is smaller than the standby configID {} \",\n+                    metadataManager.getSiteConfigID(), negotiationResponse.getSiteConfigID());\n+            throw new LogReplicationNegotiationException(\"Mismatch of configID\");\n+        }\n+\n+        /*\n+         * Now the active and standby have the same version and same configID.\n+         */\n+\n+        /*\n+         * Get the current log head.\n+         */\n+        long logHead = metadataManager.getLogHead();\n+\n+        /*\n+         * It is a fresh start, start snapshot full sync.\n+         * Following is an example that metadata value indicates a fresh start, no replicated data at standby site:\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"-1\"\n+         * \"snapshotSeqNum\": \" -1\"\n+         * \"snapshotTransferred\": \"-1\"\n+         * \"snapshotApplied\": \"-1\"\n+         * \"lastLogEntryProcessed\": \"-1\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() == -1) {\n+            negotiationResponse.getLastLogProcessed();\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                    new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_SYNC_REQUEST)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwODYxOA==", "bodyText": "Same here", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r445908618", "createdAt": "2020-06-26T00:31:14Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.corfudb.infrastructure.logreplication.runtime.fsm;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.LogReplicationNegotiationException;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationClientRouter;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+@Slf4j\n+public class NegotiatingState implements LogReplicationRuntimeState {\n+\n+    private CorfuLogReplicationRuntime fsm;\n+\n+    private Optional<String> leaderEndpoint;\n+\n+    private volatile AtomicBoolean inProgress = new AtomicBoolean(false);\n+\n+    private ExecutorService worker;\n+\n+    private LogReplicationClientRouter router;\n+\n+    private LogReplicationMetadataManager metadataManager;\n+\n+    public NegotiatingState(CorfuLogReplicationRuntime fsm, ExecutorService worker, LogReplicationClientRouter router,\n+                            LogReplicationMetadataManager metadataManager) {\n+        this.fsm = fsm;\n+        this.metadataManager = metadataManager;\n+        this.worker = worker;\n+        this.router = router;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeStateType getType() {\n+        return LogReplicationRuntimeStateType.NEGOTIATING;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeState processEvent(LogReplicationRuntimeEvent event) throws IllegalTransitionException {\n+        switch (event.getType()) {\n+            case ON_CONNECTION_DOWN:\n+                String endpointDown = event.getEndpoint();\n+                // Update list of valid connections.\n+                fsm.updateDisconnectedEndpoints(endpointDown);\n+\n+                // If the leader is the node that become unavailable, verify new leader and attempt to reconnect.\n+                if (leaderEndpoint.equals(endpointDown)) {\n+                    leaderEndpoint = Optional.empty();\n+                    return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+                } else {\n+                    // Router will attempt reconnection of non-leader endpoint\n+                    return this;\n+                }\n+            case ON_CONNECTION_UP:\n+                // Some node got connected, update connected endpoints\n+                fsm.updateConnectedEndpoints(event.getEndpoint());\n+                return this;\n+            case NEGOTIATION_COMPLETE:\n+                ((ReplicatingState)fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING)).setReplicationEvent(event.getNegotiationResult());\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING);\n+            case NEGOTIATION_FAILED:\n+                return this;\n+            case REMOTE_LEADER_NOT_FOUND:\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+            case ERROR:\n+                ((UnrecoverableState)fsm.getStates().get(LogReplicationRuntimeStateType.UNRECOVERABLE)).setThrowableCause(event.getT().getCause());\n+            default: {\n+                log.warn(\"Unexpected communication event {} when in init state.\", event.getType());\n+                throw new IllegalTransitionException(event.getType(), getType());\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void onEntry(LogReplicationRuntimeState from) {\n+        // Start Negotiation (check if ongoing negotiation is in progress)\n+        if(!inProgress.get()) {\n+            // Start Negotiation\n+            worker.submit(this::negotiate);\n+        }\n+    }\n+\n+    private void negotiate() {\n+        try {\n+            if(fsm.getLeader().isPresent()) {\n+                String remoteLeader = fsm.getLeader().get();\n+                CompletableFuture<LogReplicationNegotiationResponse> cf = router.sendMessageAndGetCompletable(\n+                        new CorfuMsg(CorfuMsgType.LOG_REPLICATION_NEGOTIATION_REQUEST).setEpoch(0), remoteLeader);\n+                LogReplicationNegotiationResponse response = cf.get(CorfuLogReplicationRuntime.DEFAULT_TIMEOUT, TimeUnit.MILLISECONDS);\n+\n+                // Process Negotiation Response, and determine if we start replication and which type type to start\n+                // (snapshot or log entry sync). This will be carried along the negotiation_complete event.\n+                processNegotiationResponse(response);\n+\n+                // Negotiation to leader node completed, unblock channel in the router.\n+                router.getConnectionFuture().complete(null);\n+\n+                // Negotiation completed\n+                inProgress.set(false);\n+            } else {\n+                // No leader found at the time of negotiation\n+                fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+            }\n+        } catch (LogReplicationNegotiationException ne) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", ne);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.ERROR));\n+        } catch (TimeoutException te) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", te);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        } catch (Exception e) {\n+            log.error(\"Unexpected exception during negotiation, retry.\", e);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        }\n+    }\n+\n+    /**\n+     * Set Leader Endpoint, determined during the transition from VERIFYING_REMOTE_LEADER\n+     * to NEGOTIATING state.\n+     *\n+     * @param endpoint leader node on remote cluster\n+     */\n+    public void setLeaderEndpoint(String endpoint) {\n+        this.leaderEndpoint = Optional.of(endpoint);\n+    }\n+\n+    /**\n+     * It will decide to do a full snapshot sync or log entry sync according to the metadata received from the standby site.\n+     *\n+     * @param negotiationResponse\n+     * @return\n+     * @throws LogReplicationNegotiationException\n+     */\n+    private void processNegotiationResponse(LogReplicationNegotiationResponse negotiationResponse)\n+            throws LogReplicationNegotiationException {\n+        /*\n+         * If the version are different, report an error.\n+         */\n+        if (!negotiationResponse.getVersion().equals(metadataManager.getVersion())) {\n+            log.error(\"The active site version {} is different from standby site version {}\",\n+                    metadataManager.getVersion(), negotiationResponse.getVersion());\n+            throw new LogReplicationNegotiationException(\" Mismatch of version number\");\n+        }\n+\n+        /*\n+         * The standby site has a smaller config ID, redo the discovery for this standby site when\n+         * getting a new notification of the site config change if this standby is in the new config.\n+         */\n+        if (negotiationResponse.getSiteConfigID() < negotiationResponse.getSiteConfigID()) {\n+            log.error(\"The active site configID {} is bigger than the standby configID {} \",\n+                    metadataManager.getSiteConfigID(), negotiationResponse.getSiteConfigID());\n+            throw new LogReplicationNegotiationException(\"Mismatch of configID\");\n+        }\n+\n+        /*\n+         * The standby site has larger config ID, redo the whole discovery for the active site\n+         * it will be triggered by a notification of the site config change.\n+         */\n+        if (negotiationResponse.getSiteConfigID() > negotiationResponse.getSiteConfigID()) {\n+            log.error(\"The active site configID {} is smaller than the standby configID {} \",\n+                    metadataManager.getSiteConfigID(), negotiationResponse.getSiteConfigID());\n+            throw new LogReplicationNegotiationException(\"Mismatch of configID\");\n+        }\n+\n+        /*\n+         * Now the active and standby have the same version and same configID.\n+         */\n+\n+        /*\n+         * Get the current log head.\n+         */\n+        long logHead = metadataManager.getLogHead();\n+\n+        /*\n+         * It is a fresh start, start snapshot full sync.\n+         * Following is an example that metadata value indicates a fresh start, no replicated data at standby site:\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"-1\"\n+         * \"snapshotSeqNum\": \" -1\"\n+         * \"snapshotTransferred\": \"-1\"\n+         * \"snapshotApplied\": \"-1\"\n+         * \"lastLogEntryProcessed\": \"-1\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() == -1) {\n+            negotiationResponse.getLastLogProcessed();\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                    new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_SYNC_REQUEST)));\n+        }\n+\n+        /*\n+         * If it is in the snapshot full sync phase I, transferring data, restart the snapshot full sync.\n+         * An example of in Snapshot Sync Phase I, transfer phase:\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"100\"\n+         * \"snapshotSeqNum\": \" 88\"\n+         * \"snapshotTransferred\": \"-1\"\n+         * \"snapshotApplied\": \"-1\"\n+         * \"lastLogEntryProcessed\": \"-1\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() > negotiationResponse.getSnapshotTransferred()) {\n+            log.info(\"Get the negotiation response {} and will start replication.\",\n+                    negotiationResponse);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                    new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_SYNC_REQUEST)));\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwODY3OQ==", "bodyText": "Same here", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r445908679", "createdAt": "2020-06-26T00:31:28Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.corfudb.infrastructure.logreplication.runtime.fsm;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.LogReplicationNegotiationException;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationClientRouter;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+@Slf4j\n+public class NegotiatingState implements LogReplicationRuntimeState {\n+\n+    private CorfuLogReplicationRuntime fsm;\n+\n+    private Optional<String> leaderEndpoint;\n+\n+    private volatile AtomicBoolean inProgress = new AtomicBoolean(false);\n+\n+    private ExecutorService worker;\n+\n+    private LogReplicationClientRouter router;\n+\n+    private LogReplicationMetadataManager metadataManager;\n+\n+    public NegotiatingState(CorfuLogReplicationRuntime fsm, ExecutorService worker, LogReplicationClientRouter router,\n+                            LogReplicationMetadataManager metadataManager) {\n+        this.fsm = fsm;\n+        this.metadataManager = metadataManager;\n+        this.worker = worker;\n+        this.router = router;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeStateType getType() {\n+        return LogReplicationRuntimeStateType.NEGOTIATING;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeState processEvent(LogReplicationRuntimeEvent event) throws IllegalTransitionException {\n+        switch (event.getType()) {\n+            case ON_CONNECTION_DOWN:\n+                String endpointDown = event.getEndpoint();\n+                // Update list of valid connections.\n+                fsm.updateDisconnectedEndpoints(endpointDown);\n+\n+                // If the leader is the node that become unavailable, verify new leader and attempt to reconnect.\n+                if (leaderEndpoint.equals(endpointDown)) {\n+                    leaderEndpoint = Optional.empty();\n+                    return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+                } else {\n+                    // Router will attempt reconnection of non-leader endpoint\n+                    return this;\n+                }\n+            case ON_CONNECTION_UP:\n+                // Some node got connected, update connected endpoints\n+                fsm.updateConnectedEndpoints(event.getEndpoint());\n+                return this;\n+            case NEGOTIATION_COMPLETE:\n+                ((ReplicatingState)fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING)).setReplicationEvent(event.getNegotiationResult());\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING);\n+            case NEGOTIATION_FAILED:\n+                return this;\n+            case REMOTE_LEADER_NOT_FOUND:\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+            case ERROR:\n+                ((UnrecoverableState)fsm.getStates().get(LogReplicationRuntimeStateType.UNRECOVERABLE)).setThrowableCause(event.getT().getCause());\n+            default: {\n+                log.warn(\"Unexpected communication event {} when in init state.\", event.getType());\n+                throw new IllegalTransitionException(event.getType(), getType());\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void onEntry(LogReplicationRuntimeState from) {\n+        // Start Negotiation (check if ongoing negotiation is in progress)\n+        if(!inProgress.get()) {\n+            // Start Negotiation\n+            worker.submit(this::negotiate);\n+        }\n+    }\n+\n+    private void negotiate() {\n+        try {\n+            if(fsm.getLeader().isPresent()) {\n+                String remoteLeader = fsm.getLeader().get();\n+                CompletableFuture<LogReplicationNegotiationResponse> cf = router.sendMessageAndGetCompletable(\n+                        new CorfuMsg(CorfuMsgType.LOG_REPLICATION_NEGOTIATION_REQUEST).setEpoch(0), remoteLeader);\n+                LogReplicationNegotiationResponse response = cf.get(CorfuLogReplicationRuntime.DEFAULT_TIMEOUT, TimeUnit.MILLISECONDS);\n+\n+                // Process Negotiation Response, and determine if we start replication and which type type to start\n+                // (snapshot or log entry sync). This will be carried along the negotiation_complete event.\n+                processNegotiationResponse(response);\n+\n+                // Negotiation to leader node completed, unblock channel in the router.\n+                router.getConnectionFuture().complete(null);\n+\n+                // Negotiation completed\n+                inProgress.set(false);\n+            } else {\n+                // No leader found at the time of negotiation\n+                fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+            }\n+        } catch (LogReplicationNegotiationException ne) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", ne);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.ERROR));\n+        } catch (TimeoutException te) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", te);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        } catch (Exception e) {\n+            log.error(\"Unexpected exception during negotiation, retry.\", e);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        }\n+    }\n+\n+    /**\n+     * Set Leader Endpoint, determined during the transition from VERIFYING_REMOTE_LEADER\n+     * to NEGOTIATING state.\n+     *\n+     * @param endpoint leader node on remote cluster\n+     */\n+    public void setLeaderEndpoint(String endpoint) {\n+        this.leaderEndpoint = Optional.of(endpoint);\n+    }\n+\n+    /**\n+     * It will decide to do a full snapshot sync or log entry sync according to the metadata received from the standby site.\n+     *\n+     * @param negotiationResponse\n+     * @return\n+     * @throws LogReplicationNegotiationException\n+     */\n+    private void processNegotiationResponse(LogReplicationNegotiationResponse negotiationResponse)\n+            throws LogReplicationNegotiationException {\n+        /*\n+         * If the version are different, report an error.\n+         */\n+        if (!negotiationResponse.getVersion().equals(metadataManager.getVersion())) {\n+            log.error(\"The active site version {} is different from standby site version {}\",\n+                    metadataManager.getVersion(), negotiationResponse.getVersion());\n+            throw new LogReplicationNegotiationException(\" Mismatch of version number\");\n+        }\n+\n+        /*\n+         * The standby site has a smaller config ID, redo the discovery for this standby site when\n+         * getting a new notification of the site config change if this standby is in the new config.\n+         */\n+        if (negotiationResponse.getSiteConfigID() < negotiationResponse.getSiteConfigID()) {\n+            log.error(\"The active site configID {} is bigger than the standby configID {} \",\n+                    metadataManager.getSiteConfigID(), negotiationResponse.getSiteConfigID());\n+            throw new LogReplicationNegotiationException(\"Mismatch of configID\");\n+        }\n+\n+        /*\n+         * The standby site has larger config ID, redo the whole discovery for the active site\n+         * it will be triggered by a notification of the site config change.\n+         */\n+        if (negotiationResponse.getSiteConfigID() > negotiationResponse.getSiteConfigID()) {\n+            log.error(\"The active site configID {} is smaller than the standby configID {} \",\n+                    metadataManager.getSiteConfigID(), negotiationResponse.getSiteConfigID());\n+            throw new LogReplicationNegotiationException(\"Mismatch of configID\");\n+        }\n+\n+        /*\n+         * Now the active and standby have the same version and same configID.\n+         */\n+\n+        /*\n+         * Get the current log head.\n+         */\n+        long logHead = metadataManager.getLogHead();\n+\n+        /*\n+         * It is a fresh start, start snapshot full sync.\n+         * Following is an example that metadata value indicates a fresh start, no replicated data at standby site:\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"-1\"\n+         * \"snapshotSeqNum\": \" -1\"\n+         * \"snapshotTransferred\": \"-1\"\n+         * \"snapshotApplied\": \"-1\"\n+         * \"lastLogEntryProcessed\": \"-1\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() == -1) {\n+            negotiationResponse.getLastLogProcessed();\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                    new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_SYNC_REQUEST)));\n+        }\n+\n+        /*\n+         * If it is in the snapshot full sync phase I, transferring data, restart the snapshot full sync.\n+         * An example of in Snapshot Sync Phase I, transfer phase:\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"100\"\n+         * \"snapshotSeqNum\": \" 88\"\n+         * \"snapshotTransferred\": \"-1\"\n+         * \"snapshotApplied\": \"-1\"\n+         * \"lastLogEntryProcessed\": \"-1\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() > negotiationResponse.getSnapshotTransferred()) {\n+            log.info(\"Get the negotiation response {} and will start replication.\",\n+                    negotiationResponse);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                    new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_SYNC_REQUEST)));\n+        }\n+\n+        /*\n+         * If it is in the snapshot full sync phase II:\n+         * the data has been transferred to the standby site and the the standby site is applying data from shadow streams\n+         * to the real streams.\n+         * It doesn't need to transfer the data again, just send a SNAPSHOT_COMPLETE message to the standby site.\n+         * An example of in Snapshot sync phase II: applying phase\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"100\"\n+         * \"snapshotSeqNum\": \" 88\"\n+         * \"snapshotTransferred\": \"100\"\n+         * \"snapshotApplied\": \"-1\"\n+         * \"lastLogEntryProcessed\": \"-1\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() == negotiationResponse.getSnapshotTransferred() &&\n+                negotiationResponse.getSnapshotTransferred() > negotiationResponse.getSnapshotApplied()) {\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                    new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_WAIT_COMPLETE,\n+                            new LogReplicationEventMetadata(LogReplicationEventMetadata.getNIL_UUID(), negotiationResponse.getSnapshotStart()))));\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwODczNw==", "bodyText": "here", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r445908737", "createdAt": "2020-06-26T00:31:41Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.corfudb.infrastructure.logreplication.runtime.fsm;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.LogReplicationNegotiationException;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationClientRouter;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+@Slf4j\n+public class NegotiatingState implements LogReplicationRuntimeState {\n+\n+    private CorfuLogReplicationRuntime fsm;\n+\n+    private Optional<String> leaderEndpoint;\n+\n+    private volatile AtomicBoolean inProgress = new AtomicBoolean(false);\n+\n+    private ExecutorService worker;\n+\n+    private LogReplicationClientRouter router;\n+\n+    private LogReplicationMetadataManager metadataManager;\n+\n+    public NegotiatingState(CorfuLogReplicationRuntime fsm, ExecutorService worker, LogReplicationClientRouter router,\n+                            LogReplicationMetadataManager metadataManager) {\n+        this.fsm = fsm;\n+        this.metadataManager = metadataManager;\n+        this.worker = worker;\n+        this.router = router;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeStateType getType() {\n+        return LogReplicationRuntimeStateType.NEGOTIATING;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeState processEvent(LogReplicationRuntimeEvent event) throws IllegalTransitionException {\n+        switch (event.getType()) {\n+            case ON_CONNECTION_DOWN:\n+                String endpointDown = event.getEndpoint();\n+                // Update list of valid connections.\n+                fsm.updateDisconnectedEndpoints(endpointDown);\n+\n+                // If the leader is the node that become unavailable, verify new leader and attempt to reconnect.\n+                if (leaderEndpoint.equals(endpointDown)) {\n+                    leaderEndpoint = Optional.empty();\n+                    return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+                } else {\n+                    // Router will attempt reconnection of non-leader endpoint\n+                    return this;\n+                }\n+            case ON_CONNECTION_UP:\n+                // Some node got connected, update connected endpoints\n+                fsm.updateConnectedEndpoints(event.getEndpoint());\n+                return this;\n+            case NEGOTIATION_COMPLETE:\n+                ((ReplicatingState)fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING)).setReplicationEvent(event.getNegotiationResult());\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING);\n+            case NEGOTIATION_FAILED:\n+                return this;\n+            case REMOTE_LEADER_NOT_FOUND:\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+            case ERROR:\n+                ((UnrecoverableState)fsm.getStates().get(LogReplicationRuntimeStateType.UNRECOVERABLE)).setThrowableCause(event.getT().getCause());\n+            default: {\n+                log.warn(\"Unexpected communication event {} when in init state.\", event.getType());\n+                throw new IllegalTransitionException(event.getType(), getType());\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void onEntry(LogReplicationRuntimeState from) {\n+        // Start Negotiation (check if ongoing negotiation is in progress)\n+        if(!inProgress.get()) {\n+            // Start Negotiation\n+            worker.submit(this::negotiate);\n+        }\n+    }\n+\n+    private void negotiate() {\n+        try {\n+            if(fsm.getLeader().isPresent()) {\n+                String remoteLeader = fsm.getLeader().get();\n+                CompletableFuture<LogReplicationNegotiationResponse> cf = router.sendMessageAndGetCompletable(\n+                        new CorfuMsg(CorfuMsgType.LOG_REPLICATION_NEGOTIATION_REQUEST).setEpoch(0), remoteLeader);\n+                LogReplicationNegotiationResponse response = cf.get(CorfuLogReplicationRuntime.DEFAULT_TIMEOUT, TimeUnit.MILLISECONDS);\n+\n+                // Process Negotiation Response, and determine if we start replication and which type type to start\n+                // (snapshot or log entry sync). This will be carried along the negotiation_complete event.\n+                processNegotiationResponse(response);\n+\n+                // Negotiation to leader node completed, unblock channel in the router.\n+                router.getConnectionFuture().complete(null);\n+\n+                // Negotiation completed\n+                inProgress.set(false);\n+            } else {\n+                // No leader found at the time of negotiation\n+                fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+            }\n+        } catch (LogReplicationNegotiationException ne) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", ne);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.ERROR));\n+        } catch (TimeoutException te) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", te);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        } catch (Exception e) {\n+            log.error(\"Unexpected exception during negotiation, retry.\", e);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        }\n+    }\n+\n+    /**\n+     * Set Leader Endpoint, determined during the transition from VERIFYING_REMOTE_LEADER\n+     * to NEGOTIATING state.\n+     *\n+     * @param endpoint leader node on remote cluster\n+     */\n+    public void setLeaderEndpoint(String endpoint) {\n+        this.leaderEndpoint = Optional.of(endpoint);\n+    }\n+\n+    /**\n+     * It will decide to do a full snapshot sync or log entry sync according to the metadata received from the standby site.\n+     *\n+     * @param negotiationResponse\n+     * @return\n+     * @throws LogReplicationNegotiationException\n+     */\n+    private void processNegotiationResponse(LogReplicationNegotiationResponse negotiationResponse)\n+            throws LogReplicationNegotiationException {\n+        /*\n+         * If the version are different, report an error.\n+         */\n+        if (!negotiationResponse.getVersion().equals(metadataManager.getVersion())) {\n+            log.error(\"The active site version {} is different from standby site version {}\",\n+                    metadataManager.getVersion(), negotiationResponse.getVersion());\n+            throw new LogReplicationNegotiationException(\" Mismatch of version number\");\n+        }\n+\n+        /*\n+         * The standby site has a smaller config ID, redo the discovery for this standby site when\n+         * getting a new notification of the site config change if this standby is in the new config.\n+         */\n+        if (negotiationResponse.getSiteConfigID() < negotiationResponse.getSiteConfigID()) {\n+            log.error(\"The active site configID {} is bigger than the standby configID {} \",\n+                    metadataManager.getSiteConfigID(), negotiationResponse.getSiteConfigID());\n+            throw new LogReplicationNegotiationException(\"Mismatch of configID\");\n+        }\n+\n+        /*\n+         * The standby site has larger config ID, redo the whole discovery for the active site\n+         * it will be triggered by a notification of the site config change.\n+         */\n+        if (negotiationResponse.getSiteConfigID() > negotiationResponse.getSiteConfigID()) {\n+            log.error(\"The active site configID {} is smaller than the standby configID {} \",\n+                    metadataManager.getSiteConfigID(), negotiationResponse.getSiteConfigID());\n+            throw new LogReplicationNegotiationException(\"Mismatch of configID\");\n+        }\n+\n+        /*\n+         * Now the active and standby have the same version and same configID.\n+         */\n+\n+        /*\n+         * Get the current log head.\n+         */\n+        long logHead = metadataManager.getLogHead();\n+\n+        /*\n+         * It is a fresh start, start snapshot full sync.\n+         * Following is an example that metadata value indicates a fresh start, no replicated data at standby site:\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"-1\"\n+         * \"snapshotSeqNum\": \" -1\"\n+         * \"snapshotTransferred\": \"-1\"\n+         * \"snapshotApplied\": \"-1\"\n+         * \"lastLogEntryProcessed\": \"-1\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() == -1) {\n+            negotiationResponse.getLastLogProcessed();\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                    new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_SYNC_REQUEST)));\n+        }\n+\n+        /*\n+         * If it is in the snapshot full sync phase I, transferring data, restart the snapshot full sync.\n+         * An example of in Snapshot Sync Phase I, transfer phase:\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"100\"\n+         * \"snapshotSeqNum\": \" 88\"\n+         * \"snapshotTransferred\": \"-1\"\n+         * \"snapshotApplied\": \"-1\"\n+         * \"lastLogEntryProcessed\": \"-1\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() > negotiationResponse.getSnapshotTransferred()) {\n+            log.info(\"Get the negotiation response {} and will start replication.\",\n+                    negotiationResponse);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                    new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_SYNC_REQUEST)));\n+        }\n+\n+        /*\n+         * If it is in the snapshot full sync phase II:\n+         * the data has been transferred to the standby site and the the standby site is applying data from shadow streams\n+         * to the real streams.\n+         * It doesn't need to transfer the data again, just send a SNAPSHOT_COMPLETE message to the standby site.\n+         * An example of in Snapshot sync phase II: applying phase\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"100\"\n+         * \"snapshotSeqNum\": \" 88\"\n+         * \"snapshotTransferred\": \"100\"\n+         * \"snapshotApplied\": \"-1\"\n+         * \"lastLogEntryProcessed\": \"-1\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() == negotiationResponse.getSnapshotTransferred() &&\n+                negotiationResponse.getSnapshotTransferred() > negotiationResponse.getSnapshotApplied()) {\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                    new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_WAIT_COMPLETE,\n+                            new LogReplicationEventMetadata(LogReplicationEventMetadata.getNIL_UUID(), negotiationResponse.getSnapshotStart()))));\n+        }\n+\n+        /* If it is in log entry sync state, continues log entry sync state.\n+         * An example to show the standby site is in log entry sync phase.\n+         * A full snapshot transfer based on timestamp 100 has been completed, and this standby has processed all log entries\n+         * between 100 to 200. A log entry sync should be restart if log entry 201 is not trimmed.\n+         * Otherwise, start a full snapshot full sync.\n+         * \"topologyConfigId\": \"10\"\n+         * \"version\": \"release-1.0\"\n+         * \"snapshotStart\": \"100\"\n+         * \"snapshotSeqNum\": \" 88\"\n+         * \"snapshotTransferred\": \"100\"\n+         * \"snapshotApplied\": \"100\"\n+         * \"lastLogEntryProcessed\": \"200\"\n+         */\n+        if (negotiationResponse.getSnapshotStart() == negotiationResponse.getSnapshotTransferred() &&\n+                negotiationResponse.getSnapshotStart() == negotiationResponse.getSnapshotApplied() &&\n+                negotiationResponse.getLastLogProcessed() >= negotiationResponse.getSnapshotStart()) {\n+            /*\n+             * If the next log entry is not trimmed, restart with log entry sync,\n+             * otherwise, start snapshot full sync.\n+             */\n+            if (logHead <= negotiationResponse.getLastLogProcessed() + 1) {\n+                fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                        new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.REPLICATION_START,\n+                                new LogReplicationEventMetadata(LogReplicationEventMetadata.getNIL_UUID(), negotiationResponse.getLastLogProcessed())\n+                        )));\n+            } else {\n+                fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,\n+                        new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_SYNC_REQUEST)));\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "originalPosition": 268}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwODkwOA==", "bodyText": "negotiationResponse.getSiteConfigID() > metadataManager.getSiteConfigID()", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r445908908", "createdAt": "2020-06-26T00:32:25Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.corfudb.infrastructure.logreplication.runtime.fsm;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.LogReplicationNegotiationException;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationClientRouter;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+@Slf4j\n+public class NegotiatingState implements LogReplicationRuntimeState {\n+\n+    private CorfuLogReplicationRuntime fsm;\n+\n+    private Optional<String> leaderEndpoint;\n+\n+    private volatile AtomicBoolean inProgress = new AtomicBoolean(false);\n+\n+    private ExecutorService worker;\n+\n+    private LogReplicationClientRouter router;\n+\n+    private LogReplicationMetadataManager metadataManager;\n+\n+    public NegotiatingState(CorfuLogReplicationRuntime fsm, ExecutorService worker, LogReplicationClientRouter router,\n+                            LogReplicationMetadataManager metadataManager) {\n+        this.fsm = fsm;\n+        this.metadataManager = metadataManager;\n+        this.worker = worker;\n+        this.router = router;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeStateType getType() {\n+        return LogReplicationRuntimeStateType.NEGOTIATING;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeState processEvent(LogReplicationRuntimeEvent event) throws IllegalTransitionException {\n+        switch (event.getType()) {\n+            case ON_CONNECTION_DOWN:\n+                String endpointDown = event.getEndpoint();\n+                // Update list of valid connections.\n+                fsm.updateDisconnectedEndpoints(endpointDown);\n+\n+                // If the leader is the node that become unavailable, verify new leader and attempt to reconnect.\n+                if (leaderEndpoint.equals(endpointDown)) {\n+                    leaderEndpoint = Optional.empty();\n+                    return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+                } else {\n+                    // Router will attempt reconnection of non-leader endpoint\n+                    return this;\n+                }\n+            case ON_CONNECTION_UP:\n+                // Some node got connected, update connected endpoints\n+                fsm.updateConnectedEndpoints(event.getEndpoint());\n+                return this;\n+            case NEGOTIATION_COMPLETE:\n+                ((ReplicatingState)fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING)).setReplicationEvent(event.getNegotiationResult());\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING);\n+            case NEGOTIATION_FAILED:\n+                return this;\n+            case REMOTE_LEADER_NOT_FOUND:\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+            case ERROR:\n+                ((UnrecoverableState)fsm.getStates().get(LogReplicationRuntimeStateType.UNRECOVERABLE)).setThrowableCause(event.getT().getCause());\n+            default: {\n+                log.warn(\"Unexpected communication event {} when in init state.\", event.getType());\n+                throw new IllegalTransitionException(event.getType(), getType());\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void onEntry(LogReplicationRuntimeState from) {\n+        // Start Negotiation (check if ongoing negotiation is in progress)\n+        if(!inProgress.get()) {\n+            // Start Negotiation\n+            worker.submit(this::negotiate);\n+        }\n+    }\n+\n+    private void negotiate() {\n+        try {\n+            if(fsm.getLeader().isPresent()) {\n+                String remoteLeader = fsm.getLeader().get();\n+                CompletableFuture<LogReplicationNegotiationResponse> cf = router.sendMessageAndGetCompletable(\n+                        new CorfuMsg(CorfuMsgType.LOG_REPLICATION_NEGOTIATION_REQUEST).setEpoch(0), remoteLeader);\n+                LogReplicationNegotiationResponse response = cf.get(CorfuLogReplicationRuntime.DEFAULT_TIMEOUT, TimeUnit.MILLISECONDS);\n+\n+                // Process Negotiation Response, and determine if we start replication and which type type to start\n+                // (snapshot or log entry sync). This will be carried along the negotiation_complete event.\n+                processNegotiationResponse(response);\n+\n+                // Negotiation to leader node completed, unblock channel in the router.\n+                router.getConnectionFuture().complete(null);\n+\n+                // Negotiation completed\n+                inProgress.set(false);\n+            } else {\n+                // No leader found at the time of negotiation\n+                fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+            }\n+        } catch (LogReplicationNegotiationException ne) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", ne);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.ERROR));\n+        } catch (TimeoutException te) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", te);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        } catch (Exception e) {\n+            log.error(\"Unexpected exception during negotiation, retry.\", e);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        }\n+    }\n+\n+    /**\n+     * Set Leader Endpoint, determined during the transition from VERIFYING_REMOTE_LEADER\n+     * to NEGOTIATING state.\n+     *\n+     * @param endpoint leader node on remote cluster\n+     */\n+    public void setLeaderEndpoint(String endpoint) {\n+        this.leaderEndpoint = Optional.of(endpoint);\n+    }\n+\n+    /**\n+     * It will decide to do a full snapshot sync or log entry sync according to the metadata received from the standby site.\n+     *\n+     * @param negotiationResponse\n+     * @return\n+     * @throws LogReplicationNegotiationException\n+     */\n+    private void processNegotiationResponse(LogReplicationNegotiationResponse negotiationResponse)\n+            throws LogReplicationNegotiationException {\n+        /*\n+         * If the version are different, report an error.\n+         */\n+        if (!negotiationResponse.getVersion().equals(metadataManager.getVersion())) {\n+            log.error(\"The active site version {} is different from standby site version {}\",\n+                    metadataManager.getVersion(), negotiationResponse.getVersion());\n+            throw new LogReplicationNegotiationException(\" Mismatch of version number\");\n+        }\n+\n+        /*\n+         * The standby site has a smaller config ID, redo the discovery for this standby site when\n+         * getting a new notification of the site config change if this standby is in the new config.\n+         */\n+        if (negotiationResponse.getSiteConfigID() < negotiationResponse.getSiteConfigID()) {\n+            log.error(\"The active site configID {} is bigger than the standby configID {} \",\n+                    metadataManager.getSiteConfigID(), negotiationResponse.getSiteConfigID());\n+            throw new LogReplicationNegotiationException(\"Mismatch of configID\");\n+        }\n+\n+        /*\n+         * The standby site has larger config ID, redo the whole discovery for the active site\n+         * it will be triggered by a notification of the site config change.\n+         */\n+        if (negotiationResponse.getSiteConfigID() > negotiationResponse.getSiteConfigID()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwOTAyNQ==", "bodyText": "negotiationResponse.getSiteConfigID() < metadataManager.getSiteConfigID()", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r445909025", "createdAt": "2020-06-26T00:32:42Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.corfudb.infrastructure.logreplication.runtime.fsm;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.LogReplicationNegotiationException;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationClientRouter;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+@Slf4j\n+public class NegotiatingState implements LogReplicationRuntimeState {\n+\n+    private CorfuLogReplicationRuntime fsm;\n+\n+    private Optional<String> leaderEndpoint;\n+\n+    private volatile AtomicBoolean inProgress = new AtomicBoolean(false);\n+\n+    private ExecutorService worker;\n+\n+    private LogReplicationClientRouter router;\n+\n+    private LogReplicationMetadataManager metadataManager;\n+\n+    public NegotiatingState(CorfuLogReplicationRuntime fsm, ExecutorService worker, LogReplicationClientRouter router,\n+                            LogReplicationMetadataManager metadataManager) {\n+        this.fsm = fsm;\n+        this.metadataManager = metadataManager;\n+        this.worker = worker;\n+        this.router = router;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeStateType getType() {\n+        return LogReplicationRuntimeStateType.NEGOTIATING;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeState processEvent(LogReplicationRuntimeEvent event) throws IllegalTransitionException {\n+        switch (event.getType()) {\n+            case ON_CONNECTION_DOWN:\n+                String endpointDown = event.getEndpoint();\n+                // Update list of valid connections.\n+                fsm.updateDisconnectedEndpoints(endpointDown);\n+\n+                // If the leader is the node that become unavailable, verify new leader and attempt to reconnect.\n+                if (leaderEndpoint.equals(endpointDown)) {\n+                    leaderEndpoint = Optional.empty();\n+                    return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+                } else {\n+                    // Router will attempt reconnection of non-leader endpoint\n+                    return this;\n+                }\n+            case ON_CONNECTION_UP:\n+                // Some node got connected, update connected endpoints\n+                fsm.updateConnectedEndpoints(event.getEndpoint());\n+                return this;\n+            case NEGOTIATION_COMPLETE:\n+                ((ReplicatingState)fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING)).setReplicationEvent(event.getNegotiationResult());\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.REPLICATING);\n+            case NEGOTIATION_FAILED:\n+                return this;\n+            case REMOTE_LEADER_NOT_FOUND:\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER);\n+            case ERROR:\n+                ((UnrecoverableState)fsm.getStates().get(LogReplicationRuntimeStateType.UNRECOVERABLE)).setThrowableCause(event.getT().getCause());\n+            default: {\n+                log.warn(\"Unexpected communication event {} when in init state.\", event.getType());\n+                throw new IllegalTransitionException(event.getType(), getType());\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void onEntry(LogReplicationRuntimeState from) {\n+        // Start Negotiation (check if ongoing negotiation is in progress)\n+        if(!inProgress.get()) {\n+            // Start Negotiation\n+            worker.submit(this::negotiate);\n+        }\n+    }\n+\n+    private void negotiate() {\n+        try {\n+            if(fsm.getLeader().isPresent()) {\n+                String remoteLeader = fsm.getLeader().get();\n+                CompletableFuture<LogReplicationNegotiationResponse> cf = router.sendMessageAndGetCompletable(\n+                        new CorfuMsg(CorfuMsgType.LOG_REPLICATION_NEGOTIATION_REQUEST).setEpoch(0), remoteLeader);\n+                LogReplicationNegotiationResponse response = cf.get(CorfuLogReplicationRuntime.DEFAULT_TIMEOUT, TimeUnit.MILLISECONDS);\n+\n+                // Process Negotiation Response, and determine if we start replication and which type type to start\n+                // (snapshot or log entry sync). This will be carried along the negotiation_complete event.\n+                processNegotiationResponse(response);\n+\n+                // Negotiation to leader node completed, unblock channel in the router.\n+                router.getConnectionFuture().complete(null);\n+\n+                // Negotiation completed\n+                inProgress.set(false);\n+            } else {\n+                // No leader found at the time of negotiation\n+                fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+            }\n+        } catch (LogReplicationNegotiationException ne) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", ne);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.ERROR));\n+        } catch (TimeoutException te) {\n+            log.error(\"Negotiation request timed out. Retry, until connection is marked as down or recovers.\", te);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        } catch (Exception e) {\n+            log.error(\"Unexpected exception during negotiation, retry.\", e);\n+            fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_FAILED));\n+        }\n+    }\n+\n+    /**\n+     * Set Leader Endpoint, determined during the transition from VERIFYING_REMOTE_LEADER\n+     * to NEGOTIATING state.\n+     *\n+     * @param endpoint leader node on remote cluster\n+     */\n+    public void setLeaderEndpoint(String endpoint) {\n+        this.leaderEndpoint = Optional.of(endpoint);\n+    }\n+\n+    /**\n+     * It will decide to do a full snapshot sync or log entry sync according to the metadata received from the standby site.\n+     *\n+     * @param negotiationResponse\n+     * @return\n+     * @throws LogReplicationNegotiationException\n+     */\n+    private void processNegotiationResponse(LogReplicationNegotiationResponse negotiationResponse)\n+            throws LogReplicationNegotiationException {\n+        /*\n+         * If the version are different, report an error.\n+         */\n+        if (!negotiationResponse.getVersion().equals(metadataManager.getVersion())) {\n+            log.error(\"The active site version {} is different from standby site version {}\",\n+                    metadataManager.getVersion(), negotiationResponse.getVersion());\n+            throw new LogReplicationNegotiationException(\" Mismatch of version number\");\n+        }\n+\n+        /*\n+         * The standby site has a smaller config ID, redo the discovery for this standby site when\n+         * getting a new notification of the site config change if this standby is in the new config.\n+         */\n+        if (negotiationResponse.getSiteConfigID() < negotiationResponse.getSiteConfigID()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwOTg0Nw==", "bodyText": "concat does not assign new string to s. Should be s = s.concat or use a string builder here.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r445909847", "createdAt": "2020-06-26T00:36:04Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java", "diffHunk": "@@ -236,75 +238,75 @@ public boolean setSrcBaseSnapshotStart(long siteConfigID, long ts) {\n      */\n     public void setLastSnapTransferDoneTimestamp(long siteConfigID, long ts) {\n         CorfuStoreMetadata.Timestamp timestamp = corfuStore.getTimestamp();\n-        long persisteSiteConfigID = query(timestamp, LogReplicationMetadataType.SiteConfigID);\n-        long persistSnapStart = query(timestamp, LogReplicationMetadataType.LastSnapshotStarted);\n+        long persisteSiteConfigID = query(timestamp, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        long persistSnapStart = query(timestamp, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);\n \n-        log.debug(\"setLastSnapTransferDone snapshotStart siteConfigID \" + siteConfigID + \" ts \" + ts +\n+        log.debug(\"setLastSnapTransferDone snapshotStart topologyConfigId \" + siteConfigID + \" ts \" + ts +\n                 \" persisteSiteConfigID \" + persisteSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n \n-        // It means the site config has changed, ingore the update operation.\n+        // It means the cluster config has changed, ingore the update operation.\n         if (siteConfigID != persisteSiteConfigID || ts <= persisteSiteConfigID) {\n-            log.warn(\"The metadata is older than the presisted one. Set snapshotStart siteConfigID \" + siteConfigID + \" ts \" + ts +\n+            log.warn(\"The metadata is older than the presisted one. Set snapshotStart topologyConfigId \" + siteConfigID + \" ts \" + ts +\n                     \" persisteSiteConfigID \" + persisteSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n             return;\n         }\n \n         TxBuilder txBuilder = corfuStore.tx(namespace);\n \n-        //Update the siteConfigID to fence all other transactions that update the metadata at the same time\n-        appendUpdate(txBuilder, LogReplicationMetadataType.SiteConfigID, siteConfigID);\n+        //Update the topologyConfigId to fence all other transactions that update the metadata at the same time\n+        appendUpdate(txBuilder, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, siteConfigID);\n \n-        //Setup the LastSnapshotStarted\n-        appendUpdate(txBuilder, LogReplicationMetadataType.LastSnapshotTransferred, ts);\n+        //Setup the LAST_SNAPSHOT_STARTED\n+        appendUpdate(txBuilder, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED, ts);\n \n         txBuilder.commit(timestamp);\n \n-        log.debug(\"Commit. Set snapshotStart siteConfigID \" + siteConfigID + \" ts \" + ts +\n+        log.debug(\"Commit. Set snapshotStart topologyConfigId \" + siteConfigID + \" ts \" + ts +\n                 \" persisteSiteConfigID \" + persisteSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n         return;\n     }\n \n     public void setSnapshotApplied(LogReplicationEntry entry) {\n         CorfuStoreMetadata.Timestamp timestamp = corfuStore.getTimestamp();\n-        long persistSiteConfigID = query(timestamp, LogReplicationMetadataType.SiteConfigID);\n-        long persistSnapStart = query(timestamp, LogReplicationMetadataType.LastSnapshotStarted);\n-        long persistSnapTranferDone = query(timestamp, LogReplicationMetadataType.LastSnapshotTransferred);\n-        long siteConfigID = entry.getMetadata().getSiteConfigID();\n+        long persistSiteConfigID = query(timestamp, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);\n+        long persistSnapStart = query(timestamp, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);\n+        long persistSnapTranferDone = query(timestamp, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED);\n+        long siteConfigID = entry.getMetadata().getTopologyConfigId();\n         long ts = entry.getMetadata().getSnapshotTimestamp();\n \n         if (siteConfigID != persistSiteConfigID || ts != persistSnapStart || ts != persistSnapTranferDone) {\n-            log.warn(\"siteConfigID \" + siteConfigID + \" != \" + \" persist \" + persistSiteConfigID +  \" ts \" + ts +\n+            log.warn(\"topologyConfigId \" + siteConfigID + \" != \" + \" persist \" + persistSiteConfigID +  \" ts \" + ts +\n                     \" != \" + \"persistSnapTranferDone \" + persistSnapTranferDone);\n             return;\n         }\n \n         TxBuilder txBuilder = corfuStore.tx(namespace);\n \n-        //Update the siteConfigID to fence all other transactions that update the metadata at the same time\n-        appendUpdate(txBuilder, LogReplicationMetadataType.SiteConfigID, siteConfigID);\n+        //Update the topologyConfigId to fence all other transactions that update the metadata at the same time\n+        appendUpdate(txBuilder, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, siteConfigID);\n \n-        appendUpdate(txBuilder, LogReplicationMetadataType.LastSnapshotApplied, ts);\n-        appendUpdate(txBuilder, LogReplicationMetadataType.LastLogProcessed, ts);\n+        appendUpdate(txBuilder, LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED, ts);\n+        appendUpdate(txBuilder, LogReplicationMetadataType.LAST_LOG_PROCESSED, ts);\n \n         //may not need\n-        appendUpdate(txBuilder, LogReplicationMetadataType.LastSnapshotSeqNum, Address.NON_ADDRESS);\n+        appendUpdate(txBuilder, LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM, Address.NON_ADDRESS);\n \n         txBuilder.commit(timestamp);\n \n-        log.debug(\"Commit. Set snapshotStart siteConfigID \" + siteConfigID + \" ts \" + ts +\n+        log.debug(\"Commit. Set snapshotStart topologyConfigId \" + siteConfigID + \" ts \" + ts +\n                 \" persistSiteConfigID \" + persistSiteConfigID + \" persistSnapStart \" + persistSnapStart);\n \n         return;\n     }\n \n     public String getMetadata() {\n         String s = new String();\n-        s.concat(LogReplicationMetadataType.SiteConfigID.getVal() + \" \" + getSiteConfigID() +\" \");\n-        s.concat(LogReplicationMetadataType.LastSnapshotStarted.getVal() + \" \" + getLastSnapStartTimestamp() +\" \");\n-        s.concat(LogReplicationMetadataType.LastSnapshotTransferred.getVal() + \" \" + getLastSnapTransferDoneTimestamp() + \" \");\n-        s.concat(LogReplicationMetadataType.LastSnapshotApplied.getVal() + \" \" + getLastSrcBaseSnapshotTimestamp() + \" \");\n-        s.concat(LogReplicationMetadataType.LastSnapshotSeqNum.getVal() + \" \" + getLastSnapSeqNum() + \" \");\n-        s.concat(LogReplicationMetadataType.LastLogProcessed.getVal() + \" \" + getLastProcessedLogTimestamp() + \" \");\n+        s.concat(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID.getVal() + \" \" + getSiteConfigID() +\" \");\n+        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED.getVal() + \" \" + getLastSnapStartTimestamp() +\" \");\n+        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED.getVal() + \" \" + getLastSnapTransferDoneTimestamp() + \" \");\n+        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED.getVal() + \" \" + getLastSrcBaseSnapshotTimestamp() + \" \");\n+        s.concat(LogReplicationMetadataType.LAST_SNAPSHOT_SEQ_NUM.getVal() + \" \" + getLastSnapSeqNum() + \" \");\n+        s.concat(LogReplicationMetadataType.LAST_LOG_PROCESSED.getVal() + \" \" + getLastProcessedLogTimestamp() + \" \");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225"}, "originalPosition": 291}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86a0ccb82874c15be2797e4cd344e3e15ac7df00", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/86a0ccb82874c15be2797e4cd344e3e15ac7df00", "committedDate": "2020-06-26T03:43:00Z", "message": "Model Log Replication Runtime as FSM"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0e30f73af9eff4a1315c637a3be0e5b91ba42225", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/0e30f73af9eff4a1315c637a3be0e5b91ba42225", "committedDate": "2020-06-25T20:30:38Z", "message": "Model Log Replication Runtime as FSM"}, "afterCommit": {"oid": "86a0ccb82874c15be2797e4cd344e3e15ac7df00", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/86a0ccb82874c15be2797e4cd344e3e15ac7df00", "committedDate": "2020-06-26T03:43:00Z", "message": "Model Log Replication Runtime as FSM"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f9f3d62ace54d51f481a3ab333fc5758da5215dc", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/f9f3d62ace54d51f481a3ab333fc5758da5215dc", "committedDate": "2020-06-27T00:10:54Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}, "afterCommit": {"oid": "25091f94b764d5975c2f2061dceede3e8f50af7c", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/25091f94b764d5975c2f2061dceede3e8f50af7c", "committedDate": "2020-06-27T00:20:01Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "25091f94b764d5975c2f2061dceede3e8f50af7c", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/25091f94b764d5975c2f2061dceede3e8f50af7c", "committedDate": "2020-06-27T00:20:01Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}, "afterCommit": {"oid": "ade186858c906e02f1a852b88bb0c6f1a612a92f", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/ade186858c906e02f1a852b88bb0c6f1a612a92f", "committedDate": "2020-06-27T00:28:27Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ade186858c906e02f1a852b88bb0c6f1a612a92f", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/ade186858c906e02f1a852b88bb0c6f1a612a92f", "committedDate": "2020-06-27T00:28:27Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}, "afterCommit": {"oid": "04686bdc1ebe7703b5d0ae072d27d9b86c71ea56", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/04686bdc1ebe7703b5d0ae072d27d9b86c71ea56", "committedDate": "2020-06-27T01:04:54Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "04686bdc1ebe7703b5d0ae072d27d9b86c71ea56", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/04686bdc1ebe7703b5d0ae072d27d9b86c71ea56", "committedDate": "2020-06-27T01:04:54Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}, "afterCommit": {"oid": "0fd59037c6cdd24305a5fa08055eccced2d52262", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/0fd59037c6cdd24305a5fa08055eccced2d52262", "committedDate": "2020-06-27T03:24:40Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0fd59037c6cdd24305a5fa08055eccced2d52262", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/0fd59037c6cdd24305a5fa08055eccced2d52262", "committedDate": "2020-06-27T03:24:40Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}, "afterCommit": {"oid": "70c8286c4d32870f697c83dbeb15dcc232db23c2", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/70c8286c4d32870f697c83dbeb15dcc232db23c2", "committedDate": "2020-06-27T20:04:05Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "70c8286c4d32870f697c83dbeb15dcc232db23c2", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/70c8286c4d32870f697c83dbeb15dcc232db23c2", "committedDate": "2020-06-27T20:04:05Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}, "afterCommit": {"oid": "8eef8b840a303ae39a85f69fdf65dca549458926", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/8eef8b840a303ae39a85f69fdf65dca549458926", "committedDate": "2020-06-28T06:23:00Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/b8902a422b580177262563872a54738d4b1e24b5", "committedDate": "2020-06-28T06:25:04Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8eef8b840a303ae39a85f69fdf65dca549458926", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/8eef8b840a303ae39a85f69fdf65dca549458926", "committedDate": "2020-06-28T06:23:00Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}, "afterCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/b8902a422b580177262563872a54738d4b1e24b5", "committedDate": "2020-06-28T06:25:04Z", "message": "Integrate Discovery Service to Sink Workflow\n\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\n- No Hard coded IPs/Ports\n- Moved Corfu Port info to ClusterDescriptor\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\n- MetadataManager created from DiscoveryService and sent to Source and Sink"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4ODA0NDY0", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-438804464", "createdAt": "2020-06-28T18:52:38Z", "commit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "state": "COMMENTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQxODo1MjozOFrOGp_fEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQyMDowMzo1MlrOGp_6ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4NDk0Nw==", "bodyText": "private final AtomicBoolean should be fine? All set operations are synchronized functions", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446684947", "createdAt": "2020-06-28T18:52:38Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -26,33 +29,36 @@\n  * The Log Replication Server, handles log replication entries--which\n  * represent parts of a Snapshot (full) sync or a Log Entry (delta) sync\n  * and also handles negotiation messages, which allows the Source Replicator\n- * to get a view of the last synchronized point at the remote site.\n+ * to get a view of the last synchronized point at the remote cluster.\n  */\n @Slf4j\n public class LogReplicationServer extends AbstractServer {\n \n-    private static final String configFilePath = \"/config/corfu/log_replication_config.properties\";\n-\n     private final ServerContext serverContext;\n \n     private final ExecutorService executor;\n \n+    @Getter\n+    private final LogReplicationMetadataManager metadataManager;\n+\n     @Getter\n     private final LogReplicationSinkManager sinkManager;\n \n+    private volatile AtomicBoolean isLeader = new AtomicBoolean(false);\n+\n+    private volatile AtomicBoolean isActive = new AtomicBoolean(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4NTI2OQ==", "bodyText": "Unused import", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446685269", "createdAt": "2020-06-28T18:55:45Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -4,12 +4,14 @@\n import lombok.Getter;\n import lombok.extern.slf4j.Slf4j;\n import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n-import org.corfudb.infrastructure.logreplication.receive.LogReplicationSinkManager;\n-import org.corfudb.infrastructure.logreplication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.infrastructure.TopologyDescriptor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4NTU0MA==", "bodyText": "can we use multi-threads here?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446685540", "createdAt": "2020-06-28T18:58:54Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -26,33 +29,36 @@\n  * The Log Replication Server, handles log replication entries--which\n  * represent parts of a Snapshot (full) sync or a Log Entry (delta) sync\n  * and also handles negotiation messages, which allows the Source Replicator\n- * to get a view of the last synchronized point at the remote site.\n+ * to get a view of the last synchronized point at the remote cluster.\n  */\n @Slf4j\n public class LogReplicationServer extends AbstractServer {\n \n-    private static final String configFilePath = \"/config/corfu/log_replication_config.properties\";\n-\n     private final ServerContext serverContext;\n \n     private final ExecutorService executor;\n \n+    @Getter\n+    private final LogReplicationMetadataManager metadataManager;\n+\n     @Getter\n     private final LogReplicationSinkManager sinkManager;\n \n+    private volatile AtomicBoolean isLeader = new AtomicBoolean(false);\n+\n+    private volatile AtomicBoolean isActive = new AtomicBoolean(false);\n+\n     @Getter\n     private final HandlerMethods handler = HandlerMethods.generateHandler(MethodHandles.lookup(), this);\n \n-    public LogReplicationServer(@Nonnull ServerContext context, LogReplicationConfig logReplicationConfig) {\n+    public LogReplicationServer(@Nonnull ServerContext context, @Nonnull  LogReplicationConfig logReplicationConfig,\n+                                @Nonnull  LogReplicationMetadataManager metadataManager, String corfuEndpoint) {\n         this.serverContext = context;\n+        this.metadataManager = metadataManager;\n+        this.sinkManager = new LogReplicationSinkManager(corfuEndpoint, logReplicationConfig, metadataManager, serverContext);\n+\n         this.executor = Executors.newFixedThreadPool(1,\n                 new ServerThreadFactory(\"LogReplicationServer-\", new ServerThreadFactory.ExceptionHandler()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4NTgyOQ==", "bodyText": "Log level could be trace? Since LOG_REPLICATION_ENTRY message is pretty common.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446685829", "createdAt": "2020-06-28T19:01:21Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -79,34 +85,80 @@ public void shutdown() {\n     private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {\n         log.info(\"Log Replication Entry received by Server.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4NTkxMw==", "bodyText": "Otherwise, we can use newSingleThreadExecutor", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446685913", "createdAt": "2020-06-28T19:02:21Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -26,33 +29,36 @@\n  * The Log Replication Server, handles log replication entries--which\n  * represent parts of a Snapshot (full) sync or a Log Entry (delta) sync\n  * and also handles negotiation messages, which allows the Source Replicator\n- * to get a view of the last synchronized point at the remote site.\n+ * to get a view of the last synchronized point at the remote cluster.\n  */\n @Slf4j\n public class LogReplicationServer extends AbstractServer {\n \n-    private static final String configFilePath = \"/config/corfu/log_replication_config.properties\";\n-\n     private final ServerContext serverContext;\n \n     private final ExecutorService executor;\n \n+    @Getter\n+    private final LogReplicationMetadataManager metadataManager;\n+\n     @Getter\n     private final LogReplicationSinkManager sinkManager;\n \n+    private volatile AtomicBoolean isLeader = new AtomicBoolean(false);\n+\n+    private volatile AtomicBoolean isActive = new AtomicBoolean(false);\n+\n     @Getter\n     private final HandlerMethods handler = HandlerMethods.generateHandler(MethodHandles.lookup(), this);\n \n-    public LogReplicationServer(@Nonnull ServerContext context, LogReplicationConfig logReplicationConfig) {\n+    public LogReplicationServer(@Nonnull ServerContext context, @Nonnull  LogReplicationConfig logReplicationConfig,\n+                                @Nonnull  LogReplicationMetadataManager metadataManager, String corfuEndpoint) {\n         this.serverContext = context;\n+        this.metadataManager = metadataManager;\n+        this.sinkManager = new LogReplicationSinkManager(corfuEndpoint, logReplicationConfig, metadataManager, serverContext);\n+\n         this.executor = Executors.newFixedThreadPool(1,\n                 new ServerThreadFactory(\"LogReplicationServer-\", new ServerThreadFactory.ExceptionHandler()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4NTU0MA=="}, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4NjM1Ng==", "bodyText": "Need to adjust other logs' levels too.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446686356", "createdAt": "2020-06-28T19:06:34Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -79,34 +85,80 @@ public void shutdown() {\n     private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {\n         log.info(\"Log Replication Entry received by Server.\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4NTgyOQ=="}, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4Njc3Mg==", "bodyText": "I think here is not dropping request, since it calls 'isLeader()' that sends a leader loss response.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446686772", "createdAt": "2020-06-28T19:09:54Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -79,34 +85,80 @@ public void shutdown() {\n     private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {\n         log.info(\"Log Replication Entry received by Server.\");\n \n-        LogReplicationEntry ack = sinkManager.receive(msg.getPayload());\n+        if (isLeader(msg, r)) {\n+            // Forward the received message to the Sink Manager for apply\n+            LogReplicationEntry ack = sinkManager.receive(msg.getPayload());\n \n-        if (ack != null) {\n-            long ts = ack.getMetadata().getMessageMetadataType().equals(MessageType.LOG_ENTRY_REPLICATED) ?\n-                    ack.getMetadata().getTimestamp() : ack.getMetadata().getSnapshotTimestamp();\n-            log.info(\"Sending ACK {} on {} to Client \", ack.getMetadata(), ts);\n-            r.sendResponse(ctx, msg, CorfuMsgType.LOG_REPLICATION_ENTRY.payloadMsg(ack));\n+            if (ack != null) {\n+                long ts = ack.getMetadata().getMessageMetadataType().equals(MessageType.LOG_ENTRY_REPLICATED) ?\n+                        ack.getMetadata().getTimestamp() : ack.getMetadata().getSnapshotTimestamp();\n+                log.info(\"Sending ACK {} on {} to Client \", ack.getMetadata(), ts);\n+                r.sendResponse(msg, CorfuMsgType.LOG_REPLICATION_ENTRY.payloadMsg(ack));\n+            }\n         }\n     }\n \n     @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_NEGOTIATION_REQUEST)\n     private void handleLogReplicationNegotiationRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n         log.info(\"Log Replication Negotiation Request received by Server.\");\n-        LogReplicationMetadataManager metadata = sinkManager.getLogReplicationMetadataManager();\n-        LogReplicationNegotiationResponse response = new LogReplicationNegotiationResponse(\n-                metadata.getSiteConfigID(),\n-                metadata.getVersion(),\n-                metadata.getLastSnapStartTimestamp(),\n-                metadata.getLastSnapTransferDoneTimestamp(),\n-                metadata.getLastSrcBaseSnapshotTimestamp(),\n-                metadata.getLastProcessedLogTimestamp());\n-        r.sendResponse(ctx, msg, CorfuMsgType.LOG_REPLICATION_NEGOTIATION_RESPONSE.payloadMsg(response));\n+\n+        if (isLeader(msg, r)) {\n+            LogReplicationMetadataManager metadata = sinkManager.getLogReplicationMetadataManager();\n+            LogReplicationNegotiationResponse response = new LogReplicationNegotiationResponse(\n+                    metadata.getTopologyConfigId(),\n+                    metadata.getVersion(),\n+                    metadata.getLastSnapStartTimestamp(),\n+                    metadata.getLastSnapTransferDoneTimestamp(),\n+                    metadata.getLastSrcBaseSnapshotTimestamp(),\n+                    metadata.getLastProcessedLogTimestamp());\n+            log.info(\"Send Negotiation response\");\n+            r.sendResponse(msg, CorfuMsgType.LOG_REPLICATION_NEGOTIATION_RESPONSE.payloadMsg(response));\n+        } else {\n+            log.warn(\"Dropping negotiation request as this node is not the leader.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4NzE5Mg==", "bodyText": "Are we using isLeader() to filter some msg? Currently, this function will send a leader loss response to each request if this node is not a leader. Is this expected behavior?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446687192", "createdAt": "2020-06-28T19:14:02Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -79,34 +85,80 @@ public void shutdown() {\n     private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {\n         log.info(\"Log Replication Entry received by Server.\");\n \n-        LogReplicationEntry ack = sinkManager.receive(msg.getPayload());\n+        if (isLeader(msg, r)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4OTcyMA==", "bodyText": "private", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446689720", "createdAt": "2020-06-28T19:39:52Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/ClusterDescriptor.java", "diffHunk": "@@ -0,0 +1,94 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterConfigurationMsg;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.NodeConfigurationMsg;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * This class describes a Cluster or Site in terms of its Log Replication Nodes\n+ */\n+public class ClusterDescriptor {\n+\n+    private static int CORFU_PORT = 9000;\n+\n+    @Getter\n+    String clusterId;\n+\n+    @Getter\n+    ClusterRole role;\n+\n+    @Getter\n+    List<NodeDescriptor> nodesDescriptors;\n+\n+    // Port on which Corfu DB runs on this cluster\n+    @Getter\n+    int corfuPort;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY4OTc1MA==", "bodyText": "Unused variable", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446689750", "createdAt": "2020-06-28T19:40:06Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/ClusterDescriptor.java", "diffHunk": "@@ -0,0 +1,94 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterConfigurationMsg;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.NodeConfigurationMsg;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * This class describes a Cluster or Site in terms of its Log Replication Nodes\n+ */\n+public class ClusterDescriptor {\n+\n+    private static int CORFU_PORT = 9000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5MTA5Mw==", "bodyText": "localClusterDescriptor.getNode might return null, need to check", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446691093", "createdAt": "2020-06-28T19:54:59Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,514 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connect to Cluster Manager adapter.\");\n+\n+            this.clusterManagerAdapter.connect(this);\n+\n+            log.info(\"Fetch topology from Cluster Manager...\");\n+\n+            topologyDescriptor = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+\n+            // Health check - confirm this node belongs to a cluster in the topology\n+            if (clusterPresentInTopology(topologyDescriptor)) {\n+\n+                log.info(\"Node[{}] belongs to cluster, descriptor={}\", localEndpoint,\n+                        localClusterDescriptor);\n+\n+                LogReplicationContext context = buildLogReplicationContext();\n+\n+                // Unblock server initialization retrieving context: topology + configuration\n+                discoveryCallback.complete(context);\n+\n+                registerToLogReplicationLock();\n+            } else {\n+                // If a cluster descriptor is not found, this node does not belong to any topology... raise an exception\n+                String message = String.format(\"Node[%s] does not belong to any Cluster provided by the discovery service, topology=%s\",\n+                        localEndpoint, topologyDescriptor);\n+                log.warn(message);\n+                throw new LogReplicationDiscoveryServiceException(message);\n+            }\n+        } catch (Exception e) {\n+            String message = \"Caught exception while fetching topology. Log Replication cannot start.\";\n+            log.error(message, e);\n+            throw new LogReplicationDiscoveryServiceException(message);\n+        }\n+    }\n+\n+    /**\n+     * Construct common log replication context.\n+     */\n+    private LogReplicationContext buildLogReplicationContext() {\n+        // Through LogReplicationConfigAdapter retrieve system-specific configurations (including streams to replicate)\n+        logReplicationConfig = getLogReplicationConfiguration(getCorfuRuntime());\n+\n+        logReplicationMetadataManager = new LogReplicationMetadataManager(getCorfuRuntime(),\n+                topologyDescriptor.getTopologyConfigId(), localClusterDescriptor.getClusterId());\n+\n+        logReplicationServer = new LogReplicationServer(serverContext, logReplicationConfig, logReplicationMetadataManager,\n+                localCorfuEndpoint);\n+        logReplicationServer.setActive(localClusterDescriptor.getRole().equals(ClusterRole.ACTIVE));\n+\n+        return new LogReplicationContext(logReplicationConfig, topologyDescriptor, logReplicationServer, localCorfuEndpoint);\n+    }\n+\n+    /**\n+     * Retrieve a Corfu Runtime to connect to the local Corfu Datastore.\n+     */\n+    private CorfuRuntime getCorfuRuntime() {\n+        if (runtime == null) {\n+            localCorfuEndpoint = getCorfuEndpoint(localHost, localClusterDescriptor.getCorfuPort());\n+            log.debug(\"Connecting to local Corfu {}\", localCorfuEndpoint);\n+            runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()\n+                    .trustStore((String) serverContext.getServerConfig().get(\"--truststore\"))\n+                    .tsPasswordFile((String) serverContext.getServerConfig().get(\"--truststore-password-file\"))\n+                    .keyStore((String) serverContext.getServerConfig().get(\"--keystore\"))\n+                    .ksPasswordFile((String) serverContext.getServerConfig().get(\"--keystore-password-file\"))\n+                    .tlsEnabled((Boolean) serverContext.getServerConfig().get(\"--enable-tls\"))\n+                    .build())\n+                    .parseConfigurationString(localCorfuEndpoint).connect();\n+        }\n+\n+        return runtime;\n+    }\n+\n+    /**\n+     * Verify current node belongs to a cluster in the topology.\n+     */\n+    private boolean clusterPresentInTopology(TopologyDescriptor topology) {\n+        localClusterDescriptor = topology.getClusterDescriptor(localEndpoint);\n+        if (localClusterDescriptor != null) {\n+            localNodeDescriptor = localClusterDescriptor.getNode(localEndpoint);\n+            return true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5MTQ1Ng==", "bodyText": "Need to check those variables are initialized or not to avoid NPE.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446691456", "createdAt": "2020-06-28T19:58:29Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuInterClusterReplicationServer.java", "diffHunk": "@@ -337,7 +371,7 @@ public void cleanShutdown() {\n         shutdownServer = true;\n         activeServer.close();\n         replicationDiscoveryService.shutdown();\n-        siteManagerAdapter.shutdown();\n+        clusterManagerAdapter.shutdown();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5MTk3OA==", "bodyText": "Can we have a thread name here?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446691978", "createdAt": "2020-06-28T20:03:52Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuInterClusterReplicationServer.java", "diffHunk": "@@ -299,6 +308,31 @@ private void startServer() {\n         log.info(\"main: Server exiting due to shutdown\");\n     }\n \n+    /**\n+     * Start Corfu Log Replication Discovery Service\n+     *\n+     * @param serverContext server context (server information)\n+     * @return completable future for discovered topology\n+     */\n+    private CompletableFuture<LogReplicationContext> startDiscoveryService(ServerContext serverContext) {\n+\n+        log.info(\"Start Discovery Service.\");\n+        CompletableFuture<LogReplicationContext> discoveryServiceCallback = new CompletableFuture<>();\n+\n+        this.clusterManagerAdapter = buildClusterManagerAdapter(serverContext.getPluginConfigFilePath());\n+\n+        // Start LogReplicationDiscovery Service, responsible for\n+        // acquiring lock, retrieving Site Manager Info and processing this info\n+        // so this node is initialized as Source (sender) or Sink (receiver)\n+        replicationDiscoveryService = new CorfuReplicationDiscoveryService(serverContext,\n+                clusterManagerAdapter, discoveryServiceCallback);\n+\n+        Thread replicationDiscoveryThread = new Thread(replicationDiscoveryService);\n+        replicationDiscoveryThread.start();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 276}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4ODE0NTMw", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-438814530", "createdAt": "2020-06-28T21:25:51Z", "commit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQyMToyNTo1MVrOGqAabg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQwMDo1MzoxN1rOGqBw4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwMDE0Mg==", "bodyText": "Why was this description changed? This class is an entry point for the log replication right?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446700142", "createdAt": "2020-06-28T21:25:51Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuInterClusterReplicationServer.java", "diffHunk": "@@ -42,24 +43,30 @@\n      * that each option must be preceded with a space.\n      */\n     private static final String USAGE =\n-            \"Log Replication Server, the server for the Log Replication.\\n\"\n+            \"Corfu Server, the server for the Corfu Infrastructure.\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwMTQxOQ==", "bodyText": "Where is this file located?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446701419", "createdAt": "2020-06-28T21:39:22Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/ServerContext.java", "diffHunk": "@@ -84,6 +83,9 @@\n     private static final String PREFIX_LOGUNIT = \"LOGUNIT\";\n     private static final String EPOCH_WATER_MARK = \"EPOCH_WATER_MARK\";\n \n+    // Corfu Replication Server\n+    public static final String PLUGIN_CONFIG_FILE_PATH = \"/config/corfu/corfu_plugin_config.properties\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwMjQ2NQ==", "bodyText": "I am a bit confused by this logic. Why do we need to cleanShutdown only when it comes to testing? Also, we register the shutdown hook earlier before the while loop? Will it kick in on system exit?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446702465", "createdAt": "2020-06-28T21:50:07Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuInterClusterReplicationServer.java", "diffHunk": "@@ -242,49 +272,28 @@ private void startServer() {\n         shutdownThread.setName(\"ShutdownThread\");\n         Runtime.getRuntime().addShutdownHook(shutdownThread);\n \n-        // Manages the lifecycle of the Corfu Server.\n+        // Manages the lifecycle of the Corfu Log Replication Server.\n         while (!shutdownServer) {\n-            final ServerContext serverContext = new ServerContext(opts);\n             try {\n-                String corfuPort = serverContext.getLocalEndpoint()\n-                    .equals(\"localhost:9020\") ? \":9001\" : \":9000\";\n-\n-                LogReplicationStreamNameTableManager replicationStreamNameTableManager =\n-                    new LogReplicationStreamNameTableManager(corfuPort);\n-\n-                // TODO pankti: Check if version does not match.  If if does not, create an event for site discovery to\n-                // do a snapshot sync.\n-                boolean upgraded = replicationStreamNameTableManager\n-                    .isUpgraded();\n-\n-                // Initialize the LogReplicationConfig with site ids and tables to replicate\n-                Set<String> streamsToReplicate =\n-                    replicationStreamNameTableManager.getStreamsToReplicate();\n+                CompletableFuture<LogReplicationContext> discoveryServiceCallback = startDiscoveryService(serverContext);\n \n-                LogReplicationConfig logReplicationConfig =\n-                    new LogReplicationConfig(streamsToReplicate,\n-                        UUID.randomUUID(), UUID.randomUUID());\n+                log.info(\"Wait for Discovery Service to provide a view of the topology...\");\n \n-                // Start LogReplicationDiscovery Service, responsible for\n-                // acquiring lock, retrieving Site Manager Info and processing this info\n-                // so this node is initialized as Source (sender) or Sink (receiver)\n-                activeServer = new CorfuInterClusterReplicationServerNode(serverContext, logReplicationConfig);\n+                // Block until the replication context is provided by the Discovery service\n+                LogReplicationContext context = discoveryServiceCallback.get();\n \n-                replicationDiscoveryService = new CorfuReplicationDiscoveryService(serverContext, activeServer, siteManagerAdapter);\n+                activeServer = new CorfuInterClusterReplicationServerNode(serverContext, context);\n \n-                Thread replicationDiscoveryThread = new Thread(replicationDiscoveryService);\n-                replicationDiscoveryThread.start();\n-\n-                // Start Corfu Replication Server Node\n                 activeServer.startAndListen();\n-\n-                if (upgraded) {\n-                    replicationDiscoveryService.putEvent(\n-                        new DiscoveryServiceEvent(DiscoveryServiceEvent.DiscoveryServiceEventType.Upgrade));\n-                }\n             } catch (Throwable th) {\n-                log.error(\"CorfuServer: Server exiting due to unrecoverable error: \", th);\n-                System.exit(EXIT_ERROR_CODE);\n+                if (!test) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwMjcwMA==", "bodyText": "Not  a part of this PR but restartServer is never used.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446702700", "createdAt": "2020-06-28T21:52:20Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuInterClusterReplicationServer.java", "diffHunk": "@@ -299,6 +308,31 @@ private void startServer() {\n         log.info(\"main: Server exiting due to shutdown\");\n     }\n \n+    /**\n+     * Start Corfu Log Replication Discovery Service\n+     *\n+     * @param serverContext server context (server information)\n+     * @return completable future for discovered topology\n+     */\n+    private CompletableFuture<LogReplicationContext> startDiscoveryService(ServerContext serverContext) {\n+\n+        log.info(\"Start Discovery Service.\");\n+        CompletableFuture<LogReplicationContext> discoveryServiceCallback = new CompletableFuture<>();\n+\n+        this.clusterManagerAdapter = buildClusterManagerAdapter(serverContext.getPluginConfigFilePath());\n+\n+        // Start LogReplicationDiscovery Service, responsible for\n+        // acquiring lock, retrieving Site Manager Info and processing this info\n+        // so this node is initialized as Source (sender) or Sink (receiver)\n+        replicationDiscoveryService = new CorfuReplicationDiscoveryService(serverContext,\n+                clusterManagerAdapter, discoveryServiceCallback);\n+\n+        Thread replicationDiscoveryThread = new Thread(replicationDiscoveryService);\n+        replicationDiscoveryThread.start();\n+\n+        return discoveryServiceCallback;\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 280}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwMjk3MA==", "bodyText": "It's ok for now but the reflections is not the best way to do the dependency injection. Also, this accounts only for the default non-parameterized constructor.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446702970", "createdAt": "2020-06-28T21:55:07Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuInterClusterReplicationServer.java", "diffHunk": "@@ -380,14 +414,19 @@ private static void printStartupMsg(Map<String, Object> opts) {\n             println(\"\");\n     }\n \n-    private CorfuReplicationSiteManagerAdapter constructSiteManagerAdapter() {\n+    /**\n+     * Retrieve Cluster Manager Adapter, i.e., the adapter to external provider of the topology.\n+     *\n+     * @return cluster manager adapter instance\n+     */\n+    private CorfuReplicationClusterManagerAdapter buildClusterManagerAdapter(String pluginConfigFilePath) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 303}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwMzY5NQ==", "bodyText": "I think some Javadoc, at least for interface description, would be nice to have here.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446703695", "createdAt": "2020-06-28T22:02:54Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryServiceAdapter.java", "diffHunk": "@@ -0,0 +1,23 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwNjA4NQ==", "bodyText": "Is it ok that it might return null? The fields of localNodeDescriptor are accessed throughout the class afterwards .", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446706085", "createdAt": "2020-06-28T22:28:21Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,514 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connect to Cluster Manager adapter.\");\n+\n+            this.clusterManagerAdapter.connect(this);\n+\n+            log.info(\"Fetch topology from Cluster Manager...\");\n+\n+            topologyDescriptor = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+\n+            // Health check - confirm this node belongs to a cluster in the topology\n+            if (clusterPresentInTopology(topologyDescriptor)) {\n+\n+                log.info(\"Node[{}] belongs to cluster, descriptor={}\", localEndpoint,\n+                        localClusterDescriptor);\n+\n+                LogReplicationContext context = buildLogReplicationContext();\n+\n+                // Unblock server initialization retrieving context: topology + configuration\n+                discoveryCallback.complete(context);\n+\n+                registerToLogReplicationLock();\n+            } else {\n+                // If a cluster descriptor is not found, this node does not belong to any topology... raise an exception\n+                String message = String.format(\"Node[%s] does not belong to any Cluster provided by the discovery service, topology=%s\",\n+                        localEndpoint, topologyDescriptor);\n+                log.warn(message);\n+                throw new LogReplicationDiscoveryServiceException(message);\n+            }\n+        } catch (Exception e) {\n+            String message = \"Caught exception while fetching topology. Log Replication cannot start.\";\n+            log.error(message, e);\n+            throw new LogReplicationDiscoveryServiceException(message);\n+        }\n+    }\n+\n+    /**\n+     * Construct common log replication context.\n+     */\n+    private LogReplicationContext buildLogReplicationContext() {\n+        // Through LogReplicationConfigAdapter retrieve system-specific configurations (including streams to replicate)\n+        logReplicationConfig = getLogReplicationConfiguration(getCorfuRuntime());\n+\n+        logReplicationMetadataManager = new LogReplicationMetadataManager(getCorfuRuntime(),\n+                topologyDescriptor.getTopologyConfigId(), localClusterDescriptor.getClusterId());\n+\n+        logReplicationServer = new LogReplicationServer(serverContext, logReplicationConfig, logReplicationMetadataManager,\n+                localCorfuEndpoint);\n+        logReplicationServer.setActive(localClusterDescriptor.getRole().equals(ClusterRole.ACTIVE));\n+\n+        return new LogReplicationContext(logReplicationConfig, topologyDescriptor, logReplicationServer, localCorfuEndpoint);\n+    }\n+\n+    /**\n+     * Retrieve a Corfu Runtime to connect to the local Corfu Datastore.\n+     */\n+    private CorfuRuntime getCorfuRuntime() {\n+        if (runtime == null) {\n+            localCorfuEndpoint = getCorfuEndpoint(localHost, localClusterDescriptor.getCorfuPort());\n+            log.debug(\"Connecting to local Corfu {}\", localCorfuEndpoint);\n+            runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()\n+                    .trustStore((String) serverContext.getServerConfig().get(\"--truststore\"))\n+                    .tsPasswordFile((String) serverContext.getServerConfig().get(\"--truststore-password-file\"))\n+                    .keyStore((String) serverContext.getServerConfig().get(\"--keystore\"))\n+                    .ksPasswordFile((String) serverContext.getServerConfig().get(\"--keystore-password-file\"))\n+                    .tlsEnabled((Boolean) serverContext.getServerConfig().get(\"--enable-tls\"))\n+                    .build())\n+                    .parseConfigurationString(localCorfuEndpoint).connect();\n+        }\n+\n+        return runtime;\n+    }\n+\n+    /**\n+     * Verify current node belongs to a cluster in the topology.\n+     */\n+    private boolean clusterPresentInTopology(TopologyDescriptor topology) {\n+        localClusterDescriptor = topology.getClusterDescriptor(localEndpoint);\n+        if (localClusterDescriptor != null) {\n+            localNodeDescriptor = localClusterDescriptor.getNode(localEndpoint);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwODc2NA==", "bodyText": "If the cluster is not present in the topology does it require any retry logic on our side?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446708764", "createdAt": "2020-06-28T22:56:06Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,514 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connect to Cluster Manager adapter.\");\n+\n+            this.clusterManagerAdapter.connect(this);\n+\n+            log.info(\"Fetch topology from Cluster Manager...\");\n+\n+            topologyDescriptor = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+\n+            // Health check - confirm this node belongs to a cluster in the topology\n+            if (clusterPresentInTopology(topologyDescriptor)) {\n+\n+                log.info(\"Node[{}] belongs to cluster, descriptor={}\", localEndpoint,\n+                        localClusterDescriptor);\n+\n+                LogReplicationContext context = buildLogReplicationContext();\n+\n+                // Unblock server initialization retrieving context: topology + configuration\n+                discoveryCallback.complete(context);\n+\n+                registerToLogReplicationLock();\n+            } else {\n+                // If a cluster descriptor is not found, this node does not belong to any topology... raise an exception\n+                String message = String.format(\"Node[%s] does not belong to any Cluster provided by the discovery service, topology=%s\",\n+                        localEndpoint, topologyDescriptor);\n+                log.warn(message);\n+                throw new LogReplicationDiscoveryServiceException(message);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxNzI3OQ==", "bodyText": "Not used", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446717279", "createdAt": "2020-06-29T00:16:21Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,514 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connect to Cluster Manager adapter.\");\n+\n+            this.clusterManagerAdapter.connect(this);\n+\n+            log.info(\"Fetch topology from Cluster Manager...\");\n+\n+            topologyDescriptor = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+\n+            // Health check - confirm this node belongs to a cluster in the topology\n+            if (clusterPresentInTopology(topologyDescriptor)) {\n+\n+                log.info(\"Node[{}] belongs to cluster, descriptor={}\", localEndpoint,\n+                        localClusterDescriptor);\n+\n+                LogReplicationContext context = buildLogReplicationContext();\n+\n+                // Unblock server initialization retrieving context: topology + configuration\n+                discoveryCallback.complete(context);\n+\n+                registerToLogReplicationLock();\n+            } else {\n+                // If a cluster descriptor is not found, this node does not belong to any topology... raise an exception\n+                String message = String.format(\"Node[%s] does not belong to any Cluster provided by the discovery service, topology=%s\",\n+                        localEndpoint, topologyDescriptor);\n+                log.warn(message);\n+                throw new LogReplicationDiscoveryServiceException(message);\n+            }\n+        } catch (Exception e) {\n+            String message = \"Caught exception while fetching topology. Log Replication cannot start.\";\n+            log.error(message, e);\n+            throw new LogReplicationDiscoveryServiceException(message);\n+        }\n+    }\n+\n+    /**\n+     * Construct common log replication context.\n+     */\n+    private LogReplicationContext buildLogReplicationContext() {\n+        // Through LogReplicationConfigAdapter retrieve system-specific configurations (including streams to replicate)\n+        logReplicationConfig = getLogReplicationConfiguration(getCorfuRuntime());\n+\n+        logReplicationMetadataManager = new LogReplicationMetadataManager(getCorfuRuntime(),\n+                topologyDescriptor.getTopologyConfigId(), localClusterDescriptor.getClusterId());\n+\n+        logReplicationServer = new LogReplicationServer(serverContext, logReplicationConfig, logReplicationMetadataManager,\n+                localCorfuEndpoint);\n+        logReplicationServer.setActive(localClusterDescriptor.getRole().equals(ClusterRole.ACTIVE));\n+\n+        return new LogReplicationContext(logReplicationConfig, topologyDescriptor, logReplicationServer, localCorfuEndpoint);\n+    }\n+\n+    /**\n+     * Retrieve a Corfu Runtime to connect to the local Corfu Datastore.\n+     */\n+    private CorfuRuntime getCorfuRuntime() {\n+        if (runtime == null) {\n+            localCorfuEndpoint = getCorfuEndpoint(localHost, localClusterDescriptor.getCorfuPort());\n+            log.debug(\"Connecting to local Corfu {}\", localCorfuEndpoint);\n+            runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()\n+                    .trustStore((String) serverContext.getServerConfig().get(\"--truststore\"))\n+                    .tsPasswordFile((String) serverContext.getServerConfig().get(\"--truststore-password-file\"))\n+                    .keyStore((String) serverContext.getServerConfig().get(\"--keystore\"))\n+                    .ksPasswordFile((String) serverContext.getServerConfig().get(\"--keystore-password-file\"))\n+                    .tlsEnabled((Boolean) serverContext.getServerConfig().get(\"--enable-tls\"))\n+                    .build())\n+                    .parseConfigurationString(localCorfuEndpoint).connect();\n+        }\n+\n+        return runtime;\n+    }\n+\n+    /**\n+     * Verify current node belongs to a cluster in the topology.\n+     */\n+    private boolean clusterPresentInTopology(TopologyDescriptor topology) {\n+        localClusterDescriptor = topology.getClusterDescriptor(localEndpoint);\n+        if (localClusterDescriptor != null) {\n+            localNodeDescriptor = localClusterDescriptor.getNode(localEndpoint);\n+            return true;\n+        }\n+\n+        return false;\n+    }\n+\n+    /**\n+     * Retrieve local Corfu Endpoint\n+     */\n+    private String getCorfuEndpoint(String localEndpoint, int corfuPort) {\n+        return NodeLocator.parseString(localEndpoint).getHost() + \":\" + corfuPort;\n+    }\n+\n+    /**\n+     * Retrieve Log Replication Configuration.\n+     *\n+     * This configuration represents all common parameters for the log replication, regardless of\n+     * a cluster's role.\n+     */\n+    private LogReplicationConfig getLogReplicationConfiguration(CorfuRuntime runtime) {\n+\n+        LogReplicationStreamNameTableManager replicationStreamNameTableManager =\n+                new LogReplicationStreamNameTableManager(runtime, pluginFilePath);\n+\n+        Set<String> streamsToReplicate = replicationStreamNameTableManager.getStreamsToReplicate();\n+\n+        // TODO pankti: Check if version does not match.  If if does not, create an event for site discovery to\n+        //  do a snapshot sync.\n+        // TODO(Gabriela): pending review upgrade path (changes)\n+        boolean upgraded = replicationStreamNameTableManager\n+                .isUpgraded();\n+\n+        if (upgraded) {\n+            input(new DiscoveryServiceEvent(DiscoveryServiceEvent.DiscoveryServiceEventType.UPGRADE));\n+        }\n+\n+        return new LogReplicationConfig(streamsToReplicate);\n+    }\n+\n+    /**\n+     * Register interest on Log Replication Lock.\n+     *\n+     * The node that acquires the lock will drive/lead log replication.\n+     */\n+    private void registerToLogReplicationLock() {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    LockClient lock = new LockClient(nodeId, getCorfuRuntime());\n+                    // Callback on lock acquisition or revoke\n+                    LockListener logReplicationLockListener = new LogReplicationLockListener(this);\n+                    // Register Interest on the shared Log Replication Lock\n+                    lock.registerInterest(LOCK_GROUP, LOCK_NAME, logReplicationLockListener);\n+                } catch (Exception e) {\n+                    log.error(\"Error while attempting to register interest on log replication lock {}:{}\", LOCK_GROUP, LOCK_NAME, e);\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to register interest on log replication lock.\", e);\n+            throw new UnrecoverableCorfuError(e);\n+        }\n+    }\n+\n+    /**\n+     * This method is only called on the leader node and it triggers the start of log replication\n+     *\n+     * Depending on the role of the cluster to which this leader node belongs to, it will start\n+     * as source (sender/producer) or sink (receiver).\n+     */\n+    private void startLogReplication() {\n+        if (!localNodeDescriptor.isLeader()) {\n+            log.warn(\"Current node {} is not the lead node, log replication cannot be started.\", localEndpoint);\n+            return;\n+        }\n+\n+        boolean activeCluster = localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE;\n+\n+        if (activeCluster) {\n+            log.info(\"Start as Source (sender/replicator) on node {}.\", localNodeDescriptor);\n+            // TODO(Gabriela): only one instance of CorfuReplicationManager\n+            replicationManager = new CorfuReplicationManager(topologyDescriptor, logReplicationConfig,\n+                    localNodeDescriptor, logReplicationMetadataManager, pluginFilePath, getCorfuRuntime());\n+            replicationManager.start();\n+        } else if (localNodeDescriptor.getRoleType() == ClusterRole.STANDBY) {\n+            // Standby Site : the LogReplicationServer (server handler) will initiate the LogReplicationSinkManager\n+            log.info(\"Start as Sink (receiver) on node {} \", localNodeDescriptor);\n+        } else {\n+            log.error(\"Log Replication not started on this cluster. Leader node {} belongs to cluster with {} role.\",\n+                    localEndpoint, localNodeDescriptor.getRoleType());\n+        }\n+    }\n+\n+    private void updateTopologyConfigId(boolean active) {\n+        // Required only on topology changes\n+        logReplicationServer.getSinkManager().updateTopologyConfigId(active, topologyDescriptor.getTopologyConfigId());\n+\n+        log.debug(\"Persist new topologyConfigId {}, status={}\", topologyDescriptor.getTopologyConfigId(),\n+                localNodeDescriptor.getRoleType());\n+    }\n+\n+    /**\n+     * Stop ongoing Log Replication\n+     */\n+    private void stopLogReplication() {\n+        if (localNodeDescriptor.isLeader() && localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE) {\n+            replicationManager.stop();\n+        }\n+    }\n+\n+    /**\n+     * Process lock acquisition event\n+     */\n+    public void processLockAcquire() {\n+        log.info(\"Process lock acquire event\");\n+\n+        logReplicationServer.setLeadership(true);\n+\n+        // TODO(Gabriela): confirm that start does not affect ongoing replication if it is called again..\n+        if (!localNodeDescriptor.isLeader()) {\n+            // leader transition from false to true, start log replication.\n+            localNodeDescriptor.setLeader(true);\n+            startLogReplication();\n+        }\n+    }\n+\n+    /**\n+     * Process lock release event\n+     *\n+     * Set leadership metadata and stop log replication in the event of leadership loss\n+     */\n+    public void processLockRelease() {\n+        logReplicationServer.setLeadership(false);\n+\n+        if (localNodeDescriptor.isLeader()) {\n+            stopLogReplication();\n+            localNodeDescriptor.setLeader(false);\n+        }\n+    }\n+\n+\n+    public void processSiteFlip(TopologyDescriptor newConfig) {\n+        // TODO(Nan): Check standby to active and active to standby...\n+        stopLogReplication();\n+        //TODO pankti: read the configuration again and refresh the LogReplicationConfig object\n+        replicationManager.setTopologyDescriptor(newConfig);\n+        boolean activeCluster = localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE;\n+        updateTopologyConfigId(activeCluster);\n+        startLogReplication();\n+    }\n+\n+    public void processSiteChangeNotification(DiscoveryServiceEvent event) {\n+        // Stale notification, skip\n+        if (event.getTopologyConfig().getTopologyConfigID() < getReplicationManager().getTopologyDescriptor().getTopologyConfigId()) {\n+            log.debug(\"Stale Topology Change Notification, current={}, received={}\", topologyDescriptor.getTopologyConfigId(), event.getTopologyConfig());\n+            return;\n+        }\n+\n+        TopologyDescriptor newConfig = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+        if (newConfig.getTopologyConfigId() == getReplicationManager().getTopologyDescriptor().getTopologyConfigId()) {\n+            if (localNodeDescriptor.getRoleType() == ClusterRole.STANDBY) {\n+                return;\n+            }\n+\n+            // If the current node is active, compare with the current siteConfig, see if there are addition/removal standbys\n+            getReplicationManager().processStandbyChange(newConfig);\n+        } else {\n+            processSiteFlip(newConfig);\n+        }\n+    }\n+\n+    /***\n+     * The standby cluster's leader change can lead to connection loss.\n+     * If the current node is not the active cluster's leader, discard the notification.\n+     * If the current node is the the active cluster's leader that is is responsible for the current\n+     * replication job, will restart the replication with the remote cluster.\n+     *\n+     * @param event\n+     */\n+    private void processConnectionLoss(DiscoveryServiceEvent event) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 431}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxOTA0Nw==", "bodyText": "Do we assume here that this call will always succeed?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446719047", "createdAt": "2020-06-29T00:30:15Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,514 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connect to Cluster Manager adapter.\");\n+\n+            this.clusterManagerAdapter.connect(this);\n+\n+            log.info(\"Fetch topology from Cluster Manager...\");\n+\n+            topologyDescriptor = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+\n+            // Health check - confirm this node belongs to a cluster in the topology\n+            if (clusterPresentInTopology(topologyDescriptor)) {\n+\n+                log.info(\"Node[{}] belongs to cluster, descriptor={}\", localEndpoint,\n+                        localClusterDescriptor);\n+\n+                LogReplicationContext context = buildLogReplicationContext();\n+\n+                // Unblock server initialization retrieving context: topology + configuration\n+                discoveryCallback.complete(context);\n+\n+                registerToLogReplicationLock();\n+            } else {\n+                // If a cluster descriptor is not found, this node does not belong to any topology... raise an exception\n+                String message = String.format(\"Node[%s] does not belong to any Cluster provided by the discovery service, topology=%s\",\n+                        localEndpoint, topologyDescriptor);\n+                log.warn(message);\n+                throw new LogReplicationDiscoveryServiceException(message);\n+            }\n+        } catch (Exception e) {\n+            String message = \"Caught exception while fetching topology. Log Replication cannot start.\";\n+            log.error(message, e);\n+            throw new LogReplicationDiscoveryServiceException(message);\n+        }\n+    }\n+\n+    /**\n+     * Construct common log replication context.\n+     */\n+    private LogReplicationContext buildLogReplicationContext() {\n+        // Through LogReplicationConfigAdapter retrieve system-specific configurations (including streams to replicate)\n+        logReplicationConfig = getLogReplicationConfiguration(getCorfuRuntime());\n+\n+        logReplicationMetadataManager = new LogReplicationMetadataManager(getCorfuRuntime(),\n+                topologyDescriptor.getTopologyConfigId(), localClusterDescriptor.getClusterId());\n+\n+        logReplicationServer = new LogReplicationServer(serverContext, logReplicationConfig, logReplicationMetadataManager,\n+                localCorfuEndpoint);\n+        logReplicationServer.setActive(localClusterDescriptor.getRole().equals(ClusterRole.ACTIVE));\n+\n+        return new LogReplicationContext(logReplicationConfig, topologyDescriptor, logReplicationServer, localCorfuEndpoint);\n+    }\n+\n+    /**\n+     * Retrieve a Corfu Runtime to connect to the local Corfu Datastore.\n+     */\n+    private CorfuRuntime getCorfuRuntime() {\n+        if (runtime == null) {\n+            localCorfuEndpoint = getCorfuEndpoint(localHost, localClusterDescriptor.getCorfuPort());\n+            log.debug(\"Connecting to local Corfu {}\", localCorfuEndpoint);\n+            runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()\n+                    .trustStore((String) serverContext.getServerConfig().get(\"--truststore\"))\n+                    .tsPasswordFile((String) serverContext.getServerConfig().get(\"--truststore-password-file\"))\n+                    .keyStore((String) serverContext.getServerConfig().get(\"--keystore\"))\n+                    .ksPasswordFile((String) serverContext.getServerConfig().get(\"--keystore-password-file\"))\n+                    .tlsEnabled((Boolean) serverContext.getServerConfig().get(\"--enable-tls\"))\n+                    .build())\n+                    .parseConfigurationString(localCorfuEndpoint).connect();\n+        }\n+\n+        return runtime;\n+    }\n+\n+    /**\n+     * Verify current node belongs to a cluster in the topology.\n+     */\n+    private boolean clusterPresentInTopology(TopologyDescriptor topology) {\n+        localClusterDescriptor = topology.getClusterDescriptor(localEndpoint);\n+        if (localClusterDescriptor != null) {\n+            localNodeDescriptor = localClusterDescriptor.getNode(localEndpoint);\n+            return true;\n+        }\n+\n+        return false;\n+    }\n+\n+    /**\n+     * Retrieve local Corfu Endpoint\n+     */\n+    private String getCorfuEndpoint(String localEndpoint, int corfuPort) {\n+        return NodeLocator.parseString(localEndpoint).getHost() + \":\" + corfuPort;\n+    }\n+\n+    /**\n+     * Retrieve Log Replication Configuration.\n+     *\n+     * This configuration represents all common parameters for the log replication, regardless of\n+     * a cluster's role.\n+     */\n+    private LogReplicationConfig getLogReplicationConfiguration(CorfuRuntime runtime) {\n+\n+        LogReplicationStreamNameTableManager replicationStreamNameTableManager =\n+                new LogReplicationStreamNameTableManager(runtime, pluginFilePath);\n+\n+        Set<String> streamsToReplicate = replicationStreamNameTableManager.getStreamsToReplicate();\n+\n+        // TODO pankti: Check if version does not match.  If if does not, create an event for site discovery to\n+        //  do a snapshot sync.\n+        // TODO(Gabriela): pending review upgrade path (changes)\n+        boolean upgraded = replicationStreamNameTableManager\n+                .isUpgraded();\n+\n+        if (upgraded) {\n+            input(new DiscoveryServiceEvent(DiscoveryServiceEvent.DiscoveryServiceEventType.UPGRADE));\n+        }\n+\n+        return new LogReplicationConfig(streamsToReplicate);\n+    }\n+\n+    /**\n+     * Register interest on Log Replication Lock.\n+     *\n+     * The node that acquires the lock will drive/lead log replication.\n+     */\n+    private void registerToLogReplicationLock() {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    LockClient lock = new LockClient(nodeId, getCorfuRuntime());\n+                    // Callback on lock acquisition or revoke\n+                    LockListener logReplicationLockListener = new LogReplicationLockListener(this);\n+                    // Register Interest on the shared Log Replication Lock\n+                    lock.registerInterest(LOCK_GROUP, LOCK_NAME, logReplicationLockListener);\n+                } catch (Exception e) {\n+                    log.error(\"Error while attempting to register interest on log replication lock {}:{}\", LOCK_GROUP, LOCK_NAME, e);\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to register interest on log replication lock.\", e);\n+            throw new UnrecoverableCorfuError(e);\n+        }\n+    }\n+\n+    /**\n+     * This method is only called on the leader node and it triggers the start of log replication\n+     *\n+     * Depending on the role of the cluster to which this leader node belongs to, it will start\n+     * as source (sender/producer) or sink (receiver).\n+     */\n+    private void startLogReplication() {\n+        if (!localNodeDescriptor.isLeader()) {\n+            log.warn(\"Current node {} is not the lead node, log replication cannot be started.\", localEndpoint);\n+            return;\n+        }\n+\n+        boolean activeCluster = localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE;\n+\n+        if (activeCluster) {\n+            log.info(\"Start as Source (sender/replicator) on node {}.\", localNodeDescriptor);\n+            // TODO(Gabriela): only one instance of CorfuReplicationManager\n+            replicationManager = new CorfuReplicationManager(topologyDescriptor, logReplicationConfig,\n+                    localNodeDescriptor, logReplicationMetadataManager, pluginFilePath, getCorfuRuntime());\n+            replicationManager.start();\n+        } else if (localNodeDescriptor.getRoleType() == ClusterRole.STANDBY) {\n+            // Standby Site : the LogReplicationServer (server handler) will initiate the LogReplicationSinkManager\n+            log.info(\"Start as Sink (receiver) on node {} \", localNodeDescriptor);\n+        } else {\n+            log.error(\"Log Replication not started on this cluster. Leader node {} belongs to cluster with {} role.\",\n+                    localEndpoint, localNodeDescriptor.getRoleType());\n+        }\n+    }\n+\n+    private void updateTopologyConfigId(boolean active) {\n+        // Required only on topology changes\n+        logReplicationServer.getSinkManager().updateTopologyConfigId(active, topologyDescriptor.getTopologyConfigId());\n+\n+        log.debug(\"Persist new topologyConfigId {}, status={}\", topologyDescriptor.getTopologyConfigId(),\n+                localNodeDescriptor.getRoleType());\n+    }\n+\n+    /**\n+     * Stop ongoing Log Replication\n+     */\n+    private void stopLogReplication() {\n+        if (localNodeDescriptor.isLeader() && localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE) {\n+            replicationManager.stop();\n+        }\n+    }\n+\n+    /**\n+     * Process lock acquisition event\n+     */\n+    public void processLockAcquire() {\n+        log.info(\"Process lock acquire event\");\n+\n+        logReplicationServer.setLeadership(true);\n+\n+        // TODO(Gabriela): confirm that start does not affect ongoing replication if it is called again..\n+        if (!localNodeDescriptor.isLeader()) {\n+            // leader transition from false to true, start log replication.\n+            localNodeDescriptor.setLeader(true);\n+            startLogReplication();\n+        }\n+    }\n+\n+    /**\n+     * Process lock release event\n+     *\n+     * Set leadership metadata and stop log replication in the event of leadership loss\n+     */\n+    public void processLockRelease() {\n+        logReplicationServer.setLeadership(false);\n+\n+        if (localNodeDescriptor.isLeader()) {\n+            stopLogReplication();\n+            localNodeDescriptor.setLeader(false);\n+        }\n+    }\n+\n+\n+    public void processSiteFlip(TopologyDescriptor newConfig) {\n+        // TODO(Nan): Check standby to active and active to standby...\n+        stopLogReplication();\n+        //TODO pankti: read the configuration again and refresh the LogReplicationConfig object\n+        replicationManager.setTopologyDescriptor(newConfig);\n+        boolean activeCluster = localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE;\n+        updateTopologyConfigId(activeCluster);\n+        startLogReplication();\n+    }\n+\n+    public void processSiteChangeNotification(DiscoveryServiceEvent event) {\n+        // Stale notification, skip\n+        if (event.getTopologyConfig().getTopologyConfigID() < getReplicationManager().getTopologyDescriptor().getTopologyConfigId()) {\n+            log.debug(\"Stale Topology Change Notification, current={}, received={}\", topologyDescriptor.getTopologyConfigId(), event.getTopologyConfig());\n+            return;\n+        }\n+\n+        TopologyDescriptor newConfig = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcyMjI3NA==", "bodyText": "I am wondering if it works as expected.\nLet's say currentStandbys.keySet() = [2, 3, 4] and newStandbys.keySet() = [1, 2, 3]. So 1 got added and 4 got removed. We do retainAll on newStandbys on line 207, this will make it newStandbys.keySet() = [2, 3] and 1 (a new standby that is not in the current config and is only in the new config) will be left out?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r446722274", "createdAt": "2020-06-29T00:53:17Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -0,0 +1,301 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+/**\n+ * This class manages Log Replication for multiple remote (standby) cluster's.\n+ */\n+@Slf4j\n+public class CorfuReplicationManager {\n+\n+    public final static int PERCENTAGE_BASE = 100;\n+\n+    // Keep map of remote cluster ID and the associated log replication runtime (an abstract\n+    // client to that cluster)\n+    private Map<String, CorfuLogReplicationRuntime> runtimeToRemoteCluster = new HashMap<>();\n+\n+    @Setter\n+    @Getter\n+    private volatile TopologyDescriptor topologyDescriptor;\n+\n+    private final LogReplicationConfig logReplicationConfig;\n+\n+    private final NodeDescriptor localNodeDescriptor;\n+\n+    private final CorfuRuntime corfuRuntime;\n+\n+    // TODO (Xiaoqin Ma): can you please add a description on this variable's meaning\n+    private long prepareSiteRoleChangeStreamTail;\n+\n+    private long totalNumEntriesToSend;\n+\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    private final String pluginFilePath;\n+\n+    /**\n+     * Constructor\n+     *\n+     * @param topologyDescriptor description of active and standby cluster' of a given topology\n+     * @param logReplicationConfig log replication configuration\n+     */\n+    public CorfuReplicationManager(TopologyDescriptor topologyDescriptor,\n+                            LogReplicationConfig logReplicationConfig,\n+                            NodeDescriptor localNodeDescriptor,\n+                            LogReplicationMetadataManager metadataManager,\n+                            String pluginFilePath, CorfuRuntime corfuRuntime) {\n+        this.topologyDescriptor = topologyDescriptor;\n+        this.logReplicationConfig = logReplicationConfig;\n+        this.metadataManager = metadataManager;\n+        this.pluginFilePath = pluginFilePath;\n+        this.corfuRuntime = corfuRuntime;\n+\n+        this.localNodeDescriptor = localNodeDescriptor;\n+        this.prepareSiteRoleChangeStreamTail = Address.NON_ADDRESS;\n+        this.totalNumEntriesToSend = 0;\n+    }\n+\n+    /**\n+     * Start Log Replication Manager, this will initiate a runtime against\n+     * each standby cluster, to further start log replication.\n+     */\n+    public void start() {\n+        for (ClusterDescriptor remoteCluster : topologyDescriptor.getStandbyClusters().values()) {\n+            try {\n+                startLogReplicationRuntime(remoteCluster);\n+            } catch (Exception e) {\n+                log.error(\"Failed to start log replication runtime for remote cluster {}\", remoteCluster.getClusterId());\n+\n+                // Remove cluster from the list of standby's, as the cluster discovery process will receive\n+                // change notification when this site becomes stable/available again.\n+                topologyDescriptor.getStandbyClusters().remove(remoteCluster.getClusterId());\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Stop log replication for all the standby sites\n+     */\n+    public void stop() {\n+        for(String clusterId : topologyDescriptor.getStandbyClusters().keySet()) {\n+            stopLogReplicationRuntime(clusterId);\n+        }\n+    }\n+\n+    /**\n+     * Restart connection to remote cluster\n+     */\n+    public void restart(ClusterDescriptor remoteCluster) {\n+        stopLogReplicationRuntime(remoteCluster.getClusterId());\n+        startLogReplicationRuntime(remoteCluster);\n+    }\n+\n+    /**\n+     * Start Log Replication Runtime to a specific standby Cluster\n+     */\n+    private void startLogReplicationRuntime(ClusterDescriptor remoteClusterDescriptor) {\n+\n+        String remoteClusterId = remoteClusterDescriptor.getClusterId();\n+\n+        try {\n+            if (!runtimeToRemoteCluster.containsKey(remoteClusterId)) {\n+                log.info(\"Starting Log Replication Runtime to Standby Cluster id={}\", remoteClusterId);\n+                connect(remoteClusterDescriptor);\n+            } else {\n+                log.warn(\"Log Replication Runtime to remote cluster {}, already exists. Skipping init.\", remoteClusterId);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Caught exception, stop log replication runtime to {}\", remoteClusterDescriptor, e);\n+            stopLogReplicationRuntime(remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * Connect to a remote Log Replicator, through a Log Replication Runtime.\n+     *\n+     * @throws InterruptedException\n+     */\n+    private void connect(ClusterDescriptor remoteCluster) throws InterruptedException {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    // TODO(Gabriela) : It's cleaner to make LogReplicationConfig agnostic of cluster information (shared across\n+                    //  all clusters) so it would be better to push down the remote cluster id or info as a separate object\n+                    //  this requires to change signatures down the pipe. TBD.\n+                    String localCorfuEndpoint = localNodeDescriptor.getIpAddress() + \":\" + topologyDescriptor.getActiveCluster().getCorfuPort();\n+\n+                    LogReplicationRuntimeParameters parameters = LogReplicationRuntimeParameters.builder()\n+                            .localCorfuEndpoint(localCorfuEndpoint)\n+                            .remoteClusterDescriptor(remoteCluster)\n+                            .localClusterId(localNodeDescriptor.getClusterId())\n+                            .replicationConfig(new LogReplicationConfig(logReplicationConfig.getStreamsToReplicate(),\n+                                    localNodeDescriptor.getClusterId(), remoteCluster.clusterId))\n+                            .pluginFilePath(pluginFilePath)\n+                            .topologyConfigId(topologyDescriptor.getTopologyConfigId())\n+                            .keyStore(corfuRuntime.getParameters().getKeyStore())\n+                            .tlsEnabled(corfuRuntime.getParameters().isTlsEnabled())\n+                            .ksPasswordFile(corfuRuntime.getParameters().getKsPasswordFile())\n+                            .trustStore(corfuRuntime.getParameters().getTrustStore())\n+                            .tsPasswordFile(corfuRuntime.getParameters().getTsPasswordFile())\n+                            .build();\n+                    CorfuLogReplicationRuntime replicationRuntime = new CorfuLogReplicationRuntime(parameters, metadataManager);\n+                    replicationRuntime.start();\n+                    runtimeToRemoteCluster.put(remoteCluster.getClusterId(), replicationRuntime);\n+                } catch (Exception e) {\n+                    log.error(\"Exception {}. Failed to connect to remote cluster {}. Retry after 1 second.\",\n+                            e, remoteCluster.getClusterId());\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to connect to remote cluster.\", e);\n+            throw e;\n+        }\n+    }\n+\n+    /**\n+     * Stop Log Replication to a specific standby Cluster\n+     */\n+    private void stopLogReplicationRuntime(String remoteClusterId) {\n+        CorfuLogReplicationRuntime logReplicationRuntime = runtimeToRemoteCluster.get(remoteClusterId);\n+        if (logReplicationRuntime != null) {\n+            log.info(\"Stop log replication runtime to remote cluster id={}\", remoteClusterId);\n+            logReplicationRuntime.stop();\n+            runtimeToRemoteCluster.remove(remoteClusterId);\n+        } else {\n+            log.warn(\"Runtime not found to remote cluster {}\", remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * The notification of change of adding/removing standby's without epoch change.\n+     *\n+     * @param newConfig has the same topologyConfigId as the current config\n+     */\n+    public void processStandbyChange(TopologyDescriptor newConfig) {\n+        if (newConfig.getTopologyConfigId() != topologyDescriptor.getTopologyConfigId()) {\n+            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+                    \"siteConfigId as the current one {}\", newConfig, topologyDescriptor);\n+            return;\n+        }\n+\n+        Map<String, ClusterDescriptor> newStandbys = newConfig.getStandbyClusters();\n+        Map<String, ClusterDescriptor> currentStandbys = topologyDescriptor.getStandbyClusters();\n+        newStandbys.keySet().retainAll(currentStandbys.keySet());\n+        Set<String> standbysToRemove = currentStandbys.keySet();\n+        standbysToRemove.removeAll(newStandbys.keySet());\n+\n+        /*\n+         * Remove standbys that are not in the new config\n+         */\n+        for (String siteID : standbysToRemove) {\n+            stopLogReplicationRuntime(siteID);\n+            topologyDescriptor.removeStandbySite(siteID);\n+        }\n+\n+        //Start the standbys that are in the new config but not in the current config\n+        for (String clusterId : newConfig.getStandbyClusters().keySet()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 215}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NDAyNDI1", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-439402425", "createdAt": "2020-06-29T18:36:21Z", "commit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQxODozNjoyMVrOGqdT6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQxODozNjoyMVrOGqdT6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE3MzYwOQ==", "bodyText": "There is a possible starving case that there are two standbys, standby1 call consume, but standby1's eventQueue is  empty, so the thread is blocking here even though standby2's eventQue is not empty.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447173609", "createdAt": "2020-06-29T18:36:21Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java", "diffHunk": "@@ -0,0 +1,295 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeStateType;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.StoppedState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.UnrecoverableState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.WaitingForConnectionsState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.IllegalTransitionException;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.NegotiatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.ReplicatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.VerifyingRemoteLeaderState;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * Runtime to connect to a remote Corfu Log Replication Cluster.\n+ *\n+ * This class represents the Log Replication Runtime Finite State Machine, which defines\n+ * all states in which the leader node on the active cluster can be.\n+ *\n+ *\n+ *                                                       R-LEADER_LOSS\n+ *                                             +-------------------------------+\n+ *                              ON_CONNECTION  |                               |    ON_CONNECTION_DOWN\n+ *                                    UP       |       ON_CONNECTION_DOWN      |       (NON_LEADER)\n+ *                                    +----+   |          (R-LEADER)           |\n+ *                                    |    |   |   +-----------------------+   |        +-----+\n+ *                                    |    |   |   |                       |   |        |     |\n+ * +---------------+  ON_CONNECTION  ++----v---v---v--+                  +-+---+--------+-+   |\n+ * |               |       UP        |                |  R-LEADER_FOUND  |                <---+\n+ * |    WAITING    +---------------->+    VERIFYING   +------------------>                +---+\n+ * |      FOR      |                 |     REMOTE     |                  |   NEGOTIATING  |   |  NEGOTIATION_FAILED\n+ * |  CONNECTIONS  +<----------------+     LEADER     |                  |                <---+       (ALARM)\n+ * |               |  ON_CONNECTION  |                +<-----------+     |                +----+\n+ * +---------------+      DOWN       +-^----+---^----++            |     +-------+-----^--+    |\n+ *                       (ALL)         |    |   |    |             |             |     |       |\n+ *                                     |    |   |    |        R-LEADER_LOSS      |     +-------+\n+ *                                     +----+   +----+             |             |  ON_CONNECTION_UP\n+ *                              ON_CONNECTION     R-LEADER_NOT     |             |    (NON-LEADER)\n+ *                                  DOWN              FOUND        |             |\n+ *                                (NOT ALL)                        |     NEGOTIATE_COMPLETE\n+ *                                                                 |             |\n+ *                                                           ON_CONNECTION       |   ON_CONNECTION_UP\n+ *                                                               DOWN            |     (NON-LEADER)\n+ *                                                             (R-LEADER)        |      +-----+\n+ *                                                                 |             |      |     |\n+ *                                                                 |     +-------v------+-+   |\n+ *            +---------------+      ALL STATES                    +-----+                <---+\n+ *            |               |                                          |                |\n+ *            |   STOPPED     <---- L-LEADER_LOSS                        |  REPLICATING   |\n+ *            |               |                     SITE FLIP <-----     |                |\n+ *            |               |                                          |                +----+\n+ *            +---------------+                                          +--------------^-+    |\n+ *                                                                                      |      |\n+ *                                                                                      +------+\n+ *            +---------------+     ALL STATES\n+ *            |               |                                                     ON_CONNECTION_DOWN\n+ *            | UNRECOVERABLE <---- ON_ERROR                                           (NON-LEADER)\n+ *            |    STATE      |\n+ *            |               |\n+ *            +---------------+\n+ *\n+ *\n+ * States:\n+ * ------\n+ *\n+ * - WAITING_FOR_CONNECTIVITY    :: initial state, waiting for any connection to remote cluster to be established.\n+ * - VERIFYING_REMOTE_LEADER     :: verifying the leader endpoint on remote cluster (querying all connected nodes)\n+ * - NEGOTIATING                 :: negotiating against the leader endpoint\n+ * - REPLICATING                 :: replicating data to remote cluster through the leader endpoint\n+ * - STOPPED                     :: stop state machine, no error, just lost leadership so replication stops from this node\n+ * - UNRECOVERABLE_STATE         :: error state, unrecoverable error reported by replication, transport or cluster manager, despite\n+ *                                  being the leader node.\n+ *\n+ *\n+ * Events / Transitions:\n+ * --------------------\n+ *\n+ * - ON_CONNECTION_UP           :: connection to a remote endpoint comes UP\n+ * - ON_CONNECTION_DOWN         :: connection to a remote endpoint comes DOWN\n+ * - REMOTE_LEADER_NOT_FOUND,   :: remote leader not found\n+ * - REMOTE_LEADER_FOUND,       :: remote leader found\n+ * - REMOTE_LEADER_LOSS,        :: remote Leader Lost (remote node reports it is no longer the leader)\n+ * - LOCAL_LEADER_LOSS          :: local node looses leadership\n+ * - NEGOTIATION_COMPLETE,      :: negotiation succeeded and completed\n+ * - NEGOTIATION_FAILED,        :: negotiation failed\n+ * - STOPPED                    :: stop log replication server (fatal state)\n+ *\n+ * @author amartinezman\n+ *\n+ */\n+@Slf4j\n+public class CorfuLogReplicationRuntime {\n+\n+    // TODO(Gabriela): add site_flip (cluster_role_flip) event... probably we need a new state called finishing_ongoing_replication... and go to to stopped...\n+\n+    public static final int DEFAULT_TIMEOUT = 5000;\n+\n+    /**\n+     * Current state of the FSM.\n+     */\n+    private volatile LogReplicationRuntimeState state;\n+\n+    /**\n+     * Map of all Log Replication Communication FSM States (reuse single instance for each state)\n+     */\n+    @Getter\n+    private Map<LogReplicationRuntimeStateType, LogReplicationRuntimeState> states = new HashMap<>();\n+\n+    /**\n+     * Executor service for FSM state tasks\n+     */\n+    private ExecutorService communicationFSMWorkers;\n+\n+    /**\n+     * Executor service for FSM event queue consume\n+     */\n+    private ExecutorService communicationFSMConsumer;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<LogReplicationRuntimeEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private final LogReplicationClientRouter router;\n+    private final LogReplicationMetadataManager metadataManager;\n+    private final LogReplicationSourceManager sourceManager;\n+    private volatile Set<String> connectedEndpoints = ConcurrentHashMap.newKeySet();\n+    private volatile Optional<String> leaderEndpoint = Optional.empty();\n+    public final String remoteClusterId;\n+\n+    /**\n+     * Default Constructor\n+     */\n+    public CorfuLogReplicationRuntime(LogReplicationRuntimeParameters parameters, LogReplicationMetadataManager metadataManager) {\n+        this.remoteClusterId = parameters.getRemoteClusterDescriptor().getClusterId();\n+        this.metadataManager = metadataManager;\n+        this.router = new LogReplicationClientRouter(parameters, this);\n+        this.router.addClient(new LogReplicationHandler());\n+        this.sourceManager = new LogReplicationSourceManager(parameters, new LogReplicationClient(router, remoteClusterId));\n+        this.communicationFSMWorkers = Executors.newSingleThreadExecutor(new\n+                ThreadFactoryBuilder().setNameFormat(\"runtime-fsm-worker\").build());\n+        this.communicationFSMConsumer = Executors.newSingleThreadExecutor(new\n+                ThreadFactoryBuilder().setNameFormat(\"runtime-fsm-consumer\").build());\n+\n+        initializeStates();\n+        this.state = states.get(LogReplicationRuntimeStateType.WAITING_FOR_CONNECTIVITY);\n+\n+        log.info(\"Log Replication Runtime State Machine initialized\");\n+    }\n+\n+    /**\n+     * Start Log Replication Communication FSM\n+     */\n+    public void start() {\n+        // Start Consumer Thread for this state machine (dedicated thread for event consumption)\n+        communicationFSMConsumer.submit(this::consume);\n+        router.connect();\n+    }\n+\n+    /**\n+     * Initialize all states for the Log Replication Runtime FSM.\n+     */\n+    private void initializeStates() {\n+        /*\n+         * Log Replication Runtime State instances are kept in a map to be reused in transitions, avoid creating one\n+         * per every transition (reduce GC cycles).\n+         */\n+        states.put(LogReplicationRuntimeStateType.WAITING_FOR_CONNECTIVITY, new WaitingForConnectionsState(this));\n+        states.put(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER, new VerifyingRemoteLeaderState(this, communicationFSMWorkers, router));\n+        states.put(LogReplicationRuntimeStateType.NEGOTIATING, new NegotiatingState(this, communicationFSMWorkers, router, metadataManager));\n+        states.put(LogReplicationRuntimeStateType.REPLICATING, new ReplicatingState(this, sourceManager));\n+        states.put(LogReplicationRuntimeStateType.STOPPED, new StoppedState(sourceManager));\n+        states.put(LogReplicationRuntimeStateType.UNRECOVERABLE, new UnrecoverableState());\n+    }\n+\n+    /**\n+     * Input function of the FSM.\n+     *\n+     * This method enqueues runtime events for further processing.\n+     *\n+     * @param event LogReplicationRuntimeEvent to process.\n+     */\n+    public synchronized void input(LogReplicationRuntimeEvent event) {\n+        try {\n+            if (state.getType().equals(LogReplicationRuntimeStateType.STOPPED)) {\n+                // Not accepting events, in stopped state\n+                return;\n+            }\n+            eventQueue.put(event);\n+        } catch (InterruptedException ex) {\n+            log.error(\"Log Replication interrupted Exception: \", ex);\n+        }\n+    }\n+\n+    /**\n+     * Consumer of the eventQueue.\n+     * <p>\n+     * This method consumes the log replication events and does the state transition.\n+     */\n+    private void consume() {\n+        try {\n+            if (state.getType() == LogReplicationRuntimeStateType.STOPPED) {\n+                log.info(\"Log Replication Communication State Machine has been stopped. No more events will be processed.\");\n+                return;\n+            }\n+\n+            //  Block until an event shows up in the queue.\n+            LogReplicationRuntimeEvent event = eventQueue.take();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 224}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1fce6cda9cf1cff66c7255e15a0339f3cfaa7bdd", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/1fce6cda9cf1cff66c7255e15a0339f3cfaa7bdd", "committedDate": "2020-06-29T18:45:23Z", "message": "Addressing Comments / Review"}, "afterCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/d955f519bca845eef0a189b25ee2d0c2196739c8", "committedDate": "2020-06-29T19:30:25Z", "message": "Addressing Comments / Review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NDA0OTE0", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-439404914", "createdAt": "2020-06-29T18:40:01Z", "commit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQxODo0MDowMVrOGqdcCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMDozNzoxOVrOGqhSDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE3NTY5MQ==", "bodyText": "Should we throw UnrecoverableCorfuInterruptedError here?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447175691", "createdAt": "2020-06-29T18:40:01Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,514 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connect to Cluster Manager adapter.\");\n+\n+            this.clusterManagerAdapter.connect(this);\n+\n+            log.info(\"Fetch topology from Cluster Manager...\");\n+\n+            topologyDescriptor = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+\n+            // Health check - confirm this node belongs to a cluster in the topology\n+            if (clusterPresentInTopology(topologyDescriptor)) {\n+\n+                log.info(\"Node[{}] belongs to cluster, descriptor={}\", localEndpoint,\n+                        localClusterDescriptor);\n+\n+                LogReplicationContext context = buildLogReplicationContext();\n+\n+                // Unblock server initialization retrieving context: topology + configuration\n+                discoveryCallback.complete(context);\n+\n+                registerToLogReplicationLock();\n+            } else {\n+                // If a cluster descriptor is not found, this node does not belong to any topology... raise an exception\n+                String message = String.format(\"Node[%s] does not belong to any Cluster provided by the discovery service, topology=%s\",\n+                        localEndpoint, topologyDescriptor);\n+                log.warn(message);\n+                throw new LogReplicationDiscoveryServiceException(message);\n+            }\n+        } catch (Exception e) {\n+            String message = \"Caught exception while fetching topology. Log Replication cannot start.\";\n+            log.error(message, e);\n+            throw new LogReplicationDiscoveryServiceException(message);\n+        }\n+    }\n+\n+    /**\n+     * Construct common log replication context.\n+     */\n+    private LogReplicationContext buildLogReplicationContext() {\n+        // Through LogReplicationConfigAdapter retrieve system-specific configurations (including streams to replicate)\n+        logReplicationConfig = getLogReplicationConfiguration(getCorfuRuntime());\n+\n+        logReplicationMetadataManager = new LogReplicationMetadataManager(getCorfuRuntime(),\n+                topologyDescriptor.getTopologyConfigId(), localClusterDescriptor.getClusterId());\n+\n+        logReplicationServer = new LogReplicationServer(serverContext, logReplicationConfig, logReplicationMetadataManager,\n+                localCorfuEndpoint);\n+        logReplicationServer.setActive(localClusterDescriptor.getRole().equals(ClusterRole.ACTIVE));\n+\n+        return new LogReplicationContext(logReplicationConfig, topologyDescriptor, logReplicationServer, localCorfuEndpoint);\n+    }\n+\n+    /**\n+     * Retrieve a Corfu Runtime to connect to the local Corfu Datastore.\n+     */\n+    private CorfuRuntime getCorfuRuntime() {\n+        if (runtime == null) {\n+            localCorfuEndpoint = getCorfuEndpoint(localHost, localClusterDescriptor.getCorfuPort());\n+            log.debug(\"Connecting to local Corfu {}\", localCorfuEndpoint);\n+            runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()\n+                    .trustStore((String) serverContext.getServerConfig().get(\"--truststore\"))\n+                    .tsPasswordFile((String) serverContext.getServerConfig().get(\"--truststore-password-file\"))\n+                    .keyStore((String) serverContext.getServerConfig().get(\"--keystore\"))\n+                    .ksPasswordFile((String) serverContext.getServerConfig().get(\"--keystore-password-file\"))\n+                    .tlsEnabled((Boolean) serverContext.getServerConfig().get(\"--enable-tls\"))\n+                    .build())\n+                    .parseConfigurationString(localCorfuEndpoint).connect();\n+        }\n+\n+        return runtime;\n+    }\n+\n+    /**\n+     * Verify current node belongs to a cluster in the topology.\n+     */\n+    private boolean clusterPresentInTopology(TopologyDescriptor topology) {\n+        localClusterDescriptor = topology.getClusterDescriptor(localEndpoint);\n+        if (localClusterDescriptor != null) {\n+            localNodeDescriptor = localClusterDescriptor.getNode(localEndpoint);\n+            return true;\n+        }\n+\n+        return false;\n+    }\n+\n+    /**\n+     * Retrieve local Corfu Endpoint\n+     */\n+    private String getCorfuEndpoint(String localEndpoint, int corfuPort) {\n+        return NodeLocator.parseString(localEndpoint).getHost() + \":\" + corfuPort;\n+    }\n+\n+    /**\n+     * Retrieve Log Replication Configuration.\n+     *\n+     * This configuration represents all common parameters for the log replication, regardless of\n+     * a cluster's role.\n+     */\n+    private LogReplicationConfig getLogReplicationConfiguration(CorfuRuntime runtime) {\n+\n+        LogReplicationStreamNameTableManager replicationStreamNameTableManager =\n+                new LogReplicationStreamNameTableManager(runtime, pluginFilePath);\n+\n+        Set<String> streamsToReplicate = replicationStreamNameTableManager.getStreamsToReplicate();\n+\n+        // TODO pankti: Check if version does not match.  If if does not, create an event for site discovery to\n+        //  do a snapshot sync.\n+        // TODO(Gabriela): pending review upgrade path (changes)\n+        boolean upgraded = replicationStreamNameTableManager\n+                .isUpgraded();\n+\n+        if (upgraded) {\n+            input(new DiscoveryServiceEvent(DiscoveryServiceEvent.DiscoveryServiceEventType.UPGRADE));\n+        }\n+\n+        return new LogReplicationConfig(streamsToReplicate);\n+    }\n+\n+    /**\n+     * Register interest on Log Replication Lock.\n+     *\n+     * The node that acquires the lock will drive/lead log replication.\n+     */\n+    private void registerToLogReplicationLock() {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    LockClient lock = new LockClient(nodeId, getCorfuRuntime());\n+                    // Callback on lock acquisition or revoke\n+                    LockListener logReplicationLockListener = new LogReplicationLockListener(this);\n+                    // Register Interest on the shared Log Replication Lock\n+                    lock.registerInterest(LOCK_GROUP, LOCK_NAME, logReplicationLockListener);\n+                } catch (Exception e) {\n+                    log.error(\"Error while attempting to register interest on log replication lock {}:{}\", LOCK_GROUP, LOCK_NAME, e);\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to register interest on log replication lock.\", e);\n+            throw new UnrecoverableCorfuError(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 312}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE4NDkxOA==", "bodyText": "When the current cluster is standby, does discovery service has a replication manager? If so, do we need to make sure they do not have any side effects? Otherwise, we might need to check if replication manager is null.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447184918", "createdAt": "2020-06-29T18:56:17Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,513 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connecting to Cluster Manager adapter...\");\n+\n+            this.clusterManagerAdapter.connect(this);\n+\n+            log.info(\"Fetch topology from Cluster Manager...\");\n+\n+            topologyDescriptor = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+\n+            // Health check - confirm this node belongs to a cluster in the topology\n+            if (clusterPresentInTopology(topologyDescriptor)) {\n+\n+                log.info(\"Node[{}] belongs to cluster, descriptor={}\", localEndpoint,\n+                        localClusterDescriptor);\n+\n+                LogReplicationContext context = buildLogReplicationContext();\n+\n+                // Unblock server initialization retrieving context: topology + configuration\n+                discoveryCallback.complete(context);\n+\n+                registerToLogReplicationLock();\n+            } else {\n+                // If a cluster descriptor is not found, this node does not belong to any topology... raise an exception\n+                String message = String.format(\"Node[%s] does not belong to any Cluster provided by the discovery service, topology=%s\",\n+                        localEndpoint, topologyDescriptor);\n+                log.warn(message);\n+                throw new LogReplicationDiscoveryServiceException(message);\n+            }\n+        } catch (Exception e) {\n+            String message = \"Caught exception while fetching topology. Log Replication cannot start.\";\n+            log.error(message, e);\n+            throw new LogReplicationDiscoveryServiceException(message);\n+        }\n+    }\n+\n+    /**\n+     * Construct common log replication context.\n+     */\n+    private LogReplicationContext buildLogReplicationContext() {\n+        // Through LogReplicationConfigAdapter retrieve system-specific configurations (including streams to replicate)\n+        logReplicationConfig = getLogReplicationConfiguration(getCorfuRuntime());\n+\n+        logReplicationMetadataManager = new LogReplicationMetadataManager(getCorfuRuntime(),\n+                topologyDescriptor.getTopologyConfigId(), localClusterDescriptor.getClusterId());\n+\n+        logReplicationServer = new LogReplicationServer(serverContext, logReplicationConfig, logReplicationMetadataManager,\n+                localCorfuEndpoint);\n+        logReplicationServer.setActive(localClusterDescriptor.getRole().equals(ClusterRole.ACTIVE));\n+\n+        return new LogReplicationContext(logReplicationConfig, topologyDescriptor, logReplicationServer, localCorfuEndpoint);\n+    }\n+\n+    /**\n+     * Retrieve a Corfu Runtime to connect to the local Corfu Datastore.\n+     */\n+    private CorfuRuntime getCorfuRuntime() {\n+        if (runtime == null) {\n+            localCorfuEndpoint = getCorfuEndpoint(localHost, localClusterDescriptor.getCorfuPort());\n+            log.debug(\"Connecting to local Corfu {}\", localCorfuEndpoint);\n+            runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()\n+                    .trustStore((String) serverContext.getServerConfig().get(\"--truststore\"))\n+                    .tsPasswordFile((String) serverContext.getServerConfig().get(\"--truststore-password-file\"))\n+                    .keyStore((String) serverContext.getServerConfig().get(\"--keystore\"))\n+                    .ksPasswordFile((String) serverContext.getServerConfig().get(\"--keystore-password-file\"))\n+                    .tlsEnabled((Boolean) serverContext.getServerConfig().get(\"--enable-tls\"))\n+                    .build())\n+                    .parseConfigurationString(localCorfuEndpoint).connect();\n+        }\n+\n+        return runtime;\n+    }\n+\n+    /**\n+     * Verify current node belongs to a cluster in the topology.\n+     */\n+    private boolean clusterPresentInTopology(TopologyDescriptor topology) {\n+        localClusterDescriptor = topology.getClusterDescriptor(localEndpoint);\n+        if (localClusterDescriptor != null) {\n+            localNodeDescriptor = localClusterDescriptor.getNode(localEndpoint);\n+        }\n+\n+        return localClusterDescriptor != null && localNodeDescriptor != null;\n+    }\n+\n+    /**\n+     * Retrieve local Corfu Endpoint\n+     */\n+    private String getCorfuEndpoint(String localEndpoint, int corfuPort) {\n+        return NodeLocator.parseString(localEndpoint).getHost() + \":\" + corfuPort;\n+    }\n+\n+    /**\n+     * Retrieve Log Replication Configuration.\n+     *\n+     * This configuration represents all common parameters for the log replication, regardless of\n+     * a cluster's role.\n+     */\n+    private LogReplicationConfig getLogReplicationConfiguration(CorfuRuntime runtime) {\n+\n+        LogReplicationStreamNameTableManager replicationStreamNameTableManager =\n+                new LogReplicationStreamNameTableManager(runtime, pluginFilePath);\n+\n+        Set<String> streamsToReplicate = replicationStreamNameTableManager.getStreamsToReplicate();\n+\n+        // TODO pankti: Check if version does not match.  If if does not, create an event for site discovery to\n+        //  do a snapshot sync.\n+        // TODO(Gabriela): pending review upgrade path (changes)\n+        boolean upgraded = replicationStreamNameTableManager\n+                .isUpgraded();\n+\n+        if (upgraded) {\n+            input(new DiscoveryServiceEvent(DiscoveryServiceEvent.DiscoveryServiceEventType.UPGRADE));\n+        }\n+\n+        return new LogReplicationConfig(streamsToReplicate);\n+    }\n+\n+    /**\n+     * Register interest on Log Replication Lock.\n+     *\n+     * The node that acquires the lock will drive/lead log replication.\n+     */\n+    private void registerToLogReplicationLock() {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    LockClient lock = new LockClient(nodeId, getCorfuRuntime());\n+                    // Callback on lock acquisition or revoke\n+                    LockListener logReplicationLockListener = new LogReplicationLockListener(this);\n+                    // Register Interest on the shared Log Replication Lock\n+                    lock.registerInterest(LOCK_GROUP, LOCK_NAME, logReplicationLockListener);\n+                } catch (Exception e) {\n+                    log.error(\"Error while attempting to register interest on log replication lock {}:{}\", LOCK_GROUP, LOCK_NAME, e);\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to register interest on log replication lock.\", e);\n+            throw new UnrecoverableCorfuError(e);\n+        }\n+    }\n+\n+    /**\n+     * This method is only called on the leader node and it triggers the start of log replication\n+     *\n+     * Depending on the role of the cluster to which this leader node belongs to, it will start\n+     * as source (sender/producer) or sink (receiver).\n+     */\n+    private void startLogReplication() {\n+        if (!localNodeDescriptor.isLeader()) {\n+            log.warn(\"Current node {} is not the lead node, log replication cannot be started.\", localEndpoint);\n+            return;\n+        }\n+\n+        boolean activeCluster = localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE;\n+\n+        if (activeCluster) {\n+            log.info(\"Start as Source (sender/replicator) on node {}.\", localNodeDescriptor);\n+            // TODO(Gabriela): only one instance of CorfuReplicationManager\n+            replicationManager = new CorfuReplicationManager(topologyDescriptor, logReplicationConfig,\n+                    localNodeDescriptor, logReplicationMetadataManager, pluginFilePath, getCorfuRuntime());\n+            replicationManager.start();\n+        } else if (localNodeDescriptor.getRoleType() == ClusterRole.STANDBY) {\n+            // Standby Site : the LogReplicationServer (server handler) will initiate the LogReplicationSinkManager\n+            log.info(\"Start as Sink (receiver) on node {} \", localNodeDescriptor);\n+        } else {\n+            log.error(\"Log Replication not started on this cluster. Leader node {} belongs to cluster with {} role.\",\n+                    localEndpoint, localNodeDescriptor.getRoleType());\n+        }\n+    }\n+\n+    private void updateTopologyConfigId(boolean active) {\n+        // Required only on topology changes\n+        logReplicationServer.getSinkManager().updateTopologyConfigId(active, topologyDescriptor.getTopologyConfigId());\n+\n+        log.debug(\"Persist new topologyConfigId {}, status={}\", topologyDescriptor.getTopologyConfigId(),\n+                localNodeDescriptor.getRoleType());\n+    }\n+\n+    /**\n+     * Stop ongoing Log Replication\n+     */\n+    private void stopLogReplication() {\n+        if (localNodeDescriptor.isLeader() && localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE) {\n+            replicationManager.stop();\n+        }\n+    }\n+\n+    /**\n+     * Process lock acquisition event\n+     */\n+    public void processLockAcquire() {\n+        log.info(\"Process lock acquire event\");\n+\n+        logReplicationServer.setLeadership(true);\n+\n+        // TODO(Gabriela): confirm that start does not affect ongoing replication if it is called again..\n+        if (!localNodeDescriptor.isLeader()) {\n+            // leader transition from false to true, start log replication.\n+            localNodeDescriptor.setLeader(true);\n+            startLogReplication();\n+        }\n+    }\n+\n+    /**\n+     * Process lock release event\n+     *\n+     * Set leadership metadata and stop log replication in the event of leadership loss\n+     */\n+    public void processLockRelease() {\n+        logReplicationServer.setLeadership(false);\n+\n+        if (localNodeDescriptor.isLeader()) {\n+            stopLogReplication();\n+            localNodeDescriptor.setLeader(false);\n+        }\n+    }\n+\n+\n+    public void processSiteFlip(TopologyDescriptor newConfig) {\n+        // TODO(Nan): Check standby to active and active to standby...\n+        stopLogReplication();\n+        //TODO pankti: read the configuration again and refresh the LogReplicationConfig object\n+        replicationManager.setTopologyDescriptor(newConfig);\n+        boolean activeCluster = localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE;\n+        updateTopologyConfigId(activeCluster);\n+        startLogReplication();\n+    }\n+\n+    public void processSiteChangeNotification(DiscoveryServiceEvent event) {\n+        // Stale notification, skip\n+        if (event.getTopologyConfig().getTopologyConfigID() < getReplicationManager().getTopologyDescriptor().getTopologyConfigId()) {\n+            log.debug(\"Stale Topology Change Notification, current={}, received={}\", topologyDescriptor.getTopologyConfigId(), event.getTopologyConfig());\n+            return;\n+        }\n+\n+        TopologyDescriptor newConfig = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+        if (newConfig.getTopologyConfigId() == getReplicationManager().getTopologyDescriptor().getTopologyConfigId()) {\n+            if (localNodeDescriptor.getRoleType() == ClusterRole.STANDBY) {\n+                return;\n+            }\n+\n+            // If the current node is active, compare with the current siteConfig, see if there are addition/removal standbys\n+            getReplicationManager().processStandbyChange(newConfig);\n+        } else {\n+            processSiteFlip(newConfig);\n+        }\n+    }\n+\n+    /***\n+     * The standby cluster's leader change can lead to connection loss.\n+     * If the current node is not the active cluster's leader, discard the notification.\n+     * If the current node is the the active cluster's leader that is is responsible for the current\n+     * replication job, will restart the replication with the remote cluster.\n+     *\n+     * @param event\n+     */\n+    private void processConnectionLoss(DiscoveryServiceEvent event) {\n+\n+        if (!localNodeDescriptor.isLeader() || localNodeDescriptor.getRoleType() != ClusterRole.ACTIVE) {\n+            return;\n+        }\n+\n+        replicationManager.restart(event.getRemoteSiteInfo());\n+    }\n+\n+    /***\n+     * After an upgrade, the active site should perform a snapshot sync\n+     */\n+    private void processUpgrade(DiscoveryServiceEvent event) {\n+        if (localNodeDescriptor.isLeader() && localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE) {\n+            // TODO pankti: is this correct?\n+            replicationManager.restart(event.getRemoteSiteInfo());\n+        }\n+    }\n+\n+    /**\n+     * Process event\n+     */\n+    public void processEvent(DiscoveryServiceEvent event) {\n+        switch (event.type) {\n+            case ACQUIRE_LOCK:\n+                processLockAcquire();\n+                break;\n+\n+            case RELEASE_LOCK:\n+                processLockRelease();\n+                break;\n+\n+            case DISCOVERY_SITE:\n+                processSiteChangeNotification(event);\n+                break;\n+\n+            case UPGRADE:\n+                processUpgrade(event);\n+                break;\n+\n+            default:\n+                log.error(\"wrong event type {}\", event);\n+        }\n+    }\n+\n+    public synchronized void input(DiscoveryServiceEvent event) {\n+        eventQueue.add(event);\n+        notifyAll();\n+    }\n+\n+    @Override\n+    public void updateSiteConfig(LogReplicationClusterInfo.TopologyConfigurationMsg topologyConfig) {\n+        input(new DiscoveryServiceEvent(DiscoveryServiceEvent.DiscoveryServiceEventType.DISCOVERY_SITE, topologyConfig));\n+    }\n+\n+    /**\n+     * Query the current all replication stream log tail and remeber the max\n+     * and query each standbySite information according to the ackInformation decide all manay total\n+     * msg needs to send out.\n+     */\n+    @Override\n+    public void prepareSiteRoleChange() {\n+        replicationManager.prepareSiteRoleChange();\n+    }\n+\n+    /**\n+     * Query the current all replication stream log tail and calculate the number of messages to be sent.\n+     * If the max tail has changed, give 0%. Otherwise,\n+     */\n+    @Override\n+    public int queryReplicationStatus() {\n+        return replicationManager.queryReplicationStatus();\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fce6cda9cf1cff66c7255e15a0339f3cfaa7bdd"}, "originalPosition": 502}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE5MTMwMg==", "bodyText": "The leader filed looks not necessary here. Constructor always set it as false and converToMessage() does not care about it. When applying a new config to discovery service, it needs to keep its original leader status after update its localNodeDescriptor. So I guess the discovery service can have the leader field?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447191302", "createdAt": "2020-06-29T19:07:44Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/NodeDescriptor.java", "diffHunk": "@@ -0,0 +1,63 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.NodeConfigurationMsg;\n+\n+import java.util.UUID;\n+\n+\n+@Slf4j\n+public class NodeDescriptor {\n+\n+    @Setter\n+    @Getter\n+    private ClusterRole roleType;\n+\n+    @Getter\n+    private String ipAddress;\n+\n+    @Getter\n+    private String port;\n+\n+    @Getter\n+    @Setter\n+    private boolean leader;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fce6cda9cf1cff66c7255e15a0339f3cfaa7bdd"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE5MjMxMg==", "bodyText": "Unused.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447192312", "createdAt": "2020-06-29T19:09:47Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/DiscoveryServiceEvent.java", "diffHunk": "@@ -0,0 +1,37 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+\n+public class DiscoveryServiceEvent {\n+    DiscoveryServiceEventType type = null;\n+\n+    @Getter\n+    TopologyConfigurationMsg topologyConfig = null;\n+\n+    @Getter\n+    @Setter\n+    ClusterDescriptor remoteSiteInfo;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fce6cda9cf1cff66c7255e15a0339f3cfaa7bdd"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE5MjQ1Mg==", "bodyText": "Unused.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447192452", "createdAt": "2020-06-29T19:10:04Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/DiscoveryServiceEvent.java", "diffHunk": "@@ -0,0 +1,37 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+\n+public class DiscoveryServiceEvent {\n+    DiscoveryServiceEventType type = null;\n+\n+    @Getter\n+    TopologyConfigurationMsg topologyConfig = null;\n+\n+    @Getter\n+    @Setter\n+    ClusterDescriptor remoteSiteInfo;\n+\n+    public DiscoveryServiceEvent(DiscoveryServiceEventType type) {\n+       this.type = type;\n+    }\n+\n+    public DiscoveryServiceEvent(DiscoveryServiceEventType type, ClusterDescriptor siteInfo) {\n+        new DiscoveryServiceEvent(type);\n+        this.remoteSiteInfo = siteInfo;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fce6cda9cf1cff66c7255e15a0339f3cfaa7bdd"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE5NzQwMg==", "bodyText": "Do we assume that topologyMessage from the cluster manager is always valid? I mean it always has only one active cluster. If not, we can throw an exception or at least have some debug logs.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447197402", "createdAt": "2020-06-29T19:19:30Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/TopologyDescriptor.java", "diffHunk": "@@ -0,0 +1,135 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterConfigurationMsg;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * This class represents a view of a Multi-Cluster/Site Topology,\n+ * where one cluster is the active/primary and n cluster's are standby's (backups).\n+ */\n+@Slf4j\n+public class TopologyDescriptor {\n+\n+    // Represents a state of the topology configuration (a topology epoch)\n+    @Getter\n+    private long topologyConfigId;\n+\n+    @Getter\n+    private ClusterDescriptor activeCluster;\n+\n+    @Getter\n+    private Map<String, ClusterDescriptor> standbyClusters;\n+\n+    @Getter\n+    private String certs;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param topologyMessage\n+     */\n+    public TopologyDescriptor(TopologyConfigurationMsg topologyMessage) {\n+        this.topologyConfigId = topologyMessage.getTopologyConfigID();\n+        this.certs = topologyMessage.getCerts();\n+        standbyClusters = new HashMap<>();\n+        for (ClusterConfigurationMsg clusterConfig : topologyMessage.getClustersList()) {\n+            ClusterDescriptor siteInfo = new ClusterDescriptor(clusterConfig);\n+            if (clusterConfig.getRole() == ClusterRole.ACTIVE) {\n+                activeCluster = siteInfo;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fce6cda9cf1cff66c7255e15a0339f3cfaa7bdd"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE5NzUzMw==", "bodyText": "nit: site -> cluster", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447197533", "createdAt": "2020-06-29T19:19:44Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/TopologyDescriptor.java", "diffHunk": "@@ -0,0 +1,135 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterConfigurationMsg;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * This class represents a view of a Multi-Cluster/Site Topology,\n+ * where one cluster is the active/primary and n cluster's are standby's (backups).\n+ */\n+@Slf4j\n+public class TopologyDescriptor {\n+\n+    // Represents a state of the topology configuration (a topology epoch)\n+    @Getter\n+    private long topologyConfigId;\n+\n+    @Getter\n+    private ClusterDescriptor activeCluster;\n+\n+    @Getter\n+    private Map<String, ClusterDescriptor> standbyClusters;\n+\n+    @Getter\n+    private String certs;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param topologyMessage\n+     */\n+    public TopologyDescriptor(TopologyConfigurationMsg topologyMessage) {\n+        this.topologyConfigId = topologyMessage.getTopologyConfigID();\n+        this.certs = topologyMessage.getCerts();\n+        standbyClusters = new HashMap<>();\n+        for (ClusterConfigurationMsg clusterConfig : topologyMessage.getClustersList()) {\n+            ClusterDescriptor siteInfo = new ClusterDescriptor(clusterConfig);\n+            if (clusterConfig.getRole() == ClusterRole.ACTIVE) {\n+                activeCluster = siteInfo;\n+            } else if (clusterConfig.getRole() == ClusterRole.STANDBY) {\n+                addStandbySite(siteInfo);\n+            }\n+        }\n+    }\n+\n+    public TopologyDescriptor(long siteConfigID, ClusterDescriptor primarySite, Map<String, ClusterDescriptor> standbySites) {\n+        this.topologyConfigId = siteConfigID;\n+        this.activeCluster = primarySite;\n+        this.standbyClusters = standbySites;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fce6cda9cf1cff66c7255e15a0339f3cfaa7bdd"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE5ODczOQ==", "bodyText": "Unused methods and repeated logs", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447198739", "createdAt": "2020-06-29T19:21:43Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/TopologyDescriptor.java", "diffHunk": "@@ -0,0 +1,135 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterConfigurationMsg;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * This class represents a view of a Multi-Cluster/Site Topology,\n+ * where one cluster is the active/primary and n cluster's are standby's (backups).\n+ */\n+@Slf4j\n+public class TopologyDescriptor {\n+\n+    // Represents a state of the topology configuration (a topology epoch)\n+    @Getter\n+    private long topologyConfigId;\n+\n+    @Getter\n+    private ClusterDescriptor activeCluster;\n+\n+    @Getter\n+    private Map<String, ClusterDescriptor> standbyClusters;\n+\n+    @Getter\n+    private String certs;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param topologyMessage\n+     */\n+    public TopologyDescriptor(TopologyConfigurationMsg topologyMessage) {\n+        this.topologyConfigId = topologyMessage.getTopologyConfigID();\n+        this.certs = topologyMessage.getCerts();\n+        standbyClusters = new HashMap<>();\n+        for (ClusterConfigurationMsg clusterConfig : topologyMessage.getClustersList()) {\n+            ClusterDescriptor siteInfo = new ClusterDescriptor(clusterConfig);\n+            if (clusterConfig.getRole() == ClusterRole.ACTIVE) {\n+                activeCluster = siteInfo;\n+            } else if (clusterConfig.getRole() == ClusterRole.STANDBY) {\n+                addStandbySite(siteInfo);\n+            }\n+        }\n+    }\n+\n+    public TopologyDescriptor(long siteConfigID, ClusterDescriptor primarySite, Map<String, ClusterDescriptor> standbySites) {\n+        this.topologyConfigId = siteConfigID;\n+        this.activeCluster = primarySite;\n+        this.standbyClusters = standbySites;\n+    }\n+\n+    public TopologyConfigurationMsg convertToMessage() {\n+        ArrayList<ClusterConfigurationMsg> clustersConfigs = new ArrayList<>();\n+        clustersConfigs.add((activeCluster.convertToMessage()));\n+\n+        for (ClusterDescriptor siteInfo : standbyClusters.values()) {\n+            clustersConfigs.add(siteInfo.convertToMessage());\n+        }\n+\n+        TopologyConfigurationMsg topologyConfig = TopologyConfigurationMsg.newBuilder()\n+                .setTopologyConfigID(topologyConfigId)\n+                .addAllClusters(clustersConfigs).build();\n+\n+        return topologyConfig;\n+    }\n+\n+    public NodeDescriptor getNodeInfo(String endpoint) {\n+        List<ClusterDescriptor> sites = new ArrayList<>(standbyClusters.values());\n+\n+        sites.add(activeCluster);\n+        NodeDescriptor nodeInfo = getNodeInfo(sites, endpoint);\n+\n+        if (nodeInfo == null) {\n+            log.warn(\"No Cluster has node with IP {} \", endpoint);\n+        }\n+\n+        return nodeInfo;\n+    }\n+\n+    private NodeDescriptor getNodeInfo(List<ClusterDescriptor> sitesInfo, String endpoint) {\n+        for (ClusterDescriptor site : sitesInfo) {\n+            for (NodeDescriptor nodeInfo : site.getNodesDescriptors()) {\n+                if (nodeInfo.getEndpoint().equals(endpoint)) {\n+                    return nodeInfo;\n+                }\n+            }\n+        }\n+\n+        log.warn(\"There is no nodeInfo for ipAddress {} \", endpoint);\n+        return null;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1fce6cda9cf1cff66c7255e15a0339f3cfaa7bdd"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIxNzU5Ng==", "bodyText": "I was wondering if this volatile is necessary. TopologyDescriptor in the replication manager is modified by some events, which are processed by a single thread in Discovery Service.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447217596", "createdAt": "2020-06-29T19:57:11Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -0,0 +1,300 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+/**\n+ * This class manages Log Replication for multiple remote (standby) cluster's.\n+ */\n+@Slf4j\n+public class CorfuReplicationManager {\n+\n+    public final static int PERCENTAGE_BASE = 100;\n+\n+    // Keep map of remote cluster ID and the associated log replication runtime (an abstract\n+    // client to that cluster)\n+    private Map<String, CorfuLogReplicationRuntime> runtimeToRemoteCluster = new HashMap<>();\n+\n+    @Setter\n+    @Getter\n+    private volatile TopologyDescriptor topologyDescriptor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzMjU0OQ==", "bodyText": "It looks like that this catch block is in a dead code path. Because startLogReplicationRuntime will catch all exceptions and input an event to FSM.\nRemove elements in an iteration over values also dangerous.\n\nIf the map is modified while an iteration over the collection is in progress (except through the iterator's own remove operation), the results of the iteration are undefined.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447232549", "createdAt": "2020-06-29T20:25:45Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -0,0 +1,300 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+/**\n+ * This class manages Log Replication for multiple remote (standby) cluster's.\n+ */\n+@Slf4j\n+public class CorfuReplicationManager {\n+\n+    public final static int PERCENTAGE_BASE = 100;\n+\n+    // Keep map of remote cluster ID and the associated log replication runtime (an abstract\n+    // client to that cluster)\n+    private Map<String, CorfuLogReplicationRuntime> runtimeToRemoteCluster = new HashMap<>();\n+\n+    @Setter\n+    @Getter\n+    private volatile TopologyDescriptor topologyDescriptor;\n+\n+    private final LogReplicationConfig logReplicationConfig;\n+\n+    private final NodeDescriptor localNodeDescriptor;\n+\n+    private final CorfuRuntime corfuRuntime;\n+\n+    // TODO (Xiaoqin Ma): can you please add a description on this variable's meaning\n+    private long prepareSiteRoleChangeStreamTail;\n+\n+    private long totalNumEntriesToSend;\n+\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    private final String pluginFilePath;\n+\n+    /**\n+     * Constructor\n+     *\n+     * @param topologyDescriptor description of active and standby cluster' of a given topology\n+     * @param logReplicationConfig log replication configuration\n+     */\n+    public CorfuReplicationManager(TopologyDescriptor topologyDescriptor,\n+                            LogReplicationConfig logReplicationConfig,\n+                            NodeDescriptor localNodeDescriptor,\n+                            LogReplicationMetadataManager metadataManager,\n+                            String pluginFilePath, CorfuRuntime corfuRuntime) {\n+        this.topologyDescriptor = topologyDescriptor;\n+        this.logReplicationConfig = logReplicationConfig;\n+        this.metadataManager = metadataManager;\n+        this.pluginFilePath = pluginFilePath;\n+        this.corfuRuntime = corfuRuntime;\n+\n+        this.localNodeDescriptor = localNodeDescriptor;\n+        this.prepareSiteRoleChangeStreamTail = Address.NON_ADDRESS;\n+        this.totalNumEntriesToSend = 0;\n+    }\n+\n+    /**\n+     * Start Log Replication Manager, this will initiate a runtime against\n+     * each standby cluster, to further start log replication.\n+     */\n+    public void start() {\n+        for (ClusterDescriptor remoteCluster : topologyDescriptor.getStandbyClusters().values()) {\n+            try {\n+                startLogReplicationRuntime(remoteCluster);\n+            } catch (Exception e) {\n+                log.error(\"Failed to start log replication runtime for remote cluster {}\", remoteCluster.getClusterId());\n+\n+                // Remove cluster from the list of standby's, as the cluster discovery process will receive\n+                // change notification when this site becomes stable/available again.\n+                topologyDescriptor.getStandbyClusters().remove(remoteCluster.getClusterId());\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzODY3MA==", "bodyText": "Query tailMap multiple times is not efficient.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447238670", "createdAt": "2020-06-29T20:37:19Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -0,0 +1,300 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+/**\n+ * This class manages Log Replication for multiple remote (standby) cluster's.\n+ */\n+@Slf4j\n+public class CorfuReplicationManager {\n+\n+    public final static int PERCENTAGE_BASE = 100;\n+\n+    // Keep map of remote cluster ID and the associated log replication runtime (an abstract\n+    // client to that cluster)\n+    private Map<String, CorfuLogReplicationRuntime> runtimeToRemoteCluster = new HashMap<>();\n+\n+    @Setter\n+    @Getter\n+    private volatile TopologyDescriptor topologyDescriptor;\n+\n+    private final LogReplicationConfig logReplicationConfig;\n+\n+    private final NodeDescriptor localNodeDescriptor;\n+\n+    private final CorfuRuntime corfuRuntime;\n+\n+    // TODO (Xiaoqin Ma): can you please add a description on this variable's meaning\n+    private long prepareSiteRoleChangeStreamTail;\n+\n+    private long totalNumEntriesToSend;\n+\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    private final String pluginFilePath;\n+\n+    /**\n+     * Constructor\n+     *\n+     * @param topologyDescriptor description of active and standby cluster' of a given topology\n+     * @param logReplicationConfig log replication configuration\n+     */\n+    public CorfuReplicationManager(TopologyDescriptor topologyDescriptor,\n+                            LogReplicationConfig logReplicationConfig,\n+                            NodeDescriptor localNodeDescriptor,\n+                            LogReplicationMetadataManager metadataManager,\n+                            String pluginFilePath, CorfuRuntime corfuRuntime) {\n+        this.topologyDescriptor = topologyDescriptor;\n+        this.logReplicationConfig = logReplicationConfig;\n+        this.metadataManager = metadataManager;\n+        this.pluginFilePath = pluginFilePath;\n+        this.corfuRuntime = corfuRuntime;\n+\n+        this.localNodeDescriptor = localNodeDescriptor;\n+        this.prepareSiteRoleChangeStreamTail = Address.NON_ADDRESS;\n+        this.totalNumEntriesToSend = 0;\n+    }\n+\n+    /**\n+     * Start Log Replication Manager, this will initiate a runtime against\n+     * each standby cluster, to further start log replication.\n+     */\n+    public void start() {\n+        for (ClusterDescriptor remoteCluster : topologyDescriptor.getStandbyClusters().values()) {\n+            try {\n+                startLogReplicationRuntime(remoteCluster);\n+            } catch (Exception e) {\n+                log.error(\"Failed to start log replication runtime for remote cluster {}\", remoteCluster.getClusterId());\n+\n+                // Remove cluster from the list of standby's, as the cluster discovery process will receive\n+                // change notification when this site becomes stable/available again.\n+                topologyDescriptor.getStandbyClusters().remove(remoteCluster.getClusterId());\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Stop log replication for all the standby sites\n+     */\n+    public void stop() {\n+        for(String clusterId : topologyDescriptor.getStandbyClusters().keySet()) {\n+            stopLogReplicationRuntime(clusterId);\n+        }\n+    }\n+\n+    /**\n+     * Restart connection to remote cluster\n+     */\n+    public void restart(ClusterDescriptor remoteCluster) {\n+        stopLogReplicationRuntime(remoteCluster.getClusterId());\n+        startLogReplicationRuntime(remoteCluster);\n+    }\n+\n+    /**\n+     * Start Log Replication Runtime to a specific standby Cluster\n+     */\n+    private void startLogReplicationRuntime(ClusterDescriptor remoteClusterDescriptor) {\n+\n+        String remoteClusterId = remoteClusterDescriptor.getClusterId();\n+\n+        try {\n+            if (!runtimeToRemoteCluster.containsKey(remoteClusterId)) {\n+                log.info(\"Starting Log Replication Runtime to Standby Cluster id={}\", remoteClusterId);\n+                connect(remoteClusterDescriptor);\n+            } else {\n+                log.warn(\"Log Replication Runtime to remote cluster {}, already exists. Skipping init.\", remoteClusterId);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Caught exception, stop log replication runtime to {}\", remoteClusterDescriptor, e);\n+            stopLogReplicationRuntime(remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * Connect to a remote Log Replicator, through a Log Replication Runtime.\n+     *\n+     * @throws InterruptedException\n+     */\n+    private void connect(ClusterDescriptor remoteCluster) throws InterruptedException {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    // TODO(Gabriela) : It's cleaner to make LogReplicationConfig agnostic of cluster information (shared across\n+                    //  all clusters) so it would be better to push down the remote cluster id or info as a separate object\n+                    //  this requires to change signatures down the pipe. TBD.\n+                    String localCorfuEndpoint = localNodeDescriptor.getIpAddress() + \":\" + topologyDescriptor.getActiveCluster().getCorfuPort();\n+\n+                    LogReplicationRuntimeParameters parameters = LogReplicationRuntimeParameters.builder()\n+                            .localCorfuEndpoint(localCorfuEndpoint)\n+                            .remoteClusterDescriptor(remoteCluster)\n+                            .localClusterId(localNodeDescriptor.getClusterId())\n+                            .replicationConfig(new LogReplicationConfig(logReplicationConfig.getStreamsToReplicate()))\n+                            .pluginFilePath(pluginFilePath)\n+                            .topologyConfigId(topologyDescriptor.getTopologyConfigId())\n+                            .keyStore(corfuRuntime.getParameters().getKeyStore())\n+                            .tlsEnabled(corfuRuntime.getParameters().isTlsEnabled())\n+                            .ksPasswordFile(corfuRuntime.getParameters().getKsPasswordFile())\n+                            .trustStore(corfuRuntime.getParameters().getTrustStore())\n+                            .tsPasswordFile(corfuRuntime.getParameters().getTsPasswordFile())\n+                            .build();\n+                    CorfuLogReplicationRuntime replicationRuntime = new CorfuLogReplicationRuntime(parameters, metadataManager);\n+                    replicationRuntime.start();\n+                    runtimeToRemoteCluster.put(remoteCluster.getClusterId(), replicationRuntime);\n+                } catch (Exception e) {\n+                    log.error(\"Exception {}. Failed to connect to remote cluster {}. Retry after 1 second.\",\n+                            e, remoteCluster.getClusterId());\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to connect to remote cluster.\", e);\n+            throw e;\n+        }\n+    }\n+\n+    /**\n+     * Stop Log Replication to a specific standby Cluster\n+     */\n+    private void stopLogReplicationRuntime(String remoteClusterId) {\n+        CorfuLogReplicationRuntime logReplicationRuntime = runtimeToRemoteCluster.get(remoteClusterId);\n+        if (logReplicationRuntime != null) {\n+            log.info(\"Stop log replication runtime to remote cluster id={}\", remoteClusterId);\n+            logReplicationRuntime.stop();\n+            runtimeToRemoteCluster.remove(remoteClusterId);\n+        } else {\n+            log.warn(\"Runtime not found to remote cluster {}\", remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * The notification of change of adding/removing standby's without epoch change.\n+     *\n+     * @param newConfig has the same topologyConfigId as the current config\n+     */\n+    public void processStandbyChange(TopologyDescriptor newConfig) {\n+        if (newConfig.getTopologyConfigId() != topologyDescriptor.getTopologyConfigId()) {\n+            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+                    \"siteConfigId as the current one {}\", newConfig, topologyDescriptor);\n+            return;\n+        }\n+\n+        Map<String, ClusterDescriptor> newStandbys = newConfig.getStandbyClusters();\n+        Map<String, ClusterDescriptor> currentStandbys = topologyDescriptor.getStandbyClusters();\n+        newStandbys.keySet().retainAll(currentStandbys.keySet());\n+        Set<String> standbysToRemove = currentStandbys.keySet();\n+        standbysToRemove.removeAll(newStandbys.keySet());\n+\n+        /*\n+         * Remove standbys that are not in the new config\n+         */\n+        for (String siteID : standbysToRemove) {\n+            stopLogReplicationRuntime(siteID);\n+            topologyDescriptor.removeStandbySite(siteID);\n+        }\n+\n+        //Start the standbys that are in the new config but not in the current config\n+        for (String clusterId : newConfig.getStandbyClusters().keySet()) {\n+            if (runtimeToRemoteCluster.get(clusterId) == null) {\n+                ClusterDescriptor clusterInfo = newConfig.getStandbyClusters().get(clusterId);\n+                topologyDescriptor.addStandbySite(clusterInfo);\n+                startLogReplicationRuntime(clusterInfo);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all relevant streams.\n+     */\n+    private long queryStreamTail() {\n+        Set<String> streamsToReplicate = logReplicationConfig.getStreamsToReplicate();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : streamsToReplicate) {\n+            UUID currentUUID = CorfuRuntime.getStreamID(s);\n+            Map<UUID, Long> tailMap = corfuRuntime.getAddressSpaceView().getAllTails().getStreamTails();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 233}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NDQ2NjQ4", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-439446648", "createdAt": "2020-06-29T19:43:23Z", "commit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQxOTo0MzoyNFrOGqfiew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMToxNjowNVrOGqigyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIxMDEwNw==", "bodyText": "This can be wrapped into another function for clarity purposes.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447210107", "createdAt": "2020-06-29T19:43:24Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,513 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIxMDQ1Mg==", "bodyText": "Better to have it in a separate catch block", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447210452", "createdAt": "2020-06-29T19:43:58Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,513 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIxNDczOA==", "bodyText": "Also, here will the real clusterManagerAdapter have some sort of a retry logic?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447214738", "createdAt": "2020-06-29T19:52:09Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,513 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connecting to Cluster Manager adapter...\");\n+\n+            this.clusterManagerAdapter.connect(this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIyNjg5Nw==", "bodyText": "id is needed here", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447226897", "createdAt": "2020-06-29T20:15:19Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -77,36 +82,80 @@ public void shutdown() {\n \n     @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_ENTRY)\n     private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.info(\"Log Replication Entry received by Server.\");\n-\n-        LogReplicationEntry ack = sinkManager.receive(msg.getPayload());\n-\n-        if (ack != null) {\n-            long ts = ack.getMetadata().getMessageMetadataType().equals(MessageType.LOG_ENTRY_REPLICATED) ?\n-                    ack.getMetadata().getTimestamp() : ack.getMetadata().getSnapshotTimestamp();\n-            log.info(\"Sending ACK {} on {} to Client \", ack.getMetadata(), ts);\n-            r.sendResponse(ctx, msg, CorfuMsgType.LOG_REPLICATION_ENTRY.payloadMsg(ack));\n+        log.trace(\"Log Replication Entry received by Server.\");\n+\n+        if (isLeader(msg, r)) {\n+            // Forward the received message to the Sink Manager for apply\n+            LogReplicationEntry ack = sinkManager.receive(msg.getPayload());\n+\n+            if (ack != null) {\n+                long ts = ack.getMetadata().getMessageMetadataType().equals(MessageType.LOG_ENTRY_REPLICATED) ?\n+                        ack.getMetadata().getTimestamp() : ack.getMetadata().getSnapshotTimestamp();\n+                log.info(\"Sending ACK {} on {} to Client \", ack.getMetadata(), ts);\n+                r.sendResponse(msg, CorfuMsgType.LOG_REPLICATION_ENTRY.payloadMsg(ack));\n+            }\n         }\n     }\n \n     @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_NEGOTIATION_REQUEST)\n     private void handleLogReplicationNegotiationRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n         log.info(\"Log Replication Negotiation Request received by Server.\");\n-        LogReplicationMetadataManager metadata = sinkManager.getLogReplicationMetadataManager();\n-        LogReplicationNegotiationResponse response = new LogReplicationNegotiationResponse(\n-                metadata.getSiteConfigID(),\n-                metadata.getVersion(),\n-                metadata.getLastSnapStartTimestamp(),\n-                metadata.getLastSnapTransferDoneTimestamp(),\n-                metadata.getLastSrcBaseSnapshotTimestamp(),\n-                metadata.getLastProcessedLogTimestamp());\n-        r.sendResponse(ctx, msg, CorfuMsgType.LOG_REPLICATION_NEGOTIATION_RESPONSE.payloadMsg(response));\n+\n+        if (isLeader(msg, r)) {\n+            LogReplicationMetadataManager metadata = sinkManager.getLogReplicationMetadataManager();\n+            LogReplicationNegotiationResponse response = new LogReplicationNegotiationResponse(\n+                    metadata.getTopologyConfigId(),\n+                    metadata.getVersion(),\n+                    metadata.getLastSnapStartTimestamp(),\n+                    metadata.getLastSnapTransferDoneTimestamp(),\n+                    metadata.getLastSrcBaseSnapshotTimestamp(),\n+                    metadata.getLastProcessedLogTimestamp());\n+            log.info(\"Send Negotiation response\");\n+            r.sendResponse(msg, CorfuMsgType.LOG_REPLICATION_NEGOTIATION_RESPONSE.payloadMsg(response));\n+        } else {\n+            log.warn(\"Dropping negotiation request as this node is not the leader.\");\n+        }\n     }\n \n     @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_QUERY_LEADERSHIP)\n     private void handleLogReplicationQueryLeadership(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.info(\"******Log Replication Query Leadership Request received by Server.\");\n-        LogReplicationQueryLeaderShipResponse resp = new LogReplicationQueryLeaderShipResponse(0, getSinkManager().isLeader());\n-        r.sendResponse(ctx, msg, CorfuMsgType.LOG_REPLICATION_QUERY_LEADERSHIP_RESPONSE.payloadMsg(resp));\n+        log.info(\"Log Replication Query Leadership Request received by Server.\");\n+        LogReplicationQueryLeaderShipResponse resp = new LogReplicationQueryLeaderShipResponse(0,\n+                isLeader.get(), serverContext.getLocalEndpoint());\n+        r.sendResponse(msg, CorfuMsgType.LOG_REPLICATION_QUERY_LEADERSHIP_RESPONSE.payloadMsg(resp));\n+    }\n+\n+    /* ************ Private / Utility Methods ************ */\n+\n+    /**\n+     * Verify if current node is still the lead receiving node.\n+     *\n+     * @return true, if leader node.\n+     *         false, otherwise.\n+     */\n+    private synchronized boolean isLeader(CorfuMsg msg, IServerRouter r) {\n+        // If the current cluster has switched to the active role (no longer the receiver) or it is no longer the leader,\n+        // skip message processing (drop received message) and nack on leadership (loss of leadership)\n+        // This will re-trigger leadership discovery on the sender.\n+        boolean lostLeadership = isActive.get() || !isLeader.get();\n+\n+        if (lostLeadership) {\n+            log.warn(\"This node has changed, active={}, leader={}. Dropping message type={}, id={}\", isActive.get(),\n+                    isLeader.get(), msg.getMsgType());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzMDA2Ng==", "bodyText": "I think this method should probably be synchronized.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447230066", "createdAt": "2020-06-29T20:21:11Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java", "diffHunk": "@@ -174,40 +190,27 @@ public LogReplicationEntry receive(LogReplicationEntry message) {\n         rxMessageCounter++;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI0NTk3NA==", "bodyText": "That's 6 independent DB calls per one LOG_REPLICATION_NEGOTIATION_REQUEST. Can we do just one? Also, It does not  look like we handle failures if one of them fails, for example.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447245974", "createdAt": "2020-06-29T20:50:46Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -77,36 +82,80 @@ public void shutdown() {\n \n     @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_ENTRY)\n     private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {\n-        log.info(\"Log Replication Entry received by Server.\");\n-\n-        LogReplicationEntry ack = sinkManager.receive(msg.getPayload());\n-\n-        if (ack != null) {\n-            long ts = ack.getMetadata().getMessageMetadataType().equals(MessageType.LOG_ENTRY_REPLICATED) ?\n-                    ack.getMetadata().getTimestamp() : ack.getMetadata().getSnapshotTimestamp();\n-            log.info(\"Sending ACK {} on {} to Client \", ack.getMetadata(), ts);\n-            r.sendResponse(ctx, msg, CorfuMsgType.LOG_REPLICATION_ENTRY.payloadMsg(ack));\n+        log.trace(\"Log Replication Entry received by Server.\");\n+\n+        if (isLeader(msg, r)) {\n+            // Forward the received message to the Sink Manager for apply\n+            LogReplicationEntry ack = sinkManager.receive(msg.getPayload());\n+\n+            if (ack != null) {\n+                long ts = ack.getMetadata().getMessageMetadataType().equals(MessageType.LOG_ENTRY_REPLICATED) ?\n+                        ack.getMetadata().getTimestamp() : ack.getMetadata().getSnapshotTimestamp();\n+                log.info(\"Sending ACK {} on {} to Client \", ack.getMetadata(), ts);\n+                r.sendResponse(msg, CorfuMsgType.LOG_REPLICATION_ENTRY.payloadMsg(ack));\n+            }\n         }\n     }\n \n     @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_NEGOTIATION_REQUEST)\n     private void handleLogReplicationNegotiationRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n         log.info(\"Log Replication Negotiation Request received by Server.\");\n-        LogReplicationMetadataManager metadata = sinkManager.getLogReplicationMetadataManager();\n-        LogReplicationNegotiationResponse response = new LogReplicationNegotiationResponse(\n-                metadata.getSiteConfigID(),\n-                metadata.getVersion(),\n-                metadata.getLastSnapStartTimestamp(),\n-                metadata.getLastSnapTransferDoneTimestamp(),\n-                metadata.getLastSrcBaseSnapshotTimestamp(),\n-                metadata.getLastProcessedLogTimestamp());\n-        r.sendResponse(ctx, msg, CorfuMsgType.LOG_REPLICATION_NEGOTIATION_RESPONSE.payloadMsg(response));\n+\n+        if (isLeader(msg, r)) {\n+            LogReplicationMetadataManager metadata = sinkManager.getLogReplicationMetadataManager();\n+            LogReplicationNegotiationResponse response = new LogReplicationNegotiationResponse(\n+                    metadata.getTopologyConfigId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI1NDk2Ng==", "bodyText": "The description should be finished here", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447254966", "createdAt": "2020-06-29T21:08:17Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,513 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connecting to Cluster Manager adapter...\");\n+\n+            this.clusterManagerAdapter.connect(this);\n+\n+            log.info(\"Fetch topology from Cluster Manager...\");\n+\n+            topologyDescriptor = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+\n+            // Health check - confirm this node belongs to a cluster in the topology\n+            if (clusterPresentInTopology(topologyDescriptor)) {\n+\n+                log.info(\"Node[{}] belongs to cluster, descriptor={}\", localEndpoint,\n+                        localClusterDescriptor);\n+\n+                LogReplicationContext context = buildLogReplicationContext();\n+\n+                // Unblock server initialization retrieving context: topology + configuration\n+                discoveryCallback.complete(context);\n+\n+                registerToLogReplicationLock();\n+            } else {\n+                // If a cluster descriptor is not found, this node does not belong to any topology... raise an exception\n+                String message = String.format(\"Node[%s] does not belong to any Cluster provided by the discovery service, topology=%s\",\n+                        localEndpoint, topologyDescriptor);\n+                log.warn(message);\n+                throw new LogReplicationDiscoveryServiceException(message);\n+            }\n+        } catch (Exception e) {\n+            String message = \"Caught exception while fetching topology. Log Replication cannot start.\";\n+            log.error(message, e);\n+            throw new LogReplicationDiscoveryServiceException(message);\n+        }\n+    }\n+\n+    /**\n+     * Construct common log replication context.\n+     */\n+    private LogReplicationContext buildLogReplicationContext() {\n+        // Through LogReplicationConfigAdapter retrieve system-specific configurations (including streams to replicate)\n+        logReplicationConfig = getLogReplicationConfiguration(getCorfuRuntime());\n+\n+        logReplicationMetadataManager = new LogReplicationMetadataManager(getCorfuRuntime(),\n+                topologyDescriptor.getTopologyConfigId(), localClusterDescriptor.getClusterId());\n+\n+        logReplicationServer = new LogReplicationServer(serverContext, logReplicationConfig, logReplicationMetadataManager,\n+                localCorfuEndpoint);\n+        logReplicationServer.setActive(localClusterDescriptor.getRole().equals(ClusterRole.ACTIVE));\n+\n+        return new LogReplicationContext(logReplicationConfig, topologyDescriptor, logReplicationServer, localCorfuEndpoint);\n+    }\n+\n+    /**\n+     * Retrieve a Corfu Runtime to connect to the local Corfu Datastore.\n+     */\n+    private CorfuRuntime getCorfuRuntime() {\n+        if (runtime == null) {\n+            localCorfuEndpoint = getCorfuEndpoint(localHost, localClusterDescriptor.getCorfuPort());\n+            log.debug(\"Connecting to local Corfu {}\", localCorfuEndpoint);\n+            runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()\n+                    .trustStore((String) serverContext.getServerConfig().get(\"--truststore\"))\n+                    .tsPasswordFile((String) serverContext.getServerConfig().get(\"--truststore-password-file\"))\n+                    .keyStore((String) serverContext.getServerConfig().get(\"--keystore\"))\n+                    .ksPasswordFile((String) serverContext.getServerConfig().get(\"--keystore-password-file\"))\n+                    .tlsEnabled((Boolean) serverContext.getServerConfig().get(\"--enable-tls\"))\n+                    .build())\n+                    .parseConfigurationString(localCorfuEndpoint).connect();\n+        }\n+\n+        return runtime;\n+    }\n+\n+    /**\n+     * Verify current node belongs to a cluster in the topology.\n+     */\n+    private boolean clusterPresentInTopology(TopologyDescriptor topology) {\n+        localClusterDescriptor = topology.getClusterDescriptor(localEndpoint);\n+        if (localClusterDescriptor != null) {\n+            localNodeDescriptor = localClusterDescriptor.getNode(localEndpoint);\n+        }\n+\n+        return localClusterDescriptor != null && localNodeDescriptor != null;\n+    }\n+\n+    /**\n+     * Retrieve local Corfu Endpoint\n+     */\n+    private String getCorfuEndpoint(String localEndpoint, int corfuPort) {\n+        return NodeLocator.parseString(localEndpoint).getHost() + \":\" + corfuPort;\n+    }\n+\n+    /**\n+     * Retrieve Log Replication Configuration.\n+     *\n+     * This configuration represents all common parameters for the log replication, regardless of\n+     * a cluster's role.\n+     */\n+    private LogReplicationConfig getLogReplicationConfiguration(CorfuRuntime runtime) {\n+\n+        LogReplicationStreamNameTableManager replicationStreamNameTableManager =\n+                new LogReplicationStreamNameTableManager(runtime, pluginFilePath);\n+\n+        Set<String> streamsToReplicate = replicationStreamNameTableManager.getStreamsToReplicate();\n+\n+        // TODO pankti: Check if version does not match.  If if does not, create an event for site discovery to\n+        //  do a snapshot sync.\n+        // TODO(Gabriela): pending review upgrade path (changes)\n+        boolean upgraded = replicationStreamNameTableManager\n+                .isUpgraded();\n+\n+        if (upgraded) {\n+            input(new DiscoveryServiceEvent(DiscoveryServiceEvent.DiscoveryServiceEventType.UPGRADE));\n+        }\n+\n+        return new LogReplicationConfig(streamsToReplicate);\n+    }\n+\n+    /**\n+     * Register interest on Log Replication Lock.\n+     *\n+     * The node that acquires the lock will drive/lead log replication.\n+     */\n+    private void registerToLogReplicationLock() {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    LockClient lock = new LockClient(nodeId, getCorfuRuntime());\n+                    // Callback on lock acquisition or revoke\n+                    LockListener logReplicationLockListener = new LogReplicationLockListener(this);\n+                    // Register Interest on the shared Log Replication Lock\n+                    lock.registerInterest(LOCK_GROUP, LOCK_NAME, logReplicationLockListener);\n+                } catch (Exception e) {\n+                    log.error(\"Error while attempting to register interest on log replication lock {}:{}\", LOCK_GROUP, LOCK_NAME, e);\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to register interest on log replication lock.\", e);\n+            throw new UnrecoverableCorfuError(e);\n+        }\n+    }\n+\n+    /**\n+     * This method is only called on the leader node and it triggers the start of log replication\n+     *\n+     * Depending on the role of the cluster to which this leader node belongs to, it will start\n+     * as source (sender/producer) or sink (receiver).\n+     */\n+    private void startLogReplication() {\n+        if (!localNodeDescriptor.isLeader()) {\n+            log.warn(\"Current node {} is not the lead node, log replication cannot be started.\", localEndpoint);\n+            return;\n+        }\n+\n+        boolean activeCluster = localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE;\n+\n+        if (activeCluster) {\n+            log.info(\"Start as Source (sender/replicator) on node {}.\", localNodeDescriptor);\n+            // TODO(Gabriela): only one instance of CorfuReplicationManager\n+            replicationManager = new CorfuReplicationManager(topologyDescriptor, logReplicationConfig,\n+                    localNodeDescriptor, logReplicationMetadataManager, pluginFilePath, getCorfuRuntime());\n+            replicationManager.start();\n+        } else if (localNodeDescriptor.getRoleType() == ClusterRole.STANDBY) {\n+            // Standby Site : the LogReplicationServer (server handler) will initiate the LogReplicationSinkManager\n+            log.info(\"Start as Sink (receiver) on node {} \", localNodeDescriptor);\n+        } else {\n+            log.error(\"Log Replication not started on this cluster. Leader node {} belongs to cluster with {} role.\",\n+                    localEndpoint, localNodeDescriptor.getRoleType());\n+        }\n+    }\n+\n+    private void updateTopologyConfigId(boolean active) {\n+        // Required only on topology changes\n+        logReplicationServer.getSinkManager().updateTopologyConfigId(active, topologyDescriptor.getTopologyConfigId());\n+\n+        log.debug(\"Persist new topologyConfigId {}, status={}\", topologyDescriptor.getTopologyConfigId(),\n+                localNodeDescriptor.getRoleType());\n+    }\n+\n+    /**\n+     * Stop ongoing Log Replication\n+     */\n+    private void stopLogReplication() {\n+        if (localNodeDescriptor.isLeader() && localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE) {\n+            replicationManager.stop();\n+        }\n+    }\n+\n+    /**\n+     * Process lock acquisition event\n+     */\n+    public void processLockAcquire() {\n+        log.info(\"Process lock acquire event\");\n+\n+        logReplicationServer.setLeadership(true);\n+\n+        // TODO(Gabriela): confirm that start does not affect ongoing replication if it is called again..\n+        if (!localNodeDescriptor.isLeader()) {\n+            // leader transition from false to true, start log replication.\n+            localNodeDescriptor.setLeader(true);\n+            startLogReplication();\n+        }\n+    }\n+\n+    /**\n+     * Process lock release event\n+     *\n+     * Set leadership metadata and stop log replication in the event of leadership loss\n+     */\n+    public void processLockRelease() {\n+        logReplicationServer.setLeadership(false);\n+\n+        if (localNodeDescriptor.isLeader()) {\n+            stopLogReplication();\n+            localNodeDescriptor.setLeader(false);\n+        }\n+    }\n+\n+\n+    public void processSiteFlip(TopologyDescriptor newConfig) {\n+        // TODO(Nan): Check standby to active and active to standby...\n+        stopLogReplication();\n+        //TODO pankti: read the configuration again and refresh the LogReplicationConfig object\n+        replicationManager.setTopologyDescriptor(newConfig);\n+        boolean activeCluster = localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE;\n+        updateTopologyConfigId(activeCluster);\n+        startLogReplication();\n+    }\n+\n+    public void processSiteChangeNotification(DiscoveryServiceEvent event) {\n+        // Stale notification, skip\n+        if (event.getTopologyConfig().getTopologyConfigID() < getReplicationManager().getTopologyDescriptor().getTopologyConfigId()) {\n+            log.debug(\"Stale Topology Change Notification, current={}, received={}\", topologyDescriptor.getTopologyConfigId(), event.getTopologyConfig());\n+            return;\n+        }\n+\n+        TopologyDescriptor newConfig = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+        if (newConfig.getTopologyConfigId() == getReplicationManager().getTopologyDescriptor().getTopologyConfigId()) {\n+            if (localNodeDescriptor.getRoleType() == ClusterRole.STANDBY) {\n+                return;\n+            }\n+\n+            // If the current node is active, compare with the current siteConfig, see if there are addition/removal standbys\n+            getReplicationManager().processStandbyChange(newConfig);\n+        } else {\n+            processSiteFlip(newConfig);\n+        }\n+    }\n+\n+    /***\n+     * The standby cluster's leader change can lead to connection loss.\n+     * If the current node is not the active cluster's leader, discard the notification.\n+     * If the current node is the the active cluster's leader that is is responsible for the current\n+     * replication job, will restart the replication with the remote cluster.\n+     *\n+     * @param event\n+     */\n+    private void processConnectionLoss(DiscoveryServiceEvent event) {\n+\n+        if (!localNodeDescriptor.isLeader() || localNodeDescriptor.getRoleType() != ClusterRole.ACTIVE) {\n+            return;\n+        }\n+\n+        replicationManager.restart(event.getRemoteSiteInfo());\n+    }\n+\n+    /***\n+     * After an upgrade, the active site should perform a snapshot sync\n+     */\n+    private void processUpgrade(DiscoveryServiceEvent event) {\n+        if (localNodeDescriptor.isLeader() && localNodeDescriptor.getRoleType() == ClusterRole.ACTIVE) {\n+            // TODO pankti: is this correct?\n+            replicationManager.restart(event.getRemoteSiteInfo());\n+        }\n+    }\n+\n+    /**\n+     * Process event\n+     */\n+    public void processEvent(DiscoveryServiceEvent event) {\n+        switch (event.type) {\n+            case ACQUIRE_LOCK:\n+                processLockAcquire();\n+                break;\n+\n+            case RELEASE_LOCK:\n+                processLockRelease();\n+                break;\n+\n+            case DISCOVERY_SITE:\n+                processSiteChangeNotification(event);\n+                break;\n+\n+            case UPGRADE:\n+                processUpgrade(event);\n+                break;\n+\n+            default:\n+                log.error(\"wrong event type {}\", event);\n+        }\n+    }\n+\n+    public synchronized void input(DiscoveryServiceEvent event) {\n+        eventQueue.add(event);\n+        notifyAll();\n+    }\n+\n+    @Override\n+    public void updateSiteConfig(LogReplicationClusterInfo.TopologyConfigurationMsg topologyConfig) {\n+        input(new DiscoveryServiceEvent(DiscoveryServiceEvent.DiscoveryServiceEventType.DISCOVERY_SITE, topologyConfig));\n+    }\n+\n+    /**\n+     * Query the current all replication stream log tail and remeber the max\n+     * and query each standbySite information according to the ackInformation decide all manay total\n+     * msg needs to send out.\n+     */\n+    @Override\n+    public void prepareSiteRoleChange() {\n+        replicationManager.prepareSiteRoleChange();\n+    }\n+\n+    /**\n+     * Query the current all replication stream log tail and calculate the number of messages to be sent.\n+     * If the max tail has changed, give 0%. Otherwise,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 497}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI1NzkwMA==", "bodyText": "not used", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447257900", "createdAt": "2020-06-29T21:14:12Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/TopologyDescriptor.java", "diffHunk": "@@ -0,0 +1,135 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterConfigurationMsg;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * This class represents a view of a Multi-Cluster/Site Topology,\n+ * where one cluster is the active/primary and n cluster's are standby's (backups).\n+ */\n+@Slf4j\n+public class TopologyDescriptor {\n+\n+    // Represents a state of the topology configuration (a topology epoch)\n+    @Getter\n+    private long topologyConfigId;\n+\n+    @Getter\n+    private ClusterDescriptor activeCluster;\n+\n+    @Getter\n+    private Map<String, ClusterDescriptor> standbyClusters;\n+\n+    @Getter\n+    private String certs;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param topologyMessage\n+     */\n+    public TopologyDescriptor(TopologyConfigurationMsg topologyMessage) {\n+        this.topologyConfigId = topologyMessage.getTopologyConfigID();\n+        this.certs = topologyMessage.getCerts();\n+        standbyClusters = new HashMap<>();\n+        for (ClusterConfigurationMsg clusterConfig : topologyMessage.getClustersList()) {\n+            ClusterDescriptor siteInfo = new ClusterDescriptor(clusterConfig);\n+            if (clusterConfig.getRole() == ClusterRole.ACTIVE) {\n+                activeCluster = siteInfo;\n+            } else if (clusterConfig.getRole() == ClusterRole.STANDBY) {\n+                addStandbySite(siteInfo);\n+            }\n+        }\n+    }\n+\n+    public TopologyDescriptor(long siteConfigID, ClusterDescriptor primarySite, Map<String, ClusterDescriptor> standbySites) {\n+        this.topologyConfigId = siteConfigID;\n+        this.activeCluster = primarySite;\n+        this.standbyClusters = standbySites;\n+    }\n+\n+    public TopologyConfigurationMsg convertToMessage() {\n+        ArrayList<ClusterConfigurationMsg> clustersConfigs = new ArrayList<>();\n+        clustersConfigs.add((activeCluster.convertToMessage()));\n+\n+        for (ClusterDescriptor siteInfo : standbyClusters.values()) {\n+            clustersConfigs.add(siteInfo.convertToMessage());\n+        }\n+\n+        TopologyConfigurationMsg topologyConfig = TopologyConfigurationMsg.newBuilder()\n+                .setTopologyConfigID(topologyConfigId)\n+                .addAllClusters(clustersConfigs).build();\n+\n+        return topologyConfig;\n+    }\n+\n+    public NodeDescriptor getNodeInfo(String endpoint) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI1ODgyNA==", "bodyText": "Right  now this will continue indefinitely in case of constant failures, why do we never want  to timeout?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447258824", "createdAt": "2020-06-29T21:16:05Z", "author": {"login": "PavelZaytsev"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java", "diffHunk": "@@ -0,0 +1,513 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationServer;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.CorfuReplicationClusterManagerAdapter;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+\n+import org.corfudb.infrastructure.logreplication.utils.LogReplicationStreamNameTableManager;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.util.NodeLocator;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+import org.corfudb.utils.lock.LockClient;\n+import org.corfudb.utils.lock.LockListener;\n+\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class represents the Replication Discovery Service.\n+ *\n+ * It manages the following:\n+ *\n+ * - Topology discovery (active and standby's)\n+ * - Lock Acquisition (leader election)\n+ * - Log Replication Configuration (streams to replicate)\n+ */\n+@Slf4j\n+public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicationDiscoveryServiceAdapter {\n+\n+    /**\n+     * Bookkeeping the topologyConfigId, version number and other log replication state information.\n+     * It is backed by a corfu store table.\n+     **/\n+    @Getter\n+    private LogReplicationMetadataManager logReplicationMetadataManager;\n+\n+    /**\n+     * Lock-related configuration parameters\n+     */\n+    private static final String LOCK_GROUP = \"Log_Replication_Group\";\n+    private static final String LOCK_NAME = \"Log_Replication_Lock\";\n+\n+    /**\n+     * Used by the active cluster\n+     */\n+    @Getter\n+    private CorfuReplicationManager replicationManager;\n+\n+    /**\n+     * Adapter for cluster discovery service\n+     */\n+    @Getter\n+    private CorfuReplicationClusterManagerAdapter clusterManagerAdapter;\n+\n+    /**\n+     * Defines the topology of the multi-cluster setting, which is discovered through the Cluster Manager\n+     */\n+    private TopologyDescriptor topologyDescriptor;\n+\n+    /**\n+     * Defines the cluster to which this node belongs to.\n+     */\n+    private ClusterDescriptor localClusterDescriptor;\n+\n+    /**\n+     * Current node's endpoint\n+     */\n+    private final String localEndpoint;\n+\n+    /**\n+     * Local host\n+     */\n+    private final String localHost;\n+\n+    /**\n+     * Current node information\n+     */\n+    private NodeDescriptor localNodeDescriptor;\n+\n+    /**\n+     * Unique node identifier\n+     */\n+    private final UUID nodeId;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<DiscoveryServiceEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private CompletableFuture<LogReplicationContext> discoveryCallback;\n+\n+    private String pluginFilePath;\n+\n+    private LogReplicationConfig logReplicationConfig;\n+\n+    private LogReplicationServer logReplicationServer;\n+\n+    private boolean shouldRun = true;\n+\n+    private ServerContext serverContext;\n+\n+    private String localCorfuEndpoint;\n+\n+    private CorfuRuntime runtime;\n+\n+    /**\n+     * Constructor Discovery Service\n+     *\n+     * @param serverContext\n+     * @param discoveryCallback\n+     */\n+    public CorfuReplicationDiscoveryService(ServerContext serverContext, CorfuReplicationClusterManagerAdapter clusterManagerAdapter,\n+                                            CompletableFuture<LogReplicationContext> discoveryCallback) {\n+        this.clusterManagerAdapter = clusterManagerAdapter;\n+        this.nodeId = serverContext.getNodeId();\n+        this.serverContext = serverContext;\n+        this.localEndpoint = serverContext.getLocalEndpoint();\n+        this.localHost =  NodeLocator.parseString(serverContext.getLocalEndpoint()).getHost();\n+        this.pluginFilePath = serverContext.getPluginConfigFilePath();\n+        this.discoveryCallback = discoveryCallback;\n+    }\n+\n+    public void run() {\n+        try {\n+            startDiscovery();\n+\n+            while (shouldRun) {\n+                try {\n+                    DiscoveryServiceEvent event = eventQueue.take();\n+                    processEvent(event);\n+                } catch (Exception e) {\n+                    log.error(\"Caught an exception. Stop discovery service.\", e);\n+                    shouldRun = false;\n+                    stopLogReplication();\n+                    if (e instanceof InterruptedException) {\n+                        Thread.interrupted();\n+                    }\n+                }\n+            }\n+        } catch (LogReplicationDiscoveryServiceException e) {\n+            log.error(\"Exceptionally terminate Log Replication Discovery Service\", e);\n+            discoveryCallback.completeExceptionally(e);\n+        } catch (Exception e) {\n+            log.error(\"Unhandled exception caught during log replication service discovery\", e);\n+        } finally {\n+            if (runtime != null) {\n+                runtime.shutdown();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * On first access start topology discovery.\n+     *\n+     * On discovery, process the topology information and fetch log replication configuration\n+     * (streams to replicate) required by an active and standby site before starting\n+     * log replication.\n+     */\n+    private void startDiscovery() throws LogReplicationDiscoveryServiceException {\n+\n+        try {\n+            log.info(\"Connecting to Cluster Manager adapter...\");\n+\n+            this.clusterManagerAdapter.connect(this);\n+\n+            log.info(\"Fetch topology from Cluster Manager...\");\n+\n+            topologyDescriptor = new TopologyDescriptor(clusterManagerAdapter.fetchTopology());\n+\n+            // Health check - confirm this node belongs to a cluster in the topology\n+            if (clusterPresentInTopology(topologyDescriptor)) {\n+\n+                log.info(\"Node[{}] belongs to cluster, descriptor={}\", localEndpoint,\n+                        localClusterDescriptor);\n+\n+                LogReplicationContext context = buildLogReplicationContext();\n+\n+                // Unblock server initialization retrieving context: topology + configuration\n+                discoveryCallback.complete(context);\n+\n+                registerToLogReplicationLock();\n+            } else {\n+                // If a cluster descriptor is not found, this node does not belong to any topology... raise an exception\n+                String message = String.format(\"Node[%s] does not belong to any Cluster provided by the discovery service, topology=%s\",\n+                        localEndpoint, topologyDescriptor);\n+                log.warn(message);\n+                throw new LogReplicationDiscoveryServiceException(message);\n+            }\n+        } catch (Exception e) {\n+            String message = \"Caught exception while fetching topology. Log Replication cannot start.\";\n+            log.error(message, e);\n+            throw new LogReplicationDiscoveryServiceException(message);\n+        }\n+    }\n+\n+    /**\n+     * Construct common log replication context.\n+     */\n+    private LogReplicationContext buildLogReplicationContext() {\n+        // Through LogReplicationConfigAdapter retrieve system-specific configurations (including streams to replicate)\n+        logReplicationConfig = getLogReplicationConfiguration(getCorfuRuntime());\n+\n+        logReplicationMetadataManager = new LogReplicationMetadataManager(getCorfuRuntime(),\n+                topologyDescriptor.getTopologyConfigId(), localClusterDescriptor.getClusterId());\n+\n+        logReplicationServer = new LogReplicationServer(serverContext, logReplicationConfig, logReplicationMetadataManager,\n+                localCorfuEndpoint);\n+        logReplicationServer.setActive(localClusterDescriptor.getRole().equals(ClusterRole.ACTIVE));\n+\n+        return new LogReplicationContext(logReplicationConfig, topologyDescriptor, logReplicationServer, localCorfuEndpoint);\n+    }\n+\n+    /**\n+     * Retrieve a Corfu Runtime to connect to the local Corfu Datastore.\n+     */\n+    private CorfuRuntime getCorfuRuntime() {\n+        if (runtime == null) {\n+            localCorfuEndpoint = getCorfuEndpoint(localHost, localClusterDescriptor.getCorfuPort());\n+            log.debug(\"Connecting to local Corfu {}\", localCorfuEndpoint);\n+            runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()\n+                    .trustStore((String) serverContext.getServerConfig().get(\"--truststore\"))\n+                    .tsPasswordFile((String) serverContext.getServerConfig().get(\"--truststore-password-file\"))\n+                    .keyStore((String) serverContext.getServerConfig().get(\"--keystore\"))\n+                    .ksPasswordFile((String) serverContext.getServerConfig().get(\"--keystore-password-file\"))\n+                    .tlsEnabled((Boolean) serverContext.getServerConfig().get(\"--enable-tls\"))\n+                    .build())\n+                    .parseConfigurationString(localCorfuEndpoint).connect();\n+        }\n+\n+        return runtime;\n+    }\n+\n+    /**\n+     * Verify current node belongs to a cluster in the topology.\n+     */\n+    private boolean clusterPresentInTopology(TopologyDescriptor topology) {\n+        localClusterDescriptor = topology.getClusterDescriptor(localEndpoint);\n+        if (localClusterDescriptor != null) {\n+            localNodeDescriptor = localClusterDescriptor.getNode(localEndpoint);\n+        }\n+\n+        return localClusterDescriptor != null && localNodeDescriptor != null;\n+    }\n+\n+    /**\n+     * Retrieve local Corfu Endpoint\n+     */\n+    private String getCorfuEndpoint(String localEndpoint, int corfuPort) {\n+        return NodeLocator.parseString(localEndpoint).getHost() + \":\" + corfuPort;\n+    }\n+\n+    /**\n+     * Retrieve Log Replication Configuration.\n+     *\n+     * This configuration represents all common parameters for the log replication, regardless of\n+     * a cluster's role.\n+     */\n+    private LogReplicationConfig getLogReplicationConfiguration(CorfuRuntime runtime) {\n+\n+        LogReplicationStreamNameTableManager replicationStreamNameTableManager =\n+                new LogReplicationStreamNameTableManager(runtime, pluginFilePath);\n+\n+        Set<String> streamsToReplicate = replicationStreamNameTableManager.getStreamsToReplicate();\n+\n+        // TODO pankti: Check if version does not match.  If if does not, create an event for site discovery to\n+        //  do a snapshot sync.\n+        // TODO(Gabriela): pending review upgrade path (changes)\n+        boolean upgraded = replicationStreamNameTableManager\n+                .isUpgraded();\n+\n+        if (upgraded) {\n+            input(new DiscoveryServiceEvent(DiscoveryServiceEvent.DiscoveryServiceEventType.UPGRADE));\n+        }\n+\n+        return new LogReplicationConfig(streamsToReplicate);\n+    }\n+\n+    /**\n+     * Register interest on Log Replication Lock.\n+     *\n+     * The node that acquires the lock will drive/lead log replication.\n+     */\n+    private void registerToLogReplicationLock() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8"}, "originalPosition": 294}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "69906091e1d34b1241cf0366c1fd60ac2a8b9e7c", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/69906091e1d34b1241cf0366c1fd60ac2a8b9e7c", "committedDate": "2020-06-29T21:36:03Z", "message": "Addressing Comments / Review"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d955f519bca845eef0a189b25ee2d0c2196739c8", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/d955f519bca845eef0a189b25ee2d0c2196739c8", "committedDate": "2020-06-29T19:30:25Z", "message": "Addressing Comments / Review"}, "afterCommit": {"oid": "69906091e1d34b1241cf0366c1fd60ac2a8b9e7c", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/69906091e1d34b1241cf0366c1fd60ac2a8b9e7c", "committedDate": "2020-06-29T21:36:03Z", "message": "Addressing Comments / Review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NDA0Mzk1", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-439404395", "createdAt": "2020-06-29T18:39:15Z", "commit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQxODozOToxNlrOGqdaUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMjozMzowNlrOGqkx4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE3NTI0OA==", "bodyText": "It is possible to do more transition here as we know the state, each transition is just a few instructions, there is no need to switch the context and generate a new task and put in the eventQue.\nif (newState is the expected happy path next state, and it is not the final state) doNext transition. Something like that.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447175248", "createdAt": "2020-06-29T18:39:16Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java", "diffHunk": "@@ -0,0 +1,295 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeStateType;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.StoppedState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.UnrecoverableState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.WaitingForConnectionsState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.IllegalTransitionException;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.NegotiatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.ReplicatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.VerifyingRemoteLeaderState;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * Runtime to connect to a remote Corfu Log Replication Cluster.\n+ *\n+ * This class represents the Log Replication Runtime Finite State Machine, which defines\n+ * all states in which the leader node on the active cluster can be.\n+ *\n+ *\n+ *                                                       R-LEADER_LOSS\n+ *                                             +-------------------------------+\n+ *                              ON_CONNECTION  |                               |    ON_CONNECTION_DOWN\n+ *                                    UP       |       ON_CONNECTION_DOWN      |       (NON_LEADER)\n+ *                                    +----+   |          (R-LEADER)           |\n+ *                                    |    |   |   +-----------------------+   |        +-----+\n+ *                                    |    |   |   |                       |   |        |     |\n+ * +---------------+  ON_CONNECTION  ++----v---v---v--+                  +-+---+--------+-+   |\n+ * |               |       UP        |                |  R-LEADER_FOUND  |                <---+\n+ * |    WAITING    +---------------->+    VERIFYING   +------------------>                +---+\n+ * |      FOR      |                 |     REMOTE     |                  |   NEGOTIATING  |   |  NEGOTIATION_FAILED\n+ * |  CONNECTIONS  +<----------------+     LEADER     |                  |                <---+       (ALARM)\n+ * |               |  ON_CONNECTION  |                +<-----------+     |                +----+\n+ * +---------------+      DOWN       +-^----+---^----++            |     +-------+-----^--+    |\n+ *                       (ALL)         |    |   |    |             |             |     |       |\n+ *                                     |    |   |    |        R-LEADER_LOSS      |     +-------+\n+ *                                     +----+   +----+             |             |  ON_CONNECTION_UP\n+ *                              ON_CONNECTION     R-LEADER_NOT     |             |    (NON-LEADER)\n+ *                                  DOWN              FOUND        |             |\n+ *                                (NOT ALL)                        |     NEGOTIATE_COMPLETE\n+ *                                                                 |             |\n+ *                                                           ON_CONNECTION       |   ON_CONNECTION_UP\n+ *                                                               DOWN            |     (NON-LEADER)\n+ *                                                             (R-LEADER)        |      +-----+\n+ *                                                                 |             |      |     |\n+ *                                                                 |     +-------v------+-+   |\n+ *            +---------------+      ALL STATES                    +-----+                <---+\n+ *            |               |                                          |                |\n+ *            |   STOPPED     <---- L-LEADER_LOSS                        |  REPLICATING   |\n+ *            |               |                     SITE FLIP <-----     |                |\n+ *            |               |                                          |                +----+\n+ *            +---------------+                                          +--------------^-+    |\n+ *                                                                                      |      |\n+ *                                                                                      +------+\n+ *            +---------------+     ALL STATES\n+ *            |               |                                                     ON_CONNECTION_DOWN\n+ *            | UNRECOVERABLE <---- ON_ERROR                                           (NON-LEADER)\n+ *            |    STATE      |\n+ *            |               |\n+ *            +---------------+\n+ *\n+ *\n+ * States:\n+ * ------\n+ *\n+ * - WAITING_FOR_CONNECTIVITY    :: initial state, waiting for any connection to remote cluster to be established.\n+ * - VERIFYING_REMOTE_LEADER     :: verifying the leader endpoint on remote cluster (querying all connected nodes)\n+ * - NEGOTIATING                 :: negotiating against the leader endpoint\n+ * - REPLICATING                 :: replicating data to remote cluster through the leader endpoint\n+ * - STOPPED                     :: stop state machine, no error, just lost leadership so replication stops from this node\n+ * - UNRECOVERABLE_STATE         :: error state, unrecoverable error reported by replication, transport or cluster manager, despite\n+ *                                  being the leader node.\n+ *\n+ *\n+ * Events / Transitions:\n+ * --------------------\n+ *\n+ * - ON_CONNECTION_UP           :: connection to a remote endpoint comes UP\n+ * - ON_CONNECTION_DOWN         :: connection to a remote endpoint comes DOWN\n+ * - REMOTE_LEADER_NOT_FOUND,   :: remote leader not found\n+ * - REMOTE_LEADER_FOUND,       :: remote leader found\n+ * - REMOTE_LEADER_LOSS,        :: remote Leader Lost (remote node reports it is no longer the leader)\n+ * - LOCAL_LEADER_LOSS          :: local node looses leadership\n+ * - NEGOTIATION_COMPLETE,      :: negotiation succeeded and completed\n+ * - NEGOTIATION_FAILED,        :: negotiation failed\n+ * - STOPPED                    :: stop log replication server (fatal state)\n+ *\n+ * @author amartinezman\n+ *\n+ */\n+@Slf4j\n+public class CorfuLogReplicationRuntime {\n+\n+    // TODO(Gabriela): add site_flip (cluster_role_flip) event... probably we need a new state called finishing_ongoing_replication... and go to to stopped...\n+\n+    public static final int DEFAULT_TIMEOUT = 5000;\n+\n+    /**\n+     * Current state of the FSM.\n+     */\n+    private volatile LogReplicationRuntimeState state;\n+\n+    /**\n+     * Map of all Log Replication Communication FSM States (reuse single instance for each state)\n+     */\n+    @Getter\n+    private Map<LogReplicationRuntimeStateType, LogReplicationRuntimeState> states = new HashMap<>();\n+\n+    /**\n+     * Executor service for FSM state tasks\n+     */\n+    private ExecutorService communicationFSMWorkers;\n+\n+    /**\n+     * Executor service for FSM event queue consume\n+     */\n+    private ExecutorService communicationFSMConsumer;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<LogReplicationRuntimeEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private final LogReplicationClientRouter router;\n+    private final LogReplicationMetadataManager metadataManager;\n+    private final LogReplicationSourceManager sourceManager;\n+    private volatile Set<String> connectedEndpoints = ConcurrentHashMap.newKeySet();\n+    private volatile Optional<String> leaderEndpoint = Optional.empty();\n+    public final String remoteClusterId;\n+\n+    /**\n+     * Default Constructor\n+     */\n+    public CorfuLogReplicationRuntime(LogReplicationRuntimeParameters parameters, LogReplicationMetadataManager metadataManager) {\n+        this.remoteClusterId = parameters.getRemoteClusterDescriptor().getClusterId();\n+        this.metadataManager = metadataManager;\n+        this.router = new LogReplicationClientRouter(parameters, this);\n+        this.router.addClient(new LogReplicationHandler());\n+        this.sourceManager = new LogReplicationSourceManager(parameters, new LogReplicationClient(router, remoteClusterId));\n+        this.communicationFSMWorkers = Executors.newSingleThreadExecutor(new\n+                ThreadFactoryBuilder().setNameFormat(\"runtime-fsm-worker\").build());\n+        this.communicationFSMConsumer = Executors.newSingleThreadExecutor(new\n+                ThreadFactoryBuilder().setNameFormat(\"runtime-fsm-consumer\").build());\n+\n+        initializeStates();\n+        this.state = states.get(LogReplicationRuntimeStateType.WAITING_FOR_CONNECTIVITY);\n+\n+        log.info(\"Log Replication Runtime State Machine initialized\");\n+    }\n+\n+    /**\n+     * Start Log Replication Communication FSM\n+     */\n+    public void start() {\n+        // Start Consumer Thread for this state machine (dedicated thread for event consumption)\n+        communicationFSMConsumer.submit(this::consume);\n+        router.connect();\n+    }\n+\n+    /**\n+     * Initialize all states for the Log Replication Runtime FSM.\n+     */\n+    private void initializeStates() {\n+        /*\n+         * Log Replication Runtime State instances are kept in a map to be reused in transitions, avoid creating one\n+         * per every transition (reduce GC cycles).\n+         */\n+        states.put(LogReplicationRuntimeStateType.WAITING_FOR_CONNECTIVITY, new WaitingForConnectionsState(this));\n+        states.put(LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER, new VerifyingRemoteLeaderState(this, communicationFSMWorkers, router));\n+        states.put(LogReplicationRuntimeStateType.NEGOTIATING, new NegotiatingState(this, communicationFSMWorkers, router, metadataManager));\n+        states.put(LogReplicationRuntimeStateType.REPLICATING, new ReplicatingState(this, sourceManager));\n+        states.put(LogReplicationRuntimeStateType.STOPPED, new StoppedState(sourceManager));\n+        states.put(LogReplicationRuntimeStateType.UNRECOVERABLE, new UnrecoverableState());\n+    }\n+\n+    /**\n+     * Input function of the FSM.\n+     *\n+     * This method enqueues runtime events for further processing.\n+     *\n+     * @param event LogReplicationRuntimeEvent to process.\n+     */\n+    public synchronized void input(LogReplicationRuntimeEvent event) {\n+        try {\n+            if (state.getType().equals(LogReplicationRuntimeStateType.STOPPED)) {\n+                // Not accepting events, in stopped state\n+                return;\n+            }\n+            eventQueue.put(event);\n+        } catch (InterruptedException ex) {\n+            log.error(\"Log Replication interrupted Exception: \", ex);\n+        }\n+    }\n+\n+    /**\n+     * Consumer of the eventQueue.\n+     * <p>\n+     * This method consumes the log replication events and does the state transition.\n+     */\n+    private void consume() {\n+        try {\n+            if (state.getType() == LogReplicationRuntimeStateType.STOPPED) {\n+                log.info(\"Log Replication Communication State Machine has been stopped. No more events will be processed.\");\n+                return;\n+            }\n+\n+            //  Block until an event shows up in the queue.\n+            LogReplicationRuntimeEvent event = eventQueue.take();\n+\n+            try {\n+                LogReplicationRuntimeState newState = state.processEvent(event);\n+                transition(state, newState);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 228}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI1OTY3NQ==", "bodyText": "Now, for each standby, it has two state machines, one used by logReplicationRuntime, one is for LogReplicationState. I am concerned about the out of sync of these two state machines.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447259675", "createdAt": "2020-06-29T21:18:01Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java", "diffHunk": "@@ -0,0 +1,295 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeStateType;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.StoppedState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.UnrecoverableState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.WaitingForConnectionsState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.IllegalTransitionException;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.NegotiatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.ReplicatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.VerifyingRemoteLeaderState;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * Runtime to connect to a remote Corfu Log Replication Cluster.\n+ *\n+ * This class represents the Log Replication Runtime Finite State Machine, which defines\n+ * all states in which the leader node on the active cluster can be.\n+ *\n+ *\n+ *                                                       R-LEADER_LOSS\n+ *                                             +-------------------------------+\n+ *                              ON_CONNECTION  |                               |    ON_CONNECTION_DOWN\n+ *                                    UP       |       ON_CONNECTION_DOWN      |       (NON_LEADER)\n+ *                                    +----+   |          (R-LEADER)           |\n+ *                                    |    |   |   +-----------------------+   |        +-----+\n+ *                                    |    |   |   |                       |   |        |     |\n+ * +---------------+  ON_CONNECTION  ++----v---v---v--+                  +-+---+--------+-+   |\n+ * |               |       UP        |                |  R-LEADER_FOUND  |                <---+\n+ * |    WAITING    +---------------->+    VERIFYING   +------------------>                +---+\n+ * |      FOR      |                 |     REMOTE     |                  |   NEGOTIATING  |   |  NEGOTIATION_FAILED\n+ * |  CONNECTIONS  +<----------------+     LEADER     |                  |                <---+       (ALARM)\n+ * |               |  ON_CONNECTION  |                +<-----------+     |                +----+\n+ * +---------------+      DOWN       +-^----+---^----++            |     +-------+-----^--+    |\n+ *                       (ALL)         |    |   |    |             |             |     |       |\n+ *                                     |    |   |    |        R-LEADER_LOSS      |     +-------+\n+ *                                     +----+   +----+             |             |  ON_CONNECTION_UP\n+ *                              ON_CONNECTION     R-LEADER_NOT     |             |    (NON-LEADER)\n+ *                                  DOWN              FOUND        |             |\n+ *                                (NOT ALL)                        |     NEGOTIATE_COMPLETE\n+ *                                                                 |             |\n+ *                                                           ON_CONNECTION       |   ON_CONNECTION_UP\n+ *                                                               DOWN            |     (NON-LEADER)\n+ *                                                             (R-LEADER)        |      +-----+\n+ *                                                                 |             |      |     |\n+ *                                                                 |     +-------v------+-+   |\n+ *            +---------------+      ALL STATES                    +-----+                <---+\n+ *            |               |                                          |                |\n+ *            |   STOPPED     <---- L-LEADER_LOSS                        |  REPLICATING   |\n+ *            |               |                     SITE FLIP <-----     |                |\n+ *            |               |                                          |                +----+\n+ *            +---------------+                                          +--------------^-+    |\n+ *                                                                                      |      |\n+ *                                                                                      +------+\n+ *            +---------------+     ALL STATES\n+ *            |               |                                                     ON_CONNECTION_DOWN\n+ *            | UNRECOVERABLE <---- ON_ERROR                                           (NON-LEADER)\n+ *            |    STATE      |\n+ *            |               |\n+ *            +---------------+\n+ *\n+ *\n+ * States:\n+ * ------\n+ *\n+ * - WAITING_FOR_CONNECTIVITY    :: initial state, waiting for any connection to remote cluster to be established.\n+ * - VERIFYING_REMOTE_LEADER     :: verifying the leader endpoint on remote cluster (querying all connected nodes)\n+ * - NEGOTIATING                 :: negotiating against the leader endpoint\n+ * - REPLICATING                 :: replicating data to remote cluster through the leader endpoint\n+ * - STOPPED                     :: stop state machine, no error, just lost leadership so replication stops from this node\n+ * - UNRECOVERABLE_STATE         :: error state, unrecoverable error reported by replication, transport or cluster manager, despite\n+ *                                  being the leader node.\n+ *\n+ *\n+ * Events / Transitions:\n+ * --------------------\n+ *\n+ * - ON_CONNECTION_UP           :: connection to a remote endpoint comes UP\n+ * - ON_CONNECTION_DOWN         :: connection to a remote endpoint comes DOWN\n+ * - REMOTE_LEADER_NOT_FOUND,   :: remote leader not found\n+ * - REMOTE_LEADER_FOUND,       :: remote leader found\n+ * - REMOTE_LEADER_LOSS,        :: remote Leader Lost (remote node reports it is no longer the leader)\n+ * - LOCAL_LEADER_LOSS          :: local node looses leadership\n+ * - NEGOTIATION_COMPLETE,      :: negotiation succeeded and completed\n+ * - NEGOTIATION_FAILED,        :: negotiation failed\n+ * - STOPPED                    :: stop log replication server (fatal state)\n+ *\n+ * @author amartinezman\n+ *\n+ */\n+@Slf4j\n+public class CorfuLogReplicationRuntime {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI3NDgyNA==", "bodyText": "I am just out of curiosity. What is the difference between this model and the thread running blocking on the eventQue?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447274824", "createdAt": "2020-06-29T21:50:59Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java", "diffHunk": "@@ -0,0 +1,295 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeStateType;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.StoppedState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.UnrecoverableState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.WaitingForConnectionsState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.IllegalTransitionException;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.NegotiatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.ReplicatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.VerifyingRemoteLeaderState;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * Runtime to connect to a remote Corfu Log Replication Cluster.\n+ *\n+ * This class represents the Log Replication Runtime Finite State Machine, which defines\n+ * all states in which the leader node on the active cluster can be.\n+ *\n+ *\n+ *                                                       R-LEADER_LOSS\n+ *                                             +-------------------------------+\n+ *                              ON_CONNECTION  |                               |    ON_CONNECTION_DOWN\n+ *                                    UP       |       ON_CONNECTION_DOWN      |       (NON_LEADER)\n+ *                                    +----+   |          (R-LEADER)           |\n+ *                                    |    |   |   +-----------------------+   |        +-----+\n+ *                                    |    |   |   |                       |   |        |     |\n+ * +---------------+  ON_CONNECTION  ++----v---v---v--+                  +-+---+--------+-+   |\n+ * |               |       UP        |                |  R-LEADER_FOUND  |                <---+\n+ * |    WAITING    +---------------->+    VERIFYING   +------------------>                +---+\n+ * |      FOR      |                 |     REMOTE     |                  |   NEGOTIATING  |   |  NEGOTIATION_FAILED\n+ * |  CONNECTIONS  +<----------------+     LEADER     |                  |                <---+       (ALARM)\n+ * |               |  ON_CONNECTION  |                +<-----------+     |                +----+\n+ * +---------------+      DOWN       +-^----+---^----++            |     +-------+-----^--+    |\n+ *                       (ALL)         |    |   |    |             |             |     |       |\n+ *                                     |    |   |    |        R-LEADER_LOSS      |     +-------+\n+ *                                     +----+   +----+             |             |  ON_CONNECTION_UP\n+ *                              ON_CONNECTION     R-LEADER_NOT     |             |    (NON-LEADER)\n+ *                                  DOWN              FOUND        |             |\n+ *                                (NOT ALL)                        |     NEGOTIATE_COMPLETE\n+ *                                                                 |             |\n+ *                                                           ON_CONNECTION       |   ON_CONNECTION_UP\n+ *                                                               DOWN            |     (NON-LEADER)\n+ *                                                             (R-LEADER)        |      +-----+\n+ *                                                                 |             |      |     |\n+ *                                                                 |     +-------v------+-+   |\n+ *            +---------------+      ALL STATES                    +-----+                <---+\n+ *            |               |                                          |                |\n+ *            |   STOPPED     <---- L-LEADER_LOSS                        |  REPLICATING   |\n+ *            |               |                     SITE FLIP <-----     |                |\n+ *            |               |                                          |                +----+\n+ *            +---------------+                                          +--------------^-+    |\n+ *                                                                                      |      |\n+ *                                                                                      +------+\n+ *            +---------------+     ALL STATES\n+ *            |               |                                                     ON_CONNECTION_DOWN\n+ *            | UNRECOVERABLE <---- ON_ERROR                                           (NON-LEADER)\n+ *            |    STATE      |\n+ *            |               |\n+ *            +---------------+\n+ *\n+ *\n+ * States:\n+ * ------\n+ *\n+ * - WAITING_FOR_CONNECTIVITY    :: initial state, waiting for any connection to remote cluster to be established.\n+ * - VERIFYING_REMOTE_LEADER     :: verifying the leader endpoint on remote cluster (querying all connected nodes)\n+ * - NEGOTIATING                 :: negotiating against the leader endpoint\n+ * - REPLICATING                 :: replicating data to remote cluster through the leader endpoint\n+ * - STOPPED                     :: stop state machine, no error, just lost leadership so replication stops from this node\n+ * - UNRECOVERABLE_STATE         :: error state, unrecoverable error reported by replication, transport or cluster manager, despite\n+ *                                  being the leader node.\n+ *\n+ *\n+ * Events / Transitions:\n+ * --------------------\n+ *\n+ * - ON_CONNECTION_UP           :: connection to a remote endpoint comes UP\n+ * - ON_CONNECTION_DOWN         :: connection to a remote endpoint comes DOWN\n+ * - REMOTE_LEADER_NOT_FOUND,   :: remote leader not found\n+ * - REMOTE_LEADER_FOUND,       :: remote leader found\n+ * - REMOTE_LEADER_LOSS,        :: remote Leader Lost (remote node reports it is no longer the leader)\n+ * - LOCAL_LEADER_LOSS          :: local node looses leadership\n+ * - NEGOTIATION_COMPLETE,      :: negotiation succeeded and completed\n+ * - NEGOTIATION_FAILED,        :: negotiation failed\n+ * - STOPPED                    :: stop log replication server (fatal state)\n+ *\n+ * @author amartinezman\n+ *\n+ */\n+@Slf4j\n+public class CorfuLogReplicationRuntime {\n+\n+    // TODO(Gabriela): add site_flip (cluster_role_flip) event... probably we need a new state called finishing_ongoing_replication... and go to to stopped...\n+\n+    public static final int DEFAULT_TIMEOUT = 5000;\n+\n+    /**\n+     * Current state of the FSM.\n+     */\n+    private volatile LogReplicationRuntimeState state;\n+\n+    /**\n+     * Map of all Log Replication Communication FSM States (reuse single instance for each state)\n+     */\n+    @Getter\n+    private Map<LogReplicationRuntimeStateType, LogReplicationRuntimeState> states = new HashMap<>();\n+\n+    /**\n+     * Executor service for FSM state tasks\n+     */\n+    private ExecutorService communicationFSMWorkers;\n+\n+    /**\n+     * Executor service for FSM event queue consume\n+     */\n+    private ExecutorService communicationFSMConsumer;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<LogReplicationRuntimeEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    private final LogReplicationClientRouter router;\n+    private final LogReplicationMetadataManager metadataManager;\n+    private final LogReplicationSourceManager sourceManager;\n+    private volatile Set<String> connectedEndpoints = ConcurrentHashMap.newKeySet();\n+    private volatile Optional<String> leaderEndpoint = Optional.empty();\n+    public final String remoteClusterId;\n+\n+    /**\n+     * Default Constructor\n+     */\n+    public CorfuLogReplicationRuntime(LogReplicationRuntimeParameters parameters, LogReplicationMetadataManager metadataManager) {\n+        this.remoteClusterId = parameters.getRemoteClusterDescriptor().getClusterId();\n+        this.metadataManager = metadataManager;\n+        this.router = new LogReplicationClientRouter(parameters, this);\n+        this.router.addClient(new LogReplicationHandler());\n+        this.sourceManager = new LogReplicationSourceManager(parameters, new LogReplicationClient(router, remoteClusterId));\n+        this.communicationFSMWorkers = Executors.newSingleThreadExecutor(new\n+                ThreadFactoryBuilder().setNameFormat(\"runtime-fsm-worker\").build());\n+        this.communicationFSMConsumer = Executors.newSingleThreadExecutor(new\n+                ThreadFactoryBuilder().setNameFormat(\"runtime-fsm-consumer\").build());\n+\n+        initializeStates();\n+        this.state = states.get(LogReplicationRuntimeStateType.WAITING_FOR_CONNECTIVITY);\n+\n+        log.info(\"Log Replication Runtime State Machine initialized\");\n+    }\n+\n+    /**\n+     * Start Log Replication Communication FSM\n+     */\n+    public void start() {\n+        // Start Consumer Thread for this state machine (dedicated thread for event consumption)\n+        communicationFSMConsumer.submit(this::consume);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI3ODk1Nw==", "bodyText": "Is it doing query the leadership?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447278957", "createdAt": "2020-06-29T22:01:01Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/VerifyingRemoteLeaderState.java", "diffHunk": "@@ -0,0 +1,142 @@\n+package org.corfudb.infrastructure.logreplication.runtime.fsm;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationClientRouter;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationQueryLeaderShipResponse;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Log Replication Runtime Verifying Remote Leader State.\n+ *\n+ * In this state the leader node in the remote cluster is identified.\n+ *\n+ * @author amartinezman\n+ */\n+@Slf4j\n+public class VerifyingRemoteLeaderState implements LogReplicationRuntimeState {\n+\n+    private static final int LEADERSHIP_RETRIES = 5;\n+\n+    private CorfuLogReplicationRuntime fsm;\n+\n+    private ExecutorService worker;\n+\n+    private LogReplicationClientRouter router;\n+\n+    public VerifyingRemoteLeaderState(CorfuLogReplicationRuntime fsm, ExecutorService worker, LogReplicationClientRouter router) {\n+        this.fsm = fsm;\n+        this.worker = worker;\n+        this.router = router;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeStateType getType() {\n+        return LogReplicationRuntimeStateType.VERIFYING_REMOTE_LEADER;\n+    }\n+\n+    @Override\n+    public LogReplicationRuntimeState processEvent(LogReplicationRuntimeEvent event) throws IllegalTransitionException {\n+        switch (event.getType()) {\n+            case REMOTE_LEADER_FOUND:\n+                ((NegotiatingState)fsm.getStates().get(LogReplicationRuntimeStateType.NEGOTIATING)).setLeaderEndpoint(event.getEndpoint());\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.NEGOTIATING);\n+            case ON_CONNECTION_DOWN:\n+                String endpointDown = event.getEndpoint();\n+                fsm.updateDisconnectedEndpoints(endpointDown);\n+\n+                // If no connection exists, return to init state, until a connection is established.\n+                if (fsm.getConnectedEndpoints().size() == 0) {\n+                    return fsm.getStates().get(LogReplicationRuntimeStateType.WAITING_FOR_CONNECTIVITY);\n+                }\n+                return this;\n+            case REMOTE_LEADER_NOT_FOUND:\n+                return this;\n+            case ON_CONNECTION_UP:\n+                // Add new connected node, for leadership verification\n+                fsm.updateConnectedEndpoints(event.getEndpoint());\n+                return this;\n+            case LOCAL_LEADER_LOSS:\n+                return fsm.getStates().get(LogReplicationRuntimeStateType.STOPPED);\n+            default: {\n+                log.warn(\"Unexpected communication event {} when in init state.\", event.getType());\n+                throw new IllegalTransitionException(event.getType(), getType());\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void onEntry(LogReplicationRuntimeState from) {\n+        log.debug(\"onEntry :: Verifying Remote Leader, transition from {}\", from);\n+        // Verify Leadership on connected nodes (ignore those for which leadership is pending)\n+        this.worker.submit(this::verifyLeadership);\n+    }\n+\n+\n+    /**\n+     * Verify who is the leader node on the remote cluster by sending leadership request to all nodes.\n+     *\n+     * If no leader is found, the verification will be attempted for LEADERSHIP_RETRIES times.\n+     */\n+    public synchronized void verifyLeadership() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4MTEyOA==", "bodyText": "Why do we need two thread pools, communicationFSMWorks and communicationFSMConsumer? Those tasks are really small, the overhead of context switch is bigger than running the task. Also, it  adds complexity to the system to make sure these two threads are sync.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447281128", "createdAt": "2020-06-29T22:05:40Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java", "diffHunk": "@@ -0,0 +1,295 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeStateType;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.StoppedState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.UnrecoverableState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.WaitingForConnectionsState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.IllegalTransitionException;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.NegotiatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.ReplicatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.VerifyingRemoteLeaderState;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * Runtime to connect to a remote Corfu Log Replication Cluster.\n+ *\n+ * This class represents the Log Replication Runtime Finite State Machine, which defines\n+ * all states in which the leader node on the active cluster can be.\n+ *\n+ *\n+ *                                                       R-LEADER_LOSS\n+ *                                             +-------------------------------+\n+ *                              ON_CONNECTION  |                               |    ON_CONNECTION_DOWN\n+ *                                    UP       |       ON_CONNECTION_DOWN      |       (NON_LEADER)\n+ *                                    +----+   |          (R-LEADER)           |\n+ *                                    |    |   |   +-----------------------+   |        +-----+\n+ *                                    |    |   |   |                       |   |        |     |\n+ * +---------------+  ON_CONNECTION  ++----v---v---v--+                  +-+---+--------+-+   |\n+ * |               |       UP        |                |  R-LEADER_FOUND  |                <---+\n+ * |    WAITING    +---------------->+    VERIFYING   +------------------>                +---+\n+ * |      FOR      |                 |     REMOTE     |                  |   NEGOTIATING  |   |  NEGOTIATION_FAILED\n+ * |  CONNECTIONS  +<----------------+     LEADER     |                  |                <---+       (ALARM)\n+ * |               |  ON_CONNECTION  |                +<-----------+     |                +----+\n+ * +---------------+      DOWN       +-^----+---^----++            |     +-------+-----^--+    |\n+ *                       (ALL)         |    |   |    |             |             |     |       |\n+ *                                     |    |   |    |        R-LEADER_LOSS      |     +-------+\n+ *                                     +----+   +----+             |             |  ON_CONNECTION_UP\n+ *                              ON_CONNECTION     R-LEADER_NOT     |             |    (NON-LEADER)\n+ *                                  DOWN              FOUND        |             |\n+ *                                (NOT ALL)                        |     NEGOTIATE_COMPLETE\n+ *                                                                 |             |\n+ *                                                           ON_CONNECTION       |   ON_CONNECTION_UP\n+ *                                                               DOWN            |     (NON-LEADER)\n+ *                                                             (R-LEADER)        |      +-----+\n+ *                                                                 |             |      |     |\n+ *                                                                 |     +-------v------+-+   |\n+ *            +---------------+      ALL STATES                    +-----+                <---+\n+ *            |               |                                          |                |\n+ *            |   STOPPED     <---- L-LEADER_LOSS                        |  REPLICATING   |\n+ *            |               |                     SITE FLIP <-----     |                |\n+ *            |               |                                          |                +----+\n+ *            +---------------+                                          +--------------^-+    |\n+ *                                                                                      |      |\n+ *                                                                                      +------+\n+ *            +---------------+     ALL STATES\n+ *            |               |                                                     ON_CONNECTION_DOWN\n+ *            | UNRECOVERABLE <---- ON_ERROR                                           (NON-LEADER)\n+ *            |    STATE      |\n+ *            |               |\n+ *            +---------------+\n+ *\n+ *\n+ * States:\n+ * ------\n+ *\n+ * - WAITING_FOR_CONNECTIVITY    :: initial state, waiting for any connection to remote cluster to be established.\n+ * - VERIFYING_REMOTE_LEADER     :: verifying the leader endpoint on remote cluster (querying all connected nodes)\n+ * - NEGOTIATING                 :: negotiating against the leader endpoint\n+ * - REPLICATING                 :: replicating data to remote cluster through the leader endpoint\n+ * - STOPPED                     :: stop state machine, no error, just lost leadership so replication stops from this node\n+ * - UNRECOVERABLE_STATE         :: error state, unrecoverable error reported by replication, transport or cluster manager, despite\n+ *                                  being the leader node.\n+ *\n+ *\n+ * Events / Transitions:\n+ * --------------------\n+ *\n+ * - ON_CONNECTION_UP           :: connection to a remote endpoint comes UP\n+ * - ON_CONNECTION_DOWN         :: connection to a remote endpoint comes DOWN\n+ * - REMOTE_LEADER_NOT_FOUND,   :: remote leader not found\n+ * - REMOTE_LEADER_FOUND,       :: remote leader found\n+ * - REMOTE_LEADER_LOSS,        :: remote Leader Lost (remote node reports it is no longer the leader)\n+ * - LOCAL_LEADER_LOSS          :: local node looses leadership\n+ * - NEGOTIATION_COMPLETE,      :: negotiation succeeded and completed\n+ * - NEGOTIATION_FAILED,        :: negotiation failed\n+ * - STOPPED                    :: stop log replication server (fatal state)\n+ *\n+ * @author amartinezman\n+ *\n+ */\n+@Slf4j\n+public class CorfuLogReplicationRuntime {\n+\n+    // TODO(Gabriela): add site_flip (cluster_role_flip) event... probably we need a new state called finishing_ongoing_replication... and go to to stopped...\n+\n+    public static final int DEFAULT_TIMEOUT = 5000;\n+\n+    /**\n+     * Current state of the FSM.\n+     */\n+    private volatile LogReplicationRuntimeState state;\n+\n+    /**\n+     * Map of all Log Replication Communication FSM States (reuse single instance for each state)\n+     */\n+    @Getter\n+    private Map<LogReplicationRuntimeStateType, LogReplicationRuntimeState> states = new HashMap<>();\n+\n+    /**\n+     * Executor service for FSM state tasks\n+     */\n+    private ExecutorService communicationFSMWorkers;\n+\n+    /**\n+     * Executor service for FSM event queue consume\n+     */\n+    private ExecutorService communicationFSMConsumer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5Mjc0Ng==", "bodyText": "It is possible that while doing the negotiation, there is a leadership change at the standby site.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447292746", "createdAt": "2020-06-29T22:24:19Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java", "diffHunk": "@@ -0,0 +1,295 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeStateType;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.StoppedState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.UnrecoverableState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.WaitingForConnectionsState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.IllegalTransitionException;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.NegotiatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.ReplicatingState;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.VerifyingRemoteLeaderState;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * Runtime to connect to a remote Corfu Log Replication Cluster.\n+ *\n+ * This class represents the Log Replication Runtime Finite State Machine, which defines\n+ * all states in which the leader node on the active cluster can be.\n+ *\n+ *\n+ *                                                       R-LEADER_LOSS\n+ *                                             +-------------------------------+\n+ *                              ON_CONNECTION  |                               |    ON_CONNECTION_DOWN\n+ *                                    UP       |       ON_CONNECTION_DOWN      |       (NON_LEADER)\n+ *                                    +----+   |          (R-LEADER)           |\n+ *                                    |    |   |   +-----------------------+   |        +-----+\n+ *                                    |    |   |   |                       |   |        |     |\n+ * +---------------+  ON_CONNECTION  ++----v---v---v--+                  +-+---+--------+-+   |\n+ * |               |       UP        |                |  R-LEADER_FOUND  |                <---+\n+ * |    WAITING    +---------------->+    VERIFYING   +------------------>                +---+\n+ * |      FOR      |                 |     REMOTE     |                  |   NEGOTIATING  |   |  NEGOTIATION_FAILED\n+ * |  CONNECTIONS  +<----------------+     LEADER     |                  |                <---+       (ALARM)\n+ * |               |  ON_CONNECTION  |                +<-----------+     |                +----+\n+ * +---------------+      DOWN       +-^----+---^----++            |     +-------+-----^--+    |\n+ *                       (ALL)         |    |   |    |             |             |     |       |\n+ *                                     |    |   |    |        R-LEADER_LOSS      |     +-------+\n+ *                                     +----+   +----+             |             |  ON_CONNECTION_UP\n+ *                              ON_CONNECTION     R-LEADER_NOT     |             |    (NON-LEADER)\n+ *                                  DOWN              FOUND        |             |\n+ *                                (NOT ALL)                        |     NEGOTIATE_COMPLETE\n+ *                                                                 |             |\n+ *                                                           ON_CONNECTION       |   ON_CONNECTION_UP\n+ *                                                               DOWN            |     (NON-LEADER)\n+ *                                                             (R-LEADER)        |      +-----+\n+ *                                                                 |             |      |     |\n+ *                                                                 |     +-------v------+-+   |\n+ *            +---------------+      ALL STATES                    +-----+                <---+\n+ *            |               |                                          |                |\n+ *            |   STOPPED     <---- L-LEADER_LOSS                        |  REPLICATING   |\n+ *            |               |                     SITE FLIP <-----     |                |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5NTk3MQ==", "bodyText": "If the connection is lost during channelAdapter.send(), should it detect it and generate an REMOTE_LEADER_LOSS message?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447295971", "createdAt": "2020-06-29T22:33:06Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/LogReplicationClientRouter.java", "diffHunk": "@@ -0,0 +1,432 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.LogReplicationPluginConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.runtime.Messages.CorfuMessage;\n+import org.corfudb.runtime.clients.IClient;\n+import org.corfudb.runtime.clients.IClientRouter;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.infrastructure.logreplication.transport.client.ChannelAdapterException;\n+import org.corfudb.infrastructure.logreplication.transport.client.IClientChannelAdapter;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.Utils;\n+import org.corfudb.utils.common.CorfuMessageConverter;\n+import org.corfudb.utils.common.CorfuMessageProtoBufException;\n+\n+import java.io.File;\n+import java.net.URL;\n+import java.net.URLClassLoader;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+/**\n+ * This Client Router is used when a custom (client-defined) transport layer is specified for\n+ * Log Replication Server communication.\n+ *\n+ */\n+@Slf4j\n+public class LogReplicationClientRouter implements IClientRouter {\n+\n+    @Getter\n+    private LogReplicationRuntimeParameters parameters;\n+\n+    /**\n+     * The handlers registered to this router.\n+     */\n+    private final Map<CorfuMsgType, IClient> handlerMap;\n+\n+    /**\n+     * The clients registered to this router.\n+     */\n+    public final List<IClient> clientList;\n+\n+    /**\n+     * Whether or not this router is shutdown.\n+     */\n+    public volatile boolean shutdown;\n+\n+    /**\n+     * A {@link CompletableFuture} which is completed when a connection,\n+     * including a successful handshake completes and messages can be sent\n+     * to the remote node.\n+     */\n+    @Getter\n+    volatile CompletableFuture<Void> remoteLeaderConnectionFuture;\n+\n+    /**\n+     * The current request ID.\n+     */\n+    @Getter\n+    @SuppressWarnings(\"checkstyle:abbreviation\")\n+    public AtomicLong requestID;\n+\n+    /**\n+     * Sync call response timeout (milliseconds).\n+     */\n+    @Getter\n+    @Setter\n+    public long timeoutResponse;\n+\n+    /**\n+     * The outstanding requests on this router.\n+     */\n+    public final Map<Long, CompletableFuture> outstandingRequests;\n+\n+    /**\n+     * Adapter to the channel implementation\n+     */\n+    private IClientChannelAdapter channelAdapter;\n+\n+    /**\n+     * Remote Cluster/Site Full Descriptor\n+     */\n+    private ClusterDescriptor remoteClusterDescriptor;\n+\n+    /**\n+     * Remote Cluster/Site unique identifier\n+     */\n+    private String remoteClusterId;\n+\n+    /**\n+     * Runtime FSM, to insert connectivity events\n+     */\n+    private CorfuLogReplicationRuntime runtimeFSM;\n+\n+    /**\n+     * Log Replication Client Constructor\n+     *\n+     * @param parameters runtime parameters (including connection settings)\n+     * @param runtimeFSM runtime state machine, insert connection related events\n+     */\n+    public LogReplicationClientRouter(LogReplicationRuntimeParameters parameters,\n+                                      CorfuLogReplicationRuntime runtimeFSM) {\n+        this.remoteClusterDescriptor = parameters.getRemoteClusterDescriptor();\n+        this.remoteClusterId = remoteClusterDescriptor.getClusterId();\n+        this.parameters = parameters;\n+        this.timeoutResponse = parameters.getRequestTimeout().toMillis();\n+        this.runtimeFSM = runtimeFSM;\n+\n+        this.handlerMap = new ConcurrentHashMap<>();\n+        this.clientList = new ArrayList<>();\n+        this.requestID = new AtomicLong();\n+        this.outstandingRequests = new ConcurrentHashMap<>();\n+        this.remoteLeaderConnectionFuture = new CompletableFuture<>();\n+    }\n+\n+    // ------------------- IClientRouter Interface ----------------------\n+\n+    @Override\n+    public IClientRouter addClient(IClient client) {\n+        // Set the client's router to this instance.\n+        client.setRouter(this);\n+\n+        // Iterate through all types of CorfuMsgType, registering the handler\n+        client.getHandledTypes().stream()\n+                .forEach(x -> {\n+                    handlerMap.put(x, client);\n+                    log.info(\"Registered {} to handle messages of type {}\", client, x);\n+                });\n+\n+        // Register this type\n+        clientList.add(client);\n+        return this;\n+    }\n+\n+    @Override\n+    public <T> CompletableFuture<T> sendMessageAndGetCompletable(CorfuMsg message) {\n+        return sendMessageAndGetCompletable(message, null);\n+    }\n+\n+    public <T> CompletableFuture<T> sendMessageAndGetCompletable(CorfuMsg message, String endpoint) {\n+        if (isValidMessage(message)) {\n+            // Get the next request ID.\n+            final long requestId = requestID.getAndIncrement();\n+\n+            // Generate a future and put it in the completion table.\n+            final CompletableFuture<T> cf = new CompletableFuture<>();\n+            outstandingRequests.put(requestId, cf);\n+\n+            try {\n+                message.setClientID(parameters.getClientId());\n+                message.setRequestID(requestId);\n+\n+                // If no endpoint is specified, the message is to be sent to the remote leader node.\n+                // We should block until a connection to the leader is established.\n+                if (endpoint == null || endpoint.length() == 0) {\n+                    // Check the connection future. If connected, continue with sending the message.\n+                    // If timed out, return a exceptionally completed with the timeout.\n+                    // Because in Log Replication, messages are sent to the leader node, the connection future\n+                    // represents a connection to the leader.\n+                    try {\n+                        remoteLeaderConnectionFuture\n+                                .get(getParameters().getConnectionTimeout().toMillis(), TimeUnit.MILLISECONDS);\n+                    } catch (InterruptedException e) {\n+                        throw new UnrecoverableCorfuInterruptedError(e);\n+                    } catch (TimeoutException te) {\n+                        cf.completeExceptionally(te);\n+                        return cf;\n+                    } catch (ExecutionException ee) {\n+                        cf.completeExceptionally(Utils.extractCauseWithCompleteStacktrace(ee));\n+                        return cf;\n+                    }\n+\n+                    // Get Remote Leader\n+                    if(runtimeFSM.getRemoteLeader().isPresent()) {\n+                        endpoint = runtimeFSM.getRemoteLeader().get();\n+                    } else {\n+                        log.error(\"Leader not found to remote cluster {}\", remoteClusterId);\n+                        runtimeFSM.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+                        throw new ChannelAdapterException(\n+                                String.format(\"Leader not found to remote cluster %s\", remoteClusterDescriptor.getClusterId()));\n+                    }\n+                }\n+\n+                // In the case the message is intended for a specific endpoint, we do not\n+                // block on connection future, this is the case of leader verification.\n+                log.info(\"Send message to {}, type={}\", endpoint, message.getMsgType());\n+                channelAdapter.send(endpoint, CorfuMessageConverter.toProtoBuf(message));\n+\n+            } catch (Exception e) {\n+                outstandingRequests.remove(requestId);\n+                log.error(\"sendMessageAndGetCompletable: Remove request {} to {} due to exception! Message:{}\",\n+                        requestId, remoteClusterId, message, e);\n+                cf.completeExceptionally(e);\n+                return cf;\n+            }\n+\n+            // Generate a timeout future, which will complete exceptionally\n+            // if the main future is not completed.\n+            final CompletableFuture<T> cfTimeout =\n+                    CFUtils.within(cf, Duration.ofMillis(timeoutResponse));\n+            cfTimeout.exceptionally(e -> {\n+                if (e.getCause() instanceof TimeoutException) {\n+                    outstandingRequests.remove(requestId);\n+                    log.debug(\"sendMessageAndGetCompletable: Remove request {} to {} due to timeout! Message:{}\",\n+                            requestId, remoteClusterId, message);\n+                }\n+                return null;\n+            });\n+\n+            return cfTimeout;\n+        }\n+\n+        log.error(\"Invalid message type {}. Currently only log replication messages are processed.\");\n+        CompletableFuture<T> f = new CompletableFuture<>();\n+        f.completeExceptionally(new Throwable(\"Invalid message type\"));\n+        return f;\n+    }\n+\n+    /**\n+     * Send a one way message, without adding a completable future.\n+     *\n+     * @param message The message to send.\n+     */\n+    @Override\n+    public void sendMessage(CorfuMsg message) {\n+        // Get the next request ID.\n+        message.setRequestID(requestID.getAndIncrement());\n+        // Get Remote Leader\n+        if(runtimeFSM.getRemoteLeader().isPresent()) {\n+            String remoteLeader = runtimeFSM.getRemoteLeader().get();\n+            channelAdapter.send(remoteLeader, CorfuMessageConverter.toProtoBuf(message));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8902a422b580177262563872a54738d4b1e24b5"}, "originalPosition": 250}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NjgwNDYz", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-439680463", "createdAt": "2020-06-30T05:29:33Z", "commit": {"oid": "69906091e1d34b1241cf0366c1fd60ac2a8b9e7c"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwNToyOTozM1rOGqsQ0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwNTo0MzoyNlrOGqshwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxODU3OA==", "bodyText": "I think this numEntries is not exactly how many entries we need to send. Because we only transfer some streams, and getNumEntriesToSend returns (maxStreamTail - ackedTimeStamp), which will count other log entries. Besides, for loop will amplify totalNumEntries multiple times.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447418578", "createdAt": "2020-06-30T05:29:33Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -0,0 +1,300 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+/**\n+ * This class manages Log Replication for multiple remote (standby) cluster's.\n+ */\n+@Slf4j\n+public class CorfuReplicationManager {\n+\n+    public final static int PERCENTAGE_BASE = 100;\n+\n+    // Keep map of remote cluster ID and the associated log replication runtime (an abstract\n+    // client to that cluster)\n+    private Map<String, CorfuLogReplicationRuntime> runtimeToRemoteCluster = new HashMap<>();\n+\n+    @Setter\n+    @Getter\n+    private volatile TopologyDescriptor topologyDescriptor;\n+\n+    private final LogReplicationConfig logReplicationConfig;\n+\n+    private final NodeDescriptor localNodeDescriptor;\n+\n+    private final CorfuRuntime corfuRuntime;\n+\n+    // TODO (Xiaoqin Ma): can you please add a description on this variable's meaning\n+    private long prepareSiteRoleChangeStreamTail;\n+\n+    private long totalNumEntriesToSend;\n+\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    private final String pluginFilePath;\n+\n+    /**\n+     * Constructor\n+     *\n+     * @param topologyDescriptor description of active and standby cluster' of a given topology\n+     * @param logReplicationConfig log replication configuration\n+     */\n+    public CorfuReplicationManager(TopologyDescriptor topologyDescriptor,\n+                            LogReplicationConfig logReplicationConfig,\n+                            NodeDescriptor localNodeDescriptor,\n+                            LogReplicationMetadataManager metadataManager,\n+                            String pluginFilePath, CorfuRuntime corfuRuntime) {\n+        this.topologyDescriptor = topologyDescriptor;\n+        this.logReplicationConfig = logReplicationConfig;\n+        this.metadataManager = metadataManager;\n+        this.pluginFilePath = pluginFilePath;\n+        this.corfuRuntime = corfuRuntime;\n+\n+        this.localNodeDescriptor = localNodeDescriptor;\n+        this.prepareSiteRoleChangeStreamTail = Address.NON_ADDRESS;\n+        this.totalNumEntriesToSend = 0;\n+    }\n+\n+    /**\n+     * Start Log Replication Manager, this will initiate a runtime against\n+     * each standby cluster, to further start log replication.\n+     */\n+    public void start() {\n+        for (ClusterDescriptor remoteCluster : topologyDescriptor.getStandbyClusters().values()) {\n+            try {\n+                startLogReplicationRuntime(remoteCluster);\n+            } catch (Exception e) {\n+                log.error(\"Failed to start log replication runtime for remote cluster {}\", remoteCluster.getClusterId());\n+\n+                // Remove cluster from the list of standby's, as the cluster discovery process will receive\n+                // change notification when this site becomes stable/available again.\n+                topologyDescriptor.getStandbyClusters().remove(remoteCluster.getClusterId());\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Stop log replication for all the standby sites\n+     */\n+    public void stop() {\n+        for(String clusterId : topologyDescriptor.getStandbyClusters().keySet()) {\n+            stopLogReplicationRuntime(clusterId);\n+        }\n+    }\n+\n+    /**\n+     * Restart connection to remote cluster\n+     */\n+    public void restart(ClusterDescriptor remoteCluster) {\n+        stopLogReplicationRuntime(remoteCluster.getClusterId());\n+        startLogReplicationRuntime(remoteCluster);\n+    }\n+\n+    /**\n+     * Start Log Replication Runtime to a specific standby Cluster\n+     */\n+    private void startLogReplicationRuntime(ClusterDescriptor remoteClusterDescriptor) {\n+\n+        String remoteClusterId = remoteClusterDescriptor.getClusterId();\n+\n+        try {\n+            if (!runtimeToRemoteCluster.containsKey(remoteClusterId)) {\n+                log.info(\"Starting Log Replication Runtime to Standby Cluster id={}\", remoteClusterId);\n+                connect(remoteClusterDescriptor);\n+            } else {\n+                log.warn(\"Log Replication Runtime to remote cluster {}, already exists. Skipping init.\", remoteClusterId);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Caught exception, stop log replication runtime to {}\", remoteClusterDescriptor, e);\n+            stopLogReplicationRuntime(remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * Connect to a remote Log Replicator, through a Log Replication Runtime.\n+     *\n+     * @throws InterruptedException\n+     */\n+    private void connect(ClusterDescriptor remoteCluster) throws InterruptedException {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    // TODO(Gabriela) : It's cleaner to make LogReplicationConfig agnostic of cluster information (shared across\n+                    //  all clusters) so it would be better to push down the remote cluster id or info as a separate object\n+                    //  this requires to change signatures down the pipe. TBD.\n+                    String localCorfuEndpoint = localNodeDescriptor.getIpAddress() + \":\" + topologyDescriptor.getActiveCluster().getCorfuPort();\n+\n+                    LogReplicationRuntimeParameters parameters = LogReplicationRuntimeParameters.builder()\n+                            .localCorfuEndpoint(localCorfuEndpoint)\n+                            .remoteClusterDescriptor(remoteCluster)\n+                            .localClusterId(localNodeDescriptor.getClusterId())\n+                            .replicationConfig(new LogReplicationConfig(logReplicationConfig.getStreamsToReplicate()))\n+                            .pluginFilePath(pluginFilePath)\n+                            .topologyConfigId(topologyDescriptor.getTopologyConfigId())\n+                            .keyStore(corfuRuntime.getParameters().getKeyStore())\n+                            .tlsEnabled(corfuRuntime.getParameters().isTlsEnabled())\n+                            .ksPasswordFile(corfuRuntime.getParameters().getKsPasswordFile())\n+                            .trustStore(corfuRuntime.getParameters().getTrustStore())\n+                            .tsPasswordFile(corfuRuntime.getParameters().getTsPasswordFile())\n+                            .build();\n+                    CorfuLogReplicationRuntime replicationRuntime = new CorfuLogReplicationRuntime(parameters, metadataManager);\n+                    replicationRuntime.start();\n+                    runtimeToRemoteCluster.put(remoteCluster.getClusterId(), replicationRuntime);\n+                } catch (Exception e) {\n+                    log.error(\"Exception {}. Failed to connect to remote cluster {}. Retry after 1 second.\",\n+                            e, remoteCluster.getClusterId());\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to connect to remote cluster.\", e);\n+            throw e;\n+        }\n+    }\n+\n+    /**\n+     * Stop Log Replication to a specific standby Cluster\n+     */\n+    private void stopLogReplicationRuntime(String remoteClusterId) {\n+        CorfuLogReplicationRuntime logReplicationRuntime = runtimeToRemoteCluster.get(remoteClusterId);\n+        if (logReplicationRuntime != null) {\n+            log.info(\"Stop log replication runtime to remote cluster id={}\", remoteClusterId);\n+            logReplicationRuntime.stop();\n+            runtimeToRemoteCluster.remove(remoteClusterId);\n+        } else {\n+            log.warn(\"Runtime not found to remote cluster {}\", remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * The notification of change of adding/removing standby's without epoch change.\n+     *\n+     * @param newConfig has the same topologyConfigId as the current config\n+     */\n+    public void processStandbyChange(TopologyDescriptor newConfig) {\n+        if (newConfig.getTopologyConfigId() != topologyDescriptor.getTopologyConfigId()) {\n+            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+                    \"siteConfigId as the current one {}\", newConfig, topologyDescriptor);\n+            return;\n+        }\n+\n+        Map<String, ClusterDescriptor> newStandbys = newConfig.getStandbyClusters();\n+        Map<String, ClusterDescriptor> currentStandbys = topologyDescriptor.getStandbyClusters();\n+        newStandbys.keySet().retainAll(currentStandbys.keySet());\n+        Set<String> standbysToRemove = currentStandbys.keySet();\n+        standbysToRemove.removeAll(newStandbys.keySet());\n+\n+        /*\n+         * Remove standbys that are not in the new config\n+         */\n+        for (String siteID : standbysToRemove) {\n+            stopLogReplicationRuntime(siteID);\n+            topologyDescriptor.removeStandbySite(siteID);\n+        }\n+\n+        //Start the standbys that are in the new config but not in the current config\n+        for (String clusterId : newConfig.getStandbyClusters().keySet()) {\n+            if (runtimeToRemoteCluster.get(clusterId) == null) {\n+                ClusterDescriptor clusterInfo = newConfig.getStandbyClusters().get(clusterId);\n+                topologyDescriptor.addStandbySite(clusterInfo);\n+                startLogReplicationRuntime(clusterInfo);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all relevant streams.\n+     */\n+    private long queryStreamTail() {\n+        Set<String> streamsToReplicate = logReplicationConfig.getStreamsToReplicate();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : streamsToReplicate) {\n+            UUID currentUUID = CorfuRuntime.getStreamID(s);\n+            Map<UUID, Long> tailMap = corfuRuntime.getAddressSpaceView().getAllTails().getStreamTails();\n+            Long currentTail = tailMap.get(currentUUID);\n+            if (currentTail != null) {\n+                maxTail = Math.max(maxTail, currentTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp, calculate how many entries to be sent for all replicated streams.\n+     *\n+     * @param timestamp\n+     */\n+    private long queryEntriesToSend(long timestamp) {\n+        int totalNumEntries = 0;\n+\n+        for (CorfuLogReplicationRuntime runtime: runtimeToRemoteCluster.values()) {\n+            totalNumEntries += runtime.getNumEntriesToSend(timestamp);\n+        }\n+\n+        return totalNumEntries;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69906091e1d34b1241cf0366c1fd60ac2a8b9e7c"}, "originalPosition": 255}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyMTM0OA==", "bodyText": "if the max stream tail moves, it calls prepareSiteRoleChange(), which call queryStreamTail() one more time, and will update totalNumEntriesToSend. Then it call queryEntriesToSend() again, will get a pretty close result as currentNumEntriesToSend. So percent calculation will always return a 0.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447421348", "createdAt": "2020-06-30T05:38:30Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -0,0 +1,300 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+/**\n+ * This class manages Log Replication for multiple remote (standby) cluster's.\n+ */\n+@Slf4j\n+public class CorfuReplicationManager {\n+\n+    public final static int PERCENTAGE_BASE = 100;\n+\n+    // Keep map of remote cluster ID and the associated log replication runtime (an abstract\n+    // client to that cluster)\n+    private Map<String, CorfuLogReplicationRuntime> runtimeToRemoteCluster = new HashMap<>();\n+\n+    @Setter\n+    @Getter\n+    private volatile TopologyDescriptor topologyDescriptor;\n+\n+    private final LogReplicationConfig logReplicationConfig;\n+\n+    private final NodeDescriptor localNodeDescriptor;\n+\n+    private final CorfuRuntime corfuRuntime;\n+\n+    // TODO (Xiaoqin Ma): can you please add a description on this variable's meaning\n+    private long prepareSiteRoleChangeStreamTail;\n+\n+    private long totalNumEntriesToSend;\n+\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    private final String pluginFilePath;\n+\n+    /**\n+     * Constructor\n+     *\n+     * @param topologyDescriptor description of active and standby cluster' of a given topology\n+     * @param logReplicationConfig log replication configuration\n+     */\n+    public CorfuReplicationManager(TopologyDescriptor topologyDescriptor,\n+                            LogReplicationConfig logReplicationConfig,\n+                            NodeDescriptor localNodeDescriptor,\n+                            LogReplicationMetadataManager metadataManager,\n+                            String pluginFilePath, CorfuRuntime corfuRuntime) {\n+        this.topologyDescriptor = topologyDescriptor;\n+        this.logReplicationConfig = logReplicationConfig;\n+        this.metadataManager = metadataManager;\n+        this.pluginFilePath = pluginFilePath;\n+        this.corfuRuntime = corfuRuntime;\n+\n+        this.localNodeDescriptor = localNodeDescriptor;\n+        this.prepareSiteRoleChangeStreamTail = Address.NON_ADDRESS;\n+        this.totalNumEntriesToSend = 0;\n+    }\n+\n+    /**\n+     * Start Log Replication Manager, this will initiate a runtime against\n+     * each standby cluster, to further start log replication.\n+     */\n+    public void start() {\n+        for (ClusterDescriptor remoteCluster : topologyDescriptor.getStandbyClusters().values()) {\n+            try {\n+                startLogReplicationRuntime(remoteCluster);\n+            } catch (Exception e) {\n+                log.error(\"Failed to start log replication runtime for remote cluster {}\", remoteCluster.getClusterId());\n+\n+                // Remove cluster from the list of standby's, as the cluster discovery process will receive\n+                // change notification when this site becomes stable/available again.\n+                topologyDescriptor.getStandbyClusters().remove(remoteCluster.getClusterId());\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Stop log replication for all the standby sites\n+     */\n+    public void stop() {\n+        for(String clusterId : topologyDescriptor.getStandbyClusters().keySet()) {\n+            stopLogReplicationRuntime(clusterId);\n+        }\n+    }\n+\n+    /**\n+     * Restart connection to remote cluster\n+     */\n+    public void restart(ClusterDescriptor remoteCluster) {\n+        stopLogReplicationRuntime(remoteCluster.getClusterId());\n+        startLogReplicationRuntime(remoteCluster);\n+    }\n+\n+    /**\n+     * Start Log Replication Runtime to a specific standby Cluster\n+     */\n+    private void startLogReplicationRuntime(ClusterDescriptor remoteClusterDescriptor) {\n+\n+        String remoteClusterId = remoteClusterDescriptor.getClusterId();\n+\n+        try {\n+            if (!runtimeToRemoteCluster.containsKey(remoteClusterId)) {\n+                log.info(\"Starting Log Replication Runtime to Standby Cluster id={}\", remoteClusterId);\n+                connect(remoteClusterDescriptor);\n+            } else {\n+                log.warn(\"Log Replication Runtime to remote cluster {}, already exists. Skipping init.\", remoteClusterId);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Caught exception, stop log replication runtime to {}\", remoteClusterDescriptor, e);\n+            stopLogReplicationRuntime(remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * Connect to a remote Log Replicator, through a Log Replication Runtime.\n+     *\n+     * @throws InterruptedException\n+     */\n+    private void connect(ClusterDescriptor remoteCluster) throws InterruptedException {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    // TODO(Gabriela) : It's cleaner to make LogReplicationConfig agnostic of cluster information (shared across\n+                    //  all clusters) so it would be better to push down the remote cluster id or info as a separate object\n+                    //  this requires to change signatures down the pipe. TBD.\n+                    String localCorfuEndpoint = localNodeDescriptor.getIpAddress() + \":\" + topologyDescriptor.getActiveCluster().getCorfuPort();\n+\n+                    LogReplicationRuntimeParameters parameters = LogReplicationRuntimeParameters.builder()\n+                            .localCorfuEndpoint(localCorfuEndpoint)\n+                            .remoteClusterDescriptor(remoteCluster)\n+                            .localClusterId(localNodeDescriptor.getClusterId())\n+                            .replicationConfig(new LogReplicationConfig(logReplicationConfig.getStreamsToReplicate()))\n+                            .pluginFilePath(pluginFilePath)\n+                            .topologyConfigId(topologyDescriptor.getTopologyConfigId())\n+                            .keyStore(corfuRuntime.getParameters().getKeyStore())\n+                            .tlsEnabled(corfuRuntime.getParameters().isTlsEnabled())\n+                            .ksPasswordFile(corfuRuntime.getParameters().getKsPasswordFile())\n+                            .trustStore(corfuRuntime.getParameters().getTrustStore())\n+                            .tsPasswordFile(corfuRuntime.getParameters().getTsPasswordFile())\n+                            .build();\n+                    CorfuLogReplicationRuntime replicationRuntime = new CorfuLogReplicationRuntime(parameters, metadataManager);\n+                    replicationRuntime.start();\n+                    runtimeToRemoteCluster.put(remoteCluster.getClusterId(), replicationRuntime);\n+                } catch (Exception e) {\n+                    log.error(\"Exception {}. Failed to connect to remote cluster {}. Retry after 1 second.\",\n+                            e, remoteCluster.getClusterId());\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to connect to remote cluster.\", e);\n+            throw e;\n+        }\n+    }\n+\n+    /**\n+     * Stop Log Replication to a specific standby Cluster\n+     */\n+    private void stopLogReplicationRuntime(String remoteClusterId) {\n+        CorfuLogReplicationRuntime logReplicationRuntime = runtimeToRemoteCluster.get(remoteClusterId);\n+        if (logReplicationRuntime != null) {\n+            log.info(\"Stop log replication runtime to remote cluster id={}\", remoteClusterId);\n+            logReplicationRuntime.stop();\n+            runtimeToRemoteCluster.remove(remoteClusterId);\n+        } else {\n+            log.warn(\"Runtime not found to remote cluster {}\", remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * The notification of change of adding/removing standby's without epoch change.\n+     *\n+     * @param newConfig has the same topologyConfigId as the current config\n+     */\n+    public void processStandbyChange(TopologyDescriptor newConfig) {\n+        if (newConfig.getTopologyConfigId() != topologyDescriptor.getTopologyConfigId()) {\n+            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+                    \"siteConfigId as the current one {}\", newConfig, topologyDescriptor);\n+            return;\n+        }\n+\n+        Map<String, ClusterDescriptor> newStandbys = newConfig.getStandbyClusters();\n+        Map<String, ClusterDescriptor> currentStandbys = topologyDescriptor.getStandbyClusters();\n+        newStandbys.keySet().retainAll(currentStandbys.keySet());\n+        Set<String> standbysToRemove = currentStandbys.keySet();\n+        standbysToRemove.removeAll(newStandbys.keySet());\n+\n+        /*\n+         * Remove standbys that are not in the new config\n+         */\n+        for (String siteID : standbysToRemove) {\n+            stopLogReplicationRuntime(siteID);\n+            topologyDescriptor.removeStandbySite(siteID);\n+        }\n+\n+        //Start the standbys that are in the new config but not in the current config\n+        for (String clusterId : newConfig.getStandbyClusters().keySet()) {\n+            if (runtimeToRemoteCluster.get(clusterId) == null) {\n+                ClusterDescriptor clusterInfo = newConfig.getStandbyClusters().get(clusterId);\n+                topologyDescriptor.addStandbySite(clusterInfo);\n+                startLogReplicationRuntime(clusterInfo);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all relevant streams.\n+     */\n+    private long queryStreamTail() {\n+        Set<String> streamsToReplicate = logReplicationConfig.getStreamsToReplicate();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : streamsToReplicate) {\n+            UUID currentUUID = CorfuRuntime.getStreamID(s);\n+            Map<UUID, Long> tailMap = corfuRuntime.getAddressSpaceView().getAllTails().getStreamTails();\n+            Long currentTail = tailMap.get(currentUUID);\n+            if (currentTail != null) {\n+                maxTail = Math.max(maxTail, currentTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp, calculate how many entries to be sent for all replicated streams.\n+     *\n+     * @param timestamp\n+     */\n+    private long queryEntriesToSend(long timestamp) {\n+        int totalNumEntries = 0;\n+\n+        for (CorfuLogReplicationRuntime runtime: runtimeToRemoteCluster.values()) {\n+            totalNumEntries += runtime.getNumEntriesToSend(timestamp);\n+        }\n+\n+        return totalNumEntries;\n+    }\n+\n+    /**\n+     * Query the current all replication stream log tail and remember the max stream tail.\n+     * Query each standby site information according to the ack information to calculate the number of\n+     * msgs to be sent out.\n+     */\n+    public void prepareSiteRoleChange() {\n+        prepareSiteRoleChangeStreamTail = queryStreamTail();\n+        totalNumEntriesToSend = queryEntriesToSend(prepareSiteRoleChangeStreamTail);\n+    }\n+\n+    /**\n+     * Query the all replication stream log tail and calculate the number of messages to be sent.\n+     * If the max tail has changed, give 0 percent has done.\n+     *\n+     * @return Percentage of work has been done, when it return 100, the replication is done.\n+     */\n+    public int queryReplicationStatus() {\n+        long maxTail = queryStreamTail();\n+\n+        /*\n+         * If the tail has been moved, reset the base calculation\n+         */\n+        if (maxTail > prepareSiteRoleChangeStreamTail) {\n+            prepareSiteRoleChange();\n+        }\n+\n+        long currentNumEntriesToSend = queryEntriesToSend(prepareSiteRoleChangeStreamTail);\n+        log.debug(\"maxTail {} totalNumEntriesToSend  {}  currentNumEntriesToSend {}\", maxTail, totalNumEntriesToSend, currentNumEntriesToSend);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69906091e1d34b1241cf0366c1fd60ac2a8b9e7c"}, "originalPosition": 284}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyMjkxMw==", "bodyText": "For example, the timestamp is 20, and we are interested in stream A[1, 3, 4], B[2, 5, 6], C[7, 8, 20]\nThe result will be (20-4) + (20-6) + (20-20) = 30. The expected result will be 0.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r447422913", "createdAt": "2020-06-30T05:43:26Z", "author": {"login": "zhangn49"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java", "diffHunk": "@@ -0,0 +1,300 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.util.retry.IRetry;\n+import org.corfudb.util.retry.IntervalRetry;\n+import org.corfudb.util.retry.RetryNeededException;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+/**\n+ * This class manages Log Replication for multiple remote (standby) cluster's.\n+ */\n+@Slf4j\n+public class CorfuReplicationManager {\n+\n+    public final static int PERCENTAGE_BASE = 100;\n+\n+    // Keep map of remote cluster ID and the associated log replication runtime (an abstract\n+    // client to that cluster)\n+    private Map<String, CorfuLogReplicationRuntime> runtimeToRemoteCluster = new HashMap<>();\n+\n+    @Setter\n+    @Getter\n+    private volatile TopologyDescriptor topologyDescriptor;\n+\n+    private final LogReplicationConfig logReplicationConfig;\n+\n+    private final NodeDescriptor localNodeDescriptor;\n+\n+    private final CorfuRuntime corfuRuntime;\n+\n+    // TODO (Xiaoqin Ma): can you please add a description on this variable's meaning\n+    private long prepareSiteRoleChangeStreamTail;\n+\n+    private long totalNumEntriesToSend;\n+\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    private final String pluginFilePath;\n+\n+    /**\n+     * Constructor\n+     *\n+     * @param topologyDescriptor description of active and standby cluster' of a given topology\n+     * @param logReplicationConfig log replication configuration\n+     */\n+    public CorfuReplicationManager(TopologyDescriptor topologyDescriptor,\n+                            LogReplicationConfig logReplicationConfig,\n+                            NodeDescriptor localNodeDescriptor,\n+                            LogReplicationMetadataManager metadataManager,\n+                            String pluginFilePath, CorfuRuntime corfuRuntime) {\n+        this.topologyDescriptor = topologyDescriptor;\n+        this.logReplicationConfig = logReplicationConfig;\n+        this.metadataManager = metadataManager;\n+        this.pluginFilePath = pluginFilePath;\n+        this.corfuRuntime = corfuRuntime;\n+\n+        this.localNodeDescriptor = localNodeDescriptor;\n+        this.prepareSiteRoleChangeStreamTail = Address.NON_ADDRESS;\n+        this.totalNumEntriesToSend = 0;\n+    }\n+\n+    /**\n+     * Start Log Replication Manager, this will initiate a runtime against\n+     * each standby cluster, to further start log replication.\n+     */\n+    public void start() {\n+        for (ClusterDescriptor remoteCluster : topologyDescriptor.getStandbyClusters().values()) {\n+            try {\n+                startLogReplicationRuntime(remoteCluster);\n+            } catch (Exception e) {\n+                log.error(\"Failed to start log replication runtime for remote cluster {}\", remoteCluster.getClusterId());\n+\n+                // Remove cluster from the list of standby's, as the cluster discovery process will receive\n+                // change notification when this site becomes stable/available again.\n+                topologyDescriptor.getStandbyClusters().remove(remoteCluster.getClusterId());\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Stop log replication for all the standby sites\n+     */\n+    public void stop() {\n+        for(String clusterId : topologyDescriptor.getStandbyClusters().keySet()) {\n+            stopLogReplicationRuntime(clusterId);\n+        }\n+    }\n+\n+    /**\n+     * Restart connection to remote cluster\n+     */\n+    public void restart(ClusterDescriptor remoteCluster) {\n+        stopLogReplicationRuntime(remoteCluster.getClusterId());\n+        startLogReplicationRuntime(remoteCluster);\n+    }\n+\n+    /**\n+     * Start Log Replication Runtime to a specific standby Cluster\n+     */\n+    private void startLogReplicationRuntime(ClusterDescriptor remoteClusterDescriptor) {\n+\n+        String remoteClusterId = remoteClusterDescriptor.getClusterId();\n+\n+        try {\n+            if (!runtimeToRemoteCluster.containsKey(remoteClusterId)) {\n+                log.info(\"Starting Log Replication Runtime to Standby Cluster id={}\", remoteClusterId);\n+                connect(remoteClusterDescriptor);\n+            } else {\n+                log.warn(\"Log Replication Runtime to remote cluster {}, already exists. Skipping init.\", remoteClusterId);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Caught exception, stop log replication runtime to {}\", remoteClusterDescriptor, e);\n+            stopLogReplicationRuntime(remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * Connect to a remote Log Replicator, through a Log Replication Runtime.\n+     *\n+     * @throws InterruptedException\n+     */\n+    private void connect(ClusterDescriptor remoteCluster) throws InterruptedException {\n+        try {\n+            IRetry.build(IntervalRetry.class, () -> {\n+                try {\n+                    // TODO(Gabriela) : It's cleaner to make LogReplicationConfig agnostic of cluster information (shared across\n+                    //  all clusters) so it would be better to push down the remote cluster id or info as a separate object\n+                    //  this requires to change signatures down the pipe. TBD.\n+                    String localCorfuEndpoint = localNodeDescriptor.getIpAddress() + \":\" + topologyDescriptor.getActiveCluster().getCorfuPort();\n+\n+                    LogReplicationRuntimeParameters parameters = LogReplicationRuntimeParameters.builder()\n+                            .localCorfuEndpoint(localCorfuEndpoint)\n+                            .remoteClusterDescriptor(remoteCluster)\n+                            .localClusterId(localNodeDescriptor.getClusterId())\n+                            .replicationConfig(new LogReplicationConfig(logReplicationConfig.getStreamsToReplicate()))\n+                            .pluginFilePath(pluginFilePath)\n+                            .topologyConfigId(topologyDescriptor.getTopologyConfigId())\n+                            .keyStore(corfuRuntime.getParameters().getKeyStore())\n+                            .tlsEnabled(corfuRuntime.getParameters().isTlsEnabled())\n+                            .ksPasswordFile(corfuRuntime.getParameters().getKsPasswordFile())\n+                            .trustStore(corfuRuntime.getParameters().getTrustStore())\n+                            .tsPasswordFile(corfuRuntime.getParameters().getTsPasswordFile())\n+                            .build();\n+                    CorfuLogReplicationRuntime replicationRuntime = new CorfuLogReplicationRuntime(parameters, metadataManager);\n+                    replicationRuntime.start();\n+                    runtimeToRemoteCluster.put(remoteCluster.getClusterId(), replicationRuntime);\n+                } catch (Exception e) {\n+                    log.error(\"Exception {}. Failed to connect to remote cluster {}. Retry after 1 second.\",\n+                            e, remoteCluster.getClusterId());\n+                    throw new RetryNeededException();\n+                }\n+                return null;\n+            }).run();\n+        } catch (InterruptedException e) {\n+            log.error(\"Unrecoverable exception when attempting to connect to remote cluster.\", e);\n+            throw e;\n+        }\n+    }\n+\n+    /**\n+     * Stop Log Replication to a specific standby Cluster\n+     */\n+    private void stopLogReplicationRuntime(String remoteClusterId) {\n+        CorfuLogReplicationRuntime logReplicationRuntime = runtimeToRemoteCluster.get(remoteClusterId);\n+        if (logReplicationRuntime != null) {\n+            log.info(\"Stop log replication runtime to remote cluster id={}\", remoteClusterId);\n+            logReplicationRuntime.stop();\n+            runtimeToRemoteCluster.remove(remoteClusterId);\n+        } else {\n+            log.warn(\"Runtime not found to remote cluster {}\", remoteClusterId);\n+        }\n+    }\n+\n+    /**\n+     * The notification of change of adding/removing standby's without epoch change.\n+     *\n+     * @param newConfig has the same topologyConfigId as the current config\n+     */\n+    public void processStandbyChange(TopologyDescriptor newConfig) {\n+        if (newConfig.getTopologyConfigId() != topologyDescriptor.getTopologyConfigId()) {\n+            log.error(\"Detected changes in the topology. The new topology descriptor {} doesn't have the same \" +\n+                    \"siteConfigId as the current one {}\", newConfig, topologyDescriptor);\n+            return;\n+        }\n+\n+        Map<String, ClusterDescriptor> newStandbys = newConfig.getStandbyClusters();\n+        Map<String, ClusterDescriptor> currentStandbys = topologyDescriptor.getStandbyClusters();\n+        newStandbys.keySet().retainAll(currentStandbys.keySet());\n+        Set<String> standbysToRemove = currentStandbys.keySet();\n+        standbysToRemove.removeAll(newStandbys.keySet());\n+\n+        /*\n+         * Remove standbys that are not in the new config\n+         */\n+        for (String siteID : standbysToRemove) {\n+            stopLogReplicationRuntime(siteID);\n+            topologyDescriptor.removeStandbySite(siteID);\n+        }\n+\n+        //Start the standbys that are in the new config but not in the current config\n+        for (String clusterId : newConfig.getStandbyClusters().keySet()) {\n+            if (runtimeToRemoteCluster.get(clusterId) == null) {\n+                ClusterDescriptor clusterInfo = newConfig.getStandbyClusters().get(clusterId);\n+                topologyDescriptor.addStandbySite(clusterInfo);\n+                startLogReplicationRuntime(clusterInfo);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all relevant streams.\n+     */\n+    private long queryStreamTail() {\n+        Set<String> streamsToReplicate = logReplicationConfig.getStreamsToReplicate();\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String s : streamsToReplicate) {\n+            UUID currentUUID = CorfuRuntime.getStreamID(s);\n+            Map<UUID, Long> tailMap = corfuRuntime.getAddressSpaceView().getAllTails().getStreamTails();\n+            Long currentTail = tailMap.get(currentUUID);\n+            if (currentTail != null) {\n+                maxTail = Math.max(maxTail, currentTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * Given a timestamp, calculate how many entries to be sent for all replicated streams.\n+     *\n+     * @param timestamp\n+     */\n+    private long queryEntriesToSend(long timestamp) {\n+        int totalNumEntries = 0;\n+\n+        for (CorfuLogReplicationRuntime runtime: runtimeToRemoteCluster.values()) {\n+            totalNumEntries += runtime.getNumEntriesToSend(timestamp);\n+        }\n+\n+        return totalNumEntries;\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxODU3OA=="}, "originalCommit": {"oid": "69906091e1d34b1241cf0366c1fd60ac2a8b9e7c"}, "originalPosition": 255}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6340da7390eba1cb12734ee0c3fa0d1e2666411d", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/6340da7390eba1cb12734ee0c3fa0d1e2666411d", "committedDate": "2020-06-30T06:20:00Z", "message": "Introduce IChannelContext\n\n- Share context between Server and Client Channel\nrequired by certain transport implementations"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwNDYzOTg2", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#pullrequestreview-440463986", "createdAt": "2020-07-01T00:03:34Z", "commit": {"oid": "6340da7390eba1cb12734ee0c3fa0d1e2666411d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwMDowMzozNFrOGrSdDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwMDowMzozNFrOGrSdDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA0NDMwMg==", "bodyText": "Is LogReplicationServer per site or per standby?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2578#discussion_r448044302", "createdAt": "2020-07-01T00:03:34Z", "author": {"login": "xiaoqin2012"}, "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -26,33 +28,36 @@\n  * The Log Replication Server, handles log replication entries--which\n  * represent parts of a Snapshot (full) sync or a Log Entry (delta) sync\n  * and also handles negotiation messages, which allows the Source Replicator\n- * to get a view of the last synchronized point at the remote site.\n+ * to get a view of the last synchronized point at the remote cluster.\n  */\n @Slf4j\n public class LogReplicationServer extends AbstractServer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6340da7390eba1cb12734ee0c3fa0d1e2666411d"}, "originalPosition": 32}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "029452f8f03f8ac36db09e88e596a94fb9c6d42b", "author": {"user": {"login": "annym", "name": "Anny Martinez"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/029452f8f03f8ac36db09e88e596a94fb9c6d42b", "committedDate": "2020-07-01T06:32:13Z", "message": "Address More Comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3302, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}