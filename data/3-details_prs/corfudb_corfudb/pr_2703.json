{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY2NDY2NTY3", "number": 2703, "title": "Stream write path performance optimization.", "bodyText": "Overview\nDescription:\n\nReuse serialization handle, which reduces number of serializations.\nAcquire token after payload serialized, which reduces reader wait time.\n\nRelated issue(s) (if applicable): #1949\nChecklist (Definition of Done):\n\n There are no TODOs left in the code\n Coding conventions (e.g. for logging, unit tests) have been followed\n Change is covered by automated tests\n Public API has Javadoc", "createdAt": "2020-08-12T02:28:03Z", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703", "merged": true, "mergeCommit": {"oid": "1a3d8ac10587bccf9d1af9071df536d2447c0e41"}, "closed": true, "closedAt": "2020-08-17T21:12:45Z", "author": {"login": "WenbinZhu"}, "timelineItems": {"totalCount": 47, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc-CYYvABqjM2NDU3NjI1ODY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc_sE4eAFqTQ2ODE4MzYyMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d11b733c9468e8e485728df3df5fb8b28bf00af8", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/d11b733c9468e8e485728df3df5fb8b28bf00af8", "committedDate": "2020-08-12T02:21:15Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}, "afterCommit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/190a4c0cd682c1dfe7340b572459349816686892", "committedDate": "2020-08-12T02:55:35Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NTc2MzEy", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465576312", "createdAt": "2020-08-12T04:04:09Z", "commit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDowNDoxMFrOG_RBPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDowNDoxMFrOG_RBPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODk5MjMxNw==", "bodyText": "Would be great if you replace boolean by\nenum SerializationMetaData {\n        INCLUDE, EXCLUDE\n    }\n\nif possible", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r468992317", "createdAt": "2020-08-12T04:04:10Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/ILogData.java", "diffHunk": "@@ -51,11 +49,12 @@ public ILogData getSerialized() {\n          * Create a new serialized handle with a reference\n          * to the log data.\n          *\n-         * @param data The log data to manage.\n+         * @param data     the log data to manage\n+         * @param metadata whether metadata needs to be serialized\n          */\n-        public SerializationHandle(ILogData data) {\n+        public SerializationHandle(ILogData data, boolean metadata) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NTc2OTcx", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465576971", "createdAt": "2020-08-12T04:06:44Z", "commit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDowNjo0NFrOG_RDeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDowNjo0NFrOG_RDeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODk5Mjg4OQ==", "bodyText": "a better one getBackpointerMap().containsKey(stream)", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r468992889", "createdAt": "2020-08-12T04:06:44Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/IMetadata.java", "diffHunk": "@@ -54,11 +47,12 @@\n \n     /**\n      * Get whether or not this entry contains a given stream.\n-     * @param stream    The stream to check.\n-     * @return          True, if the entry contains the given stream.\n+     *\n+     * @param stream The stream to check.\n+     * @return True, if the entry contains the given stream.\n      */\n     default boolean containsStream(UUID stream) {\n-        return  getBackpointerMap().keySet().contains(stream);\n+        return getBackpointerMap().keySet().contains(stream);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NTc4Njk5", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465578699", "createdAt": "2020-08-12T04:13:16Z", "commit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDoxMzoxNlrOG_RJFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDoxMzoxNlrOG_RJFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODk5NDMyNw==", "bodyText": "it should be static\n\ntake into account how many instances of LogData we have when Corfu works it should be a huge overhead", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r468994327", "createdAt": "2020-08-12T04:13:16Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -32,14 +31,20 @@\n     @Getter\n     byte[] data;\n \n-    private ByteBuf serializedCache = null;\n+    private SerializedCache serializedCache = null;\n \n     private int lastKnownSize = NOT_KNOWN;\n \n     private final transient AtomicReference<Object> payload = new AtomicReference<>();\n \n     private final EnumMap<LogUnitMetadataType, Object> metadataMap;\n \n+    @RequiredArgsConstructor\n+    private class SerializedCache {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NTc5NTg2", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465579586", "createdAt": "2020-08-12T04:16:08Z", "commit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDoxNjowOFrOG_RMJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDoxNjowOFrOG_RMJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODk5NTEwOA==", "bodyText": "I think serializedCache should be Optional it will make code more secure and less error-prone", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r468995108", "createdAt": "2020-08-12T04:16:08Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -32,14 +31,20 @@\n     @Getter\n     byte[] data;\n \n-    private ByteBuf serializedCache = null;\n+    private SerializedCache serializedCache = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NTg5OTIz", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465589923", "createdAt": "2020-08-12T04:54:28Z", "commit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDo1NDoyOFrOG_RwKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNDo1NDoyOFrOG_RwKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAwNDMzMQ==", "bodyText": "if you invert the if condition it makes code a bit more straightforward\n    public synchronized void acquireBuffer(boolean metadata) {\n        if (serializedCache == null) {\n            ByteBuf buf = Unpooled.buffer();\n            int metadataOffset;\n            \n            if (metadata) {\n                metadataOffset = doSerializeInternal(buf);\n            } else {\n                doSerializePayloadInternal(buf);\n                metadataOffset = buf.writerIndex();\n            }\n            serializedCache = new SerializedCache(buf, metadataOffset);\n        } else {\n            if (metadata) {\n                serializedCache.buffer.resetReaderIndex();\n                serializedCache.buffer.writerIndex(serializedCache.metadataOffset);\n                doSerializeMetadataInternal(serializedCache.buffer);\n            }\n            serializedCache.buffer.retain();\n        }\n    }", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r469004331", "createdAt": "2020-08-12T04:54:28Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -119,20 +124,32 @@ public Object getPayload(CorfuRuntime runtime) {\n     @Override\n     public synchronized void releaseBuffer() {\n         if (serializedCache != null) {\n-            serializedCache.release();\n-            if (serializedCache.refCnt() == 0) {\n+            serializedCache.buffer.release();\n+            if (serializedCache.buffer.refCnt() == 0) {\n                 serializedCache = null;\n             }\n         }\n     }\n \n     @Override\n-    public synchronized void acquireBuffer() {\n-        if (serializedCache == null) {\n-            serializedCache = Unpooled.buffer();\n-            doSerializeInternal(serializedCache);\n+    public synchronized void acquireBuffer(boolean metadata) {\n+        if (serializedCache != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892"}, "originalPosition": 82}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "190a4c0cd682c1dfe7340b572459349816686892", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/190a4c0cd682c1dfe7340b572459349816686892", "committedDate": "2020-08-12T02:55:35Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}, "afterCommit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/eade3dd0fec53507e9e180d5965e92a6addc93fa", "committedDate": "2020-08-12T05:28:50Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NjI3Mzkz", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465627393", "createdAt": "2020-08-12T06:37:19Z", "commit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjozNzoxOVrOG_TsKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjozNzoxOVrOG_TsKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAzNjA3NQ==", "bodyText": "This is a perfect place to use a CompositeByteBuf. The logic of maintaining an offset and overwriting can be greatly simplified. You can also remove the SerializedCache class\n        CompositeByteBuf serializationCache = Unpooled.compositeBuffer();\n        ByteBuf metadata = Unpooled.buffer();\n        ByteBuf payload = Unpooled.buffer();\n        serializationCache.addComponents(metadata, payload);", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r469036075", "createdAt": "2020-08-12T06:37:19Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -119,20 +124,32 @@ public Object getPayload(CorfuRuntime runtime) {\n     @Override\n     public synchronized void releaseBuffer() {\n         if (serializedCache != null) {\n-            serializedCache.release();\n-            if (serializedCache.refCnt() == 0) {\n+            serializedCache.buffer.release();\n+            if (serializedCache.buffer.refCnt() == 0) {\n                 serializedCache = null;\n             }\n         }\n     }\n \n     @Override\n-    public synchronized void acquireBuffer() {\n-        if (serializedCache == null) {\n-            serializedCache = Unpooled.buffer();\n-            doSerializeInternal(serializedCache);\n+    public synchronized void acquireBuffer(boolean metadata) {\n+        if (serializedCache != null) {\n+            if (metadata) {\n+                serializedCache.buffer.resetReaderIndex();\n+                serializedCache.buffer.writerIndex(serializedCache.metadataOffset);\n+                doSerializeMetadataInternal(serializedCache.buffer);\n+            }\n+            serializedCache.buffer.retain();\n+            return;\n+        }\n+\n+        ByteBuf buf = Unpooled.buffer();\n+        if (metadata) {\n+            int metadataOffset = doSerializeInternal(buf);\n+            serializedCache = new SerializedCache(buf, metadataOffset);\n         } else {\n-            serializedCache.retain();\n+            doSerializePayloadInternal(buf);\n+            serializedCache = new SerializedCache(buf, buf.writerIndex());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NjI5MzQ4", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465629348", "createdAt": "2020-08-12T06:41:22Z", "commit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo0MToyMlrOG_TykA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo0MToyMlrOG_TykA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAzNzcxMg==", "bodyText": "I think the metadata serialization is cheap enough to actually do it twice.\nI would just serialize both metadata + payload here. Then after getting a token just call doSerializeMetadataInternal with the last ByteBuf of the Composite buffer. It will overwrite it with the new token information.\nInstead of adding the boolean here, you can just introduce a method updateMetadata that will rewrite the metadata portion.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r469037712", "createdAt": "2020-08-12T06:41:22Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/ILogData.java", "diffHunk": "@@ -67,13 +66,28 @@ public void close() {\n         }\n     }\n \n-    void releaseBuffer();\n+    /**\n+     * Get the serialization handle of this entry that manages\n+     * the lifetime of the serialized copy.\n+     *\n+     * @param metadata whether metadata needs to be serialized\n+     * @return a serialization handle of this entry\n+     */\n+    default SerializationHandle getSerializedForm(boolean metadata) {\n+        return new SerializationHandle(this, metadata);\n+    }\n \n-    void acquireBuffer();\n+    /**\n+     * Release the serialization buffer.\n+     */\n+    void releaseBuffer();\n \n-    default SerializationHandle getSerializedForm() {\n-        return new SerializationHandle(this);\n-    }\n+    /**\n+     * Acquire the serialization buffer.\n+     *\n+     * @param metadata whether metadata needs to be serialized\n+     */\n+    void acquireBuffer(boolean metadata);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "originalPosition": 83}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NjMwNjE3", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465630617", "createdAt": "2020-08-12T06:44:05Z", "commit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo0NDowNVrOG_T2wA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo0NDowNVrOG_T2wA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAzODc4NA==", "bodyText": "Can remove the first clause if you change maxWriteSize to Integer.MAX_VALUE", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r469038784", "createdAt": "2020-08-12T06:44:05Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -340,12 +359,19 @@ public String toString() {\n      * Verify that max payload is enforced for the specified limit.\n      *\n      * @param limit Max write limit.\n+     * @return the serialized size of the payload\n      */\n-    public void checkMaxWriteSize(int limit) {\n-        try (ILogData.SerializationHandle sh = this.getSerializedForm()) {\n-            if (limit != 0 && getSizeEstimate() > limit) {\n-                throw new WriteSizeException(getSizeEstimate(), limit);\n-            }\n+    public int checkMaxWriteSize(int limit) {\n+        if (serializedCache == null) {\n+            throw new IllegalStateException(\"checkMaxWriteSize requires serialized form\");\n         }\n+\n+        int payloadSize = getSizeEstimate();\n+\n+        if (limit != 0 && payloadSize > limit) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "originalPosition": 220}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NjM0NTkz", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465634593", "createdAt": "2020-08-12T06:51:47Z", "commit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo1MTo0N1rOG_UEew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo1MTo0N1rOG_UEew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTA0MjI5OQ==", "bodyText": "This doesn't look correct.\nSince the SerializationHandle is acquired before the for-loop retries that will end up calling preCommitCallback will change the payload, but it will not be re-serialized. Only the token portion will be. This can introduce correctness issues to the queue ordering.\nRIP. I don't remember seeing a PR that introduced this code. It seems like it went in #2498, but it has no reviews.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r469042299", "createdAt": "2020-08-12T06:51:47Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -132,90 +132,98 @@ public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictIn\n                        @Nonnull CacheOption cacheOption, @Nonnull UUID... streamIDs) {\n \n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n-\n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n-\n         TokenResponse tokenResponse = null;\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Go to the sequencer, grab a token to write.\n-            tokenResponse = conflictInfo == null\n-                    ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n-                    : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n-\n-            // Is our token a valid type?\n-            AbortCause abortCause = null;\n-            switch (tokenResponse.getRespType()) {\n-                case TX_ABORT_CONFLICT:\n-                    abortCause = AbortCause.CONFLICT;\n-                    break;\n-                case TX_ABORT_NEWSEQ:\n-                    abortCause = AbortCause.NEW_SEQUENCER;\n-                    break;\n-                case TX_ABORT_SEQ_OVERFLOW:\n-                    abortCause = AbortCause.SEQUENCER_OVERFLOW;\n-                    break;\n-                case TX_ABORT_SEQ_TRIM:\n-                    abortCause = AbortCause.SEQUENCER_TRIM;\n-                    break;\n-            }\n \n-            if (abortCause != null) {\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(), abortCause,\n-                        TransactionalContext.getCurrentContext());\n-            }\n-\n-            try {\n-                if (TransactionalContext.isInTransaction()) {\n-                    // If this transaction has entries that wish to capture the committed address\n-                    // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n-                    // Note that we might invoke the same method multiple times on retries,\n-                    // which means the preCommitCallback must be idempotent.\n-                    TokenResponse finalTokenResponse = tokenResponse;\n-                    log.debug(\"append: Invoking {} preCommitListeners\",\n-                            TransactionalContext.getRootContext().getPreCommitListeners().size());\n-                    TransactionalContext.getRootContext()\n-                            .getPreCommitListeners()\n-                            .forEach(e -> e.preCommitCallback(finalTokenResponse));\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(false)) {\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n+\n+            for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n+                // Go to the sequencer, grab a token to write.\n+                tokenResponse = conflictInfo == null\n+                        ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n+                        : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n+\n+                // Is our token a valid type?\n+                AbortCause abortCause = null;\n+                switch (tokenResponse.getRespType()) {\n+                    case TX_ABORT_CONFLICT:\n+                        abortCause = AbortCause.CONFLICT;\n+                        break;\n+                    case TX_ABORT_NEWSEQ:\n+                        abortCause = AbortCause.NEW_SEQUENCER;\n+                        break;\n+                    case TX_ABORT_SEQ_OVERFLOW:\n+                        abortCause = AbortCause.SEQUENCER_OVERFLOW;\n+                        break;\n+                    case TX_ABORT_SEQ_TRIM:\n+                        abortCause = AbortCause.SEQUENCER_TRIM;\n+                        break;\n                 }\n \n-                // Attempt to write to the log.\n-                runtime.getAddressSpaceView().write(tokenResponse, ld, cacheOption);\n-                // If we're here, we succeeded, return the acquired token.\n-                return tokenResponse.getSequence();\n-            } catch (OverwriteException oe) {\n-                // We were overwritten, get a new token and try again.\n-                log.warn(\"append[{}]: Overwritten after {} retries, streams {}\",\n-                        tokenResponse.getSequence(), x,\n-                        Arrays.stream(streamIDs).map(Utils::toReadableId).collect(Collectors.toSet()));\n-\n-                if (conflictInfo != null) {\n-                    // On retry, check for conflicts only from the previous attempt position,\n-                    // otherwise the transaction will always conflict with itself.\n-                    conflictInfo.setSnapshotTimestamp(tokenResponse.getToken());\n+                if (abortCause != null) {\n+                    throw new TransactionAbortedException(\n+                            conflictInfo,\n+                            tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n+                            tokenResponse.getToken().getSequence(), abortCause,\n+                            TransactionalContext.getCurrentContext());\n                 }\n \n-            } catch (StaleTokenException se) {\n-                // the epoch changed from when we grabbed the token from sequencer\n-                log.warn(\"append[{}]: StaleToken, streams {}\", tokenResponse.getSequence(),\n-                        Arrays.stream(streamIDs).map(Utils::toReadableId).collect(Collectors.toSet()));\n-\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(),\n-                        AbortCause.NEW_SEQUENCER, // in the future perhaps define a new AbortCause?\n-                        TransactionalContext.getCurrentContext());\n+                try {\n+                    if (TransactionalContext.isInTransaction()) {\n+                        // If this transaction has entries that wish to capture the committed address\n+                        // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n+                        // Note that we might invoke the same method multiple times on retries,\n+                        // which means the preCommitCallback must be idempotent.\n+                        TokenResponse finalTokenResponse = tokenResponse;\n+                        log.debug(\"append: Invoking {} preCommitListeners\",\n+                                TransactionalContext.getRootContext().getPreCommitListeners().size());\n+                        TransactionalContext.getRootContext()\n+                                .getPreCommitListeners()\n+                                .forEach(e -> e.preCommitCallback(finalTokenResponse));\n+                    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "originalPosition": 128}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NjM1NTcy", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465635572", "createdAt": "2020-08-12T06:53:36Z", "commit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo1MzozNlrOG_UHiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo1MzozNlrOG_UHiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTA0MzA4MA==", "bodyText": "Can you just set the token here instead of propegating it down and setting it later. Ideally, we should just send a LogData object to the write method", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r469043080", "createdAt": "2020-08-12T06:53:36Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -132,90 +132,98 @@ public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictIn\n                        @Nonnull CacheOption cacheOption, @Nonnull UUID... streamIDs) {\n \n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n-\n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n-\n         TokenResponse tokenResponse = null;\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Go to the sequencer, grab a token to write.\n-            tokenResponse = conflictInfo == null\n-                    ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n-                    : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n-\n-            // Is our token a valid type?\n-            AbortCause abortCause = null;\n-            switch (tokenResponse.getRespType()) {\n-                case TX_ABORT_CONFLICT:\n-                    abortCause = AbortCause.CONFLICT;\n-                    break;\n-                case TX_ABORT_NEWSEQ:\n-                    abortCause = AbortCause.NEW_SEQUENCER;\n-                    break;\n-                case TX_ABORT_SEQ_OVERFLOW:\n-                    abortCause = AbortCause.SEQUENCER_OVERFLOW;\n-                    break;\n-                case TX_ABORT_SEQ_TRIM:\n-                    abortCause = AbortCause.SEQUENCER_TRIM;\n-                    break;\n-            }\n \n-            if (abortCause != null) {\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(), abortCause,\n-                        TransactionalContext.getCurrentContext());\n-            }\n-\n-            try {\n-                if (TransactionalContext.isInTransaction()) {\n-                    // If this transaction has entries that wish to capture the committed address\n-                    // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n-                    // Note that we might invoke the same method multiple times on retries,\n-                    // which means the preCommitCallback must be idempotent.\n-                    TokenResponse finalTokenResponse = tokenResponse;\n-                    log.debug(\"append: Invoking {} preCommitListeners\",\n-                            TransactionalContext.getRootContext().getPreCommitListeners().size());\n-                    TransactionalContext.getRootContext()\n-                            .getPreCommitListeners()\n-                            .forEach(e -> e.preCommitCallback(finalTokenResponse));\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(false)) {\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n+\n+            for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n+                // Go to the sequencer, grab a token to write.\n+                tokenResponse = conflictInfo == null\n+                        ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n+                        : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n+\n+                // Is our token a valid type?\n+                AbortCause abortCause = null;\n+                switch (tokenResponse.getRespType()) {\n+                    case TX_ABORT_CONFLICT:\n+                        abortCause = AbortCause.CONFLICT;\n+                        break;\n+                    case TX_ABORT_NEWSEQ:\n+                        abortCause = AbortCause.NEW_SEQUENCER;\n+                        break;\n+                    case TX_ABORT_SEQ_OVERFLOW:\n+                        abortCause = AbortCause.SEQUENCER_OVERFLOW;\n+                        break;\n+                    case TX_ABORT_SEQ_TRIM:\n+                        abortCause = AbortCause.SEQUENCER_TRIM;\n+                        break;\n                 }\n \n-                // Attempt to write to the log.\n-                runtime.getAddressSpaceView().write(tokenResponse, ld, cacheOption);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "originalPosition": 83}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NjM3MTI3", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-465637127", "createdAt": "2020-08-12T06:56:17Z", "commit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo1NjoxN1rOG_UMjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQwNjo1NjoxN1rOG_UMjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTA0NDM2Ng==", "bodyText": "Instead of having checkMaxWriteSize return the size, you can directly access it from the serialization handle", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r469044366", "createdAt": "2020-08-12T06:56:17Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/stream/AbstractQueuedStreamView.java", "diffHunk": "@@ -177,65 +177,72 @@ public long append(Object object,\n                        Function<TokenResponse, Boolean> deacquisitionCallback) {\n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n \n-        // Validate if the  size of the log data is under max write size.\n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n-\n-        // First, we get a token from the sequencer.\n-        TokenResponse tokenResponse = runtime.getSequencerView()\n-                .next(id);\n-\n-        // We loop forever until we are interrupted, since we may have to\n-        // acquire an address several times until we are successful.\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Next, we call the acquisitionCallback, if present, informing\n-            // the client of the token that we acquired.\n-            if (acquisitionCallback != null) {\n-                if (!acquisitionCallback.apply(tokenResponse)) {\n-                    // The client did not like our token, so we end here.\n-                    // We'll leave the hole to be filled by the client or\n-                    // someone else.\n-                    log.debug(\"Acquisition rejected token={}\", tokenResponse);\n-                    return -1L;\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(false)) {\n+            // Validate if the  size of the log data is under max write size.\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa"}, "originalPosition": 30}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "eade3dd0fec53507e9e180d5965e92a6addc93fa", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/eade3dd0fec53507e9e180d5965e92a6addc93fa", "committedDate": "2020-08-12T05:28:50Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}, "afterCommit": {"oid": "a82780986fc1e6abd76367d2b7287e3ba88b57d6", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/a82780986fc1e6abd76367d2b7287e3ba88b57d6", "committedDate": "2020-08-12T19:11:41Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0f780e134d494487ab314cbb778a542554916f44", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/0f780e134d494487ab314cbb778a542554916f44", "committedDate": "2020-08-13T03:12:50Z", "message": "Re-serialize payload after pre-commit listener runs."}, "afterCommit": {"oid": "7392463f51fd244363745d6206c0cc111d461c2f", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/7392463f51fd244363745d6206c0cc111d461c2f", "committedDate": "2020-08-13T03:14:09Z", "message": "Re-serialize payload after pre-commit listener runs."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7392463f51fd244363745d6206c0cc111d461c2f", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/7392463f51fd244363745d6206c0cc111d461c2f", "committedDate": "2020-08-13T03:14:09Z", "message": "Re-serialize payload after pre-commit listener runs."}, "afterCommit": {"oid": "9d965b3b93982ae565641a77c3efd6688fe64d06", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/9d965b3b93982ae565641a77c3efd6688fe64d06", "committedDate": "2020-08-13T04:03:04Z", "message": "Re-serialize payload after pre-commit listener runs."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9d965b3b93982ae565641a77c3efd6688fe64d06", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/9d965b3b93982ae565641a77c3efd6688fe64d06", "committedDate": "2020-08-13T04:03:04Z", "message": "Re-serialize payload after pre-commit listener runs."}, "afterCommit": {"oid": "a3ec98e56ad43d60a902b60b2349100c08b144e1", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/a3ec98e56ad43d60a902b60b2349100c08b144e1", "committedDate": "2020-08-13T19:43:27Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NzExMTgw", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-467711180", "createdAt": "2020-08-14T16:29:10Z", "commit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNjoyOToxMFrOHA7AxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNjoyOToxMFrOHA7AxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDcyODkwMQ==", "bodyText": "please add @NonNull annotation to guarantee that buffers can't be null", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r470728901", "createdAt": "2020-08-14T16:29:10Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -32,14 +31,20 @@\n     @Getter\n     byte[] data;\n \n-    private ByteBuf serializedCache = null;\n+    private SerializedCache serializedCache = null;\n \n     private int lastKnownSize = NOT_KNOWN;\n \n     private final transient AtomicReference<Object> payload = new AtomicReference<>();\n \n     private final EnumMap<LogUnitMetadataType, Object> metadataMap;\n \n+    @RequiredArgsConstructor\n+    private static class SerializedCache {\n+        private final ByteBuf buffer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NzE0Mjkw", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-467714290", "createdAt": "2020-08-14T16:34:09Z", "commit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNjozNDowOVrOHA7Kmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNjozNDowOVrOHA7Kmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDczMTQxOQ==", "bodyText": "Doesn't release mean also reset refCnt?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r470731419", "createdAt": "2020-08-14T16:34:09Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -119,20 +124,42 @@ public Object getPayload(CorfuRuntime runtime) {\n     @Override\n     public synchronized void releaseBuffer() {\n         if (serializedCache != null) {\n-            serializedCache.release();\n-            if (serializedCache.refCnt() == 0) {\n+            serializedCache.buffer.release();\n+            if (serializedCache.buffer.refCnt() == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NzM0MDc4", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-467734078", "createdAt": "2020-08-14T17:05:54Z", "commit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNzowNTo1NFrOHA8Iig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNzowNTo1NFrOHA8Iig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDc0NzI3NA==", "bodyText": "please make metadataMap static, otherwise, it will be a huge overhead\nLooks like code was changed earlier, and metadataTypeMap is not used anymore.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r470747274", "createdAt": "2020-08-14T17:05:54Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -166,11 +193,7 @@ public LogData(ByteBuf buf) {\n             data = null;\n         }\n \n-        if (type.isMetadataAware()) {\n-            metadataMap = ICorfuPayload.enumMapFromBuffer(buf, IMetadata.LogUnitMetadataType.class);\n-        } else {\n-            metadataMap = new EnumMap<>(IMetadata.LogUnitMetadataType.class);\n-        }\n+        metadataMap = ICorfuPayload.enumMapFromBuffer(buf, IMetadata.LogUnitMetadataType.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "originalPosition": 121}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3ODA0ODYw", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-467804860", "createdAt": "2020-08-14T18:49:30Z", "commit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODo0OTozMVrOHA_6qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODo0OTozMVrOHA_6qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDgwOTI1OQ==", "bodyText": "shouldn't we create an instance of serializedCache?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r470809259", "createdAt": "2020-08-14T18:49:31Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -119,20 +124,42 @@ public Object getPayload(CorfuRuntime runtime) {\n     @Override\n     public synchronized void releaseBuffer() {\n         if (serializedCache != null) {\n-            serializedCache.release();\n-            if (serializedCache.refCnt() == 0) {\n+            serializedCache.buffer.release();\n+            if (serializedCache.buffer.refCnt() == 0) {\n                 serializedCache = null;\n             }\n         }\n     }\n \n     @Override\n-    public synchronized void acquireBuffer() {\n+    public synchronized void acquireBuffer(boolean metadata) {\n         if (serializedCache == null) {\n-            serializedCache = Unpooled.buffer();\n-            doSerializeInternal(serializedCache);\n+            acquireBufferInternal(metadata);\n         } else {\n-            serializedCache.retain();\n+            if (metadata) {\n+                serializedCache.buffer.resetReaderIndex();\n+                serializedCache.buffer.writerIndex(serializedCache.metadataOffset);\n+                doSerializeMetadataInternal(serializedCache.buffer);\n+            }\n+            serializedCache.buffer.retain();\n+        }\n+    }\n+\n+     public synchronized void updateAcquiredBuffer(boolean metadata) {\n+        if (serializedCache == null) {\n+            return;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "originalPosition": 96}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3ODA2MTgz", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-467806183", "createdAt": "2020-08-14T18:51:42Z", "commit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODo1MTo0MlrOHA__Ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODo1MTo0MlrOHA__Ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDgxMDM4Nw==", "bodyText": "when one small method throws two different exceptions it seems too much, can we throw the only WriteSizeException?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r470810387", "createdAt": "2020-08-14T18:51:42Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -340,12 +369,19 @@ public String toString() {\n      * Verify that max payload is enforced for the specified limit.\n      *\n      * @param limit Max write limit.\n+     * @return the serialized size of the payload\n      */\n-    public void checkMaxWriteSize(int limit) {\n-        try (ILogData.SerializationHandle sh = this.getSerializedForm()) {\n-            if (limit != 0 && getSizeEstimate() > limit) {\n-                throw new WriteSizeException(getSizeEstimate(), limit);\n-            }\n+    public int checkMaxWriteSize(int limit) {\n+        if (serializedCache == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "originalPosition": 223}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3ODA2NTk3", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-467806597", "createdAt": "2020-08-14T18:52:21Z", "commit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODo1MjoyMVrOHBAANw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODo1MjoyMVrOHBAANw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDgxMDY3OQ==", "bodyText": "please rename x", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r470810679", "createdAt": "2020-08-14T18:52:21Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -131,91 +131,105 @@ public void gc(long trimMark) {\n     public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictInfo,\n                        @Nonnull CacheOption cacheOption, @Nonnull UUID... streamIDs) {\n \n+        final boolean serializeMetadata = false;\n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n-\n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n-\n         TokenResponse tokenResponse = null;\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Go to the sequencer, grab a token to write.\n-            tokenResponse = conflictInfo == null\n-                    ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n-                    : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n-\n-            // Is our token a valid type?\n-            AbortCause abortCause = null;\n-            switch (tokenResponse.getRespType()) {\n-                case TX_ABORT_CONFLICT:\n-                    abortCause = AbortCause.CONFLICT;\n-                    break;\n-                case TX_ABORT_NEWSEQ:\n-                    abortCause = AbortCause.NEW_SEQUENCER;\n-                    break;\n-                case TX_ABORT_SEQ_OVERFLOW:\n-                    abortCause = AbortCause.SEQUENCER_OVERFLOW;\n-                    break;\n-                case TX_ABORT_SEQ_TRIM:\n-                    abortCause = AbortCause.SEQUENCER_TRIM;\n-                    break;\n-            }\n \n-            if (abortCause != null) {\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(), abortCause,\n-                        TransactionalContext.getCurrentContext());\n-            }\n-\n-            try {\n-                if (TransactionalContext.isInTransaction()) {\n-                    // If this transaction has entries that wish to capture the committed address\n-                    // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n-                    // Note that we might invoke the same method multiple times on retries,\n-                    // which means the preCommitCallback must be idempotent.\n-                    TokenResponse finalTokenResponse = tokenResponse;\n-                    log.debug(\"append: Invoking {} preCommitListeners\",\n-                            TransactionalContext.getRootContext().getPreCommitListeners().size());\n-                    TransactionalContext.getRootContext()\n-                            .getPreCommitListeners()\n-                            .forEach(e -> e.preCommitCallback(finalTokenResponse));\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(serializeMetadata)) {\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n+\n+            for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a"}, "originalPosition": 61}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/42e4fd156fdb7b26bf7e6404f9a8a13a4c84236a", "committedDate": "2020-08-14T07:43:02Z", "message": "Merge branch 'master' into write_path_optimization"}, "afterCommit": {"oid": "42747cc1eca8c035ed33bc2ad6b156c382cb80de", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/42747cc1eca8c035ed33bc2ad6b156c382cb80de", "committedDate": "2020-08-14T19:44:51Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "42747cc1eca8c035ed33bc2ad6b156c382cb80de", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/42747cc1eca8c035ed33bc2ad6b156c382cb80de", "committedDate": "2020-08-14T19:44:51Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}, "afterCommit": {"oid": "90c9616470241e60f1d44db30fe216a574471ed5", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/90c9616470241e60f1d44db30fe216a574471ed5", "committedDate": "2020-08-14T19:45:50Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cb157a003af72597b10dd528909a6260aebb047d", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/cb157a003af72597b10dd528909a6260aebb047d", "committedDate": "2020-08-14T21:39:09Z", "message": "Merge branch 'master' into write_path_optimization"}, "afterCommit": {"oid": "4b704b757d5571fa30ed9cff7c40a0ee30e58f44", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/4b704b757d5571fa30ed9cff7c40a0ee30e58f44", "committedDate": "2020-08-15T00:26:52Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3OTQ1OTE4", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-467945918", "createdAt": "2020-08-15T04:09:06Z", "commit": {"oid": "8d23cfab651e4fe53a66073c7904a9077626ac5c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQwNDowOTowNlrOHBHkvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQwNDowOTowNlrOHBHkvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNDcxOQ==", "bodyText": "You can slice the buffer at the metadataOffset offset", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r470934719", "createdAt": "2020-08-15T04:09:06Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -119,20 +124,42 @@ public Object getPayload(CorfuRuntime runtime) {\n     @Override\n     public synchronized void releaseBuffer() {\n         if (serializedCache != null) {\n-            serializedCache.release();\n-            if (serializedCache.refCnt() == 0) {\n+            serializedCache.buffer.release();\n+            if (serializedCache.buffer.refCnt() == 0) {\n                 serializedCache = null;\n             }\n         }\n     }\n \n     @Override\n-    public synchronized void acquireBuffer() {\n+    public synchronized void acquireBuffer(boolean metadata) {\n         if (serializedCache == null) {\n-            serializedCache = Unpooled.buffer();\n-            doSerializeInternal(serializedCache);\n+            acquireBufferInternal(metadata);\n         } else {\n-            serializedCache.retain();\n+            if (metadata) {\n+                serializedCache.buffer.resetReaderIndex();\n+                serializedCache.buffer.writerIndex(serializedCache.metadataOffset);\n+                doSerializeMetadataInternal(serializedCache.buffer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d23cfab651e4fe53a66073c7904a9077626ac5c"}, "originalPosition": 88}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3OTQ2MzQz", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-467946343", "createdAt": "2020-08-15T04:17:01Z", "commit": {"oid": "8d23cfab651e4fe53a66073c7904a9077626ac5c"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQwNDoxNzowMlrOHBHnXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQwNDoxNzowMlrOHBHnXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNTM5MA==", "bodyText": "acquireBufferInternsl is really serializing data, making the name misleading. Perhaps something like serializeToNewBuffer()", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r470935390", "createdAt": "2020-08-15T04:17:02Z", "author": {"login": "hisundar"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -119,20 +124,42 @@ public Object getPayload(CorfuRuntime runtime) {\n     @Override\n     public synchronized void releaseBuffer() {\n         if (serializedCache != null) {\n-            serializedCache.release();\n-            if (serializedCache.refCnt() == 0) {\n+            serializedCache.buffer.release();\n+            if (serializedCache.buffer.refCnt() == 0) {\n                 serializedCache = null;\n             }\n         }\n     }\n \n     @Override\n-    public synchronized void acquireBuffer() {\n+    public synchronized void acquireBuffer(boolean metadata) {\n         if (serializedCache == null) {\n-            serializedCache = Unpooled.buffer();\n-            doSerializeInternal(serializedCache);\n+            acquireBufferInternal(metadata);\n         } else {\n-            serializedCache.retain();\n+            if (metadata) {\n+                serializedCache.buffer.resetReaderIndex();\n+                serializedCache.buffer.writerIndex(serializedCache.metadataOffset);\n+                doSerializeMetadataInternal(serializedCache.buffer);\n+            }\n+            serializedCache.buffer.retain();\n+        }\n+    }\n+\n+     public synchronized void updateAcquiredBuffer(boolean metadata) {\n+        if (serializedCache == null) {\n+            return;\n+        }\n+        acquireBufferInternal(metadata);\n+    }\n+\n+    private void acquireBufferInternal(boolean metadata) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d23cfab651e4fe53a66073c7904a9077626ac5c"}, "originalPosition": 101}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8d23cfab651e4fe53a66073c7904a9077626ac5c", "author": {"user": {"login": "xnull", "name": "Viacheslav"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/8d23cfab651e4fe53a66073c7904a9077626ac5c", "committedDate": "2020-08-15T03:58:45Z", "message": "Merge branch 'master' into write_path_optimization"}, "afterCommit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/d5332163e88b32a943770e747de84d8d2402869c", "committedDate": "2020-08-15T04:47:21Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDA5NzQ0", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468009744", "createdAt": "2020-08-15T18:20:17Z", "commit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODoyMDoxOFrOHBM1RQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODoyMDoxOFrOHBM1RQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAyMDg2OQ==", "bodyText": "we don't break the cycle here, is it correct? Are we looking for the latest abortCause on the list?\nThat looks a bit unusual. Could you please explain what expected behavior here?\nI see there is an if condition", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471020869", "createdAt": "2020-08-15T18:20:18Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -131,91 +131,105 @@ public void gc(long trimMark) {\n     public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictInfo,\n                        @Nonnull CacheOption cacheOption, @Nonnull UUID... streamIDs) {\n \n+        final boolean serializeMetadata = false;\n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n-\n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n-\n         TokenResponse tokenResponse = null;\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Go to the sequencer, grab a token to write.\n-            tokenResponse = conflictInfo == null\n-                    ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n-                    : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n-\n-            // Is our token a valid type?\n-            AbortCause abortCause = null;\n-            switch (tokenResponse.getRespType()) {\n-                case TX_ABORT_CONFLICT:\n-                    abortCause = AbortCause.CONFLICT;\n-                    break;\n-                case TX_ABORT_NEWSEQ:\n-                    abortCause = AbortCause.NEW_SEQUENCER;\n-                    break;\n-                case TX_ABORT_SEQ_OVERFLOW:\n-                    abortCause = AbortCause.SEQUENCER_OVERFLOW;\n-                    break;\n-                case TX_ABORT_SEQ_TRIM:\n-                    abortCause = AbortCause.SEQUENCER_TRIM;\n-                    break;\n-            }\n \n-            if (abortCause != null) {\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(), abortCause,\n-                        TransactionalContext.getCurrentContext());\n-            }\n-\n-            try {\n-                if (TransactionalContext.isInTransaction()) {\n-                    // If this transaction has entries that wish to capture the committed address\n-                    // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n-                    // Note that we might invoke the same method multiple times on retries,\n-                    // which means the preCommitCallback must be idempotent.\n-                    TokenResponse finalTokenResponse = tokenResponse;\n-                    log.debug(\"append: Invoking {} preCommitListeners\",\n-                            TransactionalContext.getRootContext().getPreCommitListeners().size());\n-                    TransactionalContext.getRootContext()\n-                            .getPreCommitListeners()\n-                            .forEach(e -> e.preCommitCallback(finalTokenResponse));\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(serializeMetadata)) {\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n+\n+            for (int retry = 0; retry < runtime.getParameters().getWriteRetry(); retry++) {\n+                // Go to the sequencer, grab a token to write.\n+                tokenResponse = conflictInfo == null\n+                        ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n+                        : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n+\n+                // Is our token a valid type?\n+                AbortCause abortCause = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "originalPosition": 68}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDA5ODcx", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468009871", "createdAt": "2020-08-15T18:22:30Z", "commit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODoyMjozMFrOHBM2AQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODoyMjozMFrOHBM2AQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAyMTA1Nw==", "bodyText": "the whole method is quite big, can you split it to a couple of smaller ones?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471021057", "createdAt": "2020-08-15T18:22:30Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -131,91 +131,105 @@ public void gc(long trimMark) {\n     public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictInfo,\n                        @Nonnull CacheOption cacheOption, @Nonnull UUID... streamIDs) {\n \n+        final boolean serializeMetadata = false;\n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n-\n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n-\n         TokenResponse tokenResponse = null;\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Go to the sequencer, grab a token to write.\n-            tokenResponse = conflictInfo == null\n-                    ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n-                    : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n-\n-            // Is our token a valid type?\n-            AbortCause abortCause = null;\n-            switch (tokenResponse.getRespType()) {\n-                case TX_ABORT_CONFLICT:\n-                    abortCause = AbortCause.CONFLICT;\n-                    break;\n-                case TX_ABORT_NEWSEQ:\n-                    abortCause = AbortCause.NEW_SEQUENCER;\n-                    break;\n-                case TX_ABORT_SEQ_OVERFLOW:\n-                    abortCause = AbortCause.SEQUENCER_OVERFLOW;\n-                    break;\n-                case TX_ABORT_SEQ_TRIM:\n-                    abortCause = AbortCause.SEQUENCER_TRIM;\n-                    break;\n-            }\n \n-            if (abortCause != null) {\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(), abortCause,\n-                        TransactionalContext.getCurrentContext());\n-            }\n-\n-            try {\n-                if (TransactionalContext.isInTransaction()) {\n-                    // If this transaction has entries that wish to capture the committed address\n-                    // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n-                    // Note that we might invoke the same method multiple times on retries,\n-                    // which means the preCommitCallback must be idempotent.\n-                    TokenResponse finalTokenResponse = tokenResponse;\n-                    log.debug(\"append: Invoking {} preCommitListeners\",\n-                            TransactionalContext.getRootContext().getPreCommitListeners().size());\n-                    TransactionalContext.getRootContext()\n-                            .getPreCommitListeners()\n-                            .forEach(e -> e.preCommitCallback(finalTokenResponse));\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(serializeMetadata)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "originalPosition": 58}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDEwMTkx", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468010191", "createdAt": "2020-08-15T18:28:38Z", "commit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODoyODozOFrOHBM34w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODoyODozOFrOHBM34w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAyMTUzOQ==", "bodyText": "Alternatively, you can use a map\nMap<TokenType, AbortCause> dict = new HashMap<>();\n                dict.put(TX_ABORT_CONFLICT, AbortCause.CONFLICT);\n                dict.put(TX_ABORT_NEWSEQ, AbortCause.NEW_SEQUENCER);\n                dict.put(TX_ABORT_SEQ_OVERFLOW, AbortCause.SEQUENCER_OVERFLOW);\n                dict.put(TX_ABORT_SEQ_TRIM, AbortCause.TX_ABORT_SEQ_TRIM);\n\n                AbortCause abortCause = dict.get(tokenResponse.getRespType());\n...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471021539", "createdAt": "2020-08-15T18:28:38Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -131,91 +131,105 @@ public void gc(long trimMark) {\n     public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictInfo,\n                        @Nonnull CacheOption cacheOption, @Nonnull UUID... streamIDs) {\n \n+        final boolean serializeMetadata = false;\n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n-\n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n-\n         TokenResponse tokenResponse = null;\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Go to the sequencer, grab a token to write.\n-            tokenResponse = conflictInfo == null\n-                    ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n-                    : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n-\n-            // Is our token a valid type?\n-            AbortCause abortCause = null;\n-            switch (tokenResponse.getRespType()) {\n-                case TX_ABORT_CONFLICT:\n-                    abortCause = AbortCause.CONFLICT;\n-                    break;\n-                case TX_ABORT_NEWSEQ:\n-                    abortCause = AbortCause.NEW_SEQUENCER;\n-                    break;\n-                case TX_ABORT_SEQ_OVERFLOW:\n-                    abortCause = AbortCause.SEQUENCER_OVERFLOW;\n-                    break;\n-                case TX_ABORT_SEQ_TRIM:\n-                    abortCause = AbortCause.SEQUENCER_TRIM;\n-                    break;\n-            }\n \n-            if (abortCause != null) {\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(), abortCause,\n-                        TransactionalContext.getCurrentContext());\n-            }\n-\n-            try {\n-                if (TransactionalContext.isInTransaction()) {\n-                    // If this transaction has entries that wish to capture the committed address\n-                    // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n-                    // Note that we might invoke the same method multiple times on retries,\n-                    // which means the preCommitCallback must be idempotent.\n-                    TokenResponse finalTokenResponse = tokenResponse;\n-                    log.debug(\"append: Invoking {} preCommitListeners\",\n-                            TransactionalContext.getRootContext().getPreCommitListeners().size());\n-                    TransactionalContext.getRootContext()\n-                            .getPreCommitListeners()\n-                            .forEach(e -> e.preCommitCallback(finalTokenResponse));\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(serializeMetadata)) {\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n+\n+            for (int retry = 0; retry < runtime.getParameters().getWriteRetry(); retry++) {\n+                // Go to the sequencer, grab a token to write.\n+                tokenResponse = conflictInfo == null\n+                        ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n+                        : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n+\n+                // Is our token a valid type?\n+                AbortCause abortCause = null;\n+                switch (tokenResponse.getRespType()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "originalPosition": 69}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDEwMzkx", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468010391", "createdAt": "2020-08-15T18:32:06Z", "commit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODozMjowNlrOHBM4-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODozMjowNlrOHBM4-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAyMTgxOA==", "bodyText": "everything inside for cycle above this point should be extracted into a method, let's say checkAbort();\nfor (int retry = 0; retry < runtime.getParameters().getWriteRetry(); retry++) {\n                checkAbort();\n\n                try {\n                    if (TransactionalContext.isInTransaction()) {...", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471021818", "createdAt": "2020-08-15T18:32:06Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -131,91 +131,105 @@ public void gc(long trimMark) {\n     public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictInfo,\n                        @Nonnull CacheOption cacheOption, @Nonnull UUID... streamIDs) {\n \n+        final boolean serializeMetadata = false;\n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n-\n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n-\n         TokenResponse tokenResponse = null;\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Go to the sequencer, grab a token to write.\n-            tokenResponse = conflictInfo == null\n-                    ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n-                    : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n-\n-            // Is our token a valid type?\n-            AbortCause abortCause = null;\n-            switch (tokenResponse.getRespType()) {\n-                case TX_ABORT_CONFLICT:\n-                    abortCause = AbortCause.CONFLICT;\n-                    break;\n-                case TX_ABORT_NEWSEQ:\n-                    abortCause = AbortCause.NEW_SEQUENCER;\n-                    break;\n-                case TX_ABORT_SEQ_OVERFLOW:\n-                    abortCause = AbortCause.SEQUENCER_OVERFLOW;\n-                    break;\n-                case TX_ABORT_SEQ_TRIM:\n-                    abortCause = AbortCause.SEQUENCER_TRIM;\n-                    break;\n-            }\n \n-            if (abortCause != null) {\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(), abortCause,\n-                        TransactionalContext.getCurrentContext());\n-            }\n-\n-            try {\n-                if (TransactionalContext.isInTransaction()) {\n-                    // If this transaction has entries that wish to capture the committed address\n-                    // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n-                    // Note that we might invoke the same method multiple times on retries,\n-                    // which means the preCommitCallback must be idempotent.\n-                    TokenResponse finalTokenResponse = tokenResponse;\n-                    log.debug(\"append: Invoking {} preCommitListeners\",\n-                            TransactionalContext.getRootContext().getPreCommitListeners().size());\n-                    TransactionalContext.getRootContext()\n-                            .getPreCommitListeners()\n-                            .forEach(e -> e.preCommitCallback(finalTokenResponse));\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(serializeMetadata)) {\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n+\n+            for (int retry = 0; retry < runtime.getParameters().getWriteRetry(); retry++) {\n+                // Go to the sequencer, grab a token to write.\n+                tokenResponse = conflictInfo == null\n+                        ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n+                        : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n+\n+                // Is our token a valid type?\n+                AbortCause abortCause = null;\n+                switch (tokenResponse.getRespType()) {\n+                    case TX_ABORT_CONFLICT:\n+                        abortCause = AbortCause.CONFLICT;\n+                        break;\n+                    case TX_ABORT_NEWSEQ:\n+                        abortCause = AbortCause.NEW_SEQUENCER;\n+                        break;\n+                    case TX_ABORT_SEQ_OVERFLOW:\n+                        abortCause = AbortCause.SEQUENCER_OVERFLOW;\n+                        break;\n+                    case TX_ABORT_SEQ_TRIM:\n+                        abortCause = AbortCause.SEQUENCER_TRIM;\n+                        break;\n                 }\n \n-                // Attempt to write to the log.\n-                runtime.getAddressSpaceView().write(tokenResponse, ld, cacheOption);\n-                // If we're here, we succeeded, return the acquired token.\n-                return tokenResponse.getSequence();\n-            } catch (OverwriteException oe) {\n-                // We were overwritten, get a new token and try again.\n-                log.warn(\"append[{}]: Overwritten after {} retries, streams {}\",\n-                        tokenResponse.getSequence(), x,\n-                        Arrays.stream(streamIDs).map(Utils::toReadableId).collect(Collectors.toSet()));\n-\n-                if (conflictInfo != null) {\n-                    // On retry, check for conflicts only from the previous attempt position,\n-                    // otherwise the transaction will always conflict with itself.\n-                    conflictInfo.setSnapshotTimestamp(tokenResponse.getToken());\n+                if (abortCause != null) {\n+                    throw new TransactionAbortedException(\n+                            conflictInfo,\n+                            tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n+                            tokenResponse.getToken().getSequence(), abortCause,\n+                            TransactionalContext.getCurrentContext());\n                 }\n \n-            } catch (StaleTokenException se) {\n-                // the epoch changed from when we grabbed the token from sequencer\n-                log.warn(\"append[{}]: StaleToken, streams {}\", tokenResponse.getSequence(),\n-                        Arrays.stream(streamIDs).map(Utils::toReadableId).collect(Collectors.toSet()));\n-\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(),\n-                        AbortCause.NEW_SEQUENCER, // in the future perhaps define a new AbortCause?\n-                        TransactionalContext.getCurrentContext());\n+                try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDEwNTg4", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468010588", "createdAt": "2020-08-15T18:35:35Z", "commit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODozNTozNVrOHBM6JA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQxODozNTozNVrOHBM6JA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAyMjExNg==", "bodyText": "is it Address.NON_ADDRESS ?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471022116", "createdAt": "2020-08-15T18:35:35Z", "author": {"login": "xnull"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/stream/AbstractQueuedStreamView.java", "diffHunk": "@@ -177,65 +177,72 @@ public long append(Object object,\n                        Function<TokenResponse, Boolean> deacquisitionCallback) {\n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n \n-        // Validate if the  size of the log data is under max write size.\n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n-\n-        // First, we get a token from the sequencer.\n-        TokenResponse tokenResponse = runtime.getSequencerView()\n-                .next(id);\n-\n-        // We loop forever until we are interrupted, since we may have to\n-        // acquire an address several times until we are successful.\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Next, we call the acquisitionCallback, if present, informing\n-            // the client of the token that we acquired.\n-            if (acquisitionCallback != null) {\n-                if (!acquisitionCallback.apply(tokenResponse)) {\n-                    // The client did not like our token, so we end here.\n-                    // We'll leave the hole to be filled by the client or\n-                    // someone else.\n-                    log.debug(\"Acquisition rejected token={}\", tokenResponse);\n-                    return -1L;\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(false)) {\n+            // Validate if the  size of the log data is under max write size.\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n+\n+            // First, we get a token from the sequencer.\n+            TokenResponse tokenResponse = runtime.getSequencerView().next(id);\n+\n+            // We loop forever until we are interrupted, since we may have to\n+            // acquire an address several times until we are successful.\n+            for (int retry = 0; retry < runtime.getParameters().getWriteRetry(); retry++) {\n+                // Next, we call the acquisitionCallback, if present, informing\n+                // the client of the token that we acquired.\n+                if (acquisitionCallback != null) {\n+                    if (!acquisitionCallback.apply(tokenResponse)) {\n+                        // The client did not like our token, so we end here.\n+                        // We'll leave the hole to be filled by the client or\n+                        // someone else.\n+                        log.warn(\"Acquisition rejected token={}\", tokenResponse);\n+                        return -1L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDEwNjIw", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468010620", "createdAt": "2020-08-15T18:36:03Z", "commit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d5332163e88b32a943770e747de84d8d2402869c", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/d5332163e88b32a943770e747de84d8d2402869c", "committedDate": "2020-08-15T04:47:21Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}, "afterCommit": {"oid": "acd49fc6faa8cfd4d458b623dca3e105611e6cc0", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/acd49fc6faa8cfd4d458b623dca3e105611e6cc0", "committedDate": "2020-08-15T22:13:00Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDIxNzg3", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468021787", "createdAt": "2020-08-15T22:53:07Z", "commit": {"oid": "acd49fc6faa8cfd4d458b623dca3e105611e6cc0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQyMjo1MzowN1rOHBOFxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQyMjo1MzowN1rOHBOFxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0MTQ3OA==", "bodyText": "Why do you need to reset the reader index? shouldn't you assert that its actually zero?\nWhen would you read the payload, then reseralize the metadata portion and then reread ?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471041478", "createdAt": "2020-08-15T22:53:07Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -119,20 +124,42 @@ public Object getPayload(CorfuRuntime runtime) {\n     @Override\n     public synchronized void releaseBuffer() {\n         if (serializedCache != null) {\n-            serializedCache.release();\n-            if (serializedCache.refCnt() == 0) {\n+            serializedCache.buffer.release();\n+            if (serializedCache.buffer.refCnt() == 0) {\n                 serializedCache = null;\n             }\n         }\n     }\n \n     @Override\n-    public synchronized void acquireBuffer() {\n+    public synchronized void acquireBuffer(boolean metadata) {\n         if (serializedCache == null) {\n-            serializedCache = Unpooled.buffer();\n-            doSerializeInternal(serializedCache);\n+            acquireBufferInternal(metadata);\n         } else {\n-            serializedCache.retain();\n+            if (metadata) {\n+                serializedCache.buffer.resetReaderIndex();\n+                serializedCache.buffer.writerIndex(serializedCache.metadataOffset);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acd49fc6faa8cfd4d458b623dca3e105611e6cc0"}, "originalPosition": 87}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "acd49fc6faa8cfd4d458b623dca3e105611e6cc0", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/acd49fc6faa8cfd4d458b623dca3e105611e6cc0", "committedDate": "2020-08-15T22:13:00Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}, "afterCommit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/f3672f7d0a31b805149c327f4e2a40a81484f380", "committedDate": "2020-08-15T23:16:27Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDIyNTI2", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468022526", "createdAt": "2020-08-15T23:17:02Z", "commit": {"oid": "acd49fc6faa8cfd4d458b623dca3e105611e6cc0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQyMzoxNzo0M1rOHBOMNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQyMzoxNzo0M1rOHBOMNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0MzEyNA==", "bodyText": "This doesn't seem right. When an object is serialized (not byte array), then this always return 1. Having serializedCache != null doesn't imply that LogData::data is populated with the serialized data.\nShouldn't this logic check the size against serializedCache.writerIndex() ?", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471043124", "createdAt": "2020-08-15T23:17:43Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -340,12 +369,17 @@ public String toString() {\n      * Verify that max payload is enforced for the specified limit.\n      *\n      * @param limit Max write limit.\n+     * @return the serialized size of the payload\n      */\n-    public void checkMaxWriteSize(int limit) {\n-        try (ILogData.SerializationHandle sh = this.getSerializedForm()) {\n-            if (limit != 0 && getSizeEstimate() > limit) {\n-                throw new WriteSizeException(getSizeEstimate(), limit);\n-            }\n+    public int checkMaxWriteSize(int limit) {\n+        Preconditions.checkState(serializedCache != null, \"checkMaxWriteSize requires serialized form\");\n+\n+        int payloadSize = getSizeEstimate();\n+\n+        if (payloadSize > limit) {\n+            throw new WriteSizeException(payloadSize, limit);\n         }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380"}, "originalPosition": 230}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDIzMDMy", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468023032", "createdAt": "2020-08-15T23:31:07Z", "commit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQyMzozMTowN1rOHBOP0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNVQyMzozMTowN1rOHBOP0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0NDA0OA==", "bodyText": "This doesn't cover the case of writes are issued directly to the AddressSpaceView::write method (i.e. the checkpointer writer).", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471044048", "createdAt": "2020-08-15T23:31:07Z", "author": {"login": "Maithem"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -131,91 +131,75 @@ public void gc(long trimMark) {\n     public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictInfo,\n                        @Nonnull CacheOption cacheOption, @Nonnull UUID... streamIDs) {\n \n+        final boolean serializeMetadata = false;\n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n+        TokenResponse tokenResponse = null;\n \n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(serializeMetadata)) {\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDIzMTA1", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468023105", "createdAt": "2020-08-15T23:33:16Z", "commit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDI1MDM2", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468025036", "createdAt": "2020-08-16T00:30:37Z", "commit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNlQwMDozMDozOFrOHBOfWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNlQwMToyMTo0OFrOHBOsiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0ODAyNw==", "bodyText": "Should we have a trace level logging printing the estimate size of our payloads? which could be used for tracking purposes.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471048027", "createdAt": "2020-08-16T00:30:38Z", "author": {"login": "annym"}, "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java", "diffHunk": "@@ -340,12 +369,17 @@ public String toString() {\n      * Verify that max payload is enforced for the specified limit.\n      *\n      * @param limit Max write limit.\n+     * @return the serialized size of the payload\n      */\n-    public void checkMaxWriteSize(int limit) {\n-        try (ILogData.SerializationHandle sh = this.getSerializedForm()) {\n-            if (limit != 0 && getSizeEstimate() > limit) {\n-                throw new WriteSizeException(getSizeEstimate(), limit);\n-            }\n+    public int checkMaxWriteSize(int limit) {\n+        Preconditions.checkState(serializedCache != null, \"checkMaxWriteSize requires serialized form\");\n+\n+        int payloadSize = getSizeEstimate();\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0OTM0Nw==", "bodyText": "By definition a pre-commit listener does not impose that the payload needs to change, right? so maybe in the future we could make the pre-commit listener return whether it modified or not the data, to decide if we need to update the serialized buffer or we can just skip..", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471049347", "createdAt": "2020-08-16T00:50:06Z", "author": {"login": "annym"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -229,6 +213,47 @@ public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictIn\n         return append(object, conflictInfo, CacheOption.WRITE_THROUGH, streamIDs);\n     }\n \n+    private AbortCause getAbortCauseFromToken(TokenResponse tokenResponse) {\n+        AbortCause abortCause = null;\n+\n+        switch (tokenResponse.getRespType()) {\n+            case TX_ABORT_CONFLICT:\n+                abortCause = AbortCause.CONFLICT;\n+                break;\n+            case TX_ABORT_NEWSEQ:\n+                abortCause = AbortCause.NEW_SEQUENCER;\n+                break;\n+            case TX_ABORT_SEQ_OVERFLOW:\n+                abortCause = AbortCause.SEQUENCER_OVERFLOW;\n+                break;\n+            case TX_ABORT_SEQ_TRIM:\n+                abortCause = AbortCause.SEQUENCER_TRIM;\n+                break;\n+        }\n+\n+        return abortCause;\n+    }\n+\n+    private void runPreCommitListeners(TokenResponse tokenResponse,\n+                                       LogData ld, boolean serializeMetadata) {\n+        if (TransactionalContext.isInTransaction()) {\n+            // If this transaction has entries that wish to capture the committed address\n+            // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n+            // Note that we might invoke the same method multiple times on retries,\n+            // which means the preCommitCallback must be idempotent.\n+            log.debug(\"append: Invoking {} preCommitListeners\",\n+                    TransactionalContext.getRootContext().getPreCommitListeners().size());\n+            List<TransactionalContext.PreCommitListener> listeners =\n+                    TransactionalContext.getRootContext().getPreCommitListeners();\n+            // If there are pre-commit listeners, the payload will be changed,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380"}, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA1MTQwMQ==", "bodyText": "question, in AddressSpaceView.Write we call useToken which internally sets the global address to the payload, but since, we've already serialized the payload and we'll just serialize the metadata, won't this be lost in the serialized form?\n\n  \n    \n      CorfuDB/runtime/src/main/java/org/corfudb/protocols/wireprotocol/LogData.java\n    \n    \n        Lines 243 to 245\n      in\n      4530118\n    \n    \n    \n    \n\n        \n          \n           if (payload.get() instanceof LogEntry) { \n        \n\n        \n          \n               ((LogEntry) payload.get()).setGlobalAddress(token.getSequence()); \n        \n\n        \n          \n           }", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471051401", "createdAt": "2020-08-16T01:21:48Z", "author": {"login": "annym"}, "path": "runtime/src/main/java/org/corfudb/runtime/view/StreamsView.java", "diffHunk": "@@ -131,91 +131,75 @@ public void gc(long trimMark) {\n     public long append(@Nonnull Object object, @Nullable TxResolutionInfo conflictInfo,\n                        @Nonnull CacheOption cacheOption, @Nonnull UUID... streamIDs) {\n \n+        final boolean serializeMetadata = false;\n         final LogData ld = new LogData(DataType.DATA, object, runtime.getParameters().getCodecType());\n+        TokenResponse tokenResponse = null;\n \n-        ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n+        // Opening serialization handle before acquiring token, this way we prevent the\n+        // readers to wait for the possibly long serialization time in writer.\n+        // The serialization here only serializes the payload because the token is not\n+        // acquired yet, thus metadata is incomplete. Once a token is acquired, the\n+        // writer will append the serialized metadata to the buffer.\n+        try (ILogData.SerializationHandle sh = ld.getSerializedForm(serializeMetadata)) {\n+            int payloadSize = ld.checkMaxWriteSize(runtime.getParameters().getMaxWriteSize());\n \n-        TokenResponse tokenResponse = null;\n-        for (int x = 0; x < runtime.getParameters().getWriteRetry(); x++) {\n-            // Go to the sequencer, grab a token to write.\n-            tokenResponse = conflictInfo == null\n-                    ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n-                    : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n-\n-            // Is our token a valid type?\n-            AbortCause abortCause = null;\n-            switch (tokenResponse.getRespType()) {\n-                case TX_ABORT_CONFLICT:\n-                    abortCause = AbortCause.CONFLICT;\n-                    break;\n-                case TX_ABORT_NEWSEQ:\n-                    abortCause = AbortCause.NEW_SEQUENCER;\n-                    break;\n-                case TX_ABORT_SEQ_OVERFLOW:\n-                    abortCause = AbortCause.SEQUENCER_OVERFLOW;\n-                    break;\n-                case TX_ABORT_SEQ_TRIM:\n-                    abortCause = AbortCause.SEQUENCER_TRIM;\n-                    break;\n-            }\n+            for (int retry = 0; retry < runtime.getParameters().getWriteRetry(); retry++) {\n+                // Go to the sequencer, grab a token to write.\n+                tokenResponse = conflictInfo == null\n+                        ? runtime.getSequencerView().next(streamIDs) // Token w/o conflict info\n+                        : runtime.getSequencerView().next(conflictInfo, streamIDs); // Token w/ conflict info\n \n-            if (abortCause != null) {\n-                throw new TransactionAbortedException(\n-                        conflictInfo,\n-                        tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n-                        tokenResponse.getToken().getSequence(), abortCause,\n-                        TransactionalContext.getCurrentContext());\n-            }\n+                // Is our token a valid type?\n+                AbortCause abortCause = getAbortCauseFromToken(tokenResponse);\n \n-            try {\n-                if (TransactionalContext.isInTransaction()) {\n-                    // If this transaction has entries that wish to capture the committed address\n-                    // invoke its preCommitCallbacks with the tokenResponse from the sequencer.\n-                    // Note that we might invoke the same method multiple times on retries,\n-                    // which means the preCommitCallback must be idempotent.\n-                    TokenResponse finalTokenResponse = tokenResponse;\n-                    log.debug(\"append: Invoking {} preCommitListeners\",\n-                            TransactionalContext.getRootContext().getPreCommitListeners().size());\n-                    TransactionalContext.getRootContext()\n-                            .getPreCommitListeners()\n-                            .forEach(e -> e.preCommitCallback(finalTokenResponse));\n+                if (abortCause != null) {\n+                    throw new TransactionAbortedException(\n+                            conflictInfo,\n+                            tokenResponse.getConflictKey(), tokenResponse.getConflictStream(),\n+                            tokenResponse.getToken().getSequence(), abortCause,\n+                            TransactionalContext.getCurrentContext());\n                 }\n \n-                // Attempt to write to the log.\n-                runtime.getAddressSpaceView().write(tokenResponse, ld, cacheOption);\n-                // If we're here, we succeeded, return the acquired token.\n-                return tokenResponse.getSequence();\n-            } catch (OverwriteException oe) {\n-                // We were overwritten, get a new token and try again.\n-                log.warn(\"append[{}]: Overwritten after {} retries, streams {}\",\n-                        tokenResponse.getSequence(), x,\n-                        Arrays.stream(streamIDs).map(Utils::toReadableId).collect(Collectors.toSet()));\n-\n-                if (conflictInfo != null) {\n-                    // On retry, check for conflicts only from the previous attempt position,\n-                    // otherwise the transaction will always conflict with itself.\n-                    conflictInfo.setSnapshotTimestamp(tokenResponse.getToken());\n-                }\n+                try {\n+                    // Run pre-commit listeners if we are in transaction.\n+                    runPreCommitListeners(tokenResponse, ld, serializeMetadata);\n+                    // Attempt to write to the log.\n+                    runtime.getAddressSpaceView().write(tokenResponse, ld, cacheOption);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380"}, "originalPosition": 95}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f3672f7d0a31b805149c327f4e2a40a81484f380", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/f3672f7d0a31b805149c327f4e2a40a81484f380", "committedDate": "2020-08-15T23:16:27Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}, "afterCommit": {"oid": "881aee8a6f354a22a6567ceb70c49b59a196dce2", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/881aee8a6f354a22a6567ceb70c49b59a196dce2", "committedDate": "2020-08-16T04:18:12Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9690ae566e0fb121f8d29cceb18e5197b8929d1", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/f9690ae566e0fb121f8d29cceb18e5197b8929d1", "committedDate": "2020-08-17T05:59:11Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "881aee8a6f354a22a6567ceb70c49b59a196dce2", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/881aee8a6f354a22a6567ceb70c49b59a196dce2", "committedDate": "2020-08-16T04:18:12Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}, "afterCommit": {"oid": "f9690ae566e0fb121f8d29cceb18e5197b8929d1", "author": {"user": {"login": "WenbinZhu", "name": "Wenbin Zhu"}}, "url": "https://github.com/CorfuDB/CorfuDB/commit/f9690ae566e0fb121f8d29cceb18e5197b8929d1", "committedDate": "2020-08-17T05:59:11Z", "message": "Stream write path performance optimization.\n\n- Reuse serialization handle, which reduces number of serializations.\n- Acquire token after payload serialized, which reduces reader wait time."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MTgzNjA5", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468183609", "createdAt": "2020-08-17T06:04:27Z", "commit": {"oid": "f9690ae566e0fb121f8d29cceb18e5197b8929d1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QwNjowNDoyN1rOHBavfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QwNjowNDoyN1rOHBavfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI0ODc2NQ==", "bodyText": "Codacy found an issue: Use explicit scoping instead of the default package private level", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471248765", "createdAt": "2020-08-17T06:04:27Z", "author": {"login": "corfudb-bot"}, "path": "runtime/src/main/java/org/corfudb/runtime/CorfuRuntime.java", "diffHunk": "@@ -85,13 +83,11 @@ public static CorfuRuntimeParametersBuilder builder() {\n         /*\n          * Max size for a write request.\n          */\n-\n-        int maxWriteSize = 0;\n+        int maxWriteSize = Integer.MAX_VALUE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9690ae566e0fb121f8d29cceb18e5197b8929d1"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MTgzNjIw", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#pullrequestreview-468183620", "createdAt": "2020-08-17T06:04:27Z", "commit": {"oid": "f9690ae566e0fb121f8d29cceb18e5197b8929d1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QwNjowNDoyN1rOHBavhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QwNjowNDoyN1rOHBavhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI0ODc3Mg==", "bodyText": "Codacy found an issue: Fields should be declared at the top of the class, before any method declarations, constructors, initializers or inner classes.", "url": "https://github.com/CorfuDB/CorfuDB/pull/2703#discussion_r471248772", "createdAt": "2020-08-17T06:04:27Z", "author": {"login": "corfudb-bot"}, "path": "runtime/src/main/java/org/corfudb/runtime/CorfuRuntime.java", "diffHunk": "@@ -85,13 +83,11 @@ public static CorfuRuntimeParametersBuilder builder() {\n         /*\n          * Max size for a write request.\n          */\n-\n-        int maxWriteSize = 0;\n+        int maxWriteSize = Integer.MAX_VALUE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9690ae566e0fb121f8d29cceb18e5197b8929d1"}, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4401, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}