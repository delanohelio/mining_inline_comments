{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA3NTI2MzA3", "number": 6966, "title": "rls: caching rls client", "bodyText": "the ASYNC_LOOKUP_DEFAULT_TARGET_ON_MISS will be removed via grpc/grpc-proto#77. that is reflected here.", "createdAt": "2020-04-22T20:22:26Z", "url": "https://github.com/grpc/grpc-java/pull/6966", "merged": true, "mergeCommit": {"oid": "50a829ad9de14b8a3d4b5671798947edceb6448d"}, "closed": true, "closedAt": "2020-05-01T19:02:06Z", "author": {"login": "creamsoup"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcaOTWPgH2gAyNDA3NTI2MzA3OjY5YTBjZTQ1ZDViOTQwMzE0NDQ5NjA0ODhlOTQ1YjFhZjRjYTdmMDE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcdGPZYAH2gAyNDA3NTI2MzA3OjJjZDBkMWZmNzgxZGZkOGZiYWFmMzc2ZTA2ZjdhOTE4YmQ1YWQ2ODg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "69a0ce45d5b94031444960488e945b1af4ca7f01", "author": {"user": {"login": "creamsoup", "name": "Jihun Cho"}}, "url": "https://github.com/grpc/grpc-java/commit/69a0ce45d5b94031444960488e945b1af4ca7f01", "committedDate": "2020-04-22T20:27:55Z", "message": "rls: caching rls client"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyODY1MDgz", "url": "https://github.com/grpc/grpc-java/pull/6966#pullrequestreview-402865083", "createdAt": "2020-04-29T17:03:25Z", "commit": {"oid": "69a0ce45d5b94031444960488e945b1af4ca7f01"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxNzowMzoyNVrOGOIcpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMToxNjowNFrOGORTiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQ3MTY1NQ==", "bodyText": "private constructor", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r417471655", "createdAt": "2020-04-29T17:03:25Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,979 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      checkState(\n+          childPolicyWrapper.getHelper() != null,\n+          \"incomplete childPolicyWrapper found, this is a bug\");\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled |\n+     * entry2:                        | OV | pending | hasValue | staled |\n+     * </pre>\n+     */\n+    void maybeRefresh() {\n+      synchronized (lock) {\n+        if (pendingCallCache.containsKey(request)) {\n+          // pending already requested\n+          return;\n+        }\n+        final ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+        if (!asyncCall.isDone()) {\n+          pendingCallCache.put(request, new PendingCacheEntry(request, asyncCall));\n+        } else {\n+          // async call returned finished future is most likely throttled\n+          try {\n+            RouteLookupResponse response = asyncCall.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (Exception e) {\n+            BackoffCacheEntry backoffEntry =\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+            linkedHashLruCache.cache(request, backoffEntry);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      return childPolicyWrapper;\n+    }\n+\n+    String getHeaderData() {\n+      return response.getHeaderData();\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      // size of strings and java object overhead, actual memory usage is more than this.\n+      return (response.getTarget().length() + response.getHeaderData().length()) * 2 + 38 * 2;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireTime <= now;\n+    }\n+\n+    boolean isStaled(long now) {\n+      return staleTime <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      refCountedChildPolicyWrapperFactory.release(childPolicyWrapper);\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"response\", response)\n+          .add(\"expireTime\", expireTime)\n+          .add(\"staleTime\", staleTime)\n+          .add(\"childPolicyWrapper\", childPolicyWrapper)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * Implementation of {@link CacheEntry} contains error. This entry will transition to pending\n+   * status when the backoff time is expired.\n+   */\n+  private final class BackoffCacheEntry extends CacheEntry {\n+\n+    private final Status status;\n+    private final ScheduledFuture<?> scheduledFuture;\n+    private final BackoffPolicy backoffPolicy;\n+    private final long expireMills;\n+    private boolean shutdown = false;\n+\n+    BackoffCacheEntry(RouteLookupRequest request, Status status, BackoffPolicy backoffPolicy) {\n+      super(request);\n+      this.status = checkNotNull(status, \"status\");\n+      this.backoffPolicy = checkNotNull(backoffPolicy, \"backoffPolicy\");\n+      long delayNanos = backoffPolicy.nextBackoffNanos();\n+      this.expireMills = timeProvider.currentTimeNanos() + delayNanos;\n+      this.scheduledFuture =\n+          scheduledExecutorService.schedule(\n+              new Runnable() {\n+                @Override\n+                public void run() {\n+                  transitionToPending();\n+                }\n+              },\n+              delayNanos,\n+              TimeUnit.NANOSECONDS);\n+    }\n+\n+    /** Forcefully refreshes cache entry by ignoring the backoff timer. */\n+    void forceRefresh() {\n+      boolean cancelled = scheduledFuture.cancel(false);\n+      if (cancelled) {\n+        transitionToPending();\n+      }\n+    }\n+\n+    private void transitionToPending() {\n+      synchronized (lock) {\n+        if (shutdown) {\n+          return;\n+        }\n+        ListenableFuture<RouteLookupResponse> call = asyncRlsCall(request);\n+        if (!call.isDone()) {\n+          PendingCacheEntry pendingEntry = new PendingCacheEntry(request, call, backoffPolicy);\n+          pendingCallCache.put(request, pendingEntry);\n+          linkedHashLruCache.invalidate(request);\n+        } else {\n+          try {\n+            RouteLookupResponse response = call.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (Exception e) {\n+            linkedHashLruCache.cache(\n+                request,\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffPolicy));\n+          }\n+        }\n+      }\n+    }\n+\n+    Status getStatus() {\n+      return status;\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      return 0;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireMills <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      synchronized (lock) {\n+        if (shutdown) {\n+          return;\n+        }\n+        shutdown = true;\n+        if (!scheduledFuture.isCancelled()) {\n+          scheduledFuture.cancel(true);\n+        }\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"status\", status)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .add(\"scheduledFuture\", scheduledFuture)\n+          .toString();\n+    }\n+  }\n+\n+  /** Returns a Builder for {@link CachingRlsLbClient}. */\n+  public static Builder newBuilder() {\n+    return new Builder();\n+  }\n+\n+  /** A Builder for {@link CachingRlsLbClient}. */\n+  public static final class Builder {\n+\n+    private Helper helper;\n+    private LbPolicyConfiguration lbPolicyConfig;\n+    private Throttler throttler = new HappyThrottler();\n+    private ResolvedAddressFactory resolvedAddressFactory;\n+    private TimeProvider timeProvider = TimeProvider.SYSTEM_TIME_PROVIDER;\n+    private EvictionListener<RouteLookupRequest, CacheEntry> evictionListener;\n+    private BackoffPolicy.Provider backoffProvider = new ExponentialBackoffPolicy.Provider();\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69a0ce45d5b94031444960488e945b1af4ca7f01"}, "originalPosition": 679}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQ3NDMzNw==", "bodyText": "final?", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r417474337", "createdAt": "2020-04-29T17:07:34Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,979 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    boolean isExpired() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69a0ce45d5b94031444960488e945b1af4ca7f01"}, "originalPosition": 430}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQ4MDYwMw==", "bodyText": "expireNanos", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r417480603", "createdAt": "2020-04-29T17:17:35Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,979 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      checkState(\n+          childPolicyWrapper.getHelper() != null,\n+          \"incomplete childPolicyWrapper found, this is a bug\");\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled |\n+     * entry2:                        | OV | pending | hasValue | staled |\n+     * </pre>\n+     */\n+    void maybeRefresh() {\n+      synchronized (lock) {\n+        if (pendingCallCache.containsKey(request)) {\n+          // pending already requested\n+          return;\n+        }\n+        final ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+        if (!asyncCall.isDone()) {\n+          pendingCallCache.put(request, new PendingCacheEntry(request, asyncCall));\n+        } else {\n+          // async call returned finished future is most likely throttled\n+          try {\n+            RouteLookupResponse response = asyncCall.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (Exception e) {\n+            BackoffCacheEntry backoffEntry =\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+            linkedHashLruCache.cache(request, backoffEntry);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      return childPolicyWrapper;\n+    }\n+\n+    String getHeaderData() {\n+      return response.getHeaderData();\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      // size of strings and java object overhead, actual memory usage is more than this.\n+      return (response.getTarget().length() + response.getHeaderData().length()) * 2 + 38 * 2;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireTime <= now;\n+    }\n+\n+    boolean isStaled(long now) {\n+      return staleTime <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      refCountedChildPolicyWrapperFactory.release(childPolicyWrapper);\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"response\", response)\n+          .add(\"expireTime\", expireTime)\n+          .add(\"staleTime\", staleTime)\n+          .add(\"childPolicyWrapper\", childPolicyWrapper)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * Implementation of {@link CacheEntry} contains error. This entry will transition to pending\n+   * status when the backoff time is expired.\n+   */\n+  private final class BackoffCacheEntry extends CacheEntry {\n+\n+    private final Status status;\n+    private final ScheduledFuture<?> scheduledFuture;\n+    private final BackoffPolicy backoffPolicy;\n+    private final long expireMills;\n+    private boolean shutdown = false;\n+\n+    BackoffCacheEntry(RouteLookupRequest request, Status status, BackoffPolicy backoffPolicy) {\n+      super(request);\n+      this.status = checkNotNull(status, \"status\");\n+      this.backoffPolicy = checkNotNull(backoffPolicy, \"backoffPolicy\");\n+      long delayNanos = backoffPolicy.nextBackoffNanos();\n+      this.expireMills = timeProvider.currentTimeNanos() + delayNanos;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69a0ce45d5b94031444960488e945b1af4ca7f01"}, "originalPosition": 582}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzYxNjc3OQ==", "bodyText": "LinkedHashLruCache is guarded by CachingRlsLbClient.lock.\nLinkedHashLruCache.evictionListener.onEviction() is guarded by LinkedHashLruCache.lock.\nThere could be deadlock:\nLinkedHashLruCache.cache() -> evictionListener.onEviction() -> value.cleanup()", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r417616779", "createdAt": "2020-04-29T21:16:04Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,979 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      checkState(\n+          childPolicyWrapper.getHelper() != null,\n+          \"incomplete childPolicyWrapper found, this is a bug\");\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled |\n+     * entry2:                        | OV | pending | hasValue | staled |\n+     * </pre>\n+     */\n+    void maybeRefresh() {\n+      synchronized (lock) {\n+        if (pendingCallCache.containsKey(request)) {\n+          // pending already requested\n+          return;\n+        }\n+        final ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+        if (!asyncCall.isDone()) {\n+          pendingCallCache.put(request, new PendingCacheEntry(request, asyncCall));\n+        } else {\n+          // async call returned finished future is most likely throttled\n+          try {\n+            RouteLookupResponse response = asyncCall.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (Exception e) {\n+            BackoffCacheEntry backoffEntry =\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+            linkedHashLruCache.cache(request, backoffEntry);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      return childPolicyWrapper;\n+    }\n+\n+    String getHeaderData() {\n+      return response.getHeaderData();\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      // size of strings and java object overhead, actual memory usage is more than this.\n+      return (response.getTarget().length() + response.getHeaderData().length()) * 2 + 38 * 2;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireTime <= now;\n+    }\n+\n+    boolean isStaled(long now) {\n+      return staleTime <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      refCountedChildPolicyWrapperFactory.release(childPolicyWrapper);\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"response\", response)\n+          .add(\"expireTime\", expireTime)\n+          .add(\"staleTime\", staleTime)\n+          .add(\"childPolicyWrapper\", childPolicyWrapper)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * Implementation of {@link CacheEntry} contains error. This entry will transition to pending\n+   * status when the backoff time is expired.\n+   */\n+  private final class BackoffCacheEntry extends CacheEntry {\n+\n+    private final Status status;\n+    private final ScheduledFuture<?> scheduledFuture;\n+    private final BackoffPolicy backoffPolicy;\n+    private final long expireMills;\n+    private boolean shutdown = false;\n+\n+    BackoffCacheEntry(RouteLookupRequest request, Status status, BackoffPolicy backoffPolicy) {\n+      super(request);\n+      this.status = checkNotNull(status, \"status\");\n+      this.backoffPolicy = checkNotNull(backoffPolicy, \"backoffPolicy\");\n+      long delayNanos = backoffPolicy.nextBackoffNanos();\n+      this.expireMills = timeProvider.currentTimeNanos() + delayNanos;\n+      this.scheduledFuture =\n+          scheduledExecutorService.schedule(\n+              new Runnable() {\n+                @Override\n+                public void run() {\n+                  transitionToPending();\n+                }\n+              },\n+              delayNanos,\n+              TimeUnit.NANOSECONDS);\n+    }\n+\n+    /** Forcefully refreshes cache entry by ignoring the backoff timer. */\n+    void forceRefresh() {\n+      boolean cancelled = scheduledFuture.cancel(false);\n+      if (cancelled) {\n+        transitionToPending();\n+      }\n+    }\n+\n+    private void transitionToPending() {\n+      synchronized (lock) {\n+        if (shutdown) {\n+          return;\n+        }\n+        ListenableFuture<RouteLookupResponse> call = asyncRlsCall(request);\n+        if (!call.isDone()) {\n+          PendingCacheEntry pendingEntry = new PendingCacheEntry(request, call, backoffPolicy);\n+          pendingCallCache.put(request, pendingEntry);\n+          linkedHashLruCache.invalidate(request);\n+        } else {\n+          try {\n+            RouteLookupResponse response = call.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (Exception e) {\n+            linkedHashLruCache.cache(\n+                request,\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffPolicy));\n+          }\n+        }\n+      }\n+    }\n+\n+    Status getStatus() {\n+      return status;\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      return 0;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireMills <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      synchronized (lock) {\n+        if (shutdown) {\n+          return;\n+        }\n+        shutdown = true;\n+        if (!scheduledFuture.isCancelled()) {\n+          scheduledFuture.cancel(true);\n+        }\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"status\", status)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .add(\"scheduledFuture\", scheduledFuture)\n+          .toString();\n+    }\n+  }\n+\n+  /** Returns a Builder for {@link CachingRlsLbClient}. */\n+  public static Builder newBuilder() {\n+    return new Builder();\n+  }\n+\n+  /** A Builder for {@link CachingRlsLbClient}. */\n+  public static final class Builder {\n+\n+    private Helper helper;\n+    private LbPolicyConfiguration lbPolicyConfig;\n+    private Throttler throttler = new HappyThrottler();\n+    private ResolvedAddressFactory resolvedAddressFactory;\n+    private TimeProvider timeProvider = TimeProvider.SYSTEM_TIME_PROVIDER;\n+    private EvictionListener<RouteLookupRequest, CacheEntry> evictionListener;\n+    private BackoffPolicy.Provider backoffProvider = new ExponentialBackoffPolicy.Provider();\n+\n+    public Builder setHelper(Helper helper) {\n+      this.helper = checkNotNull(helper, \"helper\");\n+      return this;\n+    }\n+\n+    public Builder setLbPolicyConfig(LbPolicyConfiguration lbPolicyConfig) {\n+      this.lbPolicyConfig = checkNotNull(lbPolicyConfig, \"lbPolicyConfig\");\n+      return this;\n+    }\n+\n+    public Builder setThrottler(Throttler throttler) {\n+      this.throttler = checkNotNull(throttler, \"throttler\");\n+      return this;\n+    }\n+\n+    /**\n+     * Sets a factory to create {@link ResolvedAddresses} for child load balancer.\n+     */\n+    public Builder setResolvedAddressesFactory(\n+        ResolvedAddressFactory resolvedAddressFactory) {\n+      this.resolvedAddressFactory =\n+          checkNotNull(resolvedAddressFactory, \"resolvedAddressFactory\");\n+      return this;\n+    }\n+\n+    public Builder setTimeProvider(TimeProvider timeProvider) {\n+      this.timeProvider = checkNotNull(timeProvider, \"timeProvider\");\n+      return this;\n+    }\n+\n+    public Builder setEvictionListener(\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> evictionListener) {\n+      this.evictionListener = evictionListener;\n+      return this;\n+    }\n+\n+    public Builder setBackoffProvider(BackoffPolicy.Provider provider) {\n+      this.backoffProvider = checkNotNull(provider, \"provider\");\n+      return this;\n+    }\n+\n+    public CachingRlsLbClient build() {\n+      return new CachingRlsLbClient(this);\n+    }\n+  }\n+\n+  /**\n+   * When any {@link CacheEntry} is evicted from {@link LruCache}, it performs {@link\n+   * CacheEntry#cleanup()} after original {@link EvictionListener} is finished.\n+   */\n+  private static final class AutoCleaningEvictionListener\n+      implements EvictionListener<RouteLookupRequest, CacheEntry> {\n+\n+    private final EvictionListener<RouteLookupRequest, CacheEntry> delegate;\n+\n+    AutoCleaningEvictionListener(\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> delegate) {\n+      this.delegate = delegate;\n+    }\n+\n+    @Override\n+    public void onEviction(RouteLookupRequest key, CacheEntry value, EvictionType cause) {\n+      if (delegate != null) {\n+        delegate.onEviction(key, value, cause);\n+      }\n+      // performs cleanup after delegation\n+      value.cleanup();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69a0ce45d5b94031444960488e945b1af4ca7f01"}, "originalPosition": 746}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b", "author": {"user": {"login": "creamsoup", "name": "Jihun Cho"}}, "url": "https://github.com/grpc/grpc-java/commit/2e371419e8f94e651211af23839a4228058aee5b", "committedDate": "2020-04-29T22:14:21Z", "message": "remove lock from cleanup, add method modifiers"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzMDgyODA4", "url": "https://github.com/grpc/grpc-java/pull/6966#pullrequestreview-403082808", "createdAt": "2020-04-29T22:24:12Z", "commit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQyMjoyNDoxM1rOGOTOCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQxOToyMjowOVrOGO3G3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY0ODEzNg==", "bodyText": "I would call helper. updateBalancingState() outside this class, in parallel with calling  helper.createResolvingOobChannel()", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r417648136", "createdAt": "2020-04-29T22:24:13Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      checkState(\n+          childPolicyWrapper.getHelper() != null,\n+          \"incomplete childPolicyWrapper found, this is a bug\");\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled |\n+     * entry2:                        | OV | pending | hasValue | staled |\n+     * </pre>\n+     */\n+    void maybeRefresh() {\n+      synchronized (lock) {\n+        if (pendingCallCache.containsKey(request)) {\n+          // pending already requested\n+          return;\n+        }\n+        final ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+        if (!asyncCall.isDone()) {\n+          pendingCallCache.put(request, new PendingCacheEntry(request, asyncCall));\n+        } else {\n+          // async call returned finished future is most likely throttled\n+          try {\n+            RouteLookupResponse response = asyncCall.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (Exception e) {\n+            BackoffCacheEntry backoffEntry =\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+            linkedHashLruCache.cache(request, backoffEntry);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      return childPolicyWrapper;\n+    }\n+\n+    String getHeaderData() {\n+      return response.getHeaderData();\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      // size of strings and java object overhead, actual memory usage is more than this.\n+      return (response.getTarget().length() + response.getHeaderData().length()) * 2 + 38 * 2;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireTime <= now;\n+    }\n+\n+    boolean isStaled(long now) {\n+      return staleTime <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      refCountedChildPolicyWrapperFactory.release(childPolicyWrapper);\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"response\", response)\n+          .add(\"expireTime\", expireTime)\n+          .add(\"staleTime\", staleTime)\n+          .add(\"childPolicyWrapper\", childPolicyWrapper)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * Implementation of {@link CacheEntry} contains error. This entry will transition to pending\n+   * status when the backoff time is expired.\n+   */\n+  private final class BackoffCacheEntry extends CacheEntry {\n+\n+    private final Status status;\n+    private final ScheduledFuture<?> scheduledFuture;\n+    private final BackoffPolicy backoffPolicy;\n+    private final long expireNanos;\n+    private boolean shutdown = false;\n+\n+    BackoffCacheEntry(RouteLookupRequest request, Status status, BackoffPolicy backoffPolicy) {\n+      super(request);\n+      this.status = checkNotNull(status, \"status\");\n+      this.backoffPolicy = checkNotNull(backoffPolicy, \"backoffPolicy\");\n+      long delayNanos = backoffPolicy.nextBackoffNanos();\n+      this.expireNanos = timeProvider.currentTimeNanos() + delayNanos;\n+      this.scheduledFuture =\n+          scheduledExecutorService.schedule(\n+              new Runnable() {\n+                @Override\n+                public void run() {\n+                  transitionToPending();\n+                }\n+              },\n+              delayNanos,\n+              TimeUnit.NANOSECONDS);\n+    }\n+\n+    /** Forcefully refreshes cache entry by ignoring the backoff timer. */\n+    void forceRefresh() {\n+      boolean cancelled = scheduledFuture.cancel(false);\n+      if (cancelled) {\n+        transitionToPending();\n+      }\n+    }\n+\n+    private void transitionToPending() {\n+      synchronized (lock) {\n+        if (shutdown) {\n+          return;\n+        }\n+        ListenableFuture<RouteLookupResponse> call = asyncRlsCall(request);\n+        if (!call.isDone()) {\n+          PendingCacheEntry pendingEntry = new PendingCacheEntry(request, call, backoffPolicy);\n+          pendingCallCache.put(request, pendingEntry);\n+          linkedHashLruCache.invalidate(request);\n+        } else {\n+          try {\n+            RouteLookupResponse response = call.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (Exception e) {\n+            linkedHashLruCache.cache(\n+                request,\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffPolicy));\n+          }\n+        }\n+      }\n+    }\n+\n+    Status getStatus() {\n+      return status;\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      return 0;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireNanos <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      if (shutdown) {\n+        return;\n+      }\n+      shutdown = true;\n+      if (!scheduledFuture.isCancelled()) {\n+        scheduledFuture.cancel(true);\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"status\", status)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .add(\"scheduledFuture\", scheduledFuture)\n+          .toString();\n+    }\n+  }\n+\n+  /** Returns a Builder for {@link CachingRlsLbClient}. */\n+  public static Builder newBuilder() {\n+    return new Builder();\n+  }\n+\n+  /** A Builder for {@link CachingRlsLbClient}. */\n+  public static final class Builder {\n+\n+    private Helper helper;\n+    private LbPolicyConfiguration lbPolicyConfig;\n+    private Throttler throttler = new HappyThrottler();\n+    private ResolvedAddressFactory resolvedAddressFactory;\n+    private TimeProvider timeProvider = TimeProvider.SYSTEM_TIME_PROVIDER;\n+    private EvictionListener<RouteLookupRequest, CacheEntry> evictionListener;\n+    private BackoffPolicy.Provider backoffProvider = new ExponentialBackoffPolicy.Provider();\n+\n+    public Builder setHelper(Helper helper) {\n+      this.helper = checkNotNull(helper, \"helper\");\n+      return this;\n+    }\n+\n+    public Builder setLbPolicyConfig(LbPolicyConfiguration lbPolicyConfig) {\n+      this.lbPolicyConfig = checkNotNull(lbPolicyConfig, \"lbPolicyConfig\");\n+      return this;\n+    }\n+\n+    public Builder setThrottler(Throttler throttler) {\n+      this.throttler = checkNotNull(throttler, \"throttler\");\n+      return this;\n+    }\n+\n+    /**\n+     * Sets a factory to create {@link ResolvedAddresses} for child load balancer.\n+     */\n+    public Builder setResolvedAddressesFactory(\n+        ResolvedAddressFactory resolvedAddressFactory) {\n+      this.resolvedAddressFactory =\n+          checkNotNull(resolvedAddressFactory, \"resolvedAddressFactory\");\n+      return this;\n+    }\n+\n+    public Builder setTimeProvider(TimeProvider timeProvider) {\n+      this.timeProvider = checkNotNull(timeProvider, \"timeProvider\");\n+      return this;\n+    }\n+\n+    public Builder setEvictionListener(\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> evictionListener) {\n+      this.evictionListener = evictionListener;\n+      return this;\n+    }\n+\n+    public Builder setBackoffProvider(BackoffPolicy.Provider provider) {\n+      this.backoffProvider = checkNotNull(provider, \"provider\");\n+      return this;\n+    }\n+\n+    public CachingRlsLbClient build() {\n+      return new CachingRlsLbClient(this);\n+    }\n+  }\n+\n+  /**\n+   * When any {@link CacheEntry} is evicted from {@link LruCache}, it performs {@link\n+   * CacheEntry#cleanup()} after original {@link EvictionListener} is finished.\n+   */\n+  private static final class AutoCleaningEvictionListener\n+      implements EvictionListener<RouteLookupRequest, CacheEntry> {\n+\n+    private final EvictionListener<RouteLookupRequest, CacheEntry> delegate;\n+\n+    AutoCleaningEvictionListener(\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> delegate) {\n+      this.delegate = delegate;\n+    }\n+\n+    @Override\n+    public void onEviction(RouteLookupRequest key, CacheEntry value, EvictionType cause) {\n+      if (delegate != null) {\n+        delegate.onEviction(key, value, cause);\n+      }\n+      // performs cleanup after delegation\n+      value.cleanup();\n+    }\n+  }\n+\n+  /** A Throttler never throttles. */\n+  private static final class HappyThrottler implements Throttler {\n+\n+    @Override\n+    public boolean shouldThrottle() {\n+      return false;\n+    }\n+\n+    @Override\n+    public void registerBackendResponse(boolean throttled) {\n+      // no-op\n+    }\n+  }\n+\n+  /** Implementation of {@link LinkedHashLruCache} for RLS. */\n+  private static final class RlsAsyncLruCache\n+      extends LinkedHashLruCache<RouteLookupRequest, CacheEntry> {\n+\n+    RlsAsyncLruCache(long maxEstimatedSizeBytes,\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> evictionListener,\n+        ScheduledExecutorService ses, TimeProvider timeProvider) {\n+      super(\n+          maxEstimatedSizeBytes,\n+          new AutoCleaningEvictionListener(evictionListener),\n+          1,\n+          TimeUnit.MINUTES,\n+          ses,\n+          timeProvider);\n+    }\n+\n+    @Override\n+    protected boolean isExpired(RouteLookupRequest key, CacheEntry value, long nowNanos) {\n+      return value.isExpired();\n+    }\n+\n+    @Override\n+    protected int estimateSizeOf(RouteLookupRequest key, CacheEntry value) {\n+      return value.getSizeBytes();\n+    }\n+\n+    @Override\n+    protected boolean shouldInvalidateEldestEntry(\n+        RouteLookupRequest eldestKey, CacheEntry eldestValue) {\n+      // eldest entry should be evicted if size limit exceeded\n+      return true;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * LbStatusListener refreshes {@link BackoffCacheEntry} when lb state is changed to {@link\n+   * ConnectivityState#READY} from {@link ConnectivityState#TRANSIENT_FAILURE}.\n+   */\n+  private final class BackoffRefreshListener implements ChildLbStatusListener {\n+\n+    @Nullable\n+    private ConnectivityState prevState = null;\n+\n+    @Override\n+    public void onStatusChanged(ConnectivityState newState) {\n+      if (prevState == ConnectivityState.TRANSIENT_FAILURE\n+          && newState == ConnectivityState.READY) {\n+        synchronized (lock) {\n+          for (CacheEntry value : linkedHashLruCache.values()) {\n+            if (value instanceof BackoffCacheEntry) {\n+              ((BackoffCacheEntry) value).forceRefresh();\n+            }\n+          }\n+        }\n+      }\n+      prevState = newState;\n+    }\n+  }\n+\n+  /** A header will be added when RLS server respond with additional header data. */\n+  public static final Metadata.Key<String> RLS_DATA_KEY =\n+      Metadata.Key.of(\"X-Google-RLS-Data\", Metadata.ASCII_STRING_MARSHALLER);\n+\n+  final class RlsPicker extends SubchannelPicker {\n+\n+    private final RlsRequestFactory requestFactory;\n+\n+    RlsPicker(RlsRequestFactory requestFactory) {\n+      this.requestFactory = checkNotNull(requestFactory, \"requestFactory\");\n+      helper.updateBalancingState(ConnectivityState.CONNECTING, this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 837}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY1Mjk5Mg==", "bodyText": "The above checkState()'s are invariants of RouteLookupConfig, no need to check again here.", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r417652992", "createdAt": "2020-04-29T22:37:02Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY1MzE1Mw==", "bodyText": "This check should be moved to RouteLookupConfig constructor.", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r417653153", "createdAt": "2020-04-29T22:37:29Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4MzA3NA==", "bodyText": "nit: move the last return statement up inside the if scope above. else is not necessary then.", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r417683074", "createdAt": "2020-04-30T00:08:01Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 209}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE0MzgxNg==", "bodyText": "Handle InterruptedException:\nif (e instanceof InterruptedException) {\n  Thread.currentThread().interrupt();\n}", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418143816", "createdAt": "2020-04-30T16:39:48Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      checkState(\n+          childPolicyWrapper.getHelper() != null,\n+          \"incomplete childPolicyWrapper found, this is a bug\");\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled |\n+     * entry2:                        | OV | pending | hasValue | staled |\n+     * </pre>\n+     */\n+    void maybeRefresh() {\n+      synchronized (lock) {\n+        if (pendingCallCache.containsKey(request)) {\n+          // pending already requested\n+          return;\n+        }\n+        final ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+        if (!asyncCall.isDone()) {\n+          pendingCallCache.put(request, new PendingCacheEntry(request, asyncCall));\n+        } else {\n+          // async call returned finished future is most likely throttled\n+          try {\n+            RouteLookupResponse response = asyncCall.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (Exception e) {\n+            BackoffCacheEntry backoffEntry =\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+            linkedHashLruCache.cache(request, backoffEntry);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      return childPolicyWrapper;\n+    }\n+\n+    String getHeaderData() {\n+      return response.getHeaderData();\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      // size of strings and java object overhead, actual memory usage is more than this.\n+      return (response.getTarget().length() + response.getHeaderData().length()) * 2 + 38 * 2;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireTime <= now;\n+    }\n+\n+    boolean isStaled(long now) {\n+      return staleTime <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      refCountedChildPolicyWrapperFactory.release(childPolicyWrapper);\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"response\", response)\n+          .add(\"expireTime\", expireTime)\n+          .add(\"staleTime\", staleTime)\n+          .add(\"childPolicyWrapper\", childPolicyWrapper)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * Implementation of {@link CacheEntry} contains error. This entry will transition to pending\n+   * status when the backoff time is expired.\n+   */\n+  private final class BackoffCacheEntry extends CacheEntry {\n+\n+    private final Status status;\n+    private final ScheduledFuture<?> scheduledFuture;\n+    private final BackoffPolicy backoffPolicy;\n+    private final long expireNanos;\n+    private boolean shutdown = false;\n+\n+    BackoffCacheEntry(RouteLookupRequest request, Status status, BackoffPolicy backoffPolicy) {\n+      super(request);\n+      this.status = checkNotNull(status, \"status\");\n+      this.backoffPolicy = checkNotNull(backoffPolicy, \"backoffPolicy\");\n+      long delayNanos = backoffPolicy.nextBackoffNanos();\n+      this.expireNanos = timeProvider.currentTimeNanos() + delayNanos;\n+      this.scheduledFuture =\n+          scheduledExecutorService.schedule(\n+              new Runnable() {\n+                @Override\n+                public void run() {\n+                  transitionToPending();\n+                }\n+              },\n+              delayNanos,\n+              TimeUnit.NANOSECONDS);\n+    }\n+\n+    /** Forcefully refreshes cache entry by ignoring the backoff timer. */\n+    void forceRefresh() {\n+      boolean cancelled = scheduledFuture.cancel(false);\n+      if (cancelled) {\n+        transitionToPending();\n+      }\n+    }\n+\n+    private void transitionToPending() {\n+      synchronized (lock) {\n+        if (shutdown) {\n+          return;\n+        }\n+        ListenableFuture<RouteLookupResponse> call = asyncRlsCall(request);\n+        if (!call.isDone()) {\n+          PendingCacheEntry pendingEntry = new PendingCacheEntry(request, call, backoffPolicy);\n+          pendingCallCache.put(request, pendingEntry);\n+          linkedHashLruCache.invalidate(request);\n+        } else {\n+          try {\n+            RouteLookupResponse response = call.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 617}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE1NTQxMA==", "bodyText": "Why not replace\n!(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null)\nwith\n(dataCacheEntry == null || pendingCacheEntry == null || backoffCacheEntry == null)\n?", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418155410", "createdAt": "2020-04-30T16:59:35Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 287}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyNDAzMw==", "bodyText": "nit: move declaration down inside the if scope below.", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418224033", "createdAt": "2020-04-30T18:59:30Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyNzM3Mg==", "bodyText": "nit: annotate the method with @GuardedBy(\"CachingRlsLbClient.this.lock\"), and remove synchronized (lock)", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418227372", "createdAt": "2020-04-30T19:05:47Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      checkState(\n+          childPolicyWrapper.getHelper() != null,\n+          \"incomplete childPolicyWrapper found, this is a bug\");\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled |\n+     * entry2:                        | OV | pending | hasValue | staled |\n+     * </pre>\n+     */\n+    void maybeRefresh() {\n+      synchronized (lock) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 502}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyOTMwNg==", "bodyText": "What does OV mean here?", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418229306", "createdAt": "2020-04-30T19:09:24Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      checkState(\n+          childPolicyWrapper.getHelper() != null,\n+          \"incomplete childPolicyWrapper found, this is a bug\");\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled |\n+     * entry2:                        | OV | pending | hasValue | staled |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 498}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIzNjEyNQ==", "bodyText": "if it is being refreshed and is pending, should we return CachedRouteLookupResponse.pendingResponse(pendingEntry)?", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418236125", "createdAt": "2020-04-30T19:22:09Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 204}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzODg5MjY1", "url": "https://github.com/grpc/grpc-java/pull/6966#pullrequestreview-403889265", "createdAt": "2020-04-30T21:26:08Z", "commit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQyMToyNjowOVrOGO66tQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQyMToyNjowOVrOGO66tQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5ODU0OQ==", "bodyText": "Why only this place is using synchronizationContext, whereas all other places are using scheduledExecutorService? Is there any guidance when to use which?", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418298549", "createdAt": "2020-04-30T21:26:09Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 375}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9df8623112de4abd3181fbdf8828a6e640658b8", "author": {"user": {"login": "creamsoup", "name": "Jihun Cho"}}, "url": "https://github.com/grpc/grpc-java/commit/f9df8623112de4abd3181fbdf8828a6e640658b8", "committedDate": "2020-04-30T22:38:49Z", "message": "address review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzOTA2NDg1", "url": "https://github.com/grpc/grpc-java/pull/6966#pullrequestreview-403906485", "createdAt": "2020-04-30T21:58:36Z", "commit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQyMTo1ODozNlrOGO7yLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQyMjo1NDoyNVrOGO9FWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxMjc1MQ==", "bodyText": "This check is no longer needed.", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418312751", "createdAt": "2020-04-30T21:58:36Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      checkState(\n+          childPolicyWrapper.getHelper() != null,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 467}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyNTc2MQ==", "bodyText": "Why updateEntrySize in constructor? It looks wired the constructor can modify linkedHashLruCache's state.", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418325761", "createdAt": "2020-04-30T22:30:43Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 461}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyODQ3Mw==", "bodyText": "\"not all has value\" is logically the same as \"at least one is no value\", but for the latter the expression does not need double negation, sort of a little \"simpler\".", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418328473", "createdAt": "2020-04-30T22:38:11Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE1NTQxMA=="}, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 287}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMzNDA0Mg==", "bodyText": "Seems this usage is not supported by the current version of errorprone. Maybe keep as is.", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418334042", "createdAt": "2020-04-30T22:54:25Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,977 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    checkState(rlsConfig.getMaxAgeInMillis() > 0L, \"maxAgeMillis should be positive\");\n+    checkState(rlsConfig.getStaleAgeInMillis() > 0L, \"staleAgeMillis should be positive\");\n+    checkState(\n+        rlsConfig.getMaxAgeInMillis() >= rlsConfig.getStaleAgeInMillis(),\n+        \"maxAgeMillis should be greater than equals to staleAgeMillis\");\n+    checkState(\n+        rlsConfig.getLookupServiceTimeoutInMillis() > 0L,\n+        \"getLookupServiceTimeoutInMillis should be positive\");\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      long now = timeProvider.currentTimeNanos();\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(now)) {\n+          dataEntry.maybeRefresh();\n+        }\n+      } else {\n+        return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  private final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+        linkedHashLruCache.updateEntrySize(request);\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      checkState(\n+          childPolicyWrapper.getHelper() != null,\n+          \"incomplete childPolicyWrapper found, this is a bug\");\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled |\n+     * entry2:                        | OV | pending | hasValue | staled |\n+     * </pre>\n+     */\n+    void maybeRefresh() {\n+      synchronized (lock) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyNzM3Mg=="}, "originalCommit": {"oid": "2e371419e8f94e651211af23839a4228058aee5b"}, "originalPosition": 502}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2d856545c700761e747320a2176c02da982dbd5a", "author": {"user": {"login": "creamsoup", "name": "Jihun Cho"}}, "url": "https://github.com/grpc/grpc-java/commit/2d856545c700761e747320a2176c02da982dbd5a", "committedDate": "2020-04-30T23:30:26Z", "message": "remove cache entry size change, remove some checks"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAzOTQzNTc1", "url": "https://github.com/grpc/grpc-java/pull/6966#pullrequestreview-403943575", "createdAt": "2020-04-30T23:26:49Z", "commit": {"oid": "2d856545c700761e747320a2176c02da982dbd5a"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQyMzoyNjo0OVrOGO9t_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQwMDowNzo0N1rOGO-b-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM0NDQ0Ng==", "bodyText": "The channel always logs picker update, so it's better to add a human readable toString().", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418344446", "createdAt": "2020-04-30T23:26:49Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,970 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.SynchronizationContext.ScheduledHandle;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    helper.updateBalancingState(ConnectivityState.CONNECTING, rlsPicker);\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(timeProvider.currentTimeNanos())) {\n+          dataEntry.maybeRefresh();\n+        }\n+        return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled  |\n+     * entry2:                        | OV* | pending | hasValue | staled |\n+     *\n+     * OV: old value\n+     * </pre>\n+     */\n+    void maybeRefresh() {\n+      synchronized (lock) {\n+        if (pendingCallCache.containsKey(request)) {\n+          // pending already requested\n+          return;\n+        }\n+        final ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+        if (!asyncCall.isDone()) {\n+          pendingCallCache.put(request, new PendingCacheEntry(request, asyncCall));\n+        } else {\n+          // async call returned finished future is most likely throttled\n+          try {\n+            RouteLookupResponse response = asyncCall.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+          } catch (Exception e) {\n+            BackoffCacheEntry backoffEntry =\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+            linkedHashLruCache.cache(request, backoffEntry);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      return childPolicyWrapper;\n+    }\n+\n+    String getHeaderData() {\n+      return response.getHeaderData();\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      // size of strings and java object overhead, actual memory usage is more than this.\n+      return (response.getTarget().length() + response.getHeaderData().length()) * 2 + 38 * 2;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireTime <= now;\n+    }\n+\n+    boolean isStaled(long now) {\n+      return staleTime <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      refCountedChildPolicyWrapperFactory.release(childPolicyWrapper);\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"response\", response)\n+          .add(\"expireTime\", expireTime)\n+          .add(\"staleTime\", staleTime)\n+          .add(\"childPolicyWrapper\", childPolicyWrapper)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * Implementation of {@link CacheEntry} contains error. This entry will transition to pending\n+   * status when the backoff time is expired.\n+   */\n+  private final class BackoffCacheEntry extends CacheEntry {\n+\n+    private final Status status;\n+    private final ScheduledHandle scheduledHandle;\n+    private final BackoffPolicy backoffPolicy;\n+    private final long expireNanos;\n+    private boolean shutdown = false;\n+\n+    BackoffCacheEntry(RouteLookupRequest request, Status status, BackoffPolicy backoffPolicy) {\n+      super(request);\n+      this.status = checkNotNull(status, \"status\");\n+      this.backoffPolicy = checkNotNull(backoffPolicy, \"backoffPolicy\");\n+      long delayNanos = backoffPolicy.nextBackoffNanos();\n+      this.expireNanos = timeProvider.currentTimeNanos() + delayNanos;\n+      this.scheduledHandle =\n+          synchronizationContext.schedule(\n+              new Runnable() {\n+                @Override\n+                public void run() {\n+                  transitionToPending();\n+                }\n+              },\n+              delayNanos,\n+              TimeUnit.NANOSECONDS,\n+              scheduledExecutorService);\n+    }\n+\n+    /** Forcefully refreshes cache entry by ignoring the backoff timer. */\n+    void forceRefresh() {\n+      if (scheduledHandle.isPending()) {\n+        scheduledHandle.cancel();\n+        transitionToPending();\n+      }\n+    }\n+\n+    private void transitionToPending() {\n+      synchronized (lock) {\n+        if (shutdown) {\n+          return;\n+        }\n+        ListenableFuture<RouteLookupResponse> call = asyncRlsCall(request);\n+        if (!call.isDone()) {\n+          PendingCacheEntry pendingEntry = new PendingCacheEntry(request, call, backoffPolicy);\n+          pendingCallCache.put(request, pendingEntry);\n+          linkedHashLruCache.invalidate(request);\n+        } else {\n+          try {\n+            RouteLookupResponse response = call.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+          } catch (Exception e) {\n+            linkedHashLruCache.cache(\n+                request,\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffPolicy));\n+          }\n+        }\n+      }\n+    }\n+\n+    Status getStatus() {\n+      return status;\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      return 0;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireNanos <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      if (shutdown) {\n+        return;\n+      }\n+      shutdown = true;\n+      if (!scheduledHandle.isPending()) {\n+        scheduledHandle.cancel();\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"status\", status)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .add(\"scheduledFuture\", scheduledHandle)\n+          .toString();\n+    }\n+  }\n+\n+  /** Returns a Builder for {@link CachingRlsLbClient}. */\n+  public static Builder newBuilder() {\n+    return new Builder();\n+  }\n+\n+  /** A Builder for {@link CachingRlsLbClient}. */\n+  public static final class Builder {\n+\n+    private Helper helper;\n+    private LbPolicyConfiguration lbPolicyConfig;\n+    private Throttler throttler = new HappyThrottler();\n+    private ResolvedAddressFactory resolvedAddressFactory;\n+    private TimeProvider timeProvider = TimeProvider.SYSTEM_TIME_PROVIDER;\n+    private EvictionListener<RouteLookupRequest, CacheEntry> evictionListener;\n+    private BackoffPolicy.Provider backoffProvider = new ExponentialBackoffPolicy.Provider();\n+\n+    public Builder setHelper(Helper helper) {\n+      this.helper = checkNotNull(helper, \"helper\");\n+      return this;\n+    }\n+\n+    public Builder setLbPolicyConfig(LbPolicyConfiguration lbPolicyConfig) {\n+      this.lbPolicyConfig = checkNotNull(lbPolicyConfig, \"lbPolicyConfig\");\n+      return this;\n+    }\n+\n+    public Builder setThrottler(Throttler throttler) {\n+      this.throttler = checkNotNull(throttler, \"throttler\");\n+      return this;\n+    }\n+\n+    /**\n+     * Sets a factory to create {@link ResolvedAddresses} for child load balancer.\n+     */\n+    public Builder setResolvedAddressesFactory(\n+        ResolvedAddressFactory resolvedAddressFactory) {\n+      this.resolvedAddressFactory =\n+          checkNotNull(resolvedAddressFactory, \"resolvedAddressFactory\");\n+      return this;\n+    }\n+\n+    public Builder setTimeProvider(TimeProvider timeProvider) {\n+      this.timeProvider = checkNotNull(timeProvider, \"timeProvider\");\n+      return this;\n+    }\n+\n+    public Builder setEvictionListener(\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> evictionListener) {\n+      this.evictionListener = evictionListener;\n+      return this;\n+    }\n+\n+    public Builder setBackoffProvider(BackoffPolicy.Provider provider) {\n+      this.backoffProvider = checkNotNull(provider, \"provider\");\n+      return this;\n+    }\n+\n+    public CachingRlsLbClient build() {\n+      return new CachingRlsLbClient(this);\n+    }\n+  }\n+\n+  /**\n+   * When any {@link CacheEntry} is evicted from {@link LruCache}, it performs {@link\n+   * CacheEntry#cleanup()} after original {@link EvictionListener} is finished.\n+   */\n+  private static final class AutoCleaningEvictionListener\n+      implements EvictionListener<RouteLookupRequest, CacheEntry> {\n+\n+    private final EvictionListener<RouteLookupRequest, CacheEntry> delegate;\n+\n+    AutoCleaningEvictionListener(\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> delegate) {\n+      this.delegate = delegate;\n+    }\n+\n+    @Override\n+    public void onEviction(RouteLookupRequest key, CacheEntry value, EvictionType cause) {\n+      if (delegate != null) {\n+        delegate.onEviction(key, value, cause);\n+      }\n+      // performs cleanup after delegation\n+      value.cleanup();\n+    }\n+  }\n+\n+  /** A Throttler never throttles. */\n+  private static final class HappyThrottler implements Throttler {\n+\n+    @Override\n+    public boolean shouldThrottle() {\n+      return false;\n+    }\n+\n+    @Override\n+    public void registerBackendResponse(boolean throttled) {\n+      // no-op\n+    }\n+  }\n+\n+  /** Implementation of {@link LinkedHashLruCache} for RLS. */\n+  private static final class RlsAsyncLruCache\n+      extends LinkedHashLruCache<RouteLookupRequest, CacheEntry> {\n+\n+    RlsAsyncLruCache(long maxEstimatedSizeBytes,\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> evictionListener,\n+        ScheduledExecutorService ses, TimeProvider timeProvider) {\n+      super(\n+          maxEstimatedSizeBytes,\n+          new AutoCleaningEvictionListener(evictionListener),\n+          1,\n+          TimeUnit.MINUTES,\n+          ses,\n+          timeProvider);\n+    }\n+\n+    @Override\n+    protected boolean isExpired(RouteLookupRequest key, CacheEntry value, long nowNanos) {\n+      return value.isExpired();\n+    }\n+\n+    @Override\n+    protected int estimateSizeOf(RouteLookupRequest key, CacheEntry value) {\n+      return value.getSizeBytes();\n+    }\n+\n+    @Override\n+    protected boolean shouldInvalidateEldestEntry(\n+        RouteLookupRequest eldestKey, CacheEntry eldestValue) {\n+      // eldest entry should be evicted if size limit exceeded\n+      return true;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * LbStatusListener refreshes {@link BackoffCacheEntry} when lb state is changed to {@link\n+   * ConnectivityState#READY} from {@link ConnectivityState#TRANSIENT_FAILURE}.\n+   */\n+  private final class BackoffRefreshListener implements ChildLbStatusListener {\n+\n+    @Nullable\n+    private ConnectivityState prevState = null;\n+\n+    @Override\n+    public void onStatusChanged(ConnectivityState newState) {\n+      if (prevState == ConnectivityState.TRANSIENT_FAILURE\n+          && newState == ConnectivityState.READY) {\n+        synchronized (lock) {\n+          for (CacheEntry value : linkedHashLruCache.values()) {\n+            if (value instanceof BackoffCacheEntry) {\n+              ((BackoffCacheEntry) value).forceRefresh();\n+            }\n+          }\n+        }\n+      }\n+      prevState = newState;\n+    }\n+  }\n+\n+  /** A header will be added when RLS server respond with additional header data. */\n+  public static final Metadata.Key<String> RLS_DATA_KEY =\n+      Metadata.Key.of(\"X-Google-RLS-Data\", Metadata.ASCII_STRING_MARSHALLER);\n+\n+  final class RlsPicker extends SubchannelPicker {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d856545c700761e747320a2176c02da982dbd5a"}, "originalPosition": 825}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM1NjIxOQ==", "bodyText": "Why block for fallback policy for lookupServiceTimeoutInMillis, which is the timeout value for lookup service requests?\nActually this latch normally is released immediately unless there is some hanging task in the queue of sychronizationConxtext.", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418356219", "createdAt": "2020-05-01T00:07:47Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,970 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.SynchronizationContext.ScheduledHandle;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    helper.updateBalancingState(ConnectivityState.CONNECTING, rlsPicker);\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(timeProvider.currentTimeNanos())) {\n+          dataEntry.maybeRefresh();\n+        }\n+        return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));\n+      lb.requestConnection();\n+    }\n+\n+    /**\n+     * Refreshes cache entry by creating {@link PendingCacheEntry}. When the {@code\n+     * PendingCacheEntry} received data from RLS server, it will replace the data entry if valid\n+     * data still exists. Flow looks like following.\n+     *\n+     * <pre>\n+     * Timeline                       | async refresh\n+     *                                V put new cache (entry2)\n+     * entry1: Pending | hasValue | staled  |\n+     * entry2:                        | OV* | pending | hasValue | staled |\n+     *\n+     * OV: old value\n+     * </pre>\n+     */\n+    void maybeRefresh() {\n+      synchronized (lock) {\n+        if (pendingCallCache.containsKey(request)) {\n+          // pending already requested\n+          return;\n+        }\n+        final ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+        if (!asyncCall.isDone()) {\n+          pendingCallCache.put(request, new PendingCacheEntry(request, asyncCall));\n+        } else {\n+          // async call returned finished future is most likely throttled\n+          try {\n+            RouteLookupResponse response = asyncCall.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+          } catch (Exception e) {\n+            BackoffCacheEntry backoffEntry =\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+            linkedHashLruCache.cache(request, backoffEntry);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      return childPolicyWrapper;\n+    }\n+\n+    String getHeaderData() {\n+      return response.getHeaderData();\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      // size of strings and java object overhead, actual memory usage is more than this.\n+      return (response.getTarget().length() + response.getHeaderData().length()) * 2 + 38 * 2;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireTime <= now;\n+    }\n+\n+    boolean isStaled(long now) {\n+      return staleTime <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      refCountedChildPolicyWrapperFactory.release(childPolicyWrapper);\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"response\", response)\n+          .add(\"expireTime\", expireTime)\n+          .add(\"staleTime\", staleTime)\n+          .add(\"childPolicyWrapper\", childPolicyWrapper)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * Implementation of {@link CacheEntry} contains error. This entry will transition to pending\n+   * status when the backoff time is expired.\n+   */\n+  private final class BackoffCacheEntry extends CacheEntry {\n+\n+    private final Status status;\n+    private final ScheduledHandle scheduledHandle;\n+    private final BackoffPolicy backoffPolicy;\n+    private final long expireNanos;\n+    private boolean shutdown = false;\n+\n+    BackoffCacheEntry(RouteLookupRequest request, Status status, BackoffPolicy backoffPolicy) {\n+      super(request);\n+      this.status = checkNotNull(status, \"status\");\n+      this.backoffPolicy = checkNotNull(backoffPolicy, \"backoffPolicy\");\n+      long delayNanos = backoffPolicy.nextBackoffNanos();\n+      this.expireNanos = timeProvider.currentTimeNanos() + delayNanos;\n+      this.scheduledHandle =\n+          synchronizationContext.schedule(\n+              new Runnable() {\n+                @Override\n+                public void run() {\n+                  transitionToPending();\n+                }\n+              },\n+              delayNanos,\n+              TimeUnit.NANOSECONDS,\n+              scheduledExecutorService);\n+    }\n+\n+    /** Forcefully refreshes cache entry by ignoring the backoff timer. */\n+    void forceRefresh() {\n+      if (scheduledHandle.isPending()) {\n+        scheduledHandle.cancel();\n+        transitionToPending();\n+      }\n+    }\n+\n+    private void transitionToPending() {\n+      synchronized (lock) {\n+        if (shutdown) {\n+          return;\n+        }\n+        ListenableFuture<RouteLookupResponse> call = asyncRlsCall(request);\n+        if (!call.isDone()) {\n+          PendingCacheEntry pendingEntry = new PendingCacheEntry(request, call, backoffPolicy);\n+          pendingCallCache.put(request, pendingEntry);\n+          linkedHashLruCache.invalidate(request);\n+        } else {\n+          try {\n+            RouteLookupResponse response = call.get();\n+            linkedHashLruCache.cache(request, new DataCacheEntry(request, response));\n+          } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+          } catch (Exception e) {\n+            linkedHashLruCache.cache(\n+                request,\n+                new BackoffCacheEntry(request, Status.fromThrowable(e), backoffPolicy));\n+          }\n+        }\n+      }\n+    }\n+\n+    Status getStatus() {\n+      return status;\n+    }\n+\n+    @Override\n+    int getSizeBytes() {\n+      return 0;\n+    }\n+\n+    @Override\n+    boolean isExpired(long now) {\n+      return expireNanos <= now;\n+    }\n+\n+    @Override\n+    void cleanup() {\n+      if (shutdown) {\n+        return;\n+      }\n+      shutdown = true;\n+      if (!scheduledHandle.isPending()) {\n+        scheduledHandle.cancel();\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"status\", status)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .add(\"scheduledFuture\", scheduledHandle)\n+          .toString();\n+    }\n+  }\n+\n+  /** Returns a Builder for {@link CachingRlsLbClient}. */\n+  public static Builder newBuilder() {\n+    return new Builder();\n+  }\n+\n+  /** A Builder for {@link CachingRlsLbClient}. */\n+  public static final class Builder {\n+\n+    private Helper helper;\n+    private LbPolicyConfiguration lbPolicyConfig;\n+    private Throttler throttler = new HappyThrottler();\n+    private ResolvedAddressFactory resolvedAddressFactory;\n+    private TimeProvider timeProvider = TimeProvider.SYSTEM_TIME_PROVIDER;\n+    private EvictionListener<RouteLookupRequest, CacheEntry> evictionListener;\n+    private BackoffPolicy.Provider backoffProvider = new ExponentialBackoffPolicy.Provider();\n+\n+    public Builder setHelper(Helper helper) {\n+      this.helper = checkNotNull(helper, \"helper\");\n+      return this;\n+    }\n+\n+    public Builder setLbPolicyConfig(LbPolicyConfiguration lbPolicyConfig) {\n+      this.lbPolicyConfig = checkNotNull(lbPolicyConfig, \"lbPolicyConfig\");\n+      return this;\n+    }\n+\n+    public Builder setThrottler(Throttler throttler) {\n+      this.throttler = checkNotNull(throttler, \"throttler\");\n+      return this;\n+    }\n+\n+    /**\n+     * Sets a factory to create {@link ResolvedAddresses} for child load balancer.\n+     */\n+    public Builder setResolvedAddressesFactory(\n+        ResolvedAddressFactory resolvedAddressFactory) {\n+      this.resolvedAddressFactory =\n+          checkNotNull(resolvedAddressFactory, \"resolvedAddressFactory\");\n+      return this;\n+    }\n+\n+    public Builder setTimeProvider(TimeProvider timeProvider) {\n+      this.timeProvider = checkNotNull(timeProvider, \"timeProvider\");\n+      return this;\n+    }\n+\n+    public Builder setEvictionListener(\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> evictionListener) {\n+      this.evictionListener = evictionListener;\n+      return this;\n+    }\n+\n+    public Builder setBackoffProvider(BackoffPolicy.Provider provider) {\n+      this.backoffProvider = checkNotNull(provider, \"provider\");\n+      return this;\n+    }\n+\n+    public CachingRlsLbClient build() {\n+      return new CachingRlsLbClient(this);\n+    }\n+  }\n+\n+  /**\n+   * When any {@link CacheEntry} is evicted from {@link LruCache}, it performs {@link\n+   * CacheEntry#cleanup()} after original {@link EvictionListener} is finished.\n+   */\n+  private static final class AutoCleaningEvictionListener\n+      implements EvictionListener<RouteLookupRequest, CacheEntry> {\n+\n+    private final EvictionListener<RouteLookupRequest, CacheEntry> delegate;\n+\n+    AutoCleaningEvictionListener(\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> delegate) {\n+      this.delegate = delegate;\n+    }\n+\n+    @Override\n+    public void onEviction(RouteLookupRequest key, CacheEntry value, EvictionType cause) {\n+      if (delegate != null) {\n+        delegate.onEviction(key, value, cause);\n+      }\n+      // performs cleanup after delegation\n+      value.cleanup();\n+    }\n+  }\n+\n+  /** A Throttler never throttles. */\n+  private static final class HappyThrottler implements Throttler {\n+\n+    @Override\n+    public boolean shouldThrottle() {\n+      return false;\n+    }\n+\n+    @Override\n+    public void registerBackendResponse(boolean throttled) {\n+      // no-op\n+    }\n+  }\n+\n+  /** Implementation of {@link LinkedHashLruCache} for RLS. */\n+  private static final class RlsAsyncLruCache\n+      extends LinkedHashLruCache<RouteLookupRequest, CacheEntry> {\n+\n+    RlsAsyncLruCache(long maxEstimatedSizeBytes,\n+        @Nullable EvictionListener<RouteLookupRequest, CacheEntry> evictionListener,\n+        ScheduledExecutorService ses, TimeProvider timeProvider) {\n+      super(\n+          maxEstimatedSizeBytes,\n+          new AutoCleaningEvictionListener(evictionListener),\n+          1,\n+          TimeUnit.MINUTES,\n+          ses,\n+          timeProvider);\n+    }\n+\n+    @Override\n+    protected boolean isExpired(RouteLookupRequest key, CacheEntry value, long nowNanos) {\n+      return value.isExpired();\n+    }\n+\n+    @Override\n+    protected int estimateSizeOf(RouteLookupRequest key, CacheEntry value) {\n+      return value.getSizeBytes();\n+    }\n+\n+    @Override\n+    protected boolean shouldInvalidateEldestEntry(\n+        RouteLookupRequest eldestKey, CacheEntry eldestValue) {\n+      // eldest entry should be evicted if size limit exceeded\n+      return true;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .toString();\n+    }\n+  }\n+\n+  /**\n+   * LbStatusListener refreshes {@link BackoffCacheEntry} when lb state is changed to {@link\n+   * ConnectivityState#READY} from {@link ConnectivityState#TRANSIENT_FAILURE}.\n+   */\n+  private final class BackoffRefreshListener implements ChildLbStatusListener {\n+\n+    @Nullable\n+    private ConnectivityState prevState = null;\n+\n+    @Override\n+    public void onStatusChanged(ConnectivityState newState) {\n+      if (prevState == ConnectivityState.TRANSIENT_FAILURE\n+          && newState == ConnectivityState.READY) {\n+        synchronized (lock) {\n+          for (CacheEntry value : linkedHashLruCache.values()) {\n+            if (value instanceof BackoffCacheEntry) {\n+              ((BackoffCacheEntry) value).forceRefresh();\n+            }\n+          }\n+        }\n+      }\n+      prevState = newState;\n+    }\n+  }\n+\n+  /** A header will be added when RLS server respond with additional header data. */\n+  public static final Metadata.Key<String> RLS_DATA_KEY =\n+      Metadata.Key.of(\"X-Google-RLS-Data\", Metadata.ASCII_STRING_MARSHALLER);\n+\n+  final class RlsPicker extends SubchannelPicker {\n+\n+    private final RlsRequestFactory requestFactory;\n+\n+    RlsPicker(RlsRequestFactory requestFactory) {\n+      this.requestFactory = checkNotNull(requestFactory, \"requestFactory\");\n+    }\n+\n+    @Override\n+    public PickResult pickSubchannel(PickSubchannelArgs args) {\n+      String[] methodName = args.getMethodDescriptor().getFullMethodName().split(\"/\", 2);\n+      RouteLookupRequest request =\n+          requestFactory.create(methodName[0], methodName[1], args.getHeaders());\n+      final CachedRouteLookupResponse response = CachingRlsLbClient.this.get(request);\n+\n+      PickSubchannelArgs rlsAppliedArgs = getApplyRlsHeader(args, response);\n+      if (response.hasData()) {\n+        ChildPolicyWrapper childPolicyWrapper = response.getChildPolicyWrapper();\n+        ConnectivityState connectivityState =\n+            childPolicyWrapper.getConnectivityStateInfo().getState();\n+        switch (connectivityState) {\n+          case CONNECTING:\n+            return PickResult.withNoResult();\n+          case IDLE:\n+            // fall through\n+          case READY:\n+            if (childPolicyWrapper.getPicker() == null) {\n+              return PickResult.withNoResult();\n+            }\n+            return childPolicyWrapper.getPicker().pickSubchannel(rlsAppliedArgs);\n+          case TRANSIENT_FAILURE:\n+            return handleError(rlsAppliedArgs, Status.INTERNAL);\n+          case SHUTDOWN:\n+          default:\n+            return handleError(rlsAppliedArgs, Status.ABORTED);\n+        }\n+      } else if (response.hasError()) {\n+        return handleError(rlsAppliedArgs, response.getStatus());\n+      } else {\n+        return PickResult.withNoResult();\n+      }\n+    }\n+\n+    private PickSubchannelArgs getApplyRlsHeader(\n+        PickSubchannelArgs args, CachedRouteLookupResponse response) {\n+      if (response.getHeaderData() == null || response.getHeaderData().isEmpty()) {\n+        return args;\n+      }\n+\n+      Metadata headers = new Metadata();\n+      headers.merge(args.getHeaders());\n+      headers.put(RLS_DATA_KEY, response.getHeaderData());\n+      return new PickSubchannelArgsImpl(args.getMethodDescriptor(), headers, args.getCallOptions());\n+    }\n+\n+    private PickResult handleError(PickSubchannelArgs args, Status cause) {\n+      RequestProcessingStrategy strategy =\n+          lbPolicyConfig.getRouteLookupConfig().getRequestProcessingStrategy();\n+      switch (strategy) {\n+        case SYNC_LOOKUP_CLIENT_SEES_ERROR:\n+          return PickResult.withError(cause);\n+        case SYNC_LOOKUP_DEFAULT_TARGET_ON_ERROR:\n+          return useFallback(args);\n+        default:\n+          throw new AssertionError(\"Unknown RequestProcessingStrategy: \" + strategy);\n+      }\n+    }\n+\n+    private ChildPolicyWrapper fallbackChildPolicyWrapper;\n+\n+    /** Uses Subchannel connected to default target. */\n+    private PickResult useFallback(PickSubchannelArgs args) {\n+      String defaultTarget = lbPolicyConfig.getRouteLookupConfig().getDefaultTarget();\n+      if (fallbackChildPolicyWrapper == null\n+          || !fallbackChildPolicyWrapper.getTarget().equals(defaultTarget)) {\n+        try {\n+          startFallbackChildPolicy()\n+              .await(\n+                  lbPolicyConfig.getRouteLookupConfig().getLookupServiceTimeoutInMillis(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d856545c700761e747320a2176c02da982dbd5a"}, "originalPosition": 903}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fecc8b0753b46ac275e5de2569dbc5181f688d40", "author": {"user": {"login": "creamsoup", "name": "Jihun Cho"}}, "url": "https://github.com/grpc/grpc-java/commit/fecc8b0753b46ac275e5de2569dbc5181f688d40", "committedDate": "2020-05-01T01:05:32Z", "message": "remove unncessary wait for fallback lb"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2", "author": {"user": {"login": "creamsoup", "name": "Jihun Cho"}}, "url": "https://github.com/grpc/grpc-java/commit/8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2", "committedDate": "2020-05-01T01:06:11Z", "message": "add todo to wait until fallback lb is ready"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA0MjgzMTgz", "url": "https://github.com/grpc/grpc-java/pull/6966#pullrequestreview-404283183", "createdAt": "2020-05-01T17:17:40Z", "commit": {"oid": "8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNzoxNzo0MFrOGPP0-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNzoxOToyN1rOGPP4VQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY0MTE0Nw==", "bodyText": "Is this run in SynchronizationContext?", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418641147", "createdAt": "2020-05-01T17:17:40Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,962 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.SynchronizationContext.ScheduledHandle;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    helper.updateBalancingState(ConnectivityState.CONNECTING, rlsPicker);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY0MTI3Ng==", "bodyText": "Is this run in SynchronizationContext?", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418641276", "createdAt": "2020-05-01T17:18:00Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,962 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.SynchronizationContext.ScheduledHandle;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    helper.updateBalancingState(ConnectivityState.CONNECTING, rlsPicker);\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(timeProvider.currentTimeNanos())) {\n+          dataEntry.maybeRefresh();\n+        }\n+        return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2"}, "originalPosition": 457}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY0MjAwNQ==", "bodyText": "Is this run in SynchronizationContext?", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418642005", "createdAt": "2020-05-01T17:19:27Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,962 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.SynchronizationContext.ScheduledHandle;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    helper.updateBalancingState(ConnectivityState.CONNECTING, rlsPicker);\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {\n+      final CacheEntry cacheEntry;\n+      cacheEntry = linkedHashLruCache.read(request);\n+      if (cacheEntry == null) {\n+        return handleNewRequest(request);\n+      }\n+\n+      if (cacheEntry instanceof DataCacheEntry) {\n+        // cache hit, initiate async-refresh if entry is staled\n+        DataCacheEntry dataEntry = ((DataCacheEntry) cacheEntry);\n+        if (dataEntry.isStaled(timeProvider.currentTimeNanos())) {\n+          dataEntry.maybeRefresh();\n+        }\n+        return CachedRouteLookupResponse.dataEntry((DataCacheEntry) cacheEntry);\n+      }\n+      return CachedRouteLookupResponse.backoffEntry((BackoffCacheEntry) cacheEntry);\n+    }\n+  }\n+\n+  /** Performs any pending maintenance operations needed by the cache. */\n+  public void close() {\n+    synchronized (lock) {\n+      // all childPolicyWrapper will be returned via AutoCleaningEvictionListener\n+      linkedHashLruCache.close();\n+      // TODO(creamsoup) maybe cancel all pending requests\n+      pendingCallCache.clear();\n+      rlsChannel.shutdown();\n+      rlsPicker.close();\n+    }\n+  }\n+\n+  /**\n+   * Populates async cache entry for new request. This is only methods directly modifies the cache,\n+   * any status change is happening via event (async request finished, timed out, etc) in {@link\n+   * PendingCacheEntry}, {@link DataCacheEntry} and {@link BackoffCacheEntry}.\n+   */\n+  private CachedRouteLookupResponse handleNewRequest(RouteLookupRequest request) {\n+    synchronized (lock) {\n+      PendingCacheEntry pendingEntry = pendingCallCache.get(request);\n+      if (pendingEntry != null) {\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      }\n+\n+      ListenableFuture<RouteLookupResponse> asyncCall = asyncRlsCall(request);\n+      if (!asyncCall.isDone()) {\n+        pendingEntry = new PendingCacheEntry(request, asyncCall);\n+        pendingCallCache.put(request, pendingEntry);\n+        return CachedRouteLookupResponse.pendingResponse(pendingEntry);\n+      } else {\n+        // async call returned finished future is most likely throttled\n+        try {\n+          RouteLookupResponse response = asyncCall.get();\n+          DataCacheEntry dataEntry = new DataCacheEntry(request, response);\n+          linkedHashLruCache.cache(request, dataEntry);\n+          return CachedRouteLookupResponse.dataEntry(dataEntry);\n+        } catch (Exception e) {\n+          BackoffCacheEntry backoffEntry =\n+              new BackoffCacheEntry(request, Status.fromThrowable(e), backoffProvider.get());\n+          linkedHashLruCache.cache(request, backoffEntry);\n+          return CachedRouteLookupResponse.backoffEntry(backoffEntry);\n+        }\n+      }\n+    }\n+  }\n+\n+  public void requestConnection() {\n+    rlsChannel.getState(true);\n+  }\n+\n+  /**\n+   * Viewer class for cached {@link RouteLookupResponse} and associated {@link ChildPolicyWrapper}.\n+   */\n+  static final class CachedRouteLookupResponse {\n+    private final RouteLookupRequest request;\n+\n+    // Should only have 1 of following 3 cache entries\n+    @Nullable\n+    private final DataCacheEntry dataCacheEntry;\n+    @Nullable\n+    private final PendingCacheEntry pendingCacheEntry;\n+    @Nullable\n+    private final BackoffCacheEntry backoffCacheEntry;\n+\n+    CachedRouteLookupResponse(\n+        RouteLookupRequest request,\n+        DataCacheEntry dataCacheEntry,\n+        PendingCacheEntry pendingCacheEntry,\n+        BackoffCacheEntry backoffCacheEntry) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.dataCacheEntry = dataCacheEntry;\n+      this.pendingCacheEntry = pendingCacheEntry;\n+      this.backoffCacheEntry = backoffCacheEntry;\n+      checkState((dataCacheEntry != null ^ pendingCacheEntry != null ^ backoffCacheEntry != null)\n+          && !(dataCacheEntry != null && pendingCacheEntry != null && backoffCacheEntry != null),\n+          \"Expected only 1 cache entry value provided\");\n+    }\n+\n+    static CachedRouteLookupResponse pendingResponse(PendingCacheEntry pendingEntry) {\n+      return new CachedRouteLookupResponse(pendingEntry.request, null, pendingEntry, null);\n+    }\n+\n+    static CachedRouteLookupResponse backoffEntry(BackoffCacheEntry backoffEntry) {\n+      return new CachedRouteLookupResponse(backoffEntry.request, null, null, backoffEntry);\n+    }\n+\n+    static CachedRouteLookupResponse dataEntry(DataCacheEntry dataEntry) {\n+      return new CachedRouteLookupResponse(dataEntry.request, dataEntry, null, null);\n+    }\n+\n+    boolean hasData() {\n+      return dataCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    ChildPolicyWrapper getChildPolicyWrapper() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getChildPolicyWrapper();\n+    }\n+\n+    @Nullable\n+    public String getHeaderData() {\n+      if (!hasData()) {\n+        return null;\n+      }\n+      return dataCacheEntry.getHeaderData();\n+    }\n+\n+    boolean hasError() {\n+      return backoffCacheEntry != null;\n+    }\n+\n+    boolean isPending() {\n+      return pendingCacheEntry != null;\n+    }\n+\n+    @Nullable\n+    Status getStatus() {\n+      if (!hasError()) {\n+        return null;\n+      }\n+      return backoffCacheEntry.getStatus();\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"dataCacheEntry\", dataCacheEntry)\n+          .add(\"pendingCacheEntry\", pendingCacheEntry)\n+          .add(\"backoffCacheEntry\", backoffCacheEntry)\n+          .toString();\n+    }\n+  }\n+\n+  /** A pending cache entry when the async RouteLookup RPC is still on the fly. */\n+  final class PendingCacheEntry {\n+    private final ListenableFuture<RouteLookupResponse> pendingCall;\n+    private final RouteLookupRequest request;\n+    private final BackoffPolicy backoffPolicy;\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request, ListenableFuture<RouteLookupResponse> pendingCall) {\n+      this(request, pendingCall, null);\n+    }\n+\n+    PendingCacheEntry(\n+        RouteLookupRequest request,\n+        ListenableFuture<RouteLookupResponse> pendingCall,\n+        @Nullable BackoffPolicy backoffPolicy) {\n+      this.request = checkNotNull(request, \"request\");\n+      this.pendingCall = pendingCall;\n+      this.backoffPolicy = backoffPolicy == null ? backoffProvider.get() : backoffPolicy;\n+      pendingCall.addListener(\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              handleDoneFuture();\n+            }\n+          },\n+          synchronizationContext);\n+    }\n+\n+    private void handleDoneFuture() {\n+      synchronized (lock) {\n+        pendingCallCache.remove(request);\n+        if (pendingCall.isCancelled()) {\n+          return;\n+        }\n+\n+        try {\n+          transitionToDataEntry(pendingCall.get());\n+        } catch (Exception e) {\n+          if (e instanceof ThrottledException) {\n+            transitionToBackOff(Status.RESOURCE_EXHAUSTED.withCause(e));\n+          } else {\n+            transitionToBackOff(Status.fromThrowable(e));\n+          }\n+        }\n+      }\n+    }\n+\n+    private void transitionToDataEntry(RouteLookupResponse routeLookupResponse) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new DataCacheEntry(request, routeLookupResponse));\n+      }\n+    }\n+\n+    private void transitionToBackOff(Status status) {\n+      synchronized (lock) {\n+        linkedHashLruCache.cache(request, new BackoffCacheEntry(request, status, backoffPolicy));\n+      }\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return MoreObjects.toStringHelper(this)\n+          .add(\"request\", request)\n+          .add(\"pendingCall\", pendingCall)\n+          .add(\"backoffPolicy\", backoffPolicy)\n+          .toString();\n+    }\n+  }\n+\n+  /** Common cache entry data for {@link RlsAsyncLruCache}. */\n+  abstract class CacheEntry {\n+\n+    protected final RouteLookupRequest request;\n+\n+    CacheEntry(RouteLookupRequest request) {\n+      this.request = checkNotNull(request, \"request\");\n+    }\n+\n+    abstract int getSizeBytes();\n+\n+    final boolean isExpired() {\n+      return isExpired(timeProvider.currentTimeNanos());\n+    }\n+\n+    abstract boolean isExpired(long now);\n+\n+    abstract void cleanup();\n+  }\n+\n+  /** Implementation of {@link CacheEntry} contains valid data. */\n+  final class DataCacheEntry extends CacheEntry {\n+    private final RouteLookupResponse response;\n+    private final long expireTime;\n+    private final long staleTime;\n+    private ChildPolicyWrapper childPolicyWrapper;\n+\n+    DataCacheEntry(RouteLookupRequest request, final RouteLookupResponse response) {\n+      super(request);\n+      this.response = checkNotNull(response, \"response\");\n+      childPolicyWrapper =\n+          refCountedChildPolicyWrapperFactory\n+              .createOrGet(response.getTarget());\n+      long now = timeProvider.currentTimeNanos();\n+      expireTime = now + maxAgeNanos;\n+      staleTime = now + staleAgeNanos;\n+\n+      if (childPolicyWrapper.getPicker() != null) {\n+        // using cached childPolicyWrapper\n+        updateLbState();\n+      } else {\n+        createChildLbPolicy();\n+      }\n+    }\n+\n+    private void updateLbState() {\n+      childPolicyWrapper\n+          .getHelper()\n+          .updateBalancingState(\n+              childPolicyWrapper.getConnectivityStateInfo().getState(),\n+              childPolicyWrapper.getPicker());\n+    }\n+\n+    private void createChildLbPolicy() {\n+      ChildLoadBalancingPolicy childPolicy = lbPolicyConfig.getLoadBalancingPolicy();\n+      LoadBalancerProvider lbProvider = childPolicy.getEffectiveLbProvider();\n+      ConfigOrError lbConfig =\n+          lbProvider\n+              .parseLoadBalancingPolicyConfig(\n+                  childPolicy.getEffectiveChildPolicy(childPolicyWrapper.getTarget()));\n+\n+      LoadBalancer lb = lbProvider.newLoadBalancer(childPolicyWrapper.getHelper());\n+      lb.handleResolvedAddresses(childLbResolvedAddressFactory.create(lbConfig.getConfig()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2"}, "originalPosition": 471}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA0Mjk5MDQz", "url": "https://github.com/grpc/grpc-java/pull/6966#pullrequestreview-404299043", "createdAt": "2020-05-01T17:46:38Z", "commit": {"oid": "8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNzo0NjozOFrOGPQqPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxODoxMDo1MFrOGPRWCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NDc4MA==", "bodyText": "An alternative is @Deprecated instead of @SuppressWarnings", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418654780", "createdAt": "2020-05-01T17:46:38Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/test/java/io/grpc/rls/internal/CachingRlsLbClientTest.java", "diffHunk": "@@ -0,0 +1,520 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.truth.Truth.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.CALLS_REAL_METHODS;\n+import static org.mockito.Mockito.inOrder;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.never;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import io.grpc.Attributes;\n+import io.grpc.ConnectivityState;\n+import io.grpc.EquivalentAddressGroup;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.NameResolver.Factory;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.inprocess.InProcessChannelBuilder;\n+import io.grpc.inprocess.InProcessServerBuilder;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.rls.internal.CachingRlsLbClient.CacheEntry;\n+import io.grpc.rls.internal.CachingRlsLbClient.CachedRouteLookupResponse;\n+import io.grpc.rls.internal.CachingRlsLbClient.RlsPicker;\n+import io.grpc.rls.internal.DoNotUseDirectScheduledExecutorService.FakeTimeProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.GrpcKeyBuilder;\n+import io.grpc.rls.internal.RlsProtoData.GrpcKeyBuilder.Name;\n+import io.grpc.rls.internal.RlsProtoData.NameMatcher;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.stub.StreamObserver;\n+import io.grpc.testing.GrpcCleanupRule;\n+import java.io.IOException;\n+import java.lang.Thread.UncaughtExceptionHandler;\n+import java.net.SocketAddress;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nonnull;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+import org.mockito.AdditionalAnswers;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.InOrder;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+@RunWith(JUnit4.class)\n+public class CachingRlsLbClientTest {\n+\n+  private static final RouteLookupConfig ROUTE_LOOKUP_CONFIG = getRouteLookupConfig();\n+  private static final int SERVER_LATENCY_MILLIS = 10;\n+\n+  @Rule\n+  public final MockitoRule mocks = MockitoJUnit.rule();\n+  @Rule\n+  public final GrpcCleanupRule grpcCleanupRule = new GrpcCleanupRule();\n+\n+  @Mock\n+  private EvictionListener<RouteLookupRequest, CacheEntry> evictionListener;\n+  @Mock\n+  private SocketAddress socketAddress;\n+\n+  private final SynchronizationContext syncContext =\n+      new SynchronizationContext(new UncaughtExceptionHandler() {\n+        @Override\n+        public void uncaughtException(Thread t, Throwable e) {\n+          throw new RuntimeException(e);\n+        }\n+      });\n+  private final FakeBackoffProvider fakeBackoffProvider = new FakeBackoffProvider();\n+  private final ResolvedAddressFactory resolvedAddressFactory =\n+      new ChildLbResolvedAddressFactory(\n+          ImmutableList.of(new EquivalentAddressGroup(socketAddress)), Attributes.EMPTY);\n+  private final TestLoadBalancerProvider lbProvider = new TestLoadBalancerProvider();\n+  private final DoNotUseDirectScheduledExecutorService fakeScheduledExecutorService =\n+      mock(DoNotUseDirectScheduledExecutorService.class, CALLS_REAL_METHODS);\n+  private final FakeTimeProvider fakeTimeProvider =\n+      fakeScheduledExecutorService.getFakeTimeProvider();\n+  private final StaticFixedDelayRlsServerImpl rlsServerImpl =\n+      new StaticFixedDelayRlsServerImpl(\n+          TimeUnit.MILLISECONDS.toNanos(SERVER_LATENCY_MILLIS), fakeScheduledExecutorService);\n+  private final ChildLoadBalancingPolicy childLbPolicy =\n+      new ChildLoadBalancingPolicy(\"target\", Collections.<String, Object>emptyMap(), lbProvider);\n+  private final Helper helper =\n+      mock(FakeHelper.class, AdditionalAnswers.delegatesTo(new FakeHelper()));\n+  private final FakeThrottler fakeThrottler = new FakeThrottler();\n+  private final LbPolicyConfiguration lbPolicyConfiguration =\n+      new LbPolicyConfiguration(ROUTE_LOOKUP_CONFIG, childLbPolicy);\n+\n+  private CachingRlsLbClient rlsLbClient;\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    rlsLbClient =\n+        CachingRlsLbClient.newBuilder()\n+            .setBackoffProvider(fakeBackoffProvider)\n+            .setResolvedAddressesFactory(resolvedAddressFactory)\n+            .setEvictionListener(evictionListener)\n+            .setHelper(helper)\n+            .setLbPolicyConfig(lbPolicyConfiguration)\n+            .setThrottler(fakeThrottler)\n+            .setTimeProvider(fakeTimeProvider)\n+            .build();\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    rlsLbClient.close();\n+  }\n+\n+  @Test\n+  public void get_noError_lifeCycle() {\n+    InOrder inOrder = inOrder(evictionListener);\n+    RouteLookupRequest routeLookupRequest =\n+        new RouteLookupRequest(\"server\", \"/foo/bar\", \"grpc\", ImmutableMap.<String, String>of());\n+    rlsServerImpl.setLookupTable(\n+        ImmutableMap.of(\n+            routeLookupRequest,\n+            new RouteLookupResponse(\"target\", \"header\")));\n+\n+    // initial request\n+    CachedRouteLookupResponse resp = rlsLbClient.get(routeLookupRequest);\n+    assertThat(resp.isPending()).isTrue();\n+\n+    // server response\n+    fakeTimeProvider.forwardTime(SERVER_LATENCY_MILLIS, TimeUnit.MILLISECONDS);\n+\n+    resp = rlsLbClient.get(routeLookupRequest);\n+    assertThat(resp.hasData()).isTrue();\n+\n+    // cache hit for staled entry\n+    fakeTimeProvider.forwardTime(ROUTE_LOOKUP_CONFIG.getStaleAgeInMillis(), TimeUnit.MILLISECONDS);\n+\n+    resp = rlsLbClient.get(routeLookupRequest);\n+    assertThat(resp.hasData()).isTrue();\n+\n+    // async refresh finishes\n+    fakeTimeProvider.forwardTime(SERVER_LATENCY_MILLIS, TimeUnit.MILLISECONDS);\n+    inOrder\n+        .verify(evictionListener)\n+        .onEviction(eq(routeLookupRequest), any(CacheEntry.class), eq(EvictionType.REPLACED));\n+\n+    resp = rlsLbClient.get(routeLookupRequest);\n+\n+    assertThat(resp.hasData()).isTrue();\n+\n+    // existing cache expired\n+    fakeTimeProvider.forwardTime(ROUTE_LOOKUP_CONFIG.getMaxAgeInMillis(), TimeUnit.MILLISECONDS);\n+\n+    resp = rlsLbClient.get(routeLookupRequest);\n+\n+    assertThat(resp.isPending()).isTrue();\n+    inOrder\n+        .verify(evictionListener)\n+        .onEviction(eq(routeLookupRequest), any(CacheEntry.class), eq(EvictionType.EXPIRED));\n+\n+    inOrder.verifyNoMoreInteractions();\n+  }\n+\n+  @Test\n+  public void get_throttledAndRecover() {\n+    RouteLookupRequest routeLookupRequest =\n+        new RouteLookupRequest(\"server\", \"/foo/bar\", \"grpc\", ImmutableMap.<String, String>of());\n+    rlsServerImpl.setLookupTable(\n+        ImmutableMap.of(\n+            routeLookupRequest,\n+            new RouteLookupResponse(\"target\", \"header\")));\n+\n+    fakeThrottler.nextResult = true;\n+    fakeBackoffProvider.nextPolicy = createBackoffPolicy(10, TimeUnit.MILLISECONDS);\n+\n+    CachedRouteLookupResponse resp = rlsLbClient.get(routeLookupRequest);\n+\n+    assertThat(resp.hasError()).isTrue();\n+\n+    fakeTimeProvider.forwardTime(10, TimeUnit.MILLISECONDS);\n+    // initially backed off entry is backed off again\n+    verify(evictionListener)\n+        .onEviction(eq(routeLookupRequest), any(CacheEntry.class), eq(EvictionType.REPLACED));\n+\n+    resp = rlsLbClient.get(routeLookupRequest);\n+\n+    assertThat(resp.hasError()).isTrue();\n+\n+    // let it pass throttler\n+    fakeThrottler.nextResult = false;\n+    fakeTimeProvider.forwardTime(10, TimeUnit.MILLISECONDS);\n+\n+    resp = rlsLbClient.get(routeLookupRequest);\n+\n+    assertThat(resp.isPending()).isTrue();\n+\n+    // server responses\n+    fakeTimeProvider.forwardTime(SERVER_LATENCY_MILLIS, TimeUnit.MILLISECONDS);\n+\n+    resp = rlsLbClient.get(routeLookupRequest);\n+\n+    assertThat(resp.hasData()).isTrue();\n+  }\n+\n+  @Test\n+  public void get_updatesLbState() {\n+    InOrder inOrder = inOrder(helper);\n+    RouteLookupRequest routeLookupRequest =\n+        new RouteLookupRequest(\"server\", \"/foo/bar\", \"grpc\", ImmutableMap.<String, String>of());\n+    rlsServerImpl.setLookupTable(\n+        ImmutableMap.of(\n+            routeLookupRequest,\n+            new RouteLookupResponse(\"target\", \"header\")));\n+\n+    // valid channel\n+    CachedRouteLookupResponse resp = rlsLbClient.get(routeLookupRequest);\n+    assertThat(resp.isPending()).isTrue();\n+    fakeTimeProvider.forwardTime(SERVER_LATENCY_MILLIS, TimeUnit.MILLISECONDS);\n+\n+    resp = rlsLbClient.get(routeLookupRequest);\n+    assertThat(resp.hasData()).isTrue();\n+\n+    ArgumentCaptor<SubchannelPicker> pickerCaptor = ArgumentCaptor.forClass(SubchannelPicker.class);\n+    ArgumentCaptor<ConnectivityState> stateCaptor =\n+        ArgumentCaptor.forClass(ConnectivityState.class);\n+    inOrder.verify(helper, times(2))\n+        .updateBalancingState(stateCaptor.capture(), pickerCaptor.capture());\n+\n+    assertThat(new HashSet<>(pickerCaptor.getAllValues())).hasSize(1);\n+    assertThat(stateCaptor.getAllValues())\n+        .containsExactly(ConnectivityState.CONNECTING, ConnectivityState.READY);\n+    assertThat(pickerCaptor.getValue()).isInstanceOf(RlsPicker.class);\n+\n+    // move backoff further back to only test error behavior\n+    fakeBackoffProvider.nextPolicy = createBackoffPolicy(100, TimeUnit.MILLISECONDS);\n+    // try to get invalid\n+    RouteLookupRequest invalidRouteLookupRequest =\n+        new RouteLookupRequest(\n+            \"unknown_server\", \"/doesn/exists\", \"grpc\", ImmutableMap.<String, String>of());\n+    CachedRouteLookupResponse errorResp = rlsLbClient.get(invalidRouteLookupRequest);\n+    assertThat(errorResp.isPending()).isTrue();\n+    fakeTimeProvider.forwardTime(SERVER_LATENCY_MILLIS, TimeUnit.MILLISECONDS);\n+\n+    errorResp = rlsLbClient.get(invalidRouteLookupRequest);\n+    assertThat(errorResp.hasError()).isTrue();\n+\n+    inOrder.verify(helper, never())\n+        .updateBalancingState(any(ConnectivityState.class), any(SubchannelPicker.class));\n+  }\n+\n+  @Test\n+  public void get_childPolicyWrapper_reusedForSameTarget() {\n+    RouteLookupRequest routeLookupRequest =\n+        new RouteLookupRequest(\"server\", \"/foo/bar\", \"grpc\", ImmutableMap.<String, String>of());\n+    RouteLookupRequest routeLookupRequest2 =\n+        new RouteLookupRequest(\"server\", \"/foo/baz\", \"grpc\", ImmutableMap.<String, String>of());\n+    rlsServerImpl.setLookupTable(\n+        ImmutableMap.of(\n+            routeLookupRequest, new RouteLookupResponse(\"target\", \"header\"),\n+            routeLookupRequest2, new RouteLookupResponse(\"target\", \"header2\")));\n+\n+    CachedRouteLookupResponse resp = rlsLbClient.get(routeLookupRequest);\n+    assertThat(resp.isPending()).isTrue();\n+    fakeTimeProvider.forwardTime(SERVER_LATENCY_MILLIS, TimeUnit.MILLISECONDS);\n+\n+    resp = rlsLbClient.get(routeLookupRequest);\n+    assertThat(resp.hasData()).isTrue();\n+    assertThat(resp.getHeaderData()).isEqualTo(\"header\");\n+\n+    ChildPolicyWrapper childPolicyWrapper = resp.getChildPolicyWrapper();\n+    assertThat(childPolicyWrapper.getTarget()).isEqualTo(\"target\");\n+    assertThat(childPolicyWrapper.getPicker()).isNotInstanceOf(RlsPicker.class);\n+\n+    // request2 has same target, it should reuse childPolicyWrapper\n+    CachedRouteLookupResponse resp2 = rlsLbClient.get(routeLookupRequest2);\n+    assertThat(resp2.isPending()).isTrue();\n+    fakeTimeProvider.forwardTime(SERVER_LATENCY_MILLIS, TimeUnit.MILLISECONDS);\n+\n+    resp2 = rlsLbClient.get(routeLookupRequest2);\n+    assertThat(resp2.hasData()).isTrue();\n+    assertThat(resp2.getHeaderData()).isEqualTo(\"header2\");\n+    assertThat(resp2.getChildPolicyWrapper()).isEqualTo(resp.getChildPolicyWrapper());\n+  }\n+\n+  private static RouteLookupConfig getRouteLookupConfig() {\n+    return new RouteLookupConfig(\n+        ImmutableList.of(\n+            new GrpcKeyBuilder(\n+                ImmutableList.of(new Name(\"service1\", \"create\")),\n+                ImmutableList.of(\n+                    new NameMatcher(\"user\", ImmutableList.of(\"User\", \"Parent\"), true),\n+                    new NameMatcher(\"id\", ImmutableList.of(\"X-Google-Id\"), true)))),\n+        /* lookupService= */ \"service1\",\n+        /* lookupServiceTimeoutInMillis= */ TimeUnit.SECONDS.toMillis(2),\n+        /* maxAgeInMillis= */ TimeUnit.SECONDS.toMillis(300),\n+        /* staleAgeInMillis= */ TimeUnit.SECONDS.toMillis(240),\n+        /* cacheSize= */ 1000,\n+        /* validTargets= */ ImmutableList.of(\"a valid target\"),\n+        /* defaultTarget= */ \"us_east_1.cloudbigtable.googleapis.com\",\n+        RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR);\n+  }\n+\n+  private static BackoffPolicy createBackoffPolicy(final long delay, final TimeUnit unit) {\n+    checkArgument(delay > 0, \"delay should be positive\");\n+    checkNotNull(unit, \"unit\");\n+    return\n+        new BackoffPolicy() {\n+          @Override\n+          public long nextBackoffNanos() {\n+            return TimeUnit.NANOSECONDS.convert(delay, unit);\n+          }\n+        };\n+  }\n+\n+  private static class FakeBackoffProvider implements BackoffPolicy.Provider {\n+\n+    private BackoffPolicy nextPolicy = createBackoffPolicy(100, TimeUnit.MILLISECONDS);\n+\n+    @Override\n+    public BackoffPolicy get() {\n+      return nextPolicy;\n+    }\n+  }\n+\n+  private static class TestLoadBalancerProvider extends LoadBalancerProvider {\n+\n+    @Override\n+    public boolean isAvailable() {\n+      return true;\n+    }\n+\n+    @Override\n+    public int getPriority() {\n+      return 0;\n+    }\n+\n+    @Override\n+    public String getPolicyName() {\n+      return null;\n+    }\n+\n+    @Override\n+    public LoadBalancer newLoadBalancer(final Helper helper) {\n+      return new LoadBalancer() {\n+\n+        @Override\n+        public void handleResolvedAddresses(ResolvedAddresses resolvedAddresses) {\n+          // TODO: make the picker accessible\n+          helper.updateBalancingState(ConnectivityState.READY, mock(SubchannelPicker.class));\n+        }\n+\n+        @Override\n+        public void handleNameResolutionError(final Status error) {\n+          class ErrorPicker extends SubchannelPicker {\n+            @Override\n+            public PickResult pickSubchannel(PickSubchannelArgs args) {\n+              return PickResult.withError(error);\n+            }\n+          }\n+\n+          helper.updateBalancingState(ConnectivityState.TRANSIENT_FAILURE, new ErrorPicker());\n+        }\n+\n+        @Override\n+        public void shutdown() {\n+        }\n+      };\n+    }\n+  }\n+\n+  private static final class StaticFixedDelayRlsServerImpl\n+      extends RouteLookupServiceGrpc.RouteLookupServiceImplBase {\n+\n+    private static final Converter<io.grpc.lookup.v1.RouteLookupRequest, RouteLookupRequest>\n+        REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter();\n+    private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+        RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+    private final long responseDelayNano;\n+    private final ScheduledExecutorService scheduledExecutorService;\n+\n+    private Map<RouteLookupRequest, RouteLookupResponse> lookupTable = ImmutableMap.of();\n+\n+    public StaticFixedDelayRlsServerImpl(\n+        long responseDelayNano, ScheduledExecutorService scheduledExecutorService) {\n+      checkArgument(responseDelayNano > 0, \"delay must be positive\");\n+      this.responseDelayNano = responseDelayNano;\n+      this.scheduledExecutorService =\n+          checkNotNull(scheduledExecutorService, \"scheduledExecutorService\");\n+    }\n+\n+    private void setLookupTable(Map<RouteLookupRequest, RouteLookupResponse> lookupTable) {\n+      this.lookupTable = checkNotNull(lookupTable, \"lookupTable\");\n+    }\n+\n+    @Override\n+    public void routeLookup(final io.grpc.lookup.v1.RouteLookupRequest request,\n+        final StreamObserver<io.grpc.lookup.v1.RouteLookupResponse> responseObserver) {\n+      ScheduledFuture<?> unused =\n+          scheduledExecutorService.schedule(\n+              new Runnable() {\n+                @Override\n+                public void run() {\n+                  RouteLookupResponse response =\n+                      lookupTable.get(REQUEST_CONVERTER.convert(request));\n+                  if (response == null) {\n+                    responseObserver.onError(new RuntimeException(\"not found\"));\n+                  } else {\n+                    responseObserver.onNext(RESPONSE_CONVERTER.convert(response));\n+                    responseObserver.onCompleted();\n+                  }\n+                }\n+              }, responseDelayNano, TimeUnit.NANOSECONDS);\n+    }\n+  }\n+\n+  private class FakeHelper extends Helper {\n+\n+    @Override\n+    public ManagedChannel createResolvingOobChannel(String target) {\n+      try {\n+        grpcCleanupRule.register(\n+            InProcessServerBuilder.forName(target)\n+                .addService(rlsServerImpl)\n+                .directExecutor()\n+                .build()\n+                .start());\n+      } catch (IOException e) {\n+        throw new RuntimeException(\"cannot create server: \" + target, e);\n+      }\n+      return InProcessChannelBuilder.forName(target).directExecutor().build();\n+    }\n+\n+    @Override\n+    public ManagedChannel createOobChannel(EquivalentAddressGroup eag, String authority) {\n+      throw new UnsupportedOperationException();\n+    }\n+\n+    @Override\n+    public void updateBalancingState(\n+        @Nonnull ConnectivityState newState, @Nonnull SubchannelPicker newPicker) {\n+      // no-op\n+    }\n+\n+    @Override\n+    @SuppressWarnings(\"deprecation\")  // this method is deprecated in the abstract class", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2"}, "originalPosition": 485}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NDcxOQ==", "bodyText": "mock(Helper.class, AdditionalAnswers.delegatesTo(new FakeHelper())); and FakeHelper and some other inner classes can be final.", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418664719", "createdAt": "2020-05-01T18:08:03Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/test/java/io/grpc/rls/internal/CachingRlsLbClientTest.java", "diffHunk": "@@ -0,0 +1,520 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.truth.Truth.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.CALLS_REAL_METHODS;\n+import static org.mockito.Mockito.inOrder;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.never;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import io.grpc.Attributes;\n+import io.grpc.ConnectivityState;\n+import io.grpc.EquivalentAddressGroup;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.NameResolver.Factory;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.inprocess.InProcessChannelBuilder;\n+import io.grpc.inprocess.InProcessServerBuilder;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.rls.internal.CachingRlsLbClient.CacheEntry;\n+import io.grpc.rls.internal.CachingRlsLbClient.CachedRouteLookupResponse;\n+import io.grpc.rls.internal.CachingRlsLbClient.RlsPicker;\n+import io.grpc.rls.internal.DoNotUseDirectScheduledExecutorService.FakeTimeProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.GrpcKeyBuilder;\n+import io.grpc.rls.internal.RlsProtoData.GrpcKeyBuilder.Name;\n+import io.grpc.rls.internal.RlsProtoData.NameMatcher;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.stub.StreamObserver;\n+import io.grpc.testing.GrpcCleanupRule;\n+import java.io.IOException;\n+import java.lang.Thread.UncaughtExceptionHandler;\n+import java.net.SocketAddress;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nonnull;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+import org.mockito.AdditionalAnswers;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.InOrder;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+@RunWith(JUnit4.class)\n+public class CachingRlsLbClientTest {\n+\n+  private static final RouteLookupConfig ROUTE_LOOKUP_CONFIG = getRouteLookupConfig();\n+  private static final int SERVER_LATENCY_MILLIS = 10;\n+\n+  @Rule\n+  public final MockitoRule mocks = MockitoJUnit.rule();\n+  @Rule\n+  public final GrpcCleanupRule grpcCleanupRule = new GrpcCleanupRule();\n+\n+  @Mock\n+  private EvictionListener<RouteLookupRequest, CacheEntry> evictionListener;\n+  @Mock\n+  private SocketAddress socketAddress;\n+\n+  private final SynchronizationContext syncContext =\n+      new SynchronizationContext(new UncaughtExceptionHandler() {\n+        @Override\n+        public void uncaughtException(Thread t, Throwable e) {\n+          throw new RuntimeException(e);\n+        }\n+      });\n+  private final FakeBackoffProvider fakeBackoffProvider = new FakeBackoffProvider();\n+  private final ResolvedAddressFactory resolvedAddressFactory =\n+      new ChildLbResolvedAddressFactory(\n+          ImmutableList.of(new EquivalentAddressGroup(socketAddress)), Attributes.EMPTY);\n+  private final TestLoadBalancerProvider lbProvider = new TestLoadBalancerProvider();\n+  private final DoNotUseDirectScheduledExecutorService fakeScheduledExecutorService =\n+      mock(DoNotUseDirectScheduledExecutorService.class, CALLS_REAL_METHODS);\n+  private final FakeTimeProvider fakeTimeProvider =\n+      fakeScheduledExecutorService.getFakeTimeProvider();\n+  private final StaticFixedDelayRlsServerImpl rlsServerImpl =\n+      new StaticFixedDelayRlsServerImpl(\n+          TimeUnit.MILLISECONDS.toNanos(SERVER_LATENCY_MILLIS), fakeScheduledExecutorService);\n+  private final ChildLoadBalancingPolicy childLbPolicy =\n+      new ChildLoadBalancingPolicy(\"target\", Collections.<String, Object>emptyMap(), lbProvider);\n+  private final Helper helper =\n+      mock(FakeHelper.class, AdditionalAnswers.delegatesTo(new FakeHelper()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NTk5Mg==", "bodyText": "Can you and synchronizationContext.throwIfNotInThisSynchronizationContext() here?", "url": "https://github.com/grpc/grpc-java/pull/6966#discussion_r418665992", "createdAt": "2020-05-01T18:10:50Z", "author": {"login": "dapengzhang0"}, "path": "rls/src/main/java/io/grpc/rls/internal/CachingRlsLbClient.java", "diffHunk": "@@ -0,0 +1,962 @@\n+/*\n+ * Copyright 2020 The gRPC Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.grpc.rls.internal;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.base.Preconditions.checkState;\n+\n+import com.google.common.base.Converter;\n+import com.google.common.base.MoreObjects;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import com.google.common.util.concurrent.SettableFuture;\n+import io.grpc.ConnectivityState;\n+import io.grpc.LoadBalancer;\n+import io.grpc.LoadBalancer.Helper;\n+import io.grpc.LoadBalancer.PickResult;\n+import io.grpc.LoadBalancer.PickSubchannelArgs;\n+import io.grpc.LoadBalancer.ResolvedAddresses;\n+import io.grpc.LoadBalancer.SubchannelPicker;\n+import io.grpc.LoadBalancerProvider;\n+import io.grpc.ManagedChannel;\n+import io.grpc.Metadata;\n+import io.grpc.NameResolver.ConfigOrError;\n+import io.grpc.Status;\n+import io.grpc.SynchronizationContext;\n+import io.grpc.SynchronizationContext.ScheduledHandle;\n+import io.grpc.internal.BackoffPolicy;\n+import io.grpc.internal.ExponentialBackoffPolicy;\n+import io.grpc.internal.PickSubchannelArgsImpl;\n+import io.grpc.internal.TimeProvider;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc;\n+import io.grpc.lookup.v1.RouteLookupServiceGrpc.RouteLookupServiceStub;\n+import io.grpc.rls.internal.ChildLoadBalancerHelper.ChildLoadBalancerHelperProvider;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLbStatusListener;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildLoadBalancingPolicy;\n+import io.grpc.rls.internal.LbPolicyConfiguration.ChildPolicyWrapper;\n+import io.grpc.rls.internal.LbPolicyConfiguration.RefCountedChildPolicyWrapperFactory;\n+import io.grpc.rls.internal.LruCache.EvictionListener;\n+import io.grpc.rls.internal.LruCache.EvictionType;\n+import io.grpc.rls.internal.RlsProtoConverters.RouteLookupResponseConverter;\n+import io.grpc.rls.internal.RlsProtoData.RequestProcessingStrategy;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupConfig;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupRequest;\n+import io.grpc.rls.internal.RlsProtoData.RouteLookupResponse;\n+import io.grpc.rls.internal.Throttler.ThrottledException;\n+import io.grpc.stub.StreamObserver;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.CheckReturnValue;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+\n+/**\n+ * A CachingRlsLbClient is a core implementation of RLS loadbalancer supports dynamic request\n+ * routing by fetching the decision from route lookup server. Every single request is routed by\n+ * the server's decision. To reduce the performance penalty, {@link LruCache} is used.\n+ */\n+@ThreadSafe\n+public final class CachingRlsLbClient {\n+\n+  private static final Converter<RouteLookupRequest, io.grpc.lookup.v1.RouteLookupRequest>\n+      REQUEST_CONVERTER = new RlsProtoConverters.RouteLookupRequestConverter().reverse();\n+  private static final Converter<RouteLookupResponse, io.grpc.lookup.v1.RouteLookupResponse>\n+      RESPONSE_CONVERTER = new RouteLookupResponseConverter().reverse();\n+\n+  // All cache status changes (pending, backoff, success) must be under this lock\n+  private final Object lock = new Object();\n+  // LRU cache based on access order (BACKOFF and actual data will be here)\n+  @GuardedBy(\"lock\")\n+  private final LinkedHashLruCache<RouteLookupRequest, CacheEntry> linkedHashLruCache;\n+  // any RPC on the fly will cached in this map\n+  @GuardedBy(\"lock\")\n+  private final Map<RouteLookupRequest, PendingCacheEntry> pendingCallCache = new HashMap<>();\n+\n+  private final SynchronizationContext synchronizationContext;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final TimeProvider timeProvider;\n+  private final Throttler throttler;\n+\n+  private final LbPolicyConfiguration lbPolicyConfig;\n+  private final BackoffPolicy.Provider backoffProvider;\n+  private final long maxAgeNanos;\n+  private final long staleAgeNanos;\n+  private final long callTimeoutNanos;\n+\n+  private final Helper helper;\n+  private final ManagedChannel rlsChannel;\n+  private final RouteLookupServiceStub rlsStub;\n+  private final RlsPicker rlsPicker;\n+  private final ResolvedAddressFactory childLbResolvedAddressFactory;\n+  private final RefCountedChildPolicyWrapperFactory refCountedChildPolicyWrapperFactory;\n+\n+  private CachingRlsLbClient(Builder builder) {\n+    helper = checkNotNull(builder.helper, \"helper\");\n+    scheduledExecutorService = helper.getScheduledExecutorService();\n+    synchronizationContext = helper.getSynchronizationContext();\n+    lbPolicyConfig = checkNotNull(builder.lbPolicyConfig, \"lbPolicyConfig\");\n+    RouteLookupConfig rlsConfig = lbPolicyConfig.getRouteLookupConfig();\n+    maxAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getMaxAgeInMillis());\n+    staleAgeNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getStaleAgeInMillis());\n+    callTimeoutNanos = TimeUnit.MILLISECONDS.toNanos(rlsConfig.getLookupServiceTimeoutInMillis());\n+    timeProvider = checkNotNull(builder.timeProvider, \"timeProvider\");\n+    throttler = checkNotNull(builder.throttler, \"throttler\");\n+    linkedHashLruCache =\n+        new RlsAsyncLruCache(\n+            rlsConfig.getCacheSizeBytes(),\n+            builder.evictionListener,\n+            scheduledExecutorService,\n+            timeProvider);\n+    RlsRequestFactory requestFactory = new RlsRequestFactory(lbPolicyConfig.getRouteLookupConfig());\n+    rlsPicker = new RlsPicker(requestFactory);\n+    rlsChannel = helper.createResolvingOobChannel(rlsConfig.getLookupService());\n+    helper.updateBalancingState(ConnectivityState.CONNECTING, rlsPicker);\n+    rlsStub = RouteLookupServiceGrpc.newStub(rlsChannel);\n+    childLbResolvedAddressFactory =\n+        checkNotNull(builder.resolvedAddressFactory, \"resolvedAddressFactory\");\n+    backoffProvider = builder.backoffProvider;\n+    ChildLoadBalancerHelperProvider childLbHelperProvider =\n+        new ChildLoadBalancerHelperProvider(helper, new SubchannelStateManagerImpl(), rlsPicker);\n+    if (rlsConfig.getRequestProcessingStrategy()\n+        == RequestProcessingStrategy.SYNC_LOOKUP_CLIENT_SEES_ERROR) {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(\n+              childLbHelperProvider, new BackoffRefreshListener());\n+    } else {\n+      refCountedChildPolicyWrapperFactory =\n+          new RefCountedChildPolicyWrapperFactory(childLbHelperProvider, null);\n+    }\n+  }\n+\n+  @CheckReturnValue\n+  private ListenableFuture<RouteLookupResponse> asyncRlsCall(RouteLookupRequest request) {\n+    final SettableFuture<RouteLookupResponse> response = SettableFuture.create();\n+    if (throttler.shouldThrottle()) {\n+      response.setException(new ThrottledException());\n+      return response;\n+    }\n+    rlsStub.withDeadlineAfter(callTimeoutNanos, TimeUnit.NANOSECONDS)\n+        .routeLookup(\n+            REQUEST_CONVERTER.convert(request),\n+            new StreamObserver<io.grpc.lookup.v1.RouteLookupResponse>() {\n+              @Override\n+              public void onNext(io.grpc.lookup.v1.RouteLookupResponse value) {\n+                response.set(RESPONSE_CONVERTER.reverse().convert(value));\n+              }\n+\n+              @Override\n+              public void onError(Throwable t) {\n+                response.setException(t);\n+                throttler.registerBackendResponse(false);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                throttler.registerBackendResponse(true);\n+              }\n+            });\n+    return response;\n+  }\n+\n+  /**\n+   * Returns async response of the {@code request}. The returned value can be in 3 different states;\n+   * cached, pending and backed-off due to error. The result remains same even if the status is\n+   * changed after the return.\n+   */\n+  @CheckReturnValue\n+  public final CachedRouteLookupResponse get(final RouteLookupRequest request) {\n+    synchronized (lock) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ad53a5bd1cc6b7816f7f12a21f5fd04751362b2"}, "originalPosition": 184}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2cd0d1ff781dfd8fbaaf376e06f7a918bd5ad688", "author": {"user": {"login": "creamsoup", "name": "Jihun Cho"}}, "url": "https://github.com/grpc/grpc-java/commit/2cd0d1ff781dfd8fbaaf376e06f7a918bd5ad688", "committedDate": "2020-05-01T18:46:08Z", "message": "check syncContext in get, make the tests workaround this"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4350, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}