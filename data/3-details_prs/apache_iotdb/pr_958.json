{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk1NDU2Mzc5", "number": 958, "title": "[IOTDB-351] Serialize raft log", "bodyText": "Serialize raft log in disk", "createdAt": "2020-03-30T07:22:19Z", "url": "https://github.com/apache/iotdb/pull/958", "merged": true, "mergeCommit": {"oid": "32157760f2a7f173ee11cbedb6e70c7121c91709"}, "closed": true, "closedAt": "2020-04-14T02:25:20Z", "author": {"login": "SilverNarcissus"}, "timelineItems": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcLDUqaAH2gAyMzk1NDU2Mzc5OmI1NGJmNzRiZDhmNjVhZDE5MjI4YWY1MjUxOTc3MThiZTg5YzMxNmU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcXZ0fXAFqTM5MjU1NjU4Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "b54bf74bd8f65ad19228af525197718be89c316e", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/b54bf74bd8f65ad19228af525197718be89c316e", "committedDate": "2020-03-06T17:11:32Z", "message": "add serializable raft log component"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9478e69875e2599a1d5f89b0420250d71c1b4fb9", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/9478e69875e2599a1d5f89b0420250d71c1b4fb9", "committedDate": "2020-03-07T09:06:15Z", "message": "fix bugs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ccc55df96b080b5070fa4f0d6b8afe87c58f73c7", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/ccc55df96b080b5070fa4f0d6b8afe87c58f73c7", "committedDate": "2020-03-07T10:53:08Z", "message": "add log view tool"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd786590ca1b9f162a064d10c07b4231b1da92dd", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/fd786590ca1b9f162a064d10c07b4231b1da92dd", "committedDate": "2020-03-12T12:05:34Z", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00898a7fccdf9fcd9d351351aae452cc96d18b34", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/00898a7fccdf9fcd9d351351aae452cc96d18b34", "committedDate": "2020-03-16T12:27:35Z", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4f88eac8e287c044d3799403fbcbacd71fa406f", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/e4f88eac8e287c044d3799403fbcbacd71fa406f", "committedDate": "2020-03-16T12:28:14Z", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6579104139e98a7f9cdf25b65fdf4dca13800b77", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/6579104139e98a7f9cdf25b65fdf4dca13800b77", "committedDate": "2020-03-18T08:42:25Z", "message": "add truncate logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82076dd13c8cfb009f1585ccf71023bbaecc7206", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/82076dd13c8cfb009f1585ccf71023bbaecc7206", "committedDate": "2020-03-24T04:03:49Z", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log\n\n# Conflicts:\n#\tcluster/src/test/java/org/apache/iotdb/cluster/common/TestUtils.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b21730ee75ea529e4d872be639b2f1a4f0cc1bb3", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/b21730ee75ea529e4d872be639b2f1a4f0cc1bb3", "committedDate": "2020-03-24T06:31:43Z", "message": "add log batch append"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d269c65b54c380fa8772e8f3f18d9a0d7f3b17c0", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/d269c65b54c380fa8772e8f3f18d9a0d7f3b17c0", "committedDate": "2020-03-24T06:49:52Z", "message": "fix bugs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea9bd6646faa30580a939c58894f0b448aae90f3", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/ea9bd6646faa30580a939c58894f0b448aae90f3", "committedDate": "2020-03-26T15:25:47Z", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log\n\n# Conflicts:\n#\tcluster/src/main/java/org/apache/iotdb/cluster/log/manage/FilePartitionedSnapshotLogManager.java\n#\tcluster/src/main/java/org/apache/iotdb/cluster/log/manage/MemoryLogManager.java\n#\tcluster/src/main/java/org/apache/iotdb/cluster/log/manage/MetaSingleSnapshotLogManager.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "10d4757bbdfdd3fe7731a2800fdc1c086b53e8a5", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/10d4757bbdfdd3fe7731a2800fdc1c086b53e8a5", "committedDate": "2020-03-30T03:35:03Z", "message": "Add license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "737c944e2959465cb77f92319d587faff2c8979f", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/737c944e2959465cb77f92319d587faff2c8979f", "committedDate": "2020-03-31T01:12:21Z", "message": "Add license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b52ed3255d2293f3547124d69d3b81075ee50e8d", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/b52ed3255d2293f3547124d69d3b81075ee50e8d", "committedDate": "2020-03-31T01:17:55Z", "message": "add license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "committedDate": "2020-03-31T05:38:58Z", "message": "add license"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg1MjE0OTg0", "url": "https://github.com/apache/iotdb/pull/958#pullrequestreview-385214984", "createdAt": "2020-04-01T01:46:10Z", "commit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMTo0NjoxMFrOF-uCIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMjo0MzozNlrOF-u61A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMDI0MA==", "bodyText": "Maybe you can use the @TestOnly annotation, so it will provide some convenience if we want to track all test methods.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401310240", "createdAt": "2020-04-01T01:46:10Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/MemoryLogManager.java", "diffHunk": "@@ -159,21 +181,32 @@ public boolean logValid(long logIndex) {\n \n   @Override\n   public Log getLastLog() {\n-    return logBuffer.isEmpty()? null : logBuffer.get(logBuffer.size() - 1);\n+    return logBuffer.isEmpty() ? null : logBuffer.get(logBuffer.size() - 1);\n   }\n \n   @Override\n   public LogApplier getApplier() {\n     return logApplier;\n   }\n \n-  @Override\n-  public void setLastLogId(long lastLogId) {\n-    this.lastLogId = lastLogId;\n+  public void removeFromHead(int length) {\n+    logBuffer.subList(0, length).clear();\n   }\n \n-  @Override\n-  public void setLastLogTerm(long lastLogTerm) {\n-    this.lastLogTerm = lastLogTerm;\n+  /**\n+   * only for test\n+   */\n+  public LogManagerMeta getMeta() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMTcwMg==", "bodyText": "Please supplement the unit of the configuration, is that the number of entries, byte, KB or something else?", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401311702", "createdAt": "2020-04-01T01:52:06Z", "author": {"login": "jt2594838"}, "path": "cluster/src/assembly/resources/conf/iotdb-cluster.properties", "diffHunk": "@@ -47,3 +47,6 @@ REPLICA_NUM=3\n # connection time out (ms) among raft nodes\n CONNECTION_TIME_OUT_MS=20000\n \n+# when the logs size larger than this, we actually delete snapshoted logs\n+MAX_REMOVED_LOG_SIZE=134217728", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMjIxMQ==", "bodyText": "This name seems unused.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401312211", "createdAt": "2020-04-01T01:53:55Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMjY0Ng==", "bodyText": "The second should be metaFile.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401312646", "createdAt": "2020-04-01T01:55:31Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMjczMA==", "bodyText": "Use log, the same as below.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401312730", "createdAt": "2020-04-01T01:55:52Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMzI5Mw==", "bodyText": "Why is metaOutputStream also in an append mode?", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401313293", "createdAt": "2020-04-01T01:58:18Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMzgzMQ==", "bodyText": "I think \"removeLast\" is no longer used, you may remove it too.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401313831", "createdAt": "2020-04-01T02:00:24Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/LogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.util.List;\n+import org.apache.iotdb.cluster.log.Log;\n+\n+public interface LogDequeSerializer {\n+\n+  /**\n+   * append a log\n+   * @param log appended log\n+   */\n+  public void addLast(Log log, LogManagerMeta meta);\n+\n+  /**\n+   * remove last log\n+   * @param meta metadata\n+   */\n+  public void removeLast(LogManagerMeta meta);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxNzMxMw==", "bodyText": "Since you have recorded the sizes of each log, you can surely the total size of removed logs, why not just use \"FileInputStream.skip()\" (be sure to check the actually skipped bytes)?", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401317313", "createdAt": "2020-04-01T02:14:12Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk\n+    try {\n+      logOutputStream.getChannel().truncate(logFile.length() - size);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      deleteRemovedLog();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public List<Log> recoverLog() {\n+    if (meta == null) {\n+      recoverMeta();\n+    }\n+\n+    if (!logFile.exists()) {\n+      return new ArrayList<>();\n+    }\n+\n+    List<Log> result = new ArrayList<>();\n+    long count = 0;\n+    try {\n+      FileInputStream logReader = new FileInputStream(logFile);\n+      FileChannel logChannel = logReader.getChannel();\n+      while (logChannel.position() < logFile.length()) {\n+        // actual log\n+        if (count >= firstLogPosition) {\n+          Log log = readLog(logReader, false);\n+          result.add(log);\n+        }\n+        // removed log, skip\n+        else {\n+          readLog(logReader, true);\n+        }\n+        count++;\n+      }\n+      logReader.close();\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    return result;\n+  }\n+\n+  // read single log\n+  private Log readLog(FileInputStream logReader, boolean canSkip) throws IOException {\n+    int logSize = ReadWriteIOUtils.readInt(logReader);\n+    int totalSize = Integer.BYTES + logSize;\n+\n+    if (canSkip) {\n+      logReader.skip(logSize);\n+      removedLogSize += totalSize;\n+      return null;\n+    }\n+\n+    Log log = null;\n+\n+    try {\n+      log = parser.parse(ByteBuffer.wrap(ReadWriteIOUtils.readBytes(logReader, logSize)));\n+    } catch (UnknownLogTypeException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+\n+    return log;\n+  }\n+\n+  @Override\n+  public LogManagerMeta recoverMeta() {\n+    if (meta == null && metaFile.exists() && metaFile.length() > 0) {\n+      try {\n+        FileInputStream metaReader = new FileInputStream(metaFile);\n+        firstLogPosition = ReadWriteIOUtils.readLong(metaReader);\n+        meta = LogManagerMeta.deserialize(\n+            ByteBuffer.wrap(ReadWriteIOUtils.readBytesWithSelfDescriptionLength(metaReader)));\n+        metaReader.close();\n+      } catch (IOException e) {\n+        e.printStackTrace();\n+      }\n+    }\n+\n+    return meta;\n+  }\n+\n+  @Override\n+  public void serializeMeta(LogManagerMeta meta) {\n+    try {\n+      metaOutputStream.getChannel().truncate(0);\n+      ReadWriteIOUtils.write(firstLogPosition, metaOutputStream);\n+      ReadWriteIOUtils.write(meta.serialize(), metaOutputStream);\n+\n+      this.meta = meta;\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      logOutputStream.close();\n+      metaOutputStream.close();\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  // actually delete removed logs, this may take lots of times\n+  // TODO : use an async method to delete file\n+  private void deleteRemovedLog() {\n+    try {\n+      FileInputStream reader = new FileInputStream(logFile);\n+      // skip removed file\n+      for (int i = 0; i < firstLogPosition; i++) {\n+        readLog(reader, true);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 277}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxNzgwMQ==", "bodyText": "It is a little misleading to use the word \"total\" and the operator \"+=\", it seems that you are adding some things up, but actually there is only one item.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401317801", "createdAt": "2020-04-01T02:16:28Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxODI4MQ==", "bodyText": "I do not believe this is \"write into disk\".", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401318281", "createdAt": "2020-04-01T02:18:26Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyMDI0OQ==", "bodyText": "Are there any countermeasures against the situation that the logs are removed but the meta is not serialized?", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401320249", "createdAt": "2020-04-01T02:25:56Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk\n+    try {\n+      logOutputStream.getChannel().truncate(logFile.length() - size);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      deleteRemovedLog();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyMTAzNg==", "bodyText": "I think if you can also save the file position of the first log (just another 8 bytes in the meta), it will be much easier to skip the removed logs.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401321036", "createdAt": "2020-04-01T02:28:51Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk\n+    try {\n+      logOutputStream.getChannel().truncate(logFile.length() - size);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      deleteRemovedLog();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public List<Log> recoverLog() {\n+    if (meta == null) {\n+      recoverMeta();\n+    }\n+\n+    if (!logFile.exists()) {\n+      return new ArrayList<>();\n+    }\n+\n+    List<Log> result = new ArrayList<>();\n+    long count = 0;\n+    try {\n+      FileInputStream logReader = new FileInputStream(logFile);\n+      FileChannel logChannel = logReader.getChannel();\n+      while (logChannel.position() < logFile.length()) {\n+        // actual log\n+        if (count >= firstLogPosition) {\n+          Log log = readLog(logReader, false);\n+          result.add(log);\n+        }\n+        // removed log, skip\n+        else {\n+          readLog(logReader, true);\n+        }\n+        count++;\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 195}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyNDAzMQ==", "bodyText": "There is a much easier way to do this, it is FileChannel.transferTo(), you may have a look.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401324031", "createdAt": "2020-04-01T02:40:25Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk\n+    try {\n+      logOutputStream.getChannel().truncate(logFile.length() - size);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      deleteRemovedLog();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public List<Log> recoverLog() {\n+    if (meta == null) {\n+      recoverMeta();\n+    }\n+\n+    if (!logFile.exists()) {\n+      return new ArrayList<>();\n+    }\n+\n+    List<Log> result = new ArrayList<>();\n+    long count = 0;\n+    try {\n+      FileInputStream logReader = new FileInputStream(logFile);\n+      FileChannel logChannel = logReader.getChannel();\n+      while (logChannel.position() < logFile.length()) {\n+        // actual log\n+        if (count >= firstLogPosition) {\n+          Log log = readLog(logReader, false);\n+          result.add(log);\n+        }\n+        // removed log, skip\n+        else {\n+          readLog(logReader, true);\n+        }\n+        count++;\n+      }\n+      logReader.close();\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    return result;\n+  }\n+\n+  // read single log\n+  private Log readLog(FileInputStream logReader, boolean canSkip) throws IOException {\n+    int logSize = ReadWriteIOUtils.readInt(logReader);\n+    int totalSize = Integer.BYTES + logSize;\n+\n+    if (canSkip) {\n+      logReader.skip(logSize);\n+      removedLogSize += totalSize;\n+      return null;\n+    }\n+\n+    Log log = null;\n+\n+    try {\n+      log = parser.parse(ByteBuffer.wrap(ReadWriteIOUtils.readBytes(logReader, logSize)));\n+    } catch (UnknownLogTypeException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+\n+    return log;\n+  }\n+\n+  @Override\n+  public LogManagerMeta recoverMeta() {\n+    if (meta == null && metaFile.exists() && metaFile.length() > 0) {\n+      try {\n+        FileInputStream metaReader = new FileInputStream(metaFile);\n+        firstLogPosition = ReadWriteIOUtils.readLong(metaReader);\n+        meta = LogManagerMeta.deserialize(\n+            ByteBuffer.wrap(ReadWriteIOUtils.readBytesWithSelfDescriptionLength(metaReader)));\n+        metaReader.close();\n+      } catch (IOException e) {\n+        e.printStackTrace();\n+      }\n+    }\n+\n+    return meta;\n+  }\n+\n+  @Override\n+  public void serializeMeta(LogManagerMeta meta) {\n+    try {\n+      metaOutputStream.getChannel().truncate(0);\n+      ReadWriteIOUtils.write(firstLogPosition, metaOutputStream);\n+      ReadWriteIOUtils.write(meta.serialize(), metaOutputStream);\n+\n+      this.meta = meta;\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      logOutputStream.close();\n+      metaOutputStream.close();\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  // actually delete removed logs, this may take lots of times\n+  // TODO : use an async method to delete file\n+  private void deleteRemovedLog() {\n+    try {\n+      FileInputStream reader = new FileInputStream(logFile);\n+      // skip removed file\n+      for (int i = 0; i < firstLogPosition; i++) {\n+        readLog(reader, true);\n+      }\n+\n+      // begin to write\n+      File tempLogFile = SystemFileFactory.INSTANCE\n+          .getFile(\n+              IoTDBDescriptor.getInstance().getConfig().getSystemDir() + File.separator + \"raftLog\"\n+                  + File.separator + \"logData.temp\");\n+\n+      logOutputStream.close();\n+      logOutputStream = new FileOutputStream(tempLogFile);\n+      int blockSize = 4096;\n+      long curPosition = reader.getChannel().position();\n+      while (curPosition < logFile.length()) {\n+        long size = Math.min(blockSize, logFile.length() - curPosition);\n+        logOutputStream.write(ReadWriteIOUtils.readBytes(reader, (int) size));\n+        curPosition = reader.getChannel().position();\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyNDc1Ng==", "bodyText": "Why are these commented\uff1f", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401324756", "createdAt": "2020-04-01T02:43:36Z", "author": {"login": "jt2594838"}, "path": "cluster/src/test/java/org/apache/iotdb/cluster/query/ClusterAggregateExecutorTest.java", "diffHunk": "@@ -29,40 +47,40 @@\n \n   private ClusterAggregateExecutor executor;\n \n-  @Test\n-  public void testNoFilter()\n-      throws QueryProcessException, StorageEngineException, IOException {\n-    AggregationPlan plan = new AggregationPlan();\n-    List<Path> paths = Arrays.asList(\n-        new Path(TestUtils.getTestSeries(0, 0)),\n-        new Path(TestUtils.getTestSeries(0, 1)),\n-        new Path(TestUtils.getTestSeries(0, 2)),\n-        new Path(TestUtils.getTestSeries(0, 3)),\n-        new Path(TestUtils.getTestSeries(0, 4)));\n-    List<TSDataType> dataTypes = Arrays.asList(TSDataType.DOUBLE, TSDataType.DOUBLE,\n-        TSDataType.DOUBLE, TSDataType.DOUBLE, TSDataType.DOUBLE);\n-    List<String> aggregations = Arrays.asList(SQLConstant.MIN_TIME, SQLConstant.MAX_VALUE,\n-        SQLConstant.AVG, SQLConstant.COUNT, SQLConstant.SUM);\n-    plan.setPaths(paths);\n-    plan.setDeduplicatedPaths(paths);\n-    plan.setDataTypes(dataTypes);\n-    plan.setDeduplicatedDataTypes(dataTypes);\n-    plan.setAggregations(aggregations);\n-    plan.setDeduplicatedAggregations(aggregations);\n-\n-    QueryContext context = new RemoteQueryContext(QueryResourceManager.getInstance().assignQueryId(true));\n-    executor = new ClusterAggregateExecutor(plan, testMetaMember);\n-    QueryDataSet queryDataSet = executor.executeWithoutValueFilter(context);\n-    assertTrue(queryDataSet.hasNext());\n-    RowRecord record = queryDataSet.next();\n-    List<Field> fields = record.getFields();\n-    assertEquals(5, fields.size());\n-    Object[] answers = new Object[] {0.0, 19.0, 9.5, 20.0, 190.0};\n-    for (int i = 0; i < 5; i++) {\n-      assertEquals((double)answers[i], Double.parseDouble(fields.get(i).toString()), 0.00001);\n-    }\n-    assertFalse(queryDataSet.hasNext());\n-  }\n+//  @Test\n+//  public void testNoFilter()\n+//      throws QueryProcessException, StorageEngineException, IOException {\n+//    AggregationPlan plan = new AggregationPlan();\n+//    List<Path> paths = Arrays.asList(\n+//        new Path(TestUtils.getTestSeries(0, 0)),\n+//        new Path(TestUtils.getTestSeries(0, 1)),\n+//        new Path(TestUtils.getTestSeries(0, 2)),\n+//        new Path(TestUtils.getTestSeries(0, 3)),\n+//        new Path(TestUtils.getTestSeries(0, 4)));\n+//    List<TSDataType> dataTypes = Arrays.asList(TSDataType.DOUBLE, TSDataType.DOUBLE,\n+//        TSDataType.DOUBLE, TSDataType.DOUBLE, TSDataType.DOUBLE);\n+//    List<String> aggregations = Arrays.asList(SQLConstant.MIN_TIME, SQLConstant.MAX_VALUE,\n+//        SQLConstant.AVG, SQLConstant.COUNT, SQLConstant.SUM);\n+//    plan.setPaths(paths);\n+//    plan.setDeduplicatedPaths(paths);\n+//    plan.setDataTypes(dataTypes);\n+//    plan.setDeduplicatedDataTypes(dataTypes);\n+//    plan.setAggregations(aggregations);\n+//    plan.setDeduplicatedAggregations(aggregations);\n+//\n+//    QueryContext context = new RemoteQueryContext(QueryResourceManager.getInstance().assignQueryId(true));\n+//    executor = new ClusterAggregateExecutor(plan, testMetaMember);\n+//    QueryDataSet queryDataSet = executor.executeWithoutValueFilter(context);\n+//    assertTrue(queryDataSet.hasNext());\n+//    RowRecord record = queryDataSet.next();\n+//    List<Field> fields = record.getFields();\n+//    assertEquals(5, fields.size());\n+//    Object[] answers = new Object[] {0.0, 19.0, 9.5, 20.0, 190.0};\n+//    for (int i = 0; i < 5; i++) {\n+//      assertEquals((double)answers[i], Double.parseDouble(fields.get(i).toString()), 0.00001);\n+//    }\n+//    assertFalse(queryDataSet.hasNext());\n+//  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33"}, "originalPosition": 102}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b6a79aeb4835282f312276e9e370138750a07df2", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/b6a79aeb4835282f312276e9e370138750a07df2", "committedDate": "2020-04-01T03:51:01Z", "message": "fix bugs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3ODE4NDQ5", "url": "https://github.com/apache/iotdb/pull/958#pullrequestreview-387818449", "createdAt": "2020-04-05T13:22:23Z", "commit": {"oid": "b6a79aeb4835282f312276e9e370138750a07df2"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNVQxMzoyMjoyNFrOGA_-BA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNVQxNDowNjowMVrOGBAS8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTI1Mg==", "bodyText": "The truncate function can be achieved at this level by taking advantage of the fact that the indexes of the raft logs must be contiguous, rather than being invoked from above. Truncate should be a function of append function rather than an interface.I'm sorry that I misdescribed it in a way that led to this implementation.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r403701252", "createdAt": "2020-04-05T13:22:24Z", "author": {"login": "LebronAl"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/DiskLogManager.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage;\n+\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogApplier;\n+import org.apache.iotdb.cluster.log.manage.serializable.LogDequeSerializer;\n+import org.apache.iotdb.cluster.log.manage.serializable.LogManagerMeta;\n+import org.apache.iotdb.cluster.log.manage.serializable.SyncLogDequeSerializer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public abstract class DiskLogManager extends MemoryLogManager {\n+  private static final Logger logger = LoggerFactory.getLogger(DiskLogManager.class);\n+\n+  // manage logs in disk\n+  private LogDequeSerializer logDequeSerializer;\n+\n+  private LogManagerMeta managerMeta = new LogManagerMeta();\n+\n+\n+  protected DiskLogManager(LogApplier logApplier) {\n+    super(logApplier);\n+    logDequeSerializer = new SyncLogDequeSerializer();\n+    recovery();\n+  }\n+\n+  private void recovery(){\n+    // recover meta\n+    LogManagerMeta logManagerMeta = logDequeSerializer.recoverMeta();\n+    if(logManagerMeta != null){\n+      setCommitLogIndex(logManagerMeta.getCommitLogIndex());\n+      setLastLogId(logManagerMeta.getLastLogId());\n+      setLastLogTerm(logManagerMeta.getLastLogTerm());\n+    }\n+    // recover logs\n+    setLogBuffer(logDequeSerializer.recoverLog());\n+  }\n+\n+\n+  @Override\n+  public long getLastLogIndex() {\n+    return lastLogId;\n+  }\n+\n+  @Override\n+  public long getLastLogTerm() {\n+    return lastLogTerm;\n+  }\n+\n+  @Override\n+  public void setLastLogTerm(long lastLogTerm) {\n+    this.lastLogTerm = lastLogTerm;\n+  }\n+\n+  @Override\n+  public long getCommitLogIndex() {\n+    return commitLogIndex;\n+  }\n+\n+  @Override\n+  public boolean appendLog(Log log) {\n+    boolean result = super.appendLog(log);\n+    if(result) {\n+      logDequeSerializer.addLast(log, getMeta());\n+    }\n+\n+    return result;\n+  }\n+\n+\n+  public void truncateLog(int count) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6a79aeb4835282f312276e9e370138750a07df2"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTgxNA==", "bodyText": "In fact, for the implementation of memoryLogManager, the lastLogTerm does not need to be maintained this way manually, because you can simply take the index of the last log in bufffer. If memoryLogManager could make this small change, here would be no need to serialize the meta data.This may require further discussion.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r403701814", "createdAt": "2020-04-05T13:27:07Z", "author": {"login": "LebronAl"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/DiskLogManager.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage;\n+\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogApplier;\n+import org.apache.iotdb.cluster.log.manage.serializable.LogDequeSerializer;\n+import org.apache.iotdb.cluster.log.manage.serializable.LogManagerMeta;\n+import org.apache.iotdb.cluster.log.manage.serializable.SyncLogDequeSerializer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public abstract class DiskLogManager extends MemoryLogManager {\n+  private static final Logger logger = LoggerFactory.getLogger(DiskLogManager.class);\n+\n+  // manage logs in disk\n+  private LogDequeSerializer logDequeSerializer;\n+\n+  private LogManagerMeta managerMeta = new LogManagerMeta();\n+\n+\n+  protected DiskLogManager(LogApplier logApplier) {\n+    super(logApplier);\n+    logDequeSerializer = new SyncLogDequeSerializer();\n+    recovery();\n+  }\n+\n+  private void recovery(){\n+    // recover meta\n+    LogManagerMeta logManagerMeta = logDequeSerializer.recoverMeta();\n+    if(logManagerMeta != null){\n+      setCommitLogIndex(logManagerMeta.getCommitLogIndex());\n+      setLastLogId(logManagerMeta.getLastLogId());\n+      setLastLogTerm(logManagerMeta.getLastLogTerm());\n+    }\n+    // recover logs\n+    setLogBuffer(logDequeSerializer.recoverLog());\n+  }\n+\n+\n+  @Override\n+  public long getLastLogIndex() {\n+    return lastLogId;\n+  }\n+\n+  @Override\n+  public long getLastLogTerm() {\n+    return lastLogTerm;\n+  }\n+\n+  @Override\n+  public void setLastLogTerm(long lastLogTerm) {\n+    this.lastLogTerm = lastLogTerm;\n+  }\n+\n+  @Override\n+  public long getCommitLogIndex() {\n+    return commitLogIndex;\n+  }\n+\n+  @Override\n+  public boolean appendLog(Log log) {\n+    boolean result = super.appendLog(log);\n+    if(result) {\n+      logDequeSerializer.addLast(log, getMeta());\n+    }\n+\n+    return result;\n+  }\n+\n+\n+  public void truncateLog(int count) {\n+    if (logBuffer.size() > count) {\n+      // do super truncate log\n+      // super.truncateLog();\n+      logDequeSerializer.truncateLog(count, getMeta());\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void commitLog(long maxLogIndex) {\n+    super.commitLog(maxLogIndex);\n+    // save commit log index\n+    serializeMeta();\n+  }\n+  \n+\n+  @Override\n+  public void setLastLogId(long lastLogId) {\n+    super.setLastLogId(lastLogId);\n+    // save meta\n+    serializeMeta();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6a79aeb4835282f312276e9e370138750a07df2"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNTkwMA==", "bodyText": "Actually, I don't find out the meaning of persisting lastLogId and lastLogTerm because both of them are available from the lastLog after recoverLog", "url": "https://github.com/apache/iotdb/pull/958#discussion_r403705900", "createdAt": "2020-04-05T13:59:55Z", "author": {"login": "LebronAl"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/LogManagerMeta.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.nio.ByteBuffer;\n+import org.apache.commons.lang3.builder.EqualsBuilder;\n+import org.apache.commons.lang3.builder.HashCodeBuilder;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+\n+public class LogManagerMeta {\n+\n+  private long commitLogIndex = -1;\n+  private long lastLogId = -1;\n+  private long lastLogTerm = -1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6a79aeb4835282f312276e9e370138750a07df2"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNjYwOQ==", "bodyText": "Sorry,I don't figure out the comment here. Is this the format of file\uff1f", "url": "https://github.com/apache/iotdb/pull/958#discussion_r403706609", "createdAt": "2020-04-05T14:06:01Z", "author": {"login": "LebronAl"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is size of log | log buffer meta in disk is firstLogPosition | size of log meta |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6a79aeb4835282f312276e9e370138750a07df2"}, "originalPosition": 75}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0cfa6c55b6d7474c9489fc1786cf7bf8e43f4542", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/0cfa6c55b6d7474c9489fc1786cf7bf8e43f4542", "committedDate": "2020-04-07T09:28:50Z", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log\n\n# Conflicts:\n#\tcluster/src/main/java/org/apache/iotdb/cluster/log/manage/MemoryLogManager.java"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MjE5MDY1", "url": "https://github.com/apache/iotdb/pull/958#pullrequestreview-389219065", "createdAt": "2020-04-07T15:14:28Z", "commit": {"oid": "0cfa6c55b6d7474c9489fc1786cf7bf8e43f4542"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MjE5ODY4", "url": "https://github.com/apache/iotdb/pull/958#pullrequestreview-389219868", "createdAt": "2020-04-07T15:15:18Z", "commit": {"oid": "0cfa6c55b6d7474c9489fc1786cf7bf8e43f4542"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MjQ4ODYw", "url": "https://github.com/apache/iotdb/pull/958#pullrequestreview-389248860", "createdAt": "2020-04-07T15:45:41Z", "commit": {"oid": "0cfa6c55b6d7474c9489fc1786cf7bf8e43f4542"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc4a65b967de1c7677513d059c8da0bb5d19c973", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/fc4a65b967de1c7677513d059c8da0bb5d19c973", "committedDate": "2020-04-08T11:03:38Z", "message": "use log list to store log data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a86f4b455ce72f1f0d5869c6499893e562ec07da", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/a86f4b455ce72f1f0d5869c6499893e562ec07da", "committedDate": "2020-04-09T01:09:08Z", "message": "fix bugs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3189d91a9f70a30bc88a24716cf74199f6f3fec", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/a3189d91a9f70a30bc88a24716cf74199f6f3fec", "committedDate": "2020-04-10T11:46:52Z", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log\n\n# Conflicts:\n#\tcluster/src/main/java/org/apache/iotdb/cluster/config/ClusterDescriptor.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1427a6ac0d03604235d0b0a2752e60d052d69f8", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/e1427a6ac0d03604235d0b0a2752e60d052d69f8", "committedDate": "2020-04-10T16:32:07Z", "message": "fix conflict solving"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNzUzODAx", "url": "https://github.com/apache/iotdb/pull/958#pullrequestreview-391753801", "createdAt": "2020-04-11T10:09:16Z", "commit": {"oid": "e1427a6ac0d03604235d0b0a2752e60d052d69f8"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMDowOToxNlrOGEMDWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMVQxMDoxNTo0M1rOGEMFnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NDk1NQ==", "bodyText": "I want to add a new function \u201cvoid append(List entries)\u201d to support batch append so that it can be easily embedded with new design.You can do it without thinking about efficiency, and you can rewrite it after I've merged it. Of course, it would be better to focus on efficiency in the first place.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407044955", "createdAt": "2020-04-11T10:09:16Z", "author": {"login": "LebronAl"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/LogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.util.List;\n+import org.apache.iotdb.cluster.log.Log;\n+\n+public interface LogDequeSerializer {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e1427a6ac0d03604235d0b0a2752e60d052d69f8"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NTUzNQ==", "bodyText": "I would like to add another function \"void removeCompactedEntries(long index)\" which means the persisted logs which index prior to index is able to be deleted.Of course, you can delete it lazily.But as we are not clear when to delete persisted raft logs so far,so you can implement it later.Just for reminding~", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407045535", "createdAt": "2020-04-11T10:15:43Z", "author": {"login": "LebronAl"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/LogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.util.List;\n+import org.apache.iotdb.cluster.log.Log;\n+\n+public interface LogDequeSerializer {\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NDk1NQ=="}, "originalCommit": {"oid": "e1427a6ac0d03604235d0b0a2752e60d052d69f8"}, "originalPosition": 25}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/3756f5cb9bd5965e40005ec0b02986242cbd53c3", "committedDate": "2020-04-12T04:38:54Z", "message": "add append log list"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxOTE5NTYx", "url": "https://github.com/apache/iotdb/pull/958#pullrequestreview-391919561", "createdAt": "2020-04-13T01:53:04Z", "commit": {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwMTo1MzowNFrOGEamkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwMjo0NzozN1rOGEbLCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4MzM0NA==", "bodyText": "In fact, each raft member will have its own logs as they are in different groups. So I cannot figure out how it works if you put them all in one folder.\nMy suggestion is: for each member, create a folder like systemDir + File.separator + \"raftLog\" + File.separator + headerNode.identifier + File.separator + \"logMeta\". Notice that only data groups use header, so you can replace headerNode.identifier with string \"meta\" for the meta group.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407283344", "createdAt": "2020-04-13T01:53:04Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4NTA0OA==", "bodyText": "Use logger.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407285048", "createdAt": "2020-04-13T02:03:21Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {\n+        size -= currentLogFile.length();\n+        try {\n+          currentLogOutputStream.close();\n+          // if system down before delete, we can use this to delete file during recovery\n+          maxAvailableTime = getFileTime(currentLogFile);\n+          serializeMeta(meta);\n+\n+          currentLogFile.delete();\n+          currentLogOutputStream = new FileOutputStream(getCurrentLogFile());\n+        } catch (IOException e) {\n+          e.printStackTrace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3"}, "originalPosition": 230}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4NjAzOA==", "bodyText": "I think you are opening the same file because you do not remove the deleted file from the list.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407286038", "createdAt": "2020-04-13T02:09:03Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {\n+        size -= currentLogFile.length();\n+        try {\n+          currentLogOutputStream.close();\n+          // if system down before delete, we can use this to delete file during recovery\n+          maxAvailableTime = getFileTime(currentLogFile);\n+          serializeMeta(meta);\n+\n+          currentLogFile.delete();\n+          currentLogOutputStream = new FileOutputStream(getCurrentLogFile());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3"}, "originalPosition": 228}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4NjQ5Mw==", "bodyText": "init() is called during the initialization and it is not likely recoverMeta() is called before so I think minAvailableTime and maxAvailableTime are in the initial state.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407286493", "createdAt": "2020-04-13T02:12:07Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4Njc3Nw==", "bodyText": "Maybe here should be <=.", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407286777", "createdAt": "2020-04-13T02:13:47Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3"}, "originalPosition": 219}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5MTU0NA==", "bodyText": "After openNewLogFile()\uff0cremovedLogSize > maxRemovedLogSize is still true. Consider the case, assuming the size of each log is 1:\ninitially: removedLogSize=50, maxRemovedLogSize=50, currentLogFileSize=100\nIf I call removeFirst(1) for ten times, each time removedLogSize > maxRemovedLogSize will be true and a new file will be open, even if the last log file may be empty.\nMy suggestion is: do not open new files during removals but during appending.\nFor example, each time the size of the current file >= maxRemovedLogSize after appending, open a new file, so the log files will have sizes around maxRemovedLogSize. And each time when removedLogSize > firstLogFile.length() after removal, you can just remove the first one or more files and set removedLogSize -= removedFile.length().", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407291544", "createdAt": "2020-04-13T02:40:35Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {\n+        size -= currentLogFile.length();\n+        try {\n+          currentLogOutputStream.close();\n+          // if system down before delete, we can use this to delete file during recovery\n+          maxAvailableTime = getFileTime(currentLogFile);\n+          serializeMeta(meta);\n+\n+          currentLogFile.delete();\n+          currentLogOutputStream = new FileOutputStream(getCurrentLogFile());\n+        } catch (IOException e) {\n+          e.printStackTrace();\n+        }\n+\n+        logFileList.remove(logFileList.size() - 1);\n+      }\n+      // else we just truncate it\n+      else {\n+        try {\n+          currentLogOutputStream.getChannel().truncate(getCurrentLogFile().length() - size);\n+          break;\n+        } catch (IOException e) {\n+          logger.error(\"Error in log serialization: \" + e.getMessage());\n+        }\n+      }\n+    }\n+\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      openNewLogFile();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3"}, "originalPosition": 260}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5MjY4MQ==", "bodyText": "It is not recommended to just override the origin file because if the system is down just after truncate, then everything is over.\nIt would be better to write a temporary file first and replace the old one with the new one such that at least the system can roll back to a previous state instead of a blank state. But during recovery, you will have to consider 3 cases: 1. both old file and new file exist; 2. only old file exists 3. only new file exists", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407292681", "createdAt": "2020-04-13T02:47:37Z", "author": {"login": "jt2594838"}, "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {\n+        size -= currentLogFile.length();\n+        try {\n+          currentLogOutputStream.close();\n+          // if system down before delete, we can use this to delete file during recovery\n+          maxAvailableTime = getFileTime(currentLogFile);\n+          serializeMeta(meta);\n+\n+          currentLogFile.delete();\n+          currentLogOutputStream = new FileOutputStream(getCurrentLogFile());\n+        } catch (IOException e) {\n+          e.printStackTrace();\n+        }\n+\n+        logFileList.remove(logFileList.size() - 1);\n+      }\n+      // else we just truncate it\n+      else {\n+        try {\n+          currentLogOutputStream.getChannel().truncate(getCurrentLogFile().length() - size);\n+          break;\n+        } catch (IOException e) {\n+          logger.error(\"Error in log serialization: \" + e.getMessage());\n+        }\n+      }\n+    }\n+\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      openNewLogFile();\n+    }\n+  }\n+\n+  @Override\n+  public List<Log> recoverLog() {\n+    if (meta == null) {\n+      recoverMeta();\n+    }\n+    // if we can totally remove some old file, remove them\n+    if (removedLogSize > 0) {\n+      actuallyDeleteFile();\n+    }\n+\n+    List<Log> result = new ArrayList<>();\n+    // skip removal file\n+    boolean shouldSkip = true;\n+\n+    for (File logFile : logFileList) {\n+      try {\n+        FileInputStream logReader = new FileInputStream(logFile);\n+        FileChannel logChannel = logReader.getChannel();\n+        if (shouldSkip) {\n+          long actuallySkippedBytes = logReader.skip(removedLogSize);\n+          if (actuallySkippedBytes != removedLogSize) {\n+            logger.info(\n+                \"Error in log serialization, skipped file length isn't consistent with removedLogSize!\");\n+            return result;\n+          }\n+          shouldSkip = false;\n+        }\n+\n+        while (logChannel.position() < logFile.length()) {\n+          // actual log\n+          Log log = readLog(logReader);\n+          result.add(log);\n+        }\n+        logReader.close();\n+      } catch (IOException e) {\n+        logger.error(\"Error in log serialization: \" + e.getMessage());\n+      }\n+    }\n+\n+    return result;\n+  }\n+\n+  // read single log\n+  private Log readLog(FileInputStream logReader) throws IOException {\n+    int logSize = ReadWriteIOUtils.readInt(logReader);\n+    int totalSize = Integer.BYTES + logSize;\n+\n+    Log log = null;\n+\n+    try {\n+      log = parser.parse(ByteBuffer.wrap(ReadWriteIOUtils.readBytes(logReader, logSize)));\n+    } catch (UnknownLogTypeException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+\n+    return log;\n+  }\n+\n+  @Override\n+  public LogManagerMeta recoverMeta() {\n+    if (meta == null && metaFile.exists() && metaFile.length() > 0) {\n+      try {\n+        FileInputStream metaReader = new FileInputStream(metaFile);\n+        firstLogPosition = ReadWriteIOUtils.readLong(metaReader);\n+        removedLogSize = ReadWriteIOUtils.readLong(metaReader);\n+        minAvailableTime = ReadWriteIOUtils.readLong(metaReader);\n+        maxAvailableTime = ReadWriteIOUtils.readLong(metaReader);\n+        meta = LogManagerMeta.deserialize(\n+            ByteBuffer.wrap(ReadWriteIOUtils.readBytesWithSelfDescriptionLength(metaReader)));\n+        metaReader.close();\n+      } catch (IOException e) {\n+        logger.error(\"Error in log serialization: \" + e.getMessage());\n+      }\n+    }\n+\n+    return meta;\n+  }\n+\n+  @Override\n+  public void serializeMeta(LogManagerMeta meta) {\n+    try {\n+      metaOutputStream.getChannel().truncate(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3"}, "originalPosition": 347}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb1854152a60fa5ced6f332f3fa75e728b7154b8", "author": {"user": {"login": "SilverNarcissus", "name": null}}, "url": "https://github.com/apache/iotdb/commit/eb1854152a60fa5ced6f332f3fa75e728b7154b8", "committedDate": "2020-04-13T10:25:26Z", "message": "fix meta file bug and add more test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNTU2NTg3", "url": "https://github.com/apache/iotdb/pull/958#pullrequestreview-392556587", "createdAt": "2020-04-14T02:11:18Z", "commit": {"oid": "eb1854152a60fa5ced6f332f3fa75e728b7154b8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3044, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}