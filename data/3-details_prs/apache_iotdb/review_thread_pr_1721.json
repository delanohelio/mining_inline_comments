{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDgzNTYzNTc1", "number": 1721, "reviewThreads": {"totalCount": 66, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQxMzo0NjoyOFrOEiIBeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNjozMTo0NVrOFE0sWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0MjE4NDkwOnYy", "diffSide": "RIGHT", "path": "server/src/assembly/resources/conf/iotdb-engine.properties", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQxMzo0NjoyOFrOHP0oQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQxMzo0NjoyOFrOHP0oQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjM1Mjk2Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # If size of a metadata operation plan is smaller than this parameter, then it will be rejected by MManager\n          \n          \n            \n            # If the size of a metadata operation plan is larger than this parameter, then it will be rejected by MManager", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486352963", "createdAt": "2020-09-10T13:46:28Z", "author": {"login": "qiaojialin"}, "path": "server/src/assembly/resources/conf/iotdb-engine.properties", "diffHunk": "@@ -169,6 +169,11 @@ timestamp_precision=ms\n # If it sets a value smaller than 0, use the default value 16777216\n wal_buffer_size=16777216\n \n+# Size of log buffer in each metadata operation plan(in byte).\n+# If size of a metadata operation plan is smaller than this parameter, then it will be rejected by MManager", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDUwMDk3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMToyMjowNlrOHQK9yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjoyNjoyM1rOHQMA7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcxODkyMw==", "bodyText": "It seems that this method is only used in tests, maybe we could add comments", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486718923", "createdAt": "2020-09-11T01:22:06Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -41,13 +42,26 @@\n   private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n   private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n   private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private long forcePeriodInMs = 0;\n \n-  public LogWriter(String logFilePath) {\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {\n     logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {\n+      fileOutputStream = new FileOutputStream(logFile, true);\n+      channel = fileOutputStream.getChannel();\n+    }\n   }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNjEwOQ==", "bodyText": "Yes, I will add some comments.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486736109", "createdAt": "2020-09-11T02:26:23Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -41,13 +42,26 @@\n   private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n   private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n   private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private long forcePeriodInMs = 0;\n \n-  public LogWriter(String logFilePath) {\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {\n     logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {\n+      fileOutputStream = new FileOutputStream(logFile, true);\n+      channel = fileOutputStream.getChannel();\n+    }\n   }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcxODkyMw=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDUxNjkzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTozMDo0NFrOHQLGuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjoyNzozMVrOHQMCEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyMTIwOQ==", "bodyText": "true if and only if the file or directory is successfully deleted\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  if (oldMLogFile.delete()) {\n          \n          \n            \n                  if (!oldMLogFile.delete()) {", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486721209", "createdAt": "2020-09-11T01:30:44Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -203,6 +203,13 @@ public void checkConfig() throws IOException {\n       }\n       // rename tmpLogFile to mlog\n       FileUtils.moveFile(tmpMLogFile, mlogFile);\n+\n+      File oldMLogFile = SystemFileFactory.INSTANCE.getFile(SCHEMA_DIR + File.separator\n+          + MetadataConstant.METADATA_OLD_LOG);\n+\n+      if (oldMLogFile.delete()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNjQwMA==", "bodyText": "yes, thank you for pointing this out.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486736400", "createdAt": "2020-09-11T02:27:31Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -203,6 +203,13 @@ public void checkConfig() throws IOException {\n       }\n       // rename tmpLogFile to mlog\n       FileUtils.moveFile(tmpMLogFile, mlogFile);\n+\n+      File oldMLogFile = SystemFileFactory.INSTANCE.getFile(SCHEMA_DIR + File.separator\n+          + MetadataConstant.METADATA_OLD_LOG);\n+\n+      if (oldMLogFile.delete()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyMTIwOQ=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDUyOTU4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTozODozMFrOHQLOSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjoyOTozN1rOHQMEKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyMzE0NQ==", "bodyText": "Could we catch FileNotFoundException here so that we won't throw it to other classes?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486723145", "createdAt": "2020-09-11T01:38:30Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -41,13 +42,26 @@\n   private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n   private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n   private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private long forcePeriodInMs = 0;\n \n-  public LogWriter(String logFilePath) {\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {\n     logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {\n+      fileOutputStream = new FileOutputStream(logFile, true);\n+      channel = fileOutputStream.getChannel();\n+    }\n   }\n \n-  public LogWriter(File logFile) {\n+  public LogWriter(File logFile, long forcePeriodInMs) throws FileNotFoundException {\n     this.logFile = logFile;\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {\n+      fileOutputStream = new FileOutputStream(logFile, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNjkzOQ==", "bodyText": "I think we should throw the exception for it's not normal, because fileoutputstream could create it if not exist.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486736939", "createdAt": "2020-09-11T02:29:37Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -41,13 +42,26 @@\n   private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n   private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n   private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private long forcePeriodInMs = 0;\n \n-  public LogWriter(String logFilePath) {\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {\n     logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {\n+      fileOutputStream = new FileOutputStream(logFile, true);\n+      channel = fileOutputStream.getChannel();\n+    }\n   }\n \n-  public LogWriter(File logFile) {\n+  public LogWriter(File logFile, long forcePeriodInMs) throws FileNotFoundException {\n     this.logFile = logFile;\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {\n+      fileOutputStream = new FileOutputStream(logFile, true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyMzE0NQ=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDUzMzUxOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/apache/iotdb/db/integration/IoTDBCreateSnapshotIT.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTo0MDozNlrOHQLQkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjoyOTo1NVrOHQMEeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyMzcyOQ==", "bodyText": "Replace if statement with switch statement", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486723729", "createdAt": "2020-09-11T01:40:36Z", "author": {"login": "samperson1997"}, "path": "server/src/test/java/org/apache/iotdb/db/integration/IoTDBCreateSnapshotIT.java", "diffHunk": "@@ -156,4 +178,20 @@ private void checkShowTimeseries(Statement statement) throws SQLException {\n       Assert.assertEquals(8, cnt);\n     }\n   }\n+\n+  private PhysicalPlan convertFromString(String str) {\n+    String[] words = str.split(\",\");\n+    if (words[0].equals(\"2\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNzAxNg==", "bodyText": "ok, thanks!", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486737016", "createdAt": "2020-09-11T02:29:55Z", "author": {"login": "mychaow"}, "path": "server/src/test/java/org/apache/iotdb/db/integration/IoTDBCreateSnapshotIT.java", "diffHunk": "@@ -156,4 +178,20 @@ private void checkShowTimeseries(Statement statement) throws SQLException {\n       Assert.assertEquals(8, cnt);\n     }\n   }\n+\n+  private PhysicalPlan convertFromString(String str) {\n+    String[] words = str.split(\",\");\n+    if (words[0].equals(\"2\")) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyMzcyOQ=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDU0NDMzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/sync/receiver/transfer/SyncServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTo0NTo1OVrOHQLWfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjozMDowOVrOHQMErg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyNTI0NA==", "bodyText": "with finally, we could close mLogReader only once", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486725244", "createdAt": "2020-09-11T01:45:59Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/sync/receiver/transfer/SyncServiceImpl.java", "diffHunk": "@@ -272,18 +274,25 @@ public SyncStatus checkDataMD5(String md5OfSender) throws TException {\n   private void loadMetadata() {\n     logger.info(\"Start to load metadata in sync process.\");\n     if (currentFile.get().exists()) {\n-      try (BufferedReader br = new BufferedReader(\n-          new java.io.FileReader(currentFile.get()))) {\n-        String metadataOperation;\n-        while ((metadataOperation = br.readLine()) != null) {\n+      MLogReader mLogReader = null;\n+      try {\n+        mLogReader = new MLogReader(config.getSchemaDir(), MetadataConstant.METADATA_LOG);\n+        while (mLogReader.hasNext()) {\n+          PhysicalPlan plan = mLogReader.next();\n           try {\n-            IoTDB.metaManager.operation(metadataOperation);\n-          } catch (IOException | MetadataException e) {\n-            logger.error(\"Can not operate metadata operation {} \", metadataOperation, e);\n+            if (plan == null) {\n+              continue;\n+            }\n+            IoTDB.metaManager.operation(plan);\n+          } catch (Exception e) {\n+            logger.error(\"Can not operate metadata operation {} for err:{}\", plan.getOperatorType(), e);\n           }\n         }\n+        mLogReader.close();\n       } catch (IOException e) {\n         logger.error(\"Cannot read the file {}.\", currentFile.get().getAbsoluteFile(), e);\n+      } finally {\n+        mLogReader.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNzA3MA==", "bodyText": "yes!", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486737070", "createdAt": "2020-09-11T02:30:09Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/sync/receiver/transfer/SyncServiceImpl.java", "diffHunk": "@@ -272,18 +274,25 @@ public SyncStatus checkDataMD5(String md5OfSender) throws TException {\n   private void loadMetadata() {\n     logger.info(\"Start to load metadata in sync process.\");\n     if (currentFile.get().exists()) {\n-      try (BufferedReader br = new BufferedReader(\n-          new java.io.FileReader(currentFile.get()))) {\n-        String metadataOperation;\n-        while ((metadataOperation = br.readLine()) != null) {\n+      MLogReader mLogReader = null;\n+      try {\n+        mLogReader = new MLogReader(config.getSchemaDir(), MetadataConstant.METADATA_LOG);\n+        while (mLogReader.hasNext()) {\n+          PhysicalPlan plan = mLogReader.next();\n           try {\n-            IoTDB.metaManager.operation(metadataOperation);\n-          } catch (IOException | MetadataException e) {\n-            logger.error(\"Can not operate metadata operation {} \", metadataOperation, e);\n+            if (plan == null) {\n+              continue;\n+            }\n+            IoTDB.metaManager.operation(plan);\n+          } catch (Exception e) {\n+            logger.error(\"Can not operate metadata operation {} for err:{}\", plan.getOperatorType(), e);\n           }\n         }\n+        mLogReader.close();\n       } catch (IOException e) {\n         logger.error(\"Cannot read the file {}.\", currentFile.get().getAbsoluteFile(), e);\n+      } finally {\n+        mLogReader.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyNTI0NA=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDU1MDg5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/qp/physical/sys/StorageGroupMNodePlan.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTo0OTozOVrOHQLaRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjozMToyMFrOHQMF7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyNjIxMw==", "bodyText": "I understand it's convenient to make them extends PhysicalPlan, but I still think it is a little bit strange to make StorageGroupMNode, MNode and MeasurementNode as a plan... How did you consider about it?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486726213", "createdAt": "2020-09-11T01:49:39Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/qp/physical/sys/StorageGroupMNodePlan.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iotdb.db.qp.physical.sys;\n+\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.qp.logical.Operator;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+\n+public class StorageGroupMNodePlan extends PhysicalPlan {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNzM5MA==", "bodyText": "haha, I will change it. It's a mistake.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486737390", "createdAt": "2020-09-11T02:31:20Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/qp/physical/sys/StorageGroupMNodePlan.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iotdb.db.qp.physical.sys;\n+\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.qp.logical.Operator;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+\n+import java.io.DataOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+\n+public class StorageGroupMNodePlan extends PhysicalPlan {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyNjIxMw=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDU2MDYyOnYy", "diffSide": "RIGHT", "path": "docs/SystemDesign/SchemaManager/SchemaManager.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTo1NTowMVrOHQLgEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTo1NTowMVrOHQLgEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyNzY5OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            All metadata operations are recorded in a metadata log file, which defaults to data/system/schema/mlog.txt.\n          \n          \n            \n            All metadata operations are recorded in a metadata log file, which defaults to data/system/schema/mlog.bin.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486727698", "createdAt": "2020-09-11T01:55:01Z", "author": {"login": "HTHou"}, "path": "docs/SystemDesign/SchemaManager/SchemaManager.md", "diffHunk": "@@ -213,7 +213,7 @@ The method is `MManager.initFromLog()`:\n \n ## Log management of metadata\n \n-* org.apache.iotdb.db.metadata.MLogWriter\n+* org.apache.iotdb.db.metadata.logfile.MLogWriter\n \n All metadata operations are recorded in a metadata log file, which defaults to data/system/schema/mlog.txt.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDU2MTQzOnYy", "diffSide": "RIGHT", "path": "docs/zh/SystemDesign/SchemaManager/SchemaManager.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTo1NToxN1rOHQLgfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjo0Mzo0MVrOHQMTeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyNzgwNw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \u6240\u6709\u5143\u6570\u636e\u7684\u64cd\u4f5c\u5747\u4f1a\u8bb0\u5f55\u5230\u5143\u6570\u636e\u65e5\u5fd7\u6587\u4ef6\u4e2d\uff0c\u6b64\u6587\u4ef6\u9ed8\u8ba4\u4e3a data/system/schema/mlog.txt\u3002\n          \n          \n            \n            \u6240\u6709\u5143\u6570\u636e\u7684\u64cd\u4f5c\u5747\u4f1a\u8bb0\u5f55\u5230\u5143\u6570\u636e\u65e5\u5fd7\u6587\u4ef6\u4e2d\uff0c\u6b64\u6587\u4ef6\u9ed8\u8ba4\u4e3a data/system/schema/mlog.bin\u3002", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486727807", "createdAt": "2020-09-11T01:55:17Z", "author": {"login": "HTHou"}, "path": "docs/zh/SystemDesign/SchemaManager/SchemaManager.md", "diffHunk": "@@ -211,7 +211,7 @@ IoTDB \u7684\u5143\u6570\u636e\u7ba1\u7406\u91c7\u7528\u76ee\u5f55\u6811\u7684\u5f62\u5f0f\uff0c\u5012\u6570\u7b2c\u4e8c\u5c42\u4e3a\u8bbe\u5907\u5c42\n \n ## \u5143\u6570\u636e\u65e5\u5fd7\u7ba1\u7406\n \n-* org.apache.iotdb.db.metadata.MLogWriter\n+* org.apache.iotdb.db.metadata.logfile.MLogWriter\n \n \u6240\u6709\u5143\u6570\u636e\u7684\u64cd\u4f5c\u5747\u4f1a\u8bb0\u5f55\u5230\u5143\u6570\u636e\u65e5\u5fd7\u6587\u4ef6\u4e2d\uff0c\u6b64\u6587\u4ef6\u9ed8\u8ba4\u4e3a data/system/schema/mlog.txt\u3002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc0MDg1Nw==", "bodyText": "Got it!", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486740857", "createdAt": "2020-09-11T02:43:41Z", "author": {"login": "mychaow"}, "path": "docs/zh/SystemDesign/SchemaManager/SchemaManager.md", "diffHunk": "@@ -211,7 +211,7 @@ IoTDB \u7684\u5143\u6570\u636e\u7ba1\u7406\u91c7\u7528\u76ee\u5f55\u6811\u7684\u5f62\u5f0f\uff0c\u5012\u6570\u7b2c\u4e8c\u5c42\u4e3a\u8bbe\u5907\u5c42\n \n ## \u5143\u6570\u636e\u65e5\u5fd7\u7ba1\u7406\n \n-* org.apache.iotdb.db.metadata.MLogWriter\n+* org.apache.iotdb.db.metadata.logfile.MLogWriter\n \n \u6240\u6709\u5143\u6570\u636e\u7684\u64cd\u4f5c\u5747\u4f1a\u8bb0\u5f55\u5230\u5143\u6570\u636e\u65e5\u5fd7\u6587\u4ef6\u4e2d\uff0c\u6b64\u6587\u4ef6\u9ed8\u8ba4\u4e3a data/system/schema/mlog.txt\u3002", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyNzgwNw=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDU2NDM4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTo1Njo0OFrOHQLiKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMTo1Njo0OFrOHQLiKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyODIzNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public void seriallizeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n          \n          \n            \n              public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486728234", "createdAt": "2020-09-11T01:56:48Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,350 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.info(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementNodePlan plan = new MeasurementNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void seriallizeStorageGroupMNode(StorageGroupMNode node) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 203}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDU3NDcxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjowMjoyOVrOHQLoRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjo1MDo1NFrOHQMaeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyOTc5Ng==", "bodyText": "Line 190 to line 205 is the part of upgrading v0.9 mlog to v0.10. Since the MetadataConstant.METADATA_LOG has changed, I don't think that upgrading will work correctly. Should we remove that?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486729796", "createdAt": "2020-09-11T02:02:29Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -203,6 +203,13 @@ public void checkConfig() throws IOException {\n       }\n       // rename tmpLogFile to mlog\n       FileUtils.moveFile(tmpMLogFile, mlogFile);\n+\n+      File oldMLogFile = SystemFileFactory.INSTANCE.getFile(SCHEMA_DIR + File.separator\n+          + MetadataConstant.METADATA_OLD_LOG);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc0MjY0OA==", "bodyText": "yes, it's no meaning.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486742648", "createdAt": "2020-09-11T02:50:54Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -203,6 +203,13 @@ public void checkConfig() throws IOException {\n       }\n       // rename tmpLogFile to mlog\n       FileUtils.moveFile(tmpMLogFile, mlogFile);\n+\n+      File oldMLogFile = SystemFileFactory.INSTANCE.getFile(SCHEMA_DIR + File.separator\n+          + MetadataConstant.METADATA_OLD_LOG);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyOTc5Ng=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDYyMDk5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjoyODoxNFrOHQMCyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjo1MTowMlrOHQMamQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNjU4Nw==", "bodyText": "Use try with resource to avoid new sonar code smell..", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486736587", "createdAt": "2020-09-11T02:28:14Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1002,55 +1008,74 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    MLogWriter mLogWriter = null;\n+    try {\n+      mLogWriter = new MLogWriter(snapshotPath);\n+      root.serializeTo(mLogWriter);\n+    } finally {\n+      if (mLogWriter != null) {\n+        mLogWriter.close();\n+      }\n     }\n   }\n \n   @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n   public static MTree deserializeFrom(File mtreeSnapshot) {\n-    try (BufferedReader br = new BufferedReader(new FileReader(mtreeSnapshot))) {\n-      String s;\n+    MLogReader mlogReader = null;\n+    try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc0MjY4MQ==", "bodyText": "Got it!", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486742681", "createdAt": "2020-09-11T02:51:02Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1002,55 +1008,74 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    MLogWriter mLogWriter = null;\n+    try {\n+      mLogWriter = new MLogWriter(snapshotPath);\n+      root.serializeTo(mLogWriter);\n+    } finally {\n+      if (mLogWriter != null) {\n+        mLogWriter.close();\n+      }\n     }\n   }\n \n   @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n   public static MTree deserializeFrom(File mtreeSnapshot) {\n-    try (BufferedReader br = new BufferedReader(new FileReader(mtreeSnapshot))) {\n-      String s;\n+    MLogReader mlogReader = null;\n+    try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNjU4Nw=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDYyMTY0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjoyODozOFrOHQMDKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjoyODozOFrOHQMDKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNjY4MA==", "bodyText": "Use try with resource", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486736680", "createdAt": "2020-09-11T02:28:38Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1002,55 +1008,74 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    MLogWriter mLogWriter = null;\n+    try {\n+      mLogWriter = new MLogWriter(snapshotPath);\n+      root.serializeTo(mLogWriter);\n+    } finally {\n+      if (mLogWriter != null) {\n+        mLogWriter.close();\n+      }\n     }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDYyMjY5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjoyOToxNVrOHQMDxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjoyOToxNVrOHQMDxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNjgzNg==", "bodyText": "Use try with resource", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486736836", "createdAt": "2020-09-11T02:29:15Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MManager.java", "diffHunk": "@@ -248,21 +237,32 @@ private int initFromLog(File logFile) throws IOException {\n     // init the metadata from the operation log\n     if (logFile.exists()) {\n       int idx = 0;\n-      try (FileReader fr = new FileReader(logFile);\n-          BufferedReader br = new BufferedReader(fr)) {\n-        String cmd;\n-        while ((cmd = br.readLine()) != null) {\n+      MLogReader mLogReader = null;\n+      try {\n+        mLogReader = new MLogReader(config.getSchemaDir(), MetadataConstant.METADATA_LOG);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDYyNjg3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjozMToyN1rOHQMGJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjozMToyN1rOHQMGJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNzQ0NA==", "bodyText": "info -> warn?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486737444", "createdAt": "2020-09-11T02:31:27Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,350 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.info(\"create schema folder {} failed.\", metadataDir);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDYyOTAzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMjozMjozNVrOHQMHVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwNDoyMTozNVrOHQNw2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNzc1MA==", "bodyText": "use try with resource", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486737750", "createdAt": "2020-09-11T02:32:35Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,350 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.info(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementNodePlan plan = new MeasurementNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void seriallizeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public static void upgradeMLog(String schemaDir, String logFileName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+        schemaDir + File.separator + MetadataConstant.METADATA_OLD_LOG);\n+\n+    if (oldLogFile.exists()) {\n+      MLogWriter mLogWriter = null;\n+      OldMLogReader oldMLogReader = null;\n+      try {\n+        // upgrade from old character log file to new binary mlog\n+        mLogWriter = new MLogWriter(schemaDir, logFileName + \".tmp\");\n+        oldMLogReader = new OldMLogReader(schemaDir, MetadataConstant.METADATA_OLD_LOG);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc2NDc2Mg==", "bodyText": "Got it!", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486764762", "createdAt": "2020-09-11T04:21:35Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,350 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.info(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementNodePlan plan = new MeasurementNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void seriallizeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public static void upgradeMLog(String schemaDir, String logFileName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+        schemaDir + File.separator + MetadataConstant.METADATA_OLD_LOG);\n+\n+    if (oldLogFile.exists()) {\n+      MLogWriter mLogWriter = null;\n+      OldMLogReader oldMLogReader = null;\n+      try {\n+        // upgrade from old character log file to new binary mlog\n+        mLogWriter = new MLogWriter(schemaDir, logFileName + \".tmp\");\n+        oldMLogReader = new OldMLogReader(schemaDir, MetadataConstant.METADATA_OLD_LOG);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjczNzc1MA=="}, "originalCommit": {"oid": "329c11ffdc000c45dbea71fcd95f003cb57e4487"}, "originalPosition": 229}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NTA0MzA4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwNjoyNDoxMFrOHQP35g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwOTowNDo0MVrOHQz0ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc5OTMzNA==", "bodyText": "Hi, may I ask why we put operations like serializeMNode to log?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r486799334", "createdAt": "2020-09-11T06:24:10Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzMDM4MA==", "bodyText": "It's snapshot file, not mlog.bin, I just serialize the snapshot and mlog by the same logwriter class. So, the snapshot file has the same format with mlog.bin.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487030380", "createdAt": "2020-09-11T13:04:16Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc5OTMzNA=="}, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM4ODI5OA==", "bodyText": "Ah... I understand, it used to be the snapshot file which serializes the MTree. @qiaojialin Do you think it is acceptable?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487388298", "createdAt": "2020-09-12T09:04:41Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc5OTMzNA=="}, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 181}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MTY3OTEzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwOTowMzoxNFrOHRKhQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwOTowMzoxNFrOHRKhQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc2MDE5Mw==", "bodyText": "larger?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487760193", "createdAt": "2020-09-14T09:03:14Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfig.java", "diffHunk": "@@ -168,6 +168,12 @@\n    */\n   private int walBufferSize = 16 * 1024 * 1024;\n \n+  /**\n+   * Size of log buffer for every MetaData operation. If the size of a MetaData operation plan\n+   * is smaller than this parameter, then the MetaData operation plan will be rejected by MManager.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MTgwMDAxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwOTozNDo0MFrOHRLqCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwOTozNDo0MFrOHRLqCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc3ODgyNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                // if both old mlog and mlog.tmp do not exist, nothing to do\n          \n          \n            \n                // if both old mlog.txt and mlog.bin.tmp do not exist, nothing to do", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487778825", "createdAt": "2020-09-14T09:34:40Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public static void upgradeMLog(String schemaDir, String logFileName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+        schemaDir + File.separator + MetadataConstant.METADATA_OLD_LOG);\n+\n+    if (oldLogFile.exists()) {\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, logFileName + \".tmp\");\n+        OldMLogReader oldMLogReader = new OldMLogReader(schemaDir, MetadataConstant.METADATA_OLD_LOG)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (oldMLogReader.hasNext()) {\n+          String cmd = oldMLogReader.next();\n+          try {\n+            mLogWriter.operation(cmd);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+\n+        return;\n+      }\n+    }\n+\n+    // if both old mlog and mlog.tmp do not exist, nothing to do", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 240}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MTgwNDA5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwOTozNTo0M1rOHRLsgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwOTozNTo0M1rOHRLsgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc3OTQ1Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                // if both old mlog and mlog.tmp exist, delete mlog tmp, then do upgrading\n          \n          \n            \n                // if both old mlog.txt and mlog.bin.tmp exist, delete mlog.bin.tmp, then do upgrading", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487779456", "createdAt": "2020-09-14T09:35:43Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public static void upgradeMLog(String schemaDir, String logFileName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+        schemaDir + File.separator + MetadataConstant.METADATA_OLD_LOG);\n+\n+    if (oldLogFile.exists()) {\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, logFileName + \".tmp\");\n+        OldMLogReader oldMLogReader = new OldMLogReader(schemaDir, MetadataConstant.METADATA_OLD_LOG)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (oldMLogReader.hasNext()) {\n+          String cmd = oldMLogReader.next();\n+          try {\n+            mLogWriter.operation(cmd);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+\n+        return;\n+      }\n+    }\n+\n+    // if both old mlog and mlog.tmp do not exist, nothing to do\n+    if (!logFile.exists() && !tmpLogFile.exists()) {\n+      return;\n+    } else if (!logFile.exists() && tmpLogFile.exists()) {\n+      // if old mlog doesn't exist but mlog.tmp exists, rename tmp file to mlog\n+      FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+      return;\n+    }\n+\n+    // if both old mlog and mlog.tmp exist, delete mlog tmp, then do upgrading", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 249}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MTg0NDUyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwOTo0NjoyNlrOHRMEyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwMToyMDo0MVrOHScoGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc4NTY3NQ==", "bodyText": "How about puting the offset to the CreateTimeseriesPlan", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487785675", "createdAt": "2020-09-14T09:46:26Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTEwNTQzMw==", "bodyText": "ok", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r489105433", "createdAt": "2020-09-16T01:20:41Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc4NTY3NQ=="}, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MTg1MDkwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwOTo0ODowMVrOHRMInA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQwOTo0ODowMVrOHRMInA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc4NjY1Mg==", "bodyText": "This is not used", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487786652", "createdAt": "2020-09-14T09:48:01Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public static void upgradeMLog(String schemaDir, String logFileName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+        schemaDir + File.separator + MetadataConstant.METADATA_OLD_LOG);\n+\n+    if (oldLogFile.exists()) {\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, logFileName + \".tmp\");\n+        OldMLogReader oldMLogReader = new OldMLogReader(schemaDir, MetadataConstant.METADATA_OLD_LOG)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (oldMLogReader.hasNext()) {\n+          String cmd = oldMLogReader.next();\n+          try {\n+            mLogWriter.operation(cmd);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+\n+        return;\n+      }\n+    }\n+\n+    // if both old mlog and mlog.tmp do not exist, nothing to do\n+    if (!logFile.exists() && !tmpLogFile.exists()) {\n+      return;\n+    } else if (!logFile.exists() && tmpLogFile.exists()) {\n+      // if old mlog doesn't exist but mlog.tmp exists, rename tmp file to mlog\n+      FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+      return;\n+    }\n+\n+    // if both old mlog and mlog.tmp exist, delete mlog tmp, then do upgrading\n+    if (tmpLogFile.exists()) {\n+      if (!tmpLogFile.delete()) {\n+        throw new IOException(\"Deleting \" + tmpLogFile + \"failed.\");\n+      }\n+    }\n+  }\n+\n+  public void clear() throws IOException {\n+    sync();\n+    logWriter.close();\n+    mlogBuffer.clear();\n+    if (logFile != null) {\n+      if (logFile.exists()) {\n+        Files.delete(logFile.toPath());\n+      }\n+    }\n+    logNum = 0;\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public int getLogNum() {\n+    return logNum;\n+  }\n+\n+  /**\n+   * only used for initialize a mlog file writer.\n+   */\n+  public void setLogNum(int number) {\n+    logNum = number;\n+  }\n+\n+  public void operation(String cmd) throws IOException, MetadataException {\n+    // see createTimeseries() to get the detailed format of the cmd\n+    String[] args = cmd.trim().split(\",\", -1);\n+    switch (args[0]) {\n+      case MetadataOperationType.CREATE_TIMESERIES:\n+        Map<String, String> props = null;\n+        if (!args[5].isEmpty()) {\n+          String[] keyValues = args[5].split(\"&\");\n+          String[] kv;\n+          props = new HashMap<>();\n+          for (String keyValue : keyValues) {\n+            kv = keyValue.split(\"=\");\n+            props.put(kv[0], kv[1]);\n+          }\n+        }\n+\n+        String alias = null;\n+        if (!args[6].isEmpty()) {\n+          alias = args[6];\n+        }\n+        long offset = -1L;\n+        Map<String, String> tagMap = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 302}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjA0NTMxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMDo0MDoyMVrOHRN8nQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMDo0MDoyMVrOHRN8nQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgxNjM0OQ==", "bodyText": "Are these codes duplicated with MLogWriter.upgrade() ? Maybe puting them to MLogWriter.upgrade() is better.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487816349", "createdAt": "2020-09-14T10:40:21Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -186,59 +186,34 @@ public void checkConfig() throws IOException {\n             inputStream, TSFileConfig.STRING_CHARSET)) {\n       properties.load(inputStreamReader);\n     }\n-    // need to upgrade from 0.9 to 0.10\n-    if (!properties.containsKey(IOTDB_VERSION_STRING)) {\n-      checkUnClosedTsFileV1();\n-      MLogWriter.upgradeMLog(SCHEMA_DIR, MetadataConstant.METADATA_LOG);\n-      upgradePropertiesFile();\n-\n-      // upgrade mlog finished, delete old mlog file\n-      File mlogFile = SystemFileFactory.INSTANCE.getFile(SCHEMA_DIR + File.separator\n-          + MetadataConstant.METADATA_LOG);\n-      File tmpMLogFile = SystemFileFactory.INSTANCE.getFile(mlogFile.getAbsolutePath()\n-          + \".tmp\");\n-\n-      if (!mlogFile.delete()) {\n-        throw new IOException(\"Deleting \" + mlogFile + \"failed.\");\n-      }\n-      // rename tmpLogFile to mlog\n-      FileUtils.moveFile(tmpMLogFile, mlogFile);\n+\n+    // upgrade from mlog.txt to mlog.bin\n+    MLogWriter.upgradeMLog(SCHEMA_DIR, MetadataConstant.METADATA_LOG);\n+    // finish upgrade, remove old mlog.txt and mlog.txt.tmp\n+    File oldMLogFile = SystemFileFactory.INSTANCE.getFile(SCHEMA_DIR + File.separator\n+      + MetadataConstant.METADATA_OLD_LOG);\n+    File tmpMLogFile = SystemFileFactory.INSTANCE.getFile(oldMLogFile.getAbsolutePath()\n+      + \".tmp\");\n+\n+    if (!oldMLogFile.delete()) {\n+      throw new IOException(\"Deleting old mlog.txt \" + oldMLogFile + \"failed.\");\n     }\n-    checkProperties();\n-  }\n \n-  /**\n-   * upgrade 0.9 properties to 0.10 properties\n-   */\n-  private void upgradePropertiesFile()\n-      throws IOException {\n-    // create an empty tmpPropertiesFile\n-    if (tmpPropertiesFile.createNewFile()) {\n-      logger.info(\"Create system.properties.tmp {}.\", tmpPropertiesFile);\n-    } else {\n-      logger.error(\"Create system.properties.tmp {} failed.\", tmpPropertiesFile);\n-      System.exit(-1);\n+    if (!tmpMLogFile.delete()) {\n+      throw new IOException(\"Deleting old mlog.txt.tmp \" + oldMLogFile + \"failed.\");\n     }\n \n-    try (FileOutputStream tmpFOS = new FileOutputStream(tmpPropertiesFile.toString())) {\n-      properties.setProperty(PARTITION_INTERVAL_STRING, String.valueOf(partitionInterval));\n-      properties.setProperty(TSFILE_FILE_SYSTEM_STRING, tsfileFileSystem);\n-      properties.setProperty(IOTDB_VERSION_STRING, IoTDBConstant.VERSION);\n-      properties.setProperty(ENABLE_PARTITION_STRING, String.valueOf(enablePartition));\n-      properties.setProperty(TAG_ATTRIBUTE_SIZE_STRING, tagAttributeTotalSize);\n-      properties.setProperty(MAX_DEGREE_OF_INDEX_STRING, maxDegreeOfIndexNode);\n-      properties.store(tmpFOS, SYSTEM_PROPERTIES_STRING);\n+    // move mlog.bin.tmp to mlog.bin\n+    File mlogFile = SystemFileFactory.INSTANCE.getFile(SCHEMA_DIR + File.separator\n+      + MetadataConstant.METADATA_LOG);\n+    tmpMLogFile = SystemFileFactory.INSTANCE.getFile(mlogFile.getAbsolutePath()\n+      + \".tmp\");\n+    // rename tmpLogFile to mlog\n+    FileUtils.moveFile(tmpMLogFile, mlogFile);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjEyMjU0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMTowMzoyMFrOHROqmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwMToyMTozNVrOHScpDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgyODEyMw==", "bodyText": "If we throw an IOException here, the user will get an empty MTree, they may feel \"lose their data\". I suggest catch all Exceptions when recovering MManager and recover mlog as much as possible. We could print an error stack and fix it later.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487828123", "createdAt": "2020-09-14T11:03:20Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MManager.java", "diffHunk": "@@ -248,21 +237,27 @@ private int initFromLog(File logFile) throws IOException {\n     // init the metadata from the operation log\n     if (logFile.exists()) {\n       int idx = 0;\n-      try (FileReader fr = new FileReader(logFile);\n-          BufferedReader br = new BufferedReader(fr)) {\n-        String cmd;\n-        while ((cmd = br.readLine()) != null) {\n+      try (MLogReader mLogReader = new MLogReader(config.getSchemaDir(), MetadataConstant.METADATA_LOG);) {\n+\n+        while (mLogReader.hasNext()) {\n+          PhysicalPlan plan = null;\n           try {\n-            operation(cmd);\n+            plan = mLogReader.next();\n+            if (plan == null) {\n+              continue;\n+            }\n+            operation(plan);\n             idx++;\n           } catch (Exception e) {\n-            logger.error(\"Can not operate cmd {}\", cmd, e);\n+            logger.error(\"Can not operate cmd {} for err:\", plan.getOperatorType(), e);\n           }\n         }\n+        logger.debug(\"spend {} ms to deserialize mtree from mlog.bin\",\n+            System.currentTimeMillis() - time);\n+        return idx;\n+      } catch (Exception e) {\n+        throw new IOException(\"Failed to parser mlog.bin for err:\" +  e.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTEwNTY3Ng==", "bodyText": "ok", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r489105676", "createdAt": "2020-09-16T01:21:35Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MManager.java", "diffHunk": "@@ -248,21 +237,27 @@ private int initFromLog(File logFile) throws IOException {\n     // init the metadata from the operation log\n     if (logFile.exists()) {\n       int idx = 0;\n-      try (FileReader fr = new FileReader(logFile);\n-          BufferedReader br = new BufferedReader(fr)) {\n-        String cmd;\n-        while ((cmd = br.readLine()) != null) {\n+      try (MLogReader mLogReader = new MLogReader(config.getSchemaDir(), MetadataConstant.METADATA_LOG);) {\n+\n+        while (mLogReader.hasNext()) {\n+          PhysicalPlan plan = null;\n           try {\n-            operation(cmd);\n+            plan = mLogReader.next();\n+            if (plan == null) {\n+              continue;\n+            }\n+            operation(plan);\n             idx++;\n           } catch (Exception e) {\n-            logger.error(\"Can not operate cmd {}\", cmd, e);\n+            logger.error(\"Can not operate cmd {} for err:\", plan.getOperatorType(), e);\n           }\n         }\n+        logger.debug(\"spend {} ms to deserialize mtree from mlog.bin\",\n+            System.currentTimeMillis() - time);\n+        return idx;\n+      } catch (Exception e) {\n+        throw new IOException(\"Failed to parser mlog.bin for err:\" +  e.toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgyODEyMw=="}, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjU5NTYzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzoxMDo1NFrOHRTCFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzoxMDo1NFrOHRTCFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg5OTY2OQ==", "bodyText": "This is not an unusual case, no need to throw an exception. Please help to remove this.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487899669", "createdAt": "2020-09-14T13:10:54Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MManager.java", "diffHunk": "@@ -248,21 +237,27 @@ private int initFromLog(File logFile) throws IOException {\n     // init the metadata from the operation log\n     if (logFile.exists()) {\n       int idx = 0;\n-      try (FileReader fr = new FileReader(logFile);\n-          BufferedReader br = new BufferedReader(fr)) {\n-        String cmd;\n-        while ((cmd = br.readLine()) != null) {\n+      try (MLogReader mLogReader = new MLogReader(config.getSchemaDir(), MetadataConstant.METADATA_LOG);) {\n+\n+        while (mLogReader.hasNext()) {\n+          PhysicalPlan plan = null;\n           try {\n-            operation(cmd);\n+            plan = mLogReader.next();\n+            if (plan == null) {\n+              continue;\n+            }\n+            operation(plan);\n             idx++;\n           } catch (Exception e) {\n-            logger.error(\"Can not operate cmd {}\", cmd, e);\n+            logger.error(\"Can not operate cmd {} for err:\", plan.getOperatorType(), e);\n           }\n         }\n+        logger.debug(\"spend {} ms to deserialize mtree from mlog.bin\",\n+            System.currentTimeMillis() - time);\n+        return idx;\n+      } catch (Exception e) {\n+        throw new IOException(\"Failed to parser mlog.bin for err:\" +  e.toString());\n       }\n-      logger.debug(\"spend {} ms to deserialize mtree from mlog.txt\",\n-          System.currentTimeMillis() - time);\n-      return idx;\n     } else if (mtreeSnapshot.exists()) {\n       throw new IOException(\"mtree snapshot file exists but mlog.txt does not exist.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjYzMDgwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzoxOTowNVrOHRTXcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwMToyMTo1MFrOHScpSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkwNTEzOQ==", "bodyText": "Add a javadoc indicating for an upgrade from mlog.txt", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487905139", "createdAt": "2020-09-14T13:19:05Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public static void upgradeMLog(String schemaDir, String logFileName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+        schemaDir + File.separator + MetadataConstant.METADATA_OLD_LOG);\n+\n+    if (oldLogFile.exists()) {\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, logFileName + \".tmp\");\n+        OldMLogReader oldMLogReader = new OldMLogReader(schemaDir, MetadataConstant.METADATA_OLD_LOG)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (oldMLogReader.hasNext()) {\n+          String cmd = oldMLogReader.next();\n+          try {\n+            mLogWriter.operation(cmd);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+\n+        return;\n+      }\n+    }\n+\n+    // if both old mlog and mlog.tmp do not exist, nothing to do\n+    if (!logFile.exists() && !tmpLogFile.exists()) {\n+      return;\n+    } else if (!logFile.exists() && tmpLogFile.exists()) {\n+      // if old mlog doesn't exist but mlog.tmp exists, rename tmp file to mlog\n+      FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+      return;\n+    }\n+\n+    // if both old mlog and mlog.tmp exist, delete mlog tmp, then do upgrading\n+    if (tmpLogFile.exists()) {\n+      if (!tmpLogFile.delete()) {\n+        throw new IOException(\"Deleting \" + tmpLogFile + \"failed.\");\n+      }\n+    }\n+  }\n+\n+  public void clear() throws IOException {\n+    sync();\n+    logWriter.close();\n+    mlogBuffer.clear();\n+    if (logFile != null) {\n+      if (logFile.exists()) {\n+        Files.delete(logFile.toPath());\n+      }\n+    }\n+    logNum = 0;\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public int getLogNum() {\n+    return logNum;\n+  }\n+\n+  /**\n+   * only used for initialize a mlog file writer.\n+   */\n+  public void setLogNum(int number) {\n+    logNum = number;\n+  }\n+\n+  public void operation(String cmd) throws IOException, MetadataException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 281}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTEwNTczOQ==", "bodyText": "ok", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r489105739", "createdAt": "2020-09-16T01:21:50Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+      mlogBuffer.reset();\n+      sync();\n+      plan.serialize(mlogBuffer);\n+    }\n+    logNum ++;\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan plan, long offset) throws IOException {\n+    try {\n+      putLog(plan);\n+      ChangeTagOffsetPlan changeTagOffsetPlan = new ChangeTagOffsetPlan(plan.getPath(), offset);\n+      putLog(changeTagOffsetPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        \"Log cannot fit into buffer, please increase mlog_buffer_size\", e);\n+    }\n+  }\n+\n+  public static void upgradeMLog(String schemaDir, String logFileName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+        schemaDir + File.separator + MetadataConstant.METADATA_OLD_LOG);\n+\n+    if (oldLogFile.exists()) {\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, logFileName + \".tmp\");\n+        OldMLogReader oldMLogReader = new OldMLogReader(schemaDir, MetadataConstant.METADATA_OLD_LOG)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (oldMLogReader.hasNext()) {\n+          String cmd = oldMLogReader.next();\n+          try {\n+            mLogWriter.operation(cmd);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+\n+        return;\n+      }\n+    }\n+\n+    // if both old mlog and mlog.tmp do not exist, nothing to do\n+    if (!logFile.exists() && !tmpLogFile.exists()) {\n+      return;\n+    } else if (!logFile.exists() && tmpLogFile.exists()) {\n+      // if old mlog doesn't exist but mlog.tmp exists, rename tmp file to mlog\n+      FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+      return;\n+    }\n+\n+    // if both old mlog and mlog.tmp exist, delete mlog tmp, then do upgrading\n+    if (tmpLogFile.exists()) {\n+      if (!tmpLogFile.delete()) {\n+        throw new IOException(\"Deleting \" + tmpLogFile + \"failed.\");\n+      }\n+    }\n+  }\n+\n+  public void clear() throws IOException {\n+    sync();\n+    logWriter.close();\n+    mlogBuffer.clear();\n+    if (logFile != null) {\n+      if (logFile.exists()) {\n+        Files.delete(logFile.toPath());\n+      }\n+    }\n+    logNum = 0;\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public int getLogNum() {\n+    return logNum;\n+  }\n+\n+  /**\n+   * only used for initialize a mlog file writer.\n+   */\n+  public void setLogNum(int number) {\n+    logNum = number;\n+  }\n+\n+  public void operation(String cmd) throws IOException, MetadataException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkwNTEzOQ=="}, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 281}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjYzMzM4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/OldMLogReader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzoxOTo0NFrOHRTZFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzoxOTo0NFrOHRTZFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkwNTU1Ng==", "bodyText": "rename to MLogTXTReader or add a javadoc :  for reading mlog.txt", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487905556", "createdAt": "2020-09-14T13:19:44Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/OldMLogReader.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+\n+\n+public class OldMLogReader implements AutoCloseable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjY3NzI3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzoyODozNVrOHRTy0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMjo0ODozM1rOHTNc8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkxMjE0NQ==", "bodyText": "This is not an error case, change this to debug level is better. The case is: Allocate 16MB for buffer and put log into this buffer one by one, In the end, it always trigger the BufferOverflowException, just reseting the buffer is ok.\nHowever, if one log exceeds 16M, this will throw an exception.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487912145", "createdAt": "2020-09-14T13:28:35Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTkwNTM5NA==", "bodyText": "yes", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r489905394", "createdAt": "2020-09-17T02:48:33Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    // always flush\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public void close() throws IOException {\n+    sync();\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    mlogBuffer.mark();\n+    try {\n+      plan.serialize(mlogBuffer);\n+    } catch (BufferOverflowException e) {\n+      logger.error(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkxMjE0NQ=="}, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MjY5MjMyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzozMToxNFrOHRT7rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMjo0NToxOFrOHTNVGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkxNDQxNA==", "bodyText": "If using a buffer like WAL, we also need a thread to sync the buffer periodically like the forceTask in MultiFileLogNodeManager. Otherwise, the last logs in the buffer will never be persisted.\nOne option is to sync the mlog one by one.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487914414", "createdAt": "2020-09-14T13:31:14Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTkwMzM4Ng==", "bodyText": "yes, I think maybe we need to call the forceTask periodically. Because FileChannel.force(true) is more costful than bufferedWriter.flush, this will result in performance degradation of metadata operation.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r489903386", "createdAt": "2020-09-17T02:45:18Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import java.io.*;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.util.*;\n+\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.*;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkxNDQxNA=="}, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1Mjg0Mzk1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzo1MjoyNVrOHRVSZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwNTozNjo0NlrOHTSHMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkzNjYxMg==", "bodyText": "The XXMNodePlan is almost the same as the XXMNode, the structure is not a problem. But creating or recovering a snapshot may be slower in this way.  Better to test the performance. If the performance does not decrease a lot, this is acceptable. We could test 10M timeseries (10000 device * 1000 measurement)", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487936612", "createdAt": "2020-09-14T13:52:25Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1002,48 +1004,57 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    try (MLogWriter mLogWriter = new MLogWriter(snapshotPath)) {\n+      root.serializeTo(mLogWriter);\n     }\n   }\n \n   @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n   public static MTree deserializeFrom(File mtreeSnapshot) {\n-    try (BufferedReader br = new BufferedReader(new FileReader(mtreeSnapshot))) {\n-      String s;\n+\n+    try (MLogReader mlogReader = new MLogReader(mtreeSnapshot)) {\n       Deque<MNode> nodeStack = new ArrayDeque<>();\n       MNode node = null;\n \n-      while ((s = br.readLine()) != null) {\n-        String[] nodeInfo = s.split(\",\");\n-        short nodeType = Short.parseShort(nodeInfo[0]);\n-        if (nodeType == MetadataConstant.STORAGE_GROUP_MNODE_TYPE) {\n-          node = StorageGroupMNode.deserializeFrom(nodeInfo);\n-        } else if (nodeType == MetadataConstant.MEASUREMENT_MNODE_TYPE) {\n-          node = MeasurementMNode.deserializeFrom(nodeInfo);\n-        } else {\n-          node = new MNode(null, nodeInfo[1]);\n-        }\n+      while (mlogReader.hasNext()) {\n+        PhysicalPlan plan = null;\n+        try {\n+          plan = mlogReader.next();\n+          if (plan == null) {\n+            continue;\n+          }\n+          int childrenSize = 0;\n+          if (plan instanceof StorageGroupMNodePlan) {\n+            node = StorageGroupMNode.deserializeFrom((StorageGroupMNodePlan) plan);\n+            childrenSize = ((StorageGroupMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MeasurementMNodePlan) {\n+            node = MeasurementMNode.deserializeFrom((MeasurementMNodePlan) plan);\n+            childrenSize = ((MeasurementMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MNodePlan) {\n+            node = new MNode(null, ((MNodePlan) plan).getName());\n+            childrenSize = ((MNodePlan) plan).getChildSize();\n+          }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTkwMzUwMg==", "bodyText": "ok, I will do some tests.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r489903502", "createdAt": "2020-09-17T02:45:32Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1002,48 +1004,57 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    try (MLogWriter mLogWriter = new MLogWriter(snapshotPath)) {\n+      root.serializeTo(mLogWriter);\n     }\n   }\n \n   @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n   public static MTree deserializeFrom(File mtreeSnapshot) {\n-    try (BufferedReader br = new BufferedReader(new FileReader(mtreeSnapshot))) {\n-      String s;\n+\n+    try (MLogReader mlogReader = new MLogReader(mtreeSnapshot)) {\n       Deque<MNode> nodeStack = new ArrayDeque<>();\n       MNode node = null;\n \n-      while ((s = br.readLine()) != null) {\n-        String[] nodeInfo = s.split(\",\");\n-        short nodeType = Short.parseShort(nodeInfo[0]);\n-        if (nodeType == MetadataConstant.STORAGE_GROUP_MNODE_TYPE) {\n-          node = StorageGroupMNode.deserializeFrom(nodeInfo);\n-        } else if (nodeType == MetadataConstant.MEASUREMENT_MNODE_TYPE) {\n-          node = MeasurementMNode.deserializeFrom(nodeInfo);\n-        } else {\n-          node = new MNode(null, nodeInfo[1]);\n-        }\n+      while (mlogReader.hasNext()) {\n+        PhysicalPlan plan = null;\n+        try {\n+          plan = mlogReader.next();\n+          if (plan == null) {\n+            continue;\n+          }\n+          int childrenSize = 0;\n+          if (plan instanceof StorageGroupMNodePlan) {\n+            node = StorageGroupMNode.deserializeFrom((StorageGroupMNodePlan) plan);\n+            childrenSize = ((StorageGroupMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MeasurementMNodePlan) {\n+            node = MeasurementMNode.deserializeFrom((MeasurementMNodePlan) plan);\n+            childrenSize = ((MeasurementMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MNodePlan) {\n+            node = new MNode(null, ((MNodePlan) plan).getName());\n+            childrenSize = ((MNodePlan) plan).getChildSize();\n+          }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkzNjYxMg=="}, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTk4MTc0Nw==", "bodyText": "I have done some tests, 1M timeseries,  the cpu cost it almost same.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r489981747", "createdAt": "2020-09-17T05:36:46Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1002,48 +1004,57 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    try (MLogWriter mLogWriter = new MLogWriter(snapshotPath)) {\n+      root.serializeTo(mLogWriter);\n     }\n   }\n \n   @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n   public static MTree deserializeFrom(File mtreeSnapshot) {\n-    try (BufferedReader br = new BufferedReader(new FileReader(mtreeSnapshot))) {\n-      String s;\n+\n+    try (MLogReader mlogReader = new MLogReader(mtreeSnapshot)) {\n       Deque<MNode> nodeStack = new ArrayDeque<>();\n       MNode node = null;\n \n-      while ((s = br.readLine()) != null) {\n-        String[] nodeInfo = s.split(\",\");\n-        short nodeType = Short.parseShort(nodeInfo[0]);\n-        if (nodeType == MetadataConstant.STORAGE_GROUP_MNODE_TYPE) {\n-          node = StorageGroupMNode.deserializeFrom(nodeInfo);\n-        } else if (nodeType == MetadataConstant.MEASUREMENT_MNODE_TYPE) {\n-          node = MeasurementMNode.deserializeFrom(nodeInfo);\n-        } else {\n-          node = new MNode(null, nodeInfo[1]);\n-        }\n+      while (mlogReader.hasNext()) {\n+        PhysicalPlan plan = null;\n+        try {\n+          plan = mlogReader.next();\n+          if (plan == null) {\n+            continue;\n+          }\n+          int childrenSize = 0;\n+          if (plan instanceof StorageGroupMNodePlan) {\n+            node = StorageGroupMNode.deserializeFrom((StorageGroupMNodePlan) plan);\n+            childrenSize = ((StorageGroupMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MeasurementMNodePlan) {\n+            node = MeasurementMNode.deserializeFrom((MeasurementMNodePlan) plan);\n+            childrenSize = ((MeasurementMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MNodePlan) {\n+            node = new MNode(null, ((MNodePlan) plan).getName());\n+            childrenSize = ((MNodePlan) plan).getChildSize();\n+          }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkzNjYxMg=="}, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1Mjg3MzQxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzo1NjozN1rOHRVj_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxMzo1NjozN1rOHRVj_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzk0MTExNg==", "bodyText": "Pay attention to force mLogWriter before close it.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r487941116", "createdAt": "2020-09-14T13:56:37Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1002,48 +1004,57 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    try (MLogWriter mLogWriter = new MLogWriter(snapshotPath)) {\n+      root.serializeTo(mLogWriter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c6e0d44c946e6ac6a39caabe38dfbe533c982df"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDg0ODMyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjozMzowMVrOH4-wyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjozMzowMVrOH4-wyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxMDYwMQ==", "bodyText": "ConsoleReader reader is not used in this method : )", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529510601", "createdAt": "2020-11-24T12:33:01Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.tools.mlog;\n+\n+import jline.console.ConsoleReader;\n+import org.apache.commons.cli.CommandLine;\n+import org.apache.commons.cli.CommandLineParser;\n+import org.apache.commons.cli.DefaultParser;\n+import org.apache.commons.cli.HelpFormatter;\n+import org.apache.commons.cli.Option;\n+import org.apache.commons.cli.Options;\n+import org.apache.commons.cli.ParseException;\n+import org.apache.iotdb.db.metadata.MLogTxtWriter;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.logfile.MLogReader;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+/**\n+ * parse the binary mlog or snapshot to text\n+ */\n+public class MLogParser {\n+\n+  private static final String MLOG_CLI_PREFIX = \"MlogParser\";\n+\n+  private static final String FILE_ARGS = \"f\";\n+  private static final String FILE_NAME = \"mlog file\";\n+\n+  private static final String OUT_ARGS = \"o\";\n+  private static final String OUT_NAME = \"output txt file\";\n+\n+  private static final String HELP_ARGS = \"help\";\n+\n+  private static String inputFile;\n+  private static String outputFile;\n+\n+  /**\n+   * create the commandline options.\n+   *\n+   * @return object Options\n+   */\n+  public static Options createOptions() {\n+    Options options = new Options();\n+\n+    Option opFile = Option.builder(FILE_ARGS).required().argName(FILE_NAME).hasArg().desc(\n+      \"Need to specify a binary mlog file to parse (required)\")\n+      .build();\n+    options.addOption(opFile);\n+\n+    Option opOut = Option.builder(OUT_ARGS).required(false).argName(OUT_NAME).hasArg().desc(\n+      \"Could specify the output file after parse (optional)\")\n+      .build();\n+    options.addOption(opOut);\n+\n+    Option opHelp = Option.builder(HELP_ARGS).longOpt(HELP_ARGS)\n+      .hasArg(false).desc(\"Display help information\")\n+      .build();\n+    options.addOption(opHelp);\n+\n+    return options;\n+  }\n+\n+  public static void main(String[] args) throws IOException {\n+    Options options = createOptions();\n+    HelpFormatter hf = new HelpFormatter();\n+    hf.setOptionComparator(null);\n+    CommandLine commandLine;\n+    CommandLineParser parser = new DefaultParser();\n+\n+    if (args == null || args.length == 0) {\n+      System.out.println(\"Too few params input, please check the following hint.\");\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    try {\n+      commandLine = parser.parse(options, args);\n+    } catch (ParseException e) {\n+      System.out.println(\"Parse error: \" + e.getMessage());\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    if (commandLine.hasOption(HELP_ARGS)) {\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+\n+    ConsoleReader reader = new ConsoleReader();\n+    reader.setExpandEvents(false);\n+    try {\n+      parseBasicParams(commandLine, reader);\n+      parseFromFile(inputFile, outputFile);\n+    } catch (Exception e) {\n+      System.out.println(\"Encounter an error, because: \" + e.getMessage());\n+    } finally {\n+      reader.close();\n+    }\n+  }\n+\n+  public static void parseBasicParams(CommandLine commandLine, ConsoleReader reader) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDg3MjQ3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjozOToyNlrOH4--pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxNDowMlrOH5gfFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxNDE1MQ==", "bodyText": "It's not recommended to add braces {} here. Maybe we could extract pathList  outside the switch statement?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529514151", "createdAt": "2020-11-24T12:39:26Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.tools.mlog;\n+\n+import jline.console.ConsoleReader;\n+import org.apache.commons.cli.CommandLine;\n+import org.apache.commons.cli.CommandLineParser;\n+import org.apache.commons.cli.DefaultParser;\n+import org.apache.commons.cli.HelpFormatter;\n+import org.apache.commons.cli.Option;\n+import org.apache.commons.cli.Options;\n+import org.apache.commons.cli.ParseException;\n+import org.apache.iotdb.db.metadata.MLogTxtWriter;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.logfile.MLogReader;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+/**\n+ * parse the binary mlog or snapshot to text\n+ */\n+public class MLogParser {\n+\n+  private static final String MLOG_CLI_PREFIX = \"MlogParser\";\n+\n+  private static final String FILE_ARGS = \"f\";\n+  private static final String FILE_NAME = \"mlog file\";\n+\n+  private static final String OUT_ARGS = \"o\";\n+  private static final String OUT_NAME = \"output txt file\";\n+\n+  private static final String HELP_ARGS = \"help\";\n+\n+  private static String inputFile;\n+  private static String outputFile;\n+\n+  /**\n+   * create the commandline options.\n+   *\n+   * @return object Options\n+   */\n+  public static Options createOptions() {\n+    Options options = new Options();\n+\n+    Option opFile = Option.builder(FILE_ARGS).required().argName(FILE_NAME).hasArg().desc(\n+      \"Need to specify a binary mlog file to parse (required)\")\n+      .build();\n+    options.addOption(opFile);\n+\n+    Option opOut = Option.builder(OUT_ARGS).required(false).argName(OUT_NAME).hasArg().desc(\n+      \"Could specify the output file after parse (optional)\")\n+      .build();\n+    options.addOption(opOut);\n+\n+    Option opHelp = Option.builder(HELP_ARGS).longOpt(HELP_ARGS)\n+      .hasArg(false).desc(\"Display help information\")\n+      .build();\n+    options.addOption(opHelp);\n+\n+    return options;\n+  }\n+\n+  public static void main(String[] args) throws IOException {\n+    Options options = createOptions();\n+    HelpFormatter hf = new HelpFormatter();\n+    hf.setOptionComparator(null);\n+    CommandLine commandLine;\n+    CommandLineParser parser = new DefaultParser();\n+\n+    if (args == null || args.length == 0) {\n+      System.out.println(\"Too few params input, please check the following hint.\");\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    try {\n+      commandLine = parser.parse(options, args);\n+    } catch (ParseException e) {\n+      System.out.println(\"Parse error: \" + e.getMessage());\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    if (commandLine.hasOption(HELP_ARGS)) {\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+\n+    ConsoleReader reader = new ConsoleReader();\n+    reader.setExpandEvents(false);\n+    try {\n+      parseBasicParams(commandLine, reader);\n+      parseFromFile(inputFile, outputFile);\n+    } catch (Exception e) {\n+      System.out.println(\"Encounter an error, because: \" + e.getMessage());\n+    } finally {\n+      reader.close();\n+    }\n+  }\n+\n+  public static void parseBasicParams(CommandLine commandLine, ConsoleReader reader) throws Exception {\n+    inputFile = checkRequiredArg(FILE_ARGS, FILE_NAME, commandLine);\n+    outputFile = commandLine.getOptionValue(OUT_ARGS);\n+\n+    if (outputFile == null) {\n+      outputFile = \"tmp.txt\";\n+    }\n+  }\n+\n+  public static String checkRequiredArg(String arg, String name, CommandLine commandLine)\n+    throws Exception {\n+    String str = commandLine.getOptionValue(arg);\n+    if (str == null) {\n+      String msg = String.format(\"Required values for option '%s' not provided\", name);\n+      System.out.println(msg);\n+      System.out.println(\"Use -help for more information\");\n+      throw new Exception(msg);\n+    }\n+    return str;\n+  }\n+\n+  public static void parseFromFile(String inputFile, String outputFile) throws IOException {\n+    try (MLogReader mLogReader = new MLogReader(inputFile);\n+         MLogTxtWriter mLogTxtWriter = new MLogTxtWriter(outputFile)) {\n+\n+      while (mLogReader.hasNext()) {\n+        PhysicalPlan plan = mLogReader.next();\n+        switch (plan.getOperatorType()) {\n+          case CREATE_TIMESERIES:\n+            mLogTxtWriter.createTimeseries((CreateTimeSeriesPlan)plan,\n+              ((CreateTimeSeriesPlan) plan).getTagOffset());\n+            break;\n+          case DELETE_TIMESERIES: {\n+            List<PartialPath> pathList = plan.getPaths();\n+            for (PartialPath partialPath : pathList) {\n+              mLogTxtWriter.deleteTimeseries(partialPath.getFullPath());\n+            }\n+          }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MzEyNw==", "bodyText": "ok", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530063127", "createdAt": "2020-11-25T02:14:02Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.tools.mlog;\n+\n+import jline.console.ConsoleReader;\n+import org.apache.commons.cli.CommandLine;\n+import org.apache.commons.cli.CommandLineParser;\n+import org.apache.commons.cli.DefaultParser;\n+import org.apache.commons.cli.HelpFormatter;\n+import org.apache.commons.cli.Option;\n+import org.apache.commons.cli.Options;\n+import org.apache.commons.cli.ParseException;\n+import org.apache.iotdb.db.metadata.MLogTxtWriter;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.logfile.MLogReader;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+/**\n+ * parse the binary mlog or snapshot to text\n+ */\n+public class MLogParser {\n+\n+  private static final String MLOG_CLI_PREFIX = \"MlogParser\";\n+\n+  private static final String FILE_ARGS = \"f\";\n+  private static final String FILE_NAME = \"mlog file\";\n+\n+  private static final String OUT_ARGS = \"o\";\n+  private static final String OUT_NAME = \"output txt file\";\n+\n+  private static final String HELP_ARGS = \"help\";\n+\n+  private static String inputFile;\n+  private static String outputFile;\n+\n+  /**\n+   * create the commandline options.\n+   *\n+   * @return object Options\n+   */\n+  public static Options createOptions() {\n+    Options options = new Options();\n+\n+    Option opFile = Option.builder(FILE_ARGS).required().argName(FILE_NAME).hasArg().desc(\n+      \"Need to specify a binary mlog file to parse (required)\")\n+      .build();\n+    options.addOption(opFile);\n+\n+    Option opOut = Option.builder(OUT_ARGS).required(false).argName(OUT_NAME).hasArg().desc(\n+      \"Could specify the output file after parse (optional)\")\n+      .build();\n+    options.addOption(opOut);\n+\n+    Option opHelp = Option.builder(HELP_ARGS).longOpt(HELP_ARGS)\n+      .hasArg(false).desc(\"Display help information\")\n+      .build();\n+    options.addOption(opHelp);\n+\n+    return options;\n+  }\n+\n+  public static void main(String[] args) throws IOException {\n+    Options options = createOptions();\n+    HelpFormatter hf = new HelpFormatter();\n+    hf.setOptionComparator(null);\n+    CommandLine commandLine;\n+    CommandLineParser parser = new DefaultParser();\n+\n+    if (args == null || args.length == 0) {\n+      System.out.println(\"Too few params input, please check the following hint.\");\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    try {\n+      commandLine = parser.parse(options, args);\n+    } catch (ParseException e) {\n+      System.out.println(\"Parse error: \" + e.getMessage());\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    if (commandLine.hasOption(HELP_ARGS)) {\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+\n+    ConsoleReader reader = new ConsoleReader();\n+    reader.setExpandEvents(false);\n+    try {\n+      parseBasicParams(commandLine, reader);\n+      parseFromFile(inputFile, outputFile);\n+    } catch (Exception e) {\n+      System.out.println(\"Encounter an error, because: \" + e.getMessage());\n+    } finally {\n+      reader.close();\n+    }\n+  }\n+\n+  public static void parseBasicParams(CommandLine commandLine, ConsoleReader reader) throws Exception {\n+    inputFile = checkRequiredArg(FILE_ARGS, FILE_NAME, commandLine);\n+    outputFile = commandLine.getOptionValue(OUT_ARGS);\n+\n+    if (outputFile == null) {\n+      outputFile = \"tmp.txt\";\n+    }\n+  }\n+\n+  public static String checkRequiredArg(String arg, String name, CommandLine commandLine)\n+    throws Exception {\n+    String str = commandLine.getOptionValue(arg);\n+    if (str == null) {\n+      String msg = String.format(\"Required values for option '%s' not provided\", name);\n+      System.out.println(msg);\n+      System.out.println(\"Use -help for more information\");\n+      throw new Exception(msg);\n+    }\n+    return str;\n+  }\n+\n+  public static void parseFromFile(String inputFile, String outputFile) throws IOException {\n+    try (MLogReader mLogReader = new MLogReader(inputFile);\n+         MLogTxtWriter mLogTxtWriter = new MLogTxtWriter(outputFile)) {\n+\n+      while (mLogReader.hasNext()) {\n+        PhysicalPlan plan = mLogReader.next();\n+        switch (plan.getOperatorType()) {\n+          case CREATE_TIMESERIES:\n+            mLogTxtWriter.createTimeseries((CreateTimeSeriesPlan)plan,\n+              ((CreateTimeSeriesPlan) plan).getTagOffset());\n+            break;\n+          case DELETE_TIMESERIES: {\n+            List<PartialPath> pathList = plan.getPaths();\n+            for (PartialPath partialPath : pathList) {\n+              mLogTxtWriter.deleteTimeseries(partialPath.getFullPath());\n+            }\n+          }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxNDE1MQ=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 162}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDg3Mjk5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjozOTozNFrOH4-_AQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjozOTozNFrOH4-_AQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxNDI0MQ==", "bodyText": "... so that braces {} could also be omitted here", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529514241", "createdAt": "2020-11-24T12:39:34Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.tools.mlog;\n+\n+import jline.console.ConsoleReader;\n+import org.apache.commons.cli.CommandLine;\n+import org.apache.commons.cli.CommandLineParser;\n+import org.apache.commons.cli.DefaultParser;\n+import org.apache.commons.cli.HelpFormatter;\n+import org.apache.commons.cli.Option;\n+import org.apache.commons.cli.Options;\n+import org.apache.commons.cli.ParseException;\n+import org.apache.iotdb.db.metadata.MLogTxtWriter;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.logfile.MLogReader;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+/**\n+ * parse the binary mlog or snapshot to text\n+ */\n+public class MLogParser {\n+\n+  private static final String MLOG_CLI_PREFIX = \"MlogParser\";\n+\n+  private static final String FILE_ARGS = \"f\";\n+  private static final String FILE_NAME = \"mlog file\";\n+\n+  private static final String OUT_ARGS = \"o\";\n+  private static final String OUT_NAME = \"output txt file\";\n+\n+  private static final String HELP_ARGS = \"help\";\n+\n+  private static String inputFile;\n+  private static String outputFile;\n+\n+  /**\n+   * create the commandline options.\n+   *\n+   * @return object Options\n+   */\n+  public static Options createOptions() {\n+    Options options = new Options();\n+\n+    Option opFile = Option.builder(FILE_ARGS).required().argName(FILE_NAME).hasArg().desc(\n+      \"Need to specify a binary mlog file to parse (required)\")\n+      .build();\n+    options.addOption(opFile);\n+\n+    Option opOut = Option.builder(OUT_ARGS).required(false).argName(OUT_NAME).hasArg().desc(\n+      \"Could specify the output file after parse (optional)\")\n+      .build();\n+    options.addOption(opOut);\n+\n+    Option opHelp = Option.builder(HELP_ARGS).longOpt(HELP_ARGS)\n+      .hasArg(false).desc(\"Display help information\")\n+      .build();\n+    options.addOption(opHelp);\n+\n+    return options;\n+  }\n+\n+  public static void main(String[] args) throws IOException {\n+    Options options = createOptions();\n+    HelpFormatter hf = new HelpFormatter();\n+    hf.setOptionComparator(null);\n+    CommandLine commandLine;\n+    CommandLineParser parser = new DefaultParser();\n+\n+    if (args == null || args.length == 0) {\n+      System.out.println(\"Too few params input, please check the following hint.\");\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    try {\n+      commandLine = parser.parse(options, args);\n+    } catch (ParseException e) {\n+      System.out.println(\"Parse error: \" + e.getMessage());\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    if (commandLine.hasOption(HELP_ARGS)) {\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+\n+    ConsoleReader reader = new ConsoleReader();\n+    reader.setExpandEvents(false);\n+    try {\n+      parseBasicParams(commandLine, reader);\n+      parseFromFile(inputFile, outputFile);\n+    } catch (Exception e) {\n+      System.out.println(\"Encounter an error, because: \" + e.getMessage());\n+    } finally {\n+      reader.close();\n+    }\n+  }\n+\n+  public static void parseBasicParams(CommandLine commandLine, ConsoleReader reader) throws Exception {\n+    inputFile = checkRequiredArg(FILE_ARGS, FILE_NAME, commandLine);\n+    outputFile = commandLine.getOptionValue(OUT_ARGS);\n+\n+    if (outputFile == null) {\n+      outputFile = \"tmp.txt\";\n+    }\n+  }\n+\n+  public static String checkRequiredArg(String arg, String name, CommandLine commandLine)\n+    throws Exception {\n+    String str = commandLine.getOptionValue(arg);\n+    if (str == null) {\n+      String msg = String.format(\"Required values for option '%s' not provided\", name);\n+      System.out.println(msg);\n+      System.out.println(\"Use -help for more information\");\n+      throw new Exception(msg);\n+    }\n+    return str;\n+  }\n+\n+  public static void parseFromFile(String inputFile, String outputFile) throws IOException {\n+    try (MLogReader mLogReader = new MLogReader(inputFile);\n+         MLogTxtWriter mLogTxtWriter = new MLogTxtWriter(outputFile)) {\n+\n+      while (mLogReader.hasNext()) {\n+        PhysicalPlan plan = mLogReader.next();\n+        switch (plan.getOperatorType()) {\n+          case CREATE_TIMESERIES:\n+            mLogTxtWriter.createTimeseries((CreateTimeSeriesPlan)plan,\n+              ((CreateTimeSeriesPlan) plan).getTagOffset());\n+            break;\n+          case DELETE_TIMESERIES: {\n+            List<PartialPath> pathList = plan.getPaths();\n+            for (PartialPath partialPath : pathList) {\n+              mLogTxtWriter.deleteTimeseries(partialPath.getFullPath());\n+            }\n+          }\n+            break;\n+          case SET_STORAGE_GROUP:\n+            mLogTxtWriter.setStorageGroup(((SetStorageGroupPlan) plan).getPath().getFullPath());\n+            break;\n+          case DELETE_STORAGE_GROUP: {\n+            List<PartialPath> pathList = plan.getPaths();\n+            for (PartialPath partialPath : pathList) {\n+              mLogTxtWriter.deleteStorageGroup(partialPath.getFullPath());\n+            }\n+          }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 172}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDg3OTI1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo0MToxOFrOH4_CvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxNDoxMVrOH5gfPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxNTE5Nw==", "bodyText": "I suggest to define and throw a specific exception. What do you think?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529515197", "createdAt": "2020-11-24T12:41:18Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.tools.mlog;\n+\n+import jline.console.ConsoleReader;\n+import org.apache.commons.cli.CommandLine;\n+import org.apache.commons.cli.CommandLineParser;\n+import org.apache.commons.cli.DefaultParser;\n+import org.apache.commons.cli.HelpFormatter;\n+import org.apache.commons.cli.Option;\n+import org.apache.commons.cli.Options;\n+import org.apache.commons.cli.ParseException;\n+import org.apache.iotdb.db.metadata.MLogTxtWriter;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.logfile.MLogReader;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+/**\n+ * parse the binary mlog or snapshot to text\n+ */\n+public class MLogParser {\n+\n+  private static final String MLOG_CLI_PREFIX = \"MlogParser\";\n+\n+  private static final String FILE_ARGS = \"f\";\n+  private static final String FILE_NAME = \"mlog file\";\n+\n+  private static final String OUT_ARGS = \"o\";\n+  private static final String OUT_NAME = \"output txt file\";\n+\n+  private static final String HELP_ARGS = \"help\";\n+\n+  private static String inputFile;\n+  private static String outputFile;\n+\n+  /**\n+   * create the commandline options.\n+   *\n+   * @return object Options\n+   */\n+  public static Options createOptions() {\n+    Options options = new Options();\n+\n+    Option opFile = Option.builder(FILE_ARGS).required().argName(FILE_NAME).hasArg().desc(\n+      \"Need to specify a binary mlog file to parse (required)\")\n+      .build();\n+    options.addOption(opFile);\n+\n+    Option opOut = Option.builder(OUT_ARGS).required(false).argName(OUT_NAME).hasArg().desc(\n+      \"Could specify the output file after parse (optional)\")\n+      .build();\n+    options.addOption(opOut);\n+\n+    Option opHelp = Option.builder(HELP_ARGS).longOpt(HELP_ARGS)\n+      .hasArg(false).desc(\"Display help information\")\n+      .build();\n+    options.addOption(opHelp);\n+\n+    return options;\n+  }\n+\n+  public static void main(String[] args) throws IOException {\n+    Options options = createOptions();\n+    HelpFormatter hf = new HelpFormatter();\n+    hf.setOptionComparator(null);\n+    CommandLine commandLine;\n+    CommandLineParser parser = new DefaultParser();\n+\n+    if (args == null || args.length == 0) {\n+      System.out.println(\"Too few params input, please check the following hint.\");\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    try {\n+      commandLine = parser.parse(options, args);\n+    } catch (ParseException e) {\n+      System.out.println(\"Parse error: \" + e.getMessage());\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    if (commandLine.hasOption(HELP_ARGS)) {\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+\n+    ConsoleReader reader = new ConsoleReader();\n+    reader.setExpandEvents(false);\n+    try {\n+      parseBasicParams(commandLine, reader);\n+      parseFromFile(inputFile, outputFile);\n+    } catch (Exception e) {\n+      System.out.println(\"Encounter an error, because: \" + e.getMessage());\n+    } finally {\n+      reader.close();\n+    }\n+  }\n+\n+  public static void parseBasicParams(CommandLine commandLine, ConsoleReader reader) throws Exception {\n+    inputFile = checkRequiredArg(FILE_ARGS, FILE_NAME, commandLine);\n+    outputFile = commandLine.getOptionValue(OUT_ARGS);\n+\n+    if (outputFile == null) {\n+      outputFile = \"tmp.txt\";\n+    }\n+  }\n+\n+  public static String checkRequiredArg(String arg, String name, CommandLine commandLine)\n+    throws Exception {\n+    String str = commandLine.getOptionValue(arg);\n+    if (str == null) {\n+      String msg = String.format(\"Required values for option '%s' not provided\", name);\n+      System.out.println(msg);\n+      System.out.println(\"Use -help for more information\");\n+      throw new Exception(msg);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MzE2Nw==", "bodyText": "yes", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530063167", "createdAt": "2020-11-25T02:14:11Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.tools.mlog;\n+\n+import jline.console.ConsoleReader;\n+import org.apache.commons.cli.CommandLine;\n+import org.apache.commons.cli.CommandLineParser;\n+import org.apache.commons.cli.DefaultParser;\n+import org.apache.commons.cli.HelpFormatter;\n+import org.apache.commons.cli.Option;\n+import org.apache.commons.cli.Options;\n+import org.apache.commons.cli.ParseException;\n+import org.apache.iotdb.db.metadata.MLogTxtWriter;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.logfile.MLogReader;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+/**\n+ * parse the binary mlog or snapshot to text\n+ */\n+public class MLogParser {\n+\n+  private static final String MLOG_CLI_PREFIX = \"MlogParser\";\n+\n+  private static final String FILE_ARGS = \"f\";\n+  private static final String FILE_NAME = \"mlog file\";\n+\n+  private static final String OUT_ARGS = \"o\";\n+  private static final String OUT_NAME = \"output txt file\";\n+\n+  private static final String HELP_ARGS = \"help\";\n+\n+  private static String inputFile;\n+  private static String outputFile;\n+\n+  /**\n+   * create the commandline options.\n+   *\n+   * @return object Options\n+   */\n+  public static Options createOptions() {\n+    Options options = new Options();\n+\n+    Option opFile = Option.builder(FILE_ARGS).required().argName(FILE_NAME).hasArg().desc(\n+      \"Need to specify a binary mlog file to parse (required)\")\n+      .build();\n+    options.addOption(opFile);\n+\n+    Option opOut = Option.builder(OUT_ARGS).required(false).argName(OUT_NAME).hasArg().desc(\n+      \"Could specify the output file after parse (optional)\")\n+      .build();\n+    options.addOption(opOut);\n+\n+    Option opHelp = Option.builder(HELP_ARGS).longOpt(HELP_ARGS)\n+      .hasArg(false).desc(\"Display help information\")\n+      .build();\n+    options.addOption(opHelp);\n+\n+    return options;\n+  }\n+\n+  public static void main(String[] args) throws IOException {\n+    Options options = createOptions();\n+    HelpFormatter hf = new HelpFormatter();\n+    hf.setOptionComparator(null);\n+    CommandLine commandLine;\n+    CommandLineParser parser = new DefaultParser();\n+\n+    if (args == null || args.length == 0) {\n+      System.out.println(\"Too few params input, please check the following hint.\");\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    try {\n+      commandLine = parser.parse(options, args);\n+    } catch (ParseException e) {\n+      System.out.println(\"Parse error: \" + e.getMessage());\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    if (commandLine.hasOption(HELP_ARGS)) {\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+\n+    ConsoleReader reader = new ConsoleReader();\n+    reader.setExpandEvents(false);\n+    try {\n+      parseBasicParams(commandLine, reader);\n+      parseFromFile(inputFile, outputFile);\n+    } catch (Exception e) {\n+      System.out.println(\"Encounter an error, because: \" + e.getMessage());\n+    } finally {\n+      reader.close();\n+    }\n+  }\n+\n+  public static void parseBasicParams(CommandLine commandLine, ConsoleReader reader) throws Exception {\n+    inputFile = checkRequiredArg(FILE_ARGS, FILE_NAME, commandLine);\n+    outputFile = commandLine.getOptionValue(OUT_ARGS);\n+\n+    if (outputFile == null) {\n+      outputFile = \"tmp.txt\";\n+    }\n+  }\n+\n+  public static String checkRequiredArg(String arg, String name, CommandLine commandLine)\n+    throws Exception {\n+    String str = commandLine.getOptionValue(arg);\n+    if (str == null) {\n+      String msg = String.format(\"Required values for option '%s' not provided\", name);\n+      System.out.println(msg);\n+      System.out.println(\"Use -help for more information\");\n+      throw new Exception(msg);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxNTE5Nw=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDg4MDYyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo0MTozOFrOH4_DlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo0MTozOFrOH4_DlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxNTQxMw==", "bodyText": "... and this Exception could be more specific as well", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529515413", "createdAt": "2020-11-24T12:41:38Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.tools.mlog;\n+\n+import jline.console.ConsoleReader;\n+import org.apache.commons.cli.CommandLine;\n+import org.apache.commons.cli.CommandLineParser;\n+import org.apache.commons.cli.DefaultParser;\n+import org.apache.commons.cli.HelpFormatter;\n+import org.apache.commons.cli.Option;\n+import org.apache.commons.cli.Options;\n+import org.apache.commons.cli.ParseException;\n+import org.apache.iotdb.db.metadata.MLogTxtWriter;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.logfile.MLogReader;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+/**\n+ * parse the binary mlog or snapshot to text\n+ */\n+public class MLogParser {\n+\n+  private static final String MLOG_CLI_PREFIX = \"MlogParser\";\n+\n+  private static final String FILE_ARGS = \"f\";\n+  private static final String FILE_NAME = \"mlog file\";\n+\n+  private static final String OUT_ARGS = \"o\";\n+  private static final String OUT_NAME = \"output txt file\";\n+\n+  private static final String HELP_ARGS = \"help\";\n+\n+  private static String inputFile;\n+  private static String outputFile;\n+\n+  /**\n+   * create the commandline options.\n+   *\n+   * @return object Options\n+   */\n+  public static Options createOptions() {\n+    Options options = new Options();\n+\n+    Option opFile = Option.builder(FILE_ARGS).required().argName(FILE_NAME).hasArg().desc(\n+      \"Need to specify a binary mlog file to parse (required)\")\n+      .build();\n+    options.addOption(opFile);\n+\n+    Option opOut = Option.builder(OUT_ARGS).required(false).argName(OUT_NAME).hasArg().desc(\n+      \"Could specify the output file after parse (optional)\")\n+      .build();\n+    options.addOption(opOut);\n+\n+    Option opHelp = Option.builder(HELP_ARGS).longOpt(HELP_ARGS)\n+      .hasArg(false).desc(\"Display help information\")\n+      .build();\n+    options.addOption(opHelp);\n+\n+    return options;\n+  }\n+\n+  public static void main(String[] args) throws IOException {\n+    Options options = createOptions();\n+    HelpFormatter hf = new HelpFormatter();\n+    hf.setOptionComparator(null);\n+    CommandLine commandLine;\n+    CommandLineParser parser = new DefaultParser();\n+\n+    if (args == null || args.length == 0) {\n+      System.out.println(\"Too few params input, please check the following hint.\");\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    try {\n+      commandLine = parser.parse(options, args);\n+    } catch (ParseException e) {\n+      System.out.println(\"Parse error: \" + e.getMessage());\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+    if (commandLine.hasOption(HELP_ARGS)) {\n+      hf.printHelp(MLOG_CLI_PREFIX, options, true);\n+      return;\n+    }\n+\n+    ConsoleReader reader = new ConsoleReader();\n+    reader.setExpandEvents(false);\n+    try {\n+      parseBasicParams(commandLine, reader);\n+      parseFromFile(inputFile, outputFile);\n+    } catch (Exception e) {\n+      System.out.println(\"Encounter an error, because: \" + e.getMessage());\n+    } finally {\n+      reader.close();\n+    }\n+  }\n+\n+  public static void parseBasicParams(CommandLine commandLine, ConsoleReader reader) throws Exception {\n+    inputFile = checkRequiredArg(FILE_ARGS, FILE_NAME, commandLine);\n+    outputFile = commandLine.getOptionValue(OUT_ARGS);\n+\n+    if (outputFile == null) {\n+      outputFile = \"tmp.txt\";\n+    }\n+  }\n+\n+  public static String checkRequiredArg(String arg, String name, CommandLine commandLine)\n+    throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDg4NDQ5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/qp/physical/sys/StorageGroupMNodePlan.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo0Mjo0OVrOH4_GCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo0Mjo0OVrOH4_GCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxNjA0Mg==", "bodyText": "Remove unused import", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529516042", "createdAt": "2020-11-24T12:42:49Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/qp/physical/sys/StorageGroupMNodePlan.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iotdb.db.qp.physical.sys;\n+\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.qp.logical.Operator;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDkwMzA4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogTxtReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo0Nzo0MVrOH4_RPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo0Nzo0MVrOH4_RPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUxODkwOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private static final Logger logger = LoggerFactory.getLogger(MLogReader.class);\n          \n          \n            \n              private static final Logger logger = LoggerFactory.getLogger(MLogTxtReader.class);", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529518908", "createdAt": "2020-11-24T12:47:41Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogTxtReader.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+\n+/**\n+ * reader for reading mlog.txt\n+ */\n+public class MLogTxtReader implements AutoCloseable {\n+  private static final Logger logger = LoggerFactory.getLogger(MLogReader.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDkyNTEwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo1MzoyN1rOH4_eZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxNDoyOVrOH5gfog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUyMjI3Ng==", "bodyText": "Refactor as below may be more logical:\n        if (childrenSize != 0) {\n            ConcurrentHashMap<String, MNode> childrenMap = new ConcurrentHashMap<>();\n            for (int i = 0; i < childrenSize; i++) {\n              MNode child = nodeStack.removeFirst();\n              child.setParent(node);\n              childrenMap.put(child.getName(), child);\n              if (child instanceof MeasurementMNode) {\n                String alias = ((MeasurementMNode) child).getAlias();\n                if (alias != null) {\n                  node.addAlias(alias, child);\n                }\n              }\n            }\n            node.setChildren(childrenMap);\n          }\n          nodeStack.push(node);\n        }", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529522276", "createdAt": "2020-11-24T12:53:27Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1262,9 +1214,68 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    try (MLogWriter mLogWriter = new MLogWriter(snapshotPath)) {\n+      root.serializeTo(mLogWriter);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n+  public static MTree deserializeFrom(File mtreeSnapshot) {\n+\n+    try (MLogReader mlogReader = new MLogReader(mtreeSnapshot)) {\n+      Deque<MNode> nodeStack = new ArrayDeque<>();\n+      MNode node = null;\n+\n+      while (mlogReader.hasNext()) {\n+        PhysicalPlan plan = null;\n+        try {\n+          plan = mlogReader.next();\n+          if (plan == null) {\n+            continue;\n+          }\n+          int childrenSize = 0;\n+          if (plan instanceof StorageGroupMNodePlan) {\n+            node = StorageGroupMNode.deserializeFrom((StorageGroupMNodePlan) plan);\n+            childrenSize = ((StorageGroupMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MeasurementMNodePlan) {\n+            node = MeasurementMNode.deserializeFrom((MeasurementMNodePlan) plan);\n+            childrenSize = ((MeasurementMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MNodePlan) {\n+            node = new MNode(null, ((MNodePlan) plan).getName());\n+            childrenSize = ((MNodePlan) plan).getChildSize();\n+          }\n+\n+          if (childrenSize == 0) {\n+            nodeStack.push(node);\n+          } else {\n+            ConcurrentHashMap<String, MNode> childrenMap = new ConcurrentHashMap<>();\n+            for (int i = 0; i < childrenSize; i++) {\n+              MNode child = nodeStack.removeFirst();\n+              child.setParent(node);\n+              childrenMap.put(child.getName(), child);\n+              if (child instanceof MeasurementMNode) {\n+                String alias = ((MeasurementMNode) child).getAlias();\n+                if (alias != null) {\n+                  node.addAlias(alias, child);\n+                }\n+              }\n+            }\n+            node.setChildren(childrenMap);\n+            nodeStack.push(node);\n+          }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MzI2Ng==", "bodyText": "Good idea!", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530063266", "createdAt": "2020-11-25T02:14:29Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1262,9 +1214,68 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    try (MLogWriter mLogWriter = new MLogWriter(snapshotPath)) {\n+      root.serializeTo(mLogWriter);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n+  public static MTree deserializeFrom(File mtreeSnapshot) {\n+\n+    try (MLogReader mlogReader = new MLogReader(mtreeSnapshot)) {\n+      Deque<MNode> nodeStack = new ArrayDeque<>();\n+      MNode node = null;\n+\n+      while (mlogReader.hasNext()) {\n+        PhysicalPlan plan = null;\n+        try {\n+          plan = mlogReader.next();\n+          if (plan == null) {\n+            continue;\n+          }\n+          int childrenSize = 0;\n+          if (plan instanceof StorageGroupMNodePlan) {\n+            node = StorageGroupMNode.deserializeFrom((StorageGroupMNodePlan) plan);\n+            childrenSize = ((StorageGroupMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MeasurementMNodePlan) {\n+            node = MeasurementMNode.deserializeFrom((MeasurementMNodePlan) plan);\n+            childrenSize = ((MeasurementMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MNodePlan) {\n+            node = new MNode(null, ((MNodePlan) plan).getName());\n+            childrenSize = ((MNodePlan) plan).getChildSize();\n+          }\n+\n+          if (childrenSize == 0) {\n+            nodeStack.push(node);\n+          } else {\n+            ConcurrentHashMap<String, MNode> childrenMap = new ConcurrentHashMap<>();\n+            for (int i = 0; i < childrenSize; i++) {\n+              MNode child = nodeStack.removeFirst();\n+              child.setParent(node);\n+              childrenMap.put(child.getName(), child);\n+              if (child instanceof MeasurementMNode) {\n+                String alias = ((MeasurementMNode) child).getAlias();\n+                if (alias != null) {\n+                  node.addAlias(alias, child);\n+                }\n+              }\n+            }\n+            node.setChildren(childrenMap);\n+            nodeStack.push(node);\n+          }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUyMjI3Ng=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDkyOTE1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo1NDoxN1rOH4_gpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMDowMjo1OVrOH5r0xQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUyMjg1NA==", "bodyText": "Maybe this Exception could be more specific too?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529522854", "createdAt": "2020-11-24T12:54:17Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1262,9 +1214,68 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    try (MLogWriter mLogWriter = new MLogWriter(snapshotPath)) {\n+      root.serializeTo(mLogWriter);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n+  public static MTree deserializeFrom(File mtreeSnapshot) {\n+\n+    try (MLogReader mlogReader = new MLogReader(mtreeSnapshot)) {\n+      Deque<MNode> nodeStack = new ArrayDeque<>();\n+      MNode node = null;\n+\n+      while (mlogReader.hasNext()) {\n+        PhysicalPlan plan = null;\n+        try {\n+          plan = mlogReader.next();\n+          if (plan == null) {\n+            continue;\n+          }\n+          int childrenSize = 0;\n+          if (plan instanceof StorageGroupMNodePlan) {\n+            node = StorageGroupMNode.deserializeFrom((StorageGroupMNodePlan) plan);\n+            childrenSize = ((StorageGroupMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MeasurementMNodePlan) {\n+            node = MeasurementMNode.deserializeFrom((MeasurementMNodePlan) plan);\n+            childrenSize = ((MeasurementMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MNodePlan) {\n+            node = new MNode(null, ((MNodePlan) plan).getName());\n+            childrenSize = ((MNodePlan) plan).getChildSize();\n+          }\n+\n+          if (childrenSize == 0) {\n+            nodeStack.push(node);\n+          } else {\n+            ConcurrentHashMap<String, MNode> childrenMap = new ConcurrentHashMap<>();\n+            for (int i = 0; i < childrenSize; i++) {\n+              MNode child = nodeStack.removeFirst();\n+              child.setParent(node);\n+              childrenMap.put(child.getName(), child);\n+              if (child instanceof MeasurementMNode) {\n+                String alias = ((MeasurementMNode) child).getAlias();\n+                if (alias != null) {\n+                  node.addAlias(alias, child);\n+                }\n+              }\n+            }\n+            node.setChildren(childrenMap);\n+            nodeStack.push(node);\n+          }\n+        } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDI0ODkwMQ==", "bodyText": "catch all exception", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530248901", "createdAt": "2020-11-25T10:02:59Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MTree.java", "diffHunk": "@@ -1262,9 +1214,68 @@ private void findNodes(MNode node, PartialPath path, List<PartialPath> res, int\n   }\n \n   public void serializeTo(String snapshotPath) throws IOException {\n-    try (BufferedWriter bw = new BufferedWriter(\n-        new FileWriter(SystemFileFactory.INSTANCE.getFile(snapshotPath)))) {\n-      root.serializeTo(bw);\n+    try (MLogWriter mLogWriter = new MLogWriter(snapshotPath)) {\n+      root.serializeTo(mLogWriter);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n+  public static MTree deserializeFrom(File mtreeSnapshot) {\n+\n+    try (MLogReader mlogReader = new MLogReader(mtreeSnapshot)) {\n+      Deque<MNode> nodeStack = new ArrayDeque<>();\n+      MNode node = null;\n+\n+      while (mlogReader.hasNext()) {\n+        PhysicalPlan plan = null;\n+        try {\n+          plan = mlogReader.next();\n+          if (plan == null) {\n+            continue;\n+          }\n+          int childrenSize = 0;\n+          if (plan instanceof StorageGroupMNodePlan) {\n+            node = StorageGroupMNode.deserializeFrom((StorageGroupMNodePlan) plan);\n+            childrenSize = ((StorageGroupMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MeasurementMNodePlan) {\n+            node = MeasurementMNode.deserializeFrom((MeasurementMNodePlan) plan);\n+            childrenSize = ((MeasurementMNodePlan) plan).getChildSize();\n+          } else if (plan instanceof MNodePlan) {\n+            node = new MNode(null, ((MNodePlan) plan).getName());\n+            childrenSize = ((MNodePlan) plan).getChildSize();\n+          }\n+\n+          if (childrenSize == 0) {\n+            nodeStack.push(node);\n+          } else {\n+            ConcurrentHashMap<String, MNode> childrenMap = new ConcurrentHashMap<>();\n+            for (int i = 0; i < childrenSize; i++) {\n+              MNode child = nodeStack.removeFirst();\n+              child.setParent(node);\n+              childrenMap.put(child.getName(), child);\n+              if (child instanceof MeasurementMNode) {\n+                String alias = ((MeasurementMNode) child).getAlias();\n+                if (alias != null) {\n+                  node.addAlias(alias, child);\n+                }\n+              }\n+            }\n+            node.setChildren(childrenMap);\n+            nodeStack.push(node);\n+          }\n+        } catch (Exception e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUyMjg1NA=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 142}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMDk1MDk4OnYy", "diffSide": "LEFT", "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxMjo1OTo0MlrOH4_tpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMDowMTo1NVrOH5rx9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUyNjE4MQ==", "bodyText": "Do you think it is necessary to delete all these codes (upgradePropertiesFile, checkUnClosedTsFileV2, checkUnClosedTsFileV2InFolders) now? I think this check should be modified before 0.12 is released... Or the users who are using v0.9 and intending to upgrade to master may encounter problems ... @qiaojialin", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r529526181", "createdAt": "2020-11-24T12:59:42Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -184,51 +185,16 @@ public void checkConfig() throws IOException {\n             inputStream, TSFileConfig.STRING_CHARSET)) {\n       properties.load(inputStreamReader);\n     }\n-    // check whether upgrading from v0.9 to v0.11", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA0ODQ2MA==", "bodyText": "Agree with @samperson1997", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530048460", "createdAt": "2020-11-25T01:25:06Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -184,51 +185,16 @@ public void checkConfig() throws IOException {\n             inputStream, TSFileConfig.STRING_CHARSET)) {\n       properties.load(inputStreamReader);\n     }\n-    // check whether upgrading from v0.9 to v0.11", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUyNjE4MQ=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MzA0Mw==", "bodyText": "I think user should upgrade to 0.11, then upgrade to 0.12. So the function is not useful in 0.12.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530063043", "createdAt": "2020-11-25T02:13:44Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -184,51 +185,16 @@ public void checkConfig() throws IOException {\n             inputStream, TSFileConfig.STRING_CHARSET)) {\n       properties.load(inputStreamReader);\n     }\n-    // check whether upgrading from v0.9 to v0.11", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUyNjE4MQ=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2NjY5MA==", "bodyText": "I mean these methods could be left here. I'll modify and reuse these methods when I implement the upgrade tool.  For now, I think it is OK to do not call these methods.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530066690", "createdAt": "2020-11-25T02:25:29Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -184,51 +185,16 @@ public void checkConfig() throws IOException {\n             inputStream, TSFileConfig.STRING_CHARSET)) {\n       properties.load(inputStreamReader);\n     }\n-    // check whether upgrading from v0.9 to v0.11", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUyNjE4MQ=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDI0ODE4Mg==", "bodyText": "ok", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530248182", "createdAt": "2020-11-25T10:01:55Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -184,51 +185,16 @@ public void checkConfig() throws IOException {\n             inputStream, TSFileConfig.STRING_CHARSET)) {\n       properties.load(inputStreamReader);\n     }\n-    // check whether upgrading from v0.9 to v0.11", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUyNjE4MQ=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDIyMTk4OnYy", "diffSide": "RIGHT", "path": "docs/UserGuide/System Tools/MLogParser Tool.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMToxNjowNVrOH5fayA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxNTowM1rOH5ggUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA0NTY0MA==", "bodyText": "It should be ./mLogParser.sh -f /your path/mlog.bin -o /your path/mlog.txt?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530045640", "createdAt": "2020-11-25T01:16:05Z", "author": {"login": "HTHou"}, "path": "docs/UserGuide/System Tools/MLogParser Tool.md", "diffHunk": "@@ -0,0 +1,37 @@\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+\n+# What\n+\n+After version 0.12.x, IoTDB encodes metadata files into binary format.\n+\n+If you want to parse metadata into a human readable way, you can use this tool to parse the specified metadata file.\n+\n+The tool can parse snapshot files and mlog files.\n+\n+# How to use\n+\n+Linux/MacOS\n+> ./mLogParser.sh -f /your path/mlog.bin -o \\your path\\mlog.txt", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MzQ0MA==", "bodyText": "yes", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530063440", "createdAt": "2020-11-25T02:15:03Z", "author": {"login": "mychaow"}, "path": "docs/UserGuide/System Tools/MLogParser Tool.md", "diffHunk": "@@ -0,0 +1,37 @@\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+\n+# What\n+\n+After version 0.12.x, IoTDB encodes metadata files into binary format.\n+\n+If you want to parse metadata into a human readable way, you can use this tool to parse the specified metadata file.\n+\n+The tool can parse snapshot files and mlog files.\n+\n+# How to use\n+\n+Linux/MacOS\n+> ./mLogParser.sh -f /your path/mlog.bin -o \\your path\\mlog.txt", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA0NTY0MA=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDIyNTQ0OnYy", "diffSide": "RIGHT", "path": "docs/zh/UserGuide/System Tools/MLogParser Tool.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMToxNzozM1rOH5fcsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMToxNzozM1rOH5fcsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA0NjEyOA==", "bodyText": "Same as above", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530046128", "createdAt": "2020-11-25T01:17:33Z", "author": {"login": "HTHou"}, "path": "docs/zh/UserGuide/System Tools/MLogParser Tool.md", "diffHunk": "@@ -0,0 +1,37 @@\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+\n+# \u5de5\u5177\u8bf4\u660e\n+\n+0.12.x\u7248\u672c\u4e4b\u540e\uff0cIoTDB\u5c06\u5143\u6570\u636e\u6587\u4ef6\u7f16\u7801\u6210\u4e8c\u8fdb\u5236\u3002\n+\n+\u5982\u679c\u60f3\u8981\u89e3\u6790\u5143\u6570\u636e\u6210\u4eba\u53ef\u8bfb\u7684\u65b9\u5f0f\uff0c\u53ef\u4ee5\u4f7f\u7528\u672c\u5de5\u5177\u6765\u89e3\u6790\u6307\u5b9a\u5143\u6570\u636e\u6587\u4ef6\u3002\n+\n+\u8be5\u5de5\u5177\u53ef\u4ee5\u540c\u65f6\u89e3\u6790snapshot\u6587\u4ef6\u548cmlog\u6587\u4ef6\u3002\n+\n+# \u4f7f\u7528\u65b9\u5f0f\n+\n+Linux/MacOS\n+> ./mLogParser.sh -f /your path/mlog.bin -o \\your path\\mlog.txt", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDMzNTI5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxMDoyMVrOH5ga3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxNTo1MlrOH5ghTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MjA0Nw==", "bodyText": "If there is a comma in the path of a timeseries, the length of args[] will be larger than 8.\nI think adding these lines back is better.\n        if (args.length > 8) {\t\n          String[] tmpArgs = new String[8];\t\n          tmpArgs[0] = args[0];\t\n          int i = 1;\t\n          tmpArgs[1] = \"\";\t\n          for (; i < args.length - 7; i++) {\t\n            tmpArgs[1] += args[i] + \",\";\t\n          }\t\n          tmpArgs[1] += args[i++];\t\n          for (int j = 2; j < 8; j++) {\t\n            tmpArgs[j] = args[i++];\t\n          }\t\n          args = tmpArgs;\t\n        }", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530062047", "createdAt": "2020-11-25T02:10:21Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,424 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.apache.iotdb.tsfile.write.schema.MeasurementSchema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  // we write log to channel every time, so we need not to call channel.force every time\n+  private static final long DUMMY_FLUSH_TIME = 100;\n+  private static final String LOG_TOO_LARGE_INFO = \"Log cannot fit into buffer, please increase mlog_buffer_size\";\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    try {\n+      plan.serialize(mlogBuffer);\n+      sync();\n+      logNum ++;\n+    } catch (BufferOverflowException e) {\n+      logger.warn(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+    }\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan createTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(createTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public static void upgradeTxtToBin(String schemaDir, String oldFileName,\n+                                     String newFileName, boolean isSnapshot) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + newFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+      schemaDir + File.separator + oldFileName);\n+    File tmpOldLogFile = SystemFileFactory.INSTANCE.getFile(oldLogFile.getAbsolutePath()\n+      + \".tmp\");\n+\n+    if (oldLogFile.exists() || tmpOldLogFile.exists()) {\n+\n+      if (tmpOldLogFile.exists() && !oldLogFile.exists()) {\n+        FileUtils.moveFile(tmpOldLogFile, oldLogFile);\n+      }\n+\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, newFileName + \".tmp\");\n+           MLogTxtReader mLogTxtReader = new MLogTxtReader(schemaDir, oldFileName)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (mLogTxtReader.hasNext()) {\n+          String cmd = mLogTxtReader.next();\n+          try {\n+            mLogWriter.operation(cmd, isSnapshot);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+      }\n+    } else if (!logFile.exists() && !tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp do not exist, nothing to do\n+    } else if (!logFile.exists() && tmpLogFile.exists()) {\n+      // if old .bin doesn't exist but .bin.tmp exists, rename tmp file to .bin\n+      FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+    } else if (tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp exist, delete .bin.tmp\n+      try {\n+        Files.delete(Paths.get(tmpLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(\"Deleting \" + tmpLogFile + \"failed with exception \" + e.getMessage());\n+      }\n+    }\n+\n+    // do some clean job\n+    // remove old .txt and .txt.tmp\n+    if (oldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(oldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(\"Deleting \" + oldLogFile + \"failed with exception \" + e.getMessage());\n+      }\n+    }\n+\n+    if (tmpOldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(tmpOldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(\"Deleting \" + tmpOldLogFile + \"failed with exception \" + e.getMessage());\n+      }\n+    }\n+\n+    // rename .bin.tmp to .bin\n+    FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+  }\n+\n+  public static void upgradeMLog() throws IOException {\n+    String schemaDir = IoTDBDescriptor.getInstance().getConfig().getSchemaDir();\n+    upgradeTxtToBin(schemaDir, MetadataConstant.METADATA_TXT_LOG, MetadataConstant.METADATA_LOG, false);\n+    upgradeTxtToBin(schemaDir, MetadataConstant.MTREE_TXT_SNAPSHOT, MetadataConstant.MTREE_SNAPSHOT, true);\n+  }\n+\n+  public void clear() throws IOException {\n+    sync();\n+    logWriter.close();\n+    mlogBuffer.clear();\n+    if (logFile != null && logFile.exists()) {\n+      Files.delete(logFile.toPath());\n+    }\n+    logNum = 0;\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public int getLogNum() {\n+    return logNum;\n+  }\n+\n+  /**\n+   * only used for initialize a mlog file writer.\n+   */\n+  public void setLogNum(int number) {\n+    logNum = number;\n+  }\n+\n+  public void operation(String cmd, boolean isSnapshot) throws IOException, MetadataException {\n+    if (!isSnapshot) {\n+      operation(cmd);\n+    } else {\n+      PhysicalPlan plan = convertFromString(cmd);\n+      try {\n+        if (plan != null) {\n+          putLog(plan);\n+        }\n+      } catch (BufferOverflowException e) {\n+        throw new IOException(\n+          LOG_TOO_LARGE_INFO, e);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * upgrade from mlog.txt to mlog.bin\n+   * @param cmd, the old meta operation\n+   * @throws IOException\n+   * @throws MetadataException\n+   */\n+  public void operation(String cmd) throws IOException, MetadataException {\n+    // see createTimeseries() to get the detailed format of the cmd\n+    String[] args = cmd.trim().split(\",\", -1);\n+    switch (args[0]) {\n+      case MetadataOperationType.CREATE_TIMESERIES:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 346}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MzY5NQ==", "bodyText": "ok", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530063695", "createdAt": "2020-11-25T02:15:52Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,424 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.apache.iotdb.tsfile.write.schema.MeasurementSchema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  // we write log to channel every time, so we need not to call channel.force every time\n+  private static final long DUMMY_FLUSH_TIME = 100;\n+  private static final String LOG_TOO_LARGE_INFO = \"Log cannot fit into buffer, please increase mlog_buffer_size\";\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    try {\n+      plan.serialize(mlogBuffer);\n+      sync();\n+      logNum ++;\n+    } catch (BufferOverflowException e) {\n+      logger.warn(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+    }\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan createTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(createTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public static void upgradeTxtToBin(String schemaDir, String oldFileName,\n+                                     String newFileName, boolean isSnapshot) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + newFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+      schemaDir + File.separator + oldFileName);\n+    File tmpOldLogFile = SystemFileFactory.INSTANCE.getFile(oldLogFile.getAbsolutePath()\n+      + \".tmp\");\n+\n+    if (oldLogFile.exists() || tmpOldLogFile.exists()) {\n+\n+      if (tmpOldLogFile.exists() && !oldLogFile.exists()) {\n+        FileUtils.moveFile(tmpOldLogFile, oldLogFile);\n+      }\n+\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, newFileName + \".tmp\");\n+           MLogTxtReader mLogTxtReader = new MLogTxtReader(schemaDir, oldFileName)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (mLogTxtReader.hasNext()) {\n+          String cmd = mLogTxtReader.next();\n+          try {\n+            mLogWriter.operation(cmd, isSnapshot);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+      }\n+    } else if (!logFile.exists() && !tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp do not exist, nothing to do\n+    } else if (!logFile.exists() && tmpLogFile.exists()) {\n+      // if old .bin doesn't exist but .bin.tmp exists, rename tmp file to .bin\n+      FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+    } else if (tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp exist, delete .bin.tmp\n+      try {\n+        Files.delete(Paths.get(tmpLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(\"Deleting \" + tmpLogFile + \"failed with exception \" + e.getMessage());\n+      }\n+    }\n+\n+    // do some clean job\n+    // remove old .txt and .txt.tmp\n+    if (oldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(oldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(\"Deleting \" + oldLogFile + \"failed with exception \" + e.getMessage());\n+      }\n+    }\n+\n+    if (tmpOldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(tmpOldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(\"Deleting \" + tmpOldLogFile + \"failed with exception \" + e.getMessage());\n+      }\n+    }\n+\n+    // rename .bin.tmp to .bin\n+    FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+  }\n+\n+  public static void upgradeMLog() throws IOException {\n+    String schemaDir = IoTDBDescriptor.getInstance().getConfig().getSchemaDir();\n+    upgradeTxtToBin(schemaDir, MetadataConstant.METADATA_TXT_LOG, MetadataConstant.METADATA_LOG, false);\n+    upgradeTxtToBin(schemaDir, MetadataConstant.MTREE_TXT_SNAPSHOT, MetadataConstant.MTREE_SNAPSHOT, true);\n+  }\n+\n+  public void clear() throws IOException {\n+    sync();\n+    logWriter.close();\n+    mlogBuffer.clear();\n+    if (logFile != null && logFile.exists()) {\n+      Files.delete(logFile.toPath());\n+    }\n+    logNum = 0;\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public int getLogNum() {\n+    return logNum;\n+  }\n+\n+  /**\n+   * only used for initialize a mlog file writer.\n+   */\n+  public void setLogNum(int number) {\n+    logNum = number;\n+  }\n+\n+  public void operation(String cmd, boolean isSnapshot) throws IOException, MetadataException {\n+    if (!isSnapshot) {\n+      operation(cmd);\n+    } else {\n+      PhysicalPlan plan = convertFromString(cmd);\n+      try {\n+        if (plan != null) {\n+          putLog(plan);\n+        }\n+      } catch (BufferOverflowException e) {\n+        throw new IOException(\n+          LOG_TOO_LARGE_INFO, e);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * upgrade from mlog.txt to mlog.bin\n+   * @param cmd, the old meta operation\n+   * @throws IOException\n+   * @throws MetadataException\n+   */\n+  public void operation(String cmd) throws IOException, MetadataException {\n+    // see createTimeseries() to get the detailed format of the cmd\n+    String[] args = cmd.trim().split(\",\", -1);\n+    switch (args[0]) {\n+      case MetadataOperationType.CREATE_TIMESERIES:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MjA0Nw=="}, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 346}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDM0MTU5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxMzozMlrOH5gekg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxMzozMlrOH5gekg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2Mjk5NA==", "bodyText": "Same reason. Add these lines.\nif (args.length > 2) {\n  StringBuilder tmp = new StringBuilder();\n  for (int i = 1; i < args.length - 1; i++) {\n    tmp.append(args[i]).append(\",\");\t\n  }\t\n  tmp.append(args[args.length - 1]);\t\n  args[1] = tmp.toString();\t\n}", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530062994", "createdAt": "2020-11-25T02:13:32Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,424 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.apache.iotdb.tsfile.write.schema.MeasurementSchema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  // we write log to channel every time, so we need not to call channel.force every time\n+  private static final long DUMMY_FLUSH_TIME = 100;\n+  private static final String LOG_TOO_LARGE_INFO = \"Log cannot fit into buffer, please increase mlog_buffer_size\";\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    try {\n+      plan.serialize(mlogBuffer);\n+      sync();\n+      logNum ++;\n+    } catch (BufferOverflowException e) {\n+      logger.warn(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+    }\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan createTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(createTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public static void upgradeTxtToBin(String schemaDir, String oldFileName,\n+                                     String newFileName, boolean isSnapshot) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + newFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+      schemaDir + File.separator + oldFileName);\n+    File tmpOldLogFile = SystemFileFactory.INSTANCE.getFile(oldLogFile.getAbsolutePath()\n+      + \".tmp\");\n+\n+    if (oldLogFile.exists() || tmpOldLogFile.exists()) {\n+\n+      if (tmpOldLogFile.exists() && !oldLogFile.exists()) {\n+        FileUtils.moveFile(tmpOldLogFile, oldLogFile);\n+      }\n+\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, newFileName + \".tmp\");\n+           MLogTxtReader mLogTxtReader = new MLogTxtReader(schemaDir, oldFileName)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (mLogTxtReader.hasNext()) {\n+          String cmd = mLogTxtReader.next();\n+          try {\n+            mLogWriter.operation(cmd, isSnapshot);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+      }\n+    } else if (!logFile.exists() && !tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp do not exist, nothing to do\n+    } else if (!logFile.exists() && tmpLogFile.exists()) {\n+      // if old .bin doesn't exist but .bin.tmp exists, rename tmp file to .bin\n+      FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+    } else if (tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp exist, delete .bin.tmp\n+      try {\n+        Files.delete(Paths.get(tmpLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(\"Deleting \" + tmpLogFile + \"failed with exception \" + e.getMessage());\n+      }\n+    }\n+\n+    // do some clean job\n+    // remove old .txt and .txt.tmp\n+    if (oldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(oldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(\"Deleting \" + oldLogFile + \"failed with exception \" + e.getMessage());\n+      }\n+    }\n+\n+    if (tmpOldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(tmpOldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(\"Deleting \" + tmpOldLogFile + \"failed with exception \" + e.getMessage());\n+      }\n+    }\n+\n+    // rename .bin.tmp to .bin\n+    FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+  }\n+\n+  public static void upgradeMLog() throws IOException {\n+    String schemaDir = IoTDBDescriptor.getInstance().getConfig().getSchemaDir();\n+    upgradeTxtToBin(schemaDir, MetadataConstant.METADATA_TXT_LOG, MetadataConstant.METADATA_LOG, false);\n+    upgradeTxtToBin(schemaDir, MetadataConstant.MTREE_TXT_SNAPSHOT, MetadataConstant.MTREE_SNAPSHOT, true);\n+  }\n+\n+  public void clear() throws IOException {\n+    sync();\n+    logWriter.close();\n+    mlogBuffer.clear();\n+    if (logFile != null && logFile.exists()) {\n+      Files.delete(logFile.toPath());\n+    }\n+    logNum = 0;\n+    logWriter = new LogWriter(logFile, 0L);\n+  }\n+\n+  public int getLogNum() {\n+    return logNum;\n+  }\n+\n+  /**\n+   * only used for initialize a mlog file writer.\n+   */\n+  public void setLogNum(int number) {\n+    logNum = number;\n+  }\n+\n+  public void operation(String cmd, boolean isSnapshot) throws IOException, MetadataException {\n+    if (!isSnapshot) {\n+      operation(cmd);\n+    } else {\n+      PhysicalPlan plan = convertFromString(cmd);\n+      try {\n+        if (plan != null) {\n+          putLog(plan);\n+        }\n+      } catch (BufferOverflowException e) {\n+        throw new IOException(\n+          LOG_TOO_LARGE_INFO, e);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * upgrade from mlog.txt to mlog.bin\n+   * @param cmd, the old meta operation\n+   * @throws IOException\n+   * @throws MetadataException\n+   */\n+  public void operation(String cmd) throws IOException, MetadataException {\n+    // see createTimeseries() to get the detailed format of the cmd\n+    String[] args = cmd.trim().split(\",\", -1);\n+    switch (args[0]) {\n+      case MetadataOperationType.CREATE_TIMESERIES:\n+        Map<String, String> props = null;\n+        if (!args[5].isEmpty()) {\n+          String[] keyValues = args[5].split(\"&\");\n+          String[] kv;\n+          props = new HashMap<>();\n+          for (String keyValue : keyValues) {\n+            kv = keyValue.split(\"=\");\n+            props.put(kv[0], kv[1]);\n+          }\n+        }\n+\n+        String alias = null;\n+        if (!args[6].isEmpty()) {\n+          alias = args[6];\n+        }\n+        long offset = -1L;\n+        if (!args[7].isEmpty()) {\n+          offset = Long.parseLong(args[7]);\n+        }\n+\n+        CreateTimeSeriesPlan plan = new CreateTimeSeriesPlan(new PartialPath(args[1]),\n+            TSDataType.deserialize(Short.parseShort(args[2])),\n+            TSEncoding.deserialize(Short.parseShort(args[3])),\n+            CompressionType.deserialize(Short.parseShort(args[4])), props, null, null, alias);\n+        plan.setTagOffset(offset);\n+\n+        createTimeseries(plan);\n+        break;\n+      case MetadataOperationType.DELETE_TIMESERIES:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 375}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDM0ODg2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxNzowNFrOH5ginA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwMjoxNzowNFrOH5ginA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2NDAyOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  logger.error(\"DO NOT UPGRADE IoTDB from v0.9 or lower version to v0.12!\"\n          \n          \n            \n                  logger.error(\"DO NOT UPGRADE IoTDB from v0.10 or lower version to v0.12!\"", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530064028", "createdAt": "2020-11-25T02:17:04Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -184,51 +185,16 @@ public void checkConfig() throws IOException {\n             inputStream, TSFileConfig.STRING_CHARSET)) {\n       properties.load(inputStreamReader);\n     }\n-    // check whether upgrading from v0.9 to v0.11\n-    if (!properties.containsKey(IOTDB_VERSION_STRING)) {\n-      logger.error(\"DO NOT UPGRADE IoTDB from v0.9 or lower version to v0.11!\"\n-          + \" Please upgrade to v0.10 first\");\n+    // check whether upgrading from v0.9 to v0.12\n+    if (!properties.containsKey(IOTDB_VERSION_STRING) ||\n+      properties.getProperty(IOTDB_VERSION_STRING).startsWith(\"0.10\")) {\n+      logger.error(\"DO NOT UPGRADE IoTDB from v0.9 or lower version to v0.12!\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNDkxNDIxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/qp/logical/Operator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNzowMzozMVrOH5lkdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwNzowMzozMVrOH5lkdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDE0NjQyMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                CREATE_MULTI_TIMESERIES  , CREATE_INDEX, DROP_INDEX, QUERY_INDEX,\n          \n          \n            \n                CREATE_MULTI_TIMESERIES, CREATE_INDEX, DROP_INDEX, QUERY_INDEX,", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r530146421", "createdAt": "2020-11-25T07:03:31Z", "author": {"login": "HTHou"}, "path": "server/src/main/java/org/apache/iotdb/db/qp/logical/Operator.java", "diffHunk": "@@ -77,7 +77,8 @@ public String toString() {\n     TTL, DELETE_STORAGE_GROUP, LOAD_CONFIGURATION, SHOW, LOAD_FILES, REMOVE_FILE, MOVE_FILE, LAST, GROUP_BY_FILL,\n     ALTER_TIMESERIES, FLUSH, MERGE, FULL_MERGE, CLEAR_CACHE,\n     SHOW_MERGE_STATUS, CREATE_SCHEMA_SNAPSHOT, TRACING, DELETE_PARTITION,\n-    CREATE_MULTI_TIMESERIES\n-    , CREATE_INDEX, DROP_INDEX, QUERY_INDEX,\n+    CREATE_MULTI_TIMESERIES  , CREATE_INDEX, DROP_INDEX, QUERY_INDEX,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18db49a9f143f75580454df2a3fb002d63c66a2d"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNjg1MzE3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwNzoyNDo0N1rOH7Vltg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQwMTozODoyN1rOH7pWvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTk4MTc1MA==", "bodyText": "Remove unused import", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r531981750", "createdAt": "2020-11-28T07:24:47Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,451 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.DeleteFailedException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjMwNTU5Nw==", "bodyText": "fixed", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r532305597", "createdAt": "2020-11-30T01:38:27Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,451 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.DeleteFailedException;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTk4MTc1MA=="}, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNjg2NTkyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwNzoyNzo0NFrOH7Vufg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwNzoyNzo0NFrOH7Vufg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTk4Mzk5OA==", "bodyText": "Remove unused import", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r531983998", "createdAt": "2020-11-28T07:27:44Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,451 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.DeleteFailedException;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.apache.iotdb.tsfile.write.schema.MeasurementSchema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Arrays;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNjg3MDk0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwNzoyODo0OFrOH7Vx7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwNzoyODo0OFrOH7Vx7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTk4NDg3Ng==", "bodyText": "Remove unused import", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r531984876", "createdAt": "2020-11-28T07:28:48Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.tools.mlog;\n+\n+import jline.console.ConsoleReader;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNjg3MTYyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwNzoyODo1OVrOH7VyZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwNzoyODo1OVrOH7VyZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTk4NDk5OQ==", "bodyText": "Remove unused import", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r531984999", "createdAt": "2020-11-28T07:28:59Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/tools/mlog/MLogParser.java", "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.tools.mlog;\n+\n+import jline.console.ConsoleReader;\n+import org.apache.commons.cli.CommandLine;\n+import org.apache.commons.cli.CommandLineParser;\n+import org.apache.commons.cli.DefaultParser;\n+import org.apache.commons.cli.HelpFormatter;\n+import org.apache.commons.cli.Option;\n+import org.apache.commons.cli.Options;\n+import org.apache.commons.cli.ParseException;\n+import org.apache.iotdb.db.metadata.MLogTxtWriter;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.logfile.MLogReader;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+\n+import java.io.IOException;\n+import java.util.List;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNjkxMjY5OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/apache/iotdb/db/integration/IoTDBRestartIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwNzozODozNlrOH7WPEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwNzozODozNlrOH7WPEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTk5MjMzNw==", "bodyText": "Remove this line", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r531992337", "createdAt": "2020-11-28T07:38:36Z", "author": {"login": "samperson1997"}, "path": "server/src/test/java/org/apache/iotdb/db/integration/IoTDBRestartIT.java", "diffHunk": "@@ -269,6 +267,7 @@ public void testRestartEndTime()\n       };\n       int cnt = 0;\n       try (ResultSet resultSet = statement.getResultSet()) {\n+        System.out.println(resultSet.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNjk4NjcxOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/apache/iotdb/db/integration/IoTDBCreateSnapshotIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwODoxNzo1M1rOH7W-Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwODoxNzo1M1rOH7W-Cw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAwNDM2Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  HashSet<PhysicalPlan> d0Plans = new HashSet<>(6);\n          \n          \n            \n                  Set<PhysicalPlan> d0Plans = new HashSet<>(6);", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r532004363", "createdAt": "2020-11-28T08:17:53Z", "author": {"login": "samperson1997"}, "path": "server/src/test/java/org/apache/iotdb/db/integration/IoTDBCreateSnapshotIT.java", "diffHunk": "@@ -71,35 +78,52 @@ public void createSnapshotTest() throws ClassNotFoundException {\n \n       // create snapshot\n       statement.execute(\"CREATE SNAPSHOT FOR SCHEMA\");\n-      File snapshotFile = new File(config.getSchemaDir() + File.separator + \"mtree-1.snapshot\");\n+      File snapshotFile = new File(config.getSchemaDir() + File.separator + \"mtree-1.snapshot.bin\");\n \n       // test snapshot file exists\n       Assert.assertTrue(snapshotFile.exists());\n \n       // test snapshot content correct\n-      Set<String> e1 = new HashSet<>(Arrays.asList(\"2,s0,,1,2,1,,-1,0\", \"2,s1,,2,2,1,,-1,0\",\n-          \"2,s2,,3,2,1,,-1,0\", \"2,s3,,5,0,1,,-1,0\", \"2,s4,,0,0,1,,-1,0\"));\n-      Set<String> e2 = new HashSet<>(Arrays.asList(\"2,s0,,1,2,1,,-1,0\", \"2,s1,,5,0,1,,-1,0\",\n-          \"2,s2,,0,0,1,,-1,0\"));\n-\n-      try (BufferedReader br = new BufferedReader(new FileReader(snapshotFile))) {\n-        for (int i = 0; i < 5; ++i) {\n-          String actual = br.readLine();\n-          Assert.assertTrue(e1.removeIf(candidate -> candidate.equals(actual)));\n-        }\n-        Assert.assertTrue(e1.isEmpty());\n+      String[] exp = new String[]{\n+        \"2,s0,,1,2,1,,-1,0\",\n+        \"2,s1,,2,2,1,,-1,0\",\n+        \"2,s2,,3,2,1,,-1,0\",\n+        \"2,s3,,5,0,1,,-1,0\",\n+        \"2,s4,,0,0,1,,-1,0\",\n+        \"1,d0,9223372036854775807,5\",\n+        \"2,s0,,1,2,1,,-1,0\",\n+        \"2,s1,,5,0,1,,-1,0\",\n+        \"2,s2,,0,0,1,,-1,0\",\n+        \"1,d1,9223372036854775807,3\",\n+        \"0,vehicle,2\",\n+        \"0,root,1\"\n+      };\n \n-        Assert.assertEquals(\"1,d0,9223372036854775807,5\", br.readLine());\n+      HashSet<PhysicalPlan> d0Plans = new HashSet<>(6);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNjk4Njc1OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/apache/iotdb/db/integration/IoTDBCreateSnapshotIT.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwODoxODowM1rOH7W-Eg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwODoxODowM1rOH7W-Eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAwNDM3MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  HashSet<PhysicalPlan> d1Plans = new HashSet<>(6);\n          \n          \n            \n                  Set<PhysicalPlan> d1Plans = new HashSet<>(6);", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r532004370", "createdAt": "2020-11-28T08:18:03Z", "author": {"login": "samperson1997"}, "path": "server/src/test/java/org/apache/iotdb/db/integration/IoTDBCreateSnapshotIT.java", "diffHunk": "@@ -71,35 +78,52 @@ public void createSnapshotTest() throws ClassNotFoundException {\n \n       // create snapshot\n       statement.execute(\"CREATE SNAPSHOT FOR SCHEMA\");\n-      File snapshotFile = new File(config.getSchemaDir() + File.separator + \"mtree-1.snapshot\");\n+      File snapshotFile = new File(config.getSchemaDir() + File.separator + \"mtree-1.snapshot.bin\");\n \n       // test snapshot file exists\n       Assert.assertTrue(snapshotFile.exists());\n \n       // test snapshot content correct\n-      Set<String> e1 = new HashSet<>(Arrays.asList(\"2,s0,,1,2,1,,-1,0\", \"2,s1,,2,2,1,,-1,0\",\n-          \"2,s2,,3,2,1,,-1,0\", \"2,s3,,5,0,1,,-1,0\", \"2,s4,,0,0,1,,-1,0\"));\n-      Set<String> e2 = new HashSet<>(Arrays.asList(\"2,s0,,1,2,1,,-1,0\", \"2,s1,,5,0,1,,-1,0\",\n-          \"2,s2,,0,0,1,,-1,0\"));\n-\n-      try (BufferedReader br = new BufferedReader(new FileReader(snapshotFile))) {\n-        for (int i = 0; i < 5; ++i) {\n-          String actual = br.readLine();\n-          Assert.assertTrue(e1.removeIf(candidate -> candidate.equals(actual)));\n-        }\n-        Assert.assertTrue(e1.isEmpty());\n+      String[] exp = new String[]{\n+        \"2,s0,,1,2,1,,-1,0\",\n+        \"2,s1,,2,2,1,,-1,0\",\n+        \"2,s2,,3,2,1,,-1,0\",\n+        \"2,s3,,5,0,1,,-1,0\",\n+        \"2,s4,,0,0,1,,-1,0\",\n+        \"1,d0,9223372036854775807,5\",\n+        \"2,s0,,1,2,1,,-1,0\",\n+        \"2,s1,,5,0,1,,-1,0\",\n+        \"2,s2,,0,0,1,,-1,0\",\n+        \"1,d1,9223372036854775807,3\",\n+        \"0,vehicle,2\",\n+        \"0,root,1\"\n+      };\n \n-        Assert.assertEquals(\"1,d0,9223372036854775807,5\", br.readLine());\n+      HashSet<PhysicalPlan> d0Plans = new HashSet<>(6);\n+      for (int i = 0; i < 6; i++) {\n+        d0Plans.add(MLogWriter.convertFromString(exp[i]));\n+      }\n+\n+      HashSet<PhysicalPlan> d1Plans = new HashSet<>(6);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNjk5MjM4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwODoyNToxNFrOH7XAgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwODoyNToxNFrOH7XAgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAwNDk5Mw==", "bodyText": "You can add @TestOnly for this method", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r532004993", "createdAt": "2020-11-28T08:25:14Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -38,16 +38,34 @@\n   private FileOutputStream fileOutputStream;\n   private FileChannel channel;\n   private CRC32 checkSummer = new CRC32();\n-  private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n   private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n   private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private long forcePeriodInMs = 0;\n \n-  public LogWriter(String logFilePath) {\n+  /**\n+   * only used by tests\n+   * @param logFilePath\n+   * @param forcePeriodInMs\n+   * @throws FileNotFoundException\n+   */\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNzAwOTE4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/MManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwODo0OToxOVrOH7XIJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwODo0OToxOVrOH7XIJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAwNjk0OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              /**\n          \n          \n            \n               * only for test\n          \n          \n            \n               */\n          \n          \n            \n              public void flushAllMlogForTest() throws IOException {\n          \n          \n            \n              @TestOnly\n          \n          \n            \n              public void flushAllMlogForTest() throws IOException {", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r532006948", "createdAt": "2020-11-28T08:49:19Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/MManager.java", "diffHunk": "@@ -1680,6 +1647,13 @@ public TimeValuePair getLastCache(PartialPath seriesPath) {\n     return null;\n   }\n \n+  /**\n+   * only for test\n+   */\n+  public void flushAllMlogForTest() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71ee0a008fd1441ce88eb2e7d8db345a2c3b28de"}, "originalPosition": 431}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM3MjE3ODcyOnYy", "diffSide": "LEFT", "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QwNDo1MDozNVrOIAV4VA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QwNDo1MDozNVrOIAV4VA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzIyOTM5Ng==", "bodyText": "do we need to upgrade grom 0.11 to 0.12?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r537229396", "createdAt": "2020-12-07T04:50:35Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -184,27 +185,23 @@ public void checkConfig() throws IOException {\n             inputStream, TSFileConfig.STRING_CHARSET)) {\n       properties.load(inputStreamReader);\n     }\n-    // check whether upgrading from v0.9 to v0.11\n-    if (!properties.containsKey(IOTDB_VERSION_STRING)) {\n-      logger.error(\"DO NOT UPGRADE IoTDB from v0.9 or lower version to v0.11!\"\n-          + \" Please upgrade to v0.10 first\");\n+    // check whether upgrading from v0.9 to v0.12\n+    if (!properties.containsKey(IOTDB_VERSION_STRING) ||\n+      properties.getProperty(IOTDB_VERSION_STRING).startsWith(\"0.10\")) {\n+      logger.error(\"DO NOT UPGRADE IoTDB from v0.10 or lower version to v0.12!\"\n+          + \" Please upgrade to v0.11 first\");\n       System.exit(-1);\n     }\n-    // check whether upgrading from v0.10 to v0.11\n-    if (properties.getProperty(IOTDB_VERSION_STRING).startsWith(\"0.10\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e68450a813c60198cfa99b799ac6f02e039428e"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM3NzY5Mzk1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwNDo0ODozMFrOIBG4_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwNDo0ODozMFrOIBG4_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODAzMjM4Mw==", "bodyText": "from <=0.10 to 0.12", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r538032383", "createdAt": "2020-12-08T04:48:30Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfigCheck.java", "diffHunk": "@@ -184,27 +185,24 @@ public void checkConfig() throws IOException {\n             inputStream, TSFileConfig.STRING_CHARSET)) {\n       properties.load(inputStreamReader);\n     }\n-    // check whether upgrading from v0.9 to v0.11\n-    if (!properties.containsKey(IOTDB_VERSION_STRING)) {\n-      logger.error(\"DO NOT UPGRADE IoTDB from v0.9 or lower version to v0.11!\"\n-          + \" Please upgrade to v0.10 first\");\n+    // check whether upgrading from v0.9 to v0.12", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3cd0707d05163af2f0b0a725b88ec65a75617262"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNTg5NTQ5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfig.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNTo0MDo1NVrOIFAsRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNzowMDo0MFrOIFCYsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEyNTEyNw==", "bodyText": "make this consistent with iotdb-engine.properties?", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542125127", "createdAt": "2020-12-14T05:40:55Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfig.java", "diffHunk": "@@ -204,12 +204,18 @@\n \n   /**\n    * Size of log buffer in each log node(in byte). If WAL is enabled and the size of a insert plan\n-   * is smaller than this parameter, then the insert plan will be rejected by WAL.\n+   * is larger than this parameter, then the insert plan will be rejected by WAL.\n    */\n   private int walBufferSize = 16 * 1024 * 1024;\n \n   private int estimatedSeriesSize = 300;\n \n+  /**\n+   * Size of log buffer for every MetaData operation. If the size of a MetaData operation plan\n+   * is larger than this parameter, then the MetaData operation plan will be rejected by MManager.\n+   */\n+  private int mlogBufferSize = 1024 * 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1Mjg4MQ==", "bodyText": "There is not a thread to do the periodic Channel.force(true) for MLogWriter, is this meet our expectation?\n\nNot\uff0cjust when we use thread pool to write, and we call shutdown to interrupt the thread, see this\nhttps://stackoverflow.com/questions/1161297/why-are-we-getting-closedbyinterruptexception-from-filechannel-map-in-java-1-6", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542152881", "createdAt": "2020-12-14T07:00:40Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/conf/IoTDBConfig.java", "diffHunk": "@@ -204,12 +204,18 @@\n \n   /**\n    * Size of log buffer in each log node(in byte). If WAL is enabled and the size of a insert plan\n-   * is smaller than this parameter, then the insert plan will be rejected by WAL.\n+   * is larger than this parameter, then the insert plan will be rejected by WAL.\n    */\n   private int walBufferSize = 16 * 1024 * 1024;\n \n   private int estimatedSeriesSize = 300;\n \n+  /**\n+   * Size of log buffer for every MetaData operation. If the size of a MetaData operation plan\n+   * is larger than this parameter, then the MetaData operation plan will be rejected by MManager.\n+   */\n+  private int mlogBufferSize = 1024 * 1024;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEyNTEyNw=="}, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNTkwNDIxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNTo0NDozMFrOIFAw2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNzowMjoxN1rOIFCbaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEyNjI5Ng==", "bodyText": "this is always true, said by idea..", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542126296", "createdAt": "2020-12-14T05:44:30Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -18,36 +18,59 @@\n  */\n package org.apache.iotdb.db.writelog.io;\n \n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n import java.io.File;\n+import java.io.FileNotFoundException;\n import java.io.FileOutputStream;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedChannelException;\n import java.nio.channels.FileChannel;\n import java.util.zip.CRC32;\n-import org.apache.iotdb.db.conf.IoTDBConfig;\n-import org.apache.iotdb.db.conf.IoTDBDescriptor;\n-import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n \n /**\n- * LogWriter writes the binarized logs into a file using FileChannel together with check sums of\n+ * LogWriter writes the binary logs into a file using FileChannel together with check sums of\n  * each log calculated using CRC32.\n  */\n public class LogWriter implements ILogWriter {\n+  private static final Logger logger = LoggerFactory.getLogger(LogWriter.class);\n \n   private File logFile;\n   private FileOutputStream fileOutputStream;\n   private FileChannel channel;\n-  private CRC32 checkSummer = new CRC32();\n-  private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n-  private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n-  private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final CRC32 checkSummer = new CRC32();\n+  private final ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n+  private final ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final long forcePeriodInMs;\n \n-  public LogWriter(String logFilePath) {\n+  /**\n+   * @param logFilePath\n+   * @param forcePeriodInMs\n+   * @throws FileNotFoundException\n+   */\n+  @TestOnly\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {\n     logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1MzU3Ng==", "bodyText": "yes, but I think add a check is not redundancy", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542153576", "createdAt": "2020-12-14T07:02:17Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -18,36 +18,59 @@\n  */\n package org.apache.iotdb.db.writelog.io;\n \n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n import java.io.File;\n+import java.io.FileNotFoundException;\n import java.io.FileOutputStream;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedChannelException;\n import java.nio.channels.FileChannel;\n import java.util.zip.CRC32;\n-import org.apache.iotdb.db.conf.IoTDBConfig;\n-import org.apache.iotdb.db.conf.IoTDBDescriptor;\n-import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n \n /**\n- * LogWriter writes the binarized logs into a file using FileChannel together with check sums of\n+ * LogWriter writes the binary logs into a file using FileChannel together with check sums of\n  * each log calculated using CRC32.\n  */\n public class LogWriter implements ILogWriter {\n+  private static final Logger logger = LoggerFactory.getLogger(LogWriter.class);\n \n   private File logFile;\n   private FileOutputStream fileOutputStream;\n   private FileChannel channel;\n-  private CRC32 checkSummer = new CRC32();\n-  private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n-  private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n-  private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final CRC32 checkSummer = new CRC32();\n+  private final ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n+  private final ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final long forcePeriodInMs;\n \n-  public LogWriter(String logFilePath) {\n+  /**\n+   * @param logFilePath\n+   * @param forcePeriodInMs\n+   * @throws FileNotFoundException\n+   */\n+  @TestOnly\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {\n     logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEyNjI5Ng=="}, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNTkwNDU4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNTo0NDozN1rOIFAxCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNTo0NDozN1rOIFAxCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEyNjM0NQ==", "bodyText": "this is always true, said by idea..", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542126345", "createdAt": "2020-12-14T05:44:37Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -18,36 +18,59 @@\n  */\n package org.apache.iotdb.db.writelog.io;\n \n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n import java.io.File;\n+import java.io.FileNotFoundException;\n import java.io.FileOutputStream;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedChannelException;\n import java.nio.channels.FileChannel;\n import java.util.zip.CRC32;\n-import org.apache.iotdb.db.conf.IoTDBConfig;\n-import org.apache.iotdb.db.conf.IoTDBDescriptor;\n-import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n \n /**\n- * LogWriter writes the binarized logs into a file using FileChannel together with check sums of\n+ * LogWriter writes the binary logs into a file using FileChannel together with check sums of\n  * each log calculated using CRC32.\n  */\n public class LogWriter implements ILogWriter {\n+  private static final Logger logger = LoggerFactory.getLogger(LogWriter.class);\n \n   private File logFile;\n   private FileOutputStream fileOutputStream;\n   private FileChannel channel;\n-  private CRC32 checkSummer = new CRC32();\n-  private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n-  private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n-  private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final CRC32 checkSummer = new CRC32();\n+  private final ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n+  private final ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final long forcePeriodInMs;\n \n-  public LogWriter(String logFilePath) {\n+  /**\n+   * @param logFilePath\n+   * @param forcePeriodInMs\n+   * @throws FileNotFoundException\n+   */\n+  @TestOnly\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {\n     logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {\n+      fileOutputStream = new FileOutputStream(logFile, true);\n+      channel = fileOutputStream.getChannel();\n+    }\n   }\n \n-  public LogWriter(File logFile) {\n+  public LogWriter(File logFile, long forcePeriodInMs) throws FileNotFoundException {\n     this.logFile = logFile;\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNTkxMTg3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNTo0NzozN1rOIFA0ww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNTo0NzozN1rOIFA0ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEyNzI5OQ==", "bodyText": "The function of this field is the same with a boolean", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542127299", "createdAt": "2020-12-14T05:47:37Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,452 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.apache.iotdb.tsfile.write.schema.MeasurementSchema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private static final String DELETE_FAILED_FORMAT = \"Deleting %s failed with exception %s\";\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  // we write log to channel every time, so we need not to call channel.force every time\n+  private static final long DUMMY_FLUSH_TIME = 100;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNTkyNzgwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNTo1NDozNlrOIFA9dA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNzo0MDowMVrOIFDZxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEyOTUyNA==", "bodyText": "The actual usage of  'forcePeriodInMs' parameter is a boolean 'forceAtEachWrite'", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542129524", "createdAt": "2020-12-14T05:54:36Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -18,36 +18,59 @@\n  */\n package org.apache.iotdb.db.writelog.io;\n \n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n import java.io.File;\n+import java.io.FileNotFoundException;\n import java.io.FileOutputStream;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedChannelException;\n import java.nio.channels.FileChannel;\n import java.util.zip.CRC32;\n-import org.apache.iotdb.db.conf.IoTDBConfig;\n-import org.apache.iotdb.db.conf.IoTDBDescriptor;\n-import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n \n /**\n- * LogWriter writes the binarized logs into a file using FileChannel together with check sums of\n+ * LogWriter writes the binary logs into a file using FileChannel together with check sums of\n  * each log calculated using CRC32.\n  */\n public class LogWriter implements ILogWriter {\n+  private static final Logger logger = LoggerFactory.getLogger(LogWriter.class);\n \n   private File logFile;\n   private FileOutputStream fileOutputStream;\n   private FileChannel channel;\n-  private CRC32 checkSummer = new CRC32();\n-  private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n-  private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n-  private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final CRC32 checkSummer = new CRC32();\n+  private final ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n+  private final ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final long forcePeriodInMs;\n \n-  public LogWriter(String logFilePath) {\n+  /**\n+   * @param logFilePath\n+   * @param forcePeriodInMs\n+   * @throws FileNotFoundException\n+   */\n+  @TestOnly\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {\n     logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {\n+      fileOutputStream = new FileOutputStream(logFile, true);\n+      channel = fileOutputStream.getChannel();\n+    }\n   }\n \n-  public LogWriter(File logFile) {\n+  public LogWriter(File logFile, long forcePeriodInMs) throws FileNotFoundException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2OTU0MA==", "bodyText": "Not that, wal use this to optimize the performance after hundreds  of milliseconds.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542169540", "createdAt": "2020-12-14T07:40:01Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/writelog/io/LogWriter.java", "diffHunk": "@@ -18,36 +18,59 @@\n  */\n package org.apache.iotdb.db.writelog.io;\n \n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n import java.io.File;\n+import java.io.FileNotFoundException;\n import java.io.FileOutputStream;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedChannelException;\n import java.nio.channels.FileChannel;\n import java.util.zip.CRC32;\n-import org.apache.iotdb.db.conf.IoTDBConfig;\n-import org.apache.iotdb.db.conf.IoTDBDescriptor;\n-import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n \n /**\n- * LogWriter writes the binarized logs into a file using FileChannel together with check sums of\n+ * LogWriter writes the binary logs into a file using FileChannel together with check sums of\n  * each log calculated using CRC32.\n  */\n public class LogWriter implements ILogWriter {\n+  private static final Logger logger = LoggerFactory.getLogger(LogWriter.class);\n \n   private File logFile;\n   private FileOutputStream fileOutputStream;\n   private FileChannel channel;\n-  private CRC32 checkSummer = new CRC32();\n-  private IoTDBConfig config = IoTDBDescriptor.getInstance().getConfig();\n-  private ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n-  private ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final CRC32 checkSummer = new CRC32();\n+  private final ByteBuffer lengthBuffer = ByteBuffer.allocate(4);\n+  private final ByteBuffer checkSumBuffer = ByteBuffer.allocate(8);\n+  private final long forcePeriodInMs;\n \n-  public LogWriter(String logFilePath) {\n+  /**\n+   * @param logFilePath\n+   * @param forcePeriodInMs\n+   * @throws FileNotFoundException\n+   */\n+  @TestOnly\n+  public LogWriter(String logFilePath, long forcePeriodInMs) throws FileNotFoundException {\n     logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    this.forcePeriodInMs = forcePeriodInMs;\n+\n+    if (channel == null) {\n+      fileOutputStream = new FileOutputStream(logFile, true);\n+      channel = fileOutputStream.getChannel();\n+    }\n   }\n \n-  public LogWriter(File logFile) {\n+  public LogWriter(File logFile, long forcePeriodInMs) throws FileNotFoundException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEyOTUyNA=="}, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNTk2NTI1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNjoxMDoxOVrOIFBRng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNzo0Mjo1MFrOIFDfAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEzNDY4Ng==", "bodyText": "The forcePeriodInMs is differenet between clear() and constructor.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542134686", "createdAt": "2020-12-14T06:10:19Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,452 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.apache.iotdb.tsfile.write.schema.MeasurementSchema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private static final String DELETE_FAILED_FORMAT = \"Deleting %s failed with exception %s\";\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  // we write log to channel every time, so we need not to call channel.force every time\n+  private static final long DUMMY_FLUSH_TIME = 100;\n+  private static final String LOG_TOO_LARGE_INFO = \"Log cannot fit into buffer, please increase mlog_buffer_size\";\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    try {\n+      plan.serialize(mlogBuffer);\n+      sync();\n+      logNum ++;\n+    } catch (BufferOverflowException e) {\n+      logger.warn(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+    }\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan createTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(createTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n+  public static void upgradeTxtToBin(String schemaDir, String oldFileName,\n+                                     String newFileName, boolean isSnapshot) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + newFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+      schemaDir + File.separator + oldFileName);\n+    File tmpOldLogFile = SystemFileFactory.INSTANCE.getFile(oldLogFile.getAbsolutePath()\n+      + \".tmp\");\n+\n+    if (oldLogFile.exists() || tmpOldLogFile.exists()) {\n+\n+      if (tmpOldLogFile.exists() && !oldLogFile.exists()) {\n+        FileUtils.moveFile(tmpOldLogFile, oldLogFile);\n+      }\n+\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, newFileName + \".tmp\");\n+           MLogTxtReader mLogTxtReader = new MLogTxtReader(schemaDir, oldFileName)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (mLogTxtReader.hasNext()) {\n+          String cmd = mLogTxtReader.next();\n+          try {\n+            mLogWriter.operation(cmd, isSnapshot);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+      }\n+    } else if (!logFile.exists() && !tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp do not exist, nothing to do\n+    } else if (!logFile.exists() && tmpLogFile.exists()) {\n+      // if old .bin doesn't exist but .bin.tmp exists, rename tmp file to .bin\n+      FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+    } else if (tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp exist, delete .bin.tmp\n+      try {\n+        Files.delete(Paths.get(tmpLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(String.format(DELETE_FAILED_FORMAT, tmpLogFile, e.getMessage()));\n+      }\n+    }\n+\n+    // do some clean job\n+    // remove old .txt and .txt.tmp\n+    if (oldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(oldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(String.format(DELETE_FAILED_FORMAT, oldLogFile, e.getMessage()));\n+      }\n+    }\n+\n+    if (tmpOldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(tmpOldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(String.format(DELETE_FAILED_FORMAT, tmpOldLogFile, e.getMessage()));\n+      }\n+    }\n+\n+    // rename .bin.tmp to .bin\n+    FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+  }\n+\n+  public static void upgradeMLog() throws IOException {\n+    String schemaDir = IoTDBDescriptor.getInstance().getConfig().getSchemaDir();\n+    upgradeTxtToBin(schemaDir, MetadataConstant.METADATA_TXT_LOG, MetadataConstant.METADATA_LOG, false);\n+    upgradeTxtToBin(schemaDir, MetadataConstant.MTREE_TXT_SNAPSHOT, MetadataConstant.MTREE_SNAPSHOT, true);\n+  }\n+\n+  public void clear() throws IOException {\n+    sync();\n+    logWriter.close();\n+    mlogBuffer.clear();\n+    if (logFile != null && logFile.exists()) {\n+      Files.delete(logFile.toPath());\n+    }\n+    logNum = 0;\n+    logWriter = new LogWriter(logFile, 0L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 308}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE3MDg4MQ==", "bodyText": "yes,  it's a mistake.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542170881", "createdAt": "2020-12-14T07:42:50Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,452 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.apache.iotdb.tsfile.write.schema.MeasurementSchema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private static final String DELETE_FAILED_FORMAT = \"Deleting %s failed with exception %s\";\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  // we write log to channel every time, so we need not to call channel.force every time\n+  private static final long DUMMY_FLUSH_TIME = 100;\n+  private static final String LOG_TOO_LARGE_INFO = \"Log cannot fit into buffer, please increase mlog_buffer_size\";\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    try {\n+      plan.serialize(mlogBuffer);\n+      sync();\n+      logNum ++;\n+    } catch (BufferOverflowException e) {\n+      logger.warn(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+    }\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan createTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(createTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n+  public static void upgradeTxtToBin(String schemaDir, String oldFileName,\n+                                     String newFileName, boolean isSnapshot) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + newFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+      schemaDir + File.separator + oldFileName);\n+    File tmpOldLogFile = SystemFileFactory.INSTANCE.getFile(oldLogFile.getAbsolutePath()\n+      + \".tmp\");\n+\n+    if (oldLogFile.exists() || tmpOldLogFile.exists()) {\n+\n+      if (tmpOldLogFile.exists() && !oldLogFile.exists()) {\n+        FileUtils.moveFile(tmpOldLogFile, oldLogFile);\n+      }\n+\n+      try (MLogWriter mLogWriter = new MLogWriter(schemaDir, newFileName + \".tmp\");\n+           MLogTxtReader mLogTxtReader = new MLogTxtReader(schemaDir, oldFileName)) {\n+        // upgrade from old character log file to new binary mlog\n+        while (mLogTxtReader.hasNext()) {\n+          String cmd = mLogTxtReader.next();\n+          try {\n+            mLogWriter.operation(cmd, isSnapshot);\n+          } catch (MetadataException e) {\n+            logger.error(\"failed to upgrade cmd {}.\", cmd, e);\n+          }\n+        }\n+      }\n+    } else if (!logFile.exists() && !tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp do not exist, nothing to do\n+    } else if (!logFile.exists() && tmpLogFile.exists()) {\n+      // if old .bin doesn't exist but .bin.tmp exists, rename tmp file to .bin\n+      FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+    } else if (tmpLogFile.exists()) {\n+      // if both .bin and .bin.tmp exist, delete .bin.tmp\n+      try {\n+        Files.delete(Paths.get(tmpLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(String.format(DELETE_FAILED_FORMAT, tmpLogFile, e.getMessage()));\n+      }\n+    }\n+\n+    // do some clean job\n+    // remove old .txt and .txt.tmp\n+    if (oldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(oldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(String.format(DELETE_FAILED_FORMAT, oldLogFile, e.getMessage()));\n+      }\n+    }\n+\n+    if (tmpOldLogFile.exists()) {\n+      try {\n+        Files.delete(Paths.get(tmpOldLogFile.toURI()));\n+      } catch (IOException e) {\n+        throw new IOException(String.format(DELETE_FAILED_FORMAT, tmpOldLogFile, e.getMessage()));\n+      }\n+    }\n+\n+    // rename .bin.tmp to .bin\n+    FSFactoryProducer.getFSFactory().moveFile(tmpLogFile, logFile);\n+  }\n+\n+  public static void upgradeMLog() throws IOException {\n+    String schemaDir = IoTDBDescriptor.getInstance().getConfig().getSchemaDir();\n+    upgradeTxtToBin(schemaDir, MetadataConstant.METADATA_TXT_LOG, MetadataConstant.METADATA_LOG, false);\n+    upgradeTxtToBin(schemaDir, MetadataConstant.MTREE_TXT_SNAPSHOT, MetadataConstant.MTREE_SNAPSHOT, true);\n+  }\n+\n+  public void clear() throws IOException {\n+    sync();\n+    logWriter.close();\n+    mlogBuffer.clear();\n+    if (logFile != null && logFile.exists()) {\n+      Files.delete(logFile.toPath());\n+    }\n+    logNum = 0;\n+    logWriter = new LogWriter(logFile, 0L);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEzNDY4Ng=="}, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 308}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNTk5Mjc4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNjoyMToyOFrOIFBf_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNzo0NTowMlrOIFDi5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEzODM2Ng==", "bodyText": "what is this file for?  I do not see the generation of this file..", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542138366", "createdAt": "2020-12-14T06:21:28Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,452 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.apache.iotdb.tsfile.write.schema.MeasurementSchema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private static final String DELETE_FAILED_FORMAT = \"Deleting %s failed with exception %s\";\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  // we write log to channel every time, so we need not to call channel.force every time\n+  private static final long DUMMY_FLUSH_TIME = 100;\n+  private static final String LOG_TOO_LARGE_INFO = \"Log cannot fit into buffer, please increase mlog_buffer_size\";\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    try {\n+      plan.serialize(mlogBuffer);\n+      sync();\n+      logNum ++;\n+    } catch (BufferOverflowException e) {\n+      logger.warn(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+    }\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan createTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(createTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n+  public static void upgradeTxtToBin(String schemaDir, String oldFileName,\n+                                     String newFileName, boolean isSnapshot) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + newFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+      schemaDir + File.separator + oldFileName);\n+    File tmpOldLogFile = SystemFileFactory.INSTANCE.getFile(oldLogFile.getAbsolutePath()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 237}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE3MTg3Ng==", "bodyText": "when we upgrade, maybe we will find the old temp mlog file, so we need to delete it or rename it to the old mlog.txt", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542171876", "createdAt": "2020-12-14T07:45:02Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/metadata/logfile/MLogWriter.java", "diffHunk": "@@ -0,0 +1,452 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.metadata.logfile;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.exception.metadata.MetadataException;\n+import org.apache.iotdb.db.metadata.MetadataConstant;\n+import org.apache.iotdb.db.metadata.MetadataOperationType;\n+import org.apache.iotdb.db.metadata.PartialPath;\n+import org.apache.iotdb.db.metadata.mnode.MNode;\n+import org.apache.iotdb.db.metadata.mnode.MeasurementMNode;\n+import org.apache.iotdb.db.metadata.mnode.StorageGroupMNode;\n+import org.apache.iotdb.db.qp.physical.PhysicalPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeAliasPlan;\n+import org.apache.iotdb.db.qp.physical.sys.ChangeTagOffsetPlan;\n+import org.apache.iotdb.db.qp.physical.sys.CreateTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.DeleteTimeSeriesPlan;\n+import org.apache.iotdb.db.qp.physical.sys.MNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.MeasurementMNodePlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetStorageGroupPlan;\n+import org.apache.iotdb.db.qp.physical.sys.SetTTLPlan;\n+import org.apache.iotdb.db.qp.physical.sys.StorageGroupMNodePlan;\n+import org.apache.iotdb.db.writelog.io.LogWriter;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.apache.iotdb.tsfile.fileSystem.FSFactoryProducer;\n+import org.apache.iotdb.tsfile.write.schema.MeasurementSchema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.BufferOverflowException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class MLogWriter implements AutoCloseable {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(MLogWriter.class);\n+  private File logFile;\n+  private LogWriter logWriter;\n+  private int logNum;\n+  private static final String DELETE_FAILED_FORMAT = \"Deleting %s failed with exception %s\";\n+  private ByteBuffer mlogBuffer = ByteBuffer.allocate(\n+    IoTDBDescriptor.getInstance().getConfig().getMlogBufferSize());\n+\n+  // we write log to channel every time, so we need not to call channel.force every time\n+  private static final long DUMMY_FLUSH_TIME = 100;\n+  private static final String LOG_TOO_LARGE_INFO = \"Log cannot fit into buffer, please increase mlog_buffer_size\";\n+\n+  public MLogWriter(String schemaDir, String logFileName) throws IOException {\n+    File metadataDir = SystemFileFactory.INSTANCE.getFile(schemaDir);\n+    if (!metadataDir.exists()) {\n+      if (metadataDir.mkdirs()) {\n+        logger.info(\"create schema folder {}.\", metadataDir);\n+      } else {\n+        logger.warn(\"create schema folder {} failed.\", metadataDir);\n+      }\n+    }\n+\n+    logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + logFileName);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  public MLogWriter(String logFilePath) throws IOException {\n+    logFile = SystemFileFactory.INSTANCE.getFile(logFilePath);\n+    logWriter = new LogWriter(logFile, DUMMY_FLUSH_TIME);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    logWriter.close();\n+  }\n+\n+  private void sync() {\n+    try {\n+      logWriter.write(mlogBuffer);\n+    } catch (IOException e) {\n+      logger.error(\"MLog {} sync failed, change system mode to read-only\", logFile.getAbsoluteFile(), e);\n+      IoTDBDescriptor.getInstance().getConfig().setReadOnly(true);\n+    }\n+    mlogBuffer.clear();\n+  }\n+\n+  private void putLog(PhysicalPlan plan) {\n+    try {\n+      plan.serialize(mlogBuffer);\n+      sync();\n+      logNum ++;\n+    } catch (BufferOverflowException e) {\n+      logger.warn(\"MLog {} BufferOverflow !\", plan.getOperatorType(), e);\n+    }\n+  }\n+\n+  public void createTimeseries(CreateTimeSeriesPlan createTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(createTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteTimeseries(DeleteTimeSeriesPlan deleteTimeSeriesPlan) throws IOException {\n+    try {\n+      putLog(deleteTimeSeriesPlan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      SetStorageGroupPlan plan = new SetStorageGroupPlan(storageGroup);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void deleteStorageGroup(PartialPath storageGroup) throws IOException {\n+    try {\n+      DeleteStorageGroupPlan plan = new DeleteStorageGroupPlan(Collections.singletonList(storageGroup));\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void setTTL(PartialPath storageGroup, long ttl) throws IOException {\n+    try {\n+      SetTTLPlan plan = new SetTTLPlan(storageGroup, ttl);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeOffset(PartialPath path, long offset) throws IOException {\n+    try {\n+      ChangeTagOffsetPlan plan = new ChangeTagOffsetPlan(path, offset);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void changeAlias(PartialPath path, String alias) throws IOException {\n+    try {\n+      ChangeAliasPlan plan = new ChangeAliasPlan(path, alias);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMNode(MNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MNodePlan plan = new MNodePlan(node.getName(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeMeasurementMNode(MeasurementMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      MeasurementMNodePlan plan = new MeasurementMNodePlan(node.getName(), node.getAlias(),\n+        node.getOffset(), childSize, node.getSchema());\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  public void serializeStorageGroupMNode(StorageGroupMNode node) throws IOException {\n+    try {\n+      int childSize = 0;\n+      if (node.getChildren() != null) {\n+        childSize = node.getChildren().size();\n+      }\n+      StorageGroupMNodePlan plan = new StorageGroupMNodePlan(node.getName(), node.getDataTTL(), childSize);\n+      putLog(plan);\n+    } catch (BufferOverflowException e) {\n+      throw new IOException(\n+        LOG_TOO_LARGE_INFO, e);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"squid:S3776\") // Suppress high Cognitive Complexity warning\n+  public static void upgradeTxtToBin(String schemaDir, String oldFileName,\n+                                     String newFileName, boolean isSnapshot) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE.getFile(schemaDir + File.separator + newFileName);\n+    File tmpLogFile = SystemFileFactory.INSTANCE.getFile(logFile.getAbsolutePath() + \".tmp\");\n+    File oldLogFile = SystemFileFactory.INSTANCE.getFile(\n+      schemaDir + File.separator + oldFileName);\n+    File tmpOldLogFile = SystemFileFactory.INSTANCE.getFile(oldLogFile.getAbsolutePath()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjEzODM2Ng=="}, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 237}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNjAxOTQ2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/qp/logical/Operator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNjozMTo0NVrOIFBuIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNzo0Nzo1MlrOIFDn6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE0MTk4NQ==", "bodyText": "This could be removed, the operator is only generated in SQL parser.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542141985", "createdAt": "2020-12-14T06:31:45Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/qp/logical/Operator.java", "diffHunk": "@@ -77,7 +77,8 @@ public String toString() {\n     TTL, DELETE_STORAGE_GROUP, LOAD_CONFIGURATION, SHOW, LOAD_FILES, REMOVE_FILE, MOVE_FILE, LAST, GROUP_BY_FILL,\n     ALTER_TIMESERIES, FLUSH, MERGE, FULL_MERGE, CLEAR_CACHE,\n     SHOW_MERGE_STATUS, CREATE_SCHEMA_SNAPSHOT, TRACING, DELETE_PARTITION,\n-    CREATE_MULTI_TIMESERIES\n-    , CREATE_INDEX, DROP_INDEX, QUERY_INDEX,\n+    CREATE_MULTI_TIMESERIES, CREATE_INDEX, DROP_INDEX, QUERY_INDEX,\n+    CHANGE_TAG_OFFSET, CHANGE_ALIAS, MNODE,\n+    MEASUREMENT_MNODE, STORAGE_GROUP_MNODE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE3MzE2MA==", "bodyText": "I use them to unify the wal and mlog, for deserializing the log.", "url": "https://github.com/apache/iotdb/pull/1721#discussion_r542173160", "createdAt": "2020-12-14T07:47:52Z", "author": {"login": "mychaow"}, "path": "server/src/main/java/org/apache/iotdb/db/qp/logical/Operator.java", "diffHunk": "@@ -77,7 +77,8 @@ public String toString() {\n     TTL, DELETE_STORAGE_GROUP, LOAD_CONFIGURATION, SHOW, LOAD_FILES, REMOVE_FILE, MOVE_FILE, LAST, GROUP_BY_FILL,\n     ALTER_TIMESERIES, FLUSH, MERGE, FULL_MERGE, CLEAR_CACHE,\n     SHOW_MERGE_STATUS, CREATE_SCHEMA_SNAPSHOT, TRACING, DELETE_PARTITION,\n-    CREATE_MULTI_TIMESERIES\n-    , CREATE_INDEX, DROP_INDEX, QUERY_INDEX,\n+    CREATE_MULTI_TIMESERIES, CREATE_INDEX, DROP_INDEX, QUERY_INDEX,\n+    CHANGE_TAG_OFFSET, CHANGE_ALIAS, MNODE,\n+    MEASUREMENT_MNODE, STORAGE_GROUP_MNODE;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE0MTk4NQ=="}, "originalCommit": {"oid": "67b5e08d8b9a9753f6867ad93a07726007a0cf7b"}, "originalPosition": 8}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 707, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}