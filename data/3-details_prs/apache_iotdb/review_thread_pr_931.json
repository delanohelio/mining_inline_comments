{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkyMDU3MzAy", "number": 931, "reviewThreads": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwODowMjozM1rODqrdfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoyMjo1NFrODwwslw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2MDc4ODQ0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/qp/strategy/PhysicalGenerator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwODowMjozM1rOF6koAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwODowMjozM1rOF6koAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2MTc5NQ==", "bodyText": "false?", "url": "https://github.com/apache/iotdb/pull/931#discussion_r396961795", "createdAt": "2020-03-24T08:02:33Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/qp/strategy/PhysicalGenerator.java", "diffHunk": "@@ -388,7 +383,11 @@ private PhysicalPlan transformQuery(QueryOperator queryOperator)\n \n       queryPlan = alignByDevicePlan;\n     } else {\n-      queryPlan.setAlignByTime(queryOperator.isAlignByTime());\n+      if (queryPlan instanceof LastQueryPlan) {\n+        queryPlan.setAlignByTime(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc142aaede148e6db7431d3fa3c9d73716aba4c0"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2MDgwMzEzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/LastQueryExecutor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwODowNzoyN1rOF6kxGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwODowNzoyN1rOF6kxGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2NDEyMQ==", "bodyText": "what if the filter is time > 0 ?\nor the latest time point is 10 and the filter is time< 20?", "url": "https://github.com/apache/iotdb/pull/931#discussion_r396964121", "createdAt": "2020-03-24T08:07:27Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/executor/LastQueryExecutor.java", "diffHunk": "@@ -115,55 +116,47 @@ private TimeValuePair calculateLastPairForOneSeries(\n     } catch (MetadataException e) {\n       throw new QueryProcessException(e);\n     }\n-    if (((LeafMNode) node).getCachedLast() != null) {\n+    if (((LeafMNode) node).getCachedLast() != null && timeFilter == null) {\n       return ((LeafMNode) node).getCachedLast();\n     }\n \n-    QueryDataSource dataSource =\n-        QueryResourceManager.getInstance().getQueryDataSource(seriesPath, context, null);\n-\n-    List<TsFileResource> seqFileResources = dataSource.getSeqResources();\n-    List<TsFileResource> unseqFileResources = dataSource.getUnseqResources();\n-\n     TimeValuePair resultPair = new TimeValuePair(Long.MIN_VALUE, null);\n-\n-    if (!seqFileResources.isEmpty()) {\n-      for (int i = seqFileResources.size() - 1; i >= 0; i--) {\n-        List<ChunkMetaData> chunkMetadata =\n-            FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n-                seqFileResources.get(i), seriesPath, context);\n-        if (!chunkMetadata.isEmpty()) {\n-          ChunkMetaData lastChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);\n-          Statistics chunkStatistics = lastChunkMetaData.getStatistics();\n-          resultPair =\n-              constructLastPair(\n+    QueryDataSource queryDataSource =\n+        QueryResourceManager.getInstance().getQueryDataSource(seriesPath, context, timeFilter);\n+    timeFilter = queryDataSource.updateFilterUsingTTL(timeFilter);\n+\n+    InvertedSeriesReader seriesReader =\n+        new InvertedSeriesReader(\n+            seriesPath, tsDataType, context, queryDataSource, timeFilter, null, null);\n+\n+    while (seriesReader.hasNextChunk()) {\n+      // cal by chunk statistics\n+      if (seriesReader.canUseCurrentChunkStatistics()) {\n+        Statistics chunkStatistics = seriesReader.currentChunkStatistics();\n+        if (resultPair == null || resultPair.getTimestamp() < chunkStatistics.getEndTime()) {\n+          resultPair = constructLastPair(\n                   chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), tsDataType);\n-          break;\n         }\n-      }\n-    }\n+        seriesReader.skipCurrentChunk();\n+      } else {\n+        BatchData lastBatchData = null;\n+        while (seriesReader.hasNextPage()) {\n+          lastBatchData = seriesReader.nextPage();\n+        }\n \n-    long version = 0;\n-    for (TsFileResource resource : unseqFileResources) {\n-      if (resource.getEndTimeMap().get(seriesPath.getDevice()) < resultPair.getTimestamp()) {\n-        continue;\n-      }\n-      List<ChunkMetaData> chunkMetadata =\n-          FileLoaderUtils.loadChunkMetadataFromTsFileResource(resource, seriesPath, context);\n-      for (ChunkMetaData chunkMetaData : chunkMetadata) {\n-        if (chunkMetaData.getEndTime() == resultPair.getTimestamp()\n-            && chunkMetaData.getVersion() > version) {\n-          Statistics chunkStatistics = chunkMetaData.getStatistics();\n-          resultPair =\n-              constructLastPair(\n-                  chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), tsDataType);\n-          version = chunkMetaData.getVersion();\n+        if (lastBatchData != null) {\n+          if (resultPair == null || resultPair.getTimestamp() < lastBatchData.getMaxTimestamp()) {\n+            resultPair = new TimeValuePair(\n+                lastBatchData.getMaxTimestamp(),\n+                lastBatchData.getTsPrimitiveTypeByIndex(lastBatchData.length() - 1));\n+          }\n         }\n       }\n     }\n \n     // Update cached last value with low priority\n-    ((LeafMNode) node).updateCachedLast(resultPair, false, Long.MIN_VALUE);\n+    if (timeFilter == null)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc142aaede148e6db7431d3fa3c9d73716aba4c0"}, "originalPosition": 160}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2MDgzMTAyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwODoxNjo0NlrOF6lC4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjozNjozOFrOF--i2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2ODY3Mg==", "bodyText": "update  ttl?", "url": "https://github.com/apache/iotdb/pull/931#discussion_r396968672", "createdAt": "2020-03-24T08:16:46Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +67,51 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void constructReaders(Path path, QueryContext context)\n+      throws StorageEngineException {\n+    Filter timeFilter = constructFilter();\n+    dataReader = new InvertedSeriesReader(path, dataType, context,\n+        QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc142aaede148e6db7431d3fa3c9d73716aba4c0"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MDc2Mw==", "bodyText": "Fixed", "url": "https://github.com/apache/iotdb/pull/931#discussion_r401580763", "createdAt": "2020-04-01T12:36:38Z", "author": {"login": "wshao08"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +67,51 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void constructReaders(Path path, QueryContext context)\n+      throws StorageEngineException {\n+    Filter timeFilter = constructFilter();\n+    dataReader = new InvertedSeriesReader(path, dataType, context,\n+        QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2ODY3Mg=="}, "originalCommit": {"oid": "bc142aaede148e6db7431d3fa3c9d73716aba4c0"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2MDgzMjYzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwODoxNzoxMlrOF6lD2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwODoxNzoxMlrOF6lD2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2ODkyMg==", "bodyText": "remove", "url": "https://github.com/apache/iotdb/pull/931#discussion_r396968922", "createdAt": "2020-03-24T08:17:12Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -18,19 +18,27 @@\n  */\n package org.apache.iotdb.db.query.fill;\n \n+import org.apache.iotdb.db.exception.StorageEngineException;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.control.QueryResourceManager;\n+import org.apache.iotdb.db.query.reader.series.InvertedSeriesReader;\n import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n import org.apache.iotdb.tsfile.read.TimeValuePair;\n import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Path;\n import org.apache.iotdb.tsfile.read.filter.TimeFilter;\n import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n import org.apache.iotdb.tsfile.read.filter.factory.FilterFactory;\n \n import java.io.IOException;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n \n public class PreviousFill extends IFill {\n \n   private long beforeRange;\n   private BatchData batchData;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc142aaede148e6db7431d3fa3c9d73716aba4c0"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTc3MjA2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMjoxNDowMVrOF9XnTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMToyMzowOVrOF9lIfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NDM1MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        lastSeqChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);\n          \n          \n            \n                        lastSeqChunkMetaData = chunkMetadata.get(i);", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399894350", "createdAt": "2020-03-30T02:14:01Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.query.executor;\n+\n+import java.sql.Time;\n+import org.apache.iotdb.db.engine.querycontext.QueryDataSource;\n+import org.apache.iotdb.db.engine.storagegroup.TsFileResource;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.filter.TsFileFilter;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkLoader;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkReader;\n+import org.apache.iotdb.db.utils.FileLoaderUtils;\n+import org.apache.iotdb.db.utils.QueryUtils;\n+import org.apache.iotdb.tsfile.file.metadata.ChunkMetaData;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n+import org.apache.iotdb.tsfile.read.TimeValuePair;\n+import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Chunk;\n+import org.apache.iotdb.tsfile.read.common.Path;\n+import org.apache.iotdb.tsfile.read.controller.IChunkLoader;\n+import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n+import org.apache.iotdb.tsfile.read.reader.IChunkReader;\n+import org.apache.iotdb.tsfile.read.reader.IPageReader;\n+import org.apache.iotdb.tsfile.read.reader.chunk.ChunkReader;\n+\n+import java.io.IOException;\n+import java.util.*;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n+\n+public class PreviousFillExecutor {\n+\n+  private final Path seriesPath;\n+  private final TSDataType dataType;\n+  private final QueryContext context;\n+  private long queryTime;\n+\n+  private final Filter timeFilter;\n+\n+  /*\n+   * file cache\n+   */\n+  private final List<TsFileResource> seqFileResource;\n+  private final PriorityQueue<TsFileResource> unseqFileResource;\n+\n+  /*\n+   * chunk cache\n+   */\n+  private ChunkMetaData lastSeqChunkMetaData;\n+  private final List<ChunkMetaData> chunkMetadatas;\n+\n+  public PreviousFillExecutor(Path seriesPath, TSDataType dataType, QueryContext context,\n+      QueryDataSource dataSource, Filter timeFilter, Filter valueFilter, TsFileFilter fileFilter,\n+      long queryTime) {\n+    this.seriesPath = seriesPath;\n+    this.dataType = dataType;\n+    this.context = context;\n+    QueryUtils.filterQueryDataSource(dataSource, fileFilter);\n+    this.seqFileResource = dataSource.getSeqResources();\n+    this.unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    this.chunkMetadatas = new ArrayList<>();\n+    this.timeFilter = timeFilter;\n+    this.queryTime = queryTime;\n+  }\n+\n+  public TimeValuePair getLastPoint() throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas();\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetaData chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n+      }\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetaData chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n+      }\n+      return lastPoint;\n+    }\n+  }\n+\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(pageStatistics)) {\n+      return constructLastPair(\n+          pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+    } else {\n+      BatchData batchData = pageReader.getAllSatisfiedPageData();\n+      return batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+    }\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private List<IPageReader> unpackChunkReaderToPageReaderList(ChunkMetaData metaData) throws IOException {\n+    if (metaData == null) {\n+      throw new IOException(\"Can't init null chunkMeta\");\n+    }\n+    IChunkReader chunkReader;\n+    IChunkLoader chunkLoader = metaData.getChunkLoader();\n+    if (chunkLoader instanceof MemChunkLoader) {\n+      MemChunkLoader memChunkLoader = (MemChunkLoader) chunkLoader;\n+      chunkReader = new MemChunkReader(memChunkLoader.getChunk(), timeFilter);\n+    } else {\n+      Chunk chunk = chunkLoader.getChunk(metaData);\n+      chunkReader = new ChunkReader(chunk, timeFilter);\n+      chunkReader.hasNextSatisfiedPage();\n+    }\n+    return chunkReader.getPageReaderList();\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * unpack all overlapped seq/unseq files and find the first chunk metadata\n+   */\n+  private void UnpackAllOverlappedFilesToChunkMetadatas() throws IOException {\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.remove(index);\n+      List<ChunkMetaData> chunkMetadata = FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n+          resource, seriesPath, context);\n+      if (!chunkMetadata.isEmpty()) {\n+        for (int i = chunkMetadata.size() - 1; i >= 0; i--) {\n+          if (chunkMetadata.get(i).getStartTime() <= queryTime) {\n+            lastSeqChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf"}, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDExNTgzNg==", "bodyText": "Fixed", "url": "https://github.com/apache/iotdb/pull/931#discussion_r400115836", "createdAt": "2020-03-30T11:23:09Z", "author": {"login": "wshao08"}, "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.query.executor;\n+\n+import java.sql.Time;\n+import org.apache.iotdb.db.engine.querycontext.QueryDataSource;\n+import org.apache.iotdb.db.engine.storagegroup.TsFileResource;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.filter.TsFileFilter;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkLoader;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkReader;\n+import org.apache.iotdb.db.utils.FileLoaderUtils;\n+import org.apache.iotdb.db.utils.QueryUtils;\n+import org.apache.iotdb.tsfile.file.metadata.ChunkMetaData;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n+import org.apache.iotdb.tsfile.read.TimeValuePair;\n+import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Chunk;\n+import org.apache.iotdb.tsfile.read.common.Path;\n+import org.apache.iotdb.tsfile.read.controller.IChunkLoader;\n+import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n+import org.apache.iotdb.tsfile.read.reader.IChunkReader;\n+import org.apache.iotdb.tsfile.read.reader.IPageReader;\n+import org.apache.iotdb.tsfile.read.reader.chunk.ChunkReader;\n+\n+import java.io.IOException;\n+import java.util.*;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n+\n+public class PreviousFillExecutor {\n+\n+  private final Path seriesPath;\n+  private final TSDataType dataType;\n+  private final QueryContext context;\n+  private long queryTime;\n+\n+  private final Filter timeFilter;\n+\n+  /*\n+   * file cache\n+   */\n+  private final List<TsFileResource> seqFileResource;\n+  private final PriorityQueue<TsFileResource> unseqFileResource;\n+\n+  /*\n+   * chunk cache\n+   */\n+  private ChunkMetaData lastSeqChunkMetaData;\n+  private final List<ChunkMetaData> chunkMetadatas;\n+\n+  public PreviousFillExecutor(Path seriesPath, TSDataType dataType, QueryContext context,\n+      QueryDataSource dataSource, Filter timeFilter, Filter valueFilter, TsFileFilter fileFilter,\n+      long queryTime) {\n+    this.seriesPath = seriesPath;\n+    this.dataType = dataType;\n+    this.context = context;\n+    QueryUtils.filterQueryDataSource(dataSource, fileFilter);\n+    this.seqFileResource = dataSource.getSeqResources();\n+    this.unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    this.chunkMetadatas = new ArrayList<>();\n+    this.timeFilter = timeFilter;\n+    this.queryTime = queryTime;\n+  }\n+\n+  public TimeValuePair getLastPoint() throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas();\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetaData chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n+      }\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetaData chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n+      }\n+      return lastPoint;\n+    }\n+  }\n+\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(pageStatistics)) {\n+      return constructLastPair(\n+          pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+    } else {\n+      BatchData batchData = pageReader.getAllSatisfiedPageData();\n+      return batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+    }\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private List<IPageReader> unpackChunkReaderToPageReaderList(ChunkMetaData metaData) throws IOException {\n+    if (metaData == null) {\n+      throw new IOException(\"Can't init null chunkMeta\");\n+    }\n+    IChunkReader chunkReader;\n+    IChunkLoader chunkLoader = metaData.getChunkLoader();\n+    if (chunkLoader instanceof MemChunkLoader) {\n+      MemChunkLoader memChunkLoader = (MemChunkLoader) chunkLoader;\n+      chunkReader = new MemChunkReader(memChunkLoader.getChunk(), timeFilter);\n+    } else {\n+      Chunk chunk = chunkLoader.getChunk(metaData);\n+      chunkReader = new ChunkReader(chunk, timeFilter);\n+      chunkReader.hasNextSatisfiedPage();\n+    }\n+    return chunkReader.getPageReaderList();\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * unpack all overlapped seq/unseq files and find the first chunk metadata\n+   */\n+  private void UnpackAllOverlappedFilesToChunkMetadatas() throws IOException {\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.remove(index);\n+      List<ChunkMetaData> chunkMetadata = FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n+          resource, seriesPath, context);\n+      if (!chunkMetadata.isEmpty()) {\n+        for (int i = chunkMetadata.size() - 1; i >= 0; i--) {\n+          if (chunkMetadata.get(i).getStartTime() <= queryTime) {\n+            lastSeqChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NDM1MA=="}, "originalCommit": {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf"}, "originalPosition": 182}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTc4NTg2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMjoyNDo1N1rOF9XvRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMTo0OTo0N1rOF_Yl_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NjM5MA==", "bodyText": "Suppose the queried time is 100.\nseq files: [1,10], [11,20], [200, 300]\nunseq files: [30, 40], [41, 50], [51, 60]\nIt's better not to find the lastSeqChunkMetadata but the last chunkmetadata between seq and unseq.", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399896390", "createdAt": "2020-03-30T02:24:57Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.query.executor;\n+\n+import java.sql.Time;\n+import org.apache.iotdb.db.engine.querycontext.QueryDataSource;\n+import org.apache.iotdb.db.engine.storagegroup.TsFileResource;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.filter.TsFileFilter;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkLoader;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkReader;\n+import org.apache.iotdb.db.utils.FileLoaderUtils;\n+import org.apache.iotdb.db.utils.QueryUtils;\n+import org.apache.iotdb.tsfile.file.metadata.ChunkMetaData;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n+import org.apache.iotdb.tsfile.read.TimeValuePair;\n+import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Chunk;\n+import org.apache.iotdb.tsfile.read.common.Path;\n+import org.apache.iotdb.tsfile.read.controller.IChunkLoader;\n+import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n+import org.apache.iotdb.tsfile.read.reader.IChunkReader;\n+import org.apache.iotdb.tsfile.read.reader.IPageReader;\n+import org.apache.iotdb.tsfile.read.reader.chunk.ChunkReader;\n+\n+import java.io.IOException;\n+import java.util.*;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n+\n+public class PreviousFillExecutor {\n+\n+  private final Path seriesPath;\n+  private final TSDataType dataType;\n+  private final QueryContext context;\n+  private long queryTime;\n+\n+  private final Filter timeFilter;\n+\n+  /*\n+   * file cache\n+   */\n+  private final List<TsFileResource> seqFileResource;\n+  private final PriorityQueue<TsFileResource> unseqFileResource;\n+\n+  /*\n+   * chunk cache\n+   */\n+  private ChunkMetaData lastSeqChunkMetaData;\n+  private final List<ChunkMetaData> chunkMetadatas;\n+\n+  public PreviousFillExecutor(Path seriesPath, TSDataType dataType, QueryContext context,\n+      QueryDataSource dataSource, Filter timeFilter, Filter valueFilter, TsFileFilter fileFilter,\n+      long queryTime) {\n+    this.seriesPath = seriesPath;\n+    this.dataType = dataType;\n+    this.context = context;\n+    QueryUtils.filterQueryDataSource(dataSource, fileFilter);\n+    this.seqFileResource = dataSource.getSeqResources();\n+    this.unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    this.chunkMetadatas = new ArrayList<>();\n+    this.timeFilter = timeFilter;\n+    this.queryTime = queryTime;\n+  }\n+\n+  public TimeValuePair getLastPoint() throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas();\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetaData chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n+      }\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetaData chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n+      }\n+      return lastPoint;\n+    }\n+  }\n+\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(pageStatistics)) {\n+      return constructLastPair(\n+          pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+    } else {\n+      BatchData batchData = pageReader.getAllSatisfiedPageData();\n+      return batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+    }\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private List<IPageReader> unpackChunkReaderToPageReaderList(ChunkMetaData metaData) throws IOException {\n+    if (metaData == null) {\n+      throw new IOException(\"Can't init null chunkMeta\");\n+    }\n+    IChunkReader chunkReader;\n+    IChunkLoader chunkLoader = metaData.getChunkLoader();\n+    if (chunkLoader instanceof MemChunkLoader) {\n+      MemChunkLoader memChunkLoader = (MemChunkLoader) chunkLoader;\n+      chunkReader = new MemChunkReader(memChunkLoader.getChunk(), timeFilter);\n+    } else {\n+      Chunk chunk = chunkLoader.getChunk(metaData);\n+      chunkReader = new ChunkReader(chunk, timeFilter);\n+      chunkReader.hasNextSatisfiedPage();\n+    }\n+    return chunkReader.getPageReaderList();\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * unpack all overlapped seq/unseq files and find the first chunk metadata\n+   */\n+  private void UnpackAllOverlappedFilesToChunkMetadatas() throws IOException {\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.remove(index);\n+      List<ChunkMetaData> chunkMetadata = FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n+          resource, seriesPath, context);\n+      if (!chunkMetadata.isEmpty()) {\n+        for (int i = chunkMetadata.size() - 1; i >= 0; i--) {\n+          if (chunkMetadata.get(i).getStartTime() <= queryTime) {\n+            lastSeqChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);\n+            chunkMetadatas.add(lastSeqChunkMetaData);\n+            break;\n+          }\n+        }\n+        break;\n+      }\n+    }\n+\n+    while (!unseqFileResource.isEmpty()\n+        && (lastSeqChunkMetaData == null || (lastSeqChunkMetaData.getStartTime()\n+        <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())))) {\n+      chunkMetadatas.addAll(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAwNzU0OQ==", "bodyText": "modified", "url": "https://github.com/apache/iotdb/pull/931#discussion_r402007549", "createdAt": "2020-04-02T01:49:47Z", "author": {"login": "wshao08"}, "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.query.executor;\n+\n+import java.sql.Time;\n+import org.apache.iotdb.db.engine.querycontext.QueryDataSource;\n+import org.apache.iotdb.db.engine.storagegroup.TsFileResource;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.filter.TsFileFilter;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkLoader;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkReader;\n+import org.apache.iotdb.db.utils.FileLoaderUtils;\n+import org.apache.iotdb.db.utils.QueryUtils;\n+import org.apache.iotdb.tsfile.file.metadata.ChunkMetaData;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n+import org.apache.iotdb.tsfile.read.TimeValuePair;\n+import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Chunk;\n+import org.apache.iotdb.tsfile.read.common.Path;\n+import org.apache.iotdb.tsfile.read.controller.IChunkLoader;\n+import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n+import org.apache.iotdb.tsfile.read.reader.IChunkReader;\n+import org.apache.iotdb.tsfile.read.reader.IPageReader;\n+import org.apache.iotdb.tsfile.read.reader.chunk.ChunkReader;\n+\n+import java.io.IOException;\n+import java.util.*;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n+\n+public class PreviousFillExecutor {\n+\n+  private final Path seriesPath;\n+  private final TSDataType dataType;\n+  private final QueryContext context;\n+  private long queryTime;\n+\n+  private final Filter timeFilter;\n+\n+  /*\n+   * file cache\n+   */\n+  private final List<TsFileResource> seqFileResource;\n+  private final PriorityQueue<TsFileResource> unseqFileResource;\n+\n+  /*\n+   * chunk cache\n+   */\n+  private ChunkMetaData lastSeqChunkMetaData;\n+  private final List<ChunkMetaData> chunkMetadatas;\n+\n+  public PreviousFillExecutor(Path seriesPath, TSDataType dataType, QueryContext context,\n+      QueryDataSource dataSource, Filter timeFilter, Filter valueFilter, TsFileFilter fileFilter,\n+      long queryTime) {\n+    this.seriesPath = seriesPath;\n+    this.dataType = dataType;\n+    this.context = context;\n+    QueryUtils.filterQueryDataSource(dataSource, fileFilter);\n+    this.seqFileResource = dataSource.getSeqResources();\n+    this.unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    this.chunkMetadatas = new ArrayList<>();\n+    this.timeFilter = timeFilter;\n+    this.queryTime = queryTime;\n+  }\n+\n+  public TimeValuePair getLastPoint() throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas();\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetaData chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n+      }\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetaData chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n+      }\n+      return lastPoint;\n+    }\n+  }\n+\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(pageStatistics)) {\n+      return constructLastPair(\n+          pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+    } else {\n+      BatchData batchData = pageReader.getAllSatisfiedPageData();\n+      return batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+    }\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private List<IPageReader> unpackChunkReaderToPageReaderList(ChunkMetaData metaData) throws IOException {\n+    if (metaData == null) {\n+      throw new IOException(\"Can't init null chunkMeta\");\n+    }\n+    IChunkReader chunkReader;\n+    IChunkLoader chunkLoader = metaData.getChunkLoader();\n+    if (chunkLoader instanceof MemChunkLoader) {\n+      MemChunkLoader memChunkLoader = (MemChunkLoader) chunkLoader;\n+      chunkReader = new MemChunkReader(memChunkLoader.getChunk(), timeFilter);\n+    } else {\n+      Chunk chunk = chunkLoader.getChunk(metaData);\n+      chunkReader = new ChunkReader(chunk, timeFilter);\n+      chunkReader.hasNextSatisfiedPage();\n+    }\n+    return chunkReader.getPageReaderList();\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * unpack all overlapped seq/unseq files and find the first chunk metadata\n+   */\n+  private void UnpackAllOverlappedFilesToChunkMetadatas() throws IOException {\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.remove(index);\n+      List<ChunkMetaData> chunkMetadata = FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n+          resource, seriesPath, context);\n+      if (!chunkMetadata.isEmpty()) {\n+        for (int i = chunkMetadata.size() - 1; i >= 0; i--) {\n+          if (chunkMetadata.get(i).getStartTime() <= queryTime) {\n+            lastSeqChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);\n+            chunkMetadatas.add(lastSeqChunkMetaData);\n+            break;\n+          }\n+        }\n+        break;\n+      }\n+    }\n+\n+    while (!unseqFileResource.isEmpty()\n+        && (lastSeqChunkMetaData == null || (lastSeqChunkMetaData.getStartTime()\n+        <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())))) {\n+      chunkMetadatas.addAll(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NjM5MA=="}, "originalCommit": {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf"}, "originalPosition": 194}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTc4OTE1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMjoyNzoxOFrOF9XxJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMjoyNzoxOFrOF9XxJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5Njg3MQ==", "bodyText": "the pageReader must satisfy this timeFilter, otherwise it will be removed when unpack the ChunkMetadata. This check is not needed.", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399896871", "createdAt": "2020-03-30T02:27:18Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.query.executor;\n+\n+import java.sql.Time;\n+import org.apache.iotdb.db.engine.querycontext.QueryDataSource;\n+import org.apache.iotdb.db.engine.storagegroup.TsFileResource;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.filter.TsFileFilter;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkLoader;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkReader;\n+import org.apache.iotdb.db.utils.FileLoaderUtils;\n+import org.apache.iotdb.db.utils.QueryUtils;\n+import org.apache.iotdb.tsfile.file.metadata.ChunkMetaData;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n+import org.apache.iotdb.tsfile.read.TimeValuePair;\n+import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Chunk;\n+import org.apache.iotdb.tsfile.read.common.Path;\n+import org.apache.iotdb.tsfile.read.controller.IChunkLoader;\n+import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n+import org.apache.iotdb.tsfile.read.reader.IChunkReader;\n+import org.apache.iotdb.tsfile.read.reader.IPageReader;\n+import org.apache.iotdb.tsfile.read.reader.chunk.ChunkReader;\n+\n+import java.io.IOException;\n+import java.util.*;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n+\n+public class PreviousFillExecutor {\n+\n+  private final Path seriesPath;\n+  private final TSDataType dataType;\n+  private final QueryContext context;\n+  private long queryTime;\n+\n+  private final Filter timeFilter;\n+\n+  /*\n+   * file cache\n+   */\n+  private final List<TsFileResource> seqFileResource;\n+  private final PriorityQueue<TsFileResource> unseqFileResource;\n+\n+  /*\n+   * chunk cache\n+   */\n+  private ChunkMetaData lastSeqChunkMetaData;\n+  private final List<ChunkMetaData> chunkMetadatas;\n+\n+  public PreviousFillExecutor(Path seriesPath, TSDataType dataType, QueryContext context,\n+      QueryDataSource dataSource, Filter timeFilter, Filter valueFilter, TsFileFilter fileFilter,\n+      long queryTime) {\n+    this.seriesPath = seriesPath;\n+    this.dataType = dataType;\n+    this.context = context;\n+    QueryUtils.filterQueryDataSource(dataSource, fileFilter);\n+    this.seqFileResource = dataSource.getSeqResources();\n+    this.unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    this.chunkMetadatas = new ArrayList<>();\n+    this.timeFilter = timeFilter;\n+    this.queryTime = queryTime;\n+  }\n+\n+  public TimeValuePair getLastPoint() throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas();\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetaData chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n+      }\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetaData chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n+      }\n+      return lastPoint;\n+    }\n+  }\n+\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTc5MDg3OnYy", "diffSide": "RIGHT", "path": "tsfile/src/main/java/org/apache/iotdb/tsfile/read/common/BatchData.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMjoyODo0MVrOF9XyLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxMToyMjo1OFrOF9lIJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzEzMg==", "bodyText": "Is this method used?", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399897132", "createdAt": "2020-03-30T02:28:41Z", "author": {"login": "qiaojialin"}, "path": "tsfile/src/main/java/org/apache/iotdb/tsfile/read/common/BatchData.java", "diffHunk": "@@ -533,6 +534,35 @@ public boolean getBooleanByIndex(int idx) {\n     return booleanRet.get(idx / capacity)[idx % capacity];\n   }\n \n+  public TsPrimitiveType getTsPrimitiveTypeByIndex(int idx) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDExNTc1MA==", "bodyText": "This is legacy code, removed", "url": "https://github.com/apache/iotdb/pull/931#discussion_r400115750", "createdAt": "2020-03-30T11:22:58Z", "author": {"login": "wshao08"}, "path": "tsfile/src/main/java/org/apache/iotdb/tsfile/read/common/BatchData.java", "diffHunk": "@@ -533,6 +534,35 @@ public boolean getBooleanByIndex(int idx) {\n     return booleanRet.get(idx / capacity)[idx % capacity];\n   }\n \n+  public TsPrimitiveType getTsPrimitiveTypeByIndex(int idx) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzEzMg=="}, "originalCommit": {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3OTc5NDYyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQwMjozMTo0OFrOF9X0WA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxMjo1ODo0N1rOF-_ZLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzY4OA==", "bodyText": "Move these to the constructor of PreviousFill, leave empty for the constructReaders. The LinearFill should also be refactored, then this method will be removed", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399897688", "createdAt": "2020-03-30T02:31:48Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -61,26 +68,19 @@ public long getBeforeRange() {\n \n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n-      }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n-        break;\n-      }\n-    }\n+    return executor.getLastPoint();\n+  }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n-    }\n-    return beforePair;\n+  @Override\n+  public void constructReaders(Path path, QueryContext context)\n+      throws StorageEngineException {\n+    Filter timeFilter = constructFilter();\n+    QueryDataSource queryDataSource =\n+        QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = queryDataSource.updateFilterUsingTTL(timeFilter);\n+    executor = new PreviousFillExecutor(\n+        path, dataType, context, queryDataSource, timeFilter, null, null, queryTime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU5NDY3MQ==", "bodyText": "Removed, move these init code into configureFill", "url": "https://github.com/apache/iotdb/pull/931#discussion_r401594671", "createdAt": "2020-04-01T12:58:47Z", "author": {"login": "wshao08"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -61,26 +68,19 @@ public long getBeforeRange() {\n \n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n-      }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n-        break;\n-      }\n-    }\n+    return executor.getLastPoint();\n+  }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n-    }\n-    return beforePair;\n+  @Override\n+  public void constructReaders(Path path, QueryContext context)\n+      throws StorageEngineException {\n+    Filter timeFilter = constructFilter();\n+    QueryDataSource queryDataSource =\n+        QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = queryDataSource.updateFilterUsingTTL(timeFilter);\n+    executor = new PreviousFillExecutor(\n+        path, dataType, context, queryDataSource, timeFilter, null, null, queryTime);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzY4OA=="}, "originalCommit": {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzE5MTYzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/FillQueryExecutor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjowNjowOVrOF_Y1ZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjowNjowOVrOF_Y1ZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAxMTQ5Mw==", "bodyText": "store context in FIll, remove the parameter in getFillResult", "url": "https://github.com/apache/iotdb/pull/931#discussion_r402011493", "createdAt": "2020-04-02T02:06:09Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/executor/FillQueryExecutor.java", "diffHunk": "@@ -89,9 +89,10 @@ public QueryDataSet execute(QueryContext context, FillQueryPlan fillQueryPlan)\n       } else {\n         fill = typeIFillMap.get(dataType).copy();\n       }\n-      configureFill(fill, dataType, path, fillQueryPlan.getAllSensorsInDevice(path.getDevice()), context, queryTime);\n+      fill.configureFill(path, dataType, queryTime,\n+          fillQueryPlan.getAllSensorsInDevice(path.getDevice()), context);\n \n-      TimeValuePair timeValuePair = fill.getFillResult();\n+      TimeValuePair timeValuePair = fill.getFillResult(context);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a04a5255b1ab02808b3caef84998e7b9224c178"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzI0OTc3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjo0MTowNFrOF_ZXIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjo0MTowNFrOF_ZXIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyMDEyOQ==", "bodyText": "the timeFilter  can not be null", "url": "https://github.com/apache/iotdb/pull/931#discussion_r402020129", "createdAt": "2020-04-02T02:41:04Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -60,27 +98,162 @@ public long getBeforeRange() {\n   }\n \n   @Override\n-  public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+  public TimeValuePair getFillResult(QueryContext context) throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas(context);\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetadata chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n-        break;\n+    }\n+    return lastPoint;\n+  }\n+\n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n       }\n+      return lastPoint;\n     }\n+  }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(pageStatistics)) {\n+      return constructLastPair(\n+          pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n     } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+      BatchData batchData = pageReader.getAllSatisfiedPageData();\n+      return batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+    }\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private List<IPageReader> unpackChunkReaderToPageReaderList(ChunkMetadata metaData) throws IOException {\n+    if (metaData == null) {\n+      throw new IOException(\"Can't init null chunkMeta\");\n     }\n-    return beforePair;\n+    IChunkReader chunkReader;\n+    IChunkLoader chunkLoader = metaData.getChunkLoader();\n+    if (chunkLoader instanceof MemChunkLoader) {\n+      MemChunkLoader memChunkLoader = (MemChunkLoader) chunkLoader;\n+      chunkReader = new MemChunkReader(memChunkLoader.getChunk(), timeFilter);\n+    } else {\n+      Chunk chunk = chunkLoader.getChunk(metaData);\n+      chunkReader = new ChunkReader(chunk, timeFilter);\n+      chunkReader.hasNextSatisfiedPage();\n+    }\n+    return chunkReader.getPageReaderList();\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * find the last chunk metadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackAllOverlappedFilesToChunkMetadatas(QueryContext context) throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    PriorityQueue<TsFileResource> unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata = FileLoaderUtils.loadTimeSeriesMetadata(\n+          resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        // The last seq file satisfies timeFilter, pick up the last chunk\n+        List<ChunkMetadata> chunkMetadata = timeseriesMetadata.getChunkMetadataList();\n+        lastChunkMetadata = chunkMetadata.get(chunkMetadata.size() - 1);\n+        chunkMetadatas.addAll(chunkMetadata);\n+        break;\n+      }\n+      seqFileResource.remove(index);\n+    }\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      TsFileResource resource = unseqFileResource.peek();\n+      TimeseriesMetadata timeseriesMetadata = FileLoaderUtils.loadTimeSeriesMetadata(\n+          resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        List<ChunkMetadata> chunkMetadatas = timeseriesMetadata.getChunkMetadataList();\n+        ChunkMetadata lastUnseqChunkMetadata = chunkMetadatas.get(chunkMetadatas.size() - 1);\n+        if (lastChunkMetadata == null) {\n+          lastChunkMetadata = lastUnseqChunkMetadata;\n+        } else if (lastChunkMetadata.getEndTime() < lastUnseqChunkMetadata.getEndTime()) {\n+          lastChunkMetadata = lastUnseqChunkMetadata;\n+        }\n+        break;\n+      }\n+      unseqFileResource.poll();\n+    }\n+\n+    // unpack all overlapped unseq files and fill chunkMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lastChunkMetadata == null || (lastChunkMetadata.getStartTime()\n+        <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())))) {\n+      chunkMetadatas.addAll(\n+          FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n+              unseqFileResource.poll(), seriesPath, context));\n+    }\n+  }\n+\n+  private boolean containedByTimeFilter(Statistics statistics) {\n+    return timeFilter == null", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a04a5255b1ab02808b3caef84998e7b9224c178"}, "originalPosition": 245}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MzI1MDYzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjo0MTo0MFrOF_ZXqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMjo0MTo0MFrOF_ZXqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyMDI2NQ==", "bodyText": "this may produce NullPointerException", "url": "https://github.com/apache/iotdb/pull/931#discussion_r402020265", "createdAt": "2020-04-02T02:41:40Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -60,27 +98,162 @@ public long getBeforeRange() {\n   }\n \n   @Override\n-  public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+  public TimeValuePair getFillResult(QueryContext context) throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas(context);\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetadata chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a04a5255b1ab02808b3caef84998e7b9224c178"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5OTYyNzI5OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxMzo0Mzo0MFrOGAWDmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QxMzo0Mzo0MFrOGAWDmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzAxNDU1NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * find the last chunk metadata and unpack all overlapped seq/unseq files\n          \n          \n            \n               * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files", "url": "https://github.com/apache/iotdb/pull/931#discussion_r403014555", "createdAt": "2020-04-03T13:43:40Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -60,27 +87,143 @@ public long getBeforeRange() {\n   }\n \n   @Override\n-  public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n+  @Override\n+  public TimeValuePair getFillResult(QueryContext context) throws IOException {\n+    UnpackOverlappedFilesToTimeseriesMetadata(context);\n+    return getTimeseriesLastPoint();\n+  }\n+\n+  private  TimeValuePair getTimeseriesLastPoint() throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!timeseriesMetadataList.isEmpty()) {\n+      TimeseriesMetadata timeseriesMetadata = timeseriesMetadataList.remove(0);\n+      List<ChunkMetadata> chunkMetadataList = timeseriesMetadata.loadChunkMetadataList();\n+      for (ChunkMetadata chunkMetadata : chunkMetadataList) {\n+        TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+        if (shouldUpdate(lastPoint.getTimestamp(), lastVersion,\n+            lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+          lastPoint = lastChunkPoint;\n+          lastVersion = chunkMetadata.getVersion();\n+        }\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return lastPoint;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    }\n+    List<IPageReader> pageReaders = FileLoaderUtils.loadPageReader(chunkMetaData, timeFilter);\n+    for (int i = pageReaders.size() - 1; i >= 0; i--) {\n+      IPageReader pageReader = pageReaders.get(i);\n+      Statistics pageStatistics = pageReader.getStatistics();\n+      if (!timeFilter.satisfy(pageStatistics)) {\n+        continue;\n+      }\n+      if (containedByTimeFilter(pageStatistics)) {\n+        lastPoint = constructLastPair(\n+            pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n       } else {\n+        BatchData batchData = pageReader.getAllSatisfiedPageData();\n+        lastPoint = batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+      }\n+      break;\n+    }\n+    return lastPoint;\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * find the last chunk metadata and unpack all overlapped seq/unseq files", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f0b44d5f2aacad05f3e761255e3d8e93c68b723a"}, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMTEyMzk3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozNjo1MlrOGDboIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozNjo1MlrOGDboIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1MTU1NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                TimeValuePair lastPoint = new TimeValuePair(0, null);\n          \n          \n            \n                TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406251555", "createdAt": "2020-04-09T14:36:52Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b355ad25834a7ea21bb73922c2f5013f0b1f5694"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMTEyODMwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozODowM1rOGDbrDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozODowM1rOGDbrDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1MjMwMw==", "bodyText": "Suppose two unseq files have the same endTime, they should all be unpacked.", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406252303", "createdAt": "2020-04-09T14:38:03Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+        break;\n+      }\n+    }\n+\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b355ad25834a7ea21bb73922c2f5013f0b1f5694"}, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMTEyOTU4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozODoxOVrOGDbr2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozODoxOVrOGDbr2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1MjUwNw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                TimeValuePair lastPoint = new TimeValuePair(0, null);\n          \n          \n            \n                TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406252507", "createdAt": "2020-04-09T14:38:19Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+        break;\n+      }\n+    }\n+\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n         break;\n       }\n     }\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b355ad25834a7ea21bb73922c2f5013f0b1f5694"}, "originalPosition": 183}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMTEzMjQ0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozODo1NlrOGDbtrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozODo1NlrOGDbtrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1Mjk3Mg==", "bodyText": "no need to check, pageReaders got from chunkmetadata should satisfy the timeFilter already", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406252972", "createdAt": "2020-04-09T14:38:56Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+        break;\n+      }\n+    }\n+\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n         break;\n       }\n     }\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+\n+    if (endtimeContainedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    }\n+    List<IPageReader> pageReaders = FileLoaderUtils.loadPageReaderList(chunkMetaData, timeFilter);\n+    for (int i = pageReaders.size() - 1; i >= 0; i--) {\n+      IPageReader pageReader = pageReaders.get(i);\n+      Statistics pageStatistics = pageReader.getStatistics();\n+      if (!timeFilter.satisfy(pageStatistics)) {\n+        continue;\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b355ad25834a7ea21bb73922c2f5013f0b1f5694"}, "originalPosition": 196}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMTEzNjU1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozOTo0NFrOGDbwGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDozOTo0NFrOGDbwGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1MzU5Mw==", "bodyText": "no need to remove(0),just traverse is ok. Otherwise, use LinkedList for higher efficiency", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406253593", "createdAt": "2020-04-09T14:39:44Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+        break;\n+      }\n+    }\n+\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n         break;\n       }\n     }\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+\n+    if (endtimeContainedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    }\n+    List<IPageReader> pageReaders = FileLoaderUtils.loadPageReaderList(chunkMetaData, timeFilter);\n+    for (int i = pageReaders.size() - 1; i >= 0; i--) {\n+      IPageReader pageReader = pageReaders.get(i);\n+      Statistics pageStatistics = pageReader.getStatistics();\n+      if (!timeFilter.satisfy(pageStatistics)) {\n+        continue;\n+      }\n+      if (endtimeContainedByTimeFilter(pageStatistics)) {\n+        lastPoint = constructLastPair(\n+            pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+      } else {\n+        BatchData batchData = pageReader.getAllSatisfiedPageData();\n+        lastPoint = batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+      }\n+      break;\n+    }\n+    return lastPoint;\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+  private PriorityQueue<ChunkMetadata> sortUnseqChunkMetadatasByEndtime() throws IOException {\n+    PriorityQueue<ChunkMetadata> chunkMetadataList =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              long endTime1 = o1.getEndTime();\n+              long endTime2 = o2.getEndTime();\n+              if (endTime1 < endTime2) {\n+                return 1;\n+              } else if (endTime1 > endTime2) {\n+                return -1;\n+              }\n+              return Long.compare(o2.getVersion(), o1.getVersion());\n+            });\n+    while (!unseqTimeseriesMetadataList.isEmpty()) {\n+      chunkMetadataList.addAll(unseqTimeseriesMetadataList.remove(0).loadChunkMetadataList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b355ad25834a7ea21bb73922c2f5013f0b1f5694"}, "originalPosition": 247}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMTEzOTYwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDo0MDoyNlrOGDbyEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOVQxNDo0MDoyNlrOGDbyEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1NDA5Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n          \n          \n            \n                    && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406254097", "createdAt": "2020-04-09T14:40:26Z", "author": {"login": "qiaojialin"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b355ad25834a7ea21bb73922c2f5013f0b1f5694"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMzEwODg0OnYy", "diffSide": "RIGHT", "path": "tsfile/src/main/java/org/apache/iotdb/tsfile/read/common/BatchData.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwMTo1MDo0MlrOGDuwzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMTowNjo0MFrOGD3suA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2NTA2OQ==", "bodyText": "What if the currentTime is not at the first index before i call the getLastPairBeforeOrEqualTimestamp method.\nSo, you should call the resetBatchData() method at the beginning of the method or you should add a javadoc for this method to remind caller that function caller should ensure the current place.", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406565069", "createdAt": "2020-04-10T01:50:42Z", "author": {"login": "JackieTien97"}, "path": "tsfile/src/main/java/org/apache/iotdb/tsfile/read/common/BatchData.java", "diffHunk": "@@ -533,6 +534,16 @@ public boolean getBooleanByIndex(int idx) {\n     return booleanRet.get(idx / capacity)[idx % capacity];\n   }\n \n+  public TimeValuePair getLastPairBeforeOrEqualTimestamp(long queryTime) {\n+    TimeValuePair resultPair = new TimeValuePair(Long.MIN_VALUE, null);\n+    while (hasCurrent() && (currentTime() <= queryTime)) {\n+      resultPair.setTimestamp(currentTime());\n+      resultPair.setValue(currentTsPrimitiveType());\n+      next();\n+    }\n+    return resultPair;\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2NTM2NQ==", "bodyText": "And BTW, i think you can improve your search way like using binary search instead of the linear search way because the time array is in order and are all loaded into memory.", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406565365", "createdAt": "2020-04-10T01:52:03Z", "author": {"login": "JackieTien97"}, "path": "tsfile/src/main/java/org/apache/iotdb/tsfile/read/common/BatchData.java", "diffHunk": "@@ -533,6 +534,16 @@ public boolean getBooleanByIndex(int idx) {\n     return booleanRet.get(idx / capacity)[idx % capacity];\n   }\n \n+  public TimeValuePair getLastPairBeforeOrEqualTimestamp(long queryTime) {\n+    TimeValuePair resultPair = new TimeValuePair(Long.MIN_VALUE, null);\n+    while (hasCurrent() && (currentTime() <= queryTime)) {\n+      resultPair.setTimestamp(currentTime());\n+      resultPair.setValue(currentTsPrimitiveType());\n+      next();\n+    }\n+    return resultPair;\n+  }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2NTA2OQ=="}, "originalCommit": {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjcxMTQ4MA==", "bodyText": "Added resetBatchData() at the beginning.", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406711480", "createdAt": "2020-04-10T11:06:40Z", "author": {"login": "wshao08"}, "path": "tsfile/src/main/java/org/apache/iotdb/tsfile/read/common/BatchData.java", "diffHunk": "@@ -533,6 +534,16 @@ public boolean getBooleanByIndex(int idx) {\n     return booleanRet.get(idx / capacity)[idx % capacity];\n   }\n \n+  public TimeValuePair getLastPairBeforeOrEqualTimestamp(long queryTime) {\n+    TimeValuePair resultPair = new TimeValuePair(Long.MIN_VALUE, null);\n+    while (hasCurrent() && (currentTime() <= queryTime)) {\n+      resultPair.setTimestamp(currentTime());\n+      resultPair.setValue(currentTsPrimitiveType());\n+      next();\n+    }\n+    return resultPair;\n+  }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2NTA2OQ=="}, "originalCommit": {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMzEzNjcyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwMjowNzozN1rOGDvAhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMTowNjoyMVrOGD3sbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2OTA5NQ==", "bodyText": "Before you use the statistics info you should use the canUseStatistics() method in the Statistics class to judge whether the statistics can be used. Because may be the chunk has been modified.\nNot only here, chunk statistics and page statistics are the same", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406569095", "createdAt": "2020-04-10T02:07:37Z", "author": {"login": "JackieTien97"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,183 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjcxMTQwNA==", "bodyText": "Fixed", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406711404", "createdAt": "2020-04-10T11:06:21Z", "author": {"login": "wshao08"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,183 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2OTA5NQ=="}, "originalCommit": {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMzE1MDYyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwMjoxNjoxNVrOGDvIeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMTowNjoxNlrOGD3sXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU3MTEyOQ==", "bodyText": "same as above, remember use canUseStatistics()", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406571129", "createdAt": "2020-04-10T02:16:15Z", "author": {"login": "JackieTien97"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,183 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n         break;\n       }\n     }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())\n+          && timeseriesMetadata.getStatistics().getEndTime()\n+              > unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8"}, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjcxMTM4OA==", "bodyText": "Fixed", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406711388", "createdAt": "2020-04-10T11:06:16Z", "author": {"login": "wshao08"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,183 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n         break;\n       }\n     }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())\n+          && timeseriesMetadata.getStatistics().getEndTime()\n+              > unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU3MTEyOQ=="}, "originalCommit": {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8"}, "originalPosition": 182}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyMzg1NjA4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQwOTowOToxN1rOGD1cnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMTowNjowNlrOGD3sNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3NDU4OQ==", "bodyText": "with a break, the for loop is not used", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406674589", "createdAt": "2020-04-10T09:09:17Z", "author": {"login": "samperson1997"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,183 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n         break;\n       }\n     }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())\n+          && timeseriesMetadata.getStatistics().getEndTime()\n+              > unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())) {\n+        break;\n+      }\n     }\n-    return beforePair;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+\n+    if (endtimeContainedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    }\n+    List<IPageReader> pageReaders = FileLoaderUtils.loadPageReaderList(chunkMetaData, timeFilter);\n+    for (int i = pageReaders.size() - 1; i >= 0; i--) {\n+      IPageReader pageReader = pageReaders.get(i);\n+      Statistics pageStatistics = pageReader.getStatistics();\n+      if (endtimeContainedByTimeFilter(pageStatistics)) {\n+        lastPoint = constructLastPair(\n+            pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+      } else {\n+        BatchData batchData = pageReader.getAllSatisfiedPageData();\n+        lastPoint = batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+      }\n+      break;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8"}, "originalPosition": 209}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjcxMTM1MA==", "bodyText": "Fixed", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406711350", "createdAt": "2020-04-10T11:06:06Z", "author": {"login": "wshao08"}, "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,183 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n         break;\n       }\n     }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())\n+          && timeseriesMetadata.getStatistics().getEndTime()\n+              > unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())) {\n+        break;\n+      }\n     }\n-    return beforePair;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+\n+    if (endtimeContainedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    }\n+    List<IPageReader> pageReaders = FileLoaderUtils.loadPageReaderList(chunkMetaData, timeFilter);\n+    for (int i = pageReaders.size() - 1; i >= 0; i--) {\n+      IPageReader pageReader = pageReaders.get(i);\n+      Statistics pageStatistics = pageReader.getStatistics();\n+      if (endtimeContainedByTimeFilter(pageStatistics)) {\n+        lastPoint = constructLastPair(\n+            pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+      } else {\n+        BatchData batchData = pageReader.getAllSatisfiedPageData();\n+        lastPoint = batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+      }\n+      break;\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3NDU4OQ=="}, "originalCommit": {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8"}, "originalPosition": 209}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDU1ODAyOnYy", "diffSide": "RIGHT", "path": "site/src/main/.vuepress/config.js", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoyMTo1NFrOGD72kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoyMTo1NFrOGD72kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3OTUzOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\t\t  '5-DataQuery/1-DataQuery',\n          \n          \n            \n                          '5-DataQuery/2-SeriesReader',\n          \n          \n            \n                          '5-DataQuery/3-RawDataQuery',\n          \n          \n            \n                          '5-DataQuery/4-AggregationQuery',\n          \n          \n            \n                          '5-DataQuery/5-GroupByQuery',\n          \n          \n            \n                          '5-DataQuery/6-LastQuery',\n          \n          \n            \n                          '5-DataQuery/7-AlignByDeviceQuery',\n          \n          \n            \n                          '5-DataQuery/8-ModificationHandle',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/1-DataQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/2-SeriesReader',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/3-RawDataQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/4-AggregationQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/5-GroupByQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/6-LastQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/7-AlignByDeviceQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/8-ModificationHandle',", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406779538", "createdAt": "2020-04-10T14:21:54Z", "author": {"login": "qiaojialin"}, "path": "site/src/main/.vuepress/config.js", "diffHunk": "@@ -423,14 +423,14 @@ var config = {\n \t\t\t\t\t{\n \t\t\t\t\t\ttitle: '5-DataQuery',\n \t\t\t\t\t\tchildren: [\n-\t\t\t\t\t\t\t'5-DataQuery/1-DataQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/2-SeriesReader',\n-\t\t\t\t\t\t\t'5-DataQuery/3-RawDataQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/4-AggregationQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/5-GroupByQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/6-LastQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/7-AlignByDeviceQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/8-ModificationHandle',\n+\t\t\t\t\t\t  '5-DataQuery/1-DataQuery',\n+              '5-DataQuery/2-SeriesReader',\n+              '5-DataQuery/3-RawDataQuery',\n+              '5-DataQuery/4-AggregationQuery',\n+              '5-DataQuery/5-GroupByQuery',\n+              '5-DataQuery/6-LastQuery',\n+              '5-DataQuery/7-AlignByDeviceQuery',\n+              '5-DataQuery/8-ModificationHandle',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b96be9ba35ec6ea44d3a17d49fbd852a8632f4"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDU2MDg3OnYy", "diffSide": "RIGHT", "path": "site/src/main/.vuepress/config.js", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoyMjo1NFrOGD74SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoyMjo1NFrOGD74SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3OTk3Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\t\t  '5-DataQuery/1-DataQuery',\n          \n          \n            \n                          '5-DataQuery/2-SeriesReader',\n          \n          \n            \n                          '5-DataQuery/3-RawDataQuery',\n          \n          \n            \n                          '5-DataQuery/4-AggregationQuery',\n          \n          \n            \n                          '5-DataQuery/5-GroupByQuery',\n          \n          \n            \n                          '5-DataQuery/6-LastQuery',\n          \n          \n            \n                          '5-DataQuery/7-AlignByDeviceQuery',\n          \n          \n            \n                          '5-DataQuery/8-ModificationHandle',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/1-DataQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/2-SeriesReader',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/3-RawDataQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/4-AggregationQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/5-GroupByQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/6-LastQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/7-AlignByDeviceQuery',\n          \n          \n            \n            \t\t\t\t\t\t\t'5-DataQuery/8-ModificationHandle',", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406779976", "createdAt": "2020-04-10T14:22:54Z", "author": {"login": "qiaojialin"}, "path": "site/src/main/.vuepress/config.js", "diffHunk": "@@ -821,14 +821,14 @@ var config = {\n \t\t\t\t\t{\n \t\t\t\t\t\ttitle: '5-\u6570\u636e\u67e5\u8be2',\n \t\t\t\t\t\tchildren: [\n-\t\t\t\t\t\t\t'5-DataQuery/1-DataQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/2-SeriesReader',\n-\t\t\t\t\t\t\t'5-DataQuery/3-RawDataQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/4-AggregationQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/5-GroupByQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/6-LastQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/7-AlignByDeviceQuery',\n-\t\t\t\t\t\t\t'5-DataQuery/8-ModificationHandle',\n+\t\t\t\t\t\t  '5-DataQuery/1-DataQuery',\n+              '5-DataQuery/2-SeriesReader',\n+              '5-DataQuery/3-RawDataQuery',\n+              '5-DataQuery/4-AggregationQuery',\n+              '5-DataQuery/5-GroupByQuery',\n+              '5-DataQuery/6-LastQuery',\n+              '5-DataQuery/7-AlignByDeviceQuery',\n+              '5-DataQuery/8-ModificationHandle',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b96be9ba35ec6ea44d3a17d49fbd852a8632f4"}, "originalPosition": 42}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 145, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}