{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY2MTk0Mzcz", "number": 11898, "title": "Balder/all in single chunk", "bodyText": "@vekterli PR", "createdAt": "2020-01-23T05:59:01Z", "url": "https://github.com/vespa-engine/vespa/pull/11898", "merged": true, "mergeCommit": {"oid": "51d4b6fcc2dd00909365ebe9e9c797d341a12d33"}, "closed": true, "closedAt": "2020-01-23T17:09:00Z", "author": {"login": "baldersheim"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb9D5bUgH2gAyMzY2MTk0MzczOjY5NGU1M2Y4MzJlNjUwMTBmMjQ2YmE5ZWY0YWIwMjc5NjcwMGM4NzM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb9NFWRgH2gAyMzY2MTk0MzczOjRkMjRhZTM5Y2QxNzI0NzQ1MDJiN2EzYTJiN2M0M2YyNjMzOGQ4NmY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "694e53f832e65010f246ba9ef4ab02796700c873", "author": {"user": {"login": "baldersheim", "name": "Henning Baldersheim"}}, "url": "https://github.com/vespa-engine/vespa/commit/694e53f832e65010f246ba9ef4ab02796700c873", "committedDate": "2020-01-23T05:56:45Z", "message": "Use a single chunk"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca8545560297ee05c5d22eb4888613adbeb6e7f8", "author": {"user": {"login": "baldersheim", "name": "Henning Baldersheim"}}, "url": "https://github.com/vespa-engine/vespa/commit/ca8545560297ee05c5d22eb4888613adbeb6e7f8", "committedDate": "2020-01-23T05:56:45Z", "message": "Remove cloneability."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f438cdcdae81a9fd55dc370a42af85b275a934c", "author": {"user": {"login": "baldersheim", "name": "Henning Baldersheim"}}, "url": "https://github.com/vespa-engine/vespa/commit/9f438cdcdae81a9fd55dc370a42af85b275a934c", "committedDate": "2020-01-23T05:56:45Z", "message": "Add indirection for the unlikely stuff to keep the likely members close and tight."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "753c6869ac764e8b1463ba214980c82401479a88", "author": {"user": {"login": "baldersheim", "name": "Henning Baldersheim"}}, "url": "https://github.com/vespa-engine/vespa/commit/753c6869ac764e8b1463ba214980c82401479a88", "committedDate": "2020-01-23T05:56:45Z", "message": "Remove ByteBuffer indirection."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d2e89d0e9fea8e19720dedfca283f4f788958d7", "author": {"user": {"login": "baldersheim", "name": "Henning Baldersheim"}}, "url": "https://github.com/vespa-engine/vespa/commit/5d2e89d0e9fea8e19720dedfca283f4f788958d7", "committedDate": "2020-01-23T05:56:45Z", "message": "Just use the stack"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e7f0c18c77929909632121f9baa52805addc4842", "author": {"user": {"login": "baldersheim", "name": "Henning Baldersheim"}}, "url": "https://github.com/vespa-engine/vespa/commit/e7f0c18c77929909632121f9baa52805addc4842", "committedDate": "2020-01-23T09:23:47Z", "message": "Move the transaction implementation from StructuredFieldValue to Document"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a97a9c569be961b79bea5990296f414d7f3f935", "author": {"user": {"login": "baldersheim", "name": "Henning Baldersheim"}}, "url": "https://github.com/vespa-engine/vespa/commit/7a97a9c569be961b79bea5990296f414d7f3f935", "committedDate": "2020-01-23T11:59:54Z", "message": "Avoid duplicating information."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3MTcyNTYz", "url": "https://github.com/vespa-engine/vespa/pull/11898#pullrequestreview-347172563", "createdAt": "2020-01-23T09:54:26Z", "commit": {"oid": "694e53f832e65010f246ba9ef4ab02796700c873"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QwOTo1NDoyNlrOFg4WtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxNTo1Nzo1MlrOFhDfXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDAyMjA2OQ==", "bodyText": "Consider adding a if (&rhs != this) { self-assignment guard if this makes sense to have", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370022069", "createdAt": "2020-01-23T09:54:26Z", "author": {"login": "vekterli"}, "path": "document/src/vespa/document/fieldvalue/serializablearray.cpp", "diffHunk": "@@ -81,6 +81,13 @@ SerializableArray::SerializableArray(const SerializableArray& other)\n     }\n }\n \n+SerializableArray &\n+SerializableArray::operator=(const SerializableArray &rhs)\n+{\n+    *this = SerializableArray(rhs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "694e53f832e65010f246ba9ef4ab02796700c873"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3NDI5OQ==", "bodyText": "As an aside, assuming there's no member with a potentially throwing destructor (marked noexcept(false)) destructors are implicitly noexcept by default. But even the core guidelines aren't 100% on when to specify it or not (https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#c37-make-destructors-noexcept) so a core, complex type like this is probably a good place to have them.", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370074299", "createdAt": "2020-01-23T11:51:35Z", "author": {"login": "vekterli"}, "path": "document/src/vespa/document/base/documentid.cpp", "diffHunk": "@@ -29,7 +29,7 @@ DocumentId::DocumentId(vespalib::nbostream & is)\n \n DocumentId::DocumentId(const DocumentId & rhs) = default;\n DocumentId & DocumentId::operator = (const DocumentId & rhs) = default;\n-DocumentId::~DocumentId() = default;\n+DocumentId::~DocumentId() noexcept = default;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7f0c18c77929909632121f9baa52805addc4842"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNDA0Ng==", "bodyText": "Consider renaming this type to something that describes the semantics a bit more. LazyUncompressableFieldData or something down that lane?", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370114046", "createdAt": "2020-01-23T13:26:00Z", "author": {"login": "vekterli"}, "path": "document/src/vespa/document/fieldvalue/serializablearray.h", "diffHunk": "@@ -159,17 +162,22 @@ class SerializableArray : public vespalib::Cloneable\n     }\n     void deCompress(); // throw (DeserializeException);\n \n+    struct Unlikely {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7f0c18c77929909632121f9baa52805addc4842"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE3NTY3Mg==", "bodyText": "Presumably if we've merged two legacy chunks down to one, this ends up transitively setting hasChanged() == true for the struct, thereby causing it to be re-serialized as one chunk (as would be expected)?", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370175672", "createdAt": "2020-01-23T15:11:50Z", "author": {"login": "vekterli"}, "path": "document/src/vespa/document/serialization/vespadocumentserializer.cpp", "diffHunk": "@@ -86,89 +86,45 @@ void VespaDocumentSerializer::write(const DocumentType &value) {\n             << static_cast<uint16_t>(0);  // version\n }\n \n+namespace {\n+\n uint8_t\n-VespaDocumentSerializer::getContentCode(bool hasHeader, bool hasBody) const\n+getContentCode(bool hasContent)\n {\n-    uint8_t content = 0x01;  // Document type is always present.\n-    if (hasHeader) {\n-        content |= 0x02;  // Header is present.\n-    }\n-    if (hasBody) {\n-        content |= 0x04;  // Body is present.\n-    }\n-    return content;\n+    return 0x01u |  // Document type is always present\n+           (hasContent ? 0x02u : 0x00u);   // Payload ?\n }\n \n-static inline size_t wantChunks(bool hasHeader, bool hasBody) {\n-    size_t res = 0;\n-    if (hasHeader) ++res;\n-    if (hasBody) ++res;\n-    return res;\n }\n \n void\n-VespaDocumentSerializer::write(const Document &value, DocSerializationMode mode) {\n+VespaDocumentSerializer::write(const Document &value) {\n     nbostream doc_stream;\n     VespaDocumentSerializer doc_serializer(doc_stream);\n     doc_serializer.write(value.getId());\n \n-    bool hasHeader = false;\n-    bool hasBody = false;\n-\n-    const StructFieldValue::Chunks & chunks = value.getFields().getChunks();\n-\n-    for (const Field & field : value.getFields()) {\n-        if (field.isHeaderField()) {\n-            hasHeader = true;\n-        } else {\n-            hasBody = true;\n-        }\n-        if (hasHeader && hasBody) {\n-            break;\n-        }\n-    }\n-    if (mode != COMPLETE) {\n-        hasBody = false;\n-    }\n-    doc_stream << getContentCode(hasHeader, hasBody);\n+    bool hasContent = ! value.getFields().empty();\n+    doc_stream << getContentCode(hasContent);\n     doc_serializer.write(value.getType());\n \n-    if (chunks.size() == wantChunks(hasHeader, hasBody) &&\n-        !structNeedsReserialization(value.getFields()))\n-    {\n-        // here we assume the receiver can handle whatever serialization the\n-        // chunks contain, so we just send them as-is, even if some fields\n-        // may have moved from header to body or vice versa.\n-        if (hasHeader || hasBody) {\n-            assert( ! chunks.empty());\n-            doc_serializer.writeUnchanged(chunks[0]);\n-        }\n-        if (hasHeader && hasBody) {\n-            assert(chunks.size() == 2);\n-            doc_serializer.writeUnchanged(chunks[1]);\n-        }\n-    } else {\n-        if (hasHeader) {\n-            doc_serializer.write(value.getFields(), HeaderFields());\n-        }\n-        if (hasBody) {\n-            doc_serializer.write(value.getFields(), BodyFields());\n+    if ( hasContent ) {\n+        if (!structNeedsReserialization(value.getFields())) {\n+            doc_serializer.writeUnchanged(value.getFields().getFields());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7f0c18c77929909632121f9baa52805addc4842"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE3Nzg2Nw==", "bodyText": "Nit: spurious extra indent", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370177867", "createdAt": "2020-01-23T15:15:28Z", "author": {"login": "vekterli"}, "path": "storage/src/tests/persistence/processalltest.cpp", "diffHunk": "@@ -166,7 +165,7 @@ TEST_F(ProcessAllHandlerTest, stat_bucket_request_can_returned_removed_entries)\n         \"  Timestamp: 208, id:mail:testdoctype1:n=4:42967.html, gid(0x04000000f19ece1668e6de48) (remove)\\n\"\n         \"  Timestamp: 209, id:mail:testdoctype1:n=4:6925.html, gid(0x04000000667c0b3cada830be) (remove)\\n\";\n \n-    EXPECT_EQ(expected, reply.getResults());\n+        EXPECT_EQ(expected, reply.getResults());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7f0c18c77929909632121f9baa52805addc4842"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE5Mzk2MA==", "bodyText": "Is it possible for _unlikely to be nullptr at this point?", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370193960", "createdAt": "2020-01-23T15:40:45Z", "author": {"login": "vekterli"}, "path": "document/src/vespa/document/fieldvalue/serializablearray.cpp", "diffHunk": "@@ -26,84 +26,103 @@ class BufferMap : public BufferMapT {\n \n }\n \n-SerializableArray::SerializableArray()\n-    : _serializedCompression(CompressionConfig::NONE),\n-      _uncompressedLength(0)\n-{\n-}\n+SerializableArray::SerializableArray() = default;\n \n-SerializableArray::SerializableArray(EntryMap entries, ByteBuffer::UP buffer,\n+SerializableArray::SerializableArray(EntryMap entries, ByteBuffer buffer,\n                                      CompressionConfig::Type comp_type, uint32_t uncompressed_length)\n     : _entries(std::move(entries)),\n-      _owned(),\n-      _serializedCompression(comp_type)\n+      _uncompSerData(),\n+      _unlikely()\n {\n \n-    if (CompressionConfig::isCompressed(_serializedCompression)) {\n-        _compSerData = std::move(buffer);\n-        _uncompressedLength = uncompressed_length;\n+    if (CompressionConfig::isCompressed(comp_type)) {\n+        _unlikely = std::make_unique<Unlikely>();\n+        _unlikely->_compSerData = std::move(buffer);\n+        _unlikely->_serializedCompression = comp_type;\n+        _unlikely->_uncompressedLength = uncompressed_length;\n     } else {\n-        _uncompressedLength = buffer->getRemaining();\n         _uncompSerData = std::move(buffer);\n     }\n }\n \n-serializablearray::BufferMap &\n-ensure(std::unique_ptr<serializablearray::BufferMap> & owned) {\n+SerializableArray::SerializableArray(SerializableArray &&) noexcept = default;\n+SerializableArray& SerializableArray::operator=(SerializableArray &&) noexcept = default;\n+SerializableArray::~SerializableArray() = default;\n+\n+namespace {\n+\n+template <typename T>\n+T &\n+ensure(std::unique_ptr<T> &owned) {\n     if (!owned) {\n-        owned = std::make_unique<serializablearray::BufferMap>();\n+        owned = std::make_unique<T>();\n     }\n     return *owned;\n }\n \n-SerializableArray::SerializableArray(const SerializableArray& other)\n-    : Cloneable(),\n-      _entries(other._entries),\n-      _owned(),\n-      _uncompSerData(other._uncompSerData.get() ? new ByteBuffer(*other._uncompSerData) : nullptr),\n-      _compSerData(other._compSerData.get() ? new ByteBuffer(*other._compSerData) : nullptr),\n-      _serializedCompression(other._serializedCompression),\n-      _uncompressedLength(other._uncompressedLength)\n+}\n+\n+SerializableArray::Unlikely::Unlikely()\n+    : _owned(),\n+      _compSerData(nullptr, 0),\n+      _serializedCompression(CompressionConfig::NONE),\n+      _uncompressedLength(0)\n+{ }\n+SerializableArray::Unlikely::~Unlikely() = default;\n+\n+SerializableArray::Unlikely::Unlikely(const Unlikely & rhs)\n+    : _owned(),\n+      _compSerData(rhs._compSerData),\n+      _serializedCompression(rhs._serializedCompression),\n+      _uncompressedLength(rhs._uncompressedLength)\n+{ }\n+\n+SerializableArray::SerializableArray(const SerializableArray& rhs)\n+    : _entries(rhs._entries),\n+      _uncompSerData(rhs._uncompSerData),\n+      _unlikely(rhs._unlikely ? new Unlikely(*rhs._unlikely) : nullptr)\n {\n     for (size_t i(0); i < _entries.size(); i++) {\n         Entry & e(_entries[i]);\n         if (e.hasBuffer()) {\n             // Pointing to a buffer in the _owned structure.\n-            ByteBuffer::UP buf(ByteBuffer::copyBuffer(e.getBuffer(_uncompSerData.get()), e.size()));\n-            e.setBuffer(buf->getBuffer());\n-            ensure(_owned)[e.id()] = std::move(buf);\n+            ByteBuffer buf(ByteBuffer::copyBuffer(e.getBuffer(&_uncompSerData), e.size()));\n+            e.setBuffer(buf.getBuffer());\n+            ensure(_unlikely->_owned)[e.id()] = std::move(buf);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a97a9c569be961b79bea5990296f414d7f3f935"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwMDExNw==", "bodyText": "Wondering if we should add an assert(buffer.getRemaining() < 0x80000000) to ensure Entry does not get tricked into believing the size MSB means something else than it does (it decides union interpretation based on this today).", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370200117", "createdAt": "2020-01-23T15:50:38Z", "author": {"login": "vekterli"}, "path": "document/src/vespa/document/fieldvalue/serializablearray.cpp", "diffHunk": "@@ -26,84 +26,103 @@ class BufferMap : public BufferMapT {\n \n }\n \n-SerializableArray::SerializableArray()\n-    : _serializedCompression(CompressionConfig::NONE),\n-      _uncompressedLength(0)\n-{\n-}\n+SerializableArray::SerializableArray() = default;\n \n-SerializableArray::SerializableArray(EntryMap entries, ByteBuffer::UP buffer,\n+SerializableArray::SerializableArray(EntryMap entries, ByteBuffer buffer,\n                                      CompressionConfig::Type comp_type, uint32_t uncompressed_length)\n     : _entries(std::move(entries)),\n-      _owned(),\n-      _serializedCompression(comp_type)\n+      _uncompSerData(),\n+      _unlikely()\n {\n \n-    if (CompressionConfig::isCompressed(_serializedCompression)) {\n-        _compSerData = std::move(buffer);\n-        _uncompressedLength = uncompressed_length;\n+    if (CompressionConfig::isCompressed(comp_type)) {\n+        _unlikely = std::make_unique<Unlikely>();\n+        _unlikely->_compSerData = std::move(buffer);\n+        _unlikely->_serializedCompression = comp_type;\n+        _unlikely->_uncompressedLength = uncompressed_length;\n     } else {\n-        _uncompressedLength = buffer->getRemaining();\n         _uncompSerData = std::move(buffer);\n     }\n }\n \n-serializablearray::BufferMap &\n-ensure(std::unique_ptr<serializablearray::BufferMap> & owned) {\n+SerializableArray::SerializableArray(SerializableArray &&) noexcept = default;\n+SerializableArray& SerializableArray::operator=(SerializableArray &&) noexcept = default;\n+SerializableArray::~SerializableArray() = default;\n+\n+namespace {\n+\n+template <typename T>\n+T &\n+ensure(std::unique_ptr<T> &owned) {\n     if (!owned) {\n-        owned = std::make_unique<serializablearray::BufferMap>();\n+        owned = std::make_unique<T>();\n     }\n     return *owned;\n }\n \n-SerializableArray::SerializableArray(const SerializableArray& other)\n-    : Cloneable(),\n-      _entries(other._entries),\n-      _owned(),\n-      _uncompSerData(other._uncompSerData.get() ? new ByteBuffer(*other._uncompSerData) : nullptr),\n-      _compSerData(other._compSerData.get() ? new ByteBuffer(*other._compSerData) : nullptr),\n-      _serializedCompression(other._serializedCompression),\n-      _uncompressedLength(other._uncompressedLength)\n+}\n+\n+SerializableArray::Unlikely::Unlikely()\n+    : _owned(),\n+      _compSerData(nullptr, 0),\n+      _serializedCompression(CompressionConfig::NONE),\n+      _uncompressedLength(0)\n+{ }\n+SerializableArray::Unlikely::~Unlikely() = default;\n+\n+SerializableArray::Unlikely::Unlikely(const Unlikely & rhs)\n+    : _owned(),\n+      _compSerData(rhs._compSerData),\n+      _serializedCompression(rhs._serializedCompression),\n+      _uncompressedLength(rhs._uncompressedLength)\n+{ }\n+\n+SerializableArray::SerializableArray(const SerializableArray& rhs)\n+    : _entries(rhs._entries),\n+      _uncompSerData(rhs._uncompSerData),\n+      _unlikely(rhs._unlikely ? new Unlikely(*rhs._unlikely) : nullptr)\n {\n     for (size_t i(0); i < _entries.size(); i++) {\n         Entry & e(_entries[i]);\n         if (e.hasBuffer()) {\n             // Pointing to a buffer in the _owned structure.\n-            ByteBuffer::UP buf(ByteBuffer::copyBuffer(e.getBuffer(_uncompSerData.get()), e.size()));\n-            e.setBuffer(buf->getBuffer());\n-            ensure(_owned)[e.id()] = std::move(buf);\n+            ByteBuffer buf(ByteBuffer::copyBuffer(e.getBuffer(&_uncompSerData), e.size()));\n+            e.setBuffer(buf.getBuffer());\n+            ensure(_unlikely->_owned)[e.id()] = std::move(buf);\n         } else {\n             // If not it is relative to the buffer _uncompSerData, and hence it is valid as is.\n         }\n     }\n-    if (_uncompSerData.get()) {\n-        LOG_ASSERT(_uncompressedLength == _uncompSerData->getRemaining());\n-    }\n+}\n+\n+SerializableArray &\n+SerializableArray::operator=(const SerializableArray &rhs)\n+{\n+    *this = SerializableArray(rhs);\n+    return *this;\n }\n \n void SerializableArray::clear()\n {\n     _entries.clear();\n-    _uncompSerData.reset();\n-    _compSerData.reset();\n-    _serializedCompression = CompressionConfig::NONE;\n-    _uncompressedLength = 0;\n+    _uncompSerData = ByteBuffer(nullptr, 0);\n+    _unlikely.reset();\n }\n \n-SerializableArray::~SerializableArray() = default;\n-\n void\n SerializableArray::invalidate()\n {\n-    _compSerData.reset();\n+    if (_unlikely) {\n+        _unlikely->_compSerData = ByteBuffer(nullptr, 0);;\n+    }\n }\n \n void\n-SerializableArray::set(int id, ByteBuffer::UP buffer)\n+SerializableArray::set(int id, ByteBuffer buffer)\n {\n     maybeDecompress();\n-    Entry e(id, buffer->getRemaining(), buffer->getBuffer());\n-    ensure(_owned)[id] = std::move(buffer);\n+    Entry e(id, buffer.getRemaining(), buffer.getBuffer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a97a9c569be961b79bea5990296f414d7f3f935"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwNDUwOQ==", "bodyText": "Will this be enough of a change in size that it will fail some sizeof-checking unit tests? PR build is broken on a presumably unrelated Java unit test, so C++ tests haven't been run.", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370204509", "createdAt": "2020-01-23T15:57:52Z", "author": {"login": "vekterli"}, "path": "document/src/vespa/document/base/idstring.h", "diffHunk": "@@ -57,7 +59,7 @@ class IdString {\n     private:\n         static constexpr uint32_t MAX_COMPONENTS = 4;\n         Offsets(vespalib::stringref id);\n-        uint16_t _offsets[MAX_COMPONENTS + 1];\n+        uint16_t _offsets[MAX_COMPONENTS];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a97a9c569be961b79bea5990296f414d7f3f935"}, "originalPosition": 27}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "19c8f9406297f359c0e04e7bda9f12ef625f1df6", "author": {"user": {"login": "baldersheim", "name": "Henning Baldersheim"}}, "url": "https://github.com/vespa-engine/vespa/commit/19c8f9406297f359c0e04e7bda9f12ef625f1df6", "committedDate": "2020-01-23T16:18:43Z", "message": "Add an extra indirection to the rarely used owned buffers, in order to keep the frequently accesed members in StructFieldValue close"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d24ae39cd172474502b7a3a2b7c43f26338d86f", "author": {"user": {"login": "baldersheim", "name": "Henning Baldersheim"}}, "url": "https://github.com/vespa-engine/vespa/commit/4d24ae39cd172474502b7a3a2b7c43f26338d86f", "committedDate": "2020-01-23T16:38:55Z", "message": "Followup on code comments."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3974, "cost": 1, "resetAt": "2021-10-28T20:13:43Z"}}}