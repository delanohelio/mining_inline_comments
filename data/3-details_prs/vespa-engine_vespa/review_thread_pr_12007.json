{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY5MDIzNDk1", "number": 12007, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMjozNTo1MVrODdUOGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMjozNTo1MVrODdUOGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMDY2NTg2OnYy", "diffSide": "RIGHT", "path": "document/src/tests/documenttestcase.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMjozNTo1MVrOFl2NwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMzo1MDoxM1rOFl4V6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTIyOTg4OA==", "bodyText": "Do we have any files checked in testing that we can read from legacy multi-chunk serializations, or is this sufficiently ancient by now that we don't consider it necessary anymore?", "url": "https://github.com/vespa-engine/vespa/pull/12007#discussion_r375229888", "createdAt": "2020-02-05T12:35:51Z", "author": {"login": "vekterli"}, "path": "document/src/tests/documenttestcase.cpp", "diffHunk": "@@ -585,7 +585,7 @@ TEST(DocumentTest, testReadSerializedFile)\n \n     EXPECT_TRUE(buf2.empty());\n     buf2.rp(0);\n-    EXPECT_EQ(len - 13, buf2.size()); // Size is smaller as we are merging to one chunk.\n+    EXPECT_EQ(len, buf2.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc6c05c46211b0c061f99408232bd5740a625107"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTI2NDc0Nw==", "bodyText": "It is fairly ancient, but I still think we have some.\nI will check.", "url": "https://github.com/vespa-engine/vespa/pull/12007#discussion_r375264747", "createdAt": "2020-02-05T13:50:13Z", "author": {"login": "baldersheim"}, "path": "document/src/tests/documenttestcase.cpp", "diffHunk": "@@ -585,7 +585,7 @@ TEST(DocumentTest, testReadSerializedFile)\n \n     EXPECT_TRUE(buf2.empty());\n     buf2.rp(0);\n-    EXPECT_EQ(len - 13, buf2.size()); // Size is smaller as we are merging to one chunk.\n+    EXPECT_EQ(len, buf2.size());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTIyOTg4OA=="}, "originalCommit": {"oid": "cc6c05c46211b0c061f99408232bd5740a625107"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2557, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}