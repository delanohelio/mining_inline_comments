{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA5NDY5ODE1", "number": 13080, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMjo0MToxMFrOD2qSCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMjo1MTowNVrOD2qkPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4NjQyNDQwOnYy", "diffSide": "RIGHT", "path": "storage/src/vespa/storage/persistence/persistencethread.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMjo0MToxMFrOGMhD1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMzoyNDowNFrOGMi9vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc3Nzc0OQ==", "bodyText": "Consider updating log message to no longer talk about looping", "url": "https://github.com/vespa-engine/vespa/pull/13080#discussion_r415777749", "createdAt": "2020-04-27T12:41:10Z", "author": {"login": "vekterli"}, "path": "storage/src/vespa/storage/persistence/persistencethread.cpp", "diffHunk": "@@ -894,115 +894,24 @@ bool hasBucketInfo(const api::StorageMessage& msg)\n \n }\n \n-void\n-PersistenceThread::flushAllReplies(\n-        const document::Bucket& bucket,\n-        std::vector<std::unique_ptr<MessageTracker> >& replies)\n-{\n-    if (replies.empty()) {\n-        return;\n-    }\n-\n-    try {\n-        if (replies.size() > 1) {\n-            _env._metrics.batchingSize.addValue(replies.size());\n-        }\n-#ifdef ENABLE_BUCKET_OPERATION_LOGGING\n-        {\n-            size_t nputs = 0, nremoves = 0, nother = 0;\n-            for (size_t i = 0; i < replies.size(); ++i) {\n-                if (dynamic_cast<api::PutReply*>(replies[i]->getReply().get()))\n-                {\n-                    ++nputs;\n-                } else if (dynamic_cast<api::RemoveReply*>(\n-                                replies[i]->getReply().get()))\n-                {\n-                    ++nremoves;\n-                } else {\n-                    ++nother;\n-                }\n-            }\n-            LOG_BUCKET_OPERATION(\n-                    bucket.getBucketId(),\n-                    vespalib::make_string(\n-                            \"flushing %zu operations (%zu puts, %zu removes, \"\n-                            \"%zu other)\",\n-                            replies.size(), nputs, nremoves, nother));\n-        }\n-#endif\n-        spi::Bucket b(bucket, spi::PartitionId(_env._partition));\n-        // Flush is not used for anything currentlu, and the context is not correct either when batching is done\n-        // So just faking it here.\n-        spi::Context dummyContext(documentapi::LoadType::DEFAULT, 0, 0);\n-        spi::Result result = _spi.flush(b, dummyContext);\n-        uint32_t errorCode = _env.convertErrorCode(result);\n-        if (errorCode != 0) {\n-            for (uint32_t i = 0; i < replies.size(); ++i) {\n-                replies[i]->getReply()->setResult(api::ReturnCode((api::ReturnCode::Result)errorCode, result.getErrorMessage()));\n-            }\n-        }\n-    } catch (std::exception& e) {\n-        for (uint32_t i = 0; i < replies.size(); ++i) {\n-            replies[i]->getReply()->setResult(api::ReturnCode(api::ReturnCode::INTERNAL_FAILURE, e.what()));\n-        }\n-    }\n-\n-    for (uint32_t i = 0; i < replies.size(); ++i) {\n-        LOG(spam, \"Sending reply up (batched): %s %\" PRIu64,\n-            replies[i]->getReply()->toString().c_str(), replies[i]->getReply()->getMsgId());\n-        _env._fileStorHandler.sendReply(replies[i]->getReply());\n-    }\n-\n-    replies.clear();\n-}\n-\n-void PersistenceThread::processMessages(FileStorHandler::LockedMessage & lock)\n-{\n+void PersistenceThread::processMessages(FileStorHandler::LockedMessage & lock) {\n     std::vector<MessageTracker::UP> trackers;\n     document::Bucket bucket = lock.first->getBucket();\n \n-    while (lock.second) {\n-        LOG(debug, \"Inside while loop %d, nodeIndex %d, ptr=%p\", _env._partition, _env._nodeIndex, lock.second.get());\n-        std::shared_ptr<api::StorageMessage> msg(lock.second);\n-        bool batchable = isBatchable(*msg);\n-\n-        // If the next operation wasn't batchable, we should flush\n-        // everything that came before.\n-        if (!batchable) {\n-            flushAllReplies(bucket, trackers);\n-        }\n-\n-        std::unique_ptr<MessageTracker> tracker = processMessage(*msg);\n-        if (!tracker || !tracker->getReply()) {\n-            // Was a reply\n-            break;\n-        }\n+    LOG(debug, \"Inside while loop %d, nodeIndex %d, ptr=%p\", _env._partition, _env._nodeIndex, lock.second.get());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f0a7a14d639059f4d9de3001fc96d95219f499b2"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTgwODk1OA==", "bodyText": "Fixed", "url": "https://github.com/vespa-engine/vespa/pull/13080#discussion_r415808958", "createdAt": "2020-04-27T13:24:04Z", "author": {"login": "baldersheim"}, "path": "storage/src/vespa/storage/persistence/persistencethread.cpp", "diffHunk": "@@ -894,115 +894,24 @@ bool hasBucketInfo(const api::StorageMessage& msg)\n \n }\n \n-void\n-PersistenceThread::flushAllReplies(\n-        const document::Bucket& bucket,\n-        std::vector<std::unique_ptr<MessageTracker> >& replies)\n-{\n-    if (replies.empty()) {\n-        return;\n-    }\n-\n-    try {\n-        if (replies.size() > 1) {\n-            _env._metrics.batchingSize.addValue(replies.size());\n-        }\n-#ifdef ENABLE_BUCKET_OPERATION_LOGGING\n-        {\n-            size_t nputs = 0, nremoves = 0, nother = 0;\n-            for (size_t i = 0; i < replies.size(); ++i) {\n-                if (dynamic_cast<api::PutReply*>(replies[i]->getReply().get()))\n-                {\n-                    ++nputs;\n-                } else if (dynamic_cast<api::RemoveReply*>(\n-                                replies[i]->getReply().get()))\n-                {\n-                    ++nremoves;\n-                } else {\n-                    ++nother;\n-                }\n-            }\n-            LOG_BUCKET_OPERATION(\n-                    bucket.getBucketId(),\n-                    vespalib::make_string(\n-                            \"flushing %zu operations (%zu puts, %zu removes, \"\n-                            \"%zu other)\",\n-                            replies.size(), nputs, nremoves, nother));\n-        }\n-#endif\n-        spi::Bucket b(bucket, spi::PartitionId(_env._partition));\n-        // Flush is not used for anything currentlu, and the context is not correct either when batching is done\n-        // So just faking it here.\n-        spi::Context dummyContext(documentapi::LoadType::DEFAULT, 0, 0);\n-        spi::Result result = _spi.flush(b, dummyContext);\n-        uint32_t errorCode = _env.convertErrorCode(result);\n-        if (errorCode != 0) {\n-            for (uint32_t i = 0; i < replies.size(); ++i) {\n-                replies[i]->getReply()->setResult(api::ReturnCode((api::ReturnCode::Result)errorCode, result.getErrorMessage()));\n-            }\n-        }\n-    } catch (std::exception& e) {\n-        for (uint32_t i = 0; i < replies.size(); ++i) {\n-            replies[i]->getReply()->setResult(api::ReturnCode(api::ReturnCode::INTERNAL_FAILURE, e.what()));\n-        }\n-    }\n-\n-    for (uint32_t i = 0; i < replies.size(); ++i) {\n-        LOG(spam, \"Sending reply up (batched): %s %\" PRIu64,\n-            replies[i]->getReply()->toString().c_str(), replies[i]->getReply()->getMsgId());\n-        _env._fileStorHandler.sendReply(replies[i]->getReply());\n-    }\n-\n-    replies.clear();\n-}\n-\n-void PersistenceThread::processMessages(FileStorHandler::LockedMessage & lock)\n-{\n+void PersistenceThread::processMessages(FileStorHandler::LockedMessage & lock) {\n     std::vector<MessageTracker::UP> trackers;\n     document::Bucket bucket = lock.first->getBucket();\n \n-    while (lock.second) {\n-        LOG(debug, \"Inside while loop %d, nodeIndex %d, ptr=%p\", _env._partition, _env._nodeIndex, lock.second.get());\n-        std::shared_ptr<api::StorageMessage> msg(lock.second);\n-        bool batchable = isBatchable(*msg);\n-\n-        // If the next operation wasn't batchable, we should flush\n-        // everything that came before.\n-        if (!batchable) {\n-            flushAllReplies(bucket, trackers);\n-        }\n-\n-        std::unique_ptr<MessageTracker> tracker = processMessage(*msg);\n-        if (!tracker || !tracker->getReply()) {\n-            // Was a reply\n-            break;\n-        }\n+    LOG(debug, \"Inside while loop %d, nodeIndex %d, ptr=%p\", _env._partition, _env._nodeIndex, lock.second.get());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc3Nzc0OQ=="}, "originalCommit": {"oid": "f0a7a14d639059f4d9de3001fc96d95219f499b2"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4NjQ3MTAxOnYy", "diffSide": "RIGHT", "path": "storage/src/vespa/storage/persistence/persistencethread.cpp", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMjo1MTowNVrOGMhehQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxMzoyNDoxOFrOGMi-bQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc4NDU4MQ==", "bodyText": "Consider updating name to not be plural anymore (probably something like processLockedMessage to avoid colliding with existing processMessage", "url": "https://github.com/vespa-engine/vespa/pull/13080#discussion_r415784581", "createdAt": "2020-04-27T12:51:05Z", "author": {"login": "vekterli"}, "path": "storage/src/vespa/storage/persistence/persistencethread.cpp", "diffHunk": "@@ -894,115 +894,24 @@ bool hasBucketInfo(const api::StorageMessage& msg)\n \n }\n \n-void\n-PersistenceThread::flushAllReplies(\n-        const document::Bucket& bucket,\n-        std::vector<std::unique_ptr<MessageTracker> >& replies)\n-{\n-    if (replies.empty()) {\n-        return;\n-    }\n-\n-    try {\n-        if (replies.size() > 1) {\n-            _env._metrics.batchingSize.addValue(replies.size());\n-        }\n-#ifdef ENABLE_BUCKET_OPERATION_LOGGING\n-        {\n-            size_t nputs = 0, nremoves = 0, nother = 0;\n-            for (size_t i = 0; i < replies.size(); ++i) {\n-                if (dynamic_cast<api::PutReply*>(replies[i]->getReply().get()))\n-                {\n-                    ++nputs;\n-                } else if (dynamic_cast<api::RemoveReply*>(\n-                                replies[i]->getReply().get()))\n-                {\n-                    ++nremoves;\n-                } else {\n-                    ++nother;\n-                }\n-            }\n-            LOG_BUCKET_OPERATION(\n-                    bucket.getBucketId(),\n-                    vespalib::make_string(\n-                            \"flushing %zu operations (%zu puts, %zu removes, \"\n-                            \"%zu other)\",\n-                            replies.size(), nputs, nremoves, nother));\n-        }\n-#endif\n-        spi::Bucket b(bucket, spi::PartitionId(_env._partition));\n-        // Flush is not used for anything currentlu, and the context is not correct either when batching is done\n-        // So just faking it here.\n-        spi::Context dummyContext(documentapi::LoadType::DEFAULT, 0, 0);\n-        spi::Result result = _spi.flush(b, dummyContext);\n-        uint32_t errorCode = _env.convertErrorCode(result);\n-        if (errorCode != 0) {\n-            for (uint32_t i = 0; i < replies.size(); ++i) {\n-                replies[i]->getReply()->setResult(api::ReturnCode((api::ReturnCode::Result)errorCode, result.getErrorMessage()));\n-            }\n-        }\n-    } catch (std::exception& e) {\n-        for (uint32_t i = 0; i < replies.size(); ++i) {\n-            replies[i]->getReply()->setResult(api::ReturnCode(api::ReturnCode::INTERNAL_FAILURE, e.what()));\n-        }\n-    }\n-\n-    for (uint32_t i = 0; i < replies.size(); ++i) {\n-        LOG(spam, \"Sending reply up (batched): %s %\" PRIu64,\n-            replies[i]->getReply()->toString().c_str(), replies[i]->getReply()->getMsgId());\n-        _env._fileStorHandler.sendReply(replies[i]->getReply());\n-    }\n-\n-    replies.clear();\n-}\n-\n-void PersistenceThread::processMessages(FileStorHandler::LockedMessage & lock)\n-{\n+void PersistenceThread::processMessages(FileStorHandler::LockedMessage & lock) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f0a7a14d639059f4d9de3001fc96d95219f499b2"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTgwOTEzMw==", "bodyText": "Fixed", "url": "https://github.com/vespa-engine/vespa/pull/13080#discussion_r415809133", "createdAt": "2020-04-27T13:24:18Z", "author": {"login": "baldersheim"}, "path": "storage/src/vespa/storage/persistence/persistencethread.cpp", "diffHunk": "@@ -894,115 +894,24 @@ bool hasBucketInfo(const api::StorageMessage& msg)\n \n }\n \n-void\n-PersistenceThread::flushAllReplies(\n-        const document::Bucket& bucket,\n-        std::vector<std::unique_ptr<MessageTracker> >& replies)\n-{\n-    if (replies.empty()) {\n-        return;\n-    }\n-\n-    try {\n-        if (replies.size() > 1) {\n-            _env._metrics.batchingSize.addValue(replies.size());\n-        }\n-#ifdef ENABLE_BUCKET_OPERATION_LOGGING\n-        {\n-            size_t nputs = 0, nremoves = 0, nother = 0;\n-            for (size_t i = 0; i < replies.size(); ++i) {\n-                if (dynamic_cast<api::PutReply*>(replies[i]->getReply().get()))\n-                {\n-                    ++nputs;\n-                } else if (dynamic_cast<api::RemoveReply*>(\n-                                replies[i]->getReply().get()))\n-                {\n-                    ++nremoves;\n-                } else {\n-                    ++nother;\n-                }\n-            }\n-            LOG_BUCKET_OPERATION(\n-                    bucket.getBucketId(),\n-                    vespalib::make_string(\n-                            \"flushing %zu operations (%zu puts, %zu removes, \"\n-                            \"%zu other)\",\n-                            replies.size(), nputs, nremoves, nother));\n-        }\n-#endif\n-        spi::Bucket b(bucket, spi::PartitionId(_env._partition));\n-        // Flush is not used for anything currentlu, and the context is not correct either when batching is done\n-        // So just faking it here.\n-        spi::Context dummyContext(documentapi::LoadType::DEFAULT, 0, 0);\n-        spi::Result result = _spi.flush(b, dummyContext);\n-        uint32_t errorCode = _env.convertErrorCode(result);\n-        if (errorCode != 0) {\n-            for (uint32_t i = 0; i < replies.size(); ++i) {\n-                replies[i]->getReply()->setResult(api::ReturnCode((api::ReturnCode::Result)errorCode, result.getErrorMessage()));\n-            }\n-        }\n-    } catch (std::exception& e) {\n-        for (uint32_t i = 0; i < replies.size(); ++i) {\n-            replies[i]->getReply()->setResult(api::ReturnCode(api::ReturnCode::INTERNAL_FAILURE, e.what()));\n-        }\n-    }\n-\n-    for (uint32_t i = 0; i < replies.size(); ++i) {\n-        LOG(spam, \"Sending reply up (batched): %s %\" PRIu64,\n-            replies[i]->getReply()->toString().c_str(), replies[i]->getReply()->getMsgId());\n-        _env._fileStorHandler.sendReply(replies[i]->getReply());\n-    }\n-\n-    replies.clear();\n-}\n-\n-void PersistenceThread::processMessages(FileStorHandler::LockedMessage & lock)\n-{\n+void PersistenceThread::processMessages(FileStorHandler::LockedMessage & lock) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc4NDU4MQ=="}, "originalCommit": {"oid": "f0a7a14d639059f4d9de3001fc96d95219f499b2"}, "originalPosition": 68}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1672, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}