{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQyMjAzMTg0", "number": 5025, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNDoxNjowMFrOFHM2Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxMzoxOVrOFHUFAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMDk0ODU5OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub/src/main/resources/ml-modules/root/marklogic-data-hub-spark-connector/readRows.sjs", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNDoxNjowMFrOIIke6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOTo0MTo1MVrOIIwg5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzI1OA==", "bodyText": "op.import returns a plan, so to avoid duplication here, try this:\nlet thePlan = op.import(...);\nif (optimization level is set) thePlan = thePlan.prepare(...);\nthePlan.result(...).toArray().forEach(...)", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r545857258", "createdAt": "2020-12-18T14:16:00Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub/src/main/resources/ml-modules/root/marklogic-data-hub-spark-connector/readRows.sjs", "diffHunk": "@@ -25,19 +25,32 @@ const results = [endpointState];\n \n const partitionNumber = endpointConstants.partitionNumber;\n const partition = endpointConstants.initializationResponse.partitions[partitionNumber];\n+const optimizationlevel = endpointConstants.optimizationlevel;\n \n if (endpointState.batchNumber <= partition.batchCount) {\n   // Determine the min/max rowID of the current batch number\n   const batch = partitionLib.getPartitionBatch(partition, endpointState.batchNumber);\n \n   // Run the parameterized plan, constraining it to the min and max row ID of the current batch\n-  op.import(endpointConstants.initializationResponse.parameterizedPlan)\n-    .result(null, {\n-      \"MIN_ROW_ID\": batch.min,\n-      \"MAX_ROW_ID\": batch.max\n-    })\n-    .toArray()\n-    .forEach(row => results.push(row));\n+  if(optimizationlevel >= 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzOTc0Nw==", "bodyText": "There's still duplication here of the \"result\" call. You can avoid that by doing what I showed above - call thePlan = thePlan.prepare if there's an optimization level.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r546039747", "createdAt": "2020-12-18T19:14:12Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub/src/main/resources/ml-modules/root/marklogic-data-hub-spark-connector/readRows.sjs", "diffHunk": "@@ -25,19 +25,32 @@ const results = [endpointState];\n \n const partitionNumber = endpointConstants.partitionNumber;\n const partition = endpointConstants.initializationResponse.partitions[partitionNumber];\n+const optimizationlevel = endpointConstants.optimizationlevel;\n \n if (endpointState.batchNumber <= partition.batchCount) {\n   // Determine the min/max rowID of the current batch number\n   const batch = partitionLib.getPartitionBatch(partition, endpointState.batchNumber);\n \n   // Run the parameterized plan, constraining it to the min and max row ID of the current batch\n-  op.import(endpointConstants.initializationResponse.parameterizedPlan)\n-    .result(null, {\n-      \"MIN_ROW_ID\": batch.min,\n-      \"MAX_ROW_ID\": batch.max\n-    })\n-    .toArray()\n-    .forEach(row => results.push(row));\n+  if(optimizationlevel >= 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzI1OA=="}, "originalCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA1NDM3Mw==", "bodyText": "Done. Sorry about the confusion.!", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r546054373", "createdAt": "2020-12-18T19:41:51Z", "author": {"login": "anu3990"}, "path": "marklogic-data-hub/src/main/resources/ml-modules/root/marklogic-data-hub-spark-connector/readRows.sjs", "diffHunk": "@@ -25,19 +25,32 @@ const results = [endpointState];\n \n const partitionNumber = endpointConstants.partitionNumber;\n const partition = endpointConstants.initializationResponse.partitions[partitionNumber];\n+const optimizationlevel = endpointConstants.optimizationlevel;\n \n if (endpointState.batchNumber <= partition.batchCount) {\n   // Determine the min/max rowID of the current batch number\n   const batch = partitionLib.getPartitionBatch(partition, endpointState.batchNumber);\n \n   // Run the parameterized plan, constraining it to the min and max row ID of the current batch\n-  op.import(endpointConstants.initializationResponse.parameterizedPlan)\n-    .result(null, {\n-      \"MIN_ROW_ID\": batch.min,\n-      \"MAX_ROW_ID\": batch.max\n-    })\n-    .toArray()\n-    .forEach(row => results.push(row));\n+  if(optimizationlevel >= 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzI1OA=="}, "originalCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMDk1MTAzOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/reader/ReadWithCustomOptimizationlevel.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNDoxNjo0NVrOIIkggQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNDoxNjo0NVrOIIkggQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzY2NQ==", "bodyText": "Since this is needed for every test, put it in a BeforeEach-annotated method at the top of the test. For readability, it's helpful to see BeforeEach methods at the top.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r545857665", "createdAt": "2020-12-18T14:16:45Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/reader/ReadWithCustomOptimizationlevel.java", "diffHunk": "@@ -0,0 +1,62 @@\n+package com.marklogic.hub.spark.sql.sources.v2.reader;\n+\n+import com.marklogic.hub.spark.sql.sources.v2.Options;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.List;\n+\n+import static org.junit.jupiter.api.Assertions.*;\n+\n+public class ReadWithCustomOptimizationlevel extends AbstractSparkReadTest {\n+\n+    @Test\n+    public void testStringOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withStringOptimizationlevel(\"2\");\n+        List<InternalRow> rows = readRows(new HubDataSourceReader(options.toDataSourceOptions()));\n+        assertEquals(10, rows.size(), \"All 10 rows could not be read.\");\n+    }\n+\n+    @Test\n+    public void testIntegerOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withIntegerOptimizationlevel(2);\n+        List<InternalRow> rows = readRows(new HubDataSourceReader(options.toDataSourceOptions()));\n+        assertEquals(10, rows.size(), \"All 10 rows could not be read.\");\n+    }\n+\n+    @Test\n+    public void testInvalidOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withIntegerOptimizationlevel(6);\n+        IllegalArgumentException ex = assertThrows(IllegalArgumentException.class,\n+            () -> readRows(new HubDataSourceReader(options.toDataSourceOptions())));\n+        assertEquals(\"optimizationlevel needs to be 0,1 or 2\",\n+            ex.getMessage());\n+\n+        Options newOptions = newOptions().withView(\"Customer\").withIntegerOptimizationlevel(-1);\n+        ex = assertThrows(IllegalArgumentException.class,\n+            () -> readRows(new HubDataSourceReader(newOptions.toDataSourceOptions())));\n+        assertEquals(\"optimizationlevel needs to be 0,1 or 2\",\n+            ex.getMessage());\n+    }\n+\n+    @Test\n+    public void testDecimalOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withStringOptimizationlevel(\"1.5\");\n+        IllegalArgumentException ex = assertThrows(IllegalArgumentException.class,\n+            () -> readRows(new HubDataSourceReader(options.toDataSourceOptions())));\n+        assertEquals(\"optimizationlevel needs to be 0,1 or 2\",\n+            ex.getMessage());\n+    }\n+\n+    private void setUp() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMDk1ODg3OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubInputPartitionReader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNDoxODozOVrOIIklEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNDoxODozOVrOIIklEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1ODgzNA==", "bodyText": "Given that we have a couple levels of nesting going on here, that's a good indicator that we could use a new private method for readability here - e.g.\naddOptimizationLevel(options, endpointConstants);\n\nThat method will then do the error handling and validation of the value that the user provides.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r545858834", "createdAt": "2020-12-18T14:18:39Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubInputPartitionReader.java", "diffHunk": "@@ -88,10 +88,21 @@ public void close() {\n         logger.debug(\"Closing\");\n     }\n \n-    private ObjectNode buildEndpointConstants(JsonNode initializationResponse, int partitionNumber) {\n+    private ObjectNode buildEndpointConstants(Map<String, String> options, JsonNode initializationResponse, int partitionNumber) {\n         ObjectNode endpointConstants = objectMapper.createObjectNode();\n         endpointConstants.set(\"initializationResponse\", initializationResponse);\n         endpointConstants.put(\"partitionNumber\", partitionNumber);\n+        String optimizationlevel = options.get(\"optimizationlevel\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzMjEzMzEyOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubInputPartitionReader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxMzoxOVrOIIvi6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxMzoxOVrOIIvi6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzODUwNQ==", "bodyText": "It's best to use StringUtils.hasText or StringUtils.isNotEmpty here, as that will do a trim().length(), which rules out whitespace.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r546038505", "createdAt": "2020-12-18T19:13:19Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubInputPartitionReader.java", "diffHunk": "@@ -117,4 +122,19 @@ private void readNextBatchOfRows() {\n             rowIndex = 0;\n         }\n     }\n+\n+    private ObjectNode addOptimizationLevel(Map<String, String> options, ObjectNode endpointConstants){\n+        String optimizationlevel = options.get(\"optimizationlevel\");\n+        if(optimizationlevel!=null && optimizationlevel.length()>0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3ec443468645149ab7114020cd65e2749071323"}, "originalPosition": 45}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2961, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}