{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg5MDM4Mzkw", "number": 4590, "title": "DHFPROD-5943: Renaming the connector to Spark Connector", "bodyText": "Description\nChecklist:\n- Note: do not change the below\n\n\nOwner:\n\n\n JIRA_ID included in all the commit messages\n\n\n PR title is in the format JIRA_ID:Title\n\n\n Rebase the branch with upstream\n\n\n Squashed all commits into a single commit\n\n\n Added Tests\n\n\nReviewer:\n\n\n Reviewed Tests", "createdAt": "2020-09-18T03:05:35Z", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590", "merged": true, "mergeCommit": {"oid": "1afa02acf2ff6e7413ba6ff7184eee4e8923ba42"}, "closed": true, "closedAt": "2020-09-18T19:12:51Z", "author": {"login": "SameeraPriyathamTadikonda"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdJ-R7ZgFqTQ5MTE0ODk5NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdKIsDPAFqTQ5MTYzODM1Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxMTQ4OTk1", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#pullrequestreview-491148995", "createdAt": "2020-09-18T04:50:32Z", "commit": {"oid": "ae3f7455276434566bd5c19730d797a8b2424720"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwNDo1MDozMlrOHT9-YQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwNDo1MjoyOVrOHT-ARw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcwMDM4NQ==", "bodyText": "HubDataSource should be inside the writer folder because it implements WriteSupport. It cannot be used as a generic class. For Reader we will have to create a new class that implements ReadSupport.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490700385", "createdAt": "2020-09-18T04:50:32Z", "author": {"login": "anu3990"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,17 +13,33 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae3f7455276434566bd5c19730d797a8b2424720"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcwMDg3MQ==", "bodyText": "I am not sure if we can have MarkLogicWriter as an inner class. Is this setup working.?", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490700871", "createdAt": "2020-09-18T04:52:29Z", "author": {"login": "anu3990"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,17 +13,33 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+\n+    @Override\n+    public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n+        logger.info(\"Creating MarkLogicWriter\");\n+        return Optional.of(new MarkLogicWriter(options.asMap(), schema){\n+\n+        });\n+    }\n+}\n+class MarkLogicWriter implements DataSourceWriter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae3f7455276434566bd5c19730d797a8b2424720"}, "originalPosition": 32}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ae3f7455276434566bd5c19730d797a8b2424720", "author": {"user": {"login": "SameeraPriyathamTadikonda", "name": null}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/ae3f7455276434566bd5c19730d797a8b2424720", "committedDate": "2020-09-18T03:04:07Z", "message": "DHFPROD-5943: Renaming the connector to Spark Connector"}, "afterCommit": {"oid": "86967777922c0430d61346b375632e3cbeda918f", "author": {"user": {"login": "SameeraPriyathamTadikonda", "name": null}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/86967777922c0430d61346b375632e3cbeda918f", "committedDate": "2020-09-18T05:28:55Z", "message": "DHFPROD-5943: Renaming the connector to Spark Connector"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4", "author": {"user": {"login": "SameeraPriyathamTadikonda", "name": null}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/4311eacc520a56edf1ca39c778b7e59f309e4cd4", "committedDate": "2020-09-18T05:37:42Z", "message": "DHFPROD-5943: Renaming the connector to Spark Connector"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "86967777922c0430d61346b375632e3cbeda918f", "author": {"user": {"login": "SameeraPriyathamTadikonda", "name": null}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/86967777922c0430d61346b375632e3cbeda918f", "committedDate": "2020-09-18T05:28:55Z", "message": "DHFPROD-5943: Renaming the connector to Spark Connector"}, "afterCommit": {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4", "author": {"user": {"login": "SameeraPriyathamTadikonda", "name": null}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/4311eacc520a56edf1ca39c778b7e59f309e4cd4", "committedDate": "2020-09-18T05:37:42Z", "message": "DHFPROD-5943: Renaming the connector to Spark Connector"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxMzk0ODA2", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#pullrequestreview-491394806", "createdAt": "2020-09-18T11:50:37Z", "commit": {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTo1MDozN1rOHUJ7gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTo1MjoyNFrOHUJ-ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5NjI1Nw==", "bodyText": "I am thinking that since WriteSupport is in the \"v2\" package and not \"v2.writer\", we'll eventually have this implement ReadSupport as well. Here's an example of that - https://www.bugdbug.com/post/speed-up-apache-spark-operations-using-a-custom-data-source .\nI think that makes sense conceptually - we have a single DataSource which supports Read and Write. That makes life easier for Ernie, who only has to worry about one DataSource class now.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490896257", "createdAt": "2020-09-18T11:50:37Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,17 +13,33 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcwMDM4NQ=="}, "originalCommit": {"oid": "ae3f7455276434566bd5c19730d797a8b2424720"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5NjY5Ng==", "bodyText": "I believe you can remove the empty braces here.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490896696", "createdAt": "2020-09-18T11:51:32Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,26 +13,42 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+\n+    @Override\n+    public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n+        logger.info(\"Creating HubDataSourceWriter\");\n+        return Optional.of(new HubDataSourceWriter(options.asMap(), schema){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5NzA5MQ==", "bodyText": "I like this approach of tossing this class in here as a non-public one. I think we'll want to do that for HubDataSourceReader too in the future.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490897091", "createdAt": "2020-09-18T11:52:24Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,26 +13,42 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+\n+    @Override\n+    public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n+        logger.info(\"Creating HubDataSourceWriter\");\n+        return Optional.of(new HubDataSourceWriter(options.asMap(), schema){\n+\n+        });\n+    }\n+}\n+class HubDataSourceWriter implements DataSourceWriter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxNjM0NTcz", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#pullrequestreview-491634573", "createdAt": "2020-09-18T16:58:50Z", "commit": {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxNjM4MzUz", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#pullrequestreview-491638353", "createdAt": "2020-09-18T17:03:50Z", "commit": {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2097, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}