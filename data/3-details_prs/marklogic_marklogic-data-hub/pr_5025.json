{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQyMjAzMTg0", "number": 5025, "title": "DHFPROD-6205: Customize Optic optimization level via Spark connector", "bodyText": "Description\nChecklist:\n- Note: do not change the below\n\n\nOwner:\n\n\n JIRA_ID included in all the commit messages\n\n\n PR title is in the format JIRA_ID:Title\n\n\n Rebase the branch with upstream\n\n\n Squashed all commits into a single commit\n\n\n Code passes ESLint tests\n\n\n Added Tests\n\n\nReviewer:\n\n\n Reviewed Tests", "createdAt": "2020-12-17T23:53:38Z", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025", "merged": true, "mergeCommit": {"oid": "f1d724e623f691e39f21218dba18a306f8ed1c2a"}, "closed": true, "closedAt": "2020-12-18T21:20:07Z", "author": {"login": "anu3990"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdnY3maAFqTU1NTUxNzk1Nw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdneqqdAFqTU1NTgxMjUwOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NTE3OTU3", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#pullrequestreview-555517957", "createdAt": "2020-12-18T14:16:00Z", "commit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNDoxNjowMFrOIIke6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxNDoxODozOVrOIIklEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzI1OA==", "bodyText": "op.import returns a plan, so to avoid duplication here, try this:\nlet thePlan = op.import(...);\nif (optimization level is set) thePlan = thePlan.prepare(...);\nthePlan.result(...).toArray().forEach(...)", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r545857258", "createdAt": "2020-12-18T14:16:00Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub/src/main/resources/ml-modules/root/marklogic-data-hub-spark-connector/readRows.sjs", "diffHunk": "@@ -25,19 +25,32 @@ const results = [endpointState];\n \n const partitionNumber = endpointConstants.partitionNumber;\n const partition = endpointConstants.initializationResponse.partitions[partitionNumber];\n+const optimizationlevel = endpointConstants.optimizationlevel;\n \n if (endpointState.batchNumber <= partition.batchCount) {\n   // Determine the min/max rowID of the current batch number\n   const batch = partitionLib.getPartitionBatch(partition, endpointState.batchNumber);\n \n   // Run the parameterized plan, constraining it to the min and max row ID of the current batch\n-  op.import(endpointConstants.initializationResponse.parameterizedPlan)\n-    .result(null, {\n-      \"MIN_ROW_ID\": batch.min,\n-      \"MAX_ROW_ID\": batch.max\n-    })\n-    .toArray()\n-    .forEach(row => results.push(row));\n+  if(optimizationlevel >= 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzY2NQ==", "bodyText": "Since this is needed for every test, put it in a BeforeEach-annotated method at the top of the test. For readability, it's helpful to see BeforeEach methods at the top.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r545857665", "createdAt": "2020-12-18T14:16:45Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/reader/ReadWithCustomOptimizationlevel.java", "diffHunk": "@@ -0,0 +1,62 @@\n+package com.marklogic.hub.spark.sql.sources.v2.reader;\n+\n+import com.marklogic.hub.spark.sql.sources.v2.Options;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.List;\n+\n+import static org.junit.jupiter.api.Assertions.*;\n+\n+public class ReadWithCustomOptimizationlevel extends AbstractSparkReadTest {\n+\n+    @Test\n+    public void testStringOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withStringOptimizationlevel(\"2\");\n+        List<InternalRow> rows = readRows(new HubDataSourceReader(options.toDataSourceOptions()));\n+        assertEquals(10, rows.size(), \"All 10 rows could not be read.\");\n+    }\n+\n+    @Test\n+    public void testIntegerOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withIntegerOptimizationlevel(2);\n+        List<InternalRow> rows = readRows(new HubDataSourceReader(options.toDataSourceOptions()));\n+        assertEquals(10, rows.size(), \"All 10 rows could not be read.\");\n+    }\n+\n+    @Test\n+    public void testInvalidOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withIntegerOptimizationlevel(6);\n+        IllegalArgumentException ex = assertThrows(IllegalArgumentException.class,\n+            () -> readRows(new HubDataSourceReader(options.toDataSourceOptions())));\n+        assertEquals(\"optimizationlevel needs to be 0,1 or 2\",\n+            ex.getMessage());\n+\n+        Options newOptions = newOptions().withView(\"Customer\").withIntegerOptimizationlevel(-1);\n+        ex = assertThrows(IllegalArgumentException.class,\n+            () -> readRows(new HubDataSourceReader(newOptions.toDataSourceOptions())));\n+        assertEquals(\"optimizationlevel needs to be 0,1 or 2\",\n+            ex.getMessage());\n+    }\n+\n+    @Test\n+    public void testDecimalOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withStringOptimizationlevel(\"1.5\");\n+        IllegalArgumentException ex = assertThrows(IllegalArgumentException.class,\n+            () -> readRows(new HubDataSourceReader(options.toDataSourceOptions())));\n+        assertEquals(\"optimizationlevel needs to be 0,1 or 2\",\n+            ex.getMessage());\n+    }\n+\n+    private void setUp() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1ODgzNA==", "bodyText": "Given that we have a couple levels of nesting going on here, that's a good indicator that we could use a new private method for readability here - e.g.\naddOptimizationLevel(options, endpointConstants);\n\nThat method will then do the error handling and validation of the value that the user provides.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r545858834", "createdAt": "2020-12-18T14:18:39Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubInputPartitionReader.java", "diffHunk": "@@ -88,10 +88,21 @@ public void close() {\n         logger.debug(\"Closing\");\n     }\n \n-    private ObjectNode buildEndpointConstants(JsonNode initializationResponse, int partitionNumber) {\n+    private ObjectNode buildEndpointConstants(Map<String, String> options, JsonNode initializationResponse, int partitionNumber) {\n         ObjectNode endpointConstants = objectMapper.createObjectNode();\n         endpointConstants.set(\"initializationResponse\", initializationResponse);\n         endpointConstants.put(\"partitionNumber\", partitionNumber);\n+        String optimizationlevel = options.get(\"optimizationlevel\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "originalPosition": 18}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f", "author": {"user": {"login": "anu3990", "name": "Anushree Sinha"}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/32067b92fc4d486f5095ce2e54856c9992d27c5f", "committedDate": "2020-12-17T23:49:48Z", "message": "DHFPROD-6205: Customize Optic optimization level via Spark connector"}, "afterCommit": {"oid": "b3ec443468645149ab7114020cd65e2749071323", "author": {"user": {"login": "anu3990", "name": "Anushree Sinha"}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/b3ec443468645149ab7114020cd65e2749071323", "committedDate": "2020-12-18T18:56:23Z", "message": "DHFPROD-6205: Customize Optic optimization level via Spark connector"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzUwMzA4", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#pullrequestreview-555750308", "createdAt": "2020-12-18T19:13:19Z", "commit": {"oid": "b3ec443468645149ab7114020cd65e2749071323"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxMzoxOVrOIIvi6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxNDoxMlrOIIvnww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzODUwNQ==", "bodyText": "It's best to use StringUtils.hasText or StringUtils.isNotEmpty here, as that will do a trim().length(), which rules out whitespace.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r546038505", "createdAt": "2020-12-18T19:13:19Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubInputPartitionReader.java", "diffHunk": "@@ -117,4 +122,19 @@ private void readNextBatchOfRows() {\n             rowIndex = 0;\n         }\n     }\n+\n+    private ObjectNode addOptimizationLevel(Map<String, String> options, ObjectNode endpointConstants){\n+        String optimizationlevel = options.get(\"optimizationlevel\");\n+        if(optimizationlevel!=null && optimizationlevel.length()>0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3ec443468645149ab7114020cd65e2749071323"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzOTc0Nw==", "bodyText": "There's still duplication here of the \"result\" call. You can avoid that by doing what I showed above - call thePlan = thePlan.prepare if there's an optimization level.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r546039747", "createdAt": "2020-12-18T19:14:12Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub/src/main/resources/ml-modules/root/marklogic-data-hub-spark-connector/readRows.sjs", "diffHunk": "@@ -25,19 +25,32 @@ const results = [endpointState];\n \n const partitionNumber = endpointConstants.partitionNumber;\n const partition = endpointConstants.initializationResponse.partitions[partitionNumber];\n+const optimizationlevel = endpointConstants.optimizationlevel;\n \n if (endpointState.batchNumber <= partition.batchCount) {\n   // Determine the min/max rowID of the current batch number\n   const batch = partitionLib.getPartitionBatch(partition, endpointState.batchNumber);\n \n   // Run the parameterized plan, constraining it to the min and max row ID of the current batch\n-  op.import(endpointConstants.initializationResponse.parameterizedPlan)\n-    .result(null, {\n-      \"MIN_ROW_ID\": batch.min,\n-      \"MAX_ROW_ID\": batch.max\n-    })\n-    .toArray()\n-    .forEach(row => results.push(row));\n+  if(optimizationlevel >= 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzI1OA=="}, "originalCommit": {"oid": "32067b92fc4d486f5095ce2e54856c9992d27c5f"}, "originalPosition": 18}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12460562e8b9fdd48742a18b7edb94db4ab1326f", "author": {"user": {"login": "anu3990", "name": "Anushree Sinha"}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/12460562e8b9fdd48742a18b7edb94db4ab1326f", "committedDate": "2020-12-18T19:38:33Z", "message": "DHFPROD-6205: Customize Optic optimization level via Spark connector"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b3ec443468645149ab7114020cd65e2749071323", "author": {"user": {"login": "anu3990", "name": "Anushree Sinha"}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/b3ec443468645149ab7114020cd65e2749071323", "committedDate": "2020-12-18T18:56:23Z", "message": "DHFPROD-6205: Customize Optic optimization level via Spark connector"}, "afterCommit": {"oid": "12460562e8b9fdd48742a18b7edb94db4ab1326f", "author": {"user": {"login": "anu3990", "name": "Anushree Sinha"}}, "url": "https://github.com/marklogic/marklogic-data-hub/commit/12460562e8b9fdd48742a18b7edb94db4ab1326f", "committedDate": "2020-12-18T19:38:33Z", "message": "DHFPROD-6205: Customize Optic optimization level via Spark connector"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1ODAzNDg2", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#pullrequestreview-555803486", "createdAt": "2020-12-18T20:46:32Z", "commit": {"oid": "12460562e8b9fdd48742a18b7edb94db4ab1326f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1ODEyNTA5", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#pullrequestreview-555812509", "createdAt": "2020-12-18T21:04:02Z", "commit": {"oid": "12460562e8b9fdd48742a18b7edb94db4ab1326f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1437, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}