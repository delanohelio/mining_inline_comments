{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE2NDUwMTQw", "number": 4830, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMjoxODoxMFrOE2EHfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxODo1NzozMVrOE26B1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1MTI2MDEyOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/HandleAbortedWriterTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMjoxODoxMFrOHur4QA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQwNzoxNzoyMVrOHvhanA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNTQ1Ng==", "bodyText": "Is the \"or\" check here only because it will be \"started\" on ML 9? If so, this should first do a check of the ML version to see if it's ML 9, and use that to determine what the expected status should be. Same goes for the other \"or\" checks below.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r518715456", "createdAt": "2020-11-06T12:18:10Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/HandleAbortedWriterTest.java", "diffHunk": "@@ -31,8 +32,10 @@ void dataSourceWriterIsAborted() {\n         assertEquals(2, getFruitCount(), \"Just verifying the two fruits were written\");\n \n         dataSourceWriter.abort(null);\n-        assertEquals(\"canceled\", getJobDocumentStatus(), \"If the DataSourceWriter is aborted for any reason, the job \" +\n+        assertTrue(getJobDocumentStatus().equals(\"canceled\") ||", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "226a58faae3b89683686ab692f923c2ef47938e9"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTU5MjYwNA==", "bodyText": "The failures are not consistent in 9.0-x. In WriteJobWithCustomEndpointsTest , whenever custom endpoint is used to initialize write , we are able to update the job document (regardless of whether custom endpoint is used to finalize write or not).\nIf default endpoints are used, we can create job doc but are not able to update it.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r519592604", "createdAt": "2020-11-09T07:17:21Z", "author": {"login": "srinathgit"}, "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/HandleAbortedWriterTest.java", "diffHunk": "@@ -31,8 +32,10 @@ void dataSourceWriterIsAborted() {\n         assertEquals(2, getFruitCount(), \"Just verifying the two fruits were written\");\n \n         dataSourceWriter.abort(null);\n-        assertEquals(\"canceled\", getJobDocumentStatus(), \"If the DataSourceWriter is aborted for any reason, the job \" +\n+        assertTrue(getJobDocumentStatus().equals(\"canceled\") ||", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNTQ1Ng=="}, "originalCommit": {"oid": "226a58faae3b89683686ab692f923c2ef47938e9"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MDA1OTg0OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/HandleAbortedWriterTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxODo0OToxNlrOHv8pQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxODo1NzowNFrOHv88FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAzODcyMw==", "bodyText": "Do we know why this is not working on 9.0-x? Is it something about amps and SJS functions? Whatever the reason is, it should be part of the assertion message.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r520038723", "createdAt": "2020-11-09T18:49:16Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/HandleAbortedWriterTest.java", "diffHunk": "@@ -31,8 +31,14 @@ void dataSourceWriterIsAborted() {\n         assertEquals(2, getFruitCount(), \"Just verifying the two fruits were written\");\n \n         dataSourceWriter.abort(null);\n-        assertEquals(\"canceled\", getJobDocumentStatus(), \"If the DataSourceWriter is aborted for any reason, the job \" +\n-            \"document should have a status of 'canceled'. Note that this does not imply whether any writes failed. \" +\n-            \"But that is a limitation of the JobStatus class in DHF.\");\n+        if(canUpdateJobDoc()){\n+            assertEquals(\"canceled\", getJobDocumentStatus(), \"If the DataSourceWriter is aborted for any reason, the job \" +\n+                \"document should have a status of 'canceled'. Note that this does not imply whether any writes failed. \" +\n+                \"But that is a limitation of the JobStatus class in DHF.\");\n+        }\n+        else{\n+            assertEquals(\"started\", getJobDocumentStatus(), \"In case of 9.0-x server, status will remain 'started'\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1db7ce1868d43097fcf1aa744d37e1a34b202001"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA0MzU0MA==", "bodyText": "Actually, this can become a new protected method in AbstractSparkConnectorTest - verifyJobDocumentWasNotUpdated(). Then you can reuse it across tests.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r520043540", "createdAt": "2020-11-09T18:57:04Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/HandleAbortedWriterTest.java", "diffHunk": "@@ -31,8 +31,14 @@ void dataSourceWriterIsAborted() {\n         assertEquals(2, getFruitCount(), \"Just verifying the two fruits were written\");\n \n         dataSourceWriter.abort(null);\n-        assertEquals(\"canceled\", getJobDocumentStatus(), \"If the DataSourceWriter is aborted for any reason, the job \" +\n-            \"document should have a status of 'canceled'. Note that this does not imply whether any writes failed. \" +\n-            \"But that is a limitation of the JobStatus class in DHF.\");\n+        if(canUpdateJobDoc()){\n+            assertEquals(\"canceled\", getJobDocumentStatus(), \"If the DataSourceWriter is aborted for any reason, the job \" +\n+                \"document should have a status of 'canceled'. Note that this does not imply whether any writes failed. \" +\n+                \"But that is a limitation of the JobStatus class in DHF.\");\n+        }\n+        else{\n+            assertEquals(\"started\", getJobDocumentStatus(), \"In case of 9.0-x server, status will remain 'started'\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAzODcyMw=="}, "originalCommit": {"oid": "1db7ce1868d43097fcf1aa744d37e1a34b202001"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MDA4NzA5OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/WriteJobWithCustomEndpointsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxODo1NjowM1rOHv85oA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxODo1NjowM1rOHv85oA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA0MjkxMg==", "bodyText": "Just to avoid duplication, toss this into a new private method - e.g verifyStatusIsStopOnError.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r520042912", "createdAt": "2020-11-09T18:56:03Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/WriteJobWithCustomEndpointsTest.java", "diffHunk": "@@ -38,7 +38,10 @@ void bothEndpointsAreCustom() {\n \n         verifyCustomInitializeEndpointIsUsed();\n         dataSourceWriter.commit(null);\n-        verifyCustomFinalizeEndpointIsUsed();\n+        assertEquals(\"stop-on-error\", getJobDocumentStatus(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1db7ce1868d43097fcf1aa744d37e1a34b202001"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MDA5MzAzOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/test/resources/custom-job-endpoints/finalizeWrite.sjs", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxODo1NzozMVrOHv89Nw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQyMDowNjozNVrOHv_ptg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA0MzgzMQ==", "bodyText": "Just to confirm - the try/catch is needed for the scenario where the custom finalize endpoint is used, but not the custom init endpoint?", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r520043831", "createdAt": "2020-11-09T18:57:31Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/test/resources/custom-job-endpoints/finalizeWrite.sjs", "diffHunk": "@@ -26,4 +26,11 @@ const Jobs = require(\"/data-hub/5/impl/jobs.sjs\");\n \n const alwaysUseThisStatus = \"stop-on-error\";\n \n-Jobs.updateJob(datahub, jobId, alwaysUseThisStatus, null, null, null, null);\n+try{\n+  Jobs.updateJob(datahub, jobId, alwaysUseThisStatus, null, null, null, null);\n+}\n+catch(ex){\n+  console.log(\"Failed to update job document; cause: \" + ex);\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1db7ce1868d43097fcf1aa744d37e1a34b202001"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA4Nzk5MA==", "bodyText": "That is correct.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r520087990", "createdAt": "2020-11-09T20:06:35Z", "author": {"login": "srinathgit"}, "path": "marklogic-data-hub-spark-connector/src/test/resources/custom-job-endpoints/finalizeWrite.sjs", "diffHunk": "@@ -26,4 +26,11 @@ const Jobs = require(\"/data-hub/5/impl/jobs.sjs\");\n \n const alwaysUseThisStatus = \"stop-on-error\";\n \n-Jobs.updateJob(datahub, jobId, alwaysUseThisStatus, null, null, null, null);\n+try{\n+  Jobs.updateJob(datahub, jobId, alwaysUseThisStatus, null, null, null, null);\n+}\n+catch(ex){\n+  console.log(\"Failed to update job document; cause: \" + ex);\n+}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA0MzgzMQ=="}, "originalCommit": {"oid": "1db7ce1868d43097fcf1aa744d37e1a34b202001"}, "originalPosition": 10}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3084, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}