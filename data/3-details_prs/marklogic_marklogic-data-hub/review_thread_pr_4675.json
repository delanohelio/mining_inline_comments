{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk4NzIyMDMz", "number": 4675, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxOTowNjoxMFrOEq4hVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQyMDozNDo0MVrOEq6VDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDAxNjg0OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxOTowNjoxMFrOHdWDRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQxOTowNjoxMFrOHdWDRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDUzMjAzNw==", "bodyText": "Given that we don't pass the OutputMode along, why log it? Its value has no impact on our connector.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4675#discussion_r500532037", "createdAt": "2020-10-06T19:06:10Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -20,26 +20,39 @@\n import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.StreamWriteSupport;\n import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n+import org.apache.spark.sql.sources.v2.writer.streaming.StreamWriter;\n+import org.apache.spark.sql.streaming.OutputMode;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n import java.util.Optional;\n \n-public class HubDataSource extends LoggingObject implements WriteSupport {\n+public class HubDataSource extends LoggingObject implements WriteSupport, StreamWriteSupport {\n \n     @Override\n     public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n         logger.info(\"Creating HubDataSourceWriter\");\n+        if(mode!=null && !mode.toString().equalsIgnoreCase(\"Save\"))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4e219a2472884da3b3ad5588b05ced4bff2776eb"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDMxMzEwOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/AbstractSparkConnectorTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQyMDozNDo0MVrOHdY7vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQyMDozNDo0MVrOHdY7vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDU3OTI2Mw==", "bodyText": "We don't need this test, as it's not testing anything new. The DataWriter that's being returned is identical to the one being returned by buildDataWriter - it's being constructed in the same fashion, since OutputMode doesn't matter. .\nWhat we need tests for are the commit/abort methods that take an epoch and don't take an epoch. But, we don't have any logic for those yet. That's where we need some research to figure out when Glue/Spark is invoking these methods - we should add some logging and then test out the connector to see when these methods are invoked, and what's in the WriterCommitMessage objects that are passed to it.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4675#discussion_r500579263", "createdAt": "2020-10-06T20:34:41Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/AbstractSparkConnectorTest.java", "diffHunk": "@@ -157,4 +159,24 @@ protected GenericInternalRow buildRow(String... values) {\n         }\n         return new GenericInternalRow(rowValues);\n     }\n+\n+    /**\n+     * @param options\n+     * @return\n+     * */\n+    protected DataWriter<InternalRow> buildStreamWriter(Options options) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "637d5ee808c54e7df027506ab384733b9186a228"}, "originalPosition": 18}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3277, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}