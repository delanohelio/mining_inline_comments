{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg5MDM4Mzkw", "number": 4590, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwNDo1MDozMlrOEk0KIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTo1MjoyM1rOEk8DeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MDM4NzU1OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwNDo1MDozMlrOHT9-YQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTo1MDozN1rOHUJ7gQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcwMDM4NQ==", "bodyText": "HubDataSource should be inside the writer folder because it implements WriteSupport. It cannot be used as a generic class. For Reader we will have to create a new class that implements ReadSupport.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490700385", "createdAt": "2020-09-18T04:50:32Z", "author": {"login": "anu3990"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,17 +13,33 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae3f7455276434566bd5c19730d797a8b2424720"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5NjI1Nw==", "bodyText": "I am thinking that since WriteSupport is in the \"v2\" package and not \"v2.writer\", we'll eventually have this implement ReadSupport as well. Here's an example of that - https://www.bugdbug.com/post/speed-up-apache-spark-operations-using-a-custom-data-source .\nI think that makes sense conceptually - we have a single DataSource which supports Read and Write. That makes life easier for Ernie, who only has to worry about one DataSource class now.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490896257", "createdAt": "2020-09-18T11:50:37Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,17 +13,33 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcwMDM4NQ=="}, "originalCommit": {"oid": "ae3f7455276434566bd5c19730d797a8b2424720"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MDM5MDY5OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwNDo1MjoyOVrOHT-ARw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwNDo1MjoyOVrOHT-ARw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcwMDg3MQ==", "bodyText": "I am not sure if we can have MarkLogicWriter as an inner class. Is this setup working.?", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490700871", "createdAt": "2020-09-18T04:52:29Z", "author": {"login": "anu3990"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,17 +13,33 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+\n+    @Override\n+    public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n+        logger.info(\"Creating MarkLogicWriter\");\n+        return Optional.of(new MarkLogicWriter(options.asMap(), schema){\n+\n+        });\n+    }\n+}\n+class MarkLogicWriter implements DataSourceWriter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ae3f7455276434566bd5c19730d797a8b2424720"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTY3ODYwOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTo1MTozMlrOHUJ9OA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTo1MTozMlrOHUJ9OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5NjY5Ng==", "bodyText": "I believe you can remove the empty braces here.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490896696", "createdAt": "2020-09-18T11:51:32Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,26 +13,42 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+\n+    @Override\n+    public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n+        logger.info(\"Creating HubDataSourceWriter\");\n+        return Optional.of(new HubDataSourceWriter(options.asMap(), schema){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MTY4MTIwOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTo1MjoyNFrOHUJ-ww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTo1MjoyNFrOHUJ-ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5NzA5MQ==", "bodyText": "I like this approach of tossing this class in here as a non-public one. I think we'll want to do that for HubDataSourceReader too in the future.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490897091", "createdAt": "2020-09-18T11:52:24Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,26 +13,42 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+\n+    @Override\n+    public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n+        logger.info(\"Creating HubDataSourceWriter\");\n+        return Optional.of(new HubDataSourceWriter(options.asMap(), schema){\n+\n+        });\n+    }\n+}\n+class HubDataSourceWriter implements DataSourceWriter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4"}, "originalPosition": 32}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3364, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}