{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE4ODY2Nzky", "number": 3963, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNTo1OToxNVrOD9LZ7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwODowODowOFrOD9SLuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDc2NTg4OnYy", "diffSide": "RIGHT", "path": "ml-data-hub-plugin/src/main/groovy/com/marklogic/gradle/task/FlowMigrationTask.groovy", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNTo1OToxNVrOGWh3Zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNTo1OToxNVrOGWh3Zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3NjcxMA==", "bodyText": "I should have mentioned - you can extend AbstractConfirmableTask from ml-gradle to do this. You won't have access to getHubConfig, but that's fine - can just call getProject().property(\"hubConfig\") instead.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426276710", "createdAt": "2020-05-17T15:59:15Z", "author": {"login": "rjrudin"}, "path": "ml-data-hub-plugin/src/main/groovy/com/marklogic/gradle/task/FlowMigrationTask.groovy", "diffHunk": "@@ -0,0 +1,24 @@\n+package com.marklogic.gradle.task\n+\n+import com.marklogic.hub.flow.impl.FlowMigrator\n+import org.gradle.api.GradleException\n+import org.gradle.api.tasks.TaskAction\n+\n+class FlowMigrationTask extends HubTask {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da04a3b12b1543e7f560133266786818193edb84"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDc2Njg3OnYy", "diffSide": "RIGHT", "path": "ml-data-hub-plugin/src/main/groovy/com/marklogic/gradle/DataHubPlugin.groovy", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjowMDowN1rOGWh34Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjowMDowN1rOGWh34Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3NjgzMw==", "bodyText": "For description, let's give a little more detail - I'm thinking: \"Migrate flows and mappings created before version 5.3.0 into the new format required for usage within Hub Central\"", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426276833", "createdAt": "2020-05-17T16:00:07Z", "author": {"login": "rjrudin"}, "path": "ml-data-hub-plugin/src/main/groovy/com/marklogic/gradle/DataHubPlugin.groovy", "diffHunk": "@@ -96,6 +96,8 @@ class DataHubPlugin implements Plugin<Project> {\n         project.task(\"hubVersion\", group: deployGroup, type: HubVersionTask,\n             description: \"Prints the versions of Data Hub and MarkLogic associated with the value of mlHost, and also prints the version of \" +\n                 \"Data Hub associated with this Gradle task\")\n+        project.task(\"hubMigrateFlows\", group: deployGroup, type: FlowMigrationTask,\n+            description: \"Migrates flows to HubCentral supported format \")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da04a3b12b1543e7f560133266786818193edb84"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDc2OTE5OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjowMzoxM1rOGWh5Bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjowMzoxM1rOGWh5Bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3NzEyNg==", "bodyText": "I'm realizing there's a gap in the story now - pinging @bsrikan  about this - what should we do about the pre-5.3 flows and mappings already deployed in ML? I'll open up a new story for that, let's not inflate this story with that question.\nHowever, I do think it's better to make use of installProjectInFolder - that avoids the need to write much code here. And it'll need to be called once we figure out what to do with already-installed files.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426277126", "createdAt": "2020-05-17T16:03:13Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "diffHunk": "@@ -0,0 +1,65 @@\n+package com.marklogic.hub.flow.impl;\n+\n+import com.marklogic.hub.AbstractHubCoreTest;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.skyscreamer.jsonassert.JSONAssert;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+\n+class FlowMigratorTest extends AbstractHubCoreTest {\n+    @BeforeEach\n+    void setUp() {\n+        try {\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/flows\"), getHubConfig().getFlowsDir().toFile());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da04a3b12b1543e7f560133266786818193edb84"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDc2OTkxOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjowNDoyOVrOGWh5aA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QxNjowNDoyOVrOGWh5aA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3NzIyNA==", "bodyText": "No need to do this - in fact, I think deleting the project directory or data from the db is an anti-pattern because if/when the test fails, it's more difficult to figure out what went wrong. That's why it's better to delete stuff when a test starts as opposed to when a test ends.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426277224", "createdAt": "2020-05-17T16:04:29Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "diffHunk": "@@ -0,0 +1,65 @@\n+package com.marklogic.hub.flow.impl;\n+\n+import com.marklogic.hub.AbstractHubCoreTest;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.skyscreamer.jsonassert.JSONAssert;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+\n+class FlowMigratorTest extends AbstractHubCoreTest {\n+    @BeforeEach\n+    void setUp() {\n+        try {\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/flows\"), getHubConfig().getFlowsDir().toFile());\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/mappings\"), getHubConfig().getHubMappingsDir().toFile());\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @AfterEach\n+    void tearDown() {\n+        deleteProjectDir();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da04a3b12b1543e7f560133266786818193edb84"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDk3MDUwOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QyMDo1NDo1NFrOGWjhow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QyMDo1NDo1NFrOGWjhow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjMwMzkwNw==", "bodyText": "I ran the test locally (it passed), but I think two changes should be made to the test:\n\nNarrow down the test files to the bare minimum of steps needed to verify that everything is working\nAdd assertions to verify that the step references are correct in every flow, and that each step document was created correctly\n\nFor the first item above - the ingestion_only-flow.flow.json file is testing 7 identical scenarios, because every one of the 7 steps is the same from a QA perspective. So we only need one non-custom ingestion step that has a fileLocations. We also need a non-custom ingestion step that doesn't have inputFileType in it so we can verify that the migrator adds sourceFormat=json.\nAs for the logic of - \"Should this step be migrated?\" - the most effective way to do that is to make \"stepRequiresMigration\" a protected method and that pass different kinds of steps into it, verifying that the result is true or false.\nFor the second item - I think it's best to make an assertion on every stepId in the migrated flow document, and also on every property of every migrated step. We specifically want to verify that everything under \"options\" was migrated to top-level properties; that \"fileLocations\" was handled correctly; and that \"options/mapping\" was not migrated (it currently is being migrated, but should not be).\nI also noticed that a \"namespaces: {}\" was added, even though no namespaces exist in the mappings. If that's something we need to account for, then we need a mapping artifact that has namespaces populated so we can verify that the special handling for it worked.\nNote that we really do not want any issues during this migration process; the last thing we want for new users on 5.3 is to migrate their flows and then run into a problem that requires involving Support and makes them think that 5.3 doesn't work. So we need to be certain to cover every scenario and ensure every line of the migrated flows/steps is correct.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426303907", "createdAt": "2020-05-17T20:54:54Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "diffHunk": "@@ -0,0 +1,63 @@\n+package com.marklogic.hub.flow.impl;\n+\n+import com.marklogic.hub.AbstractHubCoreTest;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.skyscreamer.jsonassert.JSONAssert;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+\n+class FlowMigratorTest extends AbstractHubCoreTest {\n+    @BeforeEach\n+    void setUp() {\n+        try {\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/flows\"), getHubConfig().getFlowsDir().toFile());\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/mappings\"), getHubConfig().getHubMappingsDir().toFile());\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @AfterEach\n+    void tearDown() {\n+        deleteProjectDir();\n+    }\n+\n+    @Test\n+    void migrateFlows() {\n+        HubConfig hubConfig = getHubConfig();\n+        HubProject hubProject = hubConfig.getHubProject();\n+        FlowMigrator flowMigrator = new FlowMigrator(getHubConfig());\n+        flowMigrator.migrateFlows();\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+\n+        Assertions.assertTrue(migratedFlows.toFile().exists());\n+        Assertions.assertTrue(migratedFlows.resolve(\"flows\").toFile().listFiles().length > 0);\n+        Assertions.assertTrue(migratedFlows.resolve(\"mappings\").toFile().listFiles().length > 0);\n+\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/flows\"), hubProject.getFlowsDir().toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/ingestion\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"ingestion\").toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/mapping\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"mapping\").toFile());\n+    }\n+\n+    private void verifyFiles(File expectedDir, File actualDir) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NDk3MTY0OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xN1QyMDo1NjowMVrOGWjiKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxNjo0MzoxNVrOGW_W2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjMwNDA0Mw==", "bodyText": "I realized the story isn't clear here - the mapping artifacts should be moved, not copied. That is assuming that we don't need them anymore, which I think is true. I'll double check on 5.0.x \"default\" mappings.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426304043", "createdAt": "2020-05-17T20:56:01Z", "author": {"login": "rjrudin"}, "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "diffHunk": "@@ -0,0 +1,63 @@\n+package com.marklogic.hub.flow.impl;\n+\n+import com.marklogic.hub.AbstractHubCoreTest;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.skyscreamer.jsonassert.JSONAssert;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+\n+class FlowMigratorTest extends AbstractHubCoreTest {\n+    @BeforeEach\n+    void setUp() {\n+        try {\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/flows\"), getHubConfig().getFlowsDir().toFile());\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/mappings\"), getHubConfig().getHubMappingsDir().toFile());\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @AfterEach\n+    void tearDown() {\n+        deleteProjectDir();\n+    }\n+\n+    @Test\n+    void migrateFlows() {\n+        HubConfig hubConfig = getHubConfig();\n+        HubProject hubProject = hubConfig.getHubProject();\n+        FlowMigrator flowMigrator = new FlowMigrator(getHubConfig());\n+        flowMigrator.migrateFlows();\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+\n+        Assertions.assertTrue(migratedFlows.toFile().exists());\n+        Assertions.assertTrue(migratedFlows.resolve(\"flows\").toFile().listFiles().length > 0);\n+        Assertions.assertTrue(migratedFlows.resolve(\"mappings\").toFile().listFiles().length > 0);\n+\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/flows\"), hubProject.getFlowsDir().toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/ingestion\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"ingestion\").toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/mapping\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"mapping\").toFile());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY4NjM2OQ==", "bodyText": "Since there will be no default-mapping steps and all mappings are migrated, ./mappings dir is removed.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426686369", "createdAt": "2020-05-18T14:54:36Z", "author": {"login": "srinathgit"}, "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "diffHunk": "@@ -0,0 +1,63 @@\n+package com.marklogic.hub.flow.impl;\n+\n+import com.marklogic.hub.AbstractHubCoreTest;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.skyscreamer.jsonassert.JSONAssert;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+\n+class FlowMigratorTest extends AbstractHubCoreTest {\n+    @BeforeEach\n+    void setUp() {\n+        try {\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/flows\"), getHubConfig().getFlowsDir().toFile());\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/mappings\"), getHubConfig().getHubMappingsDir().toFile());\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @AfterEach\n+    void tearDown() {\n+        deleteProjectDir();\n+    }\n+\n+    @Test\n+    void migrateFlows() {\n+        HubConfig hubConfig = getHubConfig();\n+        HubProject hubProject = hubConfig.getHubProject();\n+        FlowMigrator flowMigrator = new FlowMigrator(getHubConfig());\n+        flowMigrator.migrateFlows();\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+\n+        Assertions.assertTrue(migratedFlows.toFile().exists());\n+        Assertions.assertTrue(migratedFlows.resolve(\"flows\").toFile().listFiles().length > 0);\n+        Assertions.assertTrue(migratedFlows.resolve(\"mappings\").toFile().listFiles().length > 0);\n+\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/flows\"), hubProject.getFlowsDir().toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/ingestion\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"ingestion\").toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/mapping\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"mapping\").toFile());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjMwNDA0Mw=="}, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc1MjQ3MA==", "bodyText": "@srinathgit when I tested this PR, ./mappings dir was not removed.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426752470", "createdAt": "2020-05-18T16:30:31Z", "author": {"login": "bsrikan"}, "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "diffHunk": "@@ -0,0 +1,63 @@\n+package com.marklogic.hub.flow.impl;\n+\n+import com.marklogic.hub.AbstractHubCoreTest;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.skyscreamer.jsonassert.JSONAssert;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+\n+class FlowMigratorTest extends AbstractHubCoreTest {\n+    @BeforeEach\n+    void setUp() {\n+        try {\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/flows\"), getHubConfig().getFlowsDir().toFile());\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/mappings\"), getHubConfig().getHubMappingsDir().toFile());\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @AfterEach\n+    void tearDown() {\n+        deleteProjectDir();\n+    }\n+\n+    @Test\n+    void migrateFlows() {\n+        HubConfig hubConfig = getHubConfig();\n+        HubProject hubProject = hubConfig.getHubProject();\n+        FlowMigrator flowMigrator = new FlowMigrator(getHubConfig());\n+        flowMigrator.migrateFlows();\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+\n+        Assertions.assertTrue(migratedFlows.toFile().exists());\n+        Assertions.assertTrue(migratedFlows.resolve(\"flows\").toFile().listFiles().length > 0);\n+        Assertions.assertTrue(migratedFlows.resolve(\"mappings\").toFile().listFiles().length > 0);\n+\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/flows\"), hubProject.getFlowsDir().toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/ingestion\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"ingestion\").toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/mapping\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"mapping\").toFile());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjMwNDA0Mw=="}, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc1OTg5OA==", "bodyText": "It is removed in the latest commit", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426759898", "createdAt": "2020-05-18T16:43:15Z", "author": {"login": "srinathgit"}, "path": "marklogic-data-hub/src/test/java/com/marklogic/hub/flow/impl/FlowMigratorTest.java", "diffHunk": "@@ -0,0 +1,63 @@\n+package com.marklogic.hub.flow.impl;\n+\n+import com.marklogic.hub.AbstractHubCoreTest;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.skyscreamer.jsonassert.JSONAssert;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+\n+class FlowMigratorTest extends AbstractHubCoreTest {\n+    @BeforeEach\n+    void setUp() {\n+        try {\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/flows\"), getHubConfig().getFlowsDir().toFile());\n+            FileUtils.copyDirectory(getResourceFile(\"flow-migration-test/mappings\"), getHubConfig().getHubMappingsDir().toFile());\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @AfterEach\n+    void tearDown() {\n+        deleteProjectDir();\n+    }\n+\n+    @Test\n+    void migrateFlows() {\n+        HubConfig hubConfig = getHubConfig();\n+        HubProject hubProject = hubConfig.getHubProject();\n+        FlowMigrator flowMigrator = new FlowMigrator(getHubConfig());\n+        flowMigrator.migrateFlows();\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+\n+        Assertions.assertTrue(migratedFlows.toFile().exists());\n+        Assertions.assertTrue(migratedFlows.resolve(\"flows\").toFile().listFiles().length > 0);\n+        Assertions.assertTrue(migratedFlows.resolve(\"mappings\").toFile().listFiles().length > 0);\n+\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/flows\"), hubProject.getFlowsDir().toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/ingestion\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"ingestion\").toFile());\n+        verifyFiles(getResourceFile(\"flow-migration-test/keys/steps/mapping\"), hubProject.getProjectDir().resolve(\"steps\").resolve(\"mapping\").toFile());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjMwNDA0Mw=="}, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTc0MTUzOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoyOToyOVrOGWqm-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzoyOToyOVrOGWqm-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQxOTk2Mw==", "bodyText": "Need a space before directory.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426419963", "createdAt": "2020-05-18T07:29:29Z", "author": {"login": "bsrikan"}, "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Copyright (c) 2020 MarkLogic Corporation\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.marklogic.hub.flow.impl;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectWriter;\n+import com.fasterxml.jackson.databind.node.JsonNodeFactory;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.marklogic.hub.FlowManager;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import com.marklogic.hub.MappingManager;\n+import com.marklogic.hub.error.DataHubProjectException;\n+import com.marklogic.hub.flow.Flow;\n+import com.marklogic.hub.impl.FlowManagerImpl;\n+import com.marklogic.hub.impl.MappingManagerImpl;\n+import com.marklogic.hub.mapping.Mapping;\n+import com.marklogic.hub.step.StepDefinition;\n+import com.marklogic.hub.step.impl.Step;\n+import org.apache.commons.io.FileUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+\n+\n+/**\n+ * Class for migrating pre-5.3.0 flows to  5.3.0 and above versions\n+ */\n+\n+public class FlowMigrator {\n+\n+    private HubProject hubProject;\n+    private MappingManager mappingManager;\n+    private FlowManager flowManager;\n+    protected final Logger logger = LoggerFactory.getLogger(this.getClass());\n+    ObjectMapper mapper = new ObjectMapper();\n+\n+    public FlowMigrator(HubConfig hubConfig){\n+        hubProject = hubConfig.getHubProject();\n+        mappingManager = new MappingManagerImpl(hubConfig);\n+        flowManager = new FlowManagerImpl(hubConfig, mappingManager);\n+    }\n+\n+    public void migrateFlows(){\n+        //Backup flows and mappings\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+        try {\n+            migratedFlows.toFile().mkdirs();\n+            FileUtils.copyDirectory(hubProject.getFlowsDir().toFile(), migratedFlows.resolve(\"flows\").toFile());\n+            FileUtils.copyDirectory(hubProject.getHubMappingsDir().toFile(), migratedFlows.resolve(\"mappings\").toFile());\n+            logger.info(\"The original flows and mappings are backed up in migrated-flows/flows and migrated-flows/mappings\"+\n+                \"directory respectively.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTgyODM1OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwNzo1NDozOFrOGWrbhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwODoyMzoyM1rOGWsdoQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQzMzQxMw==", "bodyText": "After migration, not able to run the flow. Used the flows in e2e/qa-project to migrate and run. Get an error like so.:\nUnable to retrieve flow with name: PersonXMLFlow for all the flows.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426433413", "createdAt": "2020-05-18T07:54:38Z", "author": {"login": "bsrikan"}, "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Copyright (c) 2020 MarkLogic Corporation\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.marklogic.hub.flow.impl;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectWriter;\n+import com.fasterxml.jackson.databind.node.JsonNodeFactory;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.marklogic.hub.FlowManager;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import com.marklogic.hub.MappingManager;\n+import com.marklogic.hub.error.DataHubProjectException;\n+import com.marklogic.hub.flow.Flow;\n+import com.marklogic.hub.impl.FlowManagerImpl;\n+import com.marklogic.hub.impl.MappingManagerImpl;\n+import com.marklogic.hub.mapping.Mapping;\n+import com.marklogic.hub.step.StepDefinition;\n+import com.marklogic.hub.step.impl.Step;\n+import org.apache.commons.io.FileUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+\n+\n+/**\n+ * Class for migrating pre-5.3.0 flows to  5.3.0 and above versions\n+ */\n+\n+public class FlowMigrator {\n+\n+    private HubProject hubProject;\n+    private MappingManager mappingManager;\n+    private FlowManager flowManager;\n+    protected final Logger logger = LoggerFactory.getLogger(this.getClass());\n+    ObjectMapper mapper = new ObjectMapper();\n+\n+    public FlowMigrator(HubConfig hubConfig){\n+        hubProject = hubConfig.getHubProject();\n+        mappingManager = new MappingManagerImpl(hubConfig);\n+        flowManager = new FlowManagerImpl(hubConfig, mappingManager);\n+    }\n+\n+    public void migrateFlows(){\n+        //Backup flows and mappings\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+        try {\n+            migratedFlows.toFile().mkdirs();\n+            FileUtils.copyDirectory(hubProject.getFlowsDir().toFile(), migratedFlows.resolve(\"flows\").toFile());\n+            FileUtils.copyDirectory(hubProject.getHubMappingsDir().toFile(), migratedFlows.resolve(\"mappings\").toFile());\n+            logger.info(\"The original flows and mappings are backed up in migrated-flows/flows and migrated-flows/mappings\"+\n+                \"directory respectively.\");\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as backing up flows failed : \" + e.getMessage());\n+        }\n+\n+        Path stepsDir = hubProject.getProjectDir().resolve(\"steps\");\n+        Path ingestionDir = stepsDir.resolve(StepDefinition.StepDefinitionType.INGESTION.toString());\n+        Path mappingDir = stepsDir.resolve(StepDefinition.StepDefinitionType.MAPPING.toString());\n+\n+        try {\n+            ingestionDir.toFile().mkdirs();\n+            mappingDir.toFile().mkdirs();\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as creation of step artifact directories  failed : \" + e.getMessage());\n+        }\n+\n+        ObjectWriter writer = mapper.writerWithDefaultPrettyPrinter();\n+        JsonNodeFactory nodeFactory = mapper.getNodeFactory();\n+\n+        flowManager.getLocalFlows().forEach(flow ->{\n+            Map<String, Step> steps = flow.getSteps();\n+            boolean flowRequiresMigration = steps.values().stream().anyMatch(step -> stepRequiresMigration(step));\n+            logger.info(flowRequiresMigration ? \"Migrating flow \" + flow.getName() :\n+                \"Flow \" + flow.getName() + \" contains no ingestion or mapping step. It doesn't require migration\");\n+            if(flowRequiresMigration){\n+                ObjectNode newFlow = nodeFactory.objectNode();\n+                newFlow.put(\"name\", flow.getName());\n+                ObjectNode newSteps = nodeFactory.objectNode();;\n+                for (Map.Entry<String, Step> entry : steps.entrySet()) {\n+                    Step step = entry.getValue();\n+                    if(stepRequiresMigration(step)){\n+                        newSteps.set(entry.getKey(),\n+                            nodeFactory.objectNode().put(\"stepId\",String.join(\"-\", step.getName(), step.getStepDefinitionType().toString())));\n+                        ObjectNode newStepArtifact = createStepArtifact(flow, step);\n+                        Path targetDir = step.getStepDefinitionType().equals(StepDefinition.StepDefinitionType.INGESTION) ? ingestionDir : mappingDir;\n+                        String stepFileName = new StringBuilder(step.getName()).append(\".step.json\").toString();\n+                        File stepFile = targetDir.resolve(stepFileName).toFile();\n+                        logger.info(\"Creating step artifact \"+ stepFile.toString());\n+                        if (stepFile.exists()) {\n+                            String msg = \"Step artifact \" + stepFile.toString() + \" already exists. The step artifact will be written to \";\n+                            //Update step artifact with new name\n+                            String stepName = new StringBuilder(flow.getName()).append(\"-\").append(step.getName()).toString();\n+                            newStepArtifact.put(\"name\", stepName);\n+                            //Update the filename\n+                            stepFileName = new StringBuilder(flow.getName()).append(\"-\").append(stepFileName).toString();\n+                            stepFile = targetDir.resolve(stepFileName).toFile();\n+\n+                            logger.info(msg + stepFile.toString()) ;\n+                        }\n+                        try{\n+                            writer.writeValue(stepFile, newStepArtifact);\n+                            logger.info(\"Step artifact \" + stepFile.toString() + \" successfully created.\");\n+                        }\n+                        catch(IOException e){\n+                            logger.error(\"Step artifact \" + stepFile.toString() + \" creation failed: \" + e.getMessage());\n+                        }\n+                    }\n+                    else {\n+                        logger.info(\"Step \" + step.getName() + \" is not an out of the box ingestion or mapping step. It will remain inline inside the flow artifact\");\n+                        newSteps.set(entry.getKey(), mapper.valueToTree(step));\n+                    }\n+                }\n+                newFlow.set(\"steps\",newSteps);\n+                File flowFile = Paths.get(hubProject.getFlowsDir().toString(), flow.getName() + FlowManager.FLOW_FILE_EXTENSION).toFile();\n+                try{\n+                    writer.writeValue(flowFile, newFlow);\n+                    logger.info(\"Flow \" + flowFile.toString() + \" successfully migrated.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ1MDMzNw==", "bodyText": "The flows should be run after DHFPROD-4951 and DHFPROD-4952 are merged into develop though implementation of DHFPROD-4956 doesn't have dependency on them", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426450337", "createdAt": "2020-05-18T08:23:23Z", "author": {"login": "srinathgit"}, "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Copyright (c) 2020 MarkLogic Corporation\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.marklogic.hub.flow.impl;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectWriter;\n+import com.fasterxml.jackson.databind.node.JsonNodeFactory;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.marklogic.hub.FlowManager;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import com.marklogic.hub.MappingManager;\n+import com.marklogic.hub.error.DataHubProjectException;\n+import com.marklogic.hub.flow.Flow;\n+import com.marklogic.hub.impl.FlowManagerImpl;\n+import com.marklogic.hub.impl.MappingManagerImpl;\n+import com.marklogic.hub.mapping.Mapping;\n+import com.marklogic.hub.step.StepDefinition;\n+import com.marklogic.hub.step.impl.Step;\n+import org.apache.commons.io.FileUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+\n+\n+/**\n+ * Class for migrating pre-5.3.0 flows to  5.3.0 and above versions\n+ */\n+\n+public class FlowMigrator {\n+\n+    private HubProject hubProject;\n+    private MappingManager mappingManager;\n+    private FlowManager flowManager;\n+    protected final Logger logger = LoggerFactory.getLogger(this.getClass());\n+    ObjectMapper mapper = new ObjectMapper();\n+\n+    public FlowMigrator(HubConfig hubConfig){\n+        hubProject = hubConfig.getHubProject();\n+        mappingManager = new MappingManagerImpl(hubConfig);\n+        flowManager = new FlowManagerImpl(hubConfig, mappingManager);\n+    }\n+\n+    public void migrateFlows(){\n+        //Backup flows and mappings\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+        try {\n+            migratedFlows.toFile().mkdirs();\n+            FileUtils.copyDirectory(hubProject.getFlowsDir().toFile(), migratedFlows.resolve(\"flows\").toFile());\n+            FileUtils.copyDirectory(hubProject.getHubMappingsDir().toFile(), migratedFlows.resolve(\"mappings\").toFile());\n+            logger.info(\"The original flows and mappings are backed up in migrated-flows/flows and migrated-flows/mappings\"+\n+                \"directory respectively.\");\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as backing up flows failed : \" + e.getMessage());\n+        }\n+\n+        Path stepsDir = hubProject.getProjectDir().resolve(\"steps\");\n+        Path ingestionDir = stepsDir.resolve(StepDefinition.StepDefinitionType.INGESTION.toString());\n+        Path mappingDir = stepsDir.resolve(StepDefinition.StepDefinitionType.MAPPING.toString());\n+\n+        try {\n+            ingestionDir.toFile().mkdirs();\n+            mappingDir.toFile().mkdirs();\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as creation of step artifact directories  failed : \" + e.getMessage());\n+        }\n+\n+        ObjectWriter writer = mapper.writerWithDefaultPrettyPrinter();\n+        JsonNodeFactory nodeFactory = mapper.getNodeFactory();\n+\n+        flowManager.getLocalFlows().forEach(flow ->{\n+            Map<String, Step> steps = flow.getSteps();\n+            boolean flowRequiresMigration = steps.values().stream().anyMatch(step -> stepRequiresMigration(step));\n+            logger.info(flowRequiresMigration ? \"Migrating flow \" + flow.getName() :\n+                \"Flow \" + flow.getName() + \" contains no ingestion or mapping step. It doesn't require migration\");\n+            if(flowRequiresMigration){\n+                ObjectNode newFlow = nodeFactory.objectNode();\n+                newFlow.put(\"name\", flow.getName());\n+                ObjectNode newSteps = nodeFactory.objectNode();;\n+                for (Map.Entry<String, Step> entry : steps.entrySet()) {\n+                    Step step = entry.getValue();\n+                    if(stepRequiresMigration(step)){\n+                        newSteps.set(entry.getKey(),\n+                            nodeFactory.objectNode().put(\"stepId\",String.join(\"-\", step.getName(), step.getStepDefinitionType().toString())));\n+                        ObjectNode newStepArtifact = createStepArtifact(flow, step);\n+                        Path targetDir = step.getStepDefinitionType().equals(StepDefinition.StepDefinitionType.INGESTION) ? ingestionDir : mappingDir;\n+                        String stepFileName = new StringBuilder(step.getName()).append(\".step.json\").toString();\n+                        File stepFile = targetDir.resolve(stepFileName).toFile();\n+                        logger.info(\"Creating step artifact \"+ stepFile.toString());\n+                        if (stepFile.exists()) {\n+                            String msg = \"Step artifact \" + stepFile.toString() + \" already exists. The step artifact will be written to \";\n+                            //Update step artifact with new name\n+                            String stepName = new StringBuilder(flow.getName()).append(\"-\").append(step.getName()).toString();\n+                            newStepArtifact.put(\"name\", stepName);\n+                            //Update the filename\n+                            stepFileName = new StringBuilder(flow.getName()).append(\"-\").append(stepFileName).toString();\n+                            stepFile = targetDir.resolve(stepFileName).toFile();\n+\n+                            logger.info(msg + stepFile.toString()) ;\n+                        }\n+                        try{\n+                            writer.writeValue(stepFile, newStepArtifact);\n+                            logger.info(\"Step artifact \" + stepFile.toString() + \" successfully created.\");\n+                        }\n+                        catch(IOException e){\n+                            logger.error(\"Step artifact \" + stepFile.toString() + \" creation failed: \" + e.getMessage());\n+                        }\n+                    }\n+                    else {\n+                        logger.info(\"Step \" + step.getName() + \" is not an out of the box ingestion or mapping step. It will remain inline inside the flow artifact\");\n+                        newSteps.set(entry.getKey(), mapper.valueToTree(step));\n+                    }\n+                }\n+                newFlow.set(\"steps\",newSteps);\n+                File flowFile = Paths.get(hubProject.getFlowsDir().toString(), flow.getName() + FlowManager.FLOW_FILE_EXTENSION).toFile();\n+                try{\n+                    writer.writeValue(flowFile, newFlow);\n+                    logger.info(\"Flow \" + flowFile.toString() + \" successfully migrated.\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQzMzQxMw=="}, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTg1MDc2OnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwODowMDo1N1rOGWrpnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwODoyNDowOFrOGWsfMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQzNzAyMw==", "bodyText": "ingestion step seems to be show up as \"Unknown\" in the the flow, since its expecting a loadData config", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426437023", "createdAt": "2020-05-18T08:00:57Z", "author": {"login": "bsrikan"}, "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Copyright (c) 2020 MarkLogic Corporation\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.marklogic.hub.flow.impl;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectWriter;\n+import com.fasterxml.jackson.databind.node.JsonNodeFactory;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.marklogic.hub.FlowManager;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import com.marklogic.hub.MappingManager;\n+import com.marklogic.hub.error.DataHubProjectException;\n+import com.marklogic.hub.flow.Flow;\n+import com.marklogic.hub.impl.FlowManagerImpl;\n+import com.marklogic.hub.impl.MappingManagerImpl;\n+import com.marklogic.hub.mapping.Mapping;\n+import com.marklogic.hub.step.StepDefinition;\n+import com.marklogic.hub.step.impl.Step;\n+import org.apache.commons.io.FileUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+\n+\n+/**\n+ * Class for migrating pre-5.3.0 flows to  5.3.0 and above versions\n+ */\n+\n+public class FlowMigrator {\n+\n+    private HubProject hubProject;\n+    private MappingManager mappingManager;\n+    private FlowManager flowManager;\n+    protected final Logger logger = LoggerFactory.getLogger(this.getClass());\n+    ObjectMapper mapper = new ObjectMapper();\n+\n+    public FlowMigrator(HubConfig hubConfig){\n+        hubProject = hubConfig.getHubProject();\n+        mappingManager = new MappingManagerImpl(hubConfig);\n+        flowManager = new FlowManagerImpl(hubConfig, mappingManager);\n+    }\n+\n+    public void migrateFlows(){\n+        //Backup flows and mappings\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+        try {\n+            migratedFlows.toFile().mkdirs();\n+            FileUtils.copyDirectory(hubProject.getFlowsDir().toFile(), migratedFlows.resolve(\"flows\").toFile());\n+            FileUtils.copyDirectory(hubProject.getHubMappingsDir().toFile(), migratedFlows.resolve(\"mappings\").toFile());\n+            logger.info(\"The original flows and mappings are backed up in migrated-flows/flows and migrated-flows/mappings\"+\n+                \"directory respectively.\");\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as backing up flows failed : \" + e.getMessage());\n+        }\n+\n+        Path stepsDir = hubProject.getProjectDir().resolve(\"steps\");\n+        Path ingestionDir = stepsDir.resolve(StepDefinition.StepDefinitionType.INGESTION.toString());\n+        Path mappingDir = stepsDir.resolve(StepDefinition.StepDefinitionType.MAPPING.toString());\n+\n+        try {\n+            ingestionDir.toFile().mkdirs();\n+            mappingDir.toFile().mkdirs();\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as creation of step artifact directories  failed : \" + e.getMessage());\n+        }\n+\n+        ObjectWriter writer = mapper.writerWithDefaultPrettyPrinter();\n+        JsonNodeFactory nodeFactory = mapper.getNodeFactory();\n+\n+        flowManager.getLocalFlows().forEach(flow ->{\n+            Map<String, Step> steps = flow.getSteps();\n+            boolean flowRequiresMigration = steps.values().stream().anyMatch(step -> stepRequiresMigration(step));\n+            logger.info(flowRequiresMigration ? \"Migrating flow \" + flow.getName() :\n+                \"Flow \" + flow.getName() + \" contains no ingestion or mapping step. It doesn't require migration\");\n+            if(flowRequiresMigration){\n+                ObjectNode newFlow = nodeFactory.objectNode();\n+                newFlow.put(\"name\", flow.getName());\n+                ObjectNode newSteps = nodeFactory.objectNode();;\n+                for (Map.Entry<String, Step> entry : steps.entrySet()) {\n+                    Step step = entry.getValue();\n+                    if(stepRequiresMigration(step)){\n+                        newSteps.set(entry.getKey(),\n+                            nodeFactory.objectNode().put(\"stepId\",String.join(\"-\", step.getName(), step.getStepDefinitionType().toString())));\n+                        ObjectNode newStepArtifact = createStepArtifact(flow, step);\n+                        Path targetDir = step.getStepDefinitionType().equals(StepDefinition.StepDefinitionType.INGESTION) ? ingestionDir : mappingDir;\n+                        String stepFileName = new StringBuilder(step.getName()).append(\".step.json\").toString();\n+                        File stepFile = targetDir.resolve(stepFileName).toFile();\n+                        logger.info(\"Creating step artifact \"+ stepFile.toString());\n+                        if (stepFile.exists()) {\n+                            String msg = \"Step artifact \" + stepFile.toString() + \" already exists. The step artifact will be written to \";\n+                            //Update step artifact with new name\n+                            String stepName = new StringBuilder(flow.getName()).append(\"-\").append(step.getName()).toString();\n+                            newStepArtifact.put(\"name\", stepName);\n+                            //Update the filename\n+                            stepFileName = new StringBuilder(flow.getName()).append(\"-\").append(stepFileName).toString();\n+                            stepFile = targetDir.resolve(stepFileName).toFile();\n+\n+                            logger.info(msg + stepFile.toString()) ;\n+                        }\n+                        try{\n+                            writer.writeValue(stepFile, newStepArtifact);\n+                            logger.info(\"Step artifact \" + stepFile.toString() + \" successfully created.\");\n+                        }\n+                        catch(IOException e){\n+                            logger.error(\"Step artifact \" + stepFile.toString() + \" creation failed: \" + e.getMessage());\n+                        }\n+                    }\n+                    else {\n+                        logger.info(\"Step \" + step.getName() + \" is not an out of the box ingestion or mapping step. It will remain inline inside the flow artifact\");\n+                        newSteps.set(entry.getKey(), mapper.valueToTree(step));\n+                    }\n+                }\n+                newFlow.set(\"steps\",newSteps);\n+                File flowFile = Paths.get(hubProject.getFlowsDir().toString(), flow.getName() + FlowManager.FLOW_FILE_EXTENSION).toFile();\n+                try{\n+                    writer.writeValue(flowFile, newFlow);\n+                    logger.info(\"Flow \" + flowFile.toString() + \" successfully migrated.\");\n+                }\n+                catch(IOException e){\n+                    logger.error(\"Flow artifact \" + flowFile.toString() + \" creation failed: \" + e.getMessage());\n+                }\n+            }\n+        });\n+    }\n+\n+    // Only create step artifacts for ootb ingestion and mapping steps. Other steps(including custom ingestion and mapping)\n+    // will be inline\n+    private boolean stepRequiresMigration(Step step) {\n+        return (StepDefinition.StepDefinitionType.MAPPING.equals(step.getStepDefinitionType()) && \"entity-services-mapping\".equalsIgnoreCase(step.getStepDefinitionName())) ||\n+            (StepDefinition.StepDefinitionType.INGESTION.equals(step.getStepDefinitionType()) &&  \"default-ingestion\".equalsIgnoreCase(step.getStepDefinitionName()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ1MDczOA==", "bodyText": "This has to be verified after DHFPROD-4951 and DHFPROD-4952 are merged", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426450738", "createdAt": "2020-05-18T08:24:08Z", "author": {"login": "srinathgit"}, "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Copyright (c) 2020 MarkLogic Corporation\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.marklogic.hub.flow.impl;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectWriter;\n+import com.fasterxml.jackson.databind.node.JsonNodeFactory;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.marklogic.hub.FlowManager;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import com.marklogic.hub.MappingManager;\n+import com.marklogic.hub.error.DataHubProjectException;\n+import com.marklogic.hub.flow.Flow;\n+import com.marklogic.hub.impl.FlowManagerImpl;\n+import com.marklogic.hub.impl.MappingManagerImpl;\n+import com.marklogic.hub.mapping.Mapping;\n+import com.marklogic.hub.step.StepDefinition;\n+import com.marklogic.hub.step.impl.Step;\n+import org.apache.commons.io.FileUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+\n+\n+/**\n+ * Class for migrating pre-5.3.0 flows to  5.3.0 and above versions\n+ */\n+\n+public class FlowMigrator {\n+\n+    private HubProject hubProject;\n+    private MappingManager mappingManager;\n+    private FlowManager flowManager;\n+    protected final Logger logger = LoggerFactory.getLogger(this.getClass());\n+    ObjectMapper mapper = new ObjectMapper();\n+\n+    public FlowMigrator(HubConfig hubConfig){\n+        hubProject = hubConfig.getHubProject();\n+        mappingManager = new MappingManagerImpl(hubConfig);\n+        flowManager = new FlowManagerImpl(hubConfig, mappingManager);\n+    }\n+\n+    public void migrateFlows(){\n+        //Backup flows and mappings\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+        try {\n+            migratedFlows.toFile().mkdirs();\n+            FileUtils.copyDirectory(hubProject.getFlowsDir().toFile(), migratedFlows.resolve(\"flows\").toFile());\n+            FileUtils.copyDirectory(hubProject.getHubMappingsDir().toFile(), migratedFlows.resolve(\"mappings\").toFile());\n+            logger.info(\"The original flows and mappings are backed up in migrated-flows/flows and migrated-flows/mappings\"+\n+                \"directory respectively.\");\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as backing up flows failed : \" + e.getMessage());\n+        }\n+\n+        Path stepsDir = hubProject.getProjectDir().resolve(\"steps\");\n+        Path ingestionDir = stepsDir.resolve(StepDefinition.StepDefinitionType.INGESTION.toString());\n+        Path mappingDir = stepsDir.resolve(StepDefinition.StepDefinitionType.MAPPING.toString());\n+\n+        try {\n+            ingestionDir.toFile().mkdirs();\n+            mappingDir.toFile().mkdirs();\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as creation of step artifact directories  failed : \" + e.getMessage());\n+        }\n+\n+        ObjectWriter writer = mapper.writerWithDefaultPrettyPrinter();\n+        JsonNodeFactory nodeFactory = mapper.getNodeFactory();\n+\n+        flowManager.getLocalFlows().forEach(flow ->{\n+            Map<String, Step> steps = flow.getSteps();\n+            boolean flowRequiresMigration = steps.values().stream().anyMatch(step -> stepRequiresMigration(step));\n+            logger.info(flowRequiresMigration ? \"Migrating flow \" + flow.getName() :\n+                \"Flow \" + flow.getName() + \" contains no ingestion or mapping step. It doesn't require migration\");\n+            if(flowRequiresMigration){\n+                ObjectNode newFlow = nodeFactory.objectNode();\n+                newFlow.put(\"name\", flow.getName());\n+                ObjectNode newSteps = nodeFactory.objectNode();;\n+                for (Map.Entry<String, Step> entry : steps.entrySet()) {\n+                    Step step = entry.getValue();\n+                    if(stepRequiresMigration(step)){\n+                        newSteps.set(entry.getKey(),\n+                            nodeFactory.objectNode().put(\"stepId\",String.join(\"-\", step.getName(), step.getStepDefinitionType().toString())));\n+                        ObjectNode newStepArtifact = createStepArtifact(flow, step);\n+                        Path targetDir = step.getStepDefinitionType().equals(StepDefinition.StepDefinitionType.INGESTION) ? ingestionDir : mappingDir;\n+                        String stepFileName = new StringBuilder(step.getName()).append(\".step.json\").toString();\n+                        File stepFile = targetDir.resolve(stepFileName).toFile();\n+                        logger.info(\"Creating step artifact \"+ stepFile.toString());\n+                        if (stepFile.exists()) {\n+                            String msg = \"Step artifact \" + stepFile.toString() + \" already exists. The step artifact will be written to \";\n+                            //Update step artifact with new name\n+                            String stepName = new StringBuilder(flow.getName()).append(\"-\").append(step.getName()).toString();\n+                            newStepArtifact.put(\"name\", stepName);\n+                            //Update the filename\n+                            stepFileName = new StringBuilder(flow.getName()).append(\"-\").append(stepFileName).toString();\n+                            stepFile = targetDir.resolve(stepFileName).toFile();\n+\n+                            logger.info(msg + stepFile.toString()) ;\n+                        }\n+                        try{\n+                            writer.writeValue(stepFile, newStepArtifact);\n+                            logger.info(\"Step artifact \" + stepFile.toString() + \" successfully created.\");\n+                        }\n+                        catch(IOException e){\n+                            logger.error(\"Step artifact \" + stepFile.toString() + \" creation failed: \" + e.getMessage());\n+                        }\n+                    }\n+                    else {\n+                        logger.info(\"Step \" + step.getName() + \" is not an out of the box ingestion or mapping step. It will remain inline inside the flow artifact\");\n+                        newSteps.set(entry.getKey(), mapper.valueToTree(step));\n+                    }\n+                }\n+                newFlow.set(\"steps\",newSteps);\n+                File flowFile = Paths.get(hubProject.getFlowsDir().toString(), flow.getName() + FlowManager.FLOW_FILE_EXTENSION).toFile();\n+                try{\n+                    writer.writeValue(flowFile, newFlow);\n+                    logger.info(\"Flow \" + flowFile.toString() + \" successfully migrated.\");\n+                }\n+                catch(IOException e){\n+                    logger.error(\"Flow artifact \" + flowFile.toString() + \" creation failed: \" + e.getMessage());\n+                }\n+            }\n+        });\n+    }\n+\n+    // Only create step artifacts for ootb ingestion and mapping steps. Other steps(including custom ingestion and mapping)\n+    // will be inline\n+    private boolean stepRequiresMigration(Step step) {\n+        return (StepDefinition.StepDefinitionType.MAPPING.equals(step.getStepDefinitionType()) && \"entity-services-mapping\".equalsIgnoreCase(step.getStepDefinitionName())) ||\n+            (StepDefinition.StepDefinitionType.INGESTION.equals(step.getStepDefinitionType()) &&  \"default-ingestion\".equalsIgnoreCase(step.getStepDefinitionName()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQzNzAyMw=="}, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1NTg3NjQxOnYy", "diffSide": "RIGHT", "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwODowODowOFrOGWr5tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQwODoyMTowMVrOGWsYAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ0MTE0Mw==", "bodyText": "endpoint http://localhost:8080/api/artifacts/mapping seems to return all the versions of a mapping. Shouldnt it return only the latest version. UI ends up showing all the versions which is not desired.", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426441143", "createdAt": "2020-05-18T08:08:08Z", "author": {"login": "bsrikan"}, "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Copyright (c) 2020 MarkLogic Corporation\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.marklogic.hub.flow.impl;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectWriter;\n+import com.fasterxml.jackson.databind.node.JsonNodeFactory;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.marklogic.hub.FlowManager;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import com.marklogic.hub.MappingManager;\n+import com.marklogic.hub.error.DataHubProjectException;\n+import com.marklogic.hub.flow.Flow;\n+import com.marklogic.hub.impl.FlowManagerImpl;\n+import com.marklogic.hub.impl.MappingManagerImpl;\n+import com.marklogic.hub.mapping.Mapping;\n+import com.marklogic.hub.step.StepDefinition;\n+import com.marklogic.hub.step.impl.Step;\n+import org.apache.commons.io.FileUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+\n+\n+/**\n+ * Class for migrating pre-5.3.0 flows to  5.3.0 and above versions\n+ */\n+\n+public class FlowMigrator {\n+\n+    private HubProject hubProject;\n+    private MappingManager mappingManager;\n+    private FlowManager flowManager;\n+    protected final Logger logger = LoggerFactory.getLogger(this.getClass());\n+    ObjectMapper mapper = new ObjectMapper();\n+\n+    public FlowMigrator(HubConfig hubConfig){\n+        hubProject = hubConfig.getHubProject();\n+        mappingManager = new MappingManagerImpl(hubConfig);\n+        flowManager = new FlowManagerImpl(hubConfig, mappingManager);\n+    }\n+\n+    public void migrateFlows(){\n+        //Backup flows and mappings\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+        try {\n+            migratedFlows.toFile().mkdirs();\n+            FileUtils.copyDirectory(hubProject.getFlowsDir().toFile(), migratedFlows.resolve(\"flows\").toFile());\n+            FileUtils.copyDirectory(hubProject.getHubMappingsDir().toFile(), migratedFlows.resolve(\"mappings\").toFile());\n+            logger.info(\"The original flows and mappings are backed up in migrated-flows/flows and migrated-flows/mappings\"+\n+                \"directory respectively.\");\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as backing up flows failed : \" + e.getMessage());\n+        }\n+\n+        Path stepsDir = hubProject.getProjectDir().resolve(\"steps\");\n+        Path ingestionDir = stepsDir.resolve(StepDefinition.StepDefinitionType.INGESTION.toString());\n+        Path mappingDir = stepsDir.resolve(StepDefinition.StepDefinitionType.MAPPING.toString());\n+\n+        try {\n+            ingestionDir.toFile().mkdirs();\n+            mappingDir.toFile().mkdirs();\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as creation of step artifact directories  failed : \" + e.getMessage());\n+        }\n+\n+        ObjectWriter writer = mapper.writerWithDefaultPrettyPrinter();\n+        JsonNodeFactory nodeFactory = mapper.getNodeFactory();\n+\n+        flowManager.getLocalFlows().forEach(flow ->{\n+            Map<String, Step> steps = flow.getSteps();\n+            boolean flowRequiresMigration = steps.values().stream().anyMatch(step -> stepRequiresMigration(step));\n+            logger.info(flowRequiresMigration ? \"Migrating flow \" + flow.getName() :\n+                \"Flow \" + flow.getName() + \" contains no ingestion or mapping step. It doesn't require migration\");\n+            if(flowRequiresMigration){\n+                ObjectNode newFlow = nodeFactory.objectNode();\n+                newFlow.put(\"name\", flow.getName());\n+                ObjectNode newSteps = nodeFactory.objectNode();;\n+                for (Map.Entry<String, Step> entry : steps.entrySet()) {\n+                    Step step = entry.getValue();\n+                    if(stepRequiresMigration(step)){\n+                        newSteps.set(entry.getKey(),\n+                            nodeFactory.objectNode().put(\"stepId\",String.join(\"-\", step.getName(), step.getStepDefinitionType().toString())));\n+                        ObjectNode newStepArtifact = createStepArtifact(flow, step);\n+                        Path targetDir = step.getStepDefinitionType().equals(StepDefinition.StepDefinitionType.INGESTION) ? ingestionDir : mappingDir;\n+                        String stepFileName = new StringBuilder(step.getName()).append(\".step.json\").toString();\n+                        File stepFile = targetDir.resolve(stepFileName).toFile();\n+                        logger.info(\"Creating step artifact \"+ stepFile.toString());\n+                        if (stepFile.exists()) {\n+                            String msg = \"Step artifact \" + stepFile.toString() + \" already exists. The step artifact will be written to \";\n+                            //Update step artifact with new name\n+                            String stepName = new StringBuilder(flow.getName()).append(\"-\").append(step.getName()).toString();\n+                            newStepArtifact.put(\"name\", stepName);\n+                            //Update the filename\n+                            stepFileName = new StringBuilder(flow.getName()).append(\"-\").append(stepFileName).toString();\n+                            stepFile = targetDir.resolve(stepFileName).toFile();\n+\n+                            logger.info(msg + stepFile.toString()) ;\n+                        }\n+                        try{\n+                            writer.writeValue(stepFile, newStepArtifact);\n+                            logger.info(\"Step artifact \" + stepFile.toString() + \" successfully created.\");\n+                        }\n+                        catch(IOException e){\n+                            logger.error(\"Step artifact \" + stepFile.toString() + \" creation failed: \" + e.getMessage());\n+                        }\n+                    }\n+                    else {\n+                        logger.info(\"Step \" + step.getName() + \" is not an out of the box ingestion or mapping step. It will remain inline inside the flow artifact\");\n+                        newSteps.set(entry.getKey(), mapper.valueToTree(step));\n+                    }\n+                }\n+                newFlow.set(\"steps\",newSteps);\n+                File flowFile = Paths.get(hubProject.getFlowsDir().toString(), flow.getName() + FlowManager.FLOW_FILE_EXTENSION).toFile();\n+                try{\n+                    writer.writeValue(flowFile, newFlow);\n+                    logger.info(\"Flow \" + flowFile.toString() + \" successfully migrated.\");\n+                }\n+                catch(IOException e){\n+                    logger.error(\"Flow artifact \" + flowFile.toString() + \" creation failed: \" + e.getMessage());\n+                }\n+            }\n+        });\n+    }\n+\n+    // Only create step artifacts for ootb ingestion and mapping steps. Other steps(including custom ingestion and mapping)\n+    // will be inline\n+    private boolean stepRequiresMigration(Step step) {\n+        return (StepDefinition.StepDefinitionType.MAPPING.equals(step.getStepDefinitionType()) && \"entity-services-mapping\".equalsIgnoreCase(step.getStepDefinitionName())) ||", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ0ODg5Nw==", "bodyText": "It will only copy the mapping version that is specified in the flow. Also, \"mapping\" object will be removed from the mapping step in my next commit", "url": "https://github.com/marklogic/marklogic-data-hub/pull/3963#discussion_r426448897", "createdAt": "2020-05-18T08:21:01Z", "author": {"login": "srinathgit"}, "path": "marklogic-data-hub/src/main/java/com/marklogic/hub/flow/impl/FlowMigrator.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Copyright (c) 2020 MarkLogic Corporation\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.marklogic.hub.flow.impl;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectWriter;\n+import com.fasterxml.jackson.databind.node.JsonNodeFactory;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.marklogic.hub.FlowManager;\n+import com.marklogic.hub.HubConfig;\n+import com.marklogic.hub.HubProject;\n+import com.marklogic.hub.MappingManager;\n+import com.marklogic.hub.error.DataHubProjectException;\n+import com.marklogic.hub.flow.Flow;\n+import com.marklogic.hub.impl.FlowManagerImpl;\n+import com.marklogic.hub.impl.MappingManagerImpl;\n+import com.marklogic.hub.mapping.Mapping;\n+import com.marklogic.hub.step.StepDefinition;\n+import com.marklogic.hub.step.impl.Step;\n+import org.apache.commons.io.FileUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+\n+\n+/**\n+ * Class for migrating pre-5.3.0 flows to  5.3.0 and above versions\n+ */\n+\n+public class FlowMigrator {\n+\n+    private HubProject hubProject;\n+    private MappingManager mappingManager;\n+    private FlowManager flowManager;\n+    protected final Logger logger = LoggerFactory.getLogger(this.getClass());\n+    ObjectMapper mapper = new ObjectMapper();\n+\n+    public FlowMigrator(HubConfig hubConfig){\n+        hubProject = hubConfig.getHubProject();\n+        mappingManager = new MappingManagerImpl(hubConfig);\n+        flowManager = new FlowManagerImpl(hubConfig, mappingManager);\n+    }\n+\n+    public void migrateFlows(){\n+        //Backup flows and mappings\n+        Path migratedFlows = hubProject.getProjectDir().resolve(\"migrated-flows\");\n+        try {\n+            migratedFlows.toFile().mkdirs();\n+            FileUtils.copyDirectory(hubProject.getFlowsDir().toFile(), migratedFlows.resolve(\"flows\").toFile());\n+            FileUtils.copyDirectory(hubProject.getHubMappingsDir().toFile(), migratedFlows.resolve(\"mappings\").toFile());\n+            logger.info(\"The original flows and mappings are backed up in migrated-flows/flows and migrated-flows/mappings\"+\n+                \"directory respectively.\");\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as backing up flows failed : \" + e.getMessage());\n+        }\n+\n+        Path stepsDir = hubProject.getProjectDir().resolve(\"steps\");\n+        Path ingestionDir = stepsDir.resolve(StepDefinition.StepDefinitionType.INGESTION.toString());\n+        Path mappingDir = stepsDir.resolve(StepDefinition.StepDefinitionType.MAPPING.toString());\n+\n+        try {\n+            ingestionDir.toFile().mkdirs();\n+            mappingDir.toFile().mkdirs();\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Couldn't migrate flows as creation of step artifact directories  failed : \" + e.getMessage());\n+        }\n+\n+        ObjectWriter writer = mapper.writerWithDefaultPrettyPrinter();\n+        JsonNodeFactory nodeFactory = mapper.getNodeFactory();\n+\n+        flowManager.getLocalFlows().forEach(flow ->{\n+            Map<String, Step> steps = flow.getSteps();\n+            boolean flowRequiresMigration = steps.values().stream().anyMatch(step -> stepRequiresMigration(step));\n+            logger.info(flowRequiresMigration ? \"Migrating flow \" + flow.getName() :\n+                \"Flow \" + flow.getName() + \" contains no ingestion or mapping step. It doesn't require migration\");\n+            if(flowRequiresMigration){\n+                ObjectNode newFlow = nodeFactory.objectNode();\n+                newFlow.put(\"name\", flow.getName());\n+                ObjectNode newSteps = nodeFactory.objectNode();;\n+                for (Map.Entry<String, Step> entry : steps.entrySet()) {\n+                    Step step = entry.getValue();\n+                    if(stepRequiresMigration(step)){\n+                        newSteps.set(entry.getKey(),\n+                            nodeFactory.objectNode().put(\"stepId\",String.join(\"-\", step.getName(), step.getStepDefinitionType().toString())));\n+                        ObjectNode newStepArtifact = createStepArtifact(flow, step);\n+                        Path targetDir = step.getStepDefinitionType().equals(StepDefinition.StepDefinitionType.INGESTION) ? ingestionDir : mappingDir;\n+                        String stepFileName = new StringBuilder(step.getName()).append(\".step.json\").toString();\n+                        File stepFile = targetDir.resolve(stepFileName).toFile();\n+                        logger.info(\"Creating step artifact \"+ stepFile.toString());\n+                        if (stepFile.exists()) {\n+                            String msg = \"Step artifact \" + stepFile.toString() + \" already exists. The step artifact will be written to \";\n+                            //Update step artifact with new name\n+                            String stepName = new StringBuilder(flow.getName()).append(\"-\").append(step.getName()).toString();\n+                            newStepArtifact.put(\"name\", stepName);\n+                            //Update the filename\n+                            stepFileName = new StringBuilder(flow.getName()).append(\"-\").append(stepFileName).toString();\n+                            stepFile = targetDir.resolve(stepFileName).toFile();\n+\n+                            logger.info(msg + stepFile.toString()) ;\n+                        }\n+                        try{\n+                            writer.writeValue(stepFile, newStepArtifact);\n+                            logger.info(\"Step artifact \" + stepFile.toString() + \" successfully created.\");\n+                        }\n+                        catch(IOException e){\n+                            logger.error(\"Step artifact \" + stepFile.toString() + \" creation failed: \" + e.getMessage());\n+                        }\n+                    }\n+                    else {\n+                        logger.info(\"Step \" + step.getName() + \" is not an out of the box ingestion or mapping step. It will remain inline inside the flow artifact\");\n+                        newSteps.set(entry.getKey(), mapper.valueToTree(step));\n+                    }\n+                }\n+                newFlow.set(\"steps\",newSteps);\n+                File flowFile = Paths.get(hubProject.getFlowsDir().toString(), flow.getName() + FlowManager.FLOW_FILE_EXTENSION).toFile();\n+                try{\n+                    writer.writeValue(flowFile, newFlow);\n+                    logger.info(\"Flow \" + flowFile.toString() + \" successfully migrated.\");\n+                }\n+                catch(IOException e){\n+                    logger.error(\"Flow artifact \" + flowFile.toString() + \" creation failed: \" + e.getMessage());\n+                }\n+            }\n+        });\n+    }\n+\n+    // Only create step artifacts for ootb ingestion and mapping steps. Other steps(including custom ingestion and mapping)\n+    // will be inline\n+    private boolean stepRequiresMigration(Step step) {\n+        return (StepDefinition.StepDefinitionType.MAPPING.equals(step.getStepDefinitionType()) && \"entity-services-mapping\".equalsIgnoreCase(step.getStepDefinitionName())) ||", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ0MTE0Mw=="}, "originalCommit": {"oid": "224d851480d0bf11d3e0c8d9478bda3d57cb99ae"}, "originalPosition": 150}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4136, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}