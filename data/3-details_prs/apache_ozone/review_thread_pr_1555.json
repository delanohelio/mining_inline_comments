{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE2NTQyMjM0", "number": 1555, "reviewThreads": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwNjoxOTowMlrOE3kZ5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwODozNzo1OVrOFBHMkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NzAzNTkxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwNjoxOTowMlrOHw_nOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwNjoxOTowMlrOHw_nOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNTkyOQ==", "bodyText": "Please remove the * imports", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521135929", "createdAt": "2020-11-11T06:19:02Z", "author": {"login": "bshashikant"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49dec78ee794e898a0c083927238ec036131d1e8"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NzAzNzk3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwNjoyMDowMVrOHw_oYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwNzo1NDo0NFrOHxCIOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNjIyNg==", "bodyText": "Why do we need to copy these functions? Is it doing anything special with respect to ozone\n/", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521136226", "createdAt": "2020-11-11T06:20:01Z", "author": {"login": "bshashikant"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.*;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }\n+    }\n+\n+\n+    private long ceiling(long time, long interval) {\n+      return floor(time, interval) + interval;\n+    }\n+    private long floor(long time, long interval) {\n+      return (time / interval) * interval;\n+    }\n+\n+  }\n+\n+  private void createCheckpoint(Path trashRoot, Date date) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49dec78ee794e898a0c083927238ec036131d1e8"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTE1MTMwNA==", "bodyText": "Cant override these methods from TrashPolicyDefault since they have private scope in TrashPolicyDefault.so had to copy.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521151304", "createdAt": "2020-11-11T06:54:07Z", "author": {"login": "sadanand48"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.*;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }\n+    }\n+\n+\n+    private long ceiling(long time, long interval) {\n+      return floor(time, interval) + interval;\n+    }\n+    private long floor(long time, long interval) {\n+      return (time / interval) * interval;\n+    }\n+\n+  }\n+\n+  private void createCheckpoint(Path trashRoot, Date date) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNjIyNg=="}, "originalCommit": {"oid": "49dec78ee794e898a0c083927238ec036131d1e8"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTE1Mzc0OA==", "bodyText": "If you want to use the same functionality as already existing, there is no need to override.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521153748", "createdAt": "2020-11-11T06:57:42Z", "author": {"login": "bshashikant"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.*;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }\n+    }\n+\n+\n+    private long ceiling(long time, long interval) {\n+      return floor(time, interval) + interval;\n+    }\n+    private long floor(long time, long interval) {\n+      return (time / interval) * interval;\n+    }\n+\n+  }\n+\n+  private void createCheckpoint(Path trashRoot, Date date) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNjIyNg=="}, "originalCommit": {"oid": "49dec78ee794e898a0c083927238ec036131d1e8"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTE3NzE0NQ==", "bodyText": "Understood.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521177145", "createdAt": "2020-11-11T07:54:44Z", "author": {"login": "bshashikant"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.*;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }\n+    }\n+\n+\n+    private long ceiling(long time, long interval) {\n+      return floor(time, interval) + interval;\n+    }\n+    private long floor(long time, long interval) {\n+      return (time / interval) * interval;\n+    }\n+\n+  }\n+\n+  private void createCheckpoint(Path trashRoot, Date date) throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNjIyNg=="}, "originalCommit": {"oid": "49dec78ee794e898a0c083927238ec036131d1e8"}, "originalPosition": 207}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTgxNTIwOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMjoxMDo0M1rOH1TD9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMjoxMDo0M1rOH1TD9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0ODg4Nw==", "bodyText": "why are these tests commented out ?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r525648887", "createdAt": "2020-11-18T02:10:43Z", "author": {"login": "prashantpogde"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -206,19 +210,19 @@ private void checkInvalidPath(Path path) throws Exception {\n     }\n   }\n \n-  @Test(timeout = 300_000)\n+  @Test(timeout = 540_000)\n   public void testFileSystem() throws Exception {\n     setupOzoneFileSystem();\n \n     testOzoneFsServiceLoader();\n     o3fs = (OzoneFileSystem) fs;\n \n-    testCreateFileShouldCheckExistenceOfDirWithSameName();\n+  /*  testCreateFileShouldCheckExistenceOfDirWithSameName();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTgzNjk0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMjoxNjozMFrOH1TSuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMjoxNjozMFrOH1TSuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MjY2Nw==", "bodyText": "this check should be inside run method in TrashPolicyOzone. I also do not see a problem if it was run on all OM nodes.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r525652667", "createdAt": "2020-11-18T02:16:30Z", "author": {"login": "prashantpogde"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1228,17 +1238,61 @@ public void restart() throws IOException {\n       // Allow OM to start as Http Server failure is not fatal.\n       LOG.error(\"OM HttpServer failed to start.\", ex);\n     }\n-\n     omRpcServer.start();\n+\n     isOmRpcServerRunning = true;\n \n+    if (isLeader()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5ODM0MTYzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMjo1ODowNlrOH1sg6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxNDo0ODoyNVrOH1xWFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA2NTg5Ng==", "bodyText": "Can we try to catch Exception rather than IOException to avoid uncaught exception that may be swallowed here?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526065896", "createdAt": "2020-11-18T12:58:06Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.TrashPolicyDefault;\n+import org.apache.hadoop.fs.FileAlreadyExistsException;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjE0NTA0NA==", "bodyText": "done.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526145044", "createdAt": "2020-11-18T14:48:25Z", "author": {"login": "sadanand48"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.TrashPolicyDefault;\n+import org.apache.hadoop.fs.FileAlreadyExistsException;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA2NTg5Ng=="}, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 177}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5ODQ3NzUzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMzoyOTozOFrOH1t1_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxNDo0ODozNFrOH1xWcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA4NzY3OA==", "bodyText": "Can we shutdown executor pool in the finally block?\n        try {\n             while (true) {\n                 ....\n             }\n         } finally {\n            shutdown executor pool.\n         }", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526087678", "createdAt": "2020-11-18T13:29:38Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.TrashPolicyDefault;\n+import org.apache.hadoop.fs.FileAlreadyExistsException;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjE0NTEzOQ==", "bodyText": "done.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526145139", "createdAt": "2020-11-18T14:48:34Z", "author": {"login": "sadanand48"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.TrashPolicyDefault;\n+import org.apache.hadoop.fs.FileAlreadyExistsException;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA4NzY3OA=="}, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 198}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzkwMDkxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTo0NTowM1rOH3IXbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTo0NTowM1rOH3IXbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU3MDc5Ng==", "bodyText": "why do we need to increase the timeout ?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527570796", "createdAt": "2020-11-20T09:45:03Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -206,7 +209,7 @@ private void checkInvalidPath(Path path) throws Exception {\n     }\n   }\n \n-  @Test(timeout = 300_000)\n+  @Test(timeout = 540_000)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwODU1ODM2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1Mjo0NlrOH3OgXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1Mjo0NlrOH3OgXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTM5MA==", "bodyText": "This should be outside the runnable function.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527671390", "createdAt": "2020-11-20T12:52:46Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +131,24 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n               if (!trashRoot.isDirectory()) {\n                 continue;\n               }\n-              try {\n-                TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n-                trash.deleteCheckpoint(trashRoot.getPath(), false);\n-                trash.createCheckpoint(trashRoot.getPath(), new Date(now));\n-              } catch (IOException e) {\n-                LOG.warn(\"Trash caught: \"+e+\". Skipping \" +\n-                    trashRoot.getPath() + \".\");\n-              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwODU1OTc2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1MzoxM1rOH3OhPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1MzoxM1rOH3OhPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTYxMg==", "bodyText": "Same as above.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527671612", "createdAt": "2020-11-20T12:53:13Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +131,24 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwODU2MDY1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1MzoyOVrOH3OhwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1MzoyOVrOH3OhwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTc0NA==", "bodyText": "Please change the LOG.info to LOG.debug", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527671744", "createdAt": "2020-11-20T12:53:29Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +131,24 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwODU2MzQ4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1NDoyN1rOH3Ojhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1NDoyN1rOH3Ojhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MjE5OA==", "bodyText": "We also need to do executor.awaitTermination as well here.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527672198", "createdAt": "2020-11-20T12:54:27Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -139,9 +159,12 @@ public void run() {\n         fs.close();\n       } catch(IOException e) {\n         LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      } finally {\n+        executor.shutdown();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwODU2NTY4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1NTowM1rOH3Okxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1NTowM1rOH3Okxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MjUxOA==", "bodyText": "Please change this to great from a config.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527672518", "createdAt": "2020-11-20T12:55:03Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -49,6 +53,8 @@\n \n   private static final Path CURRENT = new Path(\"Current\");\n \n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MjU1NzE1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo1NDoxMFrOH8G0zA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwNToyNTozOVrOH8YrIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODQyOA==", "bodyText": "Lets use CommonConfigurationKeysPublic#FS_TRASH_CHECKPOINT_INTERVAL_KEY here", "url": "https://github.com/apache/ozone/pull/1555#discussion_r532788428", "createdAt": "2020-11-30T17:54:10Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -776,4 +784,59 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+  /**\n+   * 1.Move a Key to Trash\n+   * 2.Verify that the key gets deleted by the trash emptier.\n+   * @throws Exception\n+   */\n+\n+  public void testTrash() throws Exception {\n+    String testKeyName = \"testKey2\";\n+    Path path = new Path(OZONE_URI_DELIMITER, testKeyName);\n+    ContractTestUtils.touch(fs, path);\n+    Assert.assertTrue(trash.getConf().getClass(\n+        \"fs.trash.classname\", TrashPolicy.class).\n+        isAssignableFrom(TrashPolicyOzone.class));\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.interval\", 0), 1);\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.checkpoint.interval\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA4MDg2Ng==", "bodyText": "done", "url": "https://github.com/apache/ozone/pull/1555#discussion_r533080866", "createdAt": "2020-12-01T05:25:39Z", "author": {"login": "sadanand48"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -776,4 +784,59 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+  /**\n+   * 1.Move a Key to Trash\n+   * 2.Verify that the key gets deleted by the trash emptier.\n+   * @throws Exception\n+   */\n+\n+  public void testTrash() throws Exception {\n+    String testKeyName = \"testKey2\";\n+    Path path = new Path(OZONE_URI_DELIMITER, testKeyName);\n+    ContractTestUtils.touch(fs, path);\n+    Assert.assertTrue(trash.getConf().getClass(\n+        \"fs.trash.classname\", TrashPolicy.class).\n+        isAssignableFrom(TrashPolicyOzone.class));\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.interval\", 0), 1);\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.checkpoint.interval\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODQyOA=="}, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MjU1ODgzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo1NDozMlrOH8G1yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwNToyNTozN1rOH8YrHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODY4Mg==", "bodyText": "Lets use CommonConfigurationKeysPublic#FS_TRASH_INTERVAL_KEY here", "url": "https://github.com/apache/ozone/pull/1555#discussion_r532788682", "createdAt": "2020-11-30T17:54:32Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -776,4 +784,59 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+  /**\n+   * 1.Move a Key to Trash\n+   * 2.Verify that the key gets deleted by the trash emptier.\n+   * @throws Exception\n+   */\n+\n+  public void testTrash() throws Exception {\n+    String testKeyName = \"testKey2\";\n+    Path path = new Path(OZONE_URI_DELIMITER, testKeyName);\n+    ContractTestUtils.touch(fs, path);\n+    Assert.assertTrue(trash.getConf().getClass(\n+        \"fs.trash.classname\", TrashPolicy.class).\n+        isAssignableFrom(TrashPolicyOzone.class));\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.interval\", 0), 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA4MDg2MA==", "bodyText": "done", "url": "https://github.com/apache/ozone/pull/1555#discussion_r533080860", "createdAt": "2020-12-01T05:25:37Z", "author": {"login": "sadanand48"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -776,4 +784,59 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+  /**\n+   * 1.Move a Key to Trash\n+   * 2.Verify that the key gets deleted by the trash emptier.\n+   * @throws Exception\n+   */\n+\n+  public void testTrash() throws Exception {\n+    String testKeyName = \"testKey2\";\n+    Path path = new Path(OZONE_URI_DELIMITER, testKeyName);\n+    ContractTestUtils.touch(fs, path);\n+    Assert.assertTrue(trash.getConf().getClass(\n+        \"fs.trash.classname\", TrashPolicy.class).\n+        isAssignableFrom(TrashPolicyOzone.class));\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.interval\", 0), 1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODY4Mg=="}, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MjU2NDQ3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo1NTo1MFrOH8G5KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxNDo1NDoyM1rOIAqoEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4OTU0NQ==", "bodyText": "I think this is intentional. @elek @bharatviswa504 can you please confirm this line ?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r532789545", "createdAt": "2020-11-30T17:55:50Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1275,7 +1275,7 @@ private void startTrashEmptier(Configuration conf) throws IOException {\n \n     // configuration for the FS instance that  points to a root OFS uri.\n     // This will ensure that it will cover all volumes and buckets\n-    Configuration fsconf = new Configuration();\n+    Configuration fsconf = new OzoneConfiguration();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI1MTYyMw==", "bodyText": "From my understanding, we need to use OzoneConfiguration, as OzoneConfiguration activates ozone-default.xml\npublic static void activate() {\n// adds the default resources\nConfiguration.addDefaultResource(\"hdfs-default.xml\");\nConfiguration.addDefaultResource(\"hdfs-site.xml\");\nConfiguration.addDefaultResource(\"ozone-default.xml\");\n}\nBy using Configuration, defaults of Ozone will not be loaded. And also as we have for each config, we have defaults defined in Java code that should also be fine.\nUsing OzoneConfiguration is better IMHO.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r536251623", "createdAt": "2020-12-04T17:16:37Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1275,7 +1275,7 @@ private void startTrashEmptier(Configuration conf) throws IOException {\n \n     // configuration for the FS instance that  points to a root OFS uri.\n     // This will ensure that it will cover all volumes and buckets\n-    Configuration fsconf = new Configuration();\n+    Configuration fsconf = new OzoneConfiguration();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4OTU0NQ=="}, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU2OTI5OQ==", "bodyText": "thx @bharatviswa504", "url": "https://github.com/apache/ozone/pull/1555#discussion_r537569299", "createdAt": "2020-12-07T14:54:23Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1275,7 +1275,7 @@ private void startTrashEmptier(Configuration conf) throws IOException {\n \n     // configuration for the FS instance that  points to a root OFS uri.\n     // This will ensure that it will cover all volumes and buckets\n-    Configuration fsconf = new Configuration();\n+    Configuration fsconf = new OzoneConfiguration();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4OTU0NQ=="}, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NzA5MjQzOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/resources/ozone-default.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwODozNDozNFrOH_tC9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wMVQwNToyODoyMFrOINOGcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjU2MDM3NQ==", "bodyText": "Can you please use Java, annotation based configuration?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r536560375", "createdAt": "2020-12-05T08:34:34Z", "author": {"login": "elek"}, "path": "hadoop-hdds/common/src/main/resources/ozone-default.xml", "diffHunk": "@@ -1907,6 +1907,15 @@\n     </description>\n   </property>\n \n+  <property>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d28ee25d6adc25a9802badce75bca1705f41f055"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDczMzQyNQ==", "bodyText": "This is done in the latest changeset", "url": "https://github.com/apache/ozone/pull/1555#discussion_r550733425", "createdAt": "2021-01-01T05:28:20Z", "author": {"login": "mukul1987"}, "path": "hadoop-hdds/common/src/main/resources/ozone-default.xml", "diffHunk": "@@ -1907,6 +1907,15 @@\n     </description>\n   </property>\n \n+  <property>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjU2MDM3NQ=="}, "originalCommit": {"oid": "d28ee25d6adc25a9802badce75bca1705f41f055"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NzEwODAzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwODozNzo1OVrOH_tMrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwODozNzo1OVrOH_tMrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjU2Mjg2MA==", "bodyText": "I know it's committed in the previous commit, but can you please help me to understand why do we need FileSystem in OM side? As far as I understood the design doc has more cons against this approach.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r536562860", "createdAt": "2020-12-05T08:37:59Z", "author": {"login": "elek"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +128,23 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d28ee25d6adc25a9802badce75bca1705f41f055"}, "originalPosition": 64}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4695, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}