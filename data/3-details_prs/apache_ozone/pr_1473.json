{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk3NDYzMTc5", "number": 1473, "title": "HDDS-4266: CreateFile : store parent dir entries into DirTable and file entry into separate FileTable", "bodyText": "What changes were proposed in this pull request?\nhttps://issues.apache.org/jira/browse/HDDS-4266\nWhat is the link to the Apache JIRA\nThis task is to handle the createFileRequest. OM will store all the missing parent dirs to DirTable and leaf file node into a separate FileTable. This new FileTable and OpenFileTable is basically to segregate keys and files.\nHow was this patch tested?\nAdded UTs - TestOMFileCreateRequestV1, TestOMKeyCommitRequestV1, TestOzoneFileOps.", "createdAt": "2020-10-04T16:44:52Z", "url": "https://github.com/apache/ozone/pull/1473", "merged": true, "mergeCommit": {"oid": "61100d00cd14c832b2ec5d7aa4fd14c528b72aaa"}, "closed": true, "closedAt": "2020-10-13T17:18:36Z", "author": {"login": "rakeshadr"}, "timelineItems": {"totalCount": 30, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdPR7YqgH2gAyNDk3NDYzMTc5OjIzM2U0ODFlMTc3YmVjNzRhNWFhZDljN2M1Y2Y3MjYyZmZlYWQwMmE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdSL4YugFqTUwNzY2NjE0Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "233e481e177bec74a5aad9c7c5cf7262ffead02a", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/233e481e177bec74a5aad9c7c5cf7262ffead02a", "committedDate": "2020-10-04T16:39:21Z", "message": "HDDS-4266: CreateFile : store parent dir entries into DirTable and file entry into separate FileTable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21ef5e51d857ce2aa17cf26071ef0ee3f19dcb5b", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/21ef5e51d857ce2aa17cf26071ef0ee3f19dcb5b", "committedDate": "2020-10-05T03:57:02Z", "message": "Fixed checkstyle warnings and UT failures"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/c3ed678081f61b757c6f4181c16ad3fd45b3bb44", "committedDate": "2020-10-05T05:04:14Z", "message": "Fixed unit test failure - TestCleanupTableInfo"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNzcyMjAy", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-501772202", "createdAt": "2020-10-05T07:12:33Z", "commit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwNzoxMjozM1rOHcQAiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwNzo0NjoxMlrOHcQ_SQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NDQ1Nw==", "bodyText": "Why not add setFileName here?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499384457", "createdAt": "2020-10-05T07:12:33Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/helpers/OmKeyInfo.java", "diffHunk": "@@ -413,7 +461,8 @@ public KeyInfo getProtobuf(boolean ignorePipeline) {\n         .addAllMetadata(KeyValueUtil.toProtobuf(metadata))\n         .addAllAcls(OzoneAclUtil.toProtobuf(acls))\n         .setObjectID(objectID)\n-        .setUpdateID(updateID);\n+        .setUpdateID(updateID)\n+        .setParentID(parentObjectID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NTk5NQ==", "bodyText": "Not the change of current PR but was introduced in last PR of HDDS-2949.\n/**\n   * Given a volume, bucket and a key, return the corresponding DB prefixKey\n   * key.\n   *\n   * @param parentObjectId - parent object Id\n   * @param pathComponentName   - path component name\n   * @return DB directory key as String.\n   */\n  String getOzonePathKey(long parentObjectId, String pathComponentName);\nCan we update above comment? It's not correct.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499385995", "createdAt": "2020-10-05T07:16:04Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/interface-storage/src/main/java/org/apache/hadoop/ozone/om/OMMetadataManager.java", "diffHunk": "@@ -399,4 +399,15 @@ String getMultipartKey(String volume, String bucket, String key, String\n    * @return DB directory key as String.\n    */\n   String getOzonePathKey(long parentObjectId, String pathComponentName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NzYzMQ==", "bodyText": "Can we add openFileTable structure as well here?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499387631", "createdAt": "2020-10-05T07:19:56Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -129,6 +132,8 @@\n    * |----------------------------------------------------------------------|\n    * |  directoryTable    | parentId/directoryName -> DirectoryInfo         |\n    * |----------------------------------------------------------------------|\n+   * |  fileTable         | parentId/fileName -> FileInfo                   |\n+   * |----------------------------------------------------------------------|", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQwMDUyMQ==", "bodyText": "We could use  OmDirectoryInfo#getPath to simplified for this, there is already one method doing this.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499400521", "createdAt": "2020-10-05T07:46:12Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.file;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Response for create file request layout version1.\n+ */\n+public class OMFileCreateResponseV1 extends OMFileCreateResponse {\n+\n+  private List<OmDirectoryInfo> parentDirInfos;\n+\n+  public OMFileCreateResponseV1(@Nonnull OMResponse omResponse,\n+                                @Nonnull OmKeyInfo omKeyInfo,\n+                                @Nonnull List<OmDirectoryInfo> parentDirInfos,\n+                                long openKeySessionID,\n+                                @Nonnull OmVolumeArgs omVolumeArgs,\n+                                @Nonnull OmBucketInfo omBucketInfo) {\n+    super(omResponse, omKeyInfo, new ArrayList<>(), openKeySessionID,\n+        omVolumeArgs, omBucketInfo);\n+    this.parentDirInfos = parentDirInfos;\n+  }\n+\n+  @Override\n+  protected void addToDBBatch(OMMetadataManager omMetadataMgr,\n+                              BatchOperation batchOp) throws IOException {\n+\n+    /**\n+     * Create parent directory entries during Key Create - do not wait\n+     * for Key Commit request.\n+     * XXX handle stale directory entries.\n+     */\n+    if (parentDirInfos != null) {\n+      for (OmDirectoryInfo parentKeyInfo : parentDirInfos) {\n+        String parentKey = omMetadataMgr.getOzonePathKey(\n+                parentKeyInfo.getParentObjectID(), parentKeyInfo.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 64}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyMDE1OTg1", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-502015985", "createdAt": "2020-10-05T12:44:12Z", "commit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjo0NDoxM1rOHcbTnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzozNToyMFrOHcdWOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU2OTU2NQ==", "bodyText": "Nit: Remove this empty line.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499569565", "createdAt": "2020-10-05T12:44:13Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -346,6 +369,7 @@ protected static DBStoreBuilder addOMTablesAndCodecs(DBStoreBuilder builder) {\n         .addCodec(S3SecretValue.class, new S3SecretValueCodec())\n         .addCodec(OmPrefixInfo.class, new OmPrefixInfoCodec())\n         .addCodec(OmDirectoryInfo.class, new OmDirectoryInfoCodec())\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3NjUyOA==", "bodyText": "Can we rename method #getAllParentDirInfo to #getAllMissingParentDirInfo to make this more readable?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499576528", "createdAt": "2020-10-05T12:55:24Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos = OMDirectoryCreateRequestV1.getAllParentDirInfo(\n+              ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU4MzU1OQ==", "bodyText": "Can we use omMetadataManager.getOzonePathKey to construct db key name instead of?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499583559", "createdAt": "2020-10-05T13:06:26Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,259 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponse(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    switch (result) {\n+    case SUCCESS:\n+      // As when we commit the key, then it is visible in ozone, so we should\n+      // increment here.\n+      // As key also can have multiple versions, we need to increment keys\n+      // only if version is 0. Currently we have not complete support of\n+      // versioning of keys. So, this can be revisited later.\n+      if (omKeyInfo.getKeyLocationVersions().size() == 1) {\n+        omMetrics.incNumKeys();\n+      }\n+      LOG.debug(\"Key committed. Volume:{}, Bucket:{}, Key:{}\", volumeName,\n+              bucketName, keyName);\n+      break;\n+    case FAILURE:\n+      LOG.error(\"Key commit failed. Volume:{}, Bucket:{}, Key:{}. Exception:{}\",\n+              volumeName, bucketName, keyName, exception);\n+      omMetrics.incNumKeyCommitFails();\n+      break;\n+    default:\n+      LOG.error(\"Unrecognized Result for OMKeyCommitRequest: {}\",\n+              commitKeyRequest);\n+    }\n+\n+    return omClientResponse;\n+  }\n+\n+  /**\n+   * Get parent id for the user given path.\n+   *\n+   * @param bucketId          bucket id\n+   * @param pathComponents    fie path elements\n+   * @param keyName           user given key name\n+   * @param omMetadataManager metadata manager\n+   * @return lastKnownParentID\n+   * @throws IOException DB failure or parent not exists in DirectoryTable\n+   */\n+  private long getParentID(long bucketId, Iterator<Path> pathComponents,\n+                                        String keyName,\n+                                        OMMetadataManager omMetadataManager)\n+          throws IOException {\n+\n+    long lastKnownParentId = bucketId;\n+    boolean parentFound = true; // default bucketID as parent\n+    OmDirectoryInfo omDirectoryInfo = null;\n+    while (pathComponents.hasNext()) {\n+      String nodeName = pathComponents.next().toString();\n+      // Reached last component, which would be a file. Returns its parentID.\n+      if (!pathComponents.hasNext()) {\n+        return lastKnownParentId;\n+      }\n+      String dbNodeName = lastKnownParentId + \"/\" + nodeName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5MjU2Mg==", "bodyText": "For the cleanuptable annotation of OMKeyCommitResponseV1, we should remove OPEN_KEY_TABLE, KEY_TABLE I think. When OMKeyCommitResponseV1 is used, we should only use OPEN_FILE_TABLE, FILE_TABLE tables.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499592562", "createdAt": "2020-10-05T13:20:17Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyCommitResponseV1.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.key;\n+\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.*;\n+\n+/**\n+ * Response for CommitKey request layout version V1.\n+ */\n+@CleanupTableInfo(cleanupTables = {OPEN_KEY_TABLE, KEY_TABLE,\n+        OPEN_FILE_TABLE, FILE_TABLE})\n+public class OMKeyCommitResponseV1 extends OMKeyCommitResponse {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5NjU2NQ==", "bodyText": "Seems we lack of below logic compared with original OMFileCreateResponse logic.\n    // update volume usedBytes.\n    omMetadataManager.getVolumeTable().putWithBatch(batchOperation,\n        omMetadataManager.getVolumeKey(omVolumeArgs.getVolume()),\n        omVolumeArgs);\n    // update bucket usedBytes.\n    omMetadataManager.getBucketTable().putWithBatch(batchOperation,\n        omMetadataManager.getBucketKey(omVolumeArgs.getVolume(),\n            omBucketInfo.getBucketName()), omBucketInfo);", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499596565", "createdAt": "2020-10-05T13:26:07Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.file;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Response for create file request layout version1.\n+ */\n+public class OMFileCreateResponseV1 extends OMFileCreateResponse {\n+\n+  private List<OmDirectoryInfo> parentDirInfos;\n+\n+  public OMFileCreateResponseV1(@Nonnull OMResponse omResponse,\n+                                @Nonnull OmKeyInfo omKeyInfo,\n+                                @Nonnull List<OmDirectoryInfo> parentDirInfos,\n+                                long openKeySessionID,\n+                                @Nonnull OmVolumeArgs omVolumeArgs,\n+                                @Nonnull OmBucketInfo omBucketInfo) {\n+    super(omResponse, omKeyInfo, new ArrayList<>(), openKeySessionID,\n+        omVolumeArgs, omBucketInfo);\n+    this.parentDirInfos = parentDirInfos;\n+  }\n+\n+  @Override\n+  protected void addToDBBatch(OMMetadataManager omMetadataMgr,\n+                              BatchOperation batchOp) throws IOException {\n+\n+    /**\n+     * Create parent directory entries during Key Create - do not wait\n+     * for Key Commit request.\n+     * XXX handle stale directory entries.\n+     */\n+    if (parentDirInfos != null) {\n+      for (OmDirectoryInfo parentKeyInfo : parentDirInfos) {\n+        String parentKey = omMetadataMgr.getOzonePathKey(\n+                parentKeyInfo.getParentObjectID(), parentKeyInfo.getName());\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"putWithBatch adding parent : key {} info : {}\", parentKey,\n+                  parentKeyInfo);\n+        }\n+        omMetadataMgr.getDirectoryTable().putWithBatch(batchOp, parentKey,\n+                parentKeyInfo);\n+      }\n+    }\n+\n+    String openKey = omMetadataMgr.getOpenFileName(\n+            getOmKeyInfo().getParentObjectID(), getOmKeyInfo().getFileName(),\n+            getOpenKeySessionID());\n+    omMetadataMgr.getOpenKeyTable().putWithBatch(batchOp, openKey,\n+            getOmKeyInfo());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYwMzAwMw==", "bodyText": "We should add annotation for cleanup table.\n@CleanupTableInfo(cleanupTables = OPEN_FILE_TABLE)", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499603003", "createdAt": "2020-10-05T13:35:20Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.file;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Response for create file request layout version1.\n+ */\n+public class OMFileCreateResponseV1 extends OMFileCreateResponse {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyMDcwNjg3", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-502070687", "createdAt": "2020-10-05T13:44:39Z", "commit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzo0NDozOVrOHcdvOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNDowNzoxNFrOHcetcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYwOTQwMw==", "bodyText": "Wrong log instance name used.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499609403", "createdAt": "2020-10-05T13:44:39Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.\u2002\u2002See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.\u2002\u2002The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ *  with the License.\u2002\u2002You may obtain a copy of the License at\n+ *\n+ * \u2002\u2002\u2002\u2002 http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ozone;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.TestDataUtil;\n+import org.apache.hadoop.ozone.client.OzoneBucket;\n+import org.apache.hadoop.ozone.om.OMConfigKeys;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.util.StringUtils;\n+import org.junit.*;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_FS_ITERATE_BATCH_SIZE;\n+\n+/**\n+ * Test verifies the entries and operations in file table, open file table etc.\n+ */\n+public class TestOzoneFileOps {\n+\n+  @Rule\n+  public Timeout timeout = new Timeout(300000);\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(TestOzoneDirectory.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYxMjAzOQ==", "bodyText": "Remove this unused line.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499612039", "createdAt": "2020-10-05T13:48:26Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.\u2002\u2002See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.\u2002\u2002The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ *  with the License.\u2002\u2002You may obtain a copy of the License at\n+ *\n+ * \u2002\u2002\u2002\u2002 http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ozone;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.TestDataUtil;\n+import org.apache.hadoop.ozone.client.OzoneBucket;\n+import org.apache.hadoop.ozone.om.OMConfigKeys;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.util.StringUtils;\n+import org.junit.*;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_FS_ITERATE_BATCH_SIZE;\n+\n+/**\n+ * Test verifies the entries and operations in file table, open file table etc.\n+ */\n+public class TestOzoneFileOps {\n+\n+  @Rule\n+  public Timeout timeout = new Timeout(300000);\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(TestOzoneDirectory.class);\n+\n+  private MiniOzoneCluster cluster;\n+  private FileSystem fs;\n+  private String volumeName;\n+  private String bucketName;\n+\n+  @Before\n+  public void setupOzoneFileSystem()\n+          throws IOException, TimeoutException, InterruptedException {\n+    OzoneConfiguration conf = new OzoneConfiguration();\n+    conf.setInt(FS_TRASH_INTERVAL_KEY, 1);\n+    conf.set(OMConfigKeys.OZONE_OM_LAYOUT_VERSION, \"V1\");\n+    conf.setBoolean(OMConfigKeys.OZONE_OM_ENABLE_FILESYSTEM_PATHS, true);\n+    cluster = MiniOzoneCluster.newBuilder(conf)\n+            .setNumDatanodes(3)\n+            .build();\n+    cluster.waitForClusterToBeReady();\n+    // create a volume and a bucket to be used by OzoneFileSystem\n+    OzoneBucket bucket = TestDataUtil.createVolumeAndBucket(cluster);\n+    volumeName = bucket.getVolumeName();\n+    bucketName = bucket.getName();\n+\n+    String rootPath = String.format(\"%s://%s.%s/\",\n+            OzoneConsts.OZONE_URI_SCHEME, bucket.getName(),\n+            bucket.getVolumeName());\n+\n+    // Set the fs.defaultFS and start the filesystem\n+    conf.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY, rootPath);\n+    // Set the number of keys to be processed during batch operate.\n+    conf.setInt(OZONE_FS_ITERATE_BATCH_SIZE, 5);\n+    fs = FileSystem.get(conf);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    IOUtils.closeQuietly(fs);\n+    if (cluster != null) {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 300_000)\n+  public void testCreateFile() throws Exception {\n+    // Op 1. create dir -> /d1/d2/d3/d4/\n+    Path parent = new Path(\"/d1/d2/\");\n+    Path file = new Path(parent, \"file1\");\n+    fs.create(file);\n+    ArrayList<String> openFileKeys = new ArrayList<>();\n+\n+    OMMetadataManager omMgr = cluster.getOzoneManager().getMetadataManager();\n+    OmBucketInfo omBucketInfo = omMgr.getBucketTable().get(\n+            omMgr.getBucketKey(volumeName, bucketName));\n+    Assert.assertNotNull(\"Failed to find bucketInfo\", omBucketInfo);\n+\n+    ArrayList<String> dirKeys = new ArrayList<>();\n+    long d1ObjectID = verifyDirKey(omBucketInfo.getObjectID(), \"d1\", \"/d1\",\n+            dirKeys, omMgr);\n+    long d2ObjectID = verifyDirKey(d1ObjectID, \"d2\", \"/d1/d2\", dirKeys,\n+            omMgr);\n+    openFileKeys.add(d2ObjectID + OzoneConsts.OM_KEY_PREFIX + file.getName());\n+\n+    // verify entries in directory table\n+    TableIterator<String, ? extends\n+            Table.KeyValue<String, OmDirectoryInfo>> iterator =\n+            omMgr.getDirectoryTable().iterator();\n+    iterator.seekToFirst();\n+    int count = dirKeys.size();\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 2, count);\n+    while (iterator.hasNext()) {\n+      count--;\n+      Table.KeyValue<String, OmDirectoryInfo> value = iterator.next();\n+      verifyKeyFormat(value.getKey(), dirKeys);\n+    }\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 0, count);\n+\n+    // verify entries in directory table\n+    TableIterator<String, ? extends\n+            Table.KeyValue<String, OmKeyInfo>> keysItr =\n+            omMgr.getOpenKeyTable().iterator();\n+    keysItr.seekToFirst();\n+\n+    // Assert.assertEquals(\"Unexpected directory table entries!\", 2, count);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYxMjQzOQ==", "bodyText": "The comment should be 'verify entries in open key table'", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499612439", "createdAt": "2020-10-05T13:48:59Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.\u2002\u2002See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.\u2002\u2002The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ *  with the License.\u2002\u2002You may obtain a copy of the License at\n+ *\n+ * \u2002\u2002\u2002\u2002 http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ozone;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.TestDataUtil;\n+import org.apache.hadoop.ozone.client.OzoneBucket;\n+import org.apache.hadoop.ozone.om.OMConfigKeys;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.util.StringUtils;\n+import org.junit.*;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_FS_ITERATE_BATCH_SIZE;\n+\n+/**\n+ * Test verifies the entries and operations in file table, open file table etc.\n+ */\n+public class TestOzoneFileOps {\n+\n+  @Rule\n+  public Timeout timeout = new Timeout(300000);\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(TestOzoneDirectory.class);\n+\n+  private MiniOzoneCluster cluster;\n+  private FileSystem fs;\n+  private String volumeName;\n+  private String bucketName;\n+\n+  @Before\n+  public void setupOzoneFileSystem()\n+          throws IOException, TimeoutException, InterruptedException {\n+    OzoneConfiguration conf = new OzoneConfiguration();\n+    conf.setInt(FS_TRASH_INTERVAL_KEY, 1);\n+    conf.set(OMConfigKeys.OZONE_OM_LAYOUT_VERSION, \"V1\");\n+    conf.setBoolean(OMConfigKeys.OZONE_OM_ENABLE_FILESYSTEM_PATHS, true);\n+    cluster = MiniOzoneCluster.newBuilder(conf)\n+            .setNumDatanodes(3)\n+            .build();\n+    cluster.waitForClusterToBeReady();\n+    // create a volume and a bucket to be used by OzoneFileSystem\n+    OzoneBucket bucket = TestDataUtil.createVolumeAndBucket(cluster);\n+    volumeName = bucket.getVolumeName();\n+    bucketName = bucket.getName();\n+\n+    String rootPath = String.format(\"%s://%s.%s/\",\n+            OzoneConsts.OZONE_URI_SCHEME, bucket.getName(),\n+            bucket.getVolumeName());\n+\n+    // Set the fs.defaultFS and start the filesystem\n+    conf.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY, rootPath);\n+    // Set the number of keys to be processed during batch operate.\n+    conf.setInt(OZONE_FS_ITERATE_BATCH_SIZE, 5);\n+    fs = FileSystem.get(conf);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    IOUtils.closeQuietly(fs);\n+    if (cluster != null) {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 300_000)\n+  public void testCreateFile() throws Exception {\n+    // Op 1. create dir -> /d1/d2/d3/d4/\n+    Path parent = new Path(\"/d1/d2/\");\n+    Path file = new Path(parent, \"file1\");\n+    fs.create(file);\n+    ArrayList<String> openFileKeys = new ArrayList<>();\n+\n+    OMMetadataManager omMgr = cluster.getOzoneManager().getMetadataManager();\n+    OmBucketInfo omBucketInfo = omMgr.getBucketTable().get(\n+            omMgr.getBucketKey(volumeName, bucketName));\n+    Assert.assertNotNull(\"Failed to find bucketInfo\", omBucketInfo);\n+\n+    ArrayList<String> dirKeys = new ArrayList<>();\n+    long d1ObjectID = verifyDirKey(omBucketInfo.getObjectID(), \"d1\", \"/d1\",\n+            dirKeys, omMgr);\n+    long d2ObjectID = verifyDirKey(d1ObjectID, \"d2\", \"/d1/d2\", dirKeys,\n+            omMgr);\n+    openFileKeys.add(d2ObjectID + OzoneConsts.OM_KEY_PREFIX + file.getName());\n+\n+    // verify entries in directory table\n+    TableIterator<String, ? extends\n+            Table.KeyValue<String, OmDirectoryInfo>> iterator =\n+            omMgr.getDirectoryTable().iterator();\n+    iterator.seekToFirst();\n+    int count = dirKeys.size();\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 2, count);\n+    while (iterator.hasNext()) {\n+      count--;\n+      Table.KeyValue<String, OmDirectoryInfo> value = iterator.next();\n+      verifyKeyFormat(value.getKey(), dirKeys);\n+    }\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 0, count);\n+\n+    // verify entries in directory table", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYyNTMyOQ==", "bodyText": "Suppose here logic is same with TestOMFileCreateRequest.\nCan we fully reused the existed unit tests in TestOMFileCreateRequest?\nMaybe that we can extend TestOMFileCreateRequest and override ozone configuration we set for V1 version .", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499625329", "createdAt": "2020-10-05T14:07:14Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,456 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.request.TestOMRequestUtils;\n+import org.apache.hadoop.ozone.om.request.key.TestOMKeyRequestV1;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CreateFileRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.util.StringUtils;\n+import org.apache.hadoop.util.Time;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.util.List;\n+import java.util.UUID;\n+\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.VOLUME_NOT_FOUND;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.BUCKET_NOT_FOUND;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.FILE_ALREADY_EXISTS;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.NOT_A_FILE;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.DIRECTORY_NOT_FOUND;\n+\n+/**\n+ * Tests OMFileCreateRequest V1 layout version.\n+ */\n+public class TestOMFileCreateRequestV1 extends TestOMKeyRequestV1 {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyMDk2NTc1", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-502096575", "createdAt": "2020-10-05T14:11:01Z", "commit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNDoxMTowMVrOHce36w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNDoxMTowMVrOHce36w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYyODAxMQ==", "bodyText": "Similar comment above. Can we try to reuse the common logics here?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499628011", "createdAt": "2020-10-05T14:11:01Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/key/TestOMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFSUtils;\n+import org.apache.hadoop.ozone.om.request.TestOMRequestUtils;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CommitKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyLocation;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.util.Time;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Class tests OMKeyCommitRequestV1 class.\n+ */\n+public class TestOMKeyCommitRequestV1 extends TestOMKeyRequestV1 {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyNTQ3NTc2", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-502547576", "createdAt": "2020-10-06T02:48:07Z", "commit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMjo0ODowN1rOHc0IUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMzowMjozMFrOHc0V5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NjI3Mg==", "bodyText": "Can we also add a getPath method like that in OmDirectoryInfo? This can be conveniently used in other places.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499976272", "createdAt": "2020-10-06T02:48:07Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/helpers/OmKeyInfo.java", "diffHunk": "@@ -126,6 +144,23 @@ public void setDataSize(long size) {\n     this.dataSize = size;\n   }\n \n+  public void setFileName(String fileName) {\n+    this.fileName = fileName;\n+  }\n+\n+  public String getFileName() {\n+    return fileName;\n+  }\n+\n+  public void setParentObjectID(long parentObjectID) {\n+    this.parentObjectID = parentObjectID;\n+  }\n+\n+  public long getParentObjectID() {\n+    return parentObjectID;\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3OTc1MQ==", "bodyText": "We should additionally increase dir created metric since we created missing parent dirs.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499979751", "createdAt": "2020-10-06T03:02:30Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos = OMDirectoryCreateRequestV1.getAllParentDirInfo(\n+              ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 208}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f", "committedDate": "2020-10-06T17:18:23Z", "message": "Fixed code review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzNDE2MzM2", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-503416336", "createdAt": "2020-10-06T22:57:49Z", "commit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQyMjo1Nzo0OVrOHdcx6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQyMzozMzoxNVrOHddb5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0MjI4Mg==", "bodyText": "Why do we need to refresh here?\nBecause if override key, we add new blocks as the latest version, and use the latest blocks only.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500642282", "createdAt": "2020-10-06T22:57:49Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0MjU4Mw==", "bodyText": "Can we skip quota implementation, as it is incorrect. (I am fine with leaving if it needs rework, we can open another Jira to fix the issue for new classes also)\nFor more info refer this\nhttps://issues.apache.org/jira/browse/HDDS-4308", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500642583", "createdAt": "2020-10-06T22:58:44Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg==", "bodyText": "For file create requests even enableFSPaths is disabled still should create entries in openfileTable only right?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500649202", "createdAt": "2020-10-06T23:20:15Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA==", "bodyText": "Looks like in new version we don't need to store full keyName in OmKeyInfo, but we still store it, as OMKeyInfoCodec has still set Keyname and convert to proto.\n\n public KeyInfo getProtobuf(boolean ignorePipeline) {\n    long latestVersion = keyLocationVersions.size() == 0 ? -1 :\n        keyLocationVersions.get(keyLocationVersions.size() - 1).getVersion();\n\n    List<KeyLocationList> keyLocations = new ArrayList<>();\n    for (OmKeyLocationInfoGroup locationInfoGroup : keyLocationVersions) {\n      keyLocations.add(locationInfoGroup.getProtobuf(ignorePipeline));\n    }\n\n    KeyInfo.Builder kb = KeyInfo.newBuilder()\n        .setVolumeName(volumeName)\n        .setBucketName(bucketName)\n        .setKeyName(keyName)", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500652488", "createdAt": "2020-10-06T23:31:32Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MzAzMQ==", "bodyText": "Why can't we use keyName as leaf node name for new requests, so that we don't need to store full pathName for OmKeyInfo for new request processing.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500653031", "createdAt": "2020-10-06T23:33:15Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzNDUzMDI2", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-503453026", "createdAt": "2020-10-07T00:46:21Z", "commit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo0NjoyMlrOHdevTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo0NjoyMlrOHdevTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NDM4MQ==", "bodyText": "checkDirectoryAlreadyExists check is missing which is added by HDDS-4155", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500674381", "createdAt": "2020-10-07T00:46:22Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 131}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzNDUzNjcx", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-503453671", "createdAt": "2020-10-07T00:48:41Z", "commit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo0ODo0MVrOHdexew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo0ODo0MVrOHdexew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NDkzOQ==", "bodyText": "acquireLock -> acquireWriteLock. The old method is deprecated.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500674939", "createdAt": "2020-10-07T00:48:41Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 118}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzNDU1MTA3", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-503455107", "createdAt": "2020-10-07T00:53:38Z", "commit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo1MzozOVrOHde2aA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo1MzozOVrOHde2aA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NjIwMA==", "bodyText": "Can we move this to a common method, and call the new method from both old version and this new version.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500676200", "createdAt": "2020-10-07T00:53:39Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponse(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    switch (result) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 191}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzNDU1NTE1", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-503455515", "createdAt": "2020-10-07T00:55:06Z", "commit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo1NTowNlrOHde35w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo1NTowNlrOHde35w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NjU4Mw==", "bodyText": "OMKeyCommitResponse -> OMKeyCommitResponseV1", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500676583", "createdAt": "2020-10-07T00:55:06Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponse(omResponse.build(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 169}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzNDU2MzE5", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-503456319", "createdAt": "2020-10-07T00:58:02Z", "commit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo1ODowMlrOHde6vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo1ODowMlrOHde6vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NzMxMQ==", "bodyText": "These 3 are set, not used anywhere.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500677311", "createdAt": "2020-10-07T00:58:02Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyCommitResponseV1.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.key;\n+\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.*;\n+\n+/**\n+ * Response for CommitKey request layout version V1.\n+ */\n+@CleanupTableInfo(cleanupTables = {OPEN_FILE_TABLE, FILE_TABLE})\n+public class OMKeyCommitResponseV1 extends OMKeyCommitResponse {\n+\n+  private OmKeyInfo omKeyInfo;\n+  private String ozoneKeyName;\n+  private String openKeyName;\n+\n+  public OMKeyCommitResponseV1(@Nonnull OMResponse omResponse,\n+                               @Nonnull OmKeyInfo omKeyInfo,\n+                               String ozoneKeyName, String openKeyName,\n+                               @Nonnull OmVolumeArgs omVolumeArgs,\n+                               @Nonnull OmBucketInfo omBucketInfo) {\n+    super(omResponse, omKeyInfo, ozoneKeyName, openKeyName, omVolumeArgs,\n+            omBucketInfo);\n+    this.omKeyInfo = omKeyInfo;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzNTc3ODIy", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-503577822", "createdAt": "2020-10-07T07:02:39Z", "commit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwNzowNjowM1rOHdlWdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwNzozMTowNlrOHdmJHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDc4MjcwOA==", "bodyText": "openFileTable should have additional id after parentId/fileName and fileTable key should be parentId/fileName.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500782708", "createdAt": "2020-10-07T07:06:03Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -129,6 +132,10 @@\n    * |----------------------------------------------------------------------|\n    * |  directoryTable    | parentId/directoryName -> DirectoryInfo         |\n    * |----------------------------------------------------------------------|\n+   * |  fileTable         | parentId/fileName/id -> FileInfo                |\n+   * |----------------------------------------------------------------------|\n+   * |  openFileTable     | parentId/fileName -> FileInfo                   |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDc5NTY3Ng==", "bodyText": "assertNotNull check can be removed as we already check this in verifyPathInOpenKeyTable.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500795676", "createdAt": "2020-10-07T07:31:06Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMFileCreateRequest.java", "diffHunk": "@@ -146,7 +141,7 @@ public void testValidateAndUpdateCache() throws Exception {\n \n     // Check open table whether key is added or not.\n \n-    omKeyInfo = omMetadataManager.getOpenKeyTable().get(openKey);\n+    omKeyInfo = verifyPathInOpenKeyTable(keyName, id, true);\n     Assert.assertNotNull(omKeyInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 59}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64975e250744839bf58a002a53abef4f9034b671", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/64975e250744839bf58a002a53abef4f9034b671", "committedDate": "2020-10-07T11:04:47Z", "message": "Fixed code review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAzODM2NzUz", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-503836753", "createdAt": "2020-10-07T12:44:07Z", "commit": {"oid": "64975e250744839bf58a002a53abef4f9034b671"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMjo0NDowOFrOHdxdAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMjo0NDowOFrOHdxdAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDk4MDk5Mw==", "bodyText": "Seems we forget to reuse processResult in OMKeyCommitRequest.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500980993", "createdAt": "2020-10-07T12:44:08Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequest.java", "diffHunk": "@@ -253,4 +253,33 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n \n     return omClientResponse;\n   }\n+\n+  protected void processResult(CommitKeyRequest commitKeyRequest,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64975e250744839bf58a002a53abef4f9034b671"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d7d11ae794666030920067ea7e7f32eb0ba968d", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/3d7d11ae794666030920067ea7e7f32eb0ba968d", "committedDate": "2020-10-07T13:39:14Z", "message": "Fixed checkstyle warnings and review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0MzkwNTU2", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-504390556", "createdAt": "2020-10-08T02:39:20Z", "commit": {"oid": "3d7d11ae794666030920067ea7e7f32eb0ba968d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwMjozOToyMFrOHeL8dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwMjozOToyMFrOHeL8dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQxNTAzMQ==", "bodyText": "protected boolean checkDirectoryAlreadyExists(String volumeName,\n      String bucketName, String keyName, OMMetadataManager omMetadataManager)\n      throws IOException {\n    if (omMetadataManager.getKeyTable().isExist(\n        omMetadataManager.getOzoneDirKey(volumeName, bucketName,\n            keyName))) {\n      return true;\n    }\n    return false;\n  }\nOriginal logic(OMKeyRequest#checkDirectoryAlreadyExists) is to check if there is the same name dir key already stored in key table.\nFor here,  the logic is that we should use new file key to check if that existed in file table, not check the dir table.\ncheckDirectoryAlreadyExists will always throw OMException error once OzoneFileSystem enabled under above logic, because parents dir is already created during File create request.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501415031", "createdAt": "2020-10-08T02:39:20Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFSUtils;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CommitKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyLocation;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.NOT_A_FILE;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request layout version V1.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager, ozoneManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponseV1(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    processResult(commitKeyRequest, volumeName, bucketName, keyName, omMetrics,\n+            exception, omKeyInfo, result);\n+\n+    return omClientResponse;\n+  }\n+\n+\n+  /**\n+   * Check for directory exists with same name, if it exists throw error.\n+   *\n+   * @param keyName                  key name\n+   * @param ozoneManager             Ozone Manager\n+   * @param reachedLastPathComponent true if the path component is a fileName\n+   * @throws IOException if directory exists with same name\n+   */\n+  private void checkDirectoryAlreadyExists(String keyName,\n+                                           OzoneManager ozoneManager,\n+                                           boolean reachedLastPathComponent)\n+          throws IOException {\n+    // Reached last component, which would be a file. Returns its parentID.\n+    if (reachedLastPathComponent && ozoneManager.getEnableFileSystemPaths()) {\n+      throw new OMException(\"Can not create file: \" + keyName +\n+              \" as there is already directory in the given path\", NOT_A_FILE);\n+    }\n+  }\n+\n+  /**\n+   * Get parent id for the user given path.\n+   *\n+   * @param bucketId          bucket id\n+   * @param pathComponents    fie path elements\n+   * @param keyName           user given key name\n+   * @param omMetadataManager metadata manager\n+   * @return lastKnownParentID\n+   * @throws IOException DB failure or parent not exists in DirectoryTable\n+   */\n+  private long getParentID(long bucketId, Iterator<Path> pathComponents,\n+                           String keyName, OMMetadataManager omMetadataManager,\n+                           OzoneManager ozoneManager)\n+          throws IOException {\n+\n+    long lastKnownParentId = bucketId;\n+\n+    // If no sub-dirs then bucketID is the root/parent.\n+    if(!pathComponents.hasNext()){\n+      return bucketId;\n+    }\n+\n+    OmDirectoryInfo omDirectoryInfo;\n+    while (pathComponents.hasNext()) {\n+      String nodeName = pathComponents.next().toString();\n+      boolean reachedLastPathComponent = !pathComponents.hasNext();\n+      String dbNodeName =\n+              omMetadataManager.getOzonePathKey(lastKnownParentId, nodeName);\n+\n+      omDirectoryInfo = omMetadataManager.\n+              getDirectoryTable().get(dbNodeName);\n+      if (omDirectoryInfo != null) {\n+        checkDirectoryAlreadyExists(keyName, ozoneManager,\n+                reachedLastPathComponent);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d7d11ae794666030920067ea7e7f32eb0ba968d"}, "originalPosition": 259}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b0c589b838e210096ec3b7e6cba6206dabdb92ca", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/b0c589b838e210096ec3b7e6cba6206dabdb92ca", "committedDate": "2020-10-08T11:26:22Z", "message": "Fixed review comment - store fileName into keyName field in DB"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e99c056dfb3378b6f3baed010b6effc7e2362b0", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/7e99c056dfb3378b6f3baed010b6effc7e2362b0", "committedDate": "2020-10-08T13:54:47Z", "message": "Fixed UT failure - TestOzoneDirector#verifyDirKey"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d41f95fb47dca706d588bdb304297da10098941", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/0d41f95fb47dca706d588bdb304297da10098941", "committedDate": "2020-10-09T11:07:13Z", "message": "Fixed review comment - Removed enableFSPaths flag dependency during Dir,File Create & Commit ops"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a190b3de213d1665129ae2fc0f7c6907b7e9d325", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/a190b3de213d1665129ae2fc0f7c6907b7e9d325", "committedDate": "2020-10-09T12:30:00Z", "message": "Fixed TestOmMetadataManager test failure - modified 'omLayoutVersionV1' default value to false"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2MDEzNzcz", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-506013773", "createdAt": "2020-10-09T22:14:57Z", "commit": {"oid": "a190b3de213d1665129ae2fc0f7c6907b7e9d325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQyMjoxNDo1OFrOHfZyMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQyMjoxNDo1OFrOHfZyMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjY5MDM1NQ==", "bodyText": "Looks for every key commit now we do 2 times copy once to get from the table and here.\nI understand the reason.\nNothing needs to be done here, just mentioning the difference between the original request and V1.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502690355", "createdAt": "2020-10-09T22:14:58Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -453,4 +456,145 @@ public static void addDirectoryTableCacheEntries(\n     }\n   }\n \n+  /**\n+   * Adding Key info to the openFile Table cache.\n+   *\n+   * @param omMetadataManager OM Metadata Manager\n+   * @param dbOpenFileName    open file name key\n+   * @param omFileInfo        key info\n+   * @param fileName          file name\n+   * @param trxnLogIndex      transaction log index\n+   */\n+  public static void addOpenFileTableCacheEntry(\n+          OMMetadataManager omMetadataManager, String dbOpenFileName,\n+          @Nullable OmKeyInfo omFileInfo, String fileName, long trxnLogIndex) {\n+\n+    Optional<OmKeyInfo> keyInfoOptional = Optional.absent();\n+    if (omFileInfo != null) {\n+      // New key format for the openFileTable.\n+      // For example, the user given key path is '/a/b/c/d/e/file1', then in DB\n+      // keyName field stores only the leaf node name, which is 'file1'.\n+      OmKeyInfo dbOmFileInfo = omFileInfo.copyObject();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a190b3de213d1665129ae2fc0f7c6907b7e9d325"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2MDkwMzA4", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-506090308", "createdAt": "2020-10-10T11:25:31Z", "commit": {"oid": "a190b3de213d1665129ae2fc0f7c6907b7e9d325"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a36513af35216cc32693c1207a4dea6c083a77de", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/a36513af35216cc32693c1207a4dea6c083a77de", "committedDate": "2020-10-13T02:14:36Z", "message": "Fixed review comment: pass modified OmKeyInfo with fileName as keyName to Response class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f22f1d491381af3e9bc9ffa84a8218b9f06a5fb", "author": {"user": {"login": "rakeshadr", "name": "Rakesh Radhakrishnan"}}, "url": "https://github.com/apache/ozone/commit/1f22f1d491381af3e9bc9ffa84a8218b9f06a5fb", "committedDate": "2020-10-13T13:36:02Z", "message": "Fixed review comment: Removed additional copyObject of OmKeyInfo"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA3NjY1NTI5", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-507665529", "createdAt": "2020-10-13T17:17:32Z", "commit": {"oid": "1f22f1d491381af3e9bc9ffa84a8218b9f06a5fb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzoxNzozM1rOHgxelA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzoxNzozM1rOHgxelA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEyNzEyNA==", "bodyText": "Minor: There is no return from this method.\nCan be fixed in further jiras.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r504127124", "createdAt": "2020-10-13T17:17:33Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -466,27 +465,22 @@ public static void addDirectoryTableCacheEntries(\n    * @param trxnLogIndex      transaction log index\n    * @return dbOmFileInfo, which keeps leaf node name in keyName field", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f22f1d491381af3e9bc9ffa84a8218b9f06a5fb"}, "originalPosition": 10}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA3NjY2MTQ2", "url": "https://github.com/apache/ozone/pull/1473#pullrequestreview-507666146", "createdAt": "2020-10-13T17:18:25Z", "commit": {"oid": "1f22f1d491381af3e9bc9ffa84a8218b9f06a5fb"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2331, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}