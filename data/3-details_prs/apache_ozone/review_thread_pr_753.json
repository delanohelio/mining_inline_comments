{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk3Mzg2ODAy", "number": 753, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNDo0NDo1MFrODt_Ksw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODoxMzo1NFrODuEqig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NTQ3NDQzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon-codegen/src/main/java/org/hadoop/ozone/recon/schema/ContainerSchemaDefinition.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNDo0NDo1MFrOF_uuSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNDo0NDo1MFrOF_uuSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjM3MDEyMQ==", "bodyText": "I believe DSLContext is shared across tables. We may be able to inject this. But, I am OK with having the getter inside just this schema definition.", "url": "https://github.com/apache/ozone/pull/753#discussion_r402370121", "createdAt": "2020-04-02T14:44:50Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon-codegen/src/main/java/org/hadoop/ozone/recon/schema/ContainerSchemaDefinition.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.hadoop.ozone.recon.schema;\n+\n+import com.google.inject.Inject;\n+import com.google.inject.Singleton;\n+import org.jooq.DSLContext;\n+import org.jooq.impl.DSL;\n+import org.jooq.impl.SQLDataType;\n+\n+import javax.sql.DataSource;\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+\n+/**\n+ * Class used to create tables that are required for tracking containers.\n+ */\n+@Singleton\n+public class ContainerSchemaDefinition implements ReconSchemaDefinition {\n+\n+  public static final String CONTAINER_HISTORY_TABLE_NAME =\n+      \"container_history\";\n+  public static final String MISSING_CONTAINERS_TABLE_NAME =\n+      \"missing_containers\";\n+  private static final String CONTAINER_ID = \"container_id\";\n+  private final DataSource dataSource;\n+  private DSLContext dslContext;\n+\n+  @Inject\n+  ContainerSchemaDefinition(DataSource dataSource) {\n+    this.dataSource = dataSource;\n+  }\n+\n+  @Override\n+  public void initializeSchema() throws SQLException {\n+    Connection conn = dataSource.getConnection();\n+    dslContext = DSL.using(conn);\n+    createContainerHistoryTable();\n+    createMissingContainersTable();\n+  }\n+\n+  /**\n+   * Create the Container History table.\n+   */\n+  private void createContainerHistoryTable() {\n+    dslContext.createTableIfNotExists(CONTAINER_HISTORY_TABLE_NAME)\n+        .column(CONTAINER_ID, SQLDataType.BIGINT)\n+        .column(\"datanode_host\", SQLDataType.VARCHAR(1024))\n+        .column(\"first_report_timestamp\", SQLDataType.BIGINT)\n+        .column(\"last_report_timestamp\", SQLDataType.BIGINT)\n+        .constraint(DSL.constraint(\"pk_container_id_datanode_host\")\n+            .primaryKey(CONTAINER_ID, \"datanode_host\"))\n+        .execute();\n+  }\n+\n+  /**\n+   * Create the Missing Containers table.\n+   */\n+  private void createMissingContainersTable() {\n+    dslContext.createTableIfNotExists(MISSING_CONTAINERS_TABLE_NAME)\n+        .column(CONTAINER_ID, SQLDataType.BIGINT)\n+        .column(\"missing_since\", SQLDataType.BIGINT)\n+        .constraint(DSL.constraint(\"pk_container_id\")\n+            .primaryKey(CONTAINER_ID))\n+        .execute();\n+  }\n+\n+  public DSLContext getDSLContext() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9f9c53935d4551a386d730293cfbb6a998d2ee9"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NjI5MDI4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/fsck/TestMissingContainerTask.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNzo1MDozOVrOF_2yew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNzo1MDozOVrOF_2yew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUwMjI2Nw==", "bodyText": "Instead of initializing a schema definition as and when needed in tests, we can create a test harness that creates a test sql DB, and provides access to any DAO that the test may need. This will remove the need for a unit test to know what DAO is needed somewhere deep inside the flow, and the code will be much cleaner. Of course, this will be a different JIRA work item.", "url": "https://github.com/apache/ozone/pull/753#discussion_r402502267", "createdAt": "2020-04-02T17:50:39Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/fsck/TestMissingContainerTask.java", "diffHunk": "@@ -58,10 +60,16 @@ public void testRun() throws Exception {\n         ReconTaskSchemaDefinition.class);\n     taskSchemaDefinition.initializeSchema();\n \n-    UtilizationSchemaDefinition schemaDefinition =\n-        getInjector().getInstance(UtilizationSchemaDefinition.class);\n+    ContainerSchemaDefinition schemaDefinition =\n+        getInjector().getInstance(ContainerSchemaDefinition.class);\n     schemaDefinition.initializeSchema();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9f9c53935d4551a386d730293cfbb6a998d2ee9"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NjMzNjc3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/persistence/ContainerSchemaManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODowMzowN1rOF_3QEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODowMzowN1rOF_3QEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUwOTg0MQ==", "bodyText": "Here we are doing 2 lookups - first 'existsById' and then 'findById'. Can we refactor this by doing only one lookup instead?", "url": "https://github.com/apache/ozone/pull/753#discussion_r402509841", "createdAt": "2020-04-02T18:03:07Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/persistence/ContainerSchemaManager.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.persistence;\n+\n+import static org.hadoop.ozone.recon.schema.tables.ContainerHistoryTable.CONTAINER_HISTORY;\n+\n+import com.google.inject.Inject;\n+import com.google.inject.Singleton;\n+import org.hadoop.ozone.recon.schema.ContainerSchemaDefinition;\n+import org.hadoop.ozone.recon.schema.tables.daos.ContainerHistoryDao;\n+import org.hadoop.ozone.recon.schema.tables.daos.MissingContainersDao;\n+import org.hadoop.ozone.recon.schema.tables.pojos.ContainerHistory;\n+import org.hadoop.ozone.recon.schema.tables.pojos.MissingContainers;\n+import org.jooq.DSLContext;\n+import org.jooq.Record2;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Provide a high level API to access the Container Schema.\n+ */\n+@Singleton\n+public class ContainerSchemaManager {\n+  private ContainerHistoryDao containerHistoryDao;\n+  private MissingContainersDao missingContainersDao;\n+  private ContainerSchemaDefinition containerSchemaDefinition;\n+\n+  @Inject\n+  public ContainerSchemaManager(ContainerHistoryDao containerHistoryDao,\n+              ContainerSchemaDefinition containerSchemaDefinition,\n+              MissingContainersDao missingContainersDao) {\n+    this.containerHistoryDao = containerHistoryDao;\n+    this.missingContainersDao = missingContainersDao;\n+    this.containerSchemaDefinition = containerSchemaDefinition;\n+  }\n+\n+  public void addMissingContainer(long containerID, long time) {\n+    MissingContainers record = new MissingContainers(containerID, time);\n+    missingContainersDao.insert(record);\n+  }\n+\n+  public List<MissingContainers> getAllMissingContainers() {\n+    return missingContainersDao.findAll();\n+  }\n+\n+  public boolean isMissingContainer(long containerID) {\n+    return missingContainersDao.existsById(containerID);\n+  }\n+\n+  public void deleteMissingContainer(long containerID) {\n+    missingContainersDao.deleteById(containerID);\n+  }\n+\n+  public void upsertContainerHistory(long containerID, String datanode,\n+                                     long time) {\n+    DSLContext ctx = containerSchemaDefinition.getDSLContext();\n+    Record2<Long, String> record =\n+        ctx.newRecord(\n+        CONTAINER_HISTORY.CONTAINER_ID,\n+        CONTAINER_HISTORY.DATANODE_HOST).value1(containerID).value2(datanode);\n+    ContainerHistory newRecord = new ContainerHistory();\n+    newRecord.setContainerId(containerID);\n+    newRecord.setDatanodeHost(datanode);\n+    newRecord.setLastReportTimestamp(time);\n+    if (containerHistoryDao.existsById(record)) {\n+      newRecord.setFirstReportTimestamp(\n+          containerHistoryDao.findById(record).getFirstReportTimestamp()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d387f2e7b40a89d8f4e4c54184ae1cb20585718e"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5NjM3NTE0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/persistence/ContainerSchemaManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODoxMzo1NFrOF_3oSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODoxMzo1NFrOF_3oSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUxNjA0Mw==", "bodyText": "Can we try and use ORDER BY and LIMIT on the DB side (using SELECT API maybe) instead of client side sorting and filtering?", "url": "https://github.com/apache/ozone/pull/753#discussion_r402516043", "createdAt": "2020-04-02T18:13:54Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/persistence/ContainerSchemaManager.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.persistence;\n+\n+import static org.hadoop.ozone.recon.schema.tables.ContainerHistoryTable.CONTAINER_HISTORY;\n+\n+import com.google.inject.Inject;\n+import com.google.inject.Singleton;\n+import org.hadoop.ozone.recon.schema.ContainerSchemaDefinition;\n+import org.hadoop.ozone.recon.schema.tables.daos.ContainerHistoryDao;\n+import org.hadoop.ozone.recon.schema.tables.daos.MissingContainersDao;\n+import org.hadoop.ozone.recon.schema.tables.pojos.ContainerHistory;\n+import org.hadoop.ozone.recon.schema.tables.pojos.MissingContainers;\n+import org.jooq.DSLContext;\n+import org.jooq.Record2;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Provide a high level API to access the Container Schema.\n+ */\n+@Singleton\n+public class ContainerSchemaManager {\n+  private ContainerHistoryDao containerHistoryDao;\n+  private MissingContainersDao missingContainersDao;\n+  private ContainerSchemaDefinition containerSchemaDefinition;\n+\n+  @Inject\n+  public ContainerSchemaManager(ContainerHistoryDao containerHistoryDao,\n+              ContainerSchemaDefinition containerSchemaDefinition,\n+              MissingContainersDao missingContainersDao) {\n+    this.containerHistoryDao = containerHistoryDao;\n+    this.missingContainersDao = missingContainersDao;\n+    this.containerSchemaDefinition = containerSchemaDefinition;\n+  }\n+\n+  public void addMissingContainer(long containerID, long time) {\n+    MissingContainers record = new MissingContainers(containerID, time);\n+    missingContainersDao.insert(record);\n+  }\n+\n+  public List<MissingContainers> getAllMissingContainers() {\n+    return missingContainersDao.findAll();\n+  }\n+\n+  public boolean isMissingContainer(long containerID) {\n+    return missingContainersDao.existsById(containerID);\n+  }\n+\n+  public void deleteMissingContainer(long containerID) {\n+    missingContainersDao.deleteById(containerID);\n+  }\n+\n+  public void upsertContainerHistory(long containerID, String datanode,\n+                                     long time) {\n+    DSLContext ctx = containerSchemaDefinition.getDSLContext();\n+    Record2<Long, String> record =\n+        ctx.newRecord(\n+        CONTAINER_HISTORY.CONTAINER_ID,\n+        CONTAINER_HISTORY.DATANODE_HOST).value1(containerID).value2(datanode);\n+    ContainerHistory newRecord = new ContainerHistory();\n+    newRecord.setContainerId(containerID);\n+    newRecord.setDatanodeHost(datanode);\n+    newRecord.setLastReportTimestamp(time);\n+    if (containerHistoryDao.existsById(record)) {\n+      newRecord.setFirstReportTimestamp(\n+          containerHistoryDao.findById(record).getFirstReportTimestamp()\n+      );\n+      containerHistoryDao.update(newRecord);\n+    } else {\n+      newRecord.setFirstReportTimestamp(time);\n+      containerHistoryDao.insert(newRecord);\n+    }\n+  }\n+\n+  public List<ContainerHistory> getAllContainerHistory(long containerID) {\n+    return containerHistoryDao.fetchByContainerId(containerID);\n+  }\n+\n+  public List<ContainerHistory> getLatestContainerHistory(long containerID,\n+                                                          int limit) {\n+    // Get container history sorted in descending order of timestamp\n+    List<ContainerHistory> containerHistory =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d387f2e7b40a89d8f4e4c54184ae1cb20585718e"}, "originalPosition": 98}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4438, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}