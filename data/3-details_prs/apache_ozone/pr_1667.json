{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMzNjc5MDE0", "number": 1667, "title": "HDDS-4525. Replace Hadoop variables and functions in Ozone shell scripts with Ozone-specific ones", "bodyText": "What changes were proposed in this pull request?\n\nReplace shell functions and variables that were originally copied from Hadoop.\n\nDeprecate HADOOP_* variables, but use their values, unless the corresponding OZONE_ variable is also defined (which indicates \"new code\").\nHADOOP_CONF_DIR is replaced by OZONE_CONFIG_DIR (instead of OZONE_CONF_DIR) to workaround a behavior envtoconf that cannot handle variables named *_CONF_*. (Root cause is fixed in HDDS-4601 instead.)\n\n\nDrop unmaintained Windows scripts\nDrop empty mapreduce, yarn etc. directories in final artifact, they are no longer necessary.\nFix wrong accumulation of return codes in start-ozone.sh: it was incremented for the first and third commands and unconditionally set for the second one, so the result of the first command was lost.  It should be set for the first one instead.\n\nhttps://issues.apache.org/jira/browse/HDDS-4525\nHow was this patch tested?\nAdded:\n\nBats test for the function that deprecates a variable\nacceptance test for compatibility with HDFS_OM_OPTS etc. variables\nacceptance tests for ozone classpath and ozone envvars commands\n\nChanged MR acceptance tests to globally define both HADOOP_CLASSPATH and OZONE_CLASSPATH.  This confirms that shaded Ozone FS jar being present in HADOOP_CLASSPATH does not break Ozone startup.  Previously HADOOP_CLASSPATH had to be limited to the Hadoop containers.\nRegular CI:\nhttps://github.com/adoroszlai/hadoop-ozone/actions/runs/405676505\nManually tested start-ozone.sh and stop-ozone.sh in ozonescripts environment (see HDDS-4556 for automating the smoketest).", "createdAt": "2020-12-07T13:43:36Z", "url": "https://github.com/apache/ozone/pull/1667", "merged": true, "mergeCommit": {"oid": "bc3e3e5f62a871c50f6261534424c67a53713d22"}, "closed": true, "closedAt": "2021-01-21T20:11:52Z", "author": {"login": "adoroszlai"}, "timelineItems": {"totalCount": 43, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdi4-YigH2gAyNTMzNjc5MDE0OjcxZWVlN2FiOWM0MmE4NzFiNmM2ODdhMmQwODA1Y2QxODEwZjUyNDE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdyXzHlAH2gAyNTMzNjc5MDE0OjQ2NGJmMGYzMmE5MjFhOTkyOGU3Nzg5ZDg1NzhmMDkyMjhkOTAyMGU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "71eee7ab9c42a871b6c687a2d0805cd1810f5241", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/71eee7ab9c42a871b6c687a2d0805cd1810f5241", "committedDate": "2020-12-04T14:53:29Z", "message": "HDDS-4525. Replace Hadoop variables and functions in Ozone shell scripts with Ozone-specific ones"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "52dcf871f10b3c7dee333e68cd2aa384592c9fc2", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/52dcf871f10b3c7dee333e68cd2aa384592c9fc2", "committedDate": "2020-12-05T07:09:17Z", "message": "Run envvars CLI test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71be10e91c297258231a3e42ed3c9bf9bde6898d", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/71be10e91c297258231a3e42ed3c9bf9bde6898d", "committedDate": "2020-12-06T17:24:29Z", "message": "Add test for ozone classpath"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b75cb364a56b3a13cc8ac84c4419a3946423e8a", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/4b75cb364a56b3a13cc8ac84c4419a3946423e8a", "committedDate": "2020-12-06T17:27:08Z", "message": "remove assertion about output"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6299ac0eebb537f93420d94be95916423c49f49c", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/6299ac0eebb537f93420d94be95916423c49f49c", "committedDate": "2020-12-06T18:01:24Z", "message": "set +e"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5341926a9df84ea8b9377deb96b0e4778faccd70", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/5341926a9df84ea8b9377deb96b0e4778faccd70", "committedDate": "2020-12-07T07:57:50Z", "message": "avoid deprecation warning in compose environments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2f14aec0aeb79a668408bc7104f3518561293f5", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/f2f14aec0aeb79a668408bc7104f3518561293f5", "committedDate": "2020-12-07T08:17:12Z", "message": "Fix classpath test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c2945537c2d514966e6f0d8dc52236b942b06a3", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/3c2945537c2d514966e6f0d8dc52236b942b06a3", "committedDate": "2020-12-07T09:24:24Z", "message": "allow creating files in dist/target"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "268ea6dc05b3e534e4e1f2b1ca7e7c1b9463fe40", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/268ea6dc05b3e534e4e1f2b1ca7e7c1b9463fe40", "committedDate": "2020-12-07T09:35:35Z", "message": "rename OZONE_CONF_DIR to OZONE_CONFIG_DIR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd662394ca66a0c23b8403f079b7321430bc3afa", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/bd662394ca66a0c23b8403f079b7321430bc3afa", "committedDate": "2020-12-07T10:17:58Z", "message": "fix perm"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fde59bf504d4f7d383adfd9399232e73c89b8bc", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/7fde59bf504d4f7d383adfd9399232e73c89b8bc", "committedDate": "2020-12-07T10:31:07Z", "message": "Revert \"allow creating files in dist/target\"\n\nThis reverts commit 3c2945537c2d514966e6f0d8dc52236b942b06a3."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "afa19d8f2b5a96e0989c3ec82b05f2dc74d54ad1", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/afa19d8f2b5a96e0989c3ec82b05f2dc74d54ad1", "committedDate": "2020-12-08T06:13:22Z", "message": "Add compatibility test for command-line options"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a820c60422974e2738c8c0e5200d444f4056cfb", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/3a820c60422974e2738c8c0e5200d444f4056cfb", "committedDate": "2020-12-08T07:35:56Z", "message": "trigger new CI check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8767d83ff0f365800df5733f5fbf97b0e59028d9", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/8767d83ff0f365800df5733f5fbf97b0e59028d9", "committedDate": "2020-12-08T13:36:34Z", "message": "trigger new CI check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d767e1bf9d87e78ab30c5e5c618f464aa1ee6b8f", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/d767e1bf9d87e78ab30c5e5c618f464aa1ee6b8f", "committedDate": "2020-12-10T12:04:27Z", "message": "trigger new CI check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/e54c4390bcc8374970baa120b6c6d9b5a375ff1d", "committedDate": "2020-12-12T11:51:47Z", "message": "Merge remote-tracking branch 'origin/master' into HDDS-4525"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwODUxODUx", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-550851851", "createdAt": "2020-12-12T18:30:39Z", "commit": {"oid": "d767e1bf9d87e78ab30c5e5c618f464aa1ee6b8f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMlQxODozMDozOVrOIEnjeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMlQxODozMDozOVrOIEnjeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTcxMzI3Mg==", "bodyText": "Should be OZONE_CONFIG_DIR? nvm", "url": "https://github.com/apache/ozone/pull/1667#discussion_r541713272", "createdAt": "2020-12-12T18:30:39Z", "author": {"login": "smengcl"}, "path": "hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/utils/db/DBConfigFromFile.java", "diffHunk": "@@ -65,7 +65,7 @@ public static File getConfigLocation() throws IOException {\n \n     if (StringUtil.isBlank(path)) {\n       LOG.debug(\"Unable to find the configuration directory. \"\n-          + \"Please make sure that HADOOP_CONF_DIR is setup correctly.\");\n+          + \"Please make sure that \" + CONFIG_DIR + \" is setup correctly.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d767e1bf9d87e78ab30c5e5c618f464aa1ee6b8f"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg4NTk1", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552088595", "createdAt": "2020-12-15T04:01:11Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMToxMVrOIF307g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMToxMVrOIF307g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODQ2Mg==", "bodyText": "start-dfs.sh is mentioned two times here, can you please rephrase this comment, and the next which mentions it to point to start-ozone.sh, and to mention Ozone roles?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028462", "createdAt": "2020-12-15T04:01:11Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 125}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg4NjQw", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552088640", "createdAt": "2020-12-15T04:01:22Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMToyMlrOIF31JA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMToyMlrOIF31JA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODUxNg==", "bodyText": "We should refer to Ozone roles here.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028516", "createdAt": "2020-12-15T04:01:22Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 184}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg4Njcw", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552088670", "createdAt": "2020-12-15T04:01:27Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMToyN1rOIF31TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMToyN1rOIF31TQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODU1Nw==", "bodyText": "We should refer ozone-functions.sh here.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028557", "createdAt": "2020-12-15T04:01:27Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)\n+# Java property: hadoop.security.logger\n+# export OZONE_SECURITY_LOGGER=INFO,NullAppender\n+\n+# Default process priority level\n+# Note that sub-processes will also run at this level!\n+# export OZONE_NICENESS=0\n+\n+# Default name for the service level authorization file\n+# Java property: hadoop.policy.file\n+# export OZONE_POLICYFILE=\"hadoop-policy.xml\"\n+\n+#\n+# NOTE: this is not used by default!  <-----\n+# You can define variables right here and then re-use them later on.\n+# For example, it is common to use the same garbage collection settings\n+# for all the daemons.  So one could define:\n+#\n+# export OZONE_GC_SETTINGS=\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"\n+#\n+# .. and then use it as per the b option under the namenode.\n+\n+###\n+# Secure/privileged execution\n+###\n+\n+#\n+# Out of the box, Ozone uses jsvc from Apache Commons to launch daemons\n+# on privileged ports.  This functionality can be replaced by providing\n+# custom functions.  See hadoop-functions.sh for more information.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 213}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg4NzEz", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552088713", "createdAt": "2020-12-15T04:01:34Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMTozNFrOIF31aQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMTozNFrOIF31aQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODU4NQ==", "bodyText": "It is maybe out of scope for this PR, but shouldn't we have OZONE_RECON_OPTS, and OZONE_S3GW_OPTS similarly?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028585", "createdAt": "2020-12-15T04:01:34Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)\n+# Java property: hadoop.security.logger\n+# export OZONE_SECURITY_LOGGER=INFO,NullAppender\n+\n+# Default process priority level\n+# Note that sub-processes will also run at this level!\n+# export OZONE_NICENESS=0\n+\n+# Default name for the service level authorization file\n+# Java property: hadoop.policy.file\n+# export OZONE_POLICYFILE=\"hadoop-policy.xml\"\n+\n+#\n+# NOTE: this is not used by default!  <-----\n+# You can define variables right here and then re-use them later on.\n+# For example, it is common to use the same garbage collection settings\n+# for all the daemons.  So one could define:\n+#\n+# export OZONE_GC_SETTINGS=\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"\n+#\n+# .. and then use it as per the b option under the namenode.\n+\n+###\n+# Secure/privileged execution\n+###\n+\n+#\n+# Out of the box, Ozone uses jsvc from Apache Commons to launch daemons\n+# on privileged ports.  This functionality can be replaced by providing\n+# custom functions.  See hadoop-functions.sh for more information.\n+#\n+\n+# The jsvc implementation to use. Jsvc is required to run secure datanodes\n+# that bind to privileged ports to provide authentication of data transfer\n+# protocol.  Jsvc is not required if SASL is configured for authentication of\n+# data transfer protocol using non-privileged ports.\n+# export JSVC_HOME=/usr/bin\n+\n+#\n+# This directory contains pids for secure and privileged processes.\n+#export OZONE_SECURE_PID_DIR=${OZONE_PID_DIR}\n+\n+#\n+# This directory contains the logs for secure and privileged processes.\n+# Java property: hadoop.log.dir\n+# export OZONE_SECURE_LOG=${OZONE_LOG_DIR}\n+\n+#\n+# When running a secure daemon, the default value of OZONE_IDENT_STRING\n+# ends up being a bit bogus.  Therefore, by default, the code will\n+# replace OZONE_IDENT_STRING with OZONE_xx_SECURE_USER.  If one wants\n+# to keep OZONE_IDENT_STRING untouched, then uncomment this line.\n+# export OZONE_SECURE_IDENT_PRESERVE=\"true\"\n+\n+###\n+# Ozone Manager specific parameters\n+###\n+# Specify the JVM options to be used when starting the Ozone Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_OM_OPTS=\"\"\n+\n+###\n+# Ozone DataNode specific parameters\n+###\n+# Specify the JVM options to be used when starting Ozone DataNodes.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_DATANODE_OPTS=\"\"\n+\n+###\n+# HDFS StorageContainerManager specific parameters\n+###\n+# Specify the JVM options to be used when starting the HDFS Storage Container Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_SCM_OPTS=\"\"\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 264}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg4Nzcx", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552088771", "createdAt": "2020-12-15T04:01:44Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMTo0NFrOIF31tA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMTo0NFrOIF31tA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODY2MA==", "bodyText": "Does this remain here on purpose?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028660", "createdAt": "2020-12-15T04:01:44Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)\n+# Java property: hadoop.security.logger\n+# export OZONE_SECURITY_LOGGER=INFO,NullAppender\n+\n+# Default process priority level\n+# Note that sub-processes will also run at this level!\n+# export OZONE_NICENESS=0\n+\n+# Default name for the service level authorization file\n+# Java property: hadoop.policy.file\n+# export OZONE_POLICYFILE=\"hadoop-policy.xml\"\n+\n+#\n+# NOTE: this is not used by default!  <-----\n+# You can define variables right here and then re-use them later on.\n+# For example, it is common to use the same garbage collection settings\n+# for all the daemons.  So one could define:\n+#\n+# export OZONE_GC_SETTINGS=\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"\n+#\n+# .. and then use it as per the b option under the namenode.\n+\n+###\n+# Secure/privileged execution\n+###\n+\n+#\n+# Out of the box, Ozone uses jsvc from Apache Commons to launch daemons\n+# on privileged ports.  This functionality can be replaced by providing\n+# custom functions.  See hadoop-functions.sh for more information.\n+#\n+\n+# The jsvc implementation to use. Jsvc is required to run secure datanodes\n+# that bind to privileged ports to provide authentication of data transfer\n+# protocol.  Jsvc is not required if SASL is configured for authentication of\n+# data transfer protocol using non-privileged ports.\n+# export JSVC_HOME=/usr/bin\n+\n+#\n+# This directory contains pids for secure and privileged processes.\n+#export OZONE_SECURE_PID_DIR=${OZONE_PID_DIR}\n+\n+#\n+# This directory contains the logs for secure and privileged processes.\n+# Java property: hadoop.log.dir\n+# export OZONE_SECURE_LOG=${OZONE_LOG_DIR}\n+\n+#\n+# When running a secure daemon, the default value of OZONE_IDENT_STRING\n+# ends up being a bit bogus.  Therefore, by default, the code will\n+# replace OZONE_IDENT_STRING with OZONE_xx_SECURE_USER.  If one wants\n+# to keep OZONE_IDENT_STRING untouched, then uncomment this line.\n+# export OZONE_SECURE_IDENT_PRESERVE=\"true\"\n+\n+###\n+# Ozone Manager specific parameters\n+###\n+# Specify the JVM options to be used when starting the Ozone Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_OM_OPTS=\"\"\n+\n+###\n+# Ozone DataNode specific parameters\n+###\n+# Specify the JVM options to be used when starting Ozone DataNodes.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_DATANODE_OPTS=\"\"\n+\n+###\n+# HDFS StorageContainerManager specific parameters\n+###\n+# Specify the JVM options to be used when starting the HDFS Storage Container Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_SCM_OPTS=\"\"\n+\n+###\n+# Advanced Users Only!\n+###\n+\n+#\n+# When building Ozone, one can add the class paths to the commands\n+# via this special env var:\n+# export OZONE_ENABLE_BUILD_PATHS=\"true\"\n+\n+#\n+# To prevent accidents, shell commands be (superficially) locked\n+# to only allow certain users to execute certain subcommands.\n+# It uses the format of (command)_(subcommand)_USER.\n+#\n+# For example, to limit who can execute the namenode command,\n+# export HDFS_NAMENODE_USER=hdfs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 280}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg4ODA1", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552088805", "createdAt": "2020-12-15T04:01:51Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMTo1MlrOIF312g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMTo1MlrOIF312g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODY5OA==", "bodyText": "We duplicate this if statement here, first to write a debug level log message second to return null, can we pull the two together, and also change the log message here, and state the reason why we fail by saying something like:\nCONFIG_DIR + \" variable is empty, please make sure it is setup correctly!\"", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028698", "createdAt": "2020-12-15T04:01:52Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/utils/db/DBConfigFromFile.java", "diffHunk": "@@ -65,7 +65,7 @@ public static File getConfigLocation() throws IOException {\n \n     if (StringUtil.isBlank(path)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg4ODQ4", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552088848", "createdAt": "2020-12-15T04:02:01Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjowMVrOIF318w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjowMVrOIF318w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODcyMw==", "bodyText": "For all these replacements, shouldn't we still provide ${OZONE_OPTS} to the environment as we did with HADOOP_OPTS before? We specify the coverage related options via this variable in test_all.sh for example.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028723", "createdAt": "2020-12-15T04:02:01Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-csi/docker-compose.yaml", "diffHunk": "@@ -24,7 +24,7 @@ services:\n     env_file:\n       - docker-config\n     environment:\n-      HADOOP_OPTS: ${HADOOP_OPTS}\n+      OZONE_OPTS:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg4OTA3", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552088907", "createdAt": "2020-12-15T04:02:11Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjoxMVrOIF32Jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjoxMVrOIF32Jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODc3NQ==", "bodyText": "Shouldn't we rename this envvar also to OZONE_OM_OPTS?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028775", "createdAt": "2020-12-15T04:02:11Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/main/smoketest/compatibility/om.robot", "diffHunk": "@@ -0,0 +1,27 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test om compatibility\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Test Timeout        5 minutes\n+\n+*** Test Cases ***\n+Picks up command line options\n+    Pass Execution If    '%{HDFS_OM_OPTS}' == ''    Command-line option required for process check", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg4OTQ4", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552088948", "createdAt": "2020-12-15T04:02:18Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjoxOFrOIF32kQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjoxOFrOIF32kQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODg4MQ==", "bodyText": "Should we rename this envvar also to OZONE_SCM_OPTS or OZONE_STORAGECONTAINERMANAGER_OPTS?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028881", "createdAt": "2020-12-15T04:02:18Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/main/smoketest/compatibility/scm.robot", "diffHunk": "@@ -0,0 +1,27 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test scm compatibility\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Test Timeout        5 minutes\n+\n+*** Test Cases ***\n+Picks up command line options\n+    Pass Execution If    '%{HDFS_STORAGECONTAINERMANAGER_OPTS}' == ''    Command-line option required for process check", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg5MDYz", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552089063", "createdAt": "2020-12-15T04:02:42Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjo0M1rOIF33CA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjo0M1rOIF33CA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyOTAwMA==", "bodyText": "This seems to be a strange one here...\nSo in line 45 if ozone_bootstrap is not declared, we error out because ozone-functions.sh could not be loaded.\nAs I understand here we check for the exit status of ozone_bootstrap function, and if it is false we exit because we can not find ozone-config.sh. Why we need this second check? As I see the ozone_bootstrap function is not doing anything that should fail, but maybe my eye slipped through something.\nThis same we do in hadoop-ozone/dist/src/shell/ozone/ozone, in hadoop-ozone/dist/src/shell/ozone/start-ozone.sh and in hadoop-ozone/dist/src/shell/ozone/stop-ozone.sh files as well", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543029000", "createdAt": "2020-12-15T04:02:43Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/shell/hdds/workers.sh", "diffHunk": "@@ -20,40 +20,43 @@\n #\n # Environment Variables\n #\n-#   HADOOP_WORKERS    File naming remote hosts.\n-#     Default is ${HADOOP_CONF_DIR}/workers.\n-#   HADOOP_CONF_DIR  Alternate conf dir. Default is ${HADOOP_HOME}/conf.\n-#   HADOOP_WORKER_SLEEP Seconds to sleep between spawning remote commands.\n-#   HADOOP_SSH_OPTS Options passed to ssh when running remote commands.\n+#   OZONE_WORKERS    File naming remote hosts.\n+#     Default is ${OZONE_CONFIG_DIR}/workers.\n+#   OZONE_CONFIG_DIR  Alternate conf dir. Default is ${OZONE_HOME}/conf.\n+#   OZONE_WORKER_SLEEP Seconds to sleep between spawning remote commands.\n+#   OZONE_SSH_OPTS Options passed to ssh when running remote commands.\n ##\n \n-function hadoop_usage\n+function ozone_usage\n {\n   echo \"Usage: workers.sh [--config confdir] command...\"\n }\n \n-# let's locate libexec...\n-if [[ -n \"${HADOOP_HOME}\" ]]; then\n-  HADOOP_DEFAULT_LIBEXEC_DIR=\"${HADOOP_HOME}/libexec\"\n-else\n-  this=\"${BASH_SOURCE-$0}\"\n-  bin=$(cd -P -- \"$(dirname -- \"${this}\")\" >/dev/null && pwd -P)\n-  HADOOP_DEFAULT_LIBEXEC_DIR=\"${bin}/../libexec\"\n+# load functions\n+for dir in \"${OZONE_LIBEXEC_DIR}\" \"${OZONE_HOME}/libexec\" \"${HADOOP_LIBEXEC_DIR}\" \"${HADOOP_HOME}/libexec\" \"${bin}/../libexec\"; do\n+  if [[ -e \"${dir}/ozone-functions.sh\" ]]; then\n+    . \"${dir}/ozone-functions.sh\"\n+    if declare -F ozone_bootstrap >& /dev/null; then\n+      break\n+    fi\n+  fi\n+done\n+\n+if ! declare -F ozone_bootstrap >& /dev/null; then\n+  echo \"ERROR: Cannot find ozone-functions.sh.\" 2>&1\n+  exit 1\n fi\n \n-HADOOP_LIBEXEC_DIR=\"${HADOOP_LIBEXEC_DIR:-$HADOOP_DEFAULT_LIBEXEC_DIR}\"\n-# shellcheck disable=SC2034\n-HADOOP_NEW_CONFIG=true\n-if [[ -f \"${HADOOP_LIBEXEC_DIR}/hadoop-config.sh\" ]]; then\n-  . \"${HADOOP_LIBEXEC_DIR}/hadoop-config.sh\"\n-else\n-  echo \"ERROR: Cannot execute ${HADOOP_LIBEXEC_DIR}/hadoop-config.sh.\" 2>&1\n+if ! ozone_bootstrap; then", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 51}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMDg5NzMy", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-552089732", "createdAt": "2020-12-15T04:04:44Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowNDo0NFrOIF35lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowNDo0NFrOIF35lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyOTY1NA==", "bodyText": "Is this changed intentionally from accumulation to a set? Probably, but I wanted to be sure, and even so if this is the first place where we can safely set if this runs in just a pure context, this variable may have an initial value in some workflow which makes it worth to preserve the external value even at the first assignment?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543029654", "createdAt": "2020-12-15T04:04:44Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/shell/ozone/start-ozone.sh", "diffHunk": "@@ -64,68 +63,53 @@ if [[ $# -ge 1 ]]; then\n       dataStartOpt=\"$startOpt\"\n     ;;\n     *)\n-      hadoop_exit_with_usage 1\n+      ozone_exit_with_usage 1\n     ;;\n   esac\n fi\n \n #Add other possible options\n nameStartOpt=\"$nameStartOpt $*\"\n \n-SECURITY_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getconf -confKey hadoop.security.authentication | tr '[:upper:]' '[:lower:]' 2>&-)\n-SECURITY_AUTHORIZATION_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getconf -confKey hadoop.security.authorization | tr '[:upper:]' '[:lower:]' 2>&-)\n-\n-#if [[ ${SECURITY_ENABLED} == \"kerberos\" || ${SECURITY_AUTHORIZATION_ENABLED}\n-# == \"true\" ]]; then\n-#  echo \"Ozone is not supported in a security enabled cluster.\"\n-#  exit 1\n-#fi\n-\n-#SECURITY_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getozoneconf -confKey hadoop.security.authentication | tr '[:upper:]' '[:lower:]' 2>&-)\n-#SECURITY_AUTHORIZATION_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getozoneconf -confKey hadoop.security.authorization | tr '[:upper:]' '[:lower:]' 2>&-)\n-#if [[ ${SECURITY_ENABLED} == \"kerberos\" || ${SECURITY_AUTHORIZATION_ENABLED} == \"true\" ]]; then\n-#  echo \"Ozone is not supported in a security enabled cluster.\"\n-#  exit 1\n-#fi\n+SECURITY_ENABLED=$(\"${OZONE_HOME}/bin/ozone\" getconf -confKey hadoop.security.authentication | tr '[:upper:]' '[:lower:]' 2>&-)\n+SECURITY_AUTHORIZATION_ENABLED=$(\"${OZONE_HOME}/bin/ozone\" getconf -confKey hadoop.security.authorization | tr '[:upper:]' '[:lower:]' 2>&-)\n \n # datanodes (using default workers file)\n \n echo \"Starting datanodes\"\n-hadoop_uservar_su hdfs datanode \"${HADOOP_HDFS_HOME}/bin/ozone\" \\\n+ozone_uservar_su hdfs datanode \"${OZONE_HOME}/bin/ozone\" \\\n     --workers \\\n-    --config \"${HADOOP_CONF_DIR}\" \\\n+    --config \"${OZONE_CONFIG_DIR}\" \\\n     --daemon start \\\n     datanode ${dataStartOpt}\n-(( HADOOP_JUMBO_RETCOUNTER=HADOOP_JUMBO_RETCOUNTER + $? ))\n+OZONE_JUMBO_RETCOUNTER=$?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 98}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aab17a2ad1eb1a94acd843520da14337b8b3d664", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/aab17a2ad1eb1a94acd843520da14337b8b3d664", "committedDate": "2020-12-15T06:34:24Z", "message": "Remove duplicate `if`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f12aca5019391deb746cdff09734d98366406c5a", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/f12aca5019391deb746cdff09734d98366406c5a", "committedDate": "2020-12-15T07:56:18Z", "message": "Some leftover references to Hadoop stuff in comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9719e2b1539e767ce586be9bc2d2f555c3357140", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/9719e2b1539e767ce586be9bc2d2f555c3357140", "committedDate": "2020-12-15T07:56:18Z", "message": "Remove some leftover HDFS/YARN/MAPRED variables"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "476cdd2e9e6c8e3b084f910359809dd30091304b", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/476cdd2e9e6c8e3b084f910359809dd30091304b", "committedDate": "2020-12-15T07:56:18Z", "message": "Rename HDFS_OM_SH_OPTS to OZONE_SH_OPTS"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a992588bf942f8f93fd7e1efebbbaa1d8b877120", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/a992588bf942f8f93fd7e1efebbbaa1d8b877120", "committedDate": "2020-12-15T07:56:18Z", "message": "Remove HDFS_SCM_CLI_OPTS from `ozone insight`\n\nUsage of this variable was introduced as leftover from copy-paste (of\n`scmcli` subcommand, which was above the new `insight` case at that\ntime)."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca031fdce6e0b33b5643fd58de23bfed69771b0b", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/ca031fdce6e0b33b5643fd58de23bfed69771b0b", "committedDate": "2020-12-15T10:43:52Z", "message": "simplify ozone_bootstrap call"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1241e1ef77fb95ec19207cf8651a4b88497a70e6", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/1241e1ef77fb95ec19207cf8651a4b88497a70e6", "committedDate": "2020-12-16T07:32:32Z", "message": "Rename OZONE_CONFIG_DIR to OZONE_CONF_DIR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2036228561e6811b9364fefd874d6b5a85a3c440", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/2036228561e6811b9364fefd874d6b5a85a3c440", "committedDate": "2020-12-16T09:15:06Z", "message": "HDDS-4601. envtoconf broken for .conf and few other formats"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a8f619a24981666cbb0dc43cec1d28a24530ce0d", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/a8f619a24981666cbb0dc43cec1d28a24530ce0d", "committedDate": "2020-12-16T12:57:14Z", "message": "workaround for HDDS-4601 and HADOOP-17436"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzOTA4NDQw", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-553908440", "createdAt": "2020-12-16T17:15:07Z", "commit": {"oid": "a8f619a24981666cbb0dc43cec1d28a24530ce0d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a70def928eca460dcf5abb3b0dfe87f01cec29e5", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/a70def928eca460dcf5abb3b0dfe87f01cec29e5", "committedDate": "2020-12-16T18:23:44Z", "message": "Merge remote-tracking branch 'origin/master' into HDDS-4525"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUxODg0MDE4", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-551884018", "createdAt": "2020-12-14T20:54:01Z", "commit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMDo1NDowMVrOIFoPbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzo1NToyMFrOIHR7Sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc3MzEwMw==", "bodyText": "Does hadoop-config.sh and hadoop-functions.sh have any useful env variables? (e.g. HADOOP_OPTS)\nTODO: Check ozone-config.sh and ozone-functions.sh later.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r542773103", "createdAt": "2020-12-14T20:54:01Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/dev-support/bin/dist-layout-stitching", "diffHunk": "@@ -103,10 +93,8 @@ run cp -r \"${ROOT}/hadoop-ozone/dist/src/main/dockerlibexec/.\" \"libexec/\"\n run cp \"${ROOT}/hadoop-ozone/dist/src/shell/ozone/ozone\" \"bin/\"\n \n \n-run cp \"${ROOT}/hadoop-ozone/dist/src/shell/hdds/hadoop-config.sh\" \"libexec/\"\n-run cp \"${ROOT}/hadoop-ozone/dist/src/shell/hdds/hadoop-config.cmd\" \"libexec/\"\n-run cp \"${ROOT}/hadoop-ozone/dist/src/shell/hdds/hadoop-functions.sh\" \"libexec/\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3NTQ4NQ==", "bodyText": "neat!", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544475485", "createdAt": "2020-12-16T17:13:58Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-csi/docker-compose.yaml", "diffHunk": "@@ -24,7 +24,7 @@ services:\n     env_file:\n       - docker-config\n     environment:\n-      HADOOP_OPTS: ${HADOOP_OPTS}\n+      OZONE_OPTS:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODcyMw=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3Nzc2Mw==", "bodyText": "Is OZONE_CLASSPATH a placeholder here? Or we are setting it to empty on purpose.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544477763", "createdAt": "2020-12-16T17:17:03Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop27/docker-config", "diffHunk": "@@ -18,4 +18,7 @@ CORE-SITE.xml_fs.AbstractFileSystem.o3fs.impl=org.apache.hadoop.fs.ozone.OzFs\n CORE-SITE.xml_fs.AbstractFileSystem.ofs.impl=org.apache.hadoop.fs.ozone.RootedOzFs\n MAPRED-SITE.XML_mapreduce.application.classpath=/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop2-@project.version@.jar\n \n+HADOOP_CLASSPATH=/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop2-@project.version@.jar\n+OZONE_CLASSPATH=", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3ODE0Mg==", "bodyText": "Same here.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544478142", "createdAt": "2020-12-16T17:17:32Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop31/docker-config", "diffHunk": "@@ -18,4 +18,7 @@ CORE-SITE.xml_fs.AbstractFileSystem.o3fs.impl=org.apache.hadoop.fs.ozone.OzFs\n CORE-SITE.xml_fs.AbstractFileSystem.ofs.impl=org.apache.hadoop.fs.ozone.RootedOzFs\n MAPRED-SITE.XML_mapreduce.application.classpath=/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop3-@project.version@.jar\n \n+HADOOP_CLASSPATH=/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop3-@project.version@.jar\n+OZONE_CLASSPATH=", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3ODI2Nw==", "bodyText": "Same", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544478267", "createdAt": "2020-12-16T17:17:42Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop32/docker-config", "diffHunk": "@@ -18,4 +18,7 @@ CORE-SITE.xml_fs.AbstractFileSystem.o3fs.impl=org.apache.hadoop.fs.ozone.OzFs\n CORE-SITE.xml_fs.AbstractFileSystem.ofs.impl=org.apache.hadoop.fs.ozone.RootedOzFs\n MAPRED-SITE.XML_mapreduce.application.classpath=/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop3-@project.version@.jar\n \n+HADOOP_CLASSPATH=/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop3-@project.version@.jar\n+OZONE_CLASSPATH=", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4MjAyMw==", "bodyText": "nice. btw do we pick up HADOOP_OPTS when OZONE_OPTS is not set as well?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544482023", "createdAt": "2020-12-16T17:22:44Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/smoketest/cli/classpath.robot", "diffHunk": "@@ -0,0 +1,46 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test ozone classpath command\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Resource            ../ozone-lib/shell.robot\n+Test Timeout        5 minutes\n+Suite Setup         Find Jars Dir\n+\n+*** Test Cases ***\n+Ignores HADOOP_CLASSPATH if OZONE_CLASSPATH is set", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDUwNDY1MA==", "bodyText": "Unrelated to this patch but CMS is removed in JDK 14 and on and UseConcMarkSweepGC will be ignored by those higher version JVMs. We might want to come up with a new set of GC params soon.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544504650", "createdAt": "2020-12-16T17:55:20Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/test/shell/gc_opts.bats", "diffHunk": "@@ -19,24 +19,32 @@\n # bats gc_opts.bats\n #\n \n-load ../../shell/hdds/hadoop-functions.sh\n-@test \"Setting Hadoop GC parameters: add GC params for server\" {\n-  export HADOOP_SUBCMD_SUPPORTDAEMONIZATION=true\n-  export HADOOP_OPTS=\"Test\"\n-  hadoop_add_default_gc_opts\n-  [[ \"$HADOOP_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n+load ozone-functions_test_helper\n+\n+@test \"Setting GC parameters: add GC params for server\" {\n+  export OZONE_SUBCMD_SUPPORTDAEMONIZATION=true\n+  export OZONE_OPTS=\"Test\"\n+\n+  ozone_add_default_gc_opts\n+\n+  echo $OZONE_OPTS\n+  [[ \"$OZONE_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n }\n \n-@test \"Setting Hadoop GC parameters: disabled for client\" {\n-  export HADOOP_SUBCMD_SUPPORTDAEMONIZATION=false\n-  export HADOOP_OPTS=\"Test\"\n-  hadoop_add_default_gc_opts\n-  [[ ! \"$HADOOP_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n+@test \"Setting GC parameters: disabled for client\" {\n+  export OZONE_SUBCMD_SUPPORTDAEMONIZATION=false\n+  export OZONE_OPTS=\"Test\"\n+\n+  ozone_add_default_gc_opts\n+\n+  [[ ! \"$OZONE_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n }\n \n-@test \"Setting Hadoop GC parameters: disabled if GC params are customized\" {\n-  export HADOOP_SUBCMD_SUPPORTDAEMONIZATION=true\n-  export HADOOP_OPTS=\"-XX:++UseG1GC -Xmx512\"\n-  hadoop_add_default_gc_opts\n-  [[ ! \"$HADOOP_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n+@test \"Setting GC parameters: disabled if GC params are customized\" {\n+  export OZONE_SUBCMD_SUPPORTDAEMONIZATION=true\n+  export OZONE_OPTS=\"-XX:++UseG1GC -Xmx512\"\n+\n+  ozone_add_default_gc_opts\n+\n+  [[ ! \"$OZONE_OPTS\" =~ \"UseConcMarkSweepGC\" ]]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 47}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "15192d34ec13fb9bc7c22089842a9a372e59ecc8", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/15192d34ec13fb9bc7c22089842a9a372e59ecc8", "committedDate": "2021-01-04T14:38:00Z", "message": "Merge remote-tracking branch 'origin/master' into HDDS-4525"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxMjM5OTk5", "url": "https://github.com/apache/ozone/pull/1667#pullrequestreview-561239999", "createdAt": "2021-01-04T18:21:28Z", "commit": {"oid": "15192d34ec13fb9bc7c22089842a9a372e59ecc8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "464bf0f32a921a9928e7789d8578f09228d9020e", "author": {"user": {"login": "adoroszlai", "name": "Doroszlai, Attila"}}, "url": "https://github.com/apache/ozone/commit/464bf0f32a921a9928e7789d8578f09228d9020e", "committedDate": "2021-01-21T17:17:06Z", "message": "Merge remote-tracking branch 'origin/master' into HDDS-4525"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2047, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}