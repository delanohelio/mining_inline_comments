{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIyMTA0MjE5", "number": 959, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwODo0MToxM1rOD_TxOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwMjozMTo0M1rOD_gQDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NzEwNzc3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwODo0MToxM1rOGZ5gIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwODo1Nzo0OFrOGaU--w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwOTY5OQ==", "bodyText": "can we put this into SCMHAUtils?", "url": "https://github.com/apache/ozone/pull/959#discussion_r429809699", "createdAt": "2020-05-25T08:41:13Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import com.google.common.base.Strings;\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.server.ServerUtils;\n+import org.apache.ratis.RaftConfigKeys;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.grpc.GrpcConfigKeys;\n+import org.apache.ratis.rpc.RpcType;\n+import org.apache.ratis.server.RaftServerConfigKeys;\n+import org.apache.ratis.util.SizeInBytes;\n+import org.apache.ratis.util.TimeDuration;\n+\n+import java.io.File;\n+import java.net.InetSocketAddress;\n+import java.util.Collections;\n+import java.util.concurrent.TimeUnit;\n+\n+public class RatisUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTg2MjgwMQ==", "bodyText": "I have moved this to ReflectionUtil class which can be used for all the utility methods related to reflection. I will update the PR soon.\nI agree that we should use the existing SCMHAUtil instead of creating new RatisUtil", "url": "https://github.com/apache/ozone/pull/959#discussion_r429862801", "createdAt": "2020-05-25T10:32:16Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import com.google.common.base.Strings;\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.server.ServerUtils;\n+import org.apache.ratis.RaftConfigKeys;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.grpc.GrpcConfigKeys;\n+import org.apache.ratis.rpc.RpcType;\n+import org.apache.ratis.server.RaftServerConfigKeys;\n+import org.apache.ratis.util.SizeInBytes;\n+import org.apache.ratis.util.TimeDuration;\n+\n+import java.io.File;\n+import java.net.InetSocketAddress;\n+import java.util.Collections;\n+import java.util.concurrent.TimeUnit;\n+\n+public class RatisUtil {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwOTY5OQ=="}, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI1MDkzNA==", "bodyText": "https://issues.apache.org/jira/browse/HDDS-3660 Track it here", "url": "https://github.com/apache/ozone/pull/959#discussion_r430250934", "createdAt": "2020-05-26T08:43:10Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import com.google.common.base.Strings;\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.server.ServerUtils;\n+import org.apache.ratis.RaftConfigKeys;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.grpc.GrpcConfigKeys;\n+import org.apache.ratis.rpc.RpcType;\n+import org.apache.ratis.server.RaftServerConfigKeys;\n+import org.apache.ratis.util.SizeInBytes;\n+import org.apache.ratis.util.TimeDuration;\n+\n+import java.io.File;\n+import java.net.InetSocketAddress;\n+import java.util.Collections;\n+import java.util.concurrent.TimeUnit;\n+\n+public class RatisUtil {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwOTY5OQ=="}, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI1OTk2Mw==", "bodyText": "I feel it's ok to have ReflectionUtil, RatisUtil, and SCMHAUtil as they serve a different purpose.", "url": "https://github.com/apache/ozone/pull/959#discussion_r430259963", "createdAt": "2020-05-26T08:57:48Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import com.google.common.base.Strings;\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.server.ServerUtils;\n+import org.apache.ratis.RaftConfigKeys;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.grpc.GrpcConfigKeys;\n+import org.apache.ratis.rpc.RpcType;\n+import org.apache.ratis.server.RaftServerConfigKeys;\n+import org.apache.ratis.util.SizeInBytes;\n+import org.apache.ratis.util.TimeDuration;\n+\n+import java.io.File;\n+import java.net.InetSocketAddress;\n+import java.util.Collections;\n+import java.util.concurrent.TimeUnit;\n+\n+public class RatisUtil {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwOTY5OQ=="}, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NzExNDc2OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwODo0MzozNlrOGZ5kyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwODo1NjoxMVrOGaU65g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA==", "bodyText": "I've merged SCMRatisServer and SCMStateMachine into one between /ha and /ratis in timmylicheng#1. We can use /ha as your did here, but we need to combine all methods into one.", "url": "https://github.com/apache/ozone/pull/959#discussion_r429810890", "createdAt": "2020-05-25T08:43:36Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocolProtos;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.RaftClientReply;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.apache.ratis.protocol.RaftGroup;\n+import org.apache.ratis.protocol.RaftGroupId;\n+import org.apache.ratis.protocol.RaftPeer;\n+import org.apache.ratis.protocol.RaftPeerId;\n+import org.apache.ratis.server.RaftServer;\n+\n+public class SCMRatisServer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTg2MzgxOQ==", "bodyText": "I don't think we need to copy all the code/methods from OzoneManagerHA implementation. We can add things to SCMHA related classes whenever required.\nIt's better not to have code that is not used or needed.\nLet's add/update the SCMHA code when needed.", "url": "https://github.com/apache/ozone/pull/959#discussion_r429863819", "createdAt": "2020-05-25T10:34:40Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocolProtos;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.RaftClientReply;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.apache.ratis.protocol.RaftGroup;\n+import org.apache.ratis.protocol.RaftGroupId;\n+import org.apache.ratis.protocol.RaftPeer;\n+import org.apache.ratis.protocol.RaftPeerId;\n+import org.apache.ratis.server.RaftServer;\n+\n+public class SCMRatisServer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA=="}, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDEyNjgxMA==", "bodyText": "How about Snapshot in SCMStateMachine?", "url": "https://github.com/apache/ozone/pull/959#discussion_r430126810", "createdAt": "2020-05-26T02:31:04Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocolProtos;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.RaftClientReply;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.apache.ratis.protocol.RaftGroup;\n+import org.apache.ratis.protocol.RaftGroupId;\n+import org.apache.ratis.protocol.RaftPeer;\n+import org.apache.ratis.protocol.RaftPeerId;\n+import org.apache.ratis.server.RaftServer;\n+\n+public class SCMRatisServer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA=="}, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI1MjE0NA==", "bodyText": "Track the issue in https://issues.apache.org/jira/browse/HDDS-3661.\nThis is to split the work.", "url": "https://github.com/apache/ozone/pull/959#discussion_r430252144", "createdAt": "2020-05-26T08:45:04Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocolProtos;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.RaftClientReply;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.apache.ratis.protocol.RaftGroup;\n+import org.apache.ratis.protocol.RaftGroupId;\n+import org.apache.ratis.protocol.RaftPeer;\n+import org.apache.ratis.protocol.RaftPeerId;\n+import org.apache.ratis.server.RaftServer;\n+\n+public class SCMRatisServer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA=="}, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI1ODkxOA==", "bodyText": "Let's configure/enable Ratis snapshot after we have some design plan on how to implement the snapshot.", "url": "https://github.com/apache/ozone/pull/959#discussion_r430258918", "createdAt": "2020-05-26T08:56:11Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocolProtos;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.RaftClientReply;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.apache.ratis.protocol.RaftGroup;\n+import org.apache.ratis.protocol.RaftGroupId;\n+import org.apache.ratis.protocol.RaftPeer;\n+import org.apache.ratis.protocol.RaftPeerId;\n+import org.apache.ratis.server.RaftServer;\n+\n+public class SCMRatisServer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA=="}, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTE1Mjc5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/ContainerManagerImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwMjozMTo0M1rOGaM3WQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwODo1OTowMlrOGaVB7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDEyNjkzNw==", "bodyText": "Do we need to addContainerToDB here?", "url": "https://github.com/apache/ozone/pull/959#discussion_r430126937", "createdAt": "2020-05-26T02:31:43Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/ContainerManagerImpl.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.container;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ContainerInfoProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleEvent;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.scm.ha.SCMHAManager;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineManager;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * TODO: Add javadoc.\n+ */\n+public class ContainerManagerImpl implements ContainerManagerV2 {\n+\n+  /**\n+   *\n+   */\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      ContainerManagerImpl.class);\n+\n+  /**\n+   *\n+   */\n+  private final ReadWriteLock lock;\n+\n+  /**\n+   *\n+   */\n+  private final PipelineManager pipelineManager;\n+\n+  /**\n+   *\n+   */\n+  private final ContainerStateManagerV2 containerStateManager;\n+\n+  /**\n+   *\n+   */\n+  public ContainerManagerImpl(\n+      // Introduce builder for this class?\n+      final Configuration conf, final PipelineManager pipelineManager,\n+      final SCMHAManager scmhaManager,\n+      final Table<ContainerID, ContainerInfo> containerStore)\n+      throws IOException {\n+    this.lock = new ReentrantReadWriteLock();\n+    this.pipelineManager = pipelineManager;\n+    this.containerStateManager =  ContainerStateManagerImpl.newBuilder()\n+        .setConfiguration(conf)\n+        .setPipelineManager(pipelineManager)\n+        .setRatisServer(scmhaManager.getRatisServer())\n+        .setContainerStore(containerStore)\n+        .build();\n+  }\n+\n+  @Override\n+  public Set<ContainerID> getContainerIDs() {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs();\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public Set<ContainerInfo> getContainers() {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs().stream().map(id -> {\n+        try {\n+          return containerStateManager.getContainer(id);\n+        } catch (ContainerNotFoundException e) {\n+          // How can this happen? o_O\n+          return null;\n+        }\n+      }).filter(Objects::nonNull).collect(Collectors.toSet());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public ContainerInfo getContainer(final ContainerID containerID)\n+      throws ContainerNotFoundException {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainer(containerID);\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public Set<ContainerInfo> getContainers(final LifeCycleState state) {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs(state).stream().map(id -> {\n+        try {\n+          return containerStateManager.getContainer(id);\n+        } catch (ContainerNotFoundException e) {\n+          // How can this happen? o_O\n+          return null;\n+        }\n+      }).filter(Objects::nonNull).collect(Collectors.toSet());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public boolean exists(final ContainerID containerID) {\n+    lock.readLock().lock();\n+    try {\n+      return (containerStateManager.getContainer(containerID) != null);\n+    } catch (ContainerNotFoundException ex) {\n+      return false;\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public List<ContainerInfo> listContainers(final ContainerID startID,\n+                                            final int count) {\n+    lock.readLock().lock();\n+    try {\n+      final long startId = startID == null ? 0 : startID.getId();\n+      final List<ContainerID> containersIds =\n+          new ArrayList<>(containerStateManager.getContainerIDs());\n+      Collections.sort(containersIds);\n+      return containersIds.stream()\n+          .filter(id -> id.getId() > startId)\n+          .limit(count)\n+          .map(id -> {\n+            try {\n+              return containerStateManager.getContainer(id);\n+            } catch (ContainerNotFoundException ex) {\n+              // This can never happen, as we hold lock no one else can remove\n+              // the container after we got the container ids.\n+              LOG.warn(\"Container Missing.\", ex);\n+              return null;\n+            }\n+          }).collect(Collectors.toList());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public ContainerInfo allocateContainer(final ReplicationType type,\n+      final ReplicationFactor replicationFactor, final String owner)\n+      throws IOException {\n+    lock.writeLock().lock();\n+    try {\n+      final List<Pipeline> pipelines = pipelineManager\n+          .getPipelines(type, replicationFactor, Pipeline.PipelineState.OPEN);\n+\n+      if (pipelines.isEmpty()) {\n+        throw new IOException(\"Could not allocate container. Cannot get any\" +\n+            \" matching pipeline for Type:\" + type + \", Factor:\" +\n+            replicationFactor + \", State:PipelineState.OPEN\");\n+      }\n+\n+      final ContainerID containerID = containerStateManager\n+          .getNextContainerID();\n+      final Pipeline pipeline = pipelines.get(\n+          (int) containerID.getId() % pipelines.size());\n+\n+      final ContainerInfoProto containerInfo = ContainerInfoProto.newBuilder()\n+          .setState(LifeCycleState.OPEN)\n+          .setPipelineID(pipeline.getId().getProtobuf())\n+          .setUsedBytes(0)\n+          .setNumberOfKeys(0)\n+          .setStateEnterTime(Time.now())\n+          .setOwner(owner)\n+          .setContainerID(containerID.getId())\n+          .setDeleteTransactionId(0)\n+          .setReplicationFactor(pipeline.getFactor())\n+          .setReplicationType(pipeline.getType())\n+          .build();\n+      containerStateManager.addContainer(containerInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdfa6d5a2dabe64f0d291273d8929221ff8fda3"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI2MDcxNg==", "bodyText": "It is handled inside ContainerStateManager.", "url": "https://github.com/apache/ozone/pull/959#discussion_r430260716", "createdAt": "2020-05-26T08:59:02Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/ContainerManagerImpl.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.container;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ContainerInfoProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleEvent;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.scm.ha.SCMHAManager;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineManager;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * TODO: Add javadoc.\n+ */\n+public class ContainerManagerImpl implements ContainerManagerV2 {\n+\n+  /**\n+   *\n+   */\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      ContainerManagerImpl.class);\n+\n+  /**\n+   *\n+   */\n+  private final ReadWriteLock lock;\n+\n+  /**\n+   *\n+   */\n+  private final PipelineManager pipelineManager;\n+\n+  /**\n+   *\n+   */\n+  private final ContainerStateManagerV2 containerStateManager;\n+\n+  /**\n+   *\n+   */\n+  public ContainerManagerImpl(\n+      // Introduce builder for this class?\n+      final Configuration conf, final PipelineManager pipelineManager,\n+      final SCMHAManager scmhaManager,\n+      final Table<ContainerID, ContainerInfo> containerStore)\n+      throws IOException {\n+    this.lock = new ReentrantReadWriteLock();\n+    this.pipelineManager = pipelineManager;\n+    this.containerStateManager =  ContainerStateManagerImpl.newBuilder()\n+        .setConfiguration(conf)\n+        .setPipelineManager(pipelineManager)\n+        .setRatisServer(scmhaManager.getRatisServer())\n+        .setContainerStore(containerStore)\n+        .build();\n+  }\n+\n+  @Override\n+  public Set<ContainerID> getContainerIDs() {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs();\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public Set<ContainerInfo> getContainers() {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs().stream().map(id -> {\n+        try {\n+          return containerStateManager.getContainer(id);\n+        } catch (ContainerNotFoundException e) {\n+          // How can this happen? o_O\n+          return null;\n+        }\n+      }).filter(Objects::nonNull).collect(Collectors.toSet());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public ContainerInfo getContainer(final ContainerID containerID)\n+      throws ContainerNotFoundException {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainer(containerID);\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public Set<ContainerInfo> getContainers(final LifeCycleState state) {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs(state).stream().map(id -> {\n+        try {\n+          return containerStateManager.getContainer(id);\n+        } catch (ContainerNotFoundException e) {\n+          // How can this happen? o_O\n+          return null;\n+        }\n+      }).filter(Objects::nonNull).collect(Collectors.toSet());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public boolean exists(final ContainerID containerID) {\n+    lock.readLock().lock();\n+    try {\n+      return (containerStateManager.getContainer(containerID) != null);\n+    } catch (ContainerNotFoundException ex) {\n+      return false;\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public List<ContainerInfo> listContainers(final ContainerID startID,\n+                                            final int count) {\n+    lock.readLock().lock();\n+    try {\n+      final long startId = startID == null ? 0 : startID.getId();\n+      final List<ContainerID> containersIds =\n+          new ArrayList<>(containerStateManager.getContainerIDs());\n+      Collections.sort(containersIds);\n+      return containersIds.stream()\n+          .filter(id -> id.getId() > startId)\n+          .limit(count)\n+          .map(id -> {\n+            try {\n+              return containerStateManager.getContainer(id);\n+            } catch (ContainerNotFoundException ex) {\n+              // This can never happen, as we hold lock no one else can remove\n+              // the container after we got the container ids.\n+              LOG.warn(\"Container Missing.\", ex);\n+              return null;\n+            }\n+          }).collect(Collectors.toList());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public ContainerInfo allocateContainer(final ReplicationType type,\n+      final ReplicationFactor replicationFactor, final String owner)\n+      throws IOException {\n+    lock.writeLock().lock();\n+    try {\n+      final List<Pipeline> pipelines = pipelineManager\n+          .getPipelines(type, replicationFactor, Pipeline.PipelineState.OPEN);\n+\n+      if (pipelines.isEmpty()) {\n+        throw new IOException(\"Could not allocate container. Cannot get any\" +\n+            \" matching pipeline for Type:\" + type + \", Factor:\" +\n+            replicationFactor + \", State:PipelineState.OPEN\");\n+      }\n+\n+      final ContainerID containerID = containerStateManager\n+          .getNextContainerID();\n+      final Pipeline pipeline = pipelines.get(\n+          (int) containerID.getId() % pipelines.size());\n+\n+      final ContainerInfoProto containerInfo = ContainerInfoProto.newBuilder()\n+          .setState(LifeCycleState.OPEN)\n+          .setPipelineID(pipeline.getId().getProtobuf())\n+          .setUsedBytes(0)\n+          .setNumberOfKeys(0)\n+          .setStateEnterTime(Time.now())\n+          .setOwner(owner)\n+          .setContainerID(containerID.getId())\n+          .setDeleteTransactionId(0)\n+          .setReplicationFactor(pipeline.getFactor())\n+          .setReplicationType(pipeline.getType())\n+          .build();\n+      containerStateManager.addContainer(containerInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDEyNjkzNw=="}, "originalCommit": {"oid": "ecdfa6d5a2dabe64f0d291273d8929221ff8fda3"}, "originalPosition": 216}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4333, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}