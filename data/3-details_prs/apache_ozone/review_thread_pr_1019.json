{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI3Nzg3MDAx", "number": 1019, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNToyNDo1NFrOEC_8Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1NDo1M1rOEDAm_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTgwMTkxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/StateManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNToyNDo1NFrOGfzBZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwMzowNzowMFrOGgODGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTk5NDk4Mw==", "bodyText": "There is no need to return HddsProtos.Pipeline as a response to updatePipelineState.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r435994983", "createdAt": "2020-06-05T15:24:54Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/StateManager.java", "diffHunk": "@@ -58,7 +58,7 @@ void removePipeline(HddsProtos.PipelineID pipelineIDProto)\n    * @throws IOException\n    */\n   @Replicate\n-  void updatePipelineState(HddsProtos.PipelineID pipelineIDProto,\n+  HddsProtos.Pipeline updatePipelineState(HddsProtos.PipelineID pipelineIDProto,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzNzc4Ng==", "bodyText": "Updated.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436437786", "createdAt": "2020-06-08T03:07:00Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/StateManager.java", "diffHunk": "@@ -58,7 +58,7 @@ void removePipeline(HddsProtos.PipelineID pipelineIDProto)\n    * @throws IOException\n    */\n   @Replicate\n-  void updatePipelineState(HddsProtos.PipelineID pipelineIDProto,\n+  HddsProtos.Pipeline updatePipelineState(HddsProtos.PipelineID pipelineIDProto,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTk5NDk4Mw=="}, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTgwODUzOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNToyNjozOFrOGfzFoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwMzowNjo1M1rOGgODCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTk5NjA2NQ==", "bodyText": "We don't have to construct the Pipeline from proto object. stateManager#getPipeline should be sufficient to get the updated pipeline.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r435996065", "createdAt": "2020-06-05T15:26:38Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -299,8 +299,9 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n       }\n       if (pipeline.getPipelineState() == Pipeline.PipelineState.ALLOCATED) {\n         LOG.info(\"Pipeline {} moved to OPEN state\", pipeline);\n-        stateManager.updatePipelineState(pipelineId.getProtobuf(),\n-            HddsProtos.PipelineState.PIPELINE_OPEN);\n+        HddsProtos.Pipeline pipelineProto = stateManager.updatePipelineState(\n+            pipelineId.getProtobuf(), HddsProtos.PipelineState.PIPELINE_OPEN);\n+        pipeline = Pipeline.getFromProtobuf(pipelineProto);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzNzc3MA==", "bodyText": "Updated.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436437770", "createdAt": "2020-06-08T03:06:53Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -299,8 +299,9 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n       }\n       if (pipeline.getPipelineState() == Pipeline.PipelineState.ALLOCATED) {\n         LOG.info(\"Pipeline {} moved to OPEN state\", pipeline);\n-        stateManager.updatePipelineState(pipelineId.getProtobuf(),\n-            HddsProtos.PipelineState.PIPELINE_OPEN);\n+        HddsProtos.Pipeline pipelineProto = stateManager.updatePipelineState(\n+            pipelineId.getProtobuf(), HddsProtos.PipelineState.PIPELINE_OPEN);\n+        pipeline = Pipeline.getFromProtobuf(pipelineProto);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTk5NjA2NQ=="}, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTgzNDExOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTozMzo0NVrOGfzWXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwMzowNjo0NVrOGgOC6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAwMDM1MQ==", "bodyText": "This is never used for verification, can be removed.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436000351", "createdAt": "2020-06-05T15:33:45Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzNzczOQ==", "bodyText": "Updated.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436437739", "createdAt": "2020-06-08T03:06:45Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAwMDM1MQ=="}, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTgzOTczOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTozNToxN1rOGfzZ1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQwMzowNjoyNlrOGgOCxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAwMTIzOQ==", "bodyText": "Assert.assertTrue can be replaced with Assert.assertEquals.\nAssert.assertEquals will give a better context in case of test failure.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436001239", "createdAt": "2020-06-05T15:35:17Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline1 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline1.getId()));\n+    pipelines.add(pipeline1);\n+\n+    Pipeline pipeline2 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline2.getId()));\n+    pipelines.add(pipeline2);\n+    pipelineManager.close();\n+\n+    PipelineManagerV2Impl pipelineManager2 = createPipelineManager();\n+    // Should be able to load previous pipelines.\n+    Assert.assertFalse(pipelineManager.getPipelines().isEmpty());\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline3 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(3, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline3.getId()));\n+    pipelines.add(pipeline3);\n+\n+    pipelineManager2.close();\n+  }\n+\n+  @Test\n+  public void testUpdatePipelineStates() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzNzcwMQ==", "bodyText": "These are copied from original TestSCMPipelineManager tests. I will update them.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436437701", "createdAt": "2020-06-08T03:06:26Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline1 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline1.getId()));\n+    pipelines.add(pipeline1);\n+\n+    Pipeline pipeline2 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline2.getId()));\n+    pipelines.add(pipeline2);\n+    pipelineManager.close();\n+\n+    PipelineManagerV2Impl pipelineManager2 = createPipelineManager();\n+    // Should be able to load previous pipelines.\n+    Assert.assertFalse(pipelineManager.getPipelines().isEmpty());\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline3 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(3, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline3.getId()));\n+    pipelines.add(pipeline3);\n+\n+    pipelineManager2.close();\n+  }\n+\n+  @Test\n+  public void testUpdatePipelineStates() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAwMTIzOQ=="}, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTg2MTI5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo0MDoyM1rOGfzn8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo0MDoyM1rOGfzn8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAwNDg1MA==", "bodyText": "Assert.assertTrue can be replaced with Assert.assertEquals.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436004850", "createdAt": "2020-06-05T15:40:23Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline1 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline1.getId()));\n+    pipelines.add(pipeline1);\n+\n+    Pipeline pipeline2 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline2.getId()));\n+    pipelines.add(pipeline2);\n+    pipelineManager.close();\n+\n+    PipelineManagerV2Impl pipelineManager2 = createPipelineManager();\n+    // Should be able to load previous pipelines.\n+    Assert.assertFalse(pipelineManager.getPipelines().isEmpty());\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline3 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(3, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline3.getId()));\n+    pipelines.add(pipeline3);\n+\n+    pipelineManager2.close();\n+  }\n+\n+  @Test\n+  public void testUpdatePipelineStates() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+    PipelineID pipelineID = pipeline.getId();\n+\n+    pipelineManager.openPipeline(pipelineID);\n+    pipelineManager.addContainerToPipeline(pipelineID, ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.deactivatePipeline(pipeline.getId());\n+    Assert.assertEquals(Pipeline.PipelineState.DORMANT,\n+        pipelineManager.getPipeline(pipelineID).getPipelineState());\n+    Assert.assertFalse(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.activatePipeline(pipeline.getId());\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testRemovePipeline() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    // Create a pipeline\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 181}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTg5ODExOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1MTowNVrOGfz_xA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1MTowNVrOGfz_xA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAxMDk0OA==", "bodyText": "Instead of IOException, we can check for PipelineNotFoundException.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436010948", "createdAt": "2020-06-05T15:51:05Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline1 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline1.getId()));\n+    pipelines.add(pipeline1);\n+\n+    Pipeline pipeline2 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline2.getId()));\n+    pipelines.add(pipeline2);\n+    pipelineManager.close();\n+\n+    PipelineManagerV2Impl pipelineManager2 = createPipelineManager();\n+    // Should be able to load previous pipelines.\n+    Assert.assertFalse(pipelineManager.getPipelines().isEmpty());\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline3 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(3, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline3.getId()));\n+    pipelines.add(pipeline3);\n+\n+    pipelineManager2.close();\n+  }\n+\n+  @Test\n+  public void testUpdatePipelineStates() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+    PipelineID pipelineID = pipeline.getId();\n+\n+    pipelineManager.openPipeline(pipelineID);\n+    pipelineManager.addContainerToPipeline(pipelineID, ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.deactivatePipeline(pipeline.getId());\n+    Assert.assertEquals(Pipeline.PipelineState.DORMANT,\n+        pipelineManager.getPipeline(pipelineID).getPipelineState());\n+    Assert.assertFalse(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.activatePipeline(pipeline.getId());\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testRemovePipeline() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    // Create a pipeline\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+\n+    // Open the pipeline\n+    pipelineManager.openPipeline(pipeline.getId());\n+    pipelineManager\n+        .addContainerToPipeline(pipeline.getId(), ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    try {\n+      pipelineManager.removePipeline(pipeline.getId());\n+      fail();\n+    } catch (IOException ioe) {\n+      // Should not be able to remove the OPEN pipeline.\n+      Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    } catch (Exception e) {\n+      Assert.fail(\"Should not reach here.\");\n+    }\n+\n+    // Destroy pipeline\n+    pipelineManager.finalizeAndDestroyPipeline(pipeline, false);\n+    try {\n+      pipelineManager.getPipeline(pipeline.getId());\n+      fail(\"Pipeline should not have been retrieved\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(e.getMessage().contains(\"not found\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 208}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTkwNDUzOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1Mjo1NFrOGf0D4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1Mjo1NFrOGf0D4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAxMjAwMw==", "bodyText": "Instead of IOException, we can check for PipelineNotFoundException.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436012003", "createdAt": "2020-06-05T15:52:54Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline1 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline1.getId()));\n+    pipelines.add(pipeline1);\n+\n+    Pipeline pipeline2 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline2.getId()));\n+    pipelines.add(pipeline2);\n+    pipelineManager.close();\n+\n+    PipelineManagerV2Impl pipelineManager2 = createPipelineManager();\n+    // Should be able to load previous pipelines.\n+    Assert.assertFalse(pipelineManager.getPipelines().isEmpty());\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline3 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(3, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline3.getId()));\n+    pipelines.add(pipeline3);\n+\n+    pipelineManager2.close();\n+  }\n+\n+  @Test\n+  public void testUpdatePipelineStates() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+    PipelineID pipelineID = pipeline.getId();\n+\n+    pipelineManager.openPipeline(pipelineID);\n+    pipelineManager.addContainerToPipeline(pipelineID, ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.deactivatePipeline(pipeline.getId());\n+    Assert.assertEquals(Pipeline.PipelineState.DORMANT,\n+        pipelineManager.getPipeline(pipelineID).getPipelineState());\n+    Assert.assertFalse(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.activatePipeline(pipeline.getId());\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testRemovePipeline() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    // Create a pipeline\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+\n+    // Open the pipeline\n+    pipelineManager.openPipeline(pipeline.getId());\n+    pipelineManager\n+        .addContainerToPipeline(pipeline.getId(), ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    try {\n+      pipelineManager.removePipeline(pipeline.getId());\n+      fail();\n+    } catch (IOException ioe) {\n+      // Should not be able to remove the OPEN pipeline.\n+      Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    } catch (Exception e) {\n+      Assert.fail(\"Should not reach here.\");\n+    }\n+\n+    // Destroy pipeline\n+    pipelineManager.finalizeAndDestroyPipeline(pipeline, false);\n+    try {\n+      pipelineManager.getPipeline(pipeline.getId());\n+      fail(\"Pipeline should not have been retrieved\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(e.getMessage().contains(\"not found\"));\n+    }\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineReport() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    SCMSafeModeManager scmSafeModeManager =\n+        new SCMSafeModeManager(conf, new ArrayList<>(), pipelineManager,\n+            eventQueue);\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+\n+    // pipeline is not healthy until all dns report\n+    List<DatanodeDetails> nodes = pipeline.getNodes();\n+    Assert.assertFalse(\n+        pipelineManager.getPipeline(pipeline.getId()).isHealthy());\n+    // get pipeline report from each dn in the pipeline\n+    PipelineReportHandler pipelineReportHandler =\n+        new PipelineReportHandler(scmSafeModeManager, pipelineManager, conf);\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    // pipeline is healthy when all dns report\n+    Assert\n+        .assertTrue(pipelineManager.getPipeline(pipeline.getId()).isHealthy());\n+    // pipeline should now move to open state\n+    Assert\n+        .assertTrue(pipelineManager.getPipeline(pipeline.getId()).isOpen());\n+\n+    // close the pipeline\n+    pipelineManager.finalizeAndDestroyPipeline(pipeline, false);\n+\n+    // pipeline report for destroyed pipeline should be ignored\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    try {\n+      pipelineManager.getPipeline(pipeline.getId());\n+      fail(\"Pipeline should not have been retrieved\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(e.getMessage().contains(\"not found\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 257}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTkwOTg5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1NDozMFrOGf0HZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1NDozMFrOGf0HZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAxMjkwMA==", "bodyText": "Can be simplified to assertTrue and assertFalse.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436012900", "createdAt": "2020-06-05T15:54:30Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline1 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline1.getId()));\n+    pipelines.add(pipeline1);\n+\n+    Pipeline pipeline2 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline2.getId()));\n+    pipelines.add(pipeline2);\n+    pipelineManager.close();\n+\n+    PipelineManagerV2Impl pipelineManager2 = createPipelineManager();\n+    // Should be able to load previous pipelines.\n+    Assert.assertFalse(pipelineManager.getPipelines().isEmpty());\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline3 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(3, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline3.getId()));\n+    pipelines.add(pipeline3);\n+\n+    pipelineManager2.close();\n+  }\n+\n+  @Test\n+  public void testUpdatePipelineStates() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+    PipelineID pipelineID = pipeline.getId();\n+\n+    pipelineManager.openPipeline(pipelineID);\n+    pipelineManager.addContainerToPipeline(pipelineID, ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.deactivatePipeline(pipeline.getId());\n+    Assert.assertEquals(Pipeline.PipelineState.DORMANT,\n+        pipelineManager.getPipeline(pipelineID).getPipelineState());\n+    Assert.assertFalse(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.activatePipeline(pipeline.getId());\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testRemovePipeline() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    // Create a pipeline\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+\n+    // Open the pipeline\n+    pipelineManager.openPipeline(pipeline.getId());\n+    pipelineManager\n+        .addContainerToPipeline(pipeline.getId(), ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    try {\n+      pipelineManager.removePipeline(pipeline.getId());\n+      fail();\n+    } catch (IOException ioe) {\n+      // Should not be able to remove the OPEN pipeline.\n+      Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    } catch (Exception e) {\n+      Assert.fail(\"Should not reach here.\");\n+    }\n+\n+    // Destroy pipeline\n+    pipelineManager.finalizeAndDestroyPipeline(pipeline, false);\n+    try {\n+      pipelineManager.getPipeline(pipeline.getId());\n+      fail(\"Pipeline should not have been retrieved\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(e.getMessage().contains(\"not found\"));\n+    }\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineReport() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    SCMSafeModeManager scmSafeModeManager =\n+        new SCMSafeModeManager(conf, new ArrayList<>(), pipelineManager,\n+            eventQueue);\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+\n+    // pipeline is not healthy until all dns report\n+    List<DatanodeDetails> nodes = pipeline.getNodes();\n+    Assert.assertFalse(\n+        pipelineManager.getPipeline(pipeline.getId()).isHealthy());\n+    // get pipeline report from each dn in the pipeline\n+    PipelineReportHandler pipelineReportHandler =\n+        new PipelineReportHandler(scmSafeModeManager, pipelineManager, conf);\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    // pipeline is healthy when all dns report\n+    Assert\n+        .assertTrue(pipelineManager.getPipeline(pipeline.getId()).isHealthy());\n+    // pipeline should now move to open state\n+    Assert\n+        .assertTrue(pipelineManager.getPipeline(pipeline.getId()).isOpen());\n+\n+    // close the pipeline\n+    pipelineManager.finalizeAndDestroyPipeline(pipeline, false);\n+\n+    // pipeline report for destroyed pipeline should be ignored\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    try {\n+      pipelineManager.getPipeline(pipeline.getId());\n+      fail(\"Pipeline should not have been retrieved\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(e.getMessage().contains(\"not found\"));\n+    }\n+\n+    // clean up\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineCreationFailedMetric() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+\n+    // No pipeline at start\n+    MetricsRecordBuilder metrics = getMetrics(\n+        SCMPipelineMetrics.class.getSimpleName());\n+    long numPipelineAllocated = getLongCounter(\"NumPipelineAllocated\",\n+        metrics);\n+    Assert.assertEquals(0, numPipelineAllocated);\n+\n+    // 3 DNs are unhealthy.\n+    // Create 5 pipelines (Use up 15 Datanodes)\n+\n+    for (int i = 0; i < maxPipelineCount; i++) {\n+      Pipeline pipeline = pipelineManager\n+          .createPipeline(HddsProtos.ReplicationType.RATIS,\n+              HddsProtos.ReplicationFactor.THREE);\n+      Assert.assertNotNull(pipeline);\n+    }\n+\n+    metrics = getMetrics(\n+        SCMPipelineMetrics.class.getSimpleName());\n+    numPipelineAllocated = getLongCounter(\"NumPipelineAllocated\", metrics);\n+    Assert.assertEquals(maxPipelineCount, numPipelineAllocated);\n+\n+    long numPipelineCreateFailed = getLongCounter(\n+        \"NumPipelineCreationFailed\", metrics);\n+    Assert.assertEquals(0, numPipelineCreateFailed);\n+\n+    //This should fail...\n+    try {\n+      pipelineManager.createPipeline(HddsProtos.ReplicationType.RATIS,\n+          HddsProtos.ReplicationFactor.THREE);\n+      fail();\n+    } catch (SCMException ioe) {\n+      // pipeline creation failed this time.\n+      Assert.assertEquals(SCMException.ResultCodes.FAILED_TO_FIND_SUITABLE_NODE,\n+          ioe.getResult());\n+    }\n+\n+    metrics = getMetrics(\n+        SCMPipelineMetrics.class.getSimpleName());\n+    numPipelineAllocated = getLongCounter(\"NumPipelineAllocated\", metrics);\n+    Assert.assertEquals(maxPipelineCount, numPipelineAllocated);\n+\n+    numPipelineCreateFailed = getLongCounter(\n+        \"NumPipelineCreationFailed\", metrics);\n+    Assert.assertEquals(1, numPipelineCreateFailed);\n+\n+    // clean up\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineOpenOnlyWhenLeaderReported() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+\n+    pipelineManager.onMessage(\n+        new SCMSafeModeManager.SafeModeStatus(true, true), null);\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+    // close manager\n+    pipelineManager.close();\n+    // new pipeline manager loads the pipelines from the db in ALLOCATED state\n+    pipelineManager = createPipelineManager();\n+    Assert.assertEquals(Pipeline.PipelineState.ALLOCATED,\n+        pipelineManager.getPipeline(pipeline.getId()).getPipelineState());\n+\n+    SCMSafeModeManager scmSafeModeManager =\n+        new SCMSafeModeManager(new OzoneConfiguration(),\n+            new ArrayList<>(), pipelineManager, eventQueue);\n+    PipelineReportHandler pipelineReportHandler =\n+        new PipelineReportHandler(scmSafeModeManager, pipelineManager, conf);\n+\n+    // Report pipelines with leaders\n+    List<DatanodeDetails> nodes = pipeline.getNodes();\n+    Assert.assertEquals(3, nodes.size());\n+    // Send report for all but no leader\n+    nodes.forEach(dn -> sendPipelineReport(dn, pipeline, pipelineReportHandler,\n+        false));\n+\n+    Assert.assertEquals(Pipeline.PipelineState.ALLOCATED,\n+        pipelineManager.getPipeline(pipeline.getId()).getPipelineState());\n+\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    Assert.assertEquals(Pipeline.PipelineState.OPEN,\n+        pipelineManager.getPipeline(pipeline.getId()).getPipelineState());\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testScrubPipeline() throws Exception {\n+    // No timeout for pipeline scrubber.\n+    conf.setTimeDuration(\n+        OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT, -1,\n+        TimeUnit.MILLISECONDS);\n+\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+    // At this point, pipeline is not at OPEN stage.\n+    Assert.assertEquals(Pipeline.PipelineState.ALLOCATED,\n+        pipeline.getPipelineState());\n+\n+    // pipeline should be seen in pipelineManager as ALLOCATED.\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.ALLOCATED).contains(pipeline));\n+    pipelineManager.scrubPipeline(HddsProtos.ReplicationType.RATIS,\n+        HddsProtos.ReplicationFactor.THREE);\n+\n+    // pipeline should be scrubbed.\n+    Assert.assertFalse(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.ALLOCATED).contains(pipeline));\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineNotCreatedUntilSafeModePrecheck() throws Exception {\n+    // No timeout for pipeline scrubber.\n+    conf.setTimeDuration(\n+        OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT, -1,\n+        TimeUnit.MILLISECONDS);\n+\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    try {\n+      pipelineManager.createPipeline(HddsProtos.ReplicationType.RATIS,\n+              HddsProtos.ReplicationFactor.THREE);\n+      fail(\"Pipelines should not have been created\");\n+    } catch (IOException e) {\n+      // No pipeline is created.\n+      Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    }\n+\n+    // Ensure a pipeline of factor ONE can be created - no exceptions should be\n+    // raised.\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.ONE).contains(pipeline));\n+\n+    // Simulate safemode check exiting.\n+    pipelineManager.onMessage(\n+        new SCMSafeModeManager.SafeModeStatus(true, true), null);\n+    GenericTestUtils.waitFor(new Supplier<Boolean>() {\n+      @Override\n+      public Boolean get() {\n+        return pipelineManager.getPipelines().size() != 0;\n+      }\n+    }, 100, 10000);\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testSafeModeUpdatedOnSafemodeExit() throws Exception {\n+    // No timeout for pipeline scrubber.\n+    conf.setTimeDuration(\n+        OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT, -1,\n+        TimeUnit.MILLISECONDS);\n+\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    assertEquals(true, pipelineManager.getSafeModeStatus());\n+    assertEquals(false, pipelineManager.isPipelineCreationAllowed());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 443}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTkxMDI4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1NDozNlrOGf0Hpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1NDozNlrOGf0Hpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAxMjk2Ng==", "bodyText": "Can be simplified to assertTrue.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436012966", "createdAt": "2020-06-05T15:54:36Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline1 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline1.getId()));\n+    pipelines.add(pipeline1);\n+\n+    Pipeline pipeline2 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline2.getId()));\n+    pipelines.add(pipeline2);\n+    pipelineManager.close();\n+\n+    PipelineManagerV2Impl pipelineManager2 = createPipelineManager();\n+    // Should be able to load previous pipelines.\n+    Assert.assertFalse(pipelineManager.getPipelines().isEmpty());\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline3 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(3, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline3.getId()));\n+    pipelines.add(pipeline3);\n+\n+    pipelineManager2.close();\n+  }\n+\n+  @Test\n+  public void testUpdatePipelineStates() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+    PipelineID pipelineID = pipeline.getId();\n+\n+    pipelineManager.openPipeline(pipelineID);\n+    pipelineManager.addContainerToPipeline(pipelineID, ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.deactivatePipeline(pipeline.getId());\n+    Assert.assertEquals(Pipeline.PipelineState.DORMANT,\n+        pipelineManager.getPipeline(pipelineID).getPipelineState());\n+    Assert.assertFalse(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.activatePipeline(pipeline.getId());\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testRemovePipeline() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    // Create a pipeline\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+\n+    // Open the pipeline\n+    pipelineManager.openPipeline(pipeline.getId());\n+    pipelineManager\n+        .addContainerToPipeline(pipeline.getId(), ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    try {\n+      pipelineManager.removePipeline(pipeline.getId());\n+      fail();\n+    } catch (IOException ioe) {\n+      // Should not be able to remove the OPEN pipeline.\n+      Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    } catch (Exception e) {\n+      Assert.fail(\"Should not reach here.\");\n+    }\n+\n+    // Destroy pipeline\n+    pipelineManager.finalizeAndDestroyPipeline(pipeline, false);\n+    try {\n+      pipelineManager.getPipeline(pipeline.getId());\n+      fail(\"Pipeline should not have been retrieved\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(e.getMessage().contains(\"not found\"));\n+    }\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineReport() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    SCMSafeModeManager scmSafeModeManager =\n+        new SCMSafeModeManager(conf, new ArrayList<>(), pipelineManager,\n+            eventQueue);\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+\n+    // pipeline is not healthy until all dns report\n+    List<DatanodeDetails> nodes = pipeline.getNodes();\n+    Assert.assertFalse(\n+        pipelineManager.getPipeline(pipeline.getId()).isHealthy());\n+    // get pipeline report from each dn in the pipeline\n+    PipelineReportHandler pipelineReportHandler =\n+        new PipelineReportHandler(scmSafeModeManager, pipelineManager, conf);\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    // pipeline is healthy when all dns report\n+    Assert\n+        .assertTrue(pipelineManager.getPipeline(pipeline.getId()).isHealthy());\n+    // pipeline should now move to open state\n+    Assert\n+        .assertTrue(pipelineManager.getPipeline(pipeline.getId()).isOpen());\n+\n+    // close the pipeline\n+    pipelineManager.finalizeAndDestroyPipeline(pipeline, false);\n+\n+    // pipeline report for destroyed pipeline should be ignored\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    try {\n+      pipelineManager.getPipeline(pipeline.getId());\n+      fail(\"Pipeline should not have been retrieved\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(e.getMessage().contains(\"not found\"));\n+    }\n+\n+    // clean up\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineCreationFailedMetric() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+\n+    // No pipeline at start\n+    MetricsRecordBuilder metrics = getMetrics(\n+        SCMPipelineMetrics.class.getSimpleName());\n+    long numPipelineAllocated = getLongCounter(\"NumPipelineAllocated\",\n+        metrics);\n+    Assert.assertEquals(0, numPipelineAllocated);\n+\n+    // 3 DNs are unhealthy.\n+    // Create 5 pipelines (Use up 15 Datanodes)\n+\n+    for (int i = 0; i < maxPipelineCount; i++) {\n+      Pipeline pipeline = pipelineManager\n+          .createPipeline(HddsProtos.ReplicationType.RATIS,\n+              HddsProtos.ReplicationFactor.THREE);\n+      Assert.assertNotNull(pipeline);\n+    }\n+\n+    metrics = getMetrics(\n+        SCMPipelineMetrics.class.getSimpleName());\n+    numPipelineAllocated = getLongCounter(\"NumPipelineAllocated\", metrics);\n+    Assert.assertEquals(maxPipelineCount, numPipelineAllocated);\n+\n+    long numPipelineCreateFailed = getLongCounter(\n+        \"NumPipelineCreationFailed\", metrics);\n+    Assert.assertEquals(0, numPipelineCreateFailed);\n+\n+    //This should fail...\n+    try {\n+      pipelineManager.createPipeline(HddsProtos.ReplicationType.RATIS,\n+          HddsProtos.ReplicationFactor.THREE);\n+      fail();\n+    } catch (SCMException ioe) {\n+      // pipeline creation failed this time.\n+      Assert.assertEquals(SCMException.ResultCodes.FAILED_TO_FIND_SUITABLE_NODE,\n+          ioe.getResult());\n+    }\n+\n+    metrics = getMetrics(\n+        SCMPipelineMetrics.class.getSimpleName());\n+    numPipelineAllocated = getLongCounter(\"NumPipelineAllocated\", metrics);\n+    Assert.assertEquals(maxPipelineCount, numPipelineAllocated);\n+\n+    numPipelineCreateFailed = getLongCounter(\n+        \"NumPipelineCreationFailed\", metrics);\n+    Assert.assertEquals(1, numPipelineCreateFailed);\n+\n+    // clean up\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineOpenOnlyWhenLeaderReported() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+\n+    pipelineManager.onMessage(\n+        new SCMSafeModeManager.SafeModeStatus(true, true), null);\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+    // close manager\n+    pipelineManager.close();\n+    // new pipeline manager loads the pipelines from the db in ALLOCATED state\n+    pipelineManager = createPipelineManager();\n+    Assert.assertEquals(Pipeline.PipelineState.ALLOCATED,\n+        pipelineManager.getPipeline(pipeline.getId()).getPipelineState());\n+\n+    SCMSafeModeManager scmSafeModeManager =\n+        new SCMSafeModeManager(new OzoneConfiguration(),\n+            new ArrayList<>(), pipelineManager, eventQueue);\n+    PipelineReportHandler pipelineReportHandler =\n+        new PipelineReportHandler(scmSafeModeManager, pipelineManager, conf);\n+\n+    // Report pipelines with leaders\n+    List<DatanodeDetails> nodes = pipeline.getNodes();\n+    Assert.assertEquals(3, nodes.size());\n+    // Send report for all but no leader\n+    nodes.forEach(dn -> sendPipelineReport(dn, pipeline, pipelineReportHandler,\n+        false));\n+\n+    Assert.assertEquals(Pipeline.PipelineState.ALLOCATED,\n+        pipelineManager.getPipeline(pipeline.getId()).getPipelineState());\n+\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    Assert.assertEquals(Pipeline.PipelineState.OPEN,\n+        pipelineManager.getPipeline(pipeline.getId()).getPipelineState());\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testScrubPipeline() throws Exception {\n+    // No timeout for pipeline scrubber.\n+    conf.setTimeDuration(\n+        OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT, -1,\n+        TimeUnit.MILLISECONDS);\n+\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+    // At this point, pipeline is not at OPEN stage.\n+    Assert.assertEquals(Pipeline.PipelineState.ALLOCATED,\n+        pipeline.getPipelineState());\n+\n+    // pipeline should be seen in pipelineManager as ALLOCATED.\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.ALLOCATED).contains(pipeline));\n+    pipelineManager.scrubPipeline(HddsProtos.ReplicationType.RATIS,\n+        HddsProtos.ReplicationFactor.THREE);\n+\n+    // pipeline should be scrubbed.\n+    Assert.assertFalse(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.ALLOCATED).contains(pipeline));\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineNotCreatedUntilSafeModePrecheck() throws Exception {\n+    // No timeout for pipeline scrubber.\n+    conf.setTimeDuration(\n+        OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT, -1,\n+        TimeUnit.MILLISECONDS);\n+\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    try {\n+      pipelineManager.createPipeline(HddsProtos.ReplicationType.RATIS,\n+              HddsProtos.ReplicationFactor.THREE);\n+      fail(\"Pipelines should not have been created\");\n+    } catch (IOException e) {\n+      // No pipeline is created.\n+      Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    }\n+\n+    // Ensure a pipeline of factor ONE can be created - no exceptions should be\n+    // raised.\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.ONE).contains(pipeline));\n+\n+    // Simulate safemode check exiting.\n+    pipelineManager.onMessage(\n+        new SCMSafeModeManager.SafeModeStatus(true, true), null);\n+    GenericTestUtils.waitFor(new Supplier<Boolean>() {\n+      @Override\n+      public Boolean get() {\n+        return pipelineManager.getPipelines().size() != 0;\n+      }\n+    }, 100, 10000);\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testSafeModeUpdatedOnSafemodeExit() throws Exception {\n+    // No timeout for pipeline scrubber.\n+    conf.setTimeDuration(\n+        OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT, -1,\n+        TimeUnit.MILLISECONDS);\n+\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    assertEquals(true, pipelineManager.getSafeModeStatus());\n+    assertEquals(false, pipelineManager.isPipelineCreationAllowed());\n+    // First pass pre-check as true, but safemode still on\n+    pipelineManager.onMessage(\n+        new SCMSafeModeManager.SafeModeStatus(true, true), null);\n+    assertEquals(true, pipelineManager.getSafeModeStatus());\n+    assertEquals(true, pipelineManager.isPipelineCreationAllowed());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 448}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNTkxMTY3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1NDo1M1rOGf0IZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNTo1NDo1M1rOGf0IZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAxMzE1Nw==", "bodyText": "Can be simplified to assertTrue and assertFalse.", "url": "https://github.com/apache/ozone/pull/1019#discussion_r436013157", "createdAt": "2020-06-05T15:54:53Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelineManagerImpl.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Supplier;\n+import org.apache.hadoop.fs.FileUtil;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.TestUtils;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.MockNodeManager;\n+import org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl;\n+import org.apache.hadoop.hdds.scm.exceptions.SCMException;\n+import org.apache.hadoop.hdds.scm.ha.MockSCMHAManager;\n+import org.apache.hadoop.hdds.scm.metadata.SCMDBDefinition;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.hdds.utils.db.DBStore;\n+import org.apache.hadoop.hdds.utils.db.DBStoreBuilder;\n+import org.apache.hadoop.metrics2.MetricsRecordBuilder;\n+import org.apache.hadoop.ozone.container.common.SCMTestUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT;\n+import static org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState.ALLOCATED;\n+import static org.apache.hadoop.test.MetricsAsserts.getLongCounter;\n+import static org.apache.hadoop.test.MetricsAsserts.getMetrics;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for PipelineManagerImpl.\n+ */\n+public class TestPipelineManagerImpl {\n+  private static OzoneConfiguration conf;\n+  private static File testDir;\n+  private DBStore dbStore;\n+  private static MockNodeManager nodeManager;\n+  private static int maxPipelineCount;\n+  private static EventQueue eventQueue;\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = SCMTestUtils.getConf();\n+    testDir = GenericTestUtils.getTestDir(\n+        TestContainerManagerImpl.class.getSimpleName() + UUID.randomUUID());\n+    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, testDir.getAbsolutePath());\n+    dbStore = DBStoreBuilder.createDBStore(conf, new SCMDBDefinition());\n+    nodeManager = new MockNodeManager(true, 20);\n+    eventQueue = new EventQueue();\n+    maxPipelineCount = nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY) *\n+        conf.getInt(OZONE_DATANODE_PIPELINE_LIMIT,\n+            OZONE_DATANODE_PIPELINE_LIMIT_DEFAULT) /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+  }\n+\n+  @After\n+  public void cleanup() throws Exception {\n+    if (dbStore != null) {\n+      dbStore.close();\n+    }\n+    FileUtil.fullyDelete(testDir);\n+  }\n+\n+  private PipelineManagerV2Impl createPipelineManager()\n+      throws IOException {\n+    return PipelineManagerV2Impl.newPipelineManager(\n+        conf, MockSCMHAManager.getInstance(),\n+        nodeManager,\n+        SCMDBDefinition.PIPELINES.getTable(dbStore), eventQueue);\n+  }\n+\n+  @Test\n+  public void testCreatePipeline() throws Exception {\n+    List<Pipeline> pipelines = new ArrayList<>();\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline1 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline1.getId()));\n+    pipelines.add(pipeline1);\n+\n+    Pipeline pipeline2 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline2.getId()));\n+    pipelines.add(pipeline2);\n+    pipelineManager.close();\n+\n+    PipelineManagerV2Impl pipelineManager2 = createPipelineManager();\n+    // Should be able to load previous pipelines.\n+    Assert.assertFalse(pipelineManager.getPipelines().isEmpty());\n+    Assert.assertEquals(2, pipelineManager.getPipelines().size());\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline3 = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(3, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline3.getId()));\n+    pipelines.add(pipeline3);\n+\n+    pipelineManager2.close();\n+  }\n+\n+  @Test\n+  public void testUpdatePipelineStates() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+    PipelineID pipelineID = pipeline.getId();\n+\n+    pipelineManager.openPipeline(pipelineID);\n+    pipelineManager.addContainerToPipeline(pipelineID, ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.deactivatePipeline(pipeline.getId());\n+    Assert.assertEquals(Pipeline.PipelineState.DORMANT,\n+        pipelineManager.getPipeline(pipelineID).getPipelineState());\n+    Assert.assertFalse(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.activatePipeline(pipeline.getId());\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testRemovePipeline() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    // Create a pipeline\n+    Pipeline pipeline = pipelineManager.createPipeline(\n+        HddsProtos.ReplicationType.RATIS, HddsProtos.ReplicationFactor.THREE);\n+    Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    Assert.assertTrue(pipelineManager.containsPipeline(pipeline.getId()));\n+    Assert.assertTrue(pipeline.getPipelineState() == ALLOCATED);\n+\n+    // Open the pipeline\n+    pipelineManager.openPipeline(pipeline.getId());\n+    pipelineManager\n+        .addContainerToPipeline(pipeline.getId(), ContainerID.valueof(1));\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.OPEN).contains(pipeline));\n+\n+    try {\n+      pipelineManager.removePipeline(pipeline.getId());\n+      fail();\n+    } catch (IOException ioe) {\n+      // Should not be able to remove the OPEN pipeline.\n+      Assert.assertEquals(1, pipelineManager.getPipelines().size());\n+    } catch (Exception e) {\n+      Assert.fail(\"Should not reach here.\");\n+    }\n+\n+    // Destroy pipeline\n+    pipelineManager.finalizeAndDestroyPipeline(pipeline, false);\n+    try {\n+      pipelineManager.getPipeline(pipeline.getId());\n+      fail(\"Pipeline should not have been retrieved\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(e.getMessage().contains(\"not found\"));\n+    }\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineReport() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    SCMSafeModeManager scmSafeModeManager =\n+        new SCMSafeModeManager(conf, new ArrayList<>(), pipelineManager,\n+            eventQueue);\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+\n+    // pipeline is not healthy until all dns report\n+    List<DatanodeDetails> nodes = pipeline.getNodes();\n+    Assert.assertFalse(\n+        pipelineManager.getPipeline(pipeline.getId()).isHealthy());\n+    // get pipeline report from each dn in the pipeline\n+    PipelineReportHandler pipelineReportHandler =\n+        new PipelineReportHandler(scmSafeModeManager, pipelineManager, conf);\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    // pipeline is healthy when all dns report\n+    Assert\n+        .assertTrue(pipelineManager.getPipeline(pipeline.getId()).isHealthy());\n+    // pipeline should now move to open state\n+    Assert\n+        .assertTrue(pipelineManager.getPipeline(pipeline.getId()).isOpen());\n+\n+    // close the pipeline\n+    pipelineManager.finalizeAndDestroyPipeline(pipeline, false);\n+\n+    // pipeline report for destroyed pipeline should be ignored\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    try {\n+      pipelineManager.getPipeline(pipeline.getId());\n+      fail(\"Pipeline should not have been retrieved\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(e.getMessage().contains(\"not found\"));\n+    }\n+\n+    // clean up\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineCreationFailedMetric() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+\n+    // No pipeline at start\n+    MetricsRecordBuilder metrics = getMetrics(\n+        SCMPipelineMetrics.class.getSimpleName());\n+    long numPipelineAllocated = getLongCounter(\"NumPipelineAllocated\",\n+        metrics);\n+    Assert.assertEquals(0, numPipelineAllocated);\n+\n+    // 3 DNs are unhealthy.\n+    // Create 5 pipelines (Use up 15 Datanodes)\n+\n+    for (int i = 0; i < maxPipelineCount; i++) {\n+      Pipeline pipeline = pipelineManager\n+          .createPipeline(HddsProtos.ReplicationType.RATIS,\n+              HddsProtos.ReplicationFactor.THREE);\n+      Assert.assertNotNull(pipeline);\n+    }\n+\n+    metrics = getMetrics(\n+        SCMPipelineMetrics.class.getSimpleName());\n+    numPipelineAllocated = getLongCounter(\"NumPipelineAllocated\", metrics);\n+    Assert.assertEquals(maxPipelineCount, numPipelineAllocated);\n+\n+    long numPipelineCreateFailed = getLongCounter(\n+        \"NumPipelineCreationFailed\", metrics);\n+    Assert.assertEquals(0, numPipelineCreateFailed);\n+\n+    //This should fail...\n+    try {\n+      pipelineManager.createPipeline(HddsProtos.ReplicationType.RATIS,\n+          HddsProtos.ReplicationFactor.THREE);\n+      fail();\n+    } catch (SCMException ioe) {\n+      // pipeline creation failed this time.\n+      Assert.assertEquals(SCMException.ResultCodes.FAILED_TO_FIND_SUITABLE_NODE,\n+          ioe.getResult());\n+    }\n+\n+    metrics = getMetrics(\n+        SCMPipelineMetrics.class.getSimpleName());\n+    numPipelineAllocated = getLongCounter(\"NumPipelineAllocated\", metrics);\n+    Assert.assertEquals(maxPipelineCount, numPipelineAllocated);\n+\n+    numPipelineCreateFailed = getLongCounter(\n+        \"NumPipelineCreationFailed\", metrics);\n+    Assert.assertEquals(1, numPipelineCreateFailed);\n+\n+    // clean up\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineOpenOnlyWhenLeaderReported() throws Exception {\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+\n+    pipelineManager.onMessage(\n+        new SCMSafeModeManager.SafeModeStatus(true, true), null);\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+    // close manager\n+    pipelineManager.close();\n+    // new pipeline manager loads the pipelines from the db in ALLOCATED state\n+    pipelineManager = createPipelineManager();\n+    Assert.assertEquals(Pipeline.PipelineState.ALLOCATED,\n+        pipelineManager.getPipeline(pipeline.getId()).getPipelineState());\n+\n+    SCMSafeModeManager scmSafeModeManager =\n+        new SCMSafeModeManager(new OzoneConfiguration(),\n+            new ArrayList<>(), pipelineManager, eventQueue);\n+    PipelineReportHandler pipelineReportHandler =\n+        new PipelineReportHandler(scmSafeModeManager, pipelineManager, conf);\n+\n+    // Report pipelines with leaders\n+    List<DatanodeDetails> nodes = pipeline.getNodes();\n+    Assert.assertEquals(3, nodes.size());\n+    // Send report for all but no leader\n+    nodes.forEach(dn -> sendPipelineReport(dn, pipeline, pipelineReportHandler,\n+        false));\n+\n+    Assert.assertEquals(Pipeline.PipelineState.ALLOCATED,\n+        pipelineManager.getPipeline(pipeline.getId()).getPipelineState());\n+\n+    nodes.subList(0, 2).forEach(dn -> sendPipelineReport(dn, pipeline,\n+        pipelineReportHandler, false));\n+    sendPipelineReport(nodes.get(nodes.size() - 1), pipeline,\n+        pipelineReportHandler, true);\n+\n+    Assert.assertEquals(Pipeline.PipelineState.OPEN,\n+        pipelineManager.getPipeline(pipeline.getId()).getPipelineState());\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testScrubPipeline() throws Exception {\n+    // No timeout for pipeline scrubber.\n+    conf.setTimeDuration(\n+        OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT, -1,\n+        TimeUnit.MILLISECONDS);\n+\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    pipelineManager.allowPipelineCreation();\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE);\n+    // At this point, pipeline is not at OPEN stage.\n+    Assert.assertEquals(Pipeline.PipelineState.ALLOCATED,\n+        pipeline.getPipelineState());\n+\n+    // pipeline should be seen in pipelineManager as ALLOCATED.\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.ALLOCATED).contains(pipeline));\n+    pipelineManager.scrubPipeline(HddsProtos.ReplicationType.RATIS,\n+        HddsProtos.ReplicationFactor.THREE);\n+\n+    // pipeline should be scrubbed.\n+    Assert.assertFalse(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.THREE,\n+            Pipeline.PipelineState.ALLOCATED).contains(pipeline));\n+\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testPipelineNotCreatedUntilSafeModePrecheck() throws Exception {\n+    // No timeout for pipeline scrubber.\n+    conf.setTimeDuration(\n+        OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT, -1,\n+        TimeUnit.MILLISECONDS);\n+\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    try {\n+      pipelineManager.createPipeline(HddsProtos.ReplicationType.RATIS,\n+              HddsProtos.ReplicationFactor.THREE);\n+      fail(\"Pipelines should not have been created\");\n+    } catch (IOException e) {\n+      // No pipeline is created.\n+      Assert.assertTrue(pipelineManager.getPipelines().isEmpty());\n+    }\n+\n+    // Ensure a pipeline of factor ONE can be created - no exceptions should be\n+    // raised.\n+    Pipeline pipeline = pipelineManager\n+        .createPipeline(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.ONE);\n+    Assert.assertTrue(pipelineManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS,\n+            HddsProtos.ReplicationFactor.ONE).contains(pipeline));\n+\n+    // Simulate safemode check exiting.\n+    pipelineManager.onMessage(\n+        new SCMSafeModeManager.SafeModeStatus(true, true), null);\n+    GenericTestUtils.waitFor(new Supplier<Boolean>() {\n+      @Override\n+      public Boolean get() {\n+        return pipelineManager.getPipelines().size() != 0;\n+      }\n+    }, 100, 10000);\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testSafeModeUpdatedOnSafemodeExit() throws Exception {\n+    // No timeout for pipeline scrubber.\n+    conf.setTimeDuration(\n+        OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT, -1,\n+        TimeUnit.MILLISECONDS);\n+\n+    PipelineManagerV2Impl pipelineManager = createPipelineManager();\n+    assertEquals(true, pipelineManager.getSafeModeStatus());\n+    assertEquals(false, pipelineManager.isPipelineCreationAllowed());\n+    // First pass pre-check as true, but safemode still on\n+    pipelineManager.onMessage(\n+        new SCMSafeModeManager.SafeModeStatus(true, true), null);\n+    assertEquals(true, pipelineManager.getSafeModeStatus());\n+    assertEquals(true, pipelineManager.isPipelineCreationAllowed());\n+\n+    // Then also turn safemode off\n+    pipelineManager.onMessage(\n+        new SCMSafeModeManager.SafeModeStatus(false, true), null);\n+    assertEquals(false, pipelineManager.getSafeModeStatus());\n+    assertEquals(true, pipelineManager.isPipelineCreationAllowed());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b265dfe34e1664cc9e69a73011b6647900307a9"}, "originalPosition": 454}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4218, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}