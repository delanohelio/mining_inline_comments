{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyMzc5MDMy", "number": 1049, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQyMzo0OTo0NVrOEE4prA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNzoyMjozN1rOEMLBAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTU3OTMyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQyMzo0OTo0NVrOGiyYlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzo0MDoxNlrOGi2Bow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzMDI2MA==", "bodyText": "onTimeout is  not necessary here as this is just a state update now.", "url": "https://github.com/apache/ozone/pull/1049#discussion_r439130260", "createdAt": "2020-06-11T23:49:45Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -310,102 +315,69 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n   }\n \n   /**\n-   * Finalizes pipeline in the SCM. Removes pipeline and makes rpc call to\n-   * destroy pipeline on the datanodes immediately or after timeout based on the\n-   * value of onTimeout parameter.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n-   * @param onTimeout       - if true pipeline is removed and destroyed on\n-   *                        datanodes after timeout\n-   * @throws IOException\n-   */\n-  @Override\n-  public void finalizeAndDestroyPipeline(Pipeline pipeline, boolean onTimeout)\n-      throws IOException {\n-    LOG.info(\"Destroying pipeline:{}\", pipeline);\n-    finalizePipeline(pipeline.getId());\n-    if (onTimeout) {\n-      long pipelineDestroyTimeoutInMillis =\n-          conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n-              ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n-              TimeUnit.MILLISECONDS);\n-      scheduler.schedule(() -> destroyPipeline(pipeline),\n-          pipelineDestroyTimeoutInMillis, TimeUnit.MILLISECONDS, LOG,\n-          String.format(\"Destroy pipeline failed for pipeline:%s\", pipeline));\n-    } else {\n-      destroyPipeline(pipeline);\n-    }\n-  }\n-\n-  /**\n-   * Moves the pipeline to CLOSED state and sends close container command for\n-   * all the containers in the pipeline.\n+   * Removes the pipeline from the db and pipeline state map.\n    *\n-   * @param pipelineId - ID of the pipeline to be moved to CLOSED state.\n+   * @param pipeline - pipeline to be removed\n    * @throws IOException\n    */\n-  private void finalizePipeline(PipelineID pipelineId) throws IOException {\n+  protected void removePipeline(Pipeline pipeline) throws IOException {\n+    pipelineFactory.close(pipeline.getType(), pipeline);\n+    PipelineID pipelineID = pipeline.getId();\n+    closeContainersForPipeline(pipelineID);\n     lock.writeLock().lock();\n     try {\n-      Pipeline pipeline = stateManager.getPipeline(pipelineId);\n-      if (!pipeline.isClosed()) {\n-        stateManager.updatePipelineState(pipelineId.getProtobuf(),\n-            HddsProtos.PipelineState.PIPELINE_CLOSED);\n-        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n-      }\n-\n-      // TODO fire events to datanodes for closing pipelines\n-//      Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n-//      for (ContainerID containerID : containerIDs) {\n-//        eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n-//      }\n-      metrics.removePipelineMetrics(pipelineId);\n+      stateManager.removePipeline(pipelineID.getProtobuf());\n+      metrics.incNumPipelineDestroyed();\n+    } catch (IOException ex) {\n+      metrics.incNumPipelineDestroyFailed();\n+      throw ex;\n     } finally {\n       lock.writeLock().unlock();\n     }\n   }\n \n   /**\n-   * Removes pipeline from SCM. Sends ratis command to destroy pipeline on all\n-   * the datanodes for ratis pipelines.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n+   * Fire events to close all containers related to the input pipeline.\n+   * @param pipelineId - ID of the pipeline.\n    * @throws IOException\n    */\n-  protected void destroyPipeline(Pipeline pipeline) throws IOException {\n-    pipelineFactory.close(pipeline.getType(), pipeline);\n-    // remove the pipeline from the pipeline manager\n-    removePipeline(pipeline.getId());\n-    triggerPipelineCreation();\n+  protected void closeContainersForPipeline(final PipelineID pipelineId)\n+      throws IOException {\n+    Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n+    for (ContainerID containerID : containerIDs) {\n+      eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n+    }\n   }\n \n   /**\n-   * Removes the pipeline from the db and pipeline state map.\n-   *\n-   * @param pipelineId - ID of the pipeline to be removed\n+   * put pipeline in CLOSED state.\n+   * @param pipeline - ID of the pipeline.\n+   * @param onTimeout - whether to remove pipeline after some time.\n    * @throws IOException\n    */\n-  protected void removePipeline(PipelineID pipelineId) throws IOException {\n+  @Override\n+  public void closePipeline(Pipeline pipeline, boolean onTimeout)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94027105f4d5781045a892306363313fa1422c41"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4OTkyMw==", "bodyText": "If onTimeout is false, closePipeline will remove pipeline on spot. RemovePipeline is going to close containers and remove pipeline from db as well", "url": "https://github.com/apache/ozone/pull/1049#discussion_r439189923", "createdAt": "2020-06-12T03:40:16Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -310,102 +315,69 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n   }\n \n   /**\n-   * Finalizes pipeline in the SCM. Removes pipeline and makes rpc call to\n-   * destroy pipeline on the datanodes immediately or after timeout based on the\n-   * value of onTimeout parameter.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n-   * @param onTimeout       - if true pipeline is removed and destroyed on\n-   *                        datanodes after timeout\n-   * @throws IOException\n-   */\n-  @Override\n-  public void finalizeAndDestroyPipeline(Pipeline pipeline, boolean onTimeout)\n-      throws IOException {\n-    LOG.info(\"Destroying pipeline:{}\", pipeline);\n-    finalizePipeline(pipeline.getId());\n-    if (onTimeout) {\n-      long pipelineDestroyTimeoutInMillis =\n-          conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n-              ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n-              TimeUnit.MILLISECONDS);\n-      scheduler.schedule(() -> destroyPipeline(pipeline),\n-          pipelineDestroyTimeoutInMillis, TimeUnit.MILLISECONDS, LOG,\n-          String.format(\"Destroy pipeline failed for pipeline:%s\", pipeline));\n-    } else {\n-      destroyPipeline(pipeline);\n-    }\n-  }\n-\n-  /**\n-   * Moves the pipeline to CLOSED state and sends close container command for\n-   * all the containers in the pipeline.\n+   * Removes the pipeline from the db and pipeline state map.\n    *\n-   * @param pipelineId - ID of the pipeline to be moved to CLOSED state.\n+   * @param pipeline - pipeline to be removed\n    * @throws IOException\n    */\n-  private void finalizePipeline(PipelineID pipelineId) throws IOException {\n+  protected void removePipeline(Pipeline pipeline) throws IOException {\n+    pipelineFactory.close(pipeline.getType(), pipeline);\n+    PipelineID pipelineID = pipeline.getId();\n+    closeContainersForPipeline(pipelineID);\n     lock.writeLock().lock();\n     try {\n-      Pipeline pipeline = stateManager.getPipeline(pipelineId);\n-      if (!pipeline.isClosed()) {\n-        stateManager.updatePipelineState(pipelineId.getProtobuf(),\n-            HddsProtos.PipelineState.PIPELINE_CLOSED);\n-        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n-      }\n-\n-      // TODO fire events to datanodes for closing pipelines\n-//      Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n-//      for (ContainerID containerID : containerIDs) {\n-//        eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n-//      }\n-      metrics.removePipelineMetrics(pipelineId);\n+      stateManager.removePipeline(pipelineID.getProtobuf());\n+      metrics.incNumPipelineDestroyed();\n+    } catch (IOException ex) {\n+      metrics.incNumPipelineDestroyFailed();\n+      throw ex;\n     } finally {\n       lock.writeLock().unlock();\n     }\n   }\n \n   /**\n-   * Removes pipeline from SCM. Sends ratis command to destroy pipeline on all\n-   * the datanodes for ratis pipelines.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n+   * Fire events to close all containers related to the input pipeline.\n+   * @param pipelineId - ID of the pipeline.\n    * @throws IOException\n    */\n-  protected void destroyPipeline(Pipeline pipeline) throws IOException {\n-    pipelineFactory.close(pipeline.getType(), pipeline);\n-    // remove the pipeline from the pipeline manager\n-    removePipeline(pipeline.getId());\n-    triggerPipelineCreation();\n+  protected void closeContainersForPipeline(final PipelineID pipelineId)\n+      throws IOException {\n+    Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n+    for (ContainerID containerID : containerIDs) {\n+      eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n+    }\n   }\n \n   /**\n-   * Removes the pipeline from the db and pipeline state map.\n-   *\n-   * @param pipelineId - ID of the pipeline to be removed\n+   * put pipeline in CLOSED state.\n+   * @param pipeline - ID of the pipeline.\n+   * @param onTimeout - whether to remove pipeline after some time.\n    * @throws IOException\n    */\n-  protected void removePipeline(PipelineID pipelineId) throws IOException {\n+  @Override\n+  public void closePipeline(Pipeline pipeline, boolean onTimeout)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzMDI2MA=="}, "originalCommit": {"oid": "94027105f4d5781045a892306363313fa1422c41"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTU5MjcwOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQyMzo1NzoyM1rOGiygjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzo0MDozMlrOGi2B5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzMjMwMw==", "bodyText": "pipeline in allocated state should not have container associate with it. So I think closeContainersForPipeline is only needed for scrubClosedPipeline.", "url": "https://github.com/apache/ozone/pull/1049#discussion_r439132303", "createdAt": "2020-06-11T23:57:23Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -420,10 +392,50 @@ public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n           \" since it stays at ALLOCATED stage for \" +\n           Duration.between(currentTime, p.getCreationTimestamp()).toMinutes() +\n           \" mins.\");\n-      finalizeAndDestroyPipeline(p, false);\n+      closePipeline(p, false);\n+      closeContainersForPipeline(p.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94027105f4d5781045a892306363313fa1422c41"}, "originalPosition": 195}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4OTk4OQ==", "bodyText": "Ok good catch", "url": "https://github.com/apache/ozone/pull/1049#discussion_r439189989", "createdAt": "2020-06-12T03:40:32Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -420,10 +392,50 @@ public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n           \" since it stays at ALLOCATED stage for \" +\n           Duration.between(currentTime, p.getCreationTimestamp()).toMinutes() +\n           \" mins.\");\n-      finalizeAndDestroyPipeline(p, false);\n+      closePipeline(p, false);\n+      closeContainersForPipeline(p.getId());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzMjMwMw=="}, "originalCommit": {"oid": "94027105f4d5781045a892306363313fa1422c41"}, "originalPosition": 195}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTU5NDQ4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQyMzo1ODoyN1rOGiyhsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwNjo1MDoxNVrOGi5ATA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzMjU5Mw==", "bodyText": "is it possible to dudup the code between scrub closed and allocated pipeline?", "url": "https://github.com/apache/ozone/pull/1049#discussion_r439132593", "createdAt": "2020-06-11T23:58:27Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -310,102 +315,69 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n   }\n \n   /**\n-   * Finalizes pipeline in the SCM. Removes pipeline and makes rpc call to\n-   * destroy pipeline on the datanodes immediately or after timeout based on the\n-   * value of onTimeout parameter.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n-   * @param onTimeout       - if true pipeline is removed and destroyed on\n-   *                        datanodes after timeout\n-   * @throws IOException\n-   */\n-  @Override\n-  public void finalizeAndDestroyPipeline(Pipeline pipeline, boolean onTimeout)\n-      throws IOException {\n-    LOG.info(\"Destroying pipeline:{}\", pipeline);\n-    finalizePipeline(pipeline.getId());\n-    if (onTimeout) {\n-      long pipelineDestroyTimeoutInMillis =\n-          conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n-              ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n-              TimeUnit.MILLISECONDS);\n-      scheduler.schedule(() -> destroyPipeline(pipeline),\n-          pipelineDestroyTimeoutInMillis, TimeUnit.MILLISECONDS, LOG,\n-          String.format(\"Destroy pipeline failed for pipeline:%s\", pipeline));\n-    } else {\n-      destroyPipeline(pipeline);\n-    }\n-  }\n-\n-  /**\n-   * Moves the pipeline to CLOSED state and sends close container command for\n-   * all the containers in the pipeline.\n+   * Removes the pipeline from the db and pipeline state map.\n    *\n-   * @param pipelineId - ID of the pipeline to be moved to CLOSED state.\n+   * @param pipeline - pipeline to be removed\n    * @throws IOException\n    */\n-  private void finalizePipeline(PipelineID pipelineId) throws IOException {\n+  protected void removePipeline(Pipeline pipeline) throws IOException {\n+    pipelineFactory.close(pipeline.getType(), pipeline);\n+    PipelineID pipelineID = pipeline.getId();\n+    closeContainersForPipeline(pipelineID);\n     lock.writeLock().lock();\n     try {\n-      Pipeline pipeline = stateManager.getPipeline(pipelineId);\n-      if (!pipeline.isClosed()) {\n-        stateManager.updatePipelineState(pipelineId.getProtobuf(),\n-            HddsProtos.PipelineState.PIPELINE_CLOSED);\n-        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n-      }\n-\n-      // TODO fire events to datanodes for closing pipelines\n-//      Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n-//      for (ContainerID containerID : containerIDs) {\n-//        eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n-//      }\n-      metrics.removePipelineMetrics(pipelineId);\n+      stateManager.removePipeline(pipelineID.getProtobuf());\n+      metrics.incNumPipelineDestroyed();\n+    } catch (IOException ex) {\n+      metrics.incNumPipelineDestroyFailed();\n+      throw ex;\n     } finally {\n       lock.writeLock().unlock();\n     }\n   }\n \n   /**\n-   * Removes pipeline from SCM. Sends ratis command to destroy pipeline on all\n-   * the datanodes for ratis pipelines.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n+   * Fire events to close all containers related to the input pipeline.\n+   * @param pipelineId - ID of the pipeline.\n    * @throws IOException\n    */\n-  protected void destroyPipeline(Pipeline pipeline) throws IOException {\n-    pipelineFactory.close(pipeline.getType(), pipeline);\n-    // remove the pipeline from the pipeline manager\n-    removePipeline(pipeline.getId());\n-    triggerPipelineCreation();\n+  protected void closeContainersForPipeline(final PipelineID pipelineId)\n+      throws IOException {\n+    Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n+    for (ContainerID containerID : containerIDs) {\n+      eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n+    }\n   }\n \n   /**\n-   * Removes the pipeline from the db and pipeline state map.\n-   *\n-   * @param pipelineId - ID of the pipeline to be removed\n+   * put pipeline in CLOSED state.\n+   * @param pipeline - ID of the pipeline.\n+   * @param onTimeout - whether to remove pipeline after some time.\n    * @throws IOException\n    */\n-  protected void removePipeline(PipelineID pipelineId) throws IOException {\n+  @Override\n+  public void closePipeline(Pipeline pipeline, boolean onTimeout)\n+      throws IOException {\n+    PipelineID pipelineID = pipeline.getId();\n     lock.writeLock().lock();\n     try {\n-      stateManager.removePipeline(pipelineId.getProtobuf());\n-      metrics.incNumPipelineDestroyed();\n-    } catch (IOException ex) {\n-      metrics.incNumPipelineDestroyFailed();\n-      throw ex;\n+      if (!pipeline.isClosed()) {\n+        stateManager.updatePipelineState(pipelineID.getProtobuf(),\n+            HddsProtos.PipelineState.PIPELINE_CLOSED);\n+        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n+      }\n+      metrics.removePipelineMetrics(pipelineID);\n     } finally {\n       lock.writeLock().unlock();\n     }\n+    if (!onTimeout) {\n+      removePipeline(pipeline);\n+    }\n   }\n \n-  @Override\n-  public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n-      throws IOException{\n-    if (type != ReplicationType.RATIS || factor != ReplicationFactor.THREE) {\n-      // Only srub pipeline for RATIS THREE pipeline\n-      return;\n-    }\n-    Instant currentTime = Instant.now();\n+  private void scrubAllocatedPipeline(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94027105f4d5781045a892306363313fa1422c41"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTIzODczMg==", "bodyText": "I move them into one function", "url": "https://github.com/apache/ozone/pull/1049#discussion_r439238732", "createdAt": "2020-06-12T06:50:15Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -310,102 +315,69 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n   }\n \n   /**\n-   * Finalizes pipeline in the SCM. Removes pipeline and makes rpc call to\n-   * destroy pipeline on the datanodes immediately or after timeout based on the\n-   * value of onTimeout parameter.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n-   * @param onTimeout       - if true pipeline is removed and destroyed on\n-   *                        datanodes after timeout\n-   * @throws IOException\n-   */\n-  @Override\n-  public void finalizeAndDestroyPipeline(Pipeline pipeline, boolean onTimeout)\n-      throws IOException {\n-    LOG.info(\"Destroying pipeline:{}\", pipeline);\n-    finalizePipeline(pipeline.getId());\n-    if (onTimeout) {\n-      long pipelineDestroyTimeoutInMillis =\n-          conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n-              ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n-              TimeUnit.MILLISECONDS);\n-      scheduler.schedule(() -> destroyPipeline(pipeline),\n-          pipelineDestroyTimeoutInMillis, TimeUnit.MILLISECONDS, LOG,\n-          String.format(\"Destroy pipeline failed for pipeline:%s\", pipeline));\n-    } else {\n-      destroyPipeline(pipeline);\n-    }\n-  }\n-\n-  /**\n-   * Moves the pipeline to CLOSED state and sends close container command for\n-   * all the containers in the pipeline.\n+   * Removes the pipeline from the db and pipeline state map.\n    *\n-   * @param pipelineId - ID of the pipeline to be moved to CLOSED state.\n+   * @param pipeline - pipeline to be removed\n    * @throws IOException\n    */\n-  private void finalizePipeline(PipelineID pipelineId) throws IOException {\n+  protected void removePipeline(Pipeline pipeline) throws IOException {\n+    pipelineFactory.close(pipeline.getType(), pipeline);\n+    PipelineID pipelineID = pipeline.getId();\n+    closeContainersForPipeline(pipelineID);\n     lock.writeLock().lock();\n     try {\n-      Pipeline pipeline = stateManager.getPipeline(pipelineId);\n-      if (!pipeline.isClosed()) {\n-        stateManager.updatePipelineState(pipelineId.getProtobuf(),\n-            HddsProtos.PipelineState.PIPELINE_CLOSED);\n-        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n-      }\n-\n-      // TODO fire events to datanodes for closing pipelines\n-//      Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n-//      for (ContainerID containerID : containerIDs) {\n-//        eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n-//      }\n-      metrics.removePipelineMetrics(pipelineId);\n+      stateManager.removePipeline(pipelineID.getProtobuf());\n+      metrics.incNumPipelineDestroyed();\n+    } catch (IOException ex) {\n+      metrics.incNumPipelineDestroyFailed();\n+      throw ex;\n     } finally {\n       lock.writeLock().unlock();\n     }\n   }\n \n   /**\n-   * Removes pipeline from SCM. Sends ratis command to destroy pipeline on all\n-   * the datanodes for ratis pipelines.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n+   * Fire events to close all containers related to the input pipeline.\n+   * @param pipelineId - ID of the pipeline.\n    * @throws IOException\n    */\n-  protected void destroyPipeline(Pipeline pipeline) throws IOException {\n-    pipelineFactory.close(pipeline.getType(), pipeline);\n-    // remove the pipeline from the pipeline manager\n-    removePipeline(pipeline.getId());\n-    triggerPipelineCreation();\n+  protected void closeContainersForPipeline(final PipelineID pipelineId)\n+      throws IOException {\n+    Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n+    for (ContainerID containerID : containerIDs) {\n+      eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n+    }\n   }\n \n   /**\n-   * Removes the pipeline from the db and pipeline state map.\n-   *\n-   * @param pipelineId - ID of the pipeline to be removed\n+   * put pipeline in CLOSED state.\n+   * @param pipeline - ID of the pipeline.\n+   * @param onTimeout - whether to remove pipeline after some time.\n    * @throws IOException\n    */\n-  protected void removePipeline(PipelineID pipelineId) throws IOException {\n+  @Override\n+  public void closePipeline(Pipeline pipeline, boolean onTimeout)\n+      throws IOException {\n+    PipelineID pipelineID = pipeline.getId();\n     lock.writeLock().lock();\n     try {\n-      stateManager.removePipeline(pipelineId.getProtobuf());\n-      metrics.incNumPipelineDestroyed();\n-    } catch (IOException ex) {\n-      metrics.incNumPipelineDestroyFailed();\n-      throw ex;\n+      if (!pipeline.isClosed()) {\n+        stateManager.updatePipelineState(pipelineID.getProtobuf(),\n+            HddsProtos.PipelineState.PIPELINE_CLOSED);\n+        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n+      }\n+      metrics.removePipelineMetrics(pipelineID);\n     } finally {\n       lock.writeLock().unlock();\n     }\n+    if (!onTimeout) {\n+      removePipeline(pipeline);\n+    }\n   }\n \n-  @Override\n-  public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n-      throws IOException{\n-    if (type != ReplicationType.RATIS || factor != ReplicationFactor.THREE) {\n-      // Only srub pipeline for RATIS THREE pipeline\n-      return;\n-    }\n-    Instant currentTime = Instant.now();\n+  private void scrubAllocatedPipeline(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzMjU5Mw=="}, "originalCommit": {"oid": "94027105f4d5781045a892306363313fa1422c41"}, "originalPosition": 183}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTU5NTQ1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQyMzo1OTowMVrOGiyiSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwNjo1MDowMVrOGi4_6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzMjc0Ng==", "bodyText": "Should we avoid the stream api for better performance ?", "url": "https://github.com/apache/ozone/pull/1049#discussion_r439132746", "createdAt": "2020-06-11T23:59:01Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -420,10 +392,50 @@ public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n           \" since it stays at ALLOCATED stage for \" +\n           Duration.between(currentTime, p.getCreationTimestamp()).toMinutes() +\n           \" mins.\");\n-      finalizeAndDestroyPipeline(p, false);\n+      closePipeline(p, false);\n+      closeContainersForPipeline(p.getId());\n     }\n   }\n \n+  private void scrubClosedPipeline(\n+      ReplicationType type, ReplicationFactor factor, Instant currentTime)\n+      throws IOException {\n+    long pipelineDestroyTimeoutInMillis =\n+        conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n+            ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n+            TimeUnit.MILLISECONDS);\n+    List<Pipeline> closedPipelines = stateManager.getPipelines(type, factor,\n+        Pipeline.PipelineState.CLOSED).stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94027105f4d5781045a892306363313fa1422c41"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTIzODYzNA==", "bodyText": "I updated with for loop", "url": "https://github.com/apache/ozone/pull/1049#discussion_r439238634", "createdAt": "2020-06-12T06:50:01Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -420,10 +392,50 @@ public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n           \" since it stays at ALLOCATED stage for \" +\n           Duration.between(currentTime, p.getCreationTimestamp()).toMinutes() +\n           \" mins.\");\n-      finalizeAndDestroyPipeline(p, false);\n+      closePipeline(p, false);\n+      closeContainersForPipeline(p.getId());\n     }\n   }\n \n+  private void scrubClosedPipeline(\n+      ReplicationType type, ReplicationFactor factor, Instant currentTime)\n+      throws IOException {\n+    long pipelineDestroyTimeoutInMillis =\n+        conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n+            ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n+            TimeUnit.MILLISECONDS);\n+    List<Pipeline> closedPipelines = stateManager.getPipelines(type, factor,\n+        Pipeline.PipelineState.CLOSED).stream()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzMjc0Ng=="}, "originalCommit": {"oid": "94027105f4d5781045a892306363313fa1422c41"}, "originalPosition": 207}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTI0NjYxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMzozNjoyOFrOGtH23w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwNzoxMzo0MlrOGtLZrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk2NzgzOQ==", "bodyText": "this synchronized seems not necessary ?", "url": "https://github.com/apache/ozone/pull/1049#discussion_r449967839", "createdAt": "2020-07-06T03:36:28Z", "author": {"login": "GlenGeng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -130,7 +134,7 @@ public static PipelineManagerV2Impl newPipelineManager(\n   }\n \n   @Override\n-  public Pipeline createPipeline(ReplicationType type,\n+  public synchronized Pipeline createPipeline(ReplicationType type,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50929247a1da2eb3a36bff075cf447114a62ae28"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAyNTkwMA==", "bodyText": "Deleted.", "url": "https://github.com/apache/ozone/pull/1049#discussion_r450025900", "createdAt": "2020-07-06T07:13:42Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -130,7 +134,7 @@ public static PipelineManagerV2Impl newPipelineManager(\n   }\n \n   @Override\n-  public Pipeline createPipeline(ReplicationType type,\n+  public synchronized Pipeline createPipeline(ReplicationType type,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk2NzgzOQ=="}, "originalCommit": {"oid": "50929247a1da2eb3a36bff075cf447114a62ae28"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTI2OTA4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwMzo1NDoyNlrOGtIDow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwNzoxMzoyNlrOGtLZOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk3MTEwNw==", "bodyText": "From a Datanode side, will it be better if close container before close pipeline? Call pipelineFactory.close() before closeContainersForPipeline()  will send out ClosePipelineCommand ahead of CloseContainerCommand, which will make container unhealthy.\nRefer to CloseContainerCommandHandler\n      switch (container.getContainerState()) {\n      case OPEN:\n      case CLOSING:\n        // If the container is part of open pipeline, close it via write channel\n        if (ozoneContainer.getWriteChannel()\n            .isExist(closeCommand.getPipelineID())) {\n          ContainerCommandRequestProto request =\n              getContainerCommandRequestProto(datanodeDetails,\n                  closeCommand.getContainerID());\n          ozoneContainer.getWriteChannel()\n              .submitRequest(request, closeCommand.getPipelineID());\n        } else {\n          // Container should not exist in CLOSING state without a pipeline\n          controller.markContainerUnhealthy(containerId);\n        }", "url": "https://github.com/apache/ozone/pull/1049#discussion_r449971107", "createdAt": "2020-07-06T03:54:26Z", "author": {"login": "GlenGeng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -310,94 +321,72 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n   }\n \n   /**\n-   * Finalizes pipeline in the SCM. Removes pipeline and makes rpc call to\n-   * destroy pipeline on the datanodes immediately or after timeout based on the\n-   * value of onTimeout parameter.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n-   * @param onTimeout       - if true pipeline is removed and destroyed on\n-   *                        datanodes after timeout\n-   * @throws IOException\n-   */\n-  @Override\n-  public void finalizeAndDestroyPipeline(Pipeline pipeline, boolean onTimeout)\n-      throws IOException {\n-    LOG.info(\"Destroying pipeline:{}\", pipeline);\n-    finalizePipeline(pipeline.getId());\n-    if (onTimeout) {\n-      long pipelineDestroyTimeoutInMillis =\n-          conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n-              ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n-              TimeUnit.MILLISECONDS);\n-      scheduler.schedule(() -> destroyPipeline(pipeline),\n-          pipelineDestroyTimeoutInMillis, TimeUnit.MILLISECONDS, LOG,\n-          String.format(\"Destroy pipeline failed for pipeline:%s\", pipeline));\n-    } else {\n-      destroyPipeline(pipeline);\n-    }\n-  }\n-\n-  /**\n-   * Moves the pipeline to CLOSED state and sends close container command for\n-   * all the containers in the pipeline.\n+   * Removes the pipeline from the db and pipeline state map.\n    *\n-   * @param pipelineId - ID of the pipeline to be moved to CLOSED state.\n+   * @param pipeline - pipeline to be removed\n    * @throws IOException\n    */\n-  private void finalizePipeline(PipelineID pipelineId) throws IOException {\n+  protected void removePipeline(Pipeline pipeline) throws IOException {\n+    pipelineFactory.close(pipeline.getType(), pipeline);\n+    PipelineID pipelineID = pipeline.getId();\n     lock.writeLock().lock();\n     try {\n-      Pipeline pipeline = stateManager.getPipeline(pipelineId);\n-      if (!pipeline.isClosed()) {\n-        stateManager.updatePipelineState(\n-            pipelineId.getProtobuf(), HddsProtos.PipelineState.PIPELINE_CLOSED);\n-        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n-      }\n-\n-      // TODO fire events to datanodes for closing pipelines\n-//      Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n-//      for (ContainerID containerID : containerIDs) {\n-//        eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n-//      }\n-      metrics.removePipelineMetrics(pipelineId);\n+      closeContainersForPipeline(pipelineID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "50929247a1da2eb3a36bff075cf447114a62ae28"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAyNTc4Ng==", "bodyText": "Updated in PipelineManagerV2. That was a mistake. Thanks for the review", "url": "https://github.com/apache/ozone/pull/1049#discussion_r450025786", "createdAt": "2020-07-06T07:13:26Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -310,94 +321,72 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n   }\n \n   /**\n-   * Finalizes pipeline in the SCM. Removes pipeline and makes rpc call to\n-   * destroy pipeline on the datanodes immediately or after timeout based on the\n-   * value of onTimeout parameter.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n-   * @param onTimeout       - if true pipeline is removed and destroyed on\n-   *                        datanodes after timeout\n-   * @throws IOException\n-   */\n-  @Override\n-  public void finalizeAndDestroyPipeline(Pipeline pipeline, boolean onTimeout)\n-      throws IOException {\n-    LOG.info(\"Destroying pipeline:{}\", pipeline);\n-    finalizePipeline(pipeline.getId());\n-    if (onTimeout) {\n-      long pipelineDestroyTimeoutInMillis =\n-          conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n-              ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n-              TimeUnit.MILLISECONDS);\n-      scheduler.schedule(() -> destroyPipeline(pipeline),\n-          pipelineDestroyTimeoutInMillis, TimeUnit.MILLISECONDS, LOG,\n-          String.format(\"Destroy pipeline failed for pipeline:%s\", pipeline));\n-    } else {\n-      destroyPipeline(pipeline);\n-    }\n-  }\n-\n-  /**\n-   * Moves the pipeline to CLOSED state and sends close container command for\n-   * all the containers in the pipeline.\n+   * Removes the pipeline from the db and pipeline state map.\n    *\n-   * @param pipelineId - ID of the pipeline to be moved to CLOSED state.\n+   * @param pipeline - pipeline to be removed\n    * @throws IOException\n    */\n-  private void finalizePipeline(PipelineID pipelineId) throws IOException {\n+  protected void removePipeline(Pipeline pipeline) throws IOException {\n+    pipelineFactory.close(pipeline.getType(), pipeline);\n+    PipelineID pipelineID = pipeline.getId();\n     lock.writeLock().lock();\n     try {\n-      Pipeline pipeline = stateManager.getPipeline(pipelineId);\n-      if (!pipeline.isClosed()) {\n-        stateManager.updatePipelineState(\n-            pipelineId.getProtobuf(), HddsProtos.PipelineState.PIPELINE_CLOSED);\n-        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n-      }\n-\n-      // TODO fire events to datanodes for closing pipelines\n-//      Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n-//      for (ContainerID containerID : containerIDs) {\n-//        eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n-//      }\n-      metrics.removePipelineMetrics(pipelineId);\n+      closeContainersForPipeline(pipelineID);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk3MTEwNw=="}, "originalCommit": {"oid": "50929247a1da2eb3a36bff075cf447114a62ae28"}, "originalPosition": 137}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxMTk4MDYxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNzoyMDoyNlrOGuITAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwMzoyNTowNlrOGvoo5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTAyMzYxNw==", "bodyText": "Do we need to check the time against ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT since it enter into the CLOSED state before closecontainer and removepipeline?", "url": "https://github.com/apache/ozone/pull/1049#discussion_r451023617", "createdAt": "2020-07-07T17:20:26Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -410,18 +399,29 @@ public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n         ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT,\n         ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT_DEFAULT,\n         TimeUnit.MILLISECONDS);\n-    List<Pipeline> needToSrubPipelines = stateManager.getPipelines(type, factor,\n-        Pipeline.PipelineState.ALLOCATED).stream()\n-        .filter(p -> currentTime.toEpochMilli() - p.getCreationTimestamp()\n-            .toEpochMilli() >= pipelineScrubTimeoutInMills)\n-        .collect(Collectors.toList());\n-    for (Pipeline p : needToSrubPipelines) {\n-      LOG.info(\"Scrubbing pipeline: id: \" + p.getId().toString() +\n-          \" since it stays at ALLOCATED stage for \" +\n-          Duration.between(currentTime, p.getCreationTimestamp()).toMinutes() +\n-          \" mins.\");\n-      finalizeAndDestroyPipeline(p, false);\n+\n+    List<Pipeline> candidates = stateManager.getPipelines(type, factor);\n+\n+    for (Pipeline p : candidates) {\n+      // scrub pipelines who stay ALLOCATED for too long.\n+      if (p.getPipelineState() == Pipeline.PipelineState.ALLOCATED &&\n+          (currentTime.toEpochMilli() - p.getCreationTimestamp()\n+              .toEpochMilli() >= pipelineScrubTimeoutInMills)) {\n+        LOG.info(\"Scrubbing pipeline: id: \" + p.getId().toString() +\n+            \" since it stays at ALLOCATED stage for \" +\n+            Duration.between(currentTime, p.getCreationTimestamp())\n+                .toMinutes() + \" mins.\");\n+        closePipeline(p, false);\n+      }\n+      // scrub pipelines who stay CLOSED for too long.\n+      if (p.getPipelineState() == Pipeline.PipelineState.CLOSED) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5a7a822b3b7f7e1b6934cca992ec28ae6fe77f1e"}, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ4MjQyOQ==", "bodyText": "I feel like once pipeline is at CLOSED state, it can be removed right away since it has no chance getting back to OPEN. So I remove the OZONE_SCM_PIPELINE_DESTROY_TIMEOUT check here.", "url": "https://github.com/apache/ozone/pull/1049#discussion_r451482429", "createdAt": "2020-07-08T11:50:29Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -410,18 +399,29 @@ public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n         ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT,\n         ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT_DEFAULT,\n         TimeUnit.MILLISECONDS);\n-    List<Pipeline> needToSrubPipelines = stateManager.getPipelines(type, factor,\n-        Pipeline.PipelineState.ALLOCATED).stream()\n-        .filter(p -> currentTime.toEpochMilli() - p.getCreationTimestamp()\n-            .toEpochMilli() >= pipelineScrubTimeoutInMills)\n-        .collect(Collectors.toList());\n-    for (Pipeline p : needToSrubPipelines) {\n-      LOG.info(\"Scrubbing pipeline: id: \" + p.getId().toString() +\n-          \" since it stays at ALLOCATED stage for \" +\n-          Duration.between(currentTime, p.getCreationTimestamp()).toMinutes() +\n-          \" mins.\");\n-      finalizeAndDestroyPipeline(p, false);\n+\n+    List<Pipeline> candidates = stateManager.getPipelines(type, factor);\n+\n+    for (Pipeline p : candidates) {\n+      // scrub pipelines who stay ALLOCATED for too long.\n+      if (p.getPipelineState() == Pipeline.PipelineState.ALLOCATED &&\n+          (currentTime.toEpochMilli() - p.getCreationTimestamp()\n+              .toEpochMilli() >= pipelineScrubTimeoutInMills)) {\n+        LOG.info(\"Scrubbing pipeline: id: \" + p.getId().toString() +\n+            \" since it stays at ALLOCATED stage for \" +\n+            Duration.between(currentTime, p.getCreationTimestamp())\n+                .toMinutes() + \" mins.\");\n+        closePipeline(p, false);\n+      }\n+      // scrub pipelines who stay CLOSED for too long.\n+      if (p.getPipelineState() == Pipeline.PipelineState.CLOSED) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTAyMzYxNw=="}, "originalCommit": {"oid": "5a7a822b3b7f7e1b6934cca992ec28ae6fe77f1e"}, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYwMjA4NQ==", "bodyText": "I updated with the scheduler to schedule removing pipeline after closing contaienrs.", "url": "https://github.com/apache/ozone/pull/1049#discussion_r452602085", "createdAt": "2020-07-10T03:25:06Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -410,18 +399,29 @@ public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n         ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT,\n         ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT_DEFAULT,\n         TimeUnit.MILLISECONDS);\n-    List<Pipeline> needToSrubPipelines = stateManager.getPipelines(type, factor,\n-        Pipeline.PipelineState.ALLOCATED).stream()\n-        .filter(p -> currentTime.toEpochMilli() - p.getCreationTimestamp()\n-            .toEpochMilli() >= pipelineScrubTimeoutInMills)\n-        .collect(Collectors.toList());\n-    for (Pipeline p : needToSrubPipelines) {\n-      LOG.info(\"Scrubbing pipeline: id: \" + p.getId().toString() +\n-          \" since it stays at ALLOCATED stage for \" +\n-          Duration.between(currentTime, p.getCreationTimestamp()).toMinutes() +\n-          \" mins.\");\n-      finalizeAndDestroyPipeline(p, false);\n+\n+    List<Pipeline> candidates = stateManager.getPipelines(type, factor);\n+\n+    for (Pipeline p : candidates) {\n+      // scrub pipelines who stay ALLOCATED for too long.\n+      if (p.getPipelineState() == Pipeline.PipelineState.ALLOCATED &&\n+          (currentTime.toEpochMilli() - p.getCreationTimestamp()\n+              .toEpochMilli() >= pipelineScrubTimeoutInMills)) {\n+        LOG.info(\"Scrubbing pipeline: id: \" + p.getId().toString() +\n+            \" since it stays at ALLOCATED stage for \" +\n+            Duration.between(currentTime, p.getCreationTimestamp())\n+                .toMinutes() + \" mins.\");\n+        closePipeline(p, false);\n+      }\n+      // scrub pipelines who stay CLOSED for too long.\n+      if (p.getPipelineState() == Pipeline.PipelineState.CLOSED) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTAyMzYxNw=="}, "originalCommit": {"oid": "5a7a822b3b7f7e1b6934cca992ec28ae6fe77f1e"}, "originalPosition": 235}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxMTk4NDc0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNzoyMTozN1rOGuIVmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQwNzoyMDozOFrOGubOoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTAyNDI4Mg==", "bodyText": "how do we handle onTimeout==True? Do we assume pipeline scrubber to handle this below?", "url": "https://github.com/apache/ozone/pull/1049#discussion_r451024282", "createdAt": "2020-07-07T17:21:37Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -310,94 +321,72 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n   }\n \n   /**\n-   * Finalizes pipeline in the SCM. Removes pipeline and makes rpc call to\n-   * destroy pipeline on the datanodes immediately or after timeout based on the\n-   * value of onTimeout parameter.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n-   * @param onTimeout       - if true pipeline is removed and destroyed on\n-   *                        datanodes after timeout\n-   * @throws IOException\n-   */\n-  @Override\n-  public void finalizeAndDestroyPipeline(Pipeline pipeline, boolean onTimeout)\n-      throws IOException {\n-    LOG.info(\"Destroying pipeline:{}\", pipeline);\n-    finalizePipeline(pipeline.getId());\n-    if (onTimeout) {\n-      long pipelineDestroyTimeoutInMillis =\n-          conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n-              ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n-              TimeUnit.MILLISECONDS);\n-      scheduler.schedule(() -> destroyPipeline(pipeline),\n-          pipelineDestroyTimeoutInMillis, TimeUnit.MILLISECONDS, LOG,\n-          String.format(\"Destroy pipeline failed for pipeline:%s\", pipeline));\n-    } else {\n-      destroyPipeline(pipeline);\n-    }\n-  }\n-\n-  /**\n-   * Moves the pipeline to CLOSED state and sends close container command for\n-   * all the containers in the pipeline.\n+   * Removes the pipeline from the db and pipeline state map.\n    *\n-   * @param pipelineId - ID of the pipeline to be moved to CLOSED state.\n+   * @param pipeline - pipeline to be removed\n    * @throws IOException\n    */\n-  private void finalizePipeline(PipelineID pipelineId) throws IOException {\n+  protected void removePipeline(Pipeline pipeline) throws IOException {\n+    pipelineFactory.close(pipeline.getType(), pipeline);\n+    PipelineID pipelineID = pipeline.getId();\n     lock.writeLock().lock();\n     try {\n-      Pipeline pipeline = stateManager.getPipeline(pipelineId);\n-      if (!pipeline.isClosed()) {\n-        stateManager.updatePipelineState(\n-            pipelineId.getProtobuf(), HddsProtos.PipelineState.PIPELINE_CLOSED);\n-        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n-      }\n-\n-      // TODO fire events to datanodes for closing pipelines\n-//      Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n-//      for (ContainerID containerID : containerIDs) {\n-//        eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n-//      }\n-      metrics.removePipelineMetrics(pipelineId);\n+      stateManager.removePipeline(pipelineID.getProtobuf());\n+      metrics.incNumPipelineDestroyed();\n+    } catch (IOException ex) {\n+      metrics.incNumPipelineDestroyFailed();\n+      throw ex;\n     } finally {\n       lock.writeLock().unlock();\n     }\n   }\n \n   /**\n-   * Removes pipeline from SCM. Sends ratis command to destroy pipeline on all\n-   * the datanodes for ratis pipelines.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n+   * Fire events to close all containers related to the input pipeline.\n+   * @param pipelineId - ID of the pipeline.\n    * @throws IOException\n    */\n-  protected void destroyPipeline(Pipeline pipeline) throws IOException {\n-    pipelineFactory.close(pipeline.getType(), pipeline);\n-    // remove the pipeline from the pipeline manager\n-    removePipeline(pipeline.getId());\n-    triggerPipelineCreation();\n+  protected void closeContainersForPipeline(final PipelineID pipelineId)\n+      throws IOException {\n+    Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n+    for (ContainerID containerID : containerIDs) {\n+      eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n+    }\n   }\n \n   /**\n-   * Removes the pipeline from the db and pipeline state map.\n-   *\n-   * @param pipelineId - ID of the pipeline to be removed\n+   * put pipeline in CLOSED state.\n+   * @param pipeline - ID of the pipeline.\n+   * @param onTimeout - whether to remove pipeline after some time.\n    * @throws IOException\n    */\n-  protected void removePipeline(PipelineID pipelineId) throws IOException {\n+  @Override\n+  public void closePipeline(Pipeline pipeline, boolean onTimeout)\n+      throws IOException {\n+    PipelineID pipelineID = pipeline.getId();\n     lock.writeLock().lock();\n     try {\n-      stateManager.removePipeline(pipelineId.getProtobuf());\n-      metrics.incNumPipelineDestroyed();\n-    } catch (IOException ex) {\n-      metrics.incNumPipelineDestroyFailed();\n-      throw ex;\n+      if (!pipeline.isClosed()) {\n+        stateManager.updatePipelineState(pipelineID.getProtobuf(),\n+            HddsProtos.PipelineState.PIPELINE_CLOSED);\n+        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n+      }\n+      metrics.removePipelineMetrics(pipelineID);\n     } finally {\n       lock.writeLock().unlock();\n     }\n+    if (!onTimeout) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5a7a822b3b7f7e1b6934cca992ec28ae6fe77f1e"}, "originalPosition": 190}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTMzMzc5Mg==", "bodyText": "Yes, we let scrubber handle the rest.", "url": "https://github.com/apache/ozone/pull/1049#discussion_r451333792", "createdAt": "2020-07-08T07:20:38Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -310,94 +321,72 @@ public void openPipeline(PipelineID pipelineId) throws IOException {\n   }\n \n   /**\n-   * Finalizes pipeline in the SCM. Removes pipeline and makes rpc call to\n-   * destroy pipeline on the datanodes immediately or after timeout based on the\n-   * value of onTimeout parameter.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n-   * @param onTimeout       - if true pipeline is removed and destroyed on\n-   *                        datanodes after timeout\n-   * @throws IOException\n-   */\n-  @Override\n-  public void finalizeAndDestroyPipeline(Pipeline pipeline, boolean onTimeout)\n-      throws IOException {\n-    LOG.info(\"Destroying pipeline:{}\", pipeline);\n-    finalizePipeline(pipeline.getId());\n-    if (onTimeout) {\n-      long pipelineDestroyTimeoutInMillis =\n-          conf.getTimeDuration(ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT,\n-              ScmConfigKeys.OZONE_SCM_PIPELINE_DESTROY_TIMEOUT_DEFAULT,\n-              TimeUnit.MILLISECONDS);\n-      scheduler.schedule(() -> destroyPipeline(pipeline),\n-          pipelineDestroyTimeoutInMillis, TimeUnit.MILLISECONDS, LOG,\n-          String.format(\"Destroy pipeline failed for pipeline:%s\", pipeline));\n-    } else {\n-      destroyPipeline(pipeline);\n-    }\n-  }\n-\n-  /**\n-   * Moves the pipeline to CLOSED state and sends close container command for\n-   * all the containers in the pipeline.\n+   * Removes the pipeline from the db and pipeline state map.\n    *\n-   * @param pipelineId - ID of the pipeline to be moved to CLOSED state.\n+   * @param pipeline - pipeline to be removed\n    * @throws IOException\n    */\n-  private void finalizePipeline(PipelineID pipelineId) throws IOException {\n+  protected void removePipeline(Pipeline pipeline) throws IOException {\n+    pipelineFactory.close(pipeline.getType(), pipeline);\n+    PipelineID pipelineID = pipeline.getId();\n     lock.writeLock().lock();\n     try {\n-      Pipeline pipeline = stateManager.getPipeline(pipelineId);\n-      if (!pipeline.isClosed()) {\n-        stateManager.updatePipelineState(\n-            pipelineId.getProtobuf(), HddsProtos.PipelineState.PIPELINE_CLOSED);\n-        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n-      }\n-\n-      // TODO fire events to datanodes for closing pipelines\n-//      Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n-//      for (ContainerID containerID : containerIDs) {\n-//        eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n-//      }\n-      metrics.removePipelineMetrics(pipelineId);\n+      stateManager.removePipeline(pipelineID.getProtobuf());\n+      metrics.incNumPipelineDestroyed();\n+    } catch (IOException ex) {\n+      metrics.incNumPipelineDestroyFailed();\n+      throw ex;\n     } finally {\n       lock.writeLock().unlock();\n     }\n   }\n \n   /**\n-   * Removes pipeline from SCM. Sends ratis command to destroy pipeline on all\n-   * the datanodes for ratis pipelines.\n-   *\n-   * @param pipeline        - Pipeline to be destroyed\n+   * Fire events to close all containers related to the input pipeline.\n+   * @param pipelineId - ID of the pipeline.\n    * @throws IOException\n    */\n-  protected void destroyPipeline(Pipeline pipeline) throws IOException {\n-    pipelineFactory.close(pipeline.getType(), pipeline);\n-    // remove the pipeline from the pipeline manager\n-    removePipeline(pipeline.getId());\n-    triggerPipelineCreation();\n+  protected void closeContainersForPipeline(final PipelineID pipelineId)\n+      throws IOException {\n+    Set<ContainerID> containerIDs = stateManager.getContainers(pipelineId);\n+    for (ContainerID containerID : containerIDs) {\n+      eventPublisher.fireEvent(SCMEvents.CLOSE_CONTAINER, containerID);\n+    }\n   }\n \n   /**\n-   * Removes the pipeline from the db and pipeline state map.\n-   *\n-   * @param pipelineId - ID of the pipeline to be removed\n+   * put pipeline in CLOSED state.\n+   * @param pipeline - ID of the pipeline.\n+   * @param onTimeout - whether to remove pipeline after some time.\n    * @throws IOException\n    */\n-  protected void removePipeline(PipelineID pipelineId) throws IOException {\n+  @Override\n+  public void closePipeline(Pipeline pipeline, boolean onTimeout)\n+      throws IOException {\n+    PipelineID pipelineID = pipeline.getId();\n     lock.writeLock().lock();\n     try {\n-      stateManager.removePipeline(pipelineId.getProtobuf());\n-      metrics.incNumPipelineDestroyed();\n-    } catch (IOException ex) {\n-      metrics.incNumPipelineDestroyFailed();\n-      throw ex;\n+      if (!pipeline.isClosed()) {\n+        stateManager.updatePipelineState(pipelineID.getProtobuf(),\n+            HddsProtos.PipelineState.PIPELINE_CLOSED);\n+        LOG.info(\"Pipeline {} moved to CLOSED state\", pipeline);\n+      }\n+      metrics.removePipelineMetrics(pipelineID);\n     } finally {\n       lock.writeLock().unlock();\n     }\n+    if (!onTimeout) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTAyNDI4Mg=="}, "originalCommit": {"oid": "5a7a822b3b7f7e1b6934cca992ec28ae6fe77f1e"}, "originalPosition": 190}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxMTk4ODUwOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/SCMPipelineManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNzoyMjozN1rOGuIX9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNzoyMjozN1rOGuIX9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTAyNDg4Ng==", "bodyText": "Same as the comments for V2 manager.", "url": "https://github.com/apache/ozone/pull/1049#discussion_r451024886", "createdAt": "2020-07-07T17:22:37Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/SCMPipelineManager.java", "diffHunk": "@@ -421,18 +438,29 @@ public void scrubPipeline(ReplicationType type, ReplicationFactor factor)\n         ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT,\n         ScmConfigKeys.OZONE_SCM_PIPELINE_ALLOCATED_TIMEOUT_DEFAULT,\n         TimeUnit.MILLISECONDS);\n-    List<Pipeline> needToSrubPipelines = stateManager.getPipelines(type, factor,\n-        Pipeline.PipelineState.ALLOCATED).stream()\n-        .filter(p -> currentTime.toEpochMilli() - p.getCreationTimestamp()\n-            .toEpochMilli() >= pipelineScrubTimeoutInMills)\n-        .collect(Collectors.toList());\n-    for (Pipeline p : needToSrubPipelines) {\n-      LOG.info(\"Scrubbing pipeline: id: \" + p.getId().toString() +\n-          \" since it stays at ALLOCATED stage for \" +\n-          Duration.between(currentTime, p.getCreationTimestamp()).toMinutes() +\n-          \" mins.\");\n-      finalizeAndDestroyPipeline(p, false);\n+\n+    List<Pipeline> candidates = stateManager.getPipelines(type, factor);\n+\n+    for (Pipeline p : candidates) {\n+      // scrub pipelines who stay ALLOCATED for too long.\n+      if (p.getPipelineState() == Pipeline.PipelineState.ALLOCATED &&\n+          (currentTime.toEpochMilli() - p.getCreationTimestamp()\n+              .toEpochMilli() >= pipelineScrubTimeoutInMills)) {\n+        LOG.info(\"Scrubbing pipeline: id: \" + p.getId().toString() +\n+            \" since it stays at ALLOCATED stage for \" +\n+            Duration.between(currentTime, p.getCreationTimestamp())\n+                .toMinutes() + \" mins.\");\n+        closePipeline(p, false);\n+      }\n+      // scrub pipelines who stay CLOSED for too long.\n+      if (p.getPipelineState() == Pipeline.PipelineState.CLOSED) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5a7a822b3b7f7e1b6934cca992ec28ae6fe77f1e"}, "originalPosition": 110}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4239, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}