{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMzNjc5MDE0", "number": 1667, "reviewThreads": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMlQxODozMDozOVrOFEfC1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzo1NToyMFrOFGUnTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwMjQ3MjUzOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/utils/db/DBConfigFromFile.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMlQxODozMDozOVrOIEnjeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMlQxODozMDozOVrOIEnjeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTcxMzI3Mg==", "bodyText": "Should be OZONE_CONFIG_DIR? nvm", "url": "https://github.com/apache/ozone/pull/1667#discussion_r541713272", "createdAt": "2020-12-12T18:30:39Z", "author": {"login": "smengcl"}, "path": "hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/utils/db/DBConfigFromFile.java", "diffHunk": "@@ -65,7 +65,7 @@ public static File getConfigLocation() throws IOException {\n \n     if (StringUtil.isBlank(path)) {\n       LOG.debug(\"Unable to find the configuration directory. \"\n-          + \"Please make sure that HADOOP_CONF_DIR is setup correctly.\");\n+          + \"Please make sure that \" + CONFIG_DIR + \" is setup correctly.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d767e1bf9d87e78ab30c5e5c618f464aa1ee6b8f"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMDIwNTA4OnYy", "diffSide": "LEFT", "path": "hadoop-ozone/dist/dev-support/bin/dist-layout-stitching", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMDo1NDowMVrOIFoPbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxODo1NTowMFrOIHUUEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc3MzEwMw==", "bodyText": "Does hadoop-config.sh and hadoop-functions.sh have any useful env variables? (e.g. HADOOP_OPTS)\nTODO: Check ozone-config.sh and ozone-functions.sh later.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r542773103", "createdAt": "2020-12-14T20:54:01Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/dev-support/bin/dist-layout-stitching", "diffHunk": "@@ -103,10 +93,8 @@ run cp -r \"${ROOT}/hadoop-ozone/dist/src/main/dockerlibexec/.\" \"libexec/\"\n run cp \"${ROOT}/hadoop-ozone/dist/src/shell/ozone/ozone\" \"bin/\"\n \n \n-run cp \"${ROOT}/hadoop-ozone/dist/src/shell/hdds/hadoop-config.sh\" \"libexec/\"\n-run cp \"${ROOT}/hadoop-ozone/dist/src/shell/hdds/hadoop-config.cmd\" \"libexec/\"\n-run cp \"${ROOT}/hadoop-ozone/dist/src/shell/hdds/hadoop-functions.sh\" \"libexec/\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0Mzc2MA==", "bodyText": "Yes we have OZONE_OPTS, but not sure if HADOOP_OPTS will be picked up when OZONE_OPTS right now. Probably not?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544543760", "createdAt": "2020-12-16T18:55:00Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/dev-support/bin/dist-layout-stitching", "diffHunk": "@@ -103,10 +93,8 @@ run cp -r \"${ROOT}/hadoop-ozone/dist/src/main/dockerlibexec/.\" \"libexec/\"\n run cp \"${ROOT}/hadoop-ozone/dist/src/shell/ozone/ozone\" \"bin/\"\n \n \n-run cp \"${ROOT}/hadoop-ozone/dist/src/shell/hdds/hadoop-config.sh\" \"libexec/\"\n-run cp \"${ROOT}/hadoop-ozone/dist/src/shell/hdds/hadoop-config.cmd\" \"libexec/\"\n-run cp \"${ROOT}/hadoop-ozone/dist/src/shell/hdds/hadoop-functions.sh\" \"libexec/\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc3MzEwMw=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg4OTUxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMToxMVrOIF307g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNzo0OToxMlrOIF9TUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODQ2Mg==", "bodyText": "start-dfs.sh is mentioned two times here, can you please rephrase this comment, and the next which mentions it to point to start-ozone.sh, and to mention Ozone roles?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028462", "createdAt": "2020-12-15T04:01:11Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExODE2Mw==", "bodyText": "Thanks.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543118163", "createdAt": "2020-12-15T07:49:12Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODQ2Mg=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg4OTk2OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMToyMlrOIF31JA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNzo1MzoyN1rOIF9c7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODUxNg==", "bodyText": "We should refer to Ozone roles here.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028516", "createdAt": "2020-12-15T04:01:22Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzEyMDYyMw==", "bodyText": "Thanks.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543120623", "createdAt": "2020-12-15T07:53:27Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODUxNg=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 184}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg5MDMyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMToyN1rOIF31TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNzo1Mzo0M1rOIF9dfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODU1Nw==", "bodyText": "We should refer ozone-functions.sh here.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028557", "createdAt": "2020-12-15T04:01:27Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)\n+# Java property: hadoop.security.logger\n+# export OZONE_SECURITY_LOGGER=INFO,NullAppender\n+\n+# Default process priority level\n+# Note that sub-processes will also run at this level!\n+# export OZONE_NICENESS=0\n+\n+# Default name for the service level authorization file\n+# Java property: hadoop.policy.file\n+# export OZONE_POLICYFILE=\"hadoop-policy.xml\"\n+\n+#\n+# NOTE: this is not used by default!  <-----\n+# You can define variables right here and then re-use them later on.\n+# For example, it is common to use the same garbage collection settings\n+# for all the daemons.  So one could define:\n+#\n+# export OZONE_GC_SETTINGS=\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"\n+#\n+# .. and then use it as per the b option under the namenode.\n+\n+###\n+# Secure/privileged execution\n+###\n+\n+#\n+# Out of the box, Ozone uses jsvc from Apache Commons to launch daemons\n+# on privileged ports.  This functionality can be replaced by providing\n+# custom functions.  See hadoop-functions.sh for more information.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzEyMDc2NA==", "bodyText": "Thanks.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543120764", "createdAt": "2020-12-15T07:53:43Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)\n+# Java property: hadoop.security.logger\n+# export OZONE_SECURITY_LOGGER=INFO,NullAppender\n+\n+# Default process priority level\n+# Note that sub-processes will also run at this level!\n+# export OZONE_NICENESS=0\n+\n+# Default name for the service level authorization file\n+# Java property: hadoop.policy.file\n+# export OZONE_POLICYFILE=\"hadoop-policy.xml\"\n+\n+#\n+# NOTE: this is not used by default!  <-----\n+# You can define variables right here and then re-use them later on.\n+# For example, it is common to use the same garbage collection settings\n+# for all the daemons.  So one could define:\n+#\n+# export OZONE_GC_SETTINGS=\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"\n+#\n+# .. and then use it as per the b option under the namenode.\n+\n+###\n+# Secure/privileged execution\n+###\n+\n+#\n+# Out of the box, Ozone uses jsvc from Apache Commons to launch daemons\n+# on privileged ports.  This functionality can be replaced by providing\n+# custom functions.  See hadoop-functions.sh for more information.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODU1Nw=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 213}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg5MDUwOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMTozNFrOIF31aQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNzo1Mzo1OFrOIF9eBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODU4NQ==", "bodyText": "It is maybe out of scope for this PR, but shouldn't we have OZONE_RECON_OPTS, and OZONE_S3GW_OPTS similarly?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028585", "createdAt": "2020-12-15T04:01:34Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)\n+# Java property: hadoop.security.logger\n+# export OZONE_SECURITY_LOGGER=INFO,NullAppender\n+\n+# Default process priority level\n+# Note that sub-processes will also run at this level!\n+# export OZONE_NICENESS=0\n+\n+# Default name for the service level authorization file\n+# Java property: hadoop.policy.file\n+# export OZONE_POLICYFILE=\"hadoop-policy.xml\"\n+\n+#\n+# NOTE: this is not used by default!  <-----\n+# You can define variables right here and then re-use them later on.\n+# For example, it is common to use the same garbage collection settings\n+# for all the daemons.  So one could define:\n+#\n+# export OZONE_GC_SETTINGS=\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"\n+#\n+# .. and then use it as per the b option under the namenode.\n+\n+###\n+# Secure/privileged execution\n+###\n+\n+#\n+# Out of the box, Ozone uses jsvc from Apache Commons to launch daemons\n+# on privileged ports.  This functionality can be replaced by providing\n+# custom functions.  See hadoop-functions.sh for more information.\n+#\n+\n+# The jsvc implementation to use. Jsvc is required to run secure datanodes\n+# that bind to privileged ports to provide authentication of data transfer\n+# protocol.  Jsvc is not required if SASL is configured for authentication of\n+# data transfer protocol using non-privileged ports.\n+# export JSVC_HOME=/usr/bin\n+\n+#\n+# This directory contains pids for secure and privileged processes.\n+#export OZONE_SECURE_PID_DIR=${OZONE_PID_DIR}\n+\n+#\n+# This directory contains the logs for secure and privileged processes.\n+# Java property: hadoop.log.dir\n+# export OZONE_SECURE_LOG=${OZONE_LOG_DIR}\n+\n+#\n+# When running a secure daemon, the default value of OZONE_IDENT_STRING\n+# ends up being a bit bogus.  Therefore, by default, the code will\n+# replace OZONE_IDENT_STRING with OZONE_xx_SECURE_USER.  If one wants\n+# to keep OZONE_IDENT_STRING untouched, then uncomment this line.\n+# export OZONE_SECURE_IDENT_PRESERVE=\"true\"\n+\n+###\n+# Ozone Manager specific parameters\n+###\n+# Specify the JVM options to be used when starting the Ozone Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_OM_OPTS=\"\"\n+\n+###\n+# Ozone DataNode specific parameters\n+###\n+# Specify the JVM options to be used when starting Ozone DataNodes.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_DATANODE_OPTS=\"\"\n+\n+###\n+# HDFS StorageContainerManager specific parameters\n+###\n+# Specify the JVM options to be used when starting the HDFS Storage Container Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_SCM_OPTS=\"\"\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzEyMDkwMg==", "bodyText": "Agree, out of scope. ;)", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543120902", "createdAt": "2020-12-15T07:53:58Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)\n+# Java property: hadoop.security.logger\n+# export OZONE_SECURITY_LOGGER=INFO,NullAppender\n+\n+# Default process priority level\n+# Note that sub-processes will also run at this level!\n+# export OZONE_NICENESS=0\n+\n+# Default name for the service level authorization file\n+# Java property: hadoop.policy.file\n+# export OZONE_POLICYFILE=\"hadoop-policy.xml\"\n+\n+#\n+# NOTE: this is not used by default!  <-----\n+# You can define variables right here and then re-use them later on.\n+# For example, it is common to use the same garbage collection settings\n+# for all the daemons.  So one could define:\n+#\n+# export OZONE_GC_SETTINGS=\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"\n+#\n+# .. and then use it as per the b option under the namenode.\n+\n+###\n+# Secure/privileged execution\n+###\n+\n+#\n+# Out of the box, Ozone uses jsvc from Apache Commons to launch daemons\n+# on privileged ports.  This functionality can be replaced by providing\n+# custom functions.  See hadoop-functions.sh for more information.\n+#\n+\n+# The jsvc implementation to use. Jsvc is required to run secure datanodes\n+# that bind to privileged ports to provide authentication of data transfer\n+# protocol.  Jsvc is not required if SASL is configured for authentication of\n+# data transfer protocol using non-privileged ports.\n+# export JSVC_HOME=/usr/bin\n+\n+#\n+# This directory contains pids for secure and privileged processes.\n+#export OZONE_SECURE_PID_DIR=${OZONE_PID_DIR}\n+\n+#\n+# This directory contains the logs for secure and privileged processes.\n+# Java property: hadoop.log.dir\n+# export OZONE_SECURE_LOG=${OZONE_LOG_DIR}\n+\n+#\n+# When running a secure daemon, the default value of OZONE_IDENT_STRING\n+# ends up being a bit bogus.  Therefore, by default, the code will\n+# replace OZONE_IDENT_STRING with OZONE_xx_SECURE_USER.  If one wants\n+# to keep OZONE_IDENT_STRING untouched, then uncomment this line.\n+# export OZONE_SECURE_IDENT_PRESERVE=\"true\"\n+\n+###\n+# Ozone Manager specific parameters\n+###\n+# Specify the JVM options to be used when starting the Ozone Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_OM_OPTS=\"\"\n+\n+###\n+# Ozone DataNode specific parameters\n+###\n+# Specify the JVM options to be used when starting Ozone DataNodes.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_DATANODE_OPTS=\"\"\n+\n+###\n+# HDFS StorageContainerManager specific parameters\n+###\n+# Specify the JVM options to be used when starting the HDFS Storage Container Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_SCM_OPTS=\"\"\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODU4NQ=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 264}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg5MTEyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMTo0NFrOIF31tA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNzo1NDoxMVrOIF9edw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODY2MA==", "bodyText": "Does this remain here on purpose?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028660", "createdAt": "2020-12-15T04:01:44Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)\n+# Java property: hadoop.security.logger\n+# export OZONE_SECURITY_LOGGER=INFO,NullAppender\n+\n+# Default process priority level\n+# Note that sub-processes will also run at this level!\n+# export OZONE_NICENESS=0\n+\n+# Default name for the service level authorization file\n+# Java property: hadoop.policy.file\n+# export OZONE_POLICYFILE=\"hadoop-policy.xml\"\n+\n+#\n+# NOTE: this is not used by default!  <-----\n+# You can define variables right here and then re-use them later on.\n+# For example, it is common to use the same garbage collection settings\n+# for all the daemons.  So one could define:\n+#\n+# export OZONE_GC_SETTINGS=\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"\n+#\n+# .. and then use it as per the b option under the namenode.\n+\n+###\n+# Secure/privileged execution\n+###\n+\n+#\n+# Out of the box, Ozone uses jsvc from Apache Commons to launch daemons\n+# on privileged ports.  This functionality can be replaced by providing\n+# custom functions.  See hadoop-functions.sh for more information.\n+#\n+\n+# The jsvc implementation to use. Jsvc is required to run secure datanodes\n+# that bind to privileged ports to provide authentication of data transfer\n+# protocol.  Jsvc is not required if SASL is configured for authentication of\n+# data transfer protocol using non-privileged ports.\n+# export JSVC_HOME=/usr/bin\n+\n+#\n+# This directory contains pids for secure and privileged processes.\n+#export OZONE_SECURE_PID_DIR=${OZONE_PID_DIR}\n+\n+#\n+# This directory contains the logs for secure and privileged processes.\n+# Java property: hadoop.log.dir\n+# export OZONE_SECURE_LOG=${OZONE_LOG_DIR}\n+\n+#\n+# When running a secure daemon, the default value of OZONE_IDENT_STRING\n+# ends up being a bit bogus.  Therefore, by default, the code will\n+# replace OZONE_IDENT_STRING with OZONE_xx_SECURE_USER.  If one wants\n+# to keep OZONE_IDENT_STRING untouched, then uncomment this line.\n+# export OZONE_SECURE_IDENT_PRESERVE=\"true\"\n+\n+###\n+# Ozone Manager specific parameters\n+###\n+# Specify the JVM options to be used when starting the Ozone Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_OM_OPTS=\"\"\n+\n+###\n+# Ozone DataNode specific parameters\n+###\n+# Specify the JVM options to be used when starting Ozone DataNodes.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_DATANODE_OPTS=\"\"\n+\n+###\n+# HDFS StorageContainerManager specific parameters\n+###\n+# Specify the JVM options to be used when starting the HDFS Storage Container Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_SCM_OPTS=\"\"\n+\n+###\n+# Advanced Users Only!\n+###\n+\n+#\n+# When building Ozone, one can add the class paths to the commands\n+# via this special env var:\n+# export OZONE_ENABLE_BUILD_PATHS=\"true\"\n+\n+#\n+# To prevent accidents, shell commands be (superficially) locked\n+# to only allow certain users to execute certain subcommands.\n+# It uses the format of (command)_(subcommand)_USER.\n+#\n+# For example, to limit who can execute the namenode command,\n+# export HDFS_NAMENODE_USER=hdfs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 280}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzEyMTAxNQ==", "bodyText": "No, thanks.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543121015", "createdAt": "2020-12-15T07:54:11Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/common/src/main/conf/ozone-env.sh", "diffHunk": "@@ -0,0 +1,280 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Set Ozone-specific environment variables here.\n+\n+# Enable core dump when crash in C++\n+ulimit -c unlimited\n+\n+# Many of the options here are built from the perspective that users\n+# may want to provide OVERWRITING values on the command line.\n+# For example:\n+#\n+#  JAVA_HOME=/usr/java/testing hdfs dfs -ls\n+#\n+# Therefore, the vast majority (BUT NOT ALL!) of these defaults\n+# are configured for substitution and not append.  If append\n+# is preferable, modify this file accordingly.\n+\n+###\n+# Generic settings\n+###\n+\n+# Technically, the only required environment variable is JAVA_HOME.\n+# All others are optional.  However, the defaults are probably not\n+# preferred.  Many sites configure these options outside of Ozone,\n+# such as in /etc/profile.d\n+\n+# The java implementation to use. By default, this environment\n+# variable is REQUIRED on ALL platforms except OS X!\n+# export JAVA_HOME=\n+\n+# Location of Ozone.  By default, Ozone will attempt to determine\n+# this location based upon its execution path.\n+# export OZONE_HOME=\n+\n+# Location of Ozone's configuration information.  i.e., where this\n+# file is living. If this is not defined, Ozone will attempt to\n+# locate it based upon its execution path.\n+#\n+# NOTE: It is recommend that this variable not be set here but in\n+# /etc/profile.d or equivalent.  Some options (such as\n+# --config) may react strangely otherwise.\n+#\n+# export OZONE_CONFIG_DIR=${OZONE_HOME}/etc/hadoop\n+\n+# The maximum amount of heap to use (Java -Xmx).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xmx setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MAX=\n+\n+# The minimum amount of heap to use (Java -Xms).  If no unit\n+# is provided, it will be converted to MB.  Daemons will\n+# prefer any Xms setting in their respective _OPT variable.\n+# There is no default; the JVM will autoscale based upon machine\n+# memory size.\n+# export OZONE_HEAPSIZE_MIN=\n+\n+# Extra Java runtime options for all Ozone commands. We don't support\n+# IPv6 yet/still, so by default the preference is set to IPv4.\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true\"\n+# For Kerberos debugging, an extended option set logs more information\n+# export OZONE_OPTS=\"-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug\"\n+\n+# Some parts of the shell code may do special things dependent upon\n+# the operating system.  We have to set this here. See the next\n+# section as to why....\n+export OZONE_OS_TYPE=${OZONE_OS_TYPE:-$(uname -s)}\n+\n+# Extra Java runtime options for some Ozone commands\n+# and clients (i.e., hdfs dfs -blah).  These get appended to OZONE_OPTS for\n+# such commands.  In most cases, # this should be left empty and\n+# let users supply it on the command line.\n+# export OZONE_CLIENT_OPTS=\"\"\n+\n+#\n+# A note about classpaths.\n+#\n+# By default, Apache Ozone overrides Java's CLASSPATH\n+# environment variable.  It is configured such\n+# that it starts out blank with new entries added after passing\n+# a series of checks (file/dir exists, not already listed aka\n+# de-deduplication).  During de-deduplication, wildcards and/or\n+# directories are *NOT* expanded to keep it simple. Therefore,\n+# if the computed classpath has two specific mentions of\n+# awesome-methods-1.0.jar, only the first one added will be seen.\n+# If two directories are in the classpath that both contain\n+# awesome-methods-1.0.jar, then Java will pick up both versions.\n+\n+# An additional, custom CLASSPATH. Site-wide configs should be\n+# handled via the shellprofile functionality, utilizing the\n+# ozone_add_classpath function for greater control and much\n+# harder for apps/end-users to accidentally override.\n+# Similarly, end users should utilize ${HOME}/.ozonerc .\n+# This variable should ideally only be used as a short-cut,\n+# interactive way for temporary additions on the command line.\n+# export OZONE_CLASSPATH=\"/some/cool/path/on/your/machine\"\n+\n+# Should OZONE_CLASSPATH be first in the official CLASSPATH?\n+# export OZONE_USER_CLASSPATH_FIRST=\"yes\"\n+\n+# If OZONE_USE_CLIENT_CLASSLOADER is set, OZONE_CLASSPATH and\n+# OZONE_USER_CLASSPATH_FIRST are ignored.\n+# export OZONE_USE_CLIENT_CLASSLOADER=true\n+\n+###\n+# Options for remote shell connectivity\n+###\n+\n+# There are some optional components of hadoop that allow for\n+# command and control of remote hosts.  For example,\n+# start-dfs.sh will attempt to bring up all NNs, DNS, etc.\n+\n+# Options to pass to SSH when one of the \"log into a host and\n+# start/stop daemons\" scripts is executed\n+# export OZONE_SSH_OPTS=\"-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10s\"\n+\n+# The built-in ssh handler will limit itself to 10 simultaneous connections.\n+# For pdsh users, this sets the fanout size ( -f )\n+# Change this to increase/decrease as necessary.\n+# export OZONE_SSH_PARALLEL=10\n+\n+# Filename which contains all of the hosts for any remote execution\n+# helper scripts # such as workers.sh, start-dfs.sh, etc.\n+# export OZONE_WORKERS=\"${OZONE_CONFIG_DIR}/workers\"\n+\n+###\n+# Options for all daemons\n+###\n+#\n+\n+#\n+# Many options may also be specified as Java properties.  It is\n+# very common, and in many cases, desirable, to hard-set these\n+# in daemon _OPTS variables.  Where applicable, the appropriate\n+# Java property is also identified.  Note that many are re-used\n+# or set differently in certain contexts (e.g., secure vs\n+# non-secure)\n+#\n+\n+# Where (primarily) daemon log files are stored.\n+# ${OZONE_HOME}/logs by default.\n+# Java property: hadoop.log.dir\n+# export OZONE_LOG_DIR=${OZONE_HOME}/logs\n+\n+# A string representing this instance of hadoop. $USER by default.\n+# This is used in writing log and pid files, so keep that in mind!\n+# Java property: hadoop.id.str\n+# export OZONE_IDENT_STRING=$USER\n+\n+# How many seconds to pause after stopping a daemon\n+# export OZONE_STOP_TIMEOUT=5\n+\n+# Where pid files are stored.  /tmp by default.\n+# export OZONE_PID_DIR=/tmp\n+\n+# Default log4j setting for interactive commands\n+# Java property: hadoop.root.logger\n+# export OZONE_ROOT_LOGGER=INFO,console\n+\n+# Default log4j setting for daemons spawned explicitly by\n+# --daemon option of hadoop, hdfs, mapred and yarn command.\n+# Java property: hadoop.root.logger\n+# export OZONE_DAEMON_ROOT_LOGGER=INFO,RFA\n+\n+# Default log level and output location for security-related messages.\n+# You will almost certainly want to change this on a per-daemon basis via\n+# the Java property (i.e., -Dhadoop.security.logger=foo). (Note that the\n+# defaults for the NN and 2NN override this by default.)\n+# Java property: hadoop.security.logger\n+# export OZONE_SECURITY_LOGGER=INFO,NullAppender\n+\n+# Default process priority level\n+# Note that sub-processes will also run at this level!\n+# export OZONE_NICENESS=0\n+\n+# Default name for the service level authorization file\n+# Java property: hadoop.policy.file\n+# export OZONE_POLICYFILE=\"hadoop-policy.xml\"\n+\n+#\n+# NOTE: this is not used by default!  <-----\n+# You can define variables right here and then re-use them later on.\n+# For example, it is common to use the same garbage collection settings\n+# for all the daemons.  So one could define:\n+#\n+# export OZONE_GC_SETTINGS=\"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"\n+#\n+# .. and then use it as per the b option under the namenode.\n+\n+###\n+# Secure/privileged execution\n+###\n+\n+#\n+# Out of the box, Ozone uses jsvc from Apache Commons to launch daemons\n+# on privileged ports.  This functionality can be replaced by providing\n+# custom functions.  See hadoop-functions.sh for more information.\n+#\n+\n+# The jsvc implementation to use. Jsvc is required to run secure datanodes\n+# that bind to privileged ports to provide authentication of data transfer\n+# protocol.  Jsvc is not required if SASL is configured for authentication of\n+# data transfer protocol using non-privileged ports.\n+# export JSVC_HOME=/usr/bin\n+\n+#\n+# This directory contains pids for secure and privileged processes.\n+#export OZONE_SECURE_PID_DIR=${OZONE_PID_DIR}\n+\n+#\n+# This directory contains the logs for secure and privileged processes.\n+# Java property: hadoop.log.dir\n+# export OZONE_SECURE_LOG=${OZONE_LOG_DIR}\n+\n+#\n+# When running a secure daemon, the default value of OZONE_IDENT_STRING\n+# ends up being a bit bogus.  Therefore, by default, the code will\n+# replace OZONE_IDENT_STRING with OZONE_xx_SECURE_USER.  If one wants\n+# to keep OZONE_IDENT_STRING untouched, then uncomment this line.\n+# export OZONE_SECURE_IDENT_PRESERVE=\"true\"\n+\n+###\n+# Ozone Manager specific parameters\n+###\n+# Specify the JVM options to be used when starting the Ozone Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_OM_OPTS=\"\"\n+\n+###\n+# Ozone DataNode specific parameters\n+###\n+# Specify the JVM options to be used when starting Ozone DataNodes.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_DATANODE_OPTS=\"\"\n+\n+###\n+# HDFS StorageContainerManager specific parameters\n+###\n+# Specify the JVM options to be used when starting the HDFS Storage Container Manager.\n+# These options will be appended to the options specified as OZONE_OPTS\n+# and therefore may override any similar flags set in OZONE_OPTS\n+#\n+# export OZONE_SCM_OPTS=\"\"\n+\n+###\n+# Advanced Users Only!\n+###\n+\n+#\n+# When building Ozone, one can add the class paths to the commands\n+# via this special env var:\n+# export OZONE_ENABLE_BUILD_PATHS=\"true\"\n+\n+#\n+# To prevent accidents, shell commands be (superficially) locked\n+# to only allow certain users to execute certain subcommands.\n+# It uses the format of (command)_(subcommand)_USER.\n+#\n+# For example, to limit who can execute the namenode command,\n+# export HDFS_NAMENODE_USER=hdfs", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODY2MA=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 280}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg5MTM5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/utils/db/DBConfigFromFile.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMTo1MlrOIF312g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNzo1NDo0MlrOIF9fmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODY5OA==", "bodyText": "We duplicate this if statement here, first to write a debug level log message second to return null, can we pull the two together, and also change the log message here, and state the reason why we fail by saying something like:\nCONFIG_DIR + \" variable is empty, please make sure it is setup correctly!\"", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028698", "createdAt": "2020-12-15T04:01:52Z", "author": {"login": "fapifta"}, "path": "hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/utils/db/DBConfigFromFile.java", "diffHunk": "@@ -65,7 +65,7 @@ public static File getConfigLocation() throws IOException {\n \n     if (StringUtil.isBlank(path)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzEyMTMwNw==", "bodyText": "Not introduced by this change, but thanks for pointing out, let's fix it anyway.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543121307", "createdAt": "2020-12-15T07:54:42Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/utils/db/DBConfigFromFile.java", "diffHunk": "@@ -65,7 +65,7 @@ public static File getConfigLocation() throws IOException {\n \n     if (StringUtil.isBlank(path)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODY5OA=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg5MTU0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/compose/ozone-csi/docker-compose.yaml", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjowMVrOIF318w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzoxMzo1OFrOIHQJXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODcyMw==", "bodyText": "For all these replacements, shouldn't we still provide ${OZONE_OPTS} to the environment as we did with HADOOP_OPTS before? We specify the coverage related options via this variable in test_all.sh for example.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028723", "createdAt": "2020-12-15T04:02:01Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-csi/docker-compose.yaml", "diffHunk": "@@ -24,7 +24,7 @@ services:\n     env_file:\n       - docker-config\n     environment:\n-      HADOOP_OPTS: ${HADOOP_OPTS}\n+      OZONE_OPTS:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA4MTIyNw==", "bodyText": "Environment variables with only a key are resolved to their values on the machine Compose is running on\n\nhttps://docs.docker.com/compose/compose-file/#environment\nSo repeating the variable name is unnecessary.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543081227", "createdAt": "2020-12-15T06:31:45Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-csi/docker-compose.yaml", "diffHunk": "@@ -24,7 +24,7 @@ services:\n     env_file:\n       - docker-config\n     environment:\n-      HADOOP_OPTS: ${HADOOP_OPTS}\n+      OZONE_OPTS:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODcyMw=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3NTQ4NQ==", "bodyText": "neat!", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544475485", "createdAt": "2020-12-16T17:13:58Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-csi/docker-compose.yaml", "diffHunk": "@@ -24,7 +24,7 @@ services:\n     env_file:\n       - docker-config\n     environment:\n-      HADOOP_OPTS: ${HADOOP_OPTS}\n+      OZONE_OPTS:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODcyMw=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg5MTkwOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/smoketest/compatibility/om.robot", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjoxMVrOIF32Jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNjoyNjowNVrOIF66Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODc3NQ==", "bodyText": "Shouldn't we rename this envvar also to OZONE_OM_OPTS?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028775", "createdAt": "2020-12-15T04:02:11Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/main/smoketest/compatibility/om.robot", "diffHunk": "@@ -0,0 +1,27 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test om compatibility\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Test Timeout        5 minutes\n+\n+*** Test Cases ***\n+Picks up command line options\n+    Pass Execution If    '%{HDFS_OM_OPTS}' == ''    Command-line option required for process check", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA3ODk1OQ==", "bodyText": "No, these tests intentionaly use old names to verify compatibility with old scripts.  Some of the variables (eg. HDFS_OM_OPTS and HDFS_STORAGECONTAINERMANAGER_OPTS) were already deprecated before this change, but I changed the function that deprecates them.\n\n  \n    \n      ozone/hadoop-ozone/dist/src/shell/ozone/ozone\n    \n    \n         Line 160\n      in\n      dfd2aaf\n    \n    \n    \n    \n\n        \n          \n           hadoop_deprecate_envvar HDFS_OM_OPTS OZONE_OM_OPTS", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543078959", "createdAt": "2020-12-15T06:26:05Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/dist/src/main/smoketest/compatibility/om.robot", "diffHunk": "@@ -0,0 +1,27 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test om compatibility\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Test Timeout        5 minutes\n+\n+*** Test Cases ***\n+Picks up command line options\n+    Pass Execution If    '%{HDFS_OM_OPTS}' == ''    Command-line option required for process check", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODc3NQ=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg5Mjg4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/smoketest/compatibility/scm.robot", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjoxOFrOIF32kQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNjoyNjozN1rOIF67GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODg4MQ==", "bodyText": "Should we rename this envvar also to OZONE_SCM_OPTS or OZONE_STORAGECONTAINERMANAGER_OPTS?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543028881", "createdAt": "2020-12-15T04:02:18Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/main/smoketest/compatibility/scm.robot", "diffHunk": "@@ -0,0 +1,27 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test scm compatibility\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Test Timeout        5 minutes\n+\n+*** Test Cases ***\n+Picks up command line options\n+    Pass Execution If    '%{HDFS_STORAGECONTAINERMANAGER_OPTS}' == ''    Command-line option required for process check", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA3OTE5Mw==", "bodyText": "Same as above.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543079193", "createdAt": "2020-12-15T06:26:37Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/dist/src/main/smoketest/compatibility/scm.robot", "diffHunk": "@@ -0,0 +1,27 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test scm compatibility\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Test Timeout        5 minutes\n+\n+*** Test Cases ***\n+Picks up command line options\n+    Pass Execution If    '%{HDFS_STORAGECONTAINERMANAGER_OPTS}' == ''    Command-line option required for process check", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyODg4MQ=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg5MzgxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/shell/hdds/workers.sh", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjo0M1rOIF33CA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowMjo0M1rOIF33CA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyOTAwMA==", "bodyText": "This seems to be a strange one here...\nSo in line 45 if ozone_bootstrap is not declared, we error out because ozone-functions.sh could not be loaded.\nAs I understand here we check for the exit status of ozone_bootstrap function, and if it is false we exit because we can not find ozone-config.sh. Why we need this second check? As I see the ozone_bootstrap function is not doing anything that should fail, but maybe my eye slipped through something.\nThis same we do in hadoop-ozone/dist/src/shell/ozone/ozone, in hadoop-ozone/dist/src/shell/ozone/start-ozone.sh and in hadoop-ozone/dist/src/shell/ozone/stop-ozone.sh files as well", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543029000", "createdAt": "2020-12-15T04:02:43Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/shell/hdds/workers.sh", "diffHunk": "@@ -20,40 +20,43 @@\n #\n # Environment Variables\n #\n-#   HADOOP_WORKERS    File naming remote hosts.\n-#     Default is ${HADOOP_CONF_DIR}/workers.\n-#   HADOOP_CONF_DIR  Alternate conf dir. Default is ${HADOOP_HOME}/conf.\n-#   HADOOP_WORKER_SLEEP Seconds to sleep between spawning remote commands.\n-#   HADOOP_SSH_OPTS Options passed to ssh when running remote commands.\n+#   OZONE_WORKERS    File naming remote hosts.\n+#     Default is ${OZONE_CONFIG_DIR}/workers.\n+#   OZONE_CONFIG_DIR  Alternate conf dir. Default is ${OZONE_HOME}/conf.\n+#   OZONE_WORKER_SLEEP Seconds to sleep between spawning remote commands.\n+#   OZONE_SSH_OPTS Options passed to ssh when running remote commands.\n ##\n \n-function hadoop_usage\n+function ozone_usage\n {\n   echo \"Usage: workers.sh [--config confdir] command...\"\n }\n \n-# let's locate libexec...\n-if [[ -n \"${HADOOP_HOME}\" ]]; then\n-  HADOOP_DEFAULT_LIBEXEC_DIR=\"${HADOOP_HOME}/libexec\"\n-else\n-  this=\"${BASH_SOURCE-$0}\"\n-  bin=$(cd -P -- \"$(dirname -- \"${this}\")\" >/dev/null && pwd -P)\n-  HADOOP_DEFAULT_LIBEXEC_DIR=\"${bin}/../libexec\"\n+# load functions\n+for dir in \"${OZONE_LIBEXEC_DIR}\" \"${OZONE_HOME}/libexec\" \"${HADOOP_LIBEXEC_DIR}\" \"${HADOOP_HOME}/libexec\" \"${bin}/../libexec\"; do\n+  if [[ -e \"${dir}/ozone-functions.sh\" ]]; then\n+    . \"${dir}/ozone-functions.sh\"\n+    if declare -F ozone_bootstrap >& /dev/null; then\n+      break\n+    fi\n+  fi\n+done\n+\n+if ! declare -F ozone_bootstrap >& /dev/null; then\n+  echo \"ERROR: Cannot find ozone-functions.sh.\" 2>&1\n+  exit 1\n fi\n \n-HADOOP_LIBEXEC_DIR=\"${HADOOP_LIBEXEC_DIR:-$HADOOP_DEFAULT_LIBEXEC_DIR}\"\n-# shellcheck disable=SC2034\n-HADOOP_NEW_CONFIG=true\n-if [[ -f \"${HADOOP_LIBEXEC_DIR}/hadoop-config.sh\" ]]; then\n-  . \"${HADOOP_LIBEXEC_DIR}/hadoop-config.sh\"\n-else\n-  echo \"ERROR: Cannot execute ${HADOOP_LIBEXEC_DIR}/hadoop-config.sh.\" 2>&1\n+if ! ozone_bootstrap; then", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTg5ODU3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/shell/ozone/start-ozone.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNDowNDo0NFrOIF35lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNTozOTo1MVrOIF51CA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyOTY1NA==", "bodyText": "Is this changed intentionally from accumulation to a set? Probably, but I wanted to be sure, and even so if this is the first place where we can safely set if this runs in just a pure context, this variable may have an initial value in some workflow which makes it worth to preserve the external value even at the first assignment?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543029654", "createdAt": "2020-12-15T04:04:44Z", "author": {"login": "fapifta"}, "path": "hadoop-ozone/dist/src/shell/ozone/start-ozone.sh", "diffHunk": "@@ -64,68 +63,53 @@ if [[ $# -ge 1 ]]; then\n       dataStartOpt=\"$startOpt\"\n     ;;\n     *)\n-      hadoop_exit_with_usage 1\n+      ozone_exit_with_usage 1\n     ;;\n   esac\n fi\n \n #Add other possible options\n nameStartOpt=\"$nameStartOpt $*\"\n \n-SECURITY_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getconf -confKey hadoop.security.authentication | tr '[:upper:]' '[:lower:]' 2>&-)\n-SECURITY_AUTHORIZATION_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getconf -confKey hadoop.security.authorization | tr '[:upper:]' '[:lower:]' 2>&-)\n-\n-#if [[ ${SECURITY_ENABLED} == \"kerberos\" || ${SECURITY_AUTHORIZATION_ENABLED}\n-# == \"true\" ]]; then\n-#  echo \"Ozone is not supported in a security enabled cluster.\"\n-#  exit 1\n-#fi\n-\n-#SECURITY_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getozoneconf -confKey hadoop.security.authentication | tr '[:upper:]' '[:lower:]' 2>&-)\n-#SECURITY_AUTHORIZATION_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getozoneconf -confKey hadoop.security.authorization | tr '[:upper:]' '[:lower:]' 2>&-)\n-#if [[ ${SECURITY_ENABLED} == \"kerberos\" || ${SECURITY_AUTHORIZATION_ENABLED} == \"true\" ]]; then\n-#  echo \"Ozone is not supported in a security enabled cluster.\"\n-#  exit 1\n-#fi\n+SECURITY_ENABLED=$(\"${OZONE_HOME}/bin/ozone\" getconf -confKey hadoop.security.authentication | tr '[:upper:]' '[:lower:]' 2>&-)\n+SECURITY_AUTHORIZATION_ENABLED=$(\"${OZONE_HOME}/bin/ozone\" getconf -confKey hadoop.security.authorization | tr '[:upper:]' '[:lower:]' 2>&-)\n \n # datanodes (using default workers file)\n \n echo \"Starting datanodes\"\n-hadoop_uservar_su hdfs datanode \"${HADOOP_HDFS_HOME}/bin/ozone\" \\\n+ozone_uservar_su hdfs datanode \"${OZONE_HOME}/bin/ozone\" \\\n     --workers \\\n-    --config \"${HADOOP_CONF_DIR}\" \\\n+    --config \"${OZONE_CONFIG_DIR}\" \\\n     --daemon start \\\n     datanode ${dataStartOpt}\n-(( HADOOP_JUMBO_RETCOUNTER=HADOOP_JUMBO_RETCOUNTER + $? ))\n+OZONE_JUMBO_RETCOUNTER=$?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA2MTI1Ng==", "bodyText": "Yes, this is intentional, please see item 4 in PR description:\n\nit was incremented for the first and third commands and unconditionally set for the second one, so the result of the first command was lost.  It should be set for the first one instead.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r543061256", "createdAt": "2020-12-15T05:39:51Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/dist/src/shell/ozone/start-ozone.sh", "diffHunk": "@@ -64,68 +63,53 @@ if [[ $# -ge 1 ]]; then\n       dataStartOpt=\"$startOpt\"\n     ;;\n     *)\n-      hadoop_exit_with_usage 1\n+      ozone_exit_with_usage 1\n     ;;\n   esac\n fi\n \n #Add other possible options\n nameStartOpt=\"$nameStartOpt $*\"\n \n-SECURITY_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getconf -confKey hadoop.security.authentication | tr '[:upper:]' '[:lower:]' 2>&-)\n-SECURITY_AUTHORIZATION_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getconf -confKey hadoop.security.authorization | tr '[:upper:]' '[:lower:]' 2>&-)\n-\n-#if [[ ${SECURITY_ENABLED} == \"kerberos\" || ${SECURITY_AUTHORIZATION_ENABLED}\n-# == \"true\" ]]; then\n-#  echo \"Ozone is not supported in a security enabled cluster.\"\n-#  exit 1\n-#fi\n-\n-#SECURITY_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getozoneconf -confKey hadoop.security.authentication | tr '[:upper:]' '[:lower:]' 2>&-)\n-#SECURITY_AUTHORIZATION_ENABLED=$(\"${HADOOP_HDFS_HOME}/bin/ozone\" getozoneconf -confKey hadoop.security.authorization | tr '[:upper:]' '[:lower:]' 2>&-)\n-#if [[ ${SECURITY_ENABLED} == \"kerberos\" || ${SECURITY_AUTHORIZATION_ENABLED} == \"true\" ]]; then\n-#  echo \"Ozone is not supported in a security enabled cluster.\"\n-#  exit 1\n-#fi\n+SECURITY_ENABLED=$(\"${OZONE_HOME}/bin/ozone\" getconf -confKey hadoop.security.authentication | tr '[:upper:]' '[:lower:]' 2>&-)\n+SECURITY_AUTHORIZATION_ENABLED=$(\"${OZONE_HOME}/bin/ozone\" getconf -confKey hadoop.security.authorization | tr '[:upper:]' '[:lower:]' 2>&-)\n \n # datanodes (using default workers file)\n \n echo \"Starting datanodes\"\n-hadoop_uservar_su hdfs datanode \"${HADOOP_HDFS_HOME}/bin/ozone\" \\\n+ozone_uservar_su hdfs datanode \"${OZONE_HOME}/bin/ozone\" \\\n     --workers \\\n-    --config \"${HADOOP_CONF_DIR}\" \\\n+    --config \"${OZONE_CONFIG_DIR}\" \\\n     --daemon start \\\n     datanode ${dataStartOpt}\n-(( HADOOP_JUMBO_RETCOUNTER=HADOOP_JUMBO_RETCOUNTER + $? ))\n+OZONE_JUMBO_RETCOUNTER=$?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAyOTY1NA=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTU2MDIyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop27/docker-config", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzoxNzowM1rOIHQSQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQyMDo0NDoyNVrOIHYXeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3Nzc2Mw==", "bodyText": "Is OZONE_CLASSPATH a placeholder here? Or we are setting it to empty on purpose.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544477763", "createdAt": "2020-12-16T17:17:03Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop27/docker-config", "diffHunk": "@@ -18,4 +18,7 @@ CORE-SITE.xml_fs.AbstractFileSystem.o3fs.impl=org.apache.hadoop.fs.ozone.OzFs\n CORE-SITE.xml_fs.AbstractFileSystem.ofs.impl=org.apache.hadoop.fs.ozone.RootedOzFs\n MAPRED-SITE.XML_mapreduce.application.classpath=/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop2-@project.version@.jar\n \n+HADOOP_CLASSPATH=/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop2-@project.version@.jar\n+OZONE_CLASSPATH=", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDYxMDE2OQ==", "bodyText": "setting it to empty on purpose\n\nExactly: without it HADOOP_CLASSPATH containing OzoneFS jar would be picked up, which is bad for Ozone's health.  Actually, this is the primary motivation for this entire change.  From description of HDDS-4525:\n\nsevere problem happens if we would like to access Ozone filesystem both via ozone and hadoop commands.  The latter needs shaded Ozone FS JAR in HADOOP_CLASSPATH.  The same HADOOP_CLASSPATH results in ClassNotFound for ozone.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544610169", "createdAt": "2020-12-16T20:44:25Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop27/docker-config", "diffHunk": "@@ -18,4 +18,7 @@ CORE-SITE.xml_fs.AbstractFileSystem.o3fs.impl=org.apache.hadoop.fs.ozone.OzFs\n CORE-SITE.xml_fs.AbstractFileSystem.ofs.impl=org.apache.hadoop.fs.ozone.RootedOzFs\n MAPRED-SITE.XML_mapreduce.application.classpath=/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop2-@project.version@.jar\n \n+HADOOP_CLASSPATH=/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop2-@project.version@.jar\n+OZONE_CLASSPATH=", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3Nzc2Mw=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTU2Mjg2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop31/docker-config", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzoxNzozMlrOIHQTvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzoxNzozMlrOIHQTvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3ODE0Mg==", "bodyText": "Same here.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544478142", "createdAt": "2020-12-16T17:17:32Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop31/docker-config", "diffHunk": "@@ -18,4 +18,7 @@ CORE-SITE.xml_fs.AbstractFileSystem.o3fs.impl=org.apache.hadoop.fs.ozone.OzFs\n CORE-SITE.xml_fs.AbstractFileSystem.ofs.impl=org.apache.hadoop.fs.ozone.RootedOzFs\n MAPRED-SITE.XML_mapreduce.application.classpath=/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop3-@project.version@.jar\n \n+HADOOP_CLASSPATH=/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop3-@project.version@.jar\n+OZONE_CLASSPATH=", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTU2MzY5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop32/docker-config", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzoxNzo0MlrOIHQUOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzoxNzo0MlrOIHQUOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ3ODI2Nw==", "bodyText": "Same", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544478267", "createdAt": "2020-12-16T17:17:42Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/compose/ozone-mr/hadoop32/docker-config", "diffHunk": "@@ -18,4 +18,7 @@ CORE-SITE.xml_fs.AbstractFileSystem.o3fs.impl=org.apache.hadoop.fs.ozone.OzFs\n CORE-SITE.xml_fs.AbstractFileSystem.ofs.impl=org.apache.hadoop.fs.ozone.RootedOzFs\n MAPRED-SITE.XML_mapreduce.application.classpath=/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop3-@project.version@.jar\n \n+HADOOP_CLASSPATH=/opt/ozone/share/ozone/lib/hadoop-ozone-filesystem-hadoop3-@project.version@.jar\n+OZONE_CLASSPATH=", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTU4ODU5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/smoketest/cli/classpath.robot", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzoyMjo0NFrOIHQi5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQxODoyMDozMlrOIN7_8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4MjAyMw==", "bodyText": "nice. btw do we pick up HADOOP_OPTS when OZONE_OPTS is not set as well?", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544482023", "createdAt": "2020-12-16T17:22:44Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/smoketest/cli/classpath.robot", "diffHunk": "@@ -0,0 +1,46 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test ozone classpath command\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Resource            ../ozone-lib/shell.robot\n+Test Timeout        5 minutes\n+Suite Setup         Find Jars Dir\n+\n+*** Test Cases ***\n+Ignores HADOOP_CLASSPATH if OZONE_CLASSPATH is set", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDYxNDY3OA==", "bodyText": "Yes.  There is a compatibility test for this.  We define some old OPTS:\n\n  \n    \n      ozone/hadoop-ozone/dist/src/main/compose/compatibility/docker-config\n    \n    \n        Lines 31 to 34\n      in\n      a70def9\n    \n    \n    \n    \n\n        \n          \n           HADOOP_OPTS=\"-Dhadoop.opts=test\" \n        \n\n        \n          \n           HDFS_STORAGECONTAINERMANAGER_OPTS=\"-Dhdfs.scm.opts=test\" \n        \n\n        \n          \n           HDFS_OM_OPTS=\"-Dhdfs.om.opts=test\" \n        \n\n        \n          \n           HDDS_DN_OPTS=\"-Dhdds.dn.opts=test\" \n        \n    \n  \n\n\nand then check if these are passed to the java process that ozone om command starts:\n\n  \n    \n      ozone/hadoop-ozone/dist/src/main/smoketest/compatibility/om.robot\n    \n    \n        Lines 23 to 27\n      in\n      e54c439\n    \n    \n    \n    \n\n        \n          \n           Picks up command line options \n        \n\n        \n          \n               Pass Execution If    '%{HDFS_OM_OPTS}' == ''    Command-line option required for process check \n        \n\n        \n          \n               ${processes} =    List All Processes \n        \n\n        \n          \n               Should Contain    ${processes}   %{HDFS_OM_OPTS} \n        \n\n        \n          \n               Should Contain    ${processes}   %{HADOOP_OPTS} \n        \n    \n  \n\n\n(Similar test exists for other components.)", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544614678", "createdAt": "2020-12-16T20:52:05Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/dist/src/main/smoketest/cli/classpath.robot", "diffHunk": "@@ -0,0 +1,46 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test ozone classpath command\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Resource            ../ozone-lib/shell.robot\n+Test Timeout        5 minutes\n+Suite Setup         Find Jars Dir\n+\n+*** Test Cases ***\n+Ignores HADOOP_CLASSPATH if OZONE_CLASSPATH is set", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4MjAyMw=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQ4NTQyNQ==", "bodyText": "awesome. thanks!", "url": "https://github.com/apache/ozone/pull/1667#discussion_r551485425", "createdAt": "2021-01-04T18:20:32Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/main/smoketest/cli/classpath.robot", "diffHunk": "@@ -0,0 +1,46 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test ozone classpath command\n+Library             BuiltIn\n+Resource            ../lib/os.robot\n+Resource            ../ozone-lib/shell.robot\n+Test Timeout        5 minutes\n+Suite Setup         Find Jars Dir\n+\n+*** Test Cases ***\n+Ignores HADOOP_CLASSPATH if OZONE_CLASSPATH is set", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4MjAyMw=="}, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMTczNTE5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/test/shell/gc_opts.bats", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzo1NToyMFrOIHR7Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzo1NToyMFrOIHR7Sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDUwNDY1MA==", "bodyText": "Unrelated to this patch but CMS is removed in JDK 14 and on and UseConcMarkSweepGC will be ignored by those higher version JVMs. We might want to come up with a new set of GC params soon.", "url": "https://github.com/apache/ozone/pull/1667#discussion_r544504650", "createdAt": "2020-12-16T17:55:20Z", "author": {"login": "smengcl"}, "path": "hadoop-ozone/dist/src/test/shell/gc_opts.bats", "diffHunk": "@@ -19,24 +19,32 @@\n # bats gc_opts.bats\n #\n \n-load ../../shell/hdds/hadoop-functions.sh\n-@test \"Setting Hadoop GC parameters: add GC params for server\" {\n-  export HADOOP_SUBCMD_SUPPORTDAEMONIZATION=true\n-  export HADOOP_OPTS=\"Test\"\n-  hadoop_add_default_gc_opts\n-  [[ \"$HADOOP_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n+load ozone-functions_test_helper\n+\n+@test \"Setting GC parameters: add GC params for server\" {\n+  export OZONE_SUBCMD_SUPPORTDAEMONIZATION=true\n+  export OZONE_OPTS=\"Test\"\n+\n+  ozone_add_default_gc_opts\n+\n+  echo $OZONE_OPTS\n+  [[ \"$OZONE_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n }\n \n-@test \"Setting Hadoop GC parameters: disabled for client\" {\n-  export HADOOP_SUBCMD_SUPPORTDAEMONIZATION=false\n-  export HADOOP_OPTS=\"Test\"\n-  hadoop_add_default_gc_opts\n-  [[ ! \"$HADOOP_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n+@test \"Setting GC parameters: disabled for client\" {\n+  export OZONE_SUBCMD_SUPPORTDAEMONIZATION=false\n+  export OZONE_OPTS=\"Test\"\n+\n+  ozone_add_default_gc_opts\n+\n+  [[ ! \"$OZONE_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n }\n \n-@test \"Setting Hadoop GC parameters: disabled if GC params are customized\" {\n-  export HADOOP_SUBCMD_SUPPORTDAEMONIZATION=true\n-  export HADOOP_OPTS=\"-XX:++UseG1GC -Xmx512\"\n-  hadoop_add_default_gc_opts\n-  [[ ! \"$HADOOP_OPTS\" =~ \"UseConcMarkSweepGC\" ]]\n+@test \"Setting GC parameters: disabled if GC params are customized\" {\n+  export OZONE_SUBCMD_SUPPORTDAEMONIZATION=true\n+  export OZONE_OPTS=\"-XX:++UseG1GC -Xmx512\"\n+\n+  ozone_add_default_gc_opts\n+\n+  [[ ! \"$OZONE_OPTS\" =~ \"UseConcMarkSweepGC\" ]]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e54c4390bcc8374970baa120b6c6d9b5a375ff1d"}, "originalPosition": 47}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4572, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}