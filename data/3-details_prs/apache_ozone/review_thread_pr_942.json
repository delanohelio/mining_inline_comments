{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5ODQ3Mjcx", "number": 942, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQyMzoyMjoyOVrOD-bI4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQyMDo0OTozNVrOD-vuig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NzgyOTQ1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/storage/BlockOutputStream.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQyMzoyMjozMFrOGYhI-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMzoyNDo1MVrOGYk9mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM2MTk3OQ==", "bodyText": "Same code is in multiple places, can we have short utility to do all these in that. So, this will avoid code smell in sonar.", "url": "https://github.com/apache/ozone/pull/942#discussion_r428361979", "createdAt": "2020-05-20T23:22:30Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/storage/BlockOutputStream.java", "diffHunk": "@@ -317,10 +317,16 @@ private void handleFullBuffer() throws IOException {\n       if (!commitWatcher.getFutureMap().isEmpty()) {\n         waitOnFlushFutures();\n       }\n-    } catch (InterruptedException | ExecutionException e) {\n+    } catch (ExecutionException e) {\n       setIoException(e);\n       adjustBuffersOnException();\n       throw getIoException();\n+    } catch (InterruptedException ex) {\n+      LOG.error(\"Command execution was interrupted.\");\n+      Thread.currentThread().interrupt();\n+      setIoException(ex);\n+      adjustBuffersOnException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4728db123281dcca0b568656d2e8fc49f0ed2c9a"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQyNDYwMA==", "bodyText": "@bharatviswa504  I have tried to move the duplicate lines to separate method and also perform other cleanups.\nAt the very least, the thread interrupt must be done in the catch block and not in a separate method being called from the catch block. So, the thread.interrupt() is the only line that cannot be avoided from being duplicated.", "url": "https://github.com/apache/ozone/pull/942#discussion_r428424600", "createdAt": "2020-05-21T03:24:51Z", "author": {"login": "dineshchitlangia"}, "path": "hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/storage/BlockOutputStream.java", "diffHunk": "@@ -317,10 +317,16 @@ private void handleFullBuffer() throws IOException {\n       if (!commitWatcher.getFutureMap().isEmpty()) {\n         waitOnFlushFutures();\n       }\n-    } catch (InterruptedException | ExecutionException e) {\n+    } catch (ExecutionException e) {\n       setIoException(e);\n       adjustBuffersOnException();\n       throw getIoException();\n+    } catch (InterruptedException ex) {\n+      LOG.error(\"Command execution was interrupted.\");\n+      Thread.currentThread().interrupt();\n+      setIoException(ex);\n+      adjustBuffersOnException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM2MTk3OQ=="}, "originalCommit": {"oid": "4728db123281dcca0b568656d2e8fc49f0ed2c9a"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MTE5NTM5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/storage/BlockOutputStream.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQyMDo0NzoyMFrOGZCTaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQyMjowNzoyNFrOGZEkPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODkwNTMyMQ==", "bodyText": "Minor NIT: variable name is called skipExecutionException, but when true, we are handling ExecutionException. I think it should be viceversa.", "url": "https://github.com/apache/ozone/pull/942#discussion_r428905321", "createdAt": "2020-05-21T20:47:20Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/storage/BlockOutputStream.java", "diffHunk": "@@ -654,4 +662,34 @@ private void writeChunkToContainer(ChunkBuffer chunk) throws IOException {\n   public void setXceiverClient(XceiverClientSpi xceiverClient) {\n     this.xceiverClient = xceiverClient;\n   }\n+\n+  /**\n+   * Handles InterruptedExecution.\n+   *\n+   * @param ex\n+   * @param skipExecutionException is optional, if passed as TRUE, then\n+   * handle ExecutionException else skip it.\n+   * @throws IOException\n+   */\n+  private void handleInterruptedException(Exception ex,\n+      boolean skipExecutionException)\n+      throws IOException {\n+    LOG.error(\"Command execution was interrupted.\");\n+    if(skipExecutionException) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cbd320ef9e7523020d76d05d73047351b4b0d278"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODk0MjM5OA==", "bodyText": "Addressed in latest commit.", "url": "https://github.com/apache/ozone/pull/942#discussion_r428942398", "createdAt": "2020-05-21T22:07:24Z", "author": {"login": "dineshchitlangia"}, "path": "hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/storage/BlockOutputStream.java", "diffHunk": "@@ -654,4 +662,34 @@ private void writeChunkToContainer(ChunkBuffer chunk) throws IOException {\n   public void setXceiverClient(XceiverClientSpi xceiverClient) {\n     this.xceiverClient = xceiverClient;\n   }\n+\n+  /**\n+   * Handles InterruptedExecution.\n+   *\n+   * @param ex\n+   * @param skipExecutionException is optional, if passed as TRUE, then\n+   * handle ExecutionException else skip it.\n+   * @throws IOException\n+   */\n+  private void handleInterruptedException(Exception ex,\n+      boolean skipExecutionException)\n+      throws IOException {\n+    LOG.error(\"Command execution was interrupted.\");\n+    if(skipExecutionException) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODkwNTMyMQ=="}, "originalCommit": {"oid": "cbd320ef9e7523020d76d05d73047351b4b0d278"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MTIwMjY2OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/storage/BlockOutputStream.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQyMDo0OTozNVrOGZCX1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQyMDo0OTozNVrOGZCX1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODkwNjQ1Mw==", "bodyText": "NIT: javadoc also need to be updated for this.", "url": "https://github.com/apache/ozone/pull/942#discussion_r428906453", "createdAt": "2020-05-21T20:49:35Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/storage/BlockOutputStream.java", "diffHunk": "@@ -654,4 +662,34 @@ private void writeChunkToContainer(ChunkBuffer chunk) throws IOException {\n   public void setXceiverClient(XceiverClientSpi xceiverClient) {\n     this.xceiverClient = xceiverClient;\n   }\n+\n+  /**\n+   * Handles InterruptedExecution.\n+   *\n+   * @param ex\n+   * @param skipExecutionException is optional, if passed as TRUE, then", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cbd320ef9e7523020d76d05d73047351b4b0d278"}, "originalPosition": 126}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4322, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}