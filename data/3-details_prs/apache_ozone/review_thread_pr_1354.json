{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDczODY2OTQ5", "number": 1354, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQyMzo0NjoyNlrOEcz_Qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQyMzo0NzowN1rOEc0BmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NjQ3MzYyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQyMzo0NjoyNlrOHHkaLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QyMzoxMTozNFrOHIkRDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY5ODYwNg==", "bodyText": "I understand that we do seek, because we don't do actual read just change the position at client. but using IOUtils.copyLarge we read and skip.\nNot sure if my understanding is right? If not, can you explain if I am missing anything here?", "url": "https://github.com/apache/ozone/pull/1354#discussion_r477698606", "createdAt": "2020-08-26T23:46:26Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "diffHunk": "@@ -277,7 +278,8 @@ public Response get(\n           try (S3WrapperInputStream s3WrapperInputStream =\n               new S3WrapperInputStream(\n                   key.getInputStream())) {\n-            IOUtils.copyLarge(s3WrapperInputStream, dest, startOffset,\n+            s3WrapperInputStream.seek(startOffset);\n+            IOUtils.copyLarge(s3WrapperInputStream, dest, 0,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1a729785afef127a605e67195fc09e622b3b8e5"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Nzg4NDk0Mw==", "bodyText": "The copyLarge related code is here\n    public static long copyLarge(final InputStream input, final OutputStream output,\n                                 final long inputOffset, final long length, final byte[] buffer) throws IOException {\n        if (inputOffset > 0) {\n            skipFully(input, inputOffset);\n        }\n        if (length == 0) {\n            return 0;\n        }\n        final int bufferLength = buffer.length;\n        int bytesToRead = bufferLength;\n        if (length > 0 && length < bufferLength) {\n            bytesToRead = (int) length;\n        }\n        int read;\n        long totalRead = 0;\n        while (bytesToRead > 0 && EOF != (read = input.read(buffer, 0, bytesToRead))) {\n            output.write(buffer, 0, read);\n            totalRead += read;\n            if (length > 0) { // only adjust length if not reading to the end\n                // Note the cast must work because buffer.length is an integer\n                bytesToRead = (int) Math.min(length - totalRead, bufferLength);\n            }\n        }\n        return totalRead;\n    }\n\n    public static void skipFully(final InputStream input, final long toSkip) throws IOException {\n        if (toSkip < 0) {\n            throw new IllegalArgumentException(\"Bytes to skip must not be negative: \" + toSkip);\n        }\n        final long skipped = skip(input, toSkip);\n        if (skipped != toSkip) {\n            throw new EOFException(\"Bytes to skip: \" + toSkip + \" actual: \" + skipped);\n        }\n    }\n\npublic static long skip(final InputStream input, final long toSkip) throws IOException {\n        if (toSkip < 0) {\n            throw new IllegalArgumentException(\"Skip count must be non-negative, actual: \" + toSkip);\n        }\n        /*\n         * N.B. no need to synchronize this because: - we don't care if the buffer is created multiple times (the data\n         * is ignored) - we always use the same size buffer, so if it it is recreated it will still be OK (if the buffer\n         * size were variable, we would need to synch. to ensure some other thread did not create a smaller one)\n         */\n        if (SKIP_BYTE_BUFFER == null) {\n            SKIP_BYTE_BUFFER = new byte[SKIP_BUFFER_SIZE];\n        }\n        long remain = toSkip;\n        while (remain > 0) {\n            // See https://issues.apache.org/jira/browse/IO-203 for why we use read() rather than delegating to skip()\n            final long n = input.read(SKIP_BYTE_BUFFER, 0, (int) Math.min(remain, SKIP_BUFFER_SIZE));\n            if (n < 0) { // EOF\n                break;\n            }\n            remain -= n;\n        }\n        return toSkip - remain;\n    }\nFrom the above code of IOUtils.java, we can know that the static method skip really read the inputstream, it is unnecessary and impact the performance, instead, using seek can set the position to the right point, Let's imaging that there are a 10GB file, when we want to read the if for offset 1GB and length 1GB, it have to read the first 1GB contents from datanode and drop it, now, we can seek to the position 1GB, and read the inputstream directly.", "url": "https://github.com/apache/ozone/pull/1354#discussion_r477884943", "createdAt": "2020-08-27T01:39:35Z", "author": {"login": "maobaolong"}, "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "diffHunk": "@@ -277,7 +278,8 @@ public Response get(\n           try (S3WrapperInputStream s3WrapperInputStream =\n               new S3WrapperInputStream(\n                   key.getInputStream())) {\n-            IOUtils.copyLarge(s3WrapperInputStream, dest, startOffset,\n+            s3WrapperInputStream.seek(startOffset);\n+            IOUtils.copyLarge(s3WrapperInputStream, dest, 0,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY5ODYwNg=="}, "originalCommit": {"oid": "d1a729785afef127a605e67195fc09e622b3b8e5"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODc0NDg0Ng==", "bodyText": "Got it.", "url": "https://github.com/apache/ozone/pull/1354#discussion_r478744846", "createdAt": "2020-08-27T23:11:34Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "diffHunk": "@@ -277,7 +278,8 @@ public Response get(\n           try (S3WrapperInputStream s3WrapperInputStream =\n               new S3WrapperInputStream(\n                   key.getInputStream())) {\n-            IOUtils.copyLarge(s3WrapperInputStream, dest, startOffset,\n+            s3WrapperInputStream.seek(startOffset);\n+            IOUtils.copyLarge(s3WrapperInputStream, dest, 0,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY5ODYwNg=="}, "originalCommit": {"oid": "d1a729785afef127a605e67195fc09e622b3b8e5"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4NjQ3OTYxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQyMzo0NzowN1rOHHkeTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwMToxNTo1MVrOHImSnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY5OTY2Mw==", "bodyText": "skip again uses read and moves the position, why not use like above seek and call copylarge?", "url": "https://github.com/apache/ozone/pull/1354#discussion_r477699663", "createdAt": "2020-08-26T23:47:07Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "diffHunk": "@@ -557,8 +559,14 @@ private Response createMultipartKey(String bucket, String key, long length,\n             if (range != null) {\n               RangeHeader rangeHeader =\n                   RangeHeaderParserUtil.parseRangeHeader(range, 0);\n-              IOUtils.copyLarge(sourceObject, ozoneOutputStream,\n-                  rangeHeader.getStartOffset(),\n+              final long skipped =\n+                  sourceObject.skip(rangeHeader.getStartOffset());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1a729785afef127a605e67195fc09e622b3b8e5"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Nzg5MTMwMQ==", "bodyText": "@bharatviswa504 use skip here due to we are not sure the sourceObject is a seekable inputstream, so I have to use skip method, but luckily, I have override the skip method in KeyInputStream.java, it look like\n  public long skip(long n) throws IOException {\n    if (n <= 0) {\n      return 0;\n    }\n\n    long toSkip = Math.min(n, length - getPos());\n    seek(getPos() + toSkip);\n    return toSkip;\n  }\nSo, for KeyInputStream which is an implementation of InputStream, which implements the skip method to a seek mode, it can bring the better performance.", "url": "https://github.com/apache/ozone/pull/1354#discussion_r477891301", "createdAt": "2020-08-27T01:44:16Z", "author": {"login": "maobaolong"}, "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "diffHunk": "@@ -557,8 +559,14 @@ private Response createMultipartKey(String bucket, String key, long length,\n             if (range != null) {\n               RangeHeader rangeHeader =\n                   RangeHeaderParserUtil.parseRangeHeader(range, 0);\n-              IOUtils.copyLarge(sourceObject, ozoneOutputStream,\n-                  rangeHeader.getStartOffset(),\n+              final long skipped =\n+                  sourceObject.skip(rangeHeader.getStartOffset());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY5OTY2Mw=="}, "originalCommit": {"oid": "d1a729785afef127a605e67195fc09e622b3b8e5"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODc0NDM2MA==", "bodyText": "But we use OzoneInputStream here, which has not implemented the skip(). So we use from BaseClass InputStream, which does not take advantage of KeyInputStream seek implementation.\npublic long skip(long n) throws IOException {\n\n    long remaining = n;\n    int nr;\n\n    if (n <= 0) {\n        return 0;\n    }\n\n    int size = (int)Math.min(MAX_SKIP_BUFFER_SIZE, remaining);\n    byte[] skipBuffer = new byte[size];\n    while (remaining > 0) {\n        nr = read(skipBuffer, 0, (int)Math.min(size, remaining));\n        if (nr < 0) {\n            break;\n        }\n        remaining -= nr;\n    }\n\n    return n - remaining;\n}", "url": "https://github.com/apache/ozone/pull/1354#discussion_r478744360", "createdAt": "2020-08-27T23:10:09Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "diffHunk": "@@ -557,8 +559,14 @@ private Response createMultipartKey(String bucket, String key, long length,\n             if (range != null) {\n               RangeHeader rangeHeader =\n                   RangeHeaderParserUtil.parseRangeHeader(range, 0);\n-              IOUtils.copyLarge(sourceObject, ozoneOutputStream,\n-                  rangeHeader.getStartOffset(),\n+              final long skipped =\n+                  sourceObject.skip(rangeHeader.getStartOffset());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY5OTY2Mw=="}, "originalCommit": {"oid": "d1a729785afef127a605e67195fc09e622b3b8e5"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODc0NDc2OA==", "bodyText": "Why can't we add seek to OzoneInputStream like how we have done for S3WrapperInputStream.\nAs anyway underlying inputStream used in OzoneInputStream is KeyInputStream which has implemented seek.", "url": "https://github.com/apache/ozone/pull/1354#discussion_r478744768", "createdAt": "2020-08-27T23:11:18Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "diffHunk": "@@ -557,8 +559,14 @@ private Response createMultipartKey(String bucket, String key, long length,\n             if (range != null) {\n               RangeHeader rangeHeader =\n                   RangeHeaderParserUtil.parseRangeHeader(range, 0);\n-              IOUtils.copyLarge(sourceObject, ozoneOutputStream,\n-                  rangeHeader.getStartOffset(),\n+              final long skipped =\n+                  sourceObject.skip(rangeHeader.getStartOffset());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY5OTY2Mw=="}, "originalCommit": {"oid": "d1a729785afef127a605e67195fc09e622b3b8e5"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODc3ODAxMw==", "bodyText": "@bharatviswa504 Thanks for your suggestion, indeed, it is necessary to override the skip method of OzoneInputStream, I've done it by the last commit.", "url": "https://github.com/apache/ozone/pull/1354#discussion_r478778013", "createdAt": "2020-08-28T01:15:51Z", "author": {"login": "maobaolong"}, "path": "hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java", "diffHunk": "@@ -557,8 +559,14 @@ private Response createMultipartKey(String bucket, String key, long length,\n             if (range != null) {\n               RangeHeader rangeHeader =\n                   RangeHeaderParserUtil.parseRangeHeader(range, 0);\n-              IOUtils.copyLarge(sourceObject, ozoneOutputStream,\n-                  rangeHeader.getStartOffset(),\n+              final long skipped =\n+                  sourceObject.skip(rangeHeader.getStartOffset());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY5OTY2Mw=="}, "originalCommit": {"oid": "d1a729785afef127a605e67195fc09e622b3b8e5"}, "originalPosition": 25}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3925, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}