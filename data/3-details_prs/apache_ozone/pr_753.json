{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk3Mzg2ODAy", "number": 753, "title": "HDDS-3237. Recon should provide the list of datanodes that a missing \u2026", "bodyText": "\u2026container was present in.\nWhat changes were proposed in this pull request?\n\nCreate a new table in SQLite to keep track of container replica history\nInclude the last known datanodes of a missing container in API (/api/v1/containers/missing)\nAdd a new API (/api/v1/containers/{id}/replicaHistory) to get complete history of container replicas.\nMake changes in the UI to display datanode information in missing containers page.\nAdd unit and acceptance tests.\n\nWhat is the link to the Apache JIRA\nhttps://issues.apache.org/jira/browse/HDDS-3237\nHow was this patch tested?\n\nUnit tests, acceptance tests and manual test via docker-compose.\n\nTo test the change,\ncd hadoop-ozone/dist/target/ozone-0.6.0-SNAPSHOT/compose/ozone\nAdd the following lines to docker-config for faster testing\nOZONE-SITE.XML_ozone.scm.dead.node.interval=2m\nOZONE-SITE.XML_ozone.scm.stale.node.interval=1m\n\ndocker-compose up -d\ndocker-compose exec om bash\nozone freon rk --replicationType=RATIS --numOfVolumes=10 --numOfBuckets=10 --numOfKeys=10 --factor=ONE --numOfThreads=20\n\nNow, exit the shell and bring down datanode\ndocker ps\ndocker kill <containerid>\nNavigate to Recon UI and wait for a few minutes to see missing container alert in the Overview page. Clicking on the alert box should take you to the missing containers page:", "createdAt": "2020-04-02T06:42:58Z", "url": "https://github.com/apache/ozone/pull/753", "merged": true, "mergeCommit": {"oid": "e54d0b5681a2ae7491c90ed782c151b6d9288646"}, "closed": true, "closedAt": "2020-04-04T03:52:56Z", "author": {"login": "vivekratnavel"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcTmTcAAH2gAyMzk3Mzg2ODAyOmU5ZjljNTM5MzVkNDU1MWEzODZkNzMwMjkzY2ZiYjZhOTk4ZDJlZTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcUNRyrAFqTM4NzY2NDQzNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "e9f9c53935d4551a386d730293cfbb6a998d2ee9", "author": {"user": {"login": "vivekratnavel", "name": "Vivek Ratnavel Subramanian"}}, "url": "https://github.com/apache/ozone/commit/e9f9c53935d4551a386d730293cfbb6a998d2ee9", "committedDate": "2020-04-02T06:28:16Z", "message": "HDDS-3237. Recon should provide the list of datanodes that a missing container was present in."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d387f2e7b40a89d8f4e4c54184ae1cb20585718e", "author": {"user": {"login": "vivekratnavel", "name": "Vivek Ratnavel Subramanian"}}, "url": "https://github.com/apache/ozone/commit/d387f2e7b40a89d8f4e4c54184ae1cb20585718e", "committedDate": "2020-04-02T15:52:20Z", "message": "Fix acceptance test failures"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NDk4NzQx", "url": "https://github.com/apache/ozone/pull/753#pullrequestreview-386498741", "createdAt": "2020-04-02T14:44:50Z", "commit": {"oid": "e9f9c53935d4551a386d730293cfbb6a998d2ee9"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxNDo0NDo1MFrOF_uuSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQxODoxMzo1NFrOF_3oSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjM3MDEyMQ==", "bodyText": "I believe DSLContext is shared across tables. We may be able to inject this. But, I am OK with having the getter inside just this schema definition.", "url": "https://github.com/apache/ozone/pull/753#discussion_r402370121", "createdAt": "2020-04-02T14:44:50Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon-codegen/src/main/java/org/hadoop/ozone/recon/schema/ContainerSchemaDefinition.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.hadoop.ozone.recon.schema;\n+\n+import com.google.inject.Inject;\n+import com.google.inject.Singleton;\n+import org.jooq.DSLContext;\n+import org.jooq.impl.DSL;\n+import org.jooq.impl.SQLDataType;\n+\n+import javax.sql.DataSource;\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+\n+/**\n+ * Class used to create tables that are required for tracking containers.\n+ */\n+@Singleton\n+public class ContainerSchemaDefinition implements ReconSchemaDefinition {\n+\n+  public static final String CONTAINER_HISTORY_TABLE_NAME =\n+      \"container_history\";\n+  public static final String MISSING_CONTAINERS_TABLE_NAME =\n+      \"missing_containers\";\n+  private static final String CONTAINER_ID = \"container_id\";\n+  private final DataSource dataSource;\n+  private DSLContext dslContext;\n+\n+  @Inject\n+  ContainerSchemaDefinition(DataSource dataSource) {\n+    this.dataSource = dataSource;\n+  }\n+\n+  @Override\n+  public void initializeSchema() throws SQLException {\n+    Connection conn = dataSource.getConnection();\n+    dslContext = DSL.using(conn);\n+    createContainerHistoryTable();\n+    createMissingContainersTable();\n+  }\n+\n+  /**\n+   * Create the Container History table.\n+   */\n+  private void createContainerHistoryTable() {\n+    dslContext.createTableIfNotExists(CONTAINER_HISTORY_TABLE_NAME)\n+        .column(CONTAINER_ID, SQLDataType.BIGINT)\n+        .column(\"datanode_host\", SQLDataType.VARCHAR(1024))\n+        .column(\"first_report_timestamp\", SQLDataType.BIGINT)\n+        .column(\"last_report_timestamp\", SQLDataType.BIGINT)\n+        .constraint(DSL.constraint(\"pk_container_id_datanode_host\")\n+            .primaryKey(CONTAINER_ID, \"datanode_host\"))\n+        .execute();\n+  }\n+\n+  /**\n+   * Create the Missing Containers table.\n+   */\n+  private void createMissingContainersTable() {\n+    dslContext.createTableIfNotExists(MISSING_CONTAINERS_TABLE_NAME)\n+        .column(CONTAINER_ID, SQLDataType.BIGINT)\n+        .column(\"missing_since\", SQLDataType.BIGINT)\n+        .constraint(DSL.constraint(\"pk_container_id\")\n+            .primaryKey(CONTAINER_ID))\n+        .execute();\n+  }\n+\n+  public DSLContext getDSLContext() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9f9c53935d4551a386d730293cfbb6a998d2ee9"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUwMjI2Nw==", "bodyText": "Instead of initializing a schema definition as and when needed in tests, we can create a test harness that creates a test sql DB, and provides access to any DAO that the test may need. This will remove the need for a unit test to know what DAO is needed somewhere deep inside the flow, and the code will be much cleaner. Of course, this will be a different JIRA work item.", "url": "https://github.com/apache/ozone/pull/753#discussion_r402502267", "createdAt": "2020-04-02T17:50:39Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/fsck/TestMissingContainerTask.java", "diffHunk": "@@ -58,10 +60,16 @@ public void testRun() throws Exception {\n         ReconTaskSchemaDefinition.class);\n     taskSchemaDefinition.initializeSchema();\n \n-    UtilizationSchemaDefinition schemaDefinition =\n-        getInjector().getInstance(UtilizationSchemaDefinition.class);\n+    ContainerSchemaDefinition schemaDefinition =\n+        getInjector().getInstance(ContainerSchemaDefinition.class);\n     schemaDefinition.initializeSchema();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9f9c53935d4551a386d730293cfbb6a998d2ee9"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUwOTg0MQ==", "bodyText": "Here we are doing 2 lookups - first 'existsById' and then 'findById'. Can we refactor this by doing only one lookup instead?", "url": "https://github.com/apache/ozone/pull/753#discussion_r402509841", "createdAt": "2020-04-02T18:03:07Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/persistence/ContainerSchemaManager.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.persistence;\n+\n+import static org.hadoop.ozone.recon.schema.tables.ContainerHistoryTable.CONTAINER_HISTORY;\n+\n+import com.google.inject.Inject;\n+import com.google.inject.Singleton;\n+import org.hadoop.ozone.recon.schema.ContainerSchemaDefinition;\n+import org.hadoop.ozone.recon.schema.tables.daos.ContainerHistoryDao;\n+import org.hadoop.ozone.recon.schema.tables.daos.MissingContainersDao;\n+import org.hadoop.ozone.recon.schema.tables.pojos.ContainerHistory;\n+import org.hadoop.ozone.recon.schema.tables.pojos.MissingContainers;\n+import org.jooq.DSLContext;\n+import org.jooq.Record2;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Provide a high level API to access the Container Schema.\n+ */\n+@Singleton\n+public class ContainerSchemaManager {\n+  private ContainerHistoryDao containerHistoryDao;\n+  private MissingContainersDao missingContainersDao;\n+  private ContainerSchemaDefinition containerSchemaDefinition;\n+\n+  @Inject\n+  public ContainerSchemaManager(ContainerHistoryDao containerHistoryDao,\n+              ContainerSchemaDefinition containerSchemaDefinition,\n+              MissingContainersDao missingContainersDao) {\n+    this.containerHistoryDao = containerHistoryDao;\n+    this.missingContainersDao = missingContainersDao;\n+    this.containerSchemaDefinition = containerSchemaDefinition;\n+  }\n+\n+  public void addMissingContainer(long containerID, long time) {\n+    MissingContainers record = new MissingContainers(containerID, time);\n+    missingContainersDao.insert(record);\n+  }\n+\n+  public List<MissingContainers> getAllMissingContainers() {\n+    return missingContainersDao.findAll();\n+  }\n+\n+  public boolean isMissingContainer(long containerID) {\n+    return missingContainersDao.existsById(containerID);\n+  }\n+\n+  public void deleteMissingContainer(long containerID) {\n+    missingContainersDao.deleteById(containerID);\n+  }\n+\n+  public void upsertContainerHistory(long containerID, String datanode,\n+                                     long time) {\n+    DSLContext ctx = containerSchemaDefinition.getDSLContext();\n+    Record2<Long, String> record =\n+        ctx.newRecord(\n+        CONTAINER_HISTORY.CONTAINER_ID,\n+        CONTAINER_HISTORY.DATANODE_HOST).value1(containerID).value2(datanode);\n+    ContainerHistory newRecord = new ContainerHistory();\n+    newRecord.setContainerId(containerID);\n+    newRecord.setDatanodeHost(datanode);\n+    newRecord.setLastReportTimestamp(time);\n+    if (containerHistoryDao.existsById(record)) {\n+      newRecord.setFirstReportTimestamp(\n+          containerHistoryDao.findById(record).getFirstReportTimestamp()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d387f2e7b40a89d8f4e4c54184ae1cb20585718e"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjUxNjA0Mw==", "bodyText": "Can we try and use ORDER BY and LIMIT on the DB side (using SELECT API maybe) instead of client side sorting and filtering?", "url": "https://github.com/apache/ozone/pull/753#discussion_r402516043", "createdAt": "2020-04-02T18:13:54Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/persistence/ContainerSchemaManager.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.persistence;\n+\n+import static org.hadoop.ozone.recon.schema.tables.ContainerHistoryTable.CONTAINER_HISTORY;\n+\n+import com.google.inject.Inject;\n+import com.google.inject.Singleton;\n+import org.hadoop.ozone.recon.schema.ContainerSchemaDefinition;\n+import org.hadoop.ozone.recon.schema.tables.daos.ContainerHistoryDao;\n+import org.hadoop.ozone.recon.schema.tables.daos.MissingContainersDao;\n+import org.hadoop.ozone.recon.schema.tables.pojos.ContainerHistory;\n+import org.hadoop.ozone.recon.schema.tables.pojos.MissingContainers;\n+import org.jooq.DSLContext;\n+import org.jooq.Record2;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Provide a high level API to access the Container Schema.\n+ */\n+@Singleton\n+public class ContainerSchemaManager {\n+  private ContainerHistoryDao containerHistoryDao;\n+  private MissingContainersDao missingContainersDao;\n+  private ContainerSchemaDefinition containerSchemaDefinition;\n+\n+  @Inject\n+  public ContainerSchemaManager(ContainerHistoryDao containerHistoryDao,\n+              ContainerSchemaDefinition containerSchemaDefinition,\n+              MissingContainersDao missingContainersDao) {\n+    this.containerHistoryDao = containerHistoryDao;\n+    this.missingContainersDao = missingContainersDao;\n+    this.containerSchemaDefinition = containerSchemaDefinition;\n+  }\n+\n+  public void addMissingContainer(long containerID, long time) {\n+    MissingContainers record = new MissingContainers(containerID, time);\n+    missingContainersDao.insert(record);\n+  }\n+\n+  public List<MissingContainers> getAllMissingContainers() {\n+    return missingContainersDao.findAll();\n+  }\n+\n+  public boolean isMissingContainer(long containerID) {\n+    return missingContainersDao.existsById(containerID);\n+  }\n+\n+  public void deleteMissingContainer(long containerID) {\n+    missingContainersDao.deleteById(containerID);\n+  }\n+\n+  public void upsertContainerHistory(long containerID, String datanode,\n+                                     long time) {\n+    DSLContext ctx = containerSchemaDefinition.getDSLContext();\n+    Record2<Long, String> record =\n+        ctx.newRecord(\n+        CONTAINER_HISTORY.CONTAINER_ID,\n+        CONTAINER_HISTORY.DATANODE_HOST).value1(containerID).value2(datanode);\n+    ContainerHistory newRecord = new ContainerHistory();\n+    newRecord.setContainerId(containerID);\n+    newRecord.setDatanodeHost(datanode);\n+    newRecord.setLastReportTimestamp(time);\n+    if (containerHistoryDao.existsById(record)) {\n+      newRecord.setFirstReportTimestamp(\n+          containerHistoryDao.findById(record).getFirstReportTimestamp()\n+      );\n+      containerHistoryDao.update(newRecord);\n+    } else {\n+      newRecord.setFirstReportTimestamp(time);\n+      containerHistoryDao.insert(newRecord);\n+    }\n+  }\n+\n+  public List<ContainerHistory> getAllContainerHistory(long containerID) {\n+    return containerHistoryDao.fetchByContainerId(containerID);\n+  }\n+\n+  public List<ContainerHistory> getLatestContainerHistory(long containerID,\n+                                                          int limit) {\n+    // Get container history sorted in descending order of timestamp\n+    List<ContainerHistory> containerHistory =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d387f2e7b40a89d8f4e4c54184ae1cb20585718e"}, "originalPosition": 98}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41203c628b4a494a811f76c69bcaaab54b481776", "author": {"user": {"login": "vivekratnavel", "name": "Vivek Ratnavel Subramanian"}}, "url": "https://github.com/apache/ozone/commit/41203c628b4a494a811f76c69bcaaab54b481776", "committedDate": "2020-04-03T20:00:35Z", "message": "Fix review comments."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3NjY0NDM3", "url": "https://github.com/apache/ozone/pull/753#pullrequestreview-387664437", "createdAt": "2020-04-04T03:52:46Z", "commit": {"oid": "41203c628b4a494a811f76c69bcaaab54b481776"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3425, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}