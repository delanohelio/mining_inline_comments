{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc5MjAwOTc0", "number": 596, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQyMjoxNzo1MlrODif3Hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOToxNTowOVrODjlBsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3NTAwMTkwOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "isResolved": false, "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQyMjoxNzo1MlrOFtx6gQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMjoyNDo0NFrOFu-nkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw==", "bodyText": "Pipeline scrubber only destroy pipeline that has been in ALLOCATED for too long. And the container loader only call addContainerToPipeline if the container is in OPEN state.\nIf I understand correctly, we should not have OPEN container assigned on an ALLOCATED pipeline.", "url": "https://github.com/apache/ozone/pull/596#discussion_r383548033", "createdAt": "2020-02-24T22:17:52Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU2MTg1Mw==", "bodyText": "When SCM is restarted, all pipelines will be in allocated state, they will be moved to open state. And when pipeline reports are received from DN, they will be moved to Open State.\nSo, here scrubber removed those pipelines and container is in open State.\n2020-02-20 12:42:18,947 [RatisPipelineUtilsThread] INFO org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 35dff62d-9bfa-449b-b6e8-6f00cc8c1b6e, Nodes: 53fc2e1a-73da-4ae7-8725-9cc23ac6c393{ip: 10.65.54.245, host: om-ha-3.vpc.cloudera.com, networkLocation: /default-rack, certSerialId: null}2346b987-3126-48b8-b2d2-e8244cb2e0ae{ip: 10.65.51.168, host: om-ha-2.vpc.cloudera.com, networkLocation: /default-rack, certSerialId: null}45987d8b-4bfd-4ccc-bf2f-224bcf5b0dcd{ip: 10.65.51.49, host: om-ha-1.vpc.cloudera.com, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-02-20T03:59:02.043Z]\n2020-02-20 12:42:18,947 [RatisPipelineUtilsThread] INFO org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 35dff62d-9bfa-449b-b6e8-6f00cc8c1b6e, Nodes: 53fc2e1a-73da-4ae7-8725-9cc23ac6c393{ip: 10.65.54.245, host: om-ha-3.vpc.cloudera.com, networkLocation: /default-rack, certSerialId: null}2346b987-3126-48b8-b2d2-e8244cb2e0ae{ip: 10.65.51.168, host: om-ha-2.vpc.cloudera.com, networkLocation: /default-rack, certSerialId: null}45987d8b-4bfd-4ccc-bf2f-224bcf5b0dcd{ip: 10.65.51.49, host: om-ha-1.vpc.cloudera.com, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:null, CreationTimestamp2020-02-20T03:59:02.043Z] moved to CLOSED state\nAnd SCM log in first restart.\nNow after 2nd restart the pipeline is not in DB, but the container is in open state.", "url": "https://github.com/apache/ozone/pull/596#discussion_r383561853", "createdAt": "2020-02-24T22:50:55Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw=="}, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU2MjE0NQ==", "bodyText": "And also I am thinking scrubber should not come and delete pipelines until we are out of SafeMode, will try to do that in a new jira.", "url": "https://github.com/apache/ozone/pull/596#discussion_r383562145", "createdAt": "2020-02-24T22:51:37Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw=="}, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU3MDcxMw==", "bodyText": "As mentioned in Jira, another scenario where this can happen\nThis can happen in other scenarios like when safeModeHandler calls finalizeAndDestroyPipeline and do SCM restart.\nAs we remove the pipeline from DB and container can be in an open state. (This can happen because close container command is triggered, but not yet processed.) When SCM restart, we can be in this scenario.", "url": "https://github.com/apache/ozone/pull/596#discussion_r383570713", "createdAt": "2020-02-24T23:14:29Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw=="}, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDEwNzM5NA==", "bodyText": "bq. And also I am thinking scrubber should not come and delete pipelines until we are out of SafeMode, will try to do that in a new jira.\nAgree, we should have a special state to indicate that state of the pipeline. We can fix it in a separate JIRA.", "url": "https://github.com/apache/ozone/pull/596#discussion_r384107394", "createdAt": "2020-02-25T20:26:42Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw=="}, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDExMzQ5MA==", "bodyText": "Scrubbing to start after safe mode, I have handled in this PR #605\nI see that we can do without introducing a new state.", "url": "https://github.com/apache/ozone/pull/596#discussion_r384113490", "createdAt": "2020-02-25T20:39:59Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw=="}, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4MTA5MA==", "bodyText": "I think there are values to keep the scurbber running in safemode. Without it, any pipeline created/restored during safemode will hold there forever if any issue hit during pipeline creation. This prevent new pipeline from being created to exit safemode.\nE.g., when datanodes restart during safemode pipeline creation, before the pipeline report changed the SCM pipeline state from ALLOCATE to OPEN.", "url": "https://github.com/apache/ozone/pull/596#discussion_r384781090", "createdAt": "2020-02-26T21:36:28Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw=="}, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc5MDgxNA==", "bodyText": "If old pipelines are reported, and they are only accounted for SafeMode rule calculation. (Because the pipeline count is got from pipeline DB during startup)\nOnce, we are out of safe mode, we are triggering pipeline creation.\nSo, to come out of safe mode pipelines which have already been created if we have them and they are reported according to percentage configured, we can come out of safe mode.\nThe main purpose not to run scrub in safe mode is if it is closing the pipelines where datanodes have still not reported, we shall never come out of safe mode. To avoid this kind of scenario, I think running scrubber in safe mode is not correct.", "url": "https://github.com/apache/ozone/pull/596#discussion_r384790814", "createdAt": "2020-02-26T21:55:31Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw=="}, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc5MTEzMg==", "bodyText": "The fix for not to run scrubber is in HDDS-3072, we can discuss more on that over #605\nIf this is fine, we can get this in.", "url": "https://github.com/apache/ozone/pull/596#discussion_r384791132", "createdAt": "2020-02-26T21:56:11Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw=="}, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgwNDc1NQ==", "bodyText": "bq. The main purpose not to run scrub in safe mode is if it is closing the pipelines where datanodes have still not reported, we shall never come out of safe mode.\nMulti-raft allows additional pipeline being created on top if existing one if they are not functional. To new OM client to write, there is no difference between pipeline loaded/reported or created/reported. If those loaded but not reported pipeline is not working, we should use scrubber to allow recreate/report. Agree, we can discuss this on #605.", "url": "https://github.com/apache/ozone/pull/596#discussion_r384804755", "createdAt": "2020-02-26T22:24:44Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +126,17 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU0ODAzMw=="}, "originalCommit": {"oid": "ff0eef45745e5e73fff5c0cb750507b981762786"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3ODYyNDc0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMDozNjo0NVrOFuUVpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQwMDoxMjowMVrOFuZ_CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDExMjAzNw==", "bodyText": "NIT: can we reword \"with out a pipeline {}\" to \"with pipeline {} that does not exist\"", "url": "https://github.com/apache/ozone/pull/596#discussion_r384112037", "createdAt": "2020-02-25T20:36:45Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +119,28 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {\n+          pipelineManager.addContainerToPipeline(container.getPipelineID(),\n+              ContainerID.valueof(container.getContainerID()));\n+        }\n+      } catch (PipelineNotFoundException ex) {\n+        LOG.warn(\"Found a Container {} which is in {} state with out a \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cecc04cbc0eb7010089d985da0c2d0a9fd0bfce6"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDIwNDU1Mw==", "bodyText": "Fixed it.", "url": "https://github.com/apache/ozone/pull/596#discussion_r384204553", "createdAt": "2020-02-26T00:12:01Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +119,28 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {\n+          pipelineManager.addContainerToPipeline(container.getPipelineID(),\n+              ContainerID.valueof(container.getContainerID()));\n+        }\n+      } catch (PipelineNotFoundException ex) {\n+        LOG.warn(\"Found a Container {} which is in {} state with out a \" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDExMjAzNw=="}, "originalCommit": {"oid": "cecc04cbc0eb7010089d985da0c2d0a9fd0bfce6"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3ODY0NTY0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNVQyMDo0NDowNlrOFuUirQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQwMDoxMDozNVrOFuZ9MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDExNTM3Mw==", "bodyText": "This comment does not match with the code any more. Should we remove it?\n\"// Not firing CLOSE_CONTAINER event ...\"", "url": "https://github.com/apache/ozone/pull/596#discussion_r384115373", "createdAt": "2020-02-25T20:44:06Z", "author": {"login": "xiaoyuyao"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +119,28 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {\n+          pipelineManager.addContainerToPipeline(container.getPipelineID(),\n+              ContainerID.valueof(container.getContainerID()));\n+        }\n+      } catch (PipelineNotFoundException ex) {\n+        LOG.warn(\"Found a Container {} which is in {} state with out a \" +\n+            \"pipeline {}. Close Container.\", container, container.getState(),\n+            container.getPipelineID());\n+\n+        // Not firing CLOSE_CONTAINER event because CloseContainer Event", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cecc04cbc0eb7010089d985da0c2d0a9fd0bfce6"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDIwNDA4MA==", "bodyText": "This was added to explain the reason why we are not calling CLOSE_CONTAINER event to close container. In future, if someone changes this part of the code, they will know the reason in doing this way.", "url": "https://github.com/apache/ozone/pull/596#discussion_r384204080", "createdAt": "2020-02-26T00:10:35Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +119,28 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {\n+          pipelineManager.addContainerToPipeline(container.getPipelineID(),\n+              ContainerID.valueof(container.getContainerID()));\n+        }\n+      } catch (PipelineNotFoundException ex) {\n+        LOG.warn(\"Found a Container {} which is in {} state with out a \" +\n+            \"pipeline {}. Close Container.\", container, container.getState(),\n+            container.getPipelineID());\n+\n+        // Not firing CLOSE_CONTAINER event because CloseContainer Event", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDExNTM3Mw=="}, "originalCommit": {"oid": "cecc04cbc0eb7010089d985da0c2d0a9fd0bfce6"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NjMyNDg2OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOToxMjowOVrOFvdxQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMjoxMDo0NVrOFvjAdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMxNTEzOQ==", "bodyText": "We don't need this comment. As SCMContainerManager is the one which is taking this decision, it should not file an event to close the container. It is logical to directly update the container state.\nIt is very explicit that we are performing this in case of PipelineNotFoundException, so there is no need to repeat it again.", "url": "https://github.com/apache/ozone/pull/596#discussion_r385315139", "createdAt": "2020-02-27T19:12:09Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +119,28 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {\n+          pipelineManager.addContainerToPipeline(container.getPipelineID(),\n+              ContainerID.valueof(container.getContainerID()));\n+        }\n+      } catch (PipelineNotFoundException ex) {\n+        LOG.warn(\"Found a Container {} which is in {} state with pipeline {} \" +\n+                \"that does not exist. Closing Container.\", container,\n+            container.getState(), container.getPipelineID());\n+\n+        // Not firing CLOSE_CONTAINER event because CloseContainer event\n+        // handler is not registered by the time when we come\n+        // here. So, we are calling update Container state to set\n+        // container state to CLOSING, and later replication manager takes care\n+        // of send close commands to datanode to close containers on the\n+        // datanode.\n+\n+        // Skipping pipeline to container removal because, we got a\n+        // pipelineNotFoundException when adding container to\n+        // pipeline. So, we can only update container state.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34ee16ff8cd1ade8ff2be6ea8f5a6c6e45209043"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQwMDk1MQ==", "bodyText": "Done.", "url": "https://github.com/apache/ozone/pull/596#discussion_r385400951", "createdAt": "2020-02-27T22:10:45Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +119,28 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {\n+          pipelineManager.addContainerToPipeline(container.getPipelineID(),\n+              ContainerID.valueof(container.getContainerID()));\n+        }\n+      } catch (PipelineNotFoundException ex) {\n+        LOG.warn(\"Found a Container {} which is in {} state with pipeline {} \" +\n+                \"that does not exist. Closing Container.\", container,\n+            container.getState(), container.getPipelineID());\n+\n+        // Not firing CLOSE_CONTAINER event because CloseContainer event\n+        // handler is not registered by the time when we come\n+        // here. So, we are calling update Container state to set\n+        // container state to CLOSING, and later replication manager takes care\n+        // of send close commands to datanode to close containers on the\n+        // datanode.\n+\n+        // Skipping pipeline to container removal because, we got a\n+        // pipelineNotFoundException when adding container to\n+        // pipeline. So, we can only update container state.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMxNTEzOQ=="}, "originalCommit": {"oid": "34ee16ff8cd1ade8ff2be6ea8f5a6c6e45209043"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NjMzMzk0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOToxNTowOVrOFvd3BQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMjowOTo1NlrOFvi_LQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMxNjYxMw==", "bodyText": "We don't have to introduce a new method to updateContainerState. Since we are doing this inside a constructor, we don't need any lock.\nWe can directly call containerStateManager.updateContainerState(container.containerID(), HddsProtos.LifeCycleEvent.FINALIZE)", "url": "https://github.com/apache/ozone/pull/596#discussion_r385316613", "createdAt": "2020-02-27T19:15:09Z", "author": {"login": "nandakumar131"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +119,28 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {\n+          pipelineManager.addContainerToPipeline(container.getPipelineID(),\n+              ContainerID.valueof(container.getContainerID()));\n+        }\n+      } catch (PipelineNotFoundException ex) {\n+        LOG.warn(\"Found a Container {} which is in {} state with pipeline {} \" +\n+                \"that does not exist. Closing Container.\", container,\n+            container.getState(), container.getPipelineID());\n+\n+        // Not firing CLOSE_CONTAINER event because CloseContainer event\n+        // handler is not registered by the time when we come\n+        // here. So, we are calling update Container state to set\n+        // container state to CLOSING, and later replication manager takes care\n+        // of send close commands to datanode to close containers on the\n+        // datanode.\n+\n+        // Skipping pipeline to container removal because, we got a\n+        // pipelineNotFoundException when adding container to\n+        // pipeline. So, we can only update container state.\n+        updateContainerState(container.containerID(),\n+            HddsProtos.LifeCycleEvent.FINALIZE, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34ee16ff8cd1ade8ff2be6ea8f5a6c6e45209043"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQwMDYyMQ==", "bodyText": "This call is being done so that it will be reflected in container DB also.", "url": "https://github.com/apache/ozone/pull/596#discussion_r385400621", "createdAt": "2020-02-27T22:09:56Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -117,9 +119,28 @@ private void loadExistingContainers() throws IOException {\n           ContainerInfoProto.PARSER.parseFrom(entry.getValue()));\n       Preconditions.checkNotNull(container);\n       containerStateManager.loadContainer(container);\n-      if (container.getState() == LifeCycleState.OPEN) {\n-        pipelineManager.addContainerToPipeline(container.getPipelineID(),\n-            ContainerID.valueof(container.getContainerID()));\n+      try {\n+        if (container.getState() == LifeCycleState.OPEN) {\n+          pipelineManager.addContainerToPipeline(container.getPipelineID(),\n+              ContainerID.valueof(container.getContainerID()));\n+        }\n+      } catch (PipelineNotFoundException ex) {\n+        LOG.warn(\"Found a Container {} which is in {} state with pipeline {} \" +\n+                \"that does not exist. Closing Container.\", container,\n+            container.getState(), container.getPipelineID());\n+\n+        // Not firing CLOSE_CONTAINER event because CloseContainer event\n+        // handler is not registered by the time when we come\n+        // here. So, we are calling update Container state to set\n+        // container state to CLOSING, and later replication manager takes care\n+        // of send close commands to datanode to close containers on the\n+        // datanode.\n+\n+        // Skipping pipeline to container removal because, we got a\n+        // pipelineNotFoundException when adding container to\n+        // pipeline. So, we can only update container state.\n+        updateContainerState(container.containerID(),\n+            HddsProtos.LifeCycleEvent.FINALIZE, true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMxNjYxMw=="}, "originalCommit": {"oid": "34ee16ff8cd1ade8ff2be6ea8f5a6c6e45209043"}, "originalPosition": 46}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4918, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}