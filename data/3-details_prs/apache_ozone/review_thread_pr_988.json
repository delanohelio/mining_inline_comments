{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI0NzY5NjE1", "number": 988, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNjo0OToyMFrOEA9uAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzoxMTowMFrOEA-O9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDQ2NjU4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon-codegen/src/main/java/org/hadoop/ozone/recon/schema/UtilizationSchemaDefinition.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNjo0OToyMFrOGckbEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxODo0NDoxN1rOGcoITQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYxMDA2Ng==", "bodyText": "Do we know if 64 is the actual volume & bucket name length limit as enforced by OM? If not, we have to change this to handle longer lengths.", "url": "https://github.com/apache/ozone/pull/988#discussion_r432610066", "createdAt": "2020-05-29T16:49:20Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon-codegen/src/main/java/org/hadoop/ozone/recon/schema/UtilizationSchemaDefinition.java", "diffHunk": "@@ -83,11 +86,17 @@ private void createClusterGrowthTable(Connection conn) {\n   }\n \n   private void createFileSizeCountTable(Connection conn) {\n-    DSL.using(conn).createTableIfNotExists(FILE_COUNT_BY_SIZE_TABLE_NAME)\n+    dslContext.createTableIfNotExists(FILE_COUNT_BY_SIZE_TABLE_NAME)\n+        .column(\"volume\", SQLDataType.VARCHAR(64))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY3MDc5Nw==", "bodyText": "Yes, verified that the max character limit of volume name and bucket name is 63 characters.", "url": "https://github.com/apache/ozone/pull/988#discussion_r432670797", "createdAt": "2020-05-29T18:44:17Z", "author": {"login": "vivekratnavel"}, "path": "hadoop-ozone/recon-codegen/src/main/java/org/hadoop/ozone/recon/schema/UtilizationSchemaDefinition.java", "diffHunk": "@@ -83,11 +86,17 @@ private void createClusterGrowthTable(Connection conn) {\n   }\n \n   private void createFileSizeCountTable(Connection conn) {\n-    DSL.using(conn).createTableIfNotExists(FILE_COUNT_BY_SIZE_TABLE_NAME)\n+    dslContext.createTableIfNotExists(FILE_COUNT_BY_SIZE_TABLE_NAME)\n+        .column(\"volume\", SQLDataType.VARCHAR(64))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYxMDA2Ng=="}, "originalCommit": {"oid": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDUxODk0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestFileSizeCountTask.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzowMjozMVrOGck9OA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzowMjozMVrOGck9OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYxODgwOA==", "bodyText": "Good test to see how much we can handle!", "url": "https://github.com/apache/ozone/pull/988#discussion_r432618808", "createdAt": "2020-05-29T17:02:31Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestFileSizeCountTask.java", "diffHunk": "@@ -206,10 +216,189 @@ public void testProcess() {\n         Arrays.asList(updateEvent, putEvent, deleteEvent));\n     fileSizeCountTask.process(omUpdateEventBatch);\n \n-    upperBoundCount = fileSizeCountTask.getUpperBoundCount();\n-    assertEquals(1, upperBoundCount[0]); // newKey\n-    assertEquals(0, upperBoundCount[1]); // deletedKey\n-    assertEquals(0, upperBoundCount[4]); // updatedKey old\n-    assertEquals(1, upperBoundCount[6]); // updatedKey new\n+    assertEquals(4, fileCountBySizeDao.count());\n+    recordToFind.value3(1024L);\n+    assertEquals(1, fileCountBySizeDao.findById(recordToFind)\n+        .getCount().longValue());\n+    recordToFind.value3(2048L);\n+    assertEquals(0, fileCountBySizeDao.findById(recordToFind)\n+        .getCount().longValue());\n+    recordToFind.value3(16384L);\n+    assertEquals(0, fileCountBySizeDao.findById(recordToFind)\n+        .getCount().longValue());\n+    recordToFind.value3(65536L);\n+    assertEquals(1, fileCountBySizeDao.findById(recordToFind)\n+        .getCount().longValue());\n+  }\n+\n+  @Test\n+  public void testReprocessAtScale() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c"}, "originalPosition": 261}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDUzMDk4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/tasks/FileSizeCountTask.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzowNjoxNlrOGclE7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQwNjoxODoxOFrOGc_47Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyMDc4Mw==", "bodyText": "Since we don't read everything from the DB at init time, 'fileSizeCountMap' can be a local variable created inside the 'process' and 'reprocess' methods.", "url": "https://github.com/apache/ozone/pull/988#discussion_r432620783", "createdAt": "2020-05-29T17:06:16Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/tasks/FileSizeCountTask.java", "diffHunk": "@@ -49,33 +52,28 @@\n   private static final Logger LOG =\n       LoggerFactory.getLogger(FileSizeCountTask.class);\n \n-  private int maxBinSize = -1;\n-  private long maxFileSizeUpperBound = 1125899906842624L; // 1 PB\n-  private long[] upperBoundCount;\n-  private long oneKb = 1024L;\n+  // 1125899906842624L = 1PB\n+  private static final long MAX_FILE_SIZE_UPPER_BOUND = 1125899906842624L;\n   private FileCountBySizeDao fileCountBySizeDao;\n+  // Map to store file counts in each <volume,bucket,fileSizeUpperBound>\n+  private Map<FileSizeCountKey, Long> fileSizeCountMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc1NDMxNQ==", "bodyText": "Moving it to local variable would then require writeCountsToDB, handlePutKeyEvent and handleDeleteKeyEvent methods to take Map<FileSizeCountKey, Long> fileSizeCountMap as another argument. Currently, initializing this map in reprocess and process is just enough since both methods will never be called at the same time.", "url": "https://github.com/apache/ozone/pull/988#discussion_r432754315", "createdAt": "2020-05-29T21:47:28Z", "author": {"login": "vivekratnavel"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/tasks/FileSizeCountTask.java", "diffHunk": "@@ -49,33 +52,28 @@\n   private static final Logger LOG =\n       LoggerFactory.getLogger(FileSizeCountTask.class);\n \n-  private int maxBinSize = -1;\n-  private long maxFileSizeUpperBound = 1125899906842624L; // 1 PB\n-  private long[] upperBoundCount;\n-  private long oneKb = 1024L;\n+  // 1125899906842624L = 1PB\n+  private static final long MAX_FILE_SIZE_UPPER_BOUND = 1125899906842624L;\n   private FileCountBySizeDao fileCountBySizeDao;\n+  // Map to store file counts in each <volume,bucket,fileSizeUpperBound>\n+  private Map<FileSizeCountKey, Long> fileSizeCountMap;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyMDc4Mw=="}, "originalCommit": {"oid": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA2MDA3Nw==", "bodyText": "IMO, it is OK to have the handleDeleteKeyEvent & handlePutKeyEvent and writeCountsToDB to take the map as a parameter. They are meant to be stateless helper methods that act on the input given to them. In the current implementation, there is an assumption that the task's implementation makes of the higher level caller, which may not be true in the future.", "url": "https://github.com/apache/ozone/pull/988#discussion_r433060077", "createdAt": "2020-06-01T06:18:18Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/tasks/FileSizeCountTask.java", "diffHunk": "@@ -49,33 +52,28 @@\n   private static final Logger LOG =\n       LoggerFactory.getLogger(FileSizeCountTask.class);\n \n-  private int maxBinSize = -1;\n-  private long maxFileSizeUpperBound = 1125899906842624L; // 1 PB\n-  private long[] upperBoundCount;\n-  private long oneKb = 1024L;\n+  // 1125899906842624L = 1PB\n+  private static final long MAX_FILE_SIZE_UPPER_BOUND = 1125899906842624L;\n   private FileCountBySizeDao fileCountBySizeDao;\n+  // Map to store file counts in each <volume,bucket,fileSizeUpperBound>\n+  private Map<FileSizeCountKey, Long> fileSizeCountMap;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyMDc4Mw=="}, "originalCommit": {"oid": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5NDU1MDk1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/UtilizationEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzoxMTowMFrOGclRPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxNzoxMTowMFrOGclRPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyMzkzMw==", "bodyText": "Can we add an endpoint for getFileCounts(volume, bucket, fileSize(Default = null)) here?", "url": "https://github.com/apache/ozone/pull/988#discussion_r432623933", "createdAt": "2020-05-29T17:11:00Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/UtilizationEndpoint.java", "diffHunk": "@@ -34,7 +34,7 @@\n  */\n @Path(\"/utilization\")\n @Produces(MediaType.APPLICATION_JSON)\n-public class UtilizationService {\n+public class UtilizationEndpoint {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4189, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}