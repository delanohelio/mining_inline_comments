{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2MDYyNTM4", "number": 1613, "title": "HDDS-4480. Implement OM Prepare Request/Response.", "bodyText": "What changes were proposed in this pull request?\nThis is the first Jira to begin implementing prepare functionality for OM non rolling upgrade/downgrades. See HDDS-4470 for the design these Jiras aim to accomplish.\nThis PR adds the new OM request that will be used to prepare the OM for upgrade. In the applyTransaction step for this request:\n\nWait for double buffer flush to finish.\nTake a snapshot.\npurge the log.\nThe transaction log index of this request will be returned in the response to the caller.\n\nThis PR exposed a bug in the OM table cache cleanup, where the s3 table was still listed in the OMDBDefinition (although not used), and not listed in the OmMetadataManager. This resulted in an error when using the @CleanupTableInfo(cleanupAll = true) annotation on an OMResponse, because the OzoneManagerDoubleBuffer#cleanupCache method would get the s3 table from the OMDBDefinition, but fail to retrieve it from the OmMetadataManager. This issue has been fixed by removing the unused s3 table, and a unit test has been added to catch the issue.\nBefore the design of HDDS-4470 was finalized, it was initially proposed to prepare the OM using a CLI command, rather than a Ratis request, and some code to implement this was added. Since this approach will no longer be used, that code has either been removed by this PR, adapted to fit this PR, or commented out with a TODO marker so it can be adapted in later PRs for the prepare feature.\nAccording to HDDS-4470, correctness of the prepare feature is dependent on a gate in OzoneManagerStateMachine#preAppend, and a marker file written to disk. These are not implemented in this PR, but TODO notes referencing them have been left that will be picked up by later Jira issues.\nWhat is the link to the Apache JIRA\nHDDS-4480\nHow was this patch tested?\nIntegration tests added.", "createdAt": "2020-11-23T23:43:25Z", "url": "https://github.com/apache/ozone/pull/1613", "merged": true, "mergeCommit": {"oid": "a7797aacea8925b4e489f935b4b8344561b10439"}, "closed": true, "closedAt": "2020-12-06T05:39:25Z", "author": {"login": "errose28"}, "timelineItems": {"totalCount": 69, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABddZzJgAH2gAyNTI2MDYyNTM4OmY4ZTFkZGQ2NTkzOWZmOTUyNGVhZGRjNWE0MzA0MDhhYjkzNTg1Nzc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdjaPWcgFqTU0NTY3MjgyMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f8e1ddd65939ff9524eaddc5a430408ab9358577", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/f8e1ddd65939ff9524eaddc5a430408ab9358577", "committedDate": "2020-11-17T13:44:32Z", "message": "Outline new request class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4709e9fe046bdf9d1515126cdee014e4792dc4e3", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/4709e9fe046bdf9d1515126cdee014e4792dc4e3", "committedDate": "2020-11-17T14:05:18Z", "message": "Fix typo in proto definitions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f6206b50d04fe35859d8e9f5a5ba94d373db8f04", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/f6206b50d04fe35859d8e9f5a5ba94d373db8f04", "committedDate": "2020-11-17T14:05:35Z", "message": "Add Response class for prepare for upgrade"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a24420f13d89ea16af8943f0faa1391690d9b998", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/a24420f13d89ea16af8943f0faa1391690d9b998", "committedDate": "2020-11-18T18:17:32Z", "message": "Get RatisUpgradeUtils changes from original prepare upgrade feature"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfa75ee02770203130c40f842ac727957e868260", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/cfa75ee02770203130c40f842ac727957e868260", "committedDate": "2020-11-18T18:43:51Z", "message": "Switch ratis snapshot to newer version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c177fa3fa8e51b16094aa8194d961abdea5668f", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/4c177fa3fa8e51b16094aa8194d961abdea5668f", "committedDate": "2020-11-18T21:21:28Z", "message": "Remove --prepareForUpgrade startup flag\n\nOM now has prepared state internally that is not set on startup.\nA similar startup flag can be re-introduced when the --upgrade mode is implemented to take the OMs out of prepare with the new bits."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a5f333c6156818d02e2230accefd4c2779afe71", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/9a5f333c6156818d02e2230accefd4c2779afe71", "committedDate": "2020-11-18T21:58:19Z", "message": "Call new OM Prepare method to do purge and snapshot"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b26a6c9c9db1e757eb02d49915a45cfc02db173", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/6b26a6c9c9db1e757eb02d49915a45cfc02db173", "committedDate": "2020-11-18T22:00:00Z", "message": "Remove requestAllowed method from OzoneManager\n\nThis can be added when preAppend changes are handled"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a16d5f8dfe75df8e7e0800c4e3046cc4f974a87", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/3a16d5f8dfe75df8e7e0800c4e3046cc4f974a87", "committedDate": "2020-11-19T16:46:26Z", "message": "Fix typo in proto imports and declaration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b644600c7ce2efbe2e06ed42873c9dad6d827e6", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/0b644600c7ce2efbe2e06ed42873c9dad6d827e6", "committedDate": "2020-11-19T16:46:38Z", "message": "Update files to use new Ratis APIs after snapshot update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1bfa8e162c80c60d464f2b822a57c3c6643ef48", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/e1bfa8e162c80c60d464f2b822a57c3c6643ef48", "committedDate": "2020-11-19T19:58:28Z", "message": "Add missed Ratis upgrade fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cefdb08c0a08a1971cf0400f21cd27818b3f8f6f", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/cefdb08c0a08a1971cf0400f21cd27818b3f8f6f", "committedDate": "2020-11-19T21:52:18Z", "message": "Add original prepare integration test\n\nMight be discarded for the one Aravindan already created."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfb578d69d33df396ad87deb0db7023b39367bb1", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/cfb578d69d33df396ad87deb0db7023b39367bb1", "committedDate": "2020-11-19T23:29:49Z", "message": "Add Prepare Response to proto"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6cf0cef13f68a960ca277cace073106a139145b5", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/6cf0cef13f68a960ca277cace073106a139145b5", "committedDate": "2020-11-19T23:30:52Z", "message": "Fix typo in comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "99c9de139ef20b6e54c529ebe045ac1517c13822", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/99c9de139ef20b6e54c529ebe045ac1517c13822", "committedDate": "2020-11-19T23:32:09Z", "message": "Fix typo in response builder"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2433bddec9e9d83a0f8f2d0118bb901c54f299b0", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/2433bddec9e9d83a0f8f2d0118bb901c54f299b0", "committedDate": "2020-11-19T23:32:21Z", "message": "Initial draft of tests\n\nUnit test is minimal but passing.\nIntegration test still needs work."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "348eae2536368be69092d4d6ac18aa09dbcfa2a9", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/348eae2536368be69092d4d6ac18aa09dbcfa2a9", "committedDate": "2020-11-20T16:03:03Z", "message": "Add more robust (but failing) mini ozone cluster test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea88dfccd6282c83d2e3482ce6e9edc7974f0be3", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/ea88dfccd6282c83d2e3482ce6e9edc7974f0be3", "committedDate": "2020-11-20T16:55:23Z", "message": "Add (failing) test for calling prepare directly on OM with data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "454fa8dbd81607304f3dddfe77e0241880b54e3e", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/454fa8dbd81607304f3dddfe77e0241880b54e3e", "committedDate": "2020-11-20T19:13:43Z", "message": "Add passing test for prepare of one OM with no ratis transactions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "78eab948d23a26515d8fe93779ba62f52e55b565", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/78eab948d23a26515d8fe93779ba62f52e55b565", "committedDate": "2020-11-20T20:32:47Z", "message": "Fix NPE when preparing without transactions, and move prepare flag to correct place"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5eef0fdf8f175f37e57f248e498604b66d6baed4", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/5eef0fdf8f175f37e57f248e498604b66d6baed4", "committedDate": "2020-11-20T20:33:22Z", "message": "Remove todo comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b6332c5750df9fba6ca78e2646ac5e0de3468b6", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/1b6332c5750df9fba6ca78e2646ac5e0de3468b6", "committedDate": "2020-11-20T23:16:01Z", "message": "Fix bug in s3 table cleanup (not introduced by this change)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ec4316998a5dae8bca8fdf17796f68f9dbe76e1", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/7ec4316998a5dae8bca8fdf17796f68f9dbe76e1", "committedDate": "2020-11-20T23:17:08Z", "message": "Add comment explaining logic in snapshot and sync logs method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "57559e07901e2a934428d5687e446fb59c206909", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/57559e07901e2a934428d5687e446fb59c206909", "committedDate": "2020-11-20T23:18:16Z", "message": "Passing Ratis integration test for prepare\n\nStill need to clean up OzoneManager"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a6a861a8afa8097f4cbb35b16cd7af5340c16fb", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/4a6a861a8afa8097f4cbb35b16cd7af5340c16fb", "committedDate": "2020-11-23T22:48:11Z", "message": "Add imports to make code more readable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88b45db1b2b02be3a92f2412d325c4b880a5e55f", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/88b45db1b2b02be3a92f2412d325c4b880a5e55f", "committedDate": "2020-11-23T22:48:33Z", "message": "Fix old class header"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24b3497124b310d640fec70100f6c19f2f466431", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/24b3497124b310d640fec70100f6c19f2f466431", "committedDate": "2020-11-23T22:54:39Z", "message": "Add wait for double buffer flush in prepare request, and more robust testing\n\nThe complex test case with a downed OM is still failing due to issues with mini ozone cluster."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ce04cc781ccfeee73419ebf730c117d18c926e0", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/2ce04cc781ccfeee73419ebf730c117d18c926e0", "committedDate": "2020-11-23T23:00:05Z", "message": "Comment out failing test and update comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "212c03bd4189add41a6d6811c0ad076d863e41cf", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/212c03bd4189add41a6d6811c0ad076d863e41cf", "committedDate": "2020-11-23T23:21:51Z", "message": "Rename old uses of PrepareForUpgrade to Prepare"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ed9ec08503c3804d04e64e9b18ec911bc99c413", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/7ed9ec08503c3804d04e64e9b18ec911bc99c413", "committedDate": "2020-11-23T23:26:14Z", "message": "Fix some checkstyle violations"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3bdb40ea4f08e1e6dd373b61c86ea66560a642c", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/a3bdb40ea4f08e1e6dd373b61c86ea66560a642c", "committedDate": "2020-11-23T23:32:29Z", "message": "Fix checkstyle violations and remove unused OM code from older iteration"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM3NTY5Njkx", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-537569691", "createdAt": "2020-11-24T14:51:56Z", "commit": {"oid": "a3bdb40ea4f08e1e6dd373b61c86ea66560a642c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNDo1MTo1N1rOH5EeRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNDo1MTo1N1rOH5EeRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTYwNDE2Nw==", "bodyText": "Transaction entry added in double buffer is async flushed to db. Shall we pass transactionLogIndex to double check and make sure previous txns be applied.  I mean we would better to double check and ensure that snapshot index equals current prepare transactionLogIndex.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r529604167", "createdAt": "2020-11-24T14:51:57Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.hdds.ratis.RatisUpgradeUtils;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final long DOUBLE_BUFFER_FLUSH_TIMEOUT_SECONDS = 5 * 60;\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final long DOUBLE_BUFFER_FLUSH_CHECK_SECONDS = 1;\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareForUpgradeResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      OzoneManagerStateMachine omStateMachine =\n+          omRatisServer.getOmStateMachine();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      RatisUpgradeUtils.waitForAllTxnsApplied(omStateMachine, serverImpl,\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT_SECONDS,\n+          DOUBLE_BUFFER_FLUSH_CHECK_SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3bdb40ea4f08e1e6dd373b61c86ea66560a642c"}, "originalPosition": 83}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f259f39cb483cf2bb9e955d8c9a317fde0d89914", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/f259f39cb483cf2bb9e955d8c9a317fde0d89914", "committedDate": "2020-11-24T15:16:35Z", "message": "Merge branch 'HDDS-3698-upgrade' into HDDS-4480\n\n* HDDS-3698-upgrade: (46 commits)\n  HDDS-4468. Fix Goofys listBucket large than 1000 objects will stuck forever (#1595)\n  HDDS-4417. Simplify Ozone client code with configuration object -- addendum (#1581)\n  HDDS-4476. Improve the ZH translation of the HA.md in doc. (#1597)\n  HDDS-4432. Update Ratis version to latest snapshot. (#1586)\n  HDDS-4488. Open RocksDB read only when loading containers at Datanode startup (#1605)\n  HDDS-4478. Large deletedKeyset slows down OM via listStatus. (#1598)\n  HDDS-4452. findbugs.sh couldn't be executed after a full build (#1576)\n  HDDS-4427. Avoid ContainerCache in ContainerReader at Datanode startup (#1549)\n  HDDS-4448. Duplicate refreshPipeline in listStatus (#1569)\n  HDDS-4450. Cannot run ozone if HADOOP_HOME points to Hadoop install (#1572)\n  HDDS-4346.Ozone specific Trash Policy (#1535)\n  HDDS-4426. SCM should create transactions using all blocks received from OM (#1561)\n  HDDS-4399. Safe mode rule for piplelines should only consider open pipelines. (#1526)\n  HDDS-4367. Configuration for deletion service intervals should be different for OM, SCM and datanodes (#1573)\n  HDDS-4462. Add --frozen-lockfile to pnpm install to prevent ozone-recon-web/pnpm-lock.yaml from being updated automatically (#1589)\n  HDDS-4082. Create ZH translation of HA.md in doc. (#1591)\n  HDDS-4464. Upgrade httpclient version due to CVE-2020-13956. (#1590)\n  HDDS-4467. Acceptance test fails due to new Hadoop 3 image (#1594)\n  HDDS-4466. Update url in .asf.yaml to use TLP project (#1592)\n  HDDS-4458. Fix Max Transaction ID value in OM. (#1585)\n  ..."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30c405dd3089aa470d2f99544bc422f101ad1851", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/30c405dd3089aa470d2f99544bc422f101ad1851", "committedDate": "2020-11-24T16:07:14Z", "message": "Fix build errors, and clean up code formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4247f166fecfa584210fd3ea0b523c96f6ddede", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/a4247f166fecfa584210fd3ea0b523c96f6ddede", "committedDate": "2020-11-24T17:01:03Z", "message": "Add fully remove s3 table and add unit test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f9e80848087f25d1b72206f55ce4ed1bf70347f", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/8f9e80848087f25d1b72206f55ce4ed1bf70347f", "committedDate": "2020-11-24T17:04:40Z", "message": "Fix rat violation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad28431d6577868a9c84dd157d44090b18a389ed", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/ad28431d6577868a9c84dd157d44090b18a389ed", "committedDate": "2020-11-24T21:35:22Z", "message": "Fix double buffer wait and take snapshot outside of request's applyTxn"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90a3457e936457e8173b7e8f63a161eb12b52af0", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/90a3457e936457e8173b7e8f63a161eb12b52af0", "committedDate": "2020-11-25T17:09:14Z", "message": "Move all prepare logic back inside the prepare request\n\nAlso move the snapshot method out of RatisUpgradeUtils, meaning it is no longer used."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "28c2690879e9a9aaaa148c9e119d0203bb61c1d0", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/28c2690879e9a9aaaa148c9e119d0203bb61c1d0", "committedDate": "2020-11-25T18:58:37Z", "message": "Minor readability change"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d69fdea088d883e0f2b78b2c8f9fa66d2d7aa849", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/d69fdea088d883e0f2b78b2c8f9fa66d2d7aa849", "committedDate": "2020-11-25T18:59:52Z", "message": "Fix failures in tests with all 3 OMs up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff15f3e4e67ae79a60e23bc8f8624631dc4ab6d0", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/ff15f3e4e67ae79a60e23bc8f8624631dc4ab6d0", "committedDate": "2020-11-25T19:01:19Z", "message": "Remove unit test for prepare request\n\nBecause prepare request needs Ratis, we can only test it with integration tests and mini ozone cluster."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/3a6a9d2c22d25e757d80028288a39cb11e048668", "committedDate": "2020-11-25T19:07:33Z", "message": "Fix checkstyle violation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4ODM2OTQ4", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-538836948", "createdAt": "2020-11-25T20:48:35Z", "commit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo0ODozNlrOH6Davw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo1ODo0OFrOH6DqnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzNTQ1NQ==", "bodyText": "We need to have the RPC server running even in \"Prepared\" state. This if condition can be removed.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530635455", "createdAt": "2020-11-25T20:48:36Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1239,7 +1208,7 @@ public void start() throws IOException {\n       LOG.error(\"OM HttpServer failed to start.\", ex);\n     }\n \n-    if (!prepareForUpgrade) {\n+    if (!isPrepared) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzODQ2Ng==", "bodyText": "3 second timeout maybe a bit aggressive. Can we increase it to 30seconds?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530638466", "createdAt": "2020-11-25T20:56:11Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */\n+  // TODO: Fix this test so it passes.\n+  // @Test\n+  public void testPrepareDownedOM() throws Exception {\n+    // Index of the OM that will be shut down during this test.\n+    final int shutdownOMIndex = 2;\n+\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    // Create keys with all 3 OMs up.\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 50; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Shut down one OM.\n+    cluster.stopOzoneManager(shutdownOMIndex);\n+    OzoneManager downedOM = cluster.getOzoneManager(shutdownOMIndex);\n+    Assert.assertFalse(downedOM.isRunning());\n+\n+    // Write keys with the remaining OMs up.\n+    for (int i = 51; i <= 100; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Submit prepare request via Ratis.\n+    OzoneManager leaderOM = cluster.getOMLeader();\n+    long prepareIndex =\n+        leaderOM.getOmRatisServer().submitRequest(buildPrepareRequest())\n+            .getPrepareResponse()\n+            .getTxnID();\n+\n+    // Check that the two live OMs are prepared.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      if (om == leaderOM) {\n+        // Leader should have been prepared after we got the response.\n+        checkPrepared(om, prepareIndex);\n+      } else if (om != downedOM) {\n+        // Follower may still be applying transactions.\n+        waitAndCheckPrepared(om, prepareIndex);\n+      }\n+    }\n+\n+    // Restart the downed OM and wait for it to catch up.\n+    // Since prepare was the last Ratis transaction, it should have all data\n+    // it missed once it receives the prepare transaction.\n+    cluster.restartOzoneManager(downedOM, true);\n+    // Wait for other OMs to catch this one up on transactions.\n+    LambdaTestUtils.await(3000, 1000,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzOTUxNg==", "bodyText": "Let's add a logFilesPresentInRatisPeer 'true' assert here so that we start from an 'expected' state and also to make sure that there are no bugs in that method itself :).", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530639516", "createdAt": "2020-11-25T20:58:48Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */\n+  // TODO: Fix this test so it passes.\n+  // @Test\n+  public void testPrepareDownedOM() throws Exception {\n+    // Index of the OM that will be shut down during this test.\n+    final int shutdownOMIndex = 2;\n+\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    // Create keys with all 3 OMs up.\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 50; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Shut down one OM.\n+    cluster.stopOzoneManager(shutdownOMIndex);\n+    OzoneManager downedOM = cluster.getOzoneManager(shutdownOMIndex);\n+    Assert.assertFalse(downedOM.isRunning());\n+\n+    // Write keys with the remaining OMs up.\n+    for (int i = 51; i <= 100; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668"}, "originalPosition": 180}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6", "committedDate": "2020-11-25T23:42:09Z", "message": "Add fixes from code review\n\nIncrease test timeout to 30 seconds.\nAssert logs are present before prepare in tests.\nLeave RPC server running in prepared state."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQwMzU2ODg4", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-540356888", "createdAt": "2020-11-28T09:46:04Z", "commit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwOTo0NjowNFrOH7XfLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwOTo0Nzo1NFrOH7Xf2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAxMjg0NQ==", "bodyText": "Can we rename to PrepareUpgrade which can be more readable? In the design doc, it also called PrepareUpgrade request.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532012845", "createdAt": "2020-11-28T09:46:04Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "diffHunk": "@@ -74,6 +74,7 @@ enum Type {\n   DBUpdates = 53;\n   FinalizeUpgrade = 54;\n   FinalizeUpgradeProgress = 55;\n+  Prepare = 56;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAxMzAxNw==", "bodyText": "Can we rename to PrepareUpgradeRequest/PrepareUpgradeResponse?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532013017", "createdAt": "2020-11-28T09:47:54Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "diffHunk": "@@ -145,6 +146,7 @@ message OMRequest {\n   optional DBUpdatesRequest                  dbUpdatesRequest              = 53;\n   optional FinalizeUpgradeRequest           finalizeUpgradeRequest         = 54;\n   optional FinalizeUpgradeProgressRequest   finalizeUpgradeProgressRequest = 55;\n+  optional PrepareRequest                   prepareRequest                 = 56;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQwNDQ5MjUz", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-540449253", "createdAt": "2020-11-29T05:43:03Z", "commit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOVQwNTo0MzowM1rOH7gbzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOVQwNTo0MzowM1rOH7gbzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjE1OTQzNg==", "bodyText": "Not a comment for this PR, another TODO thing I am thinking: After this prepare request be executed, OM should  reject subsequent requests immediately, how do we implement this? Exit OM and use upgrade flag to restart OM?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532159436", "createdAt": "2020-11-29T05:43:03Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(serverImpl);\n+\n+      // TODO: Create marker file with txn index.\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 112}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0c82642283718163a8a31853c64e8e0798c48271", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/0c82642283718163a8a31853c64e8e0798c48271", "committedDate": "2020-11-30T15:40:17Z", "message": "Fix checkstyle violation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3de786e23c6778a7b265ab5b421a2ad11eaf40d3", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/3de786e23c6778a7b265ab5b421a2ad11eaf40d3", "committedDate": "2020-11-30T22:14:29Z", "message": "Retrigger CI"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ced3350e8caec9bd9ce7224a1319b954407a5026", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/ced3350e8caec9bd9ce7224a1319b954407a5026", "committedDate": "2020-11-30T23:08:16Z", "message": "Merge branch 'HDDS-3698-upgrade' into HDDS-4480\n\n* HDDS-3698-upgrade:\n  HDDS-4429. Create unit test for SimpleContainerDownloader. (#1551)\n  HDDS-4461. Reuse compiled binaries in acceptance test (#1588)\n  HDDS-4511: Avoiding StaleNodeHandler to take effect in TestDeleteWithSlowFollower. (#1625)\n  HDDS-4510. SCM can avoid creating RetriableDatanodeEventWatcher for deletion command ACK (#1626)\n  HDDS-3363. Intermittent failure in testContainerImportExport (#1618)\n  HDDS-4370. Datanode deletion service can avoid storing deleted blocks. (#1620)\n  HDDS-4512. Remove unused netty3 transitive dependency (#1627)\n  HDDS-4481. With HA OM can send deletion blocks to SCM multiple times. (#1608)\n  HDDS-4487. SCM can avoid using RETRIABLE_DATANODE_COMMAND for datanode deletion commands. (#1621)\n  HDDS-4471. GrpcOutputStream length can overflow (#1617)\n  HDDS-4308. Fix issue with quota update (#1489)\n  HDDS-4392. [DOC] Add Recon architecture to docs (#1602)\n  HDDS-4501. Reload OM State fail should terminate OM for any exceptions. (#1622)\n  HDDS-4492. CLI flag --quota should default to 'spaceQuota' to preserve backward compatibility. (#1609)\n  HDDS-3689. Add various profiles to MiniOzoneChaosCluster to run different modes. (#1420)\n  HDDS-4497. Recon File Size Count task throws SQL Exception. (#1612)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/e3a5a8919c6205ed438f36292b4ece78fdce3f25", "committedDate": "2020-12-01T15:29:11Z", "message": "Add accidentally deleted RPC server start call in OM"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTc5OTc4", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-542179978", "createdAt": "2020-12-01T18:26:18Z", "commit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoyNjoxOFrOH86JEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoyNjoxOFrOH86JEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyOTIwMw==", "bodyText": "Minor nit: Why isn't this externally configurable? Since we throw an IOException after waiting. For non-rolling upgrades probably unnecessary hence a minor nit.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533629203", "createdAt": "2020-12-01T18:26:18Z", "author": {"login": "swagle"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTgyNzk2", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-542182796", "createdAt": "2020-12-01T18:29:52Z", "commit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoyOTo1M1rOH86Rwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoyOTo1M1rOH86Rwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg==", "bodyText": "Minor nit: unused local references", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533631426", "createdAt": "2020-12-01T18:29:53Z", "author": {"login": "swagle"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 104}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTg2OTE3", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-542186917", "createdAt": "2020-12-01T18:35:23Z", "commit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODozNToyNFrOH86ekQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODozNToyNFrOH86ekQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzNDcwNQ==", "bodyText": "Can we add a comment here: What is the recovery step from this? If the snapshot index does not match will subsequent prepare ever succeed? cc: @avijayanhwx", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533634705", "createdAt": "2020-12-01T18:35:24Z", "author": {"login": "swagle"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(serverImpl);\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n+      throw new IOException(\"Index from Snapshot does not match last applied \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 169}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5185112d1fd1f7666aa808500ddb0c8aae0374e1", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/5185112d1fd1f7666aa808500ddb0c8aae0374e1", "committedDate": "2020-12-01T20:09:51Z", "message": "Update ratis request to use new API"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed1f492185a7f67d13c9e701739c751730252063", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/ed1f492185a7f67d13c9e701739c751730252063", "committedDate": "2020-12-01T20:26:27Z", "message": "Add comments about failure cases"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "committedDate": "2020-12-01T21:23:57Z", "message": "Fix checkstyle violations"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMzYwNTM2", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-542360536", "createdAt": "2020-12-01T22:46:13Z", "commit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMjo0NjoxM1rOH9C6iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMjo0NjoxM1rOH9C6iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3MjkzNg==", "bodyText": "I believe there is a chance of snapshotIndex != lastAppliedTermIndex.\nBecause once doubleBuffer flush completes, it calls updateLastAppliedIndex from DoubleBuffer flush thread, to update lastAppliedIndex, but if doubleBuffer flush thread has not completed updateLastAppliedIndex updating, then this might not be equal.\nThere is very little chance to happen, as there is takeSnapshot which flush to DB, as updateLastAppliedIndex is inmemory map update.\nSo, to be safer side check lastAppliedTermIndex is the same as the TransactionInfo table lastAppliedIndex in the waitForDoubleBufferFlush method.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533772936", "createdAt": "2020-12-01T22:46:13Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,\n+    // the exception is propagated, resulting in an error response to the\n+    // client. They can retry the prepare request.\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 176}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMzY4NzE0", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-542368714", "createdAt": "2020-12-01T23:01:03Z", "commit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMzowMTowM1rOH9DWCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMDoyNzowOVrOH9FVwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3OTk3OA==", "bodyText": "Minor: We can pass the serverImpl which we got in L106 to takeSnapshotAndPurgeLogs", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533779978", "createdAt": "2020-12-01T23:01:03Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4MTcwMA==", "bodyText": "Why we need to return success in this case, because when PrepareRequest is added to double-buffer that mean double-buffer will flush the transaction of PrepareRequest to DB, even if there is no request to OM at all.\nAnd also not understood the reason for the null pointer exception part", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533781700", "createdAt": "2020-12-01T23:05:03Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjYyOQ==", "bodyText": "Question: According to design flow, in preAppend we set the prepare flag to true so that no new transactions will be accepted. In which scenario will we have logs more than snapshotIndex and if we purge them those requests will not receive any response from OM leader and timed out?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533786629", "createdAt": "2020-12-01T23:15:51Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,\n+    // the exception is propagated, resulting in an error response to the\n+    // client. They can retry the prepare request.\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n+      throw new IOException(\"Index from Snapshot does not match last applied \" +\n+          \"Index\");\n+    }\n+\n+    RaftLog raftLog = impl.getState().getLog();\n+    // In order to get rid of all logs, make sure we also account for\n+    // intermediate Ratis entries that do not pertain to OM.\n+    long lastIndex = Math.max(snapshotIndex,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjgxNg==", "bodyText": "Why cleanupAll is true in this case, as this has not touched any DB, so it can be false right?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533786816", "createdAt": "2020-12-01T23:16:22Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/upgrade/OMPrepareResponse.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.upgrade;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Response for prepare request.\n+ */\n+@CleanupTableInfo(cleanupAll = true)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4OTA0NA==", "bodyText": "In design flow, the prepare flag is set in preAppend will that be handled in a seperate Jira?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533789044", "createdAt": "2020-12-01T23:21:42Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMjY3Mg==", "bodyText": "Is this failing test that needs more changes?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533812672", "createdAt": "2020-12-02T00:27:09Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,326 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OMRatisHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.Message;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+  private final int timeoutMillis = 30000;\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse = submitPrepareRequest(leader.getOmRatisServer());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Make sure all OMs have logs from writing data, so we can check that\n+    // they are purged after prepare.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      LambdaTestUtils.await(timeoutMillis, 1000,\n+          () -> logFilesPresentInRatisPeer(om));\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse = submitPrepareRequest(leader.getOmRatisServer());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 154}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyNDA3NjU4", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-542407658", "createdAt": "2020-12-02T00:29:46Z", "commit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMDoyOTo0NlrOH9FZeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMDoyOTo0NlrOH9FZeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMzYyNA==", "bodyText": "Offline discussion with @avijayanhwx this part of logic will be revisited in next jiras, if another PrepareUpgrade request is let in, we cleanup logIndexes greater than snapshotIndex and also syncWithSnapshot does not close when end logIndex is greater than snapshotIndex, so that might be left out.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533813624", "createdAt": "2020-12-02T00:29:46Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 173}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6ddb371f5dc5647601d627ca8846e5438d728523", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/6ddb371f5dc5647601d627ca8846e5438d728523", "committedDate": "2020-12-02T20:35:20Z", "message": "Update checks in snapshot and purge step"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "626120ce3011b4238a430789833ecfbb4fab7960", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/626120ce3011b4238a430789833ecfbb4fab7960", "committedDate": "2020-12-02T21:33:51Z", "message": "Remove cleanupTables = all marking from prepare response\n\nIt does not touch any tables."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb09232c91b1f8fca27db28116917a6cb27fe33e", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/bb09232c91b1f8fca27db28116917a6cb27fe33e", "committedDate": "2020-12-02T21:34:47Z", "message": "Readability improvements for waitForDoubleBufferFlush method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d12a4e1e87a59b203db63b9c9f0f8ee6c430d43", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/8d12a4e1e87a59b203db63b9c9f0f8ee6c430d43", "committedDate": "2020-12-02T23:08:53Z", "message": "Fix checkstyle violation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "464c15edc8c9f8e7c521edab6f29bbc3c13b52da", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/464c15edc8c9f8e7c521edab6f29bbc3c13b52da", "committedDate": "2020-12-03T17:18:09Z", "message": "Allow OMPrepareResponse to have no cleanup tables in unit test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a3ad7259f026832e0b4f35f7ab028ed7ce70fbf", "author": {"user": {"login": "errose28", "name": "Ethan Rose"}}, "url": "https://github.com/apache/ozone/commit/7a3ad7259f026832e0b4f35f7ab028ed7ce70fbf", "committedDate": "2020-12-04T16:52:22Z", "message": "Wait on both ratis index and DB index, and don't terminate OM on failed prepare"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzUyMDQ0", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-545352044", "createdAt": "2020-12-04T22:57:31Z", "commit": {"oid": "6ddb371f5dc5647601d627ca8846e5438d728523"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMjo1NzozMVrOH_lRJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMjo1OTo1M1rOH_lUQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMjkzNQ==", "bodyText": "Right now adding this logic might have issue, as there is no safeguard logic to not allow further requests after PUR.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536432935", "createdAt": "2020-12-04T22:57:31Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -166,36 +166,29 @@ private static void waitForDoubleBufferFlush(\n    */\n   public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n       throws IOException {\n-\n     StateMachine stateMachine = impl.getStateMachine();\n     long snapshotIndex = stateMachine.takeSnapshot();\n+    RaftLog raftLog = impl.getState().getLog();\n+    long raftLogIndex = raftLog.getLastEntryTermIndex().getIndex();\n \n-    // If the snapshot indices from Ratis and the state machine do not match,\n-    // the exception is propagated, resulting in an error response to the\n-    // client. They can retry the prepare request.\n-    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n-      throw new IOException(\"Index from Snapshot does not match last applied \" +\n-          \"Index\");\n+    if (snapshotIndex != raftLogIndex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ddb371f5dc5647601d627ca8846e5438d728523"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ==", "bodyText": "When PUR is flushed, in DB of transactionInfo table still it is null means something wrong right?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536433729", "createdAt": "2020-12-04T22:59:53Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -137,16 +137,21 @@ private static void waitForDoubleBufferFlush(\n       // If no transactions have been persisted to the DB, transaction info\n       // will be null, not zero, causing a null pointer exception within\n       // ozoneManager#getRatisSnaphotIndex.\n-      // Get the transaction directly instead.\n-      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+      // Get the transaction directly instead to handle the case when it is\n+      // null.\n+      OMTransactionInfo dbTxnInfo = ozoneManager.getMetadataManager()\n           .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n-      if (txnInfo == null) {\n-        success = (txnLogIndex == 0);\n+      if (dbTxnInfo == null) {\n+        // If there are no transactions in the DB, we are prepared to log", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb09232c91b1f8fca27db28116917a6cb27fe33e"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzY5MDY0", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-545369064", "createdAt": "2020-12-04T23:53:08Z", "commit": {"oid": "7a3ad7259f026832e0b4f35f7ab028ed7ce70fbf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzY5MTg0", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-545369184", "createdAt": "2020-12-04T23:53:39Z", "commit": {"oid": "7a3ad7259f026832e0b4f35f7ab028ed7ce70fbf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NjcyODIy", "url": "https://github.com/apache/ozone/pull/1613#pullrequestreview-545672822", "createdAt": "2020-12-06T05:38:53Z", "commit": {"oid": "7a3ad7259f026832e0b4f35f7ab028ed7ce70fbf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1953, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}