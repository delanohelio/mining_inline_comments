{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2MDg1MDgx", "number": 656, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzoyNDoyNlrODnLG4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzozNzoxOFrODnLd6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNDAzMDQxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/freon/FakeScmBlockLocationProtocolClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzoyNDoyNlrOF1BKaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzoyNDoyNlrOF1BKaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTEzNzg5Ng==", "bodyText": "Intended to be BLOCK_PER_CONTAINER?", "url": "https://github.com/apache/ozone/pull/656#discussion_r391137896", "createdAt": "2020-03-11T17:24:26Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/freon/FakeScmBlockLocationProtocolClient.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.freon;\n+\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ContainerBlockID;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.GetScmInfoResponseProto;\n+import org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos.AllocateBlockResponse;\n+import org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos.AllocateScmBlockResponseProto;\n+import org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos.AllocateScmBlockResponseProto.Builder;\n+import org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos.SCMBlockLocationRequest;\n+import org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos.SCMBlockLocationResponse;\n+import org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos.Status;\n+import org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos.Type;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Fake SCM client to return a simulated block location.\n+ */\n+public final class FakeScmBlockLocationProtocolClient {\n+\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(FakeScmBlockLocationProtocolClient.class);\n+\n+  public static final int BLOCK_PER_COUNTER = 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "977f740b0fc1f861186abddde5b2fb0c735d9dd4"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNDAzOTU4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/freon/FakeScmContainerLocationProtocolClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzoyNjozNVrOF1BQBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQxNjo0NzowNFrOF4N51A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTEzOTMzMg==", "bodyText": "Isn't node 1 added in the loop, too?", "url": "https://github.com/apache/ozone/pull/656#discussion_r391139332", "createdAt": "2020-03-11T17:26:35Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/freon/FakeScmContainerLocationProtocolClient.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.freon;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.DatanodeDetailsProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.Node;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeState;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.NodeQueryResponseProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.NodeQueryResponseProto.Builder;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.ScmContainerLocationRequest;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.ScmContainerLocationResponse;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.ScmContainerLocationResponse.Status;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.Type;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Fake SCM client to return a simulated block location.\n+ */\n+public final class FakeScmContainerLocationProtocolClient {\n+\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(FakeScmContainerLocationProtocolClient.class);\n+\n+  private FakeScmContainerLocationProtocolClient() {\n+  }\n+\n+  public static ScmContainerLocationResponse submitRequest(\n+      ScmContainerLocationRequest req)\n+      throws IOException {\n+    try {\n+      if (req.getCmdType() == Type.QueryNode) {\n+        Builder builder = NodeQueryResponseProto.newBuilder()\n+            .addDatanodes(Node.newBuilder()\n+                .setNodeID(FakeClusterTopology.INSTANCE.getDatanode(1))\n+                .addNodeStates(NodeState.HEALTHY)\n+                .build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "977f740b0fc1f861186abddde5b2fb0c735d9dd4"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDQ5MjM3Mg==", "bodyText": "Yeah, it came from an old code, thanks.", "url": "https://github.com/apache/ozone/pull/656#discussion_r394492372", "createdAt": "2020-03-18T16:47:04Z", "author": {"login": "elek"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/freon/FakeScmContainerLocationProtocolClient.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.freon;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.DatanodeDetailsProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.Node;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeState;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.NodeQueryResponseProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.NodeQueryResponseProto.Builder;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.ScmContainerLocationRequest;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.ScmContainerLocationResponse;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.ScmContainerLocationResponse.Status;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos.Type;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Fake SCM client to return a simulated block location.\n+ */\n+public final class FakeScmContainerLocationProtocolClient {\n+\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(FakeScmContainerLocationProtocolClient.class);\n+\n+  private FakeScmContainerLocationProtocolClient() {\n+  }\n+\n+  public static ScmContainerLocationResponse submitRequest(\n+      ScmContainerLocationRequest req)\n+      throws IOException {\n+    try {\n+      if (req.getCmdType() == Type.QueryNode) {\n+        Builder builder = NodeQueryResponseProto.newBuilder()\n+            .addDatanodes(Node.newBuilder()\n+                .setNodeID(FakeClusterTopology.INSTANCE.getDatanode(1))\n+                .addNodeStates(NodeState.HEALTHY)\n+                .build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTEzOTMzMg=="}, "originalCommit": {"oid": "977f740b0fc1f861186abddde5b2fb0c735d9dd4"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNDA4OTM5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/freon/FakeClusterTopology.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzozNzoxOFrOF1Btsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzozNzoxOFrOF1Btsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0NjkzMA==", "bodyText": "typo: piplines -> pipelines", "url": "https://github.com/apache/ozone/pull/656#discussion_r391146930", "createdAt": "2020-03-11T17:37:18Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/freon/FakeClusterTopology.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdds.freon;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.DatanodeDetailsProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.Pipeline;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.Port;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Class to store pre-generated topology information for load-tests.\n+ */\n+public class FakeClusterTopology {\n+\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(FakeClusterTopology.class);\n+\n+  public static final FakeClusterTopology INSTANCE = new FakeClusterTopology();\n+\n+  private List<DatanodeDetailsProto> datanodes = new ArrayList<>();\n+\n+  private List<Pipeline> piplines = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "977f740b0fc1f861186abddde5b2fb0c735d9dd4"}, "originalPosition": 47}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4812, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}